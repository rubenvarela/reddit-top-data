{"kind": "Listing", "data": {"after": "t3_11g2nbo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel sometimes like this sub is a bit of a dbt / snowflake / sql love-in. Nothing wrong with that stack or skillset btw but I thought that stuff was more for analytics engineers?\n\nI am more involved in the platforms &amp; ingestion side of things. Lots of IaC for setting up data infrastructure, maintaining a streaming solution, working with SWE teams to ingest data from their apps and OLTP systems in a transactional and performant manner, and implementing things like data contracts and schema validation to stop upstream breaking changes. Some custom integrations using python and various AWS services to pull external data sources. I'm also pretty good with spark and do some initial validation, transformations &amp; optimizations etc in the warehouse before handing over to the modelers.\n\nGot to be other people like me here but I guess we're in a minority? Curious to hear where the boundary between DE and AE lies in your business?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any other DEs here not involved in data warehousing / data modeling? Where's the love for the infrastructure and ingestion guys?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fyslh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677750450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel sometimes like this sub is a bit of a dbt / snowflake / sql love-in. Nothing wrong with that stack or skillset btw but I thought that stuff was more for analytics engineers?&lt;/p&gt;\n\n&lt;p&gt;I am more involved in the platforms &amp;amp; ingestion side of things. Lots of IaC for setting up data infrastructure, maintaining a streaming solution, working with SWE teams to ingest data from their apps and OLTP systems in a transactional and performant manner, and implementing things like data contracts and schema validation to stop upstream breaking changes. Some custom integrations using python and various AWS services to pull external data sources. I&amp;#39;m also pretty good with spark and do some initial validation, transformations &amp;amp; optimizations etc in the warehouse before handing over to the modelers.&lt;/p&gt;\n\n&lt;p&gt;Got to be other people like me here but I guess we&amp;#39;re in a minority? Curious to hear where the boundary between DE and AE lies in your business?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fyslh", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fyslh/any_other_des_here_not_involved_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fyslh/any_other_des_here_not_involved_in_data/", "subreddit_subscribers": 91659, "created_utc": 1677750450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on an API data ingestion project, and I usually use AWS Lambda or Python on Databricks for the whole process, but I was wondering if there are any better options/services for Extract and Load part of the process, like dbt is for data transformation.", "author_fullname": "t2_nmja4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If dbt is the \"T\" part of an \"ELT\", what do you use for \"EL\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fhmqu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677703813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on an API data ingestion project, and I usually use AWS Lambda or Python on Databricks for the whole process, but I was wondering if there are any better options/services for Extract and Load part of the process, like dbt is for data transformation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fhmqu", "is_robot_indexable": true, "report_reasons": null, "author": "we_need_more_lumber", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fhmqu/if_dbt_is_the_t_part_of_an_elt_what_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fhmqu/if_dbt_is_the_t_part_of_an_elt_what_do_you_use/", "subreddit_subscribers": 91659, "created_utc": 1677703813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company didn't give raises this year, so wanted to survey if that was common. \n\nRaise: 0%  \nYOE: 5  \nIndustry: Healthcare", "author_fullname": "t2_x2qa5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2023 Raise Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fg6vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677701266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company didn&amp;#39;t give raises this year, so wanted to survey if that was common. &lt;/p&gt;\n\n&lt;p&gt;Raise: 0%&lt;br/&gt;\nYOE: 5&lt;br/&gt;\nIndustry: Healthcare&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fg6vq", "is_robot_indexable": true, "report_reasons": null, "author": "fadeghost12345", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fg6vq/2023_raise_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fg6vq/2023_raise_survey/", "subreddit_subscribers": 91659, "created_utc": 1677701266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow Data Engineers,\n\nI sometimes find Analytics Engineers in my company create select statements with group by 1,2,3,4,5,6,7,8,9,10,11\n\nI'd like to help my team avoid this bad practice but I feel I don't have strong-enough arguments yet.\nBesides being hard to read and maintain, I'm sure there are other drawbacks.\n\nWhat are the drawbacks of creating such long group bys? And what is the appropriate way to avoid them?\n\nThanks a lot in advance for your help \ud83d\ude4f", "author_fullname": "t2_75ftbv6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Group by 1,2,3,4,5,6,7,8,9,10,11", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fyyi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677751060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;I sometimes find Analytics Engineers in my company create select statements with group by 1,2,3,4,5,6,7,8,9,10,11&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to help my team avoid this bad practice but I feel I don&amp;#39;t have strong-enough arguments yet.\nBesides being hard to read and maintain, I&amp;#39;m sure there are other drawbacks.&lt;/p&gt;\n\n&lt;p&gt;What are the drawbacks of creating such long group bys? And what is the appropriate way to avoid them?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance for your help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fyyi5", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Falcon_9", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fyyi5/group_by_1234567891011/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fyyi5/group_by_1234567891011/", "subreddit_subscribers": 91659, "created_utc": 1677751060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now, I'm still focused on getting a good foundation for most of the industry tools. Some things that I'm working to get more exposure to are Spark, Kafka, and datawarehouse management. I have a workable competency for most of the other major tools/concepts. \n\nI'm wondering if I should also prioritize learning a low-mid level language? I sometimes feel like my computer science foundational skills are very lacking. I also have had to look up stuff when certain technologies require things related to computer networking, ports, etc.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a self taught programmer, is it necessary to learn a low-mid level level language?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fkmvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677710527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now, I&amp;#39;m still focused on getting a good foundation for most of the industry tools. Some things that I&amp;#39;m working to get more exposure to are Spark, Kafka, and datawarehouse management. I have a workable competency for most of the other major tools/concepts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if I should also prioritize learning a low-mid level language? I sometimes feel like my computer science foundational skills are very lacking. I also have had to look up stuff when certain technologies require things related to computer networking, ports, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fkmvz", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11fkmvz/as_a_self_taught_programmer_is_it_necessary_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fkmvz/as_a_self_taught_programmer_is_it_necessary_to/", "subreddit_subscribers": 91659, "created_utc": 1677710527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently I have been seeing many posts talking about ETL/ELT and suggesting airbyte/fivetran/ some other tool for such purposes.I have been using Nifi for more than a couple of years and I liked the flexibility it provides / the functionalities it provides out of the box.I am just curious that, is it just me feeling so or does Nifi now no longer has the community approval.\n\nPS: I have tried Airbyte/Dataprep for ELT and found the UI to be good, but functionality wise I still thought nifi has better connectors available.\n\nPPS: Would love to hear what else are being considered as alternatives to NiFi. From my knowledge Airbyte/Fivetran/ADF/ .....", "author_fullname": "t2_3m6lypuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache NiFi dead", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g217e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677761739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677761548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I have been seeing many posts talking about ETL/ELT and suggesting airbyte/fivetran/ some other tool for such purposes.I have been using Nifi for more than a couple of years and I liked the flexibility it provides / the functionalities it provides out of the box.I am just curious that, is it just me feeling so or does Nifi now no longer has the community approval.&lt;/p&gt;\n\n&lt;p&gt;PS: I have tried Airbyte/Dataprep for ELT and found the UI to be good, but functionality wise I still thought nifi has better connectors available.&lt;/p&gt;\n\n&lt;p&gt;PPS: Would love to hear what else are being considered as alternatives to NiFi. From my knowledge Airbyte/Fivetran/ADF/ .....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11g217e", "is_robot_indexable": true, "report_reasons": null, "author": "Bored_ITzen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g217e/is_apache_nifi_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g217e/is_apache_nifi_dead/", "subreddit_subscribers": 91659, "created_utc": 1677761548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y15lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Composable OLAP, Unbundling of the Datawarehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "name": "t3_11g9ek8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RfDRasO0QJ24ju8fCH10qz73DTVUy-FBN_hWPqKZtZQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677780263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.fal.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.fal.ai/composable-olap/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?auto=webp&amp;v=enabled&amp;s=e48fdea921349d75304c8641c932560dd43784dc", "width": 1488, "height": 1048}, "resolutions": [{"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429628724da1eaf75d0fd6bff418b256291de7fe", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eed0705330a4ff47feeaa2d7190eb506e9ed83df", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26d2fabccb286988ee0ecc10a08e0aef5debe919", "width": 320, "height": 225}, {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0fa5c6c0076946bf2a7b37351bacad33ef186323", "width": 640, "height": 450}, {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78a0843b95e62e78a7a45e6ef0022630ace8dc0a", "width": 960, "height": 676}, {"url": "https://external-preview.redd.it/Jrm6U8U6Oe6ICDz2UuLqgKlEREOhTcfmCD2-3Zz9iEk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9005ba88fec57f10300811e5afc333eb259a243e", "width": 1080, "height": 760}], "variants": {}, "id": "ZinaVX5eSuAk-VMHQt5lJ-HbVtlq6_liKAqmKIT8RoU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11g9ek8", "is_robot_indexable": true, "report_reasons": null, "author": "gorkemyurt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g9ek8/composable_olap_unbundling_of_the_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.fal.ai/composable-olap/", "subreddit_subscribers": 91659, "created_utc": 1677780263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me, it has to be (S)FTP. I would have never guessed that they would still be so popular and used for mission-critical data workflows.", "author_fullname": "t2_cqao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technologies you didn't expect to be so popular in the industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g3w7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677766699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me, it has to be (S)FTP. I would have never guessed that they would still be so popular and used for mission-critical data workflows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11g3w7v", "is_robot_indexable": true, "report_reasons": null, "author": "dan_the_lion", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g3w7v/technologies_you_didnt_expect_to_be_so_popular_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g3w7v/technologies_you_didnt_expect_to_be_so_popular_in/", "subreddit_subscribers": 91659, "created_utc": 1677766699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to implement a data stack for a small business with a low amount of data (at most 10-100k rows). We have to get the data out of a CRM through an API, preferably store it in a data warehouse and then display it in Power BI.\n\nI'm having problems finding a cheap and reliable data stack solution though as there are so many options and I've previously worked with enterprise offerings like Azure but in this case I feel like it is going to be too expensive.\n\nCurrently we have some python scripts scheduled with cron, but we want something better with an actual orchestrator that could monitor the pipelines as the API from which we get most of our data is not entirely reliable.\n\nI've considered using Airflow, but could you suggest any cloud platforms to host this for this small scale?\n\nAnd what about some cheap SQL data warehouse? I've used Azure dedicated SQL but even at the lowest level that's a bit too expensive.", "author_fullname": "t2_elso2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data stack would you use for small use cases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fxhaa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677745749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to implement a data stack for a small business with a low amount of data (at most 10-100k rows). We have to get the data out of a CRM through an API, preferably store it in a data warehouse and then display it in Power BI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having problems finding a cheap and reliable data stack solution though as there are so many options and I&amp;#39;ve previously worked with enterprise offerings like Azure but in this case I feel like it is going to be too expensive.&lt;/p&gt;\n\n&lt;p&gt;Currently we have some python scripts scheduled with cron, but we want something better with an actual orchestrator that could monitor the pipelines as the API from which we get most of our data is not entirely reliable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered using Airflow, but could you suggest any cloud platforms to host this for this small scale?&lt;/p&gt;\n\n&lt;p&gt;And what about some cheap SQL data warehouse? I&amp;#39;ve used Azure dedicated SQL but even at the lowest level that&amp;#39;s a bit too expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fxhaa", "is_robot_indexable": true, "report_reasons": null, "author": "Kardinals", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fxhaa/what_data_stack_would_you_use_for_small_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fxhaa/what_data_stack_would_you_use_for_small_use_cases/", "subreddit_subscribers": 91659, "created_utc": 1677745749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm working on an Airflow project where we have 20 parallel pipelines, independent of each other. We currently use YAML configuration files to define the pipelines, and our DAG loops over these pipelines to complete the same tasks for each of them.\n\nWe're facing two challenges that we're trying to solve:\n\n1. We have pipelines with different processing times, and files for these pipelines arrive at different times. We're trying to avoid splitting them into separate DAGs and instead, create a single DAG that checks for files at different times and processes them accordingly. Is this a good approach? How can we avoid failing the tasks if the files are not available at the time when the DAG checks for them?\n2. We want to optimize resource utilization and reduce the load on the scheduler. Currently, we use a single DAG that checks for files every x minutes, even when there are no files to process. We're thinking of grouping pipelines based on the time when the files arrive to create separate DAGs that run only when the files are present. Does this make sense? How significant is the resource use for the OmegaFileSensor poking every 30 minutes?\n\nWe're considering these options, but we're not sure which one is the best approach. I'd love to hear your thoughts and experiences.\n\nThanks in advance for your help!", "author_fullname": "t2_gfx5s46h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage Airflow DAGs and optimize resource utilization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fvvul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677740399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on an Airflow project where we have 20 parallel pipelines, independent of each other. We currently use YAML configuration files to define the pipelines, and our DAG loops over these pipelines to complete the same tasks for each of them.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re facing two challenges that we&amp;#39;re trying to solve:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We have pipelines with different processing times, and files for these pipelines arrive at different times. We&amp;#39;re trying to avoid splitting them into separate DAGs and instead, create a single DAG that checks for files at different times and processes them accordingly. Is this a good approach? How can we avoid failing the tasks if the files are not available at the time when the DAG checks for them?&lt;/li&gt;\n&lt;li&gt;We want to optimize resource utilization and reduce the load on the scheduler. Currently, we use a single DAG that checks for files every x minutes, even when there are no files to process. We&amp;#39;re thinking of grouping pipelines based on the time when the files arrive to create separate DAGs that run only when the files are present. Does this make sense? How significant is the resource use for the OmegaFileSensor poking every 30 minutes?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We&amp;#39;re considering these options, but we&amp;#39;re not sure which one is the best approach. I&amp;#39;d love to hear your thoughts and experiences.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fvvul", "is_robot_indexable": true, "report_reasons": null, "author": "LeftHelicopter5297", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fvvul/how_to_manage_airflow_dags_and_optimize_resource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fvvul/how_to_manage_airflow_dags_and_optimize_resource/", "subreddit_subscribers": 91659, "created_utc": 1677740399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had an interview with a company in which they asked this. I talked about use of metadata in ADF but couldn\u2019t say anything on databricks. How do the pros do it?", "author_fullname": "t2_6n3bw1hv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality checks in Azure Data Factory and Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g62b8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had an interview with a company in which they asked this. I talked about use of metadata in ADF but couldn\u2019t say anything on databricks. How do the pros do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11g62b8", "is_robot_indexable": true, "report_reasons": null, "author": "thtkrazyguy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g62b8/data_quality_checks_in_azure_data_factory_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g62b8/data_quality_checks_in_azure_data_factory_and/", "subreddit_subscribers": 91659, "created_utc": 1677772263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I\u2019m just venturing into the Data Engineering world and working towards building my first project which I\u2019m building on GCP. I had a question about the flow and storage of data. Once I extract the raw data \u2014&gt; store it in Google Cloud Storage (GCS) (or Data Lake) \u2014&gt;Pull data from GCS and transform it (change data types, remove nulls etc) \u2014&gt; Load it into Big Query (Data Warehouse); is it ok to also store the transformed data in GCS or would it be considered repetitive and waste of storage space? My main confusion is if this is an acceptable practice or not. TIA", "author_fullname": "t2_6qagmcox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Question about ELT pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fty7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677734430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m just venturing into the Data Engineering world and working towards building my first project which I\u2019m building on GCP. I had a question about the flow and storage of data. Once I extract the raw data \u2014&amp;gt; store it in Google Cloud Storage (GCS) (or Data Lake) \u2014&amp;gt;Pull data from GCS and transform it (change data types, remove nulls etc) \u2014&amp;gt; Load it into Big Query (Data Warehouse); is it ok to also store the transformed data in GCS or would it be considered repetitive and waste of storage space? My main confusion is if this is an acceptable practice or not. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fty7b", "is_robot_indexable": true, "report_reasons": null, "author": "nomadicjourneys", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fty7b/beginner_question_about_elt_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fty7b/beginner_question_about_elt_pipeline/", "subreddit_subscribers": 91659, "created_utc": 1677734430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hope this is the right place to ask.\n\nSo essentially I\u2018ve been trying to remodel our companies data from two separate web shop projects into a star schema for data analysis with PowerBi.\n\n\nThe issue I\u2018ve encountered which I do not seem to get around, even after doing quite a bit of research is: How to model subscriptions/contracts in relation with orders\u2026\n\nSo the business works as follows: Customers can make orders, the first order a customer makes initiates a contract(or subscription) which essentially runs until the end of the year and is renewed(unless cancelled).\n\nSo a contract can be associated with multiple orders.\nNow I am trying to analyze the amount of contracts that have been extended (or not extended) and created a Fact table essentially containing all contracts, with contract_id as a primary key, contract_start, contract end, and surrogate keys for dimensions such as termination reason, contract state.,contract notice date etc.\n\n\nHowever my main issue here would that, that I\u2018d have to link my Contracts Fact table with my dimension fact table through contract_id, if I want to get further information about the contracts\u2026 but that would break the rules of a Kimball star schema. \n\nIs there any correct way to model this?", "author_fullname": "t2_baxqioo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kimball Data Modeling: Problem with two related Fact tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fm7re", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677714215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this is the right place to ask.&lt;/p&gt;\n\n&lt;p&gt;So essentially I\u2018ve been trying to remodel our companies data from two separate web shop projects into a star schema for data analysis with PowerBi.&lt;/p&gt;\n\n&lt;p&gt;The issue I\u2018ve encountered which I do not seem to get around, even after doing quite a bit of research is: How to model subscriptions/contracts in relation with orders\u2026&lt;/p&gt;\n\n&lt;p&gt;So the business works as follows: Customers can make orders, the first order a customer makes initiates a contract(or subscription) which essentially runs until the end of the year and is renewed(unless cancelled).&lt;/p&gt;\n\n&lt;p&gt;So a contract can be associated with multiple orders.\nNow I am trying to analyze the amount of contracts that have been extended (or not extended) and created a Fact table essentially containing all contracts, with contract_id as a primary key, contract_start, contract end, and surrogate keys for dimensions such as termination reason, contract state.,contract notice date etc.&lt;/p&gt;\n\n&lt;p&gt;However my main issue here would that, that I\u2018d have to link my Contracts Fact table with my dimension fact table through contract_id, if I want to get further information about the contracts\u2026 but that would break the rules of a Kimball star schema. &lt;/p&gt;\n\n&lt;p&gt;Is there any correct way to model this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fm7re", "is_robot_indexable": true, "report_reasons": null, "author": "DalaiLamaRood", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fm7re/kimball_data_modeling_problem_with_two_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fm7re/kimball_data_modeling_problem_with_two_related/", "subreddit_subscribers": 91659, "created_utc": 1677714215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, would really like my next career move to be in a senior position and would love feedback on how to best prepare for that. Since graduating a little over 3 years ago I have worked at 2 startups as the first DE hire, which has been great for hands on experience and top to bottom of funnel experience, but hasn't been great for mentorship.  Being startups, I've additionally had to do a lot of platform, ML, and software engineering work. This has made me very much a generalist, and not a specialist at anything. What are the main skillsets that are required to make the jump to Senior Data Engineer? As I've had a very hard time getting that first interview when applying.\n\nmy very high level background for context\n\nDE Architecture: \n\n\\- Full lake house architecture and data warehouse design and build (2x)\n\n\\- Custom blue/green deployment for zero data downtime\n\nTools/Infrastructure: \n\n\\- Pulumi/Terraform to manage resources (databricks, s3, sqs, etc.), permission (rbac), compute, etc.\n\n\\- AWS DMS for data migration\n\n\\- AWS SQS/SNS for streaming notifications\n\n\\- Databricks (DLT), Postgres, aurora, MongoDb, Snowflake,\n\nML Ops:\n\n\\- Integrated models into production code base (javascript)\n\n\\- Custom ML labeling and auto retrain pipelines (logging, label-studio, data collection, etc.)\n\nWeb Scraping:\n\n\\- BFS web crawler (saving har files and parsing responses to reduce dev maintenance time)\n\n\\- Puppeteer html/css manipulation for ML model to handle iframes, css styling, hidden elements, etc.", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to Senior DE Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fs2n0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677729094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, would really like my next career move to be in a senior position and would love feedback on how to best prepare for that. Since graduating a little over 3 years ago I have worked at 2 startups as the first DE hire, which has been great for hands on experience and top to bottom of funnel experience, but hasn&amp;#39;t been great for mentorship.  Being startups, I&amp;#39;ve additionally had to do a lot of platform, ML, and software engineering work. This has made me very much a generalist, and not a specialist at anything. What are the main skillsets that are required to make the jump to Senior Data Engineer? As I&amp;#39;ve had a very hard time getting that first interview when applying.&lt;/p&gt;\n\n&lt;p&gt;my very high level background for context&lt;/p&gt;\n\n&lt;p&gt;DE Architecture: &lt;/p&gt;\n\n&lt;p&gt;- Full lake house architecture and data warehouse design and build (2x)&lt;/p&gt;\n\n&lt;p&gt;- Custom blue/green deployment for zero data downtime&lt;/p&gt;\n\n&lt;p&gt;Tools/Infrastructure: &lt;/p&gt;\n\n&lt;p&gt;- Pulumi/Terraform to manage resources (databricks, s3, sqs, etc.), permission (rbac), compute, etc.&lt;/p&gt;\n\n&lt;p&gt;- AWS DMS for data migration&lt;/p&gt;\n\n&lt;p&gt;- AWS SQS/SNS for streaming notifications&lt;/p&gt;\n\n&lt;p&gt;- Databricks (DLT), Postgres, aurora, MongoDb, Snowflake,&lt;/p&gt;\n\n&lt;p&gt;ML Ops:&lt;/p&gt;\n\n&lt;p&gt;- Integrated models into production code base (javascript)&lt;/p&gt;\n\n&lt;p&gt;- Custom ML labeling and auto retrain pipelines (logging, label-studio, data collection, etc.)&lt;/p&gt;\n\n&lt;p&gt;Web Scraping:&lt;/p&gt;\n\n&lt;p&gt;- BFS web crawler (saving har files and parsing responses to reduce dev maintenance time)&lt;/p&gt;\n\n&lt;p&gt;- Puppeteer html/css manipulation for ML model to handle iframes, css styling, hidden elements, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fs2n0", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fs2n0/transition_to_senior_de_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fs2n0/transition_to_senior_de_advice/", "subreddit_subscribers": 91659, "created_utc": 1677729094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tabular is GA (Iceberg Founders)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fr7wl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677726823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tabular.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tabular.io/blog/announcing-tabular/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11fr7wl", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fr7wl/tabular_is_ga_iceberg_founders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tabular.io/blog/announcing-tabular/", "subreddit_subscribers": 91659, "created_utc": 1677726823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a junior computer technician / Junior programmer and I have been working on an inventory management system in C# using dapper and MariaDB , thing is I need to figure out a way to manage items sold in boxes with the particularity being these boxes can be sold by items instead of boxes and I need to keep an accurate track of how many individual items I have as well as said boxes. Im contemplating the idea of just remove X amount of items to the contained product everytime a Box is removed from the inventory but it feels wrongs to do it this way. Would really like the point of view of people with more experience on how to manage this database wise (And or C# wise)", "author_fullname": "t2_qmmqdk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips regarding product management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fmqcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677715469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a junior computer technician / Junior programmer and I have been working on an inventory management system in C# using dapper and MariaDB , thing is I need to figure out a way to manage items sold in boxes with the particularity being these boxes can be sold by items instead of boxes and I need to keep an accurate track of how many individual items I have as well as said boxes. Im contemplating the idea of just remove X amount of items to the contained product everytime a Box is removed from the inventory but it feels wrongs to do it this way. Would really like the point of view of people with more experience on how to manage this database wise (And or C# wise)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fmqcu", "is_robot_indexable": true, "report_reasons": null, "author": "Psychot75", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fmqcu/tips_regarding_product_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fmqcu/tips_regarding_product_management/", "subreddit_subscribers": 91659, "created_utc": 1677715469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At mine we have a single central data science server that connects to the data warehouse/databases and has all the credentials. There is a different user on the server for each employee - access is never direct via SSH but through a Jupyter notebook. Each user on the server has their own copies of the git repository that they copy updates to. This is done for security and simplicity - not every employee stores database connection credentials on their computer. One drawback is editing code on a different server than the one you are running on (this makes it difficult to grep, use git, custom IDE's etc.)\n\nSome alternatives I can think of are:\n\nA different data science server for every employee. This way employees can use any OS for their personal computer but run queries on a universal (docker image?) environment so that they don't have to install anything custom. Also the compute is not centered on a single server - everyone can run queries, edit code, login at the same time via SSH.\n\nAllow the employees to store database credentials on their own computer. This allows ultimate flexibility for the employees to edit the queries, run jobs, etc. at the cost of security. Compute could be done really locally (duckdb, pandas, etc) or by running queries on the cloud data warehouse and let that thing worry about concurrency.\n\nWhat do you do?", "author_fullname": "t2_b3n9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Data Engineers, Scientists, and Analysts run queries at your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11flx0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677714097.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677713493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At mine we have a single central data science server that connects to the data warehouse/databases and has all the credentials. There is a different user on the server for each employee - access is never direct via SSH but through a Jupyter notebook. Each user on the server has their own copies of the git repository that they copy updates to. This is done for security and simplicity - not every employee stores database connection credentials on their computer. One drawback is editing code on a different server than the one you are running on (this makes it difficult to grep, use git, custom IDE&amp;#39;s etc.)&lt;/p&gt;\n\n&lt;p&gt;Some alternatives I can think of are:&lt;/p&gt;\n\n&lt;p&gt;A different data science server for every employee. This way employees can use any OS for their personal computer but run queries on a universal (docker image?) environment so that they don&amp;#39;t have to install anything custom. Also the compute is not centered on a single server - everyone can run queries, edit code, login at the same time via SSH.&lt;/p&gt;\n\n&lt;p&gt;Allow the employees to store database credentials on their own computer. This allows ultimate flexibility for the employees to edit the queries, run jobs, etc. at the cost of security. Compute could be done really locally (duckdb, pandas, etc) or by running queries on the cloud data warehouse and let that thing worry about concurrency.&lt;/p&gt;\n\n&lt;p&gt;What do you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11flx0o", "is_robot_indexable": true, "report_reasons": null, "author": "third_dude", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11flx0o/how_do_data_engineers_scientists_and_analysts_run/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11flx0o/how_do_data_engineers_scientists_and_analysts_run/", "subreddit_subscribers": 91659, "created_utc": 1677713493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I get a bunch of emails that have attachments that need to be saved into a data warehouse. Some are csv, xlsx, json.\n\nI thought it would be a bigger issue but I can\u2019t find anything. Maybe I am not searching the right phrases.\n\nI have built a solution in the past but it was incredibly tedious. \n\nAre there any frameworks or saas for this problem?", "author_fullname": "t2_6mh3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Framework to get email attachments into Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ga6hd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677782190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get a bunch of emails that have attachments that need to be saved into a data warehouse. Some are csv, xlsx, json.&lt;/p&gt;\n\n&lt;p&gt;I thought it would be a bigger issue but I can\u2019t find anything. Maybe I am not searching the right phrases.&lt;/p&gt;\n\n&lt;p&gt;I have built a solution in the past but it was incredibly tedious. &lt;/p&gt;\n\n&lt;p&gt;Are there any frameworks or saas for this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ga6hd", "is_robot_indexable": true, "report_reasons": null, "author": "jahaz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ga6hd/framework_to_get_email_attachments_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ga6hd/framework_to_get_email_attachments_into_data/", "subreddit_subscribers": 91659, "created_utc": 1677782190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tired of 70 hour sprint weeks because there's no technical leadership.\n\n&amp;#x200B;\n\nGuess I needed to hear it.", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't know who needs to hear this, but scoping a project depends who is on the team just as much as what the project is.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g94rc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677779625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tired of 70 hour sprint weeks because there&amp;#39;s no technical leadership.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Guess I needed to hear it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11g94rc", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g94rc/i_dont_know_who_needs_to_hear_this_but_scoping_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g94rc/i_dont_know_who_needs_to_hear_this_but_scoping_a/", "subreddit_subscribers": 91659, "created_utc": 1677779625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the process of doing some due diligence on Monte Carlo and am curious to hear any thoughts or opinions. Do they have a good product? Is the price right? Do you believe this segment is ripe for continued growth? Have you used them and if so, how was that experience? Thanks in advance!", "author_fullname": "t2_mjm9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Monte Carlo (data observability company)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g7zpp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677776870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of doing some due diligence on Monte Carlo and am curious to hear any thoughts or opinions. Do they have a good product? Is the price right? Do you believe this segment is ripe for continued growth? Have you used them and if so, how was that experience? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11g7zpp", "is_robot_indexable": true, "report_reasons": null, "author": "Kitten-Smuggler", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g7zpp/thoughts_on_monte_carlo_data_observability_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g7zpp/thoughts_on_monte_carlo_data_observability_company/", "subreddit_subscribers": 91659, "created_utc": 1677776870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3lv3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created data testing framework in Python, with support for Spark, Snowflake and MySQL/MariaDB. Maybe you will find it useful. Comments and contributions are mostly welcomed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11g6bt2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gMbsLpTpbVeFB8AGDgp8VmSafGpMdr919ZD6sx2Fx4I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677772884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/gladykov/chain.train/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?auto=webp&amp;v=enabled&amp;s=f23f078effa003d002dec337381ee7eb64aab01d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6df34dc45724c7774893c29f5c1390f4c98ac29", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62c528595669faa17925c3a5c316c9fcd3a0b3c8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e5ac8d1ffbf3d8a126f1a4f660fb8bc40d552cf", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ed8a46e5faca2677a9682706d641e36cfe807c2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65ea5b4a08c16a4546dd4b64bb6106b75472346d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4g1qJ5fcLM6n2CC9ooQUyOmO2m_8wmojPUvPrJuZ4zE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6de5cfeaee0118492a452d41a8a38635d5070408", "width": 1080, "height": 540}], "variants": {}, "id": "1ojDRnlz6qAZQumcF4gwE4dgcrjzfx98ewvUuWP0fY8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11g6bt2", "is_robot_indexable": true, "report_reasons": null, "author": "gladykov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g6bt2/i_created_data_testing_framework_in_python_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/gladykov/chain.train/", "subreddit_subscribers": 91659, "created_utc": 1677772884.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm struggling to figure out what granularity to set my dimension and fact table, so I was wondering if any of yall could help/guide me.\n\nThe data I have is like a Service Request (SR), where someone would call into a helpdesk to create a Service Request, making it a status of `New`. Most of the time, the SR isn't answered right away, so it gets put into a status of `In Progress`. Once a SR is completed, it gets put into a `Completed` status. There are a few other options for Status, but you probably get the point already.\n\nNow the business process that I'm trying to help measure KPIs around these Service Requests - how long were they open, how many there are in general, etc. I'm struggling as to whether I should be setting my fact and/or dim tables at the Service Request - Status granularity, where there would be one row for each status that a Service Request meets, or at just the Service Request granularity so that one row is one SR and includes all statuses and calculations as different fields. \n\nIn simpler words, any reason why or why not to do either option? I know I would get more granularity at a SR - Status combination. I'm also struggling to differentiate how I would differentiate a fact and dimension table, because I think this warrants both `fact_service_request` and `dim_service_request`. Would you put those two tables at the same granularity?\n\nHow would you model this data?", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some advice/pointers on how to set up a dimensional model for this scenario", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g5yy1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to figure out what granularity to set my dimension and fact table, so I was wondering if any of yall could help/guide me.&lt;/p&gt;\n\n&lt;p&gt;The data I have is like a Service Request (SR), where someone would call into a helpdesk to create a Service Request, making it a status of &lt;code&gt;New&lt;/code&gt;. Most of the time, the SR isn&amp;#39;t answered right away, so it gets put into a status of &lt;code&gt;In Progress&lt;/code&gt;. Once a SR is completed, it gets put into a &lt;code&gt;Completed&lt;/code&gt; status. There are a few other options for Status, but you probably get the point already.&lt;/p&gt;\n\n&lt;p&gt;Now the business process that I&amp;#39;m trying to help measure KPIs around these Service Requests - how long were they open, how many there are in general, etc. I&amp;#39;m struggling as to whether I should be setting my fact and/or dim tables at the Service Request - Status granularity, where there would be one row for each status that a Service Request meets, or at just the Service Request granularity so that one row is one SR and includes all statuses and calculations as different fields. &lt;/p&gt;\n\n&lt;p&gt;In simpler words, any reason why or why not to do either option? I know I would get more granularity at a SR - Status combination. I&amp;#39;m also struggling to differentiate how I would differentiate a fact and dimension table, because I think this warrants both &lt;code&gt;fact_service_request&lt;/code&gt; and &lt;code&gt;dim_service_request&lt;/code&gt;. Would you put those two tables at the same granularity?&lt;/p&gt;\n\n&lt;p&gt;How would you model this data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11g5yy1", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g5yy1/need_some_advicepointers_on_how_to_set_up_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g5yy1/need_some_advicepointers_on_how_to_set_up_a/", "subreddit_subscribers": 91659, "created_utc": 1677772034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are building some dimensional data models related to web analytics (user events, pages, etc) coming from adobe and I\u2019m interested in some ideas for the data model design. This book has some thoughts but is over 20 years old so yeah the internet has changed a bit. Just wondering if there is something that is a modern equivalent to it, or if anyone has good resources for modeling web analytics data. Thanks!", "author_fullname": "t2_c6w52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a modern alternative to the Kimball \u201cData Webhouse Toolkit\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g5yxd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are building some dimensional data models related to web analytics (user events, pages, etc) coming from adobe and I\u2019m interested in some ideas for the data model design. This book has some thoughts but is over 20 years old so yeah the internet has changed a bit. Just wondering if there is something that is a modern equivalent to it, or if anyone has good resources for modeling web analytics data. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11g5yxd", "is_robot_indexable": true, "report_reasons": null, "author": "EmergenL", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g5yxd/is_there_a_modern_alternative_to_the_kimball_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g5yxd/is_there_a_modern_alternative_to_the_kimball_data/", "subreddit_subscribers": 91659, "created_utc": 1677772033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I'm developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB's to Azure and add them to elastic pools - nothing crazy.\n\nI'm currently working on my MS in DS while working full time. It's quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp; Finance.\n\nI've been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I'm extremely interested in and I was ecstatic to find out I got an interview. \n\nBelow are the general job duties:\n\n* Identifying and implementing optimal cloud-based solutions, including team education and training\n* Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance\n* Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science\n* Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures\n* Orchestrating and automating cloud operations and processes\n* Collaborating with stakeholders across the business to balance competing objectives\n* Working with third-party vendors to meet business requirements.\n\nAs I mentioned before, I don't have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide's, but nothing in terms of actual development.\n\nI have just completed the 3rd and final interview they\u2019ve offered me the position. I\u2019m just worried I might struggle to balance the masters workload and the new job. \n\nA few questions/concerns:\n\n* Firstly, does it seem like I have imposter syndrome? I worry that I'm just not qualified for this job and I won't deliver what they expect\n* Do I continue my MS if I'm getting legitimate experience as a Cloud Engineer?\n* If I do continue my MS, am I going to be able to manage the workload with this new role?\n* The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?\n\nThank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g5dx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677770610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I&amp;#39;m developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB&amp;#39;s to Azure and add them to elastic pools - nothing crazy.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on my MS in DS while working full time. It&amp;#39;s quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp;amp; Finance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I&amp;#39;m extremely interested in and I was ecstatic to find out I got an interview. &lt;/p&gt;\n\n&lt;p&gt;Below are the general job duties:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identifying and implementing optimal cloud-based solutions, including team education and training&lt;/li&gt;\n&lt;li&gt;Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance&lt;/li&gt;\n&lt;li&gt;Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science&lt;/li&gt;\n&lt;li&gt;Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures&lt;/li&gt;\n&lt;li&gt;Orchestrating and automating cloud operations and processes&lt;/li&gt;\n&lt;li&gt;Collaborating with stakeholders across the business to balance competing objectives&lt;/li&gt;\n&lt;li&gt;Working with third-party vendors to meet business requirements.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As I mentioned before, I don&amp;#39;t have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide&amp;#39;s, but nothing in terms of actual development.&lt;/p&gt;\n\n&lt;p&gt;I have just completed the 3rd and final interview they\u2019ve offered me the position. I\u2019m just worried I might struggle to balance the masters workload and the new job. &lt;/p&gt;\n\n&lt;p&gt;A few questions/concerns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Firstly, does it seem like I have imposter syndrome? I worry that I&amp;#39;m just not qualified for this job and I won&amp;#39;t deliver what they expect&lt;/li&gt;\n&lt;li&gt;Do I continue my MS if I&amp;#39;m getting legitimate experience as a Cloud Engineer?&lt;/li&gt;\n&lt;li&gt;If I do continue my MS, am I going to be able to manage the workload with this new role?&lt;/li&gt;\n&lt;li&gt;The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11g5dx0", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11g5dx0/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g5dx0/career_advice/", "subreddit_subscribers": 91659, "created_utc": 1677770610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Am I correct in thinking the T step is at least 2 parts? The first is cleaning the data (formatting, removing nulls, etc) and the second is adding in the business logic and doing whatever modeling is needed to make the data usable for the business? Is this technically part of the transformation process? \n\nI would even think some of the main KPIs should be built out before the data is fed into whatever reporting or viz tool the company uses. Like if you need to track product sell thru, that involves joining orders to inventory and the calculation should be done in the data warehouse to create the 'source of truth'.", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner question about transformation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g2nbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677763319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Am I correct in thinking the T step is at least 2 parts? The first is cleaning the data (formatting, removing nulls, etc) and the second is adding in the business logic and doing whatever modeling is needed to make the data usable for the business? Is this technically part of the transformation process? &lt;/p&gt;\n\n&lt;p&gt;I would even think some of the main KPIs should be built out before the data is fed into whatever reporting or viz tool the company uses. Like if you need to track product sell thru, that involves joining orders to inventory and the calculation should be done in the data warehouse to create the &amp;#39;source of truth&amp;#39;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11g2nbo", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11g2nbo/beginner_question_about_transformation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11g2nbo/beginner_question_about_transformation/", "subreddit_subscribers": 91659, "created_utc": 1677763319.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}