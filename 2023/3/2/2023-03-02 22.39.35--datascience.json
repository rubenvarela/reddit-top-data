{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: [**quix-streams**](https://github.com/quixio/quix-streams))   \nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: \n\n    def on_parameter_data_handler(df: pd.DataFrame):\n    \n        # If the braking force applied is more than 50%, we mark HardBraking with True\n        df[\"HardBraking\"] = df.apply(lambda row: \"True\" if row.Brake &gt; 0.5 else \"False\", axis=1)\n    \n        stream_producer.timeseries.publish(df)  # Send data back to the stream\n\n Anyway, just posting it here with the hope that it makes someone\u2019s job easier.", "author_fullname": "t2_byx12w8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A more accessible python library for interacting with Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g68dw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: &lt;a href=\"https://github.com/quixio/quix-streams\"&gt;&lt;strong&gt;quix-streams&lt;/strong&gt;&lt;/a&gt;)&lt;br/&gt;\nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def on_parameter_data_handler(df: pd.DataFrame):\n\n    # If the braking force applied is more than 50%, we mark HardBraking with True\n    df[&amp;quot;HardBraking&amp;quot;] = df.apply(lambda row: &amp;quot;True&amp;quot; if row.Brake &amp;gt; 0.5 else &amp;quot;False&amp;quot;, axis=1)\n\n    stream_producer.timeseries.publish(df)  # Send data back to the stream\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Anyway, just posting it here with the hope that it makes someone\u2019s job easier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?auto=webp&amp;v=enabled&amp;s=78d5675a84f6726e7618cd3c42250b7d51c363fa", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13a6a9b0f62ec4033e162a3122ec7f912271ca6a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc65e91fc8010c02faecf87eb3e910a374973c22", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42f0e4e73e3e4a79267bd8b98e97ca66836c96e6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19838c0ac27c309b1e866cc3aaae3b447bdd9671", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7215b5d40310d21d5d1e4a91848bac7d3147f437", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fdcf5eafb0a7070f4aea6e4bdfacc90c0c14c34d", "width": 1080, "height": 540}], "variants": {}, "id": "ZuoT62YF_0noD68oqz7qPsTsv9obcPgozqhj0lnVZyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g68dw", "is_robot_indexable": true, "report_reasons": null, "author": "Jota_Blanco", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "subreddit_subscribers": 853345, "created_utc": 1677772668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been struggling with staying organized as an MLE for quite a long time. \n\nI have multiple model classes to work on and multiple iteration per model class. Then each have experiments assigned or not. Some have resource constraints  that need to be resolved. Some models need to finish at the same time and be experimented simultanously, etcetra.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nWondering, how do you keep your self organized and the modelling pipeline progress smooth? Any app, toolbox, methodology helpful for this?", "author_fullname": "t2_e6ppgt2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Meta] How do you stay organized as a machine learning engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fk7to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677709591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been struggling with staying organized as an MLE for quite a long time. &lt;/p&gt;\n\n&lt;p&gt;I have multiple model classes to work on and multiple iteration per model class. Then each have experiments assigned or not. Some have resource constraints  that need to be resolved. Some models need to finish at the same time and be experimented simultanously, etcetra.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Wondering, how do you keep your self organized and the modelling pipeline progress smooth? Any app, toolbox, methodology helpful for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fk7to", "is_robot_indexable": true, "report_reasons": null, "author": "Which-Distance1384", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fk7to/meta_how_do_you_stay_organized_as_a_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fk7to/meta_how_do_you_stay_organized_as_a_machine/", "subreddit_subscribers": 853345, "created_utc": 1677709591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I've found out that it doesn't give the same model parameters.", "author_fullname": "t2_6zlc2ji4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing for RMSE vs. R2, for feature selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g416x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I&amp;#39;ve found out that it doesn&amp;#39;t give the same model parameters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g416x", "is_robot_indexable": true, "report_reasons": null, "author": "dilkur", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "subreddit_subscribers": 853345, "created_utc": 1677767070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We have a model that's trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.\n\nProblem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn't too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. \n\nBut, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can't say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won't have to impute the missing values?\n\nAny tips would be highly appreciated \ud83d\ude4f", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Missing data related", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g8u9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677778919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a model that&amp;#39;s trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.&lt;/p&gt;\n\n&lt;p&gt;Problem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn&amp;#39;t too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. &lt;/p&gt;\n\n&lt;p&gt;But, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can&amp;#39;t say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won&amp;#39;t have to impute the missing values?&lt;/p&gt;\n\n&lt;p&gt;Any tips would be highly appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g8u9w", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g8u9w/missing_data_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g8u9w/missing_data_related/", "subreddit_subscribers": 853345, "created_utc": 1677778919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a new graduate working as a data analyst for a large health organization. I was formally trained in Stata and have some experience using R and Python. Our organization uses SQL to query data, and is moving more towards SAS as the standard for analyses. I had always planned on moving away from Stata and focusing more on SQL, R and Python, but I am now expected to learn SAS. I would still like to be proficient in R and Python, however, I'm worried that trying to learn too many programs will limit my ability to really excel in any one of them.\n\nMy question is how many statistical programs do you have in your \"toolkit\", and how many can one learn before reaching a point of diminishing returns?", "author_fullname": "t2_129ywp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many statistical programs have you learned?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fjzre", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677709091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new graduate working as a data analyst for a large health organization. I was formally trained in Stata and have some experience using R and Python. Our organization uses SQL to query data, and is moving more towards SAS as the standard for analyses. I had always planned on moving away from Stata and focusing more on SQL, R and Python, but I am now expected to learn SAS. I would still like to be proficient in R and Python, however, I&amp;#39;m worried that trying to learn too many programs will limit my ability to really excel in any one of them.&lt;/p&gt;\n\n&lt;p&gt;My question is how many statistical programs do you have in your &amp;quot;toolkit&amp;quot;, and how many can one learn before reaching a point of diminishing returns?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fjzre", "is_robot_indexable": true, "report_reasons": null, "author": "amipregananant", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fjzre/how_many_statistical_programs_have_you_learned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fjzre/how_many_statistical_programs_have_you_learned/", "subreddit_subscribers": 853345, "created_utc": 1677709091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I'd love to hear your thoughts on my story. I applied for Slack DS internship early November. They reached out in December and I interviewed in mid-December. After the first round, they got me waiting for long. The recruiter reached out in Jan 20 finally and said I'm in for the second round which will be the last one ( except for the presentation round after that). I did my second interview on Jan 27 and again since then, they didn't get back to me. I emailed the recruiter - no response. I contacted the manager with whom I interviewed and she said she is not sure about the recruitment progress and that I should contact the recruiter. She also said that she will check with the recruiter herself. As of now, I'm still waiting. My workday status is interview. I know it isn't going right but can't stop thinking about what's happening. Is it just ghosting? Then why the manager got back with basically no updates? It just sucks to get no response whatsoever... \n\nThank you!", "author_fullname": "t2_31lqqzal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slack DS Summer Intern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11foffz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677719751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;d love to hear your thoughts on my story. I applied for Slack DS internship early November. They reached out in December and I interviewed in mid-December. After the first round, they got me waiting for long. The recruiter reached out in Jan 20 finally and said I&amp;#39;m in for the second round which will be the last one ( except for the presentation round after that). I did my second interview on Jan 27 and again since then, they didn&amp;#39;t get back to me. I emailed the recruiter - no response. I contacted the manager with whom I interviewed and she said she is not sure about the recruitment progress and that I should contact the recruiter. She also said that she will check with the recruiter herself. As of now, I&amp;#39;m still waiting. My workday status is interview. I know it isn&amp;#39;t going right but can&amp;#39;t stop thinking about what&amp;#39;s happening. Is it just ghosting? Then why the manager got back with basically no updates? It just sucks to get no response whatsoever... &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11foffz", "is_robot_indexable": true, "report_reasons": null, "author": "pdb29", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11foffz/slack_ds_summer_intern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11foffz/slack_ds_summer_intern/", "subreddit_subscribers": 853345, "created_utc": 1677719751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You have a bunch of time series data from some sensors attached to different parts of a machine and one or more parts get damaged, which, in principle, should reflect in the signals from corresponding sensors.\n\nWhat approaches come to mind in order to detect/localize anomalies in the data that correspond to the damaging event and/or predicting/forecasting the same?\n\nTime series is discontinuous in time as the machine is operating only certain hours a day, with several breaks in between.", "author_fullname": "t2_8cvbnc48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick and basic approaches for anomaly detection in time series data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fl6ht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677711781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You have a bunch of time series data from some sensors attached to different parts of a machine and one or more parts get damaged, which, in principle, should reflect in the signals from corresponding sensors.&lt;/p&gt;\n\n&lt;p&gt;What approaches come to mind in order to detect/localize anomalies in the data that correspond to the damaging event and/or predicting/forecasting the same?&lt;/p&gt;\n\n&lt;p&gt;Time series is discontinuous in time as the machine is operating only certain hours a day, with several breaks in between.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fl6ht", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious_Two_810", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fl6ht/quick_and_basic_approaches_for_anomaly_detection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fl6ht/quick_and_basic_approaches_for_anomaly_detection/", "subreddit_subscribers": 853345, "created_utc": 1677711781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m excited to share **ActiveLab**, a better algorithm for practical active learning.\n\nhttps://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441\n\nWe recently published a [paper](https://arxiv.org/abs/2301.11856) introducing this novel method and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we've made a quick [Jupyter tutorial](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) to run ActiveLab on your own data. For ML researchers, we've made all of our [benchmarking code](https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks) available for reproducibility so you can see for yourself how effective ActiveLab is in practice.\n\nLabeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: **which new data should I label, or which of my current labels should be checked again?**\n\nhttps://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532\n\nActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).\n\nIf you're interested in reading more, check out our blogpost: [https://cleanlab.ai/blog/active-learning/](https://cleanlab.ai/blog/active-learning/)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ActiveLab: Active Learning with Data Re-Labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": false, "media_metadata": {"txcqiokmndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/txcqiokmndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7d8d67e9a27f3e9285d527d97e3e4eb02745a31"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/txcqiokmndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e76a85cb7aed17de368f294442b8ebaf67689a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/txcqiokmndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58229ab58467ee7a78e93c80393f1add5197ce9d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/txcqiokmndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef92c312f65f5cb27f47322c13cd7da812bc331"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f7dc49616689bbf2494f80cdef7b794eb239377"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532"}, "id": "txcqiokmndla1"}, "j2payaxlndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/j2payaxlndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01d685cfe0e84c7330b2a6c8539f6a4962a6f49f"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/j2payaxlndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee839ef82870e92011aa669f688ae342c0ccfe5a"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/j2payaxlndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01bb7951a8dd486e1fcb47e6afa8342c061092cb"}, {"y": 521, "x": 640, "u": "https://preview.redd.it/j2payaxlndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32109a8f100ca18f84d51c80feaf5f12e7cbde28"}, {"y": 782, "x": 960, "u": "https://preview.redd.it/j2payaxlndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=376c6267681605bba52a5b4571dd3b35efa4c285"}, {"y": 879, "x": 1080, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcdddc82c386ea077c6ab26e82746573fb30e394"}], "s": {"y": 1258, "x": 1544, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441"}, "id": "j2payaxlndla1"}}, "name": "t3_11gbjgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvoqFpUhmlzuenpEc3NFwOVAKwdWZiUsqZ7tUQ83SYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677785412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m excited to share &lt;strong&gt;ActiveLab&lt;/strong&gt;, a better algorithm for practical active learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441\"&gt;https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We recently published a &lt;a href=\"https://arxiv.org/abs/2301.11856\"&gt;paper&lt;/a&gt; introducing this novel method and an &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;open-source&lt;/a&gt; Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we&amp;#39;ve made a quick &lt;a href=\"https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb\"&gt;Jupyter tutorial&lt;/a&gt; to run ActiveLab on your own data. For ML researchers, we&amp;#39;ve made all of our &lt;a href=\"https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks\"&gt;benchmarking code&lt;/a&gt; available for reproducibility so you can see for yourself how effective ActiveLab is in practice.&lt;/p&gt;\n\n&lt;p&gt;Labeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: &lt;strong&gt;which new data should I label, or which of my current labels should be checked again?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532\"&gt;https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in reading more, check out our blogpost: &lt;a href=\"https://cleanlab.ai/blog/active-learning/\"&gt;https://cleanlab.ai/blog/active-learning/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbjgm", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "subreddit_subscribers": 853345, "created_utc": 1677785412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tl;dr: **How \"static\" should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?**\n\nFor example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?\n\n\\---\n\nI was having an argument with a colleague of mine where he argued the point *that a new holdout dataset should be created every time we train a new model*, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.\n\nHis reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn't make sense.\n\nMy argument was *in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time*. \n\nMy reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.", "author_fullname": "t2_u1cec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How \"static\" should holdout datasets be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g60h8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr: &lt;strong&gt;How &amp;quot;static&amp;quot; should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I was having an argument with a colleague of mine where he argued the point &lt;em&gt;that a new holdout dataset should be created every time we train a new model&lt;/em&gt;, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.&lt;/p&gt;\n\n&lt;p&gt;His reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn&amp;#39;t make sense.&lt;/p&gt;\n\n&lt;p&gt;My argument was &lt;em&gt;in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;My reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g60h8", "is_robot_indexable": true, "report_reasons": null, "author": "fferegrino", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "subreddit_subscribers": 853345, "created_utc": 1677772142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.\n\nEDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.", "author_fullname": "t2_bvyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/Cons of Moving over to Exclusively Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbv79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.&lt;/p&gt;\n\n&lt;p&gt;EDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbv79", "is_robot_indexable": true, "report_reasons": null, "author": "robml", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "subreddit_subscribers": 853345, "created_utc": 1677786167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for some options on new visualization tools that are 508 compliant. AWS QS puts it on their roadmap for some time next year. I know PowerBI and Tableau are compliant but they're also very expensive to deploy and support a large numbers of users. I'm honestly looking for a more custom option like a shiny dashboard that I could custom code but it seems like making a compliant shiny dashboard would be a nightmare to maintain. Anyone have any experience with these types of requirements and have tooling suggestions?", "author_fullname": "t2_gepu6ks7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "508 Compliant Visualization Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbuzh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some options on new visualization tools that are 508 compliant. AWS QS puts it on their roadmap for some time next year. I know PowerBI and Tableau are compliant but they&amp;#39;re also very expensive to deploy and support a large numbers of users. I&amp;#39;m honestly looking for a more custom option like a shiny dashboard that I could custom code but it seems like making a compliant shiny dashboard would be a nightmare to maintain. Anyone have any experience with these types of requirements and have tooling suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbuzh", "is_robot_indexable": true, "report_reasons": null, "author": "Empty_Search6446", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbuzh/508_compliant_visualization_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbuzh/508_compliant_visualization_tools/", "subreddit_subscribers": 853345, "created_utc": 1677786150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello Folks,  \n\n\nHelp us, Kulturehire interns, with our Market Research Project! Please fill out our survey form it would be of great help to my learning. Your input is highly appreciated. [\\#fresherscanwork](https://www.linkedin.com/feed/hashtag/?keywords=fresherscanwork&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037135999642046464)   \n\n\n[https://docs.google.com/forms/d/e/1FAIpQLSe--\\_wYgXXxhlNdekKRemWUkkjZ\\_Mqpy8kYPOVMWoJ3tvI96A/viewform?pli=1](https://docs.google.com/forms/d/e/1FAIpQLSe--_wYgXXxhlNdekKRemWUkkjZ_Mqpy8kYPOVMWoJ3tvI96A/viewform?pli=1)", "author_fullname": "t2_r9mknxyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market Research Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gazq2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677784128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,  &lt;/p&gt;\n\n&lt;p&gt;Help us, Kulturehire interns, with our Market Research Project! Please fill out our survey form it would be of great help to my learning. Your input is highly appreciated. &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=fresherscanwork&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037135999642046464\"&gt;#fresherscanwork&lt;/a&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/forms/d/e/1FAIpQLSe--_wYgXXxhlNdekKRemWUkkjZ_Mqpy8kYPOVMWoJ3tvI96A/viewform?pli=1\"&gt;https://docs.google.com/forms/d/e/1FAIpQLSe--_wYgXXxhlNdekKRemWUkkjZ_Mqpy8kYPOVMWoJ3tvI96A/viewform?pli=1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;v=enabled&amp;s=751b05e77b1c50dfc8477f4c599cb33affc7e2fc", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gazq2", "is_robot_indexable": true, "report_reasons": null, "author": "Educational_Zombie13", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gazq2/market_research_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gazq2/market_research_survey/", "subreddit_subscribers": 853345, "created_utc": 1677784128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to classify proteins based on certain properties, some of which are matrices. \n\nSome features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.\n\nWhatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.\n\nHow do I solve for this?", "author_fullname": "t2_15k55n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with vectors as features in a dataset for classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g7srv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677776438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to classify proteins based on certain properties, some of which are matrices. &lt;/p&gt;\n\n&lt;p&gt;Some features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.&lt;/p&gt;\n\n&lt;p&gt;Whatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.&lt;/p&gt;\n\n&lt;p&gt;How do I solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g7srv", "is_robot_indexable": true, "report_reasons": null, "author": "colouredzindagi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "subreddit_subscribers": 853345, "created_utc": 1677776438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a report for school where I need to ask a data science professional some questions and then write a report on it. You don't have to answer all of them and the responses don't have to be that long they can be on the shorter side. Any help would be greatly appreciated. Thank you.\n\n1) As AI advances do you see any possible risk of mass job displacement in the future? Such as self driving cars replacing truck drivers, taxi drivers, etc. Do you think this will be a problem in the future or will it be the same as all the times we've automated something in the past and people will just adapt to the job market?\n\n\n2) Recently there has been some controversy around algorithmic bias, especially in data science. Such as automating parole decisions, job application screening, or applying for credit cards. Some people argue these machine learning algorithms have been somewhat racist/sexist in the past. Do you think data scientists should be doing their best to eliminate bias?\n\n\n3) With the recent release of chat bots like chatGPT students have been using it to help them write papers or help with their programming assignments. Do you see anything wrong with claiming chatGPT's responses as your own work? Do you consider it plagiarism?\n\n\n4) Art generation has gotten very popular recently and there have actually been some lawsuits against these AI's claiming they were trained on copyrighted images. Do you believe AI shouldn't be legally allowed to train on copyrighted material or will doing so significantly hinder AI's development as data scientists will have to be much more careful about how they obtain their datasets?\n\n\n5) As AI and image detection/recognition algorithms become more withspread do you think adversarial attacks will ever be a significant and practical problem?", "author_fullname": "t2_dj5j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working on a report for school, can someone answer a few ethics related data science questions for me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fpp9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677722890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a report for school where I need to ask a data science professional some questions and then write a report on it. You don&amp;#39;t have to answer all of them and the responses don&amp;#39;t have to be that long they can be on the shorter side. Any help would be greatly appreciated. Thank you.&lt;/p&gt;\n\n&lt;p&gt;1) As AI advances do you see any possible risk of mass job displacement in the future? Such as self driving cars replacing truck drivers, taxi drivers, etc. Do you think this will be a problem in the future or will it be the same as all the times we&amp;#39;ve automated something in the past and people will just adapt to the job market?&lt;/p&gt;\n\n&lt;p&gt;2) Recently there has been some controversy around algorithmic bias, especially in data science. Such as automating parole decisions, job application screening, or applying for credit cards. Some people argue these machine learning algorithms have been somewhat racist/sexist in the past. Do you think data scientists should be doing their best to eliminate bias?&lt;/p&gt;\n\n&lt;p&gt;3) With the recent release of chat bots like chatGPT students have been using it to help them write papers or help with their programming assignments. Do you see anything wrong with claiming chatGPT&amp;#39;s responses as your own work? Do you consider it plagiarism?&lt;/p&gt;\n\n&lt;p&gt;4) Art generation has gotten very popular recently and there have actually been some lawsuits against these AI&amp;#39;s claiming they were trained on copyrighted images. Do you believe AI shouldn&amp;#39;t be legally allowed to train on copyrighted material or will doing so significantly hinder AI&amp;#39;s development as data scientists will have to be much more careful about how they obtain their datasets?&lt;/p&gt;\n\n&lt;p&gt;5) As AI and image detection/recognition algorithms become more withspread do you think adversarial attacks will ever be a significant and practical problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fpp9o", "is_robot_indexable": true, "report_reasons": null, "author": "VelvetRevolver_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fpp9o/working_on_a_report_for_school_can_someone_answer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fpp9o/working_on_a_report_for_school_can_someone_answer/", "subreddit_subscribers": 853345, "created_utc": 1677722890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and to inside them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it's a proxy variable at the most and doesn't hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.\n\nNow I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I'd like to find.\n\nThanks.", "author_fullname": "t2_bvba4ue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find actual important variables for Proxies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fwel0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677742083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and to inside them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it&amp;#39;s a proxy variable at the most and doesn&amp;#39;t hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.&lt;/p&gt;\n\n&lt;p&gt;Now I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I&amp;#39;d like to find.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fwel0", "is_robot_indexable": true, "report_reasons": null, "author": "invincible_moron", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fwel0/how_to_find_actual_important_variables_for_proxies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fwel0/how_to_find_actual_important_variables_for_proxies/", "subreddit_subscribers": 853345, "created_utc": 1677742083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newly promoted to a senior data/analytics position at my company. Administrative question here. How do you all structure your folders and files? In general. If you were able to start from scratch in your current role, or if you just started a new job.. how do you organize? Aside from files and folders, do you leverage apps like OneNote, Evernote, databases, etc., to keep track of clients, projects, sandbox scripts and whatnot?", "author_fullname": "t2_gn8s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Folder Structuring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fu2ne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677734804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newly promoted to a senior data/analytics position at my company. Administrative question here. How do you all structure your folders and files? In general. If you were able to start from scratch in your current role, or if you just started a new job.. how do you organize? Aside from files and folders, do you leverage apps like OneNote, Evernote, databases, etc., to keep track of clients, projects, sandbox scripts and whatnot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fu2ne", "is_robot_indexable": true, "report_reasons": null, "author": "Thiseffingguy2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fu2ne/folder_structuring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fu2ne/folder_structuring/", "subreddit_subscribers": 853345, "created_utc": 1677734804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "today my work mainly consists of doing some data wrangling (mostly satellite image sequences) with python scripts run on a cloud instance, then using pytorch to build and train a deep learning model on a gpu instance on aws (I connect via ssh with vscode). I use tensorboard to monitor training. when it's done I usually pass the weights to other people and they will take care of making it available via an API.\n\nhow do I give the next step as a machine learning engineer? which tools to use? which concepts to learn?", "author_fullname": "t2_rhw2olfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to improve as a machine learning engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11flc7j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677712150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;today my work mainly consists of doing some data wrangling (mostly satellite image sequences) with python scripts run on a cloud instance, then using pytorch to build and train a deep learning model on a gpu instance on aws (I connect via ssh with vscode). I use tensorboard to monitor training. when it&amp;#39;s done I usually pass the weights to other people and they will take care of making it available via an API.&lt;/p&gt;\n\n&lt;p&gt;how do I give the next step as a machine learning engineer? which tools to use? which concepts to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11flc7j", "is_robot_indexable": true, "report_reasons": null, "author": "pocolai", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11flc7j/how_to_improve_as_a_machine_learning_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11flc7j/how_to_improve_as_a_machine_learning_engineer/", "subreddit_subscribers": 853345, "created_utc": 1677712150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nBayesian methods is implemented by the function krige.bayes.It can be performed for different\u201cdegrees\nof uncertainty\u201d,hence the model parameters can be treated as fixed or random.We will consider a model\nwithout nugget and including uncertainty in the mean,sill and range parameters.\n10\nbaye.model&lt;-krige.bayes(\ng data 2,\nloc=matrix(\nc(0.2,0.6,0.2,1.1,0.2,0.3,1.0,1.1),\nn col=2\n),\nprior=prior.control(\nphi.discrete=seq(0,5,l=101),phi.prior=\"rec\"\n),\noutput=output.control(n.post=5000)\n)\n##krige.bayes:modelwithconstantmean\n##krige.bayes:computingthediscreteposteriorofphi/tausq.rel\n##krige.bayes:computingtheposteriorprobabilities.\n##Number Of Parameters ETS:101\n##1,11,21,31,41,51,61,71,81,91,101,\n##\n##krige.bayes:samplingfromposteriordistribution\n##krige.bayes:samplefromthe(joint)posteriorofphiandtausq.rel\n##[,1][,2][,3]\n##phi0.250.30.35\n##tausq.rel0.000.00.00\n##frequency3540.001451.09.00\n##\n##krige.bayes:startingpredictionattheprovidedlocations\n##krige.bayes:phi/tausq.relsamplesforthepredictivearesameasfortheposterior\n##krige.bayes:computingmomentsofthepredictivedistribution\n##krige.bayes:samplingfromthepredictive\n##Number Of Parameters ETS:3\n##1,2,3,\n##krige.bayes:preparingsummariesofthepredictivedistribution", "author_fullname": "t2_uwl5ul7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fit by Bayesian methods", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gb6xi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677784603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bayesian methods is implemented by the function krige.bayes.It can be performed for different\u201cdegrees\nof uncertainty\u201d,hence the model parameters can be treated as fixed or random.We will consider a model\nwithout nugget and including uncertainty in the mean,sill and range parameters.\n10\nbaye.model&amp;lt;-krige.bayes(\ng data 2,\nloc=matrix(\nc(0.2,0.6,0.2,1.1,0.2,0.3,1.0,1.1),\nn col=2\n),\nprior=prior.control(\nphi.discrete=seq(0,5,l=101),phi.prior=&amp;quot;rec&amp;quot;\n),\noutput=output.control(n.post=5000)\n)&lt;/p&gt;\n\n&lt;h2&gt;krige.bayes:modelwithconstantmean&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:computingthediscreteposteriorofphi/tausq.rel&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:computingtheposteriorprobabilities.&lt;/h2&gt;\n\n&lt;h2&gt;Number Of Parameters ETS:101&lt;/h2&gt;\n\n&lt;h2&gt;1,11,21,31,41,51,61,71,81,91,101,&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:samplingfromposteriordistribution&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:samplefromthe(joint)posteriorofphiandtausq.rel&lt;/h2&gt;\n\n&lt;h2&gt;[,1][,2][,3]&lt;/h2&gt;\n\n&lt;h2&gt;phi0.250.30.35&lt;/h2&gt;\n\n&lt;h2&gt;tausq.rel0.000.00.00&lt;/h2&gt;\n\n&lt;h2&gt;frequency3540.001451.09.00&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:startingpredictionattheprovidedlocations&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:phi/tausq.relsamplesforthepredictivearesameasfortheposterior&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:computingmomentsofthepredictivedistribution&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:samplingfromthepredictive&lt;/h2&gt;\n\n&lt;h2&gt;Number Of Parameters ETS:3&lt;/h2&gt;\n\n&lt;h2&gt;1,2,3,&lt;/h2&gt;\n\n&lt;h2&gt;krige.bayes:preparingsummariesofthepredictivedistribution&lt;/h2&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gb6xi", "is_robot_indexable": true, "report_reasons": null, "author": "clinton_CT", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gb6xi/fit_by_bayesian_methods/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gb6xi/fit_by_bayesian_methods/", "subreddit_subscribers": 853345, "created_utc": 1677784603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "ive been into ds for some 6 months and ive been selling my services based on supervised learning techniques only and it was all going good but now they've vetted the services meaning I have to place my gigs under one of their given 4 sub categories or I cant continue selling.\n\ni mean I am learning time series forecasting right now but they keep sending mails that I got a month to keep my gig alive n shit.\n\ncan yall suggest a good sol pls", "author_fullname": "t2_clohgnz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does the fiverr vetting system sucks or is it just me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g9y5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677781615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ive been into ds for some 6 months and ive been selling my services based on supervised learning techniques only and it was all going good but now they&amp;#39;ve vetted the services meaning I have to place my gigs under one of their given 4 sub categories or I cant continue selling.&lt;/p&gt;\n\n&lt;p&gt;i mean I am learning time series forecasting right now but they keep sending mails that I got a month to keep my gig alive n shit.&lt;/p&gt;\n\n&lt;p&gt;can yall suggest a good sol pls&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g9y5o", "is_robot_indexable": true, "report_reasons": null, "author": "futbolhead975", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g9y5o/does_the_fiverr_vetting_system_sucks_or_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g9y5o/does_the_fiverr_vetting_system_sucks_or_is_it/", "subreddit_subscribers": 853345, "created_utc": 1677781615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newbie question! The project I'm currently on is user clustering of a food delivery company.\n\nI'm at the preprocessing stage and I'm feeling stuck, and I'm having 2 dataframe columns with list and dict like structure. Any ideas how to deal with such columns?\n\nAll I can think about is data normalization as to convert those 2 columns to 2 separate dataframes,  but I don't know if that is the common practice to such issue.\n\nAny help is appreciated, thanks so much in advance.\n\nhttps://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8\n\nhttps://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258", "author_fullname": "t2_vn7kuoox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with multiple columns containing multiple values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bs1v640z6cla1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=454c4224db2cad798461c9103d82e4be0ae27ca9"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1b16bbf2cb2ac0569897e7111bae07ec288507b"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89874ec0bfaf139c8c8026d65e82273922631f99"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2631e786d2e2d2bc2f1460cc94344291098036f4"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fd074d9b9dbe14bcb28844e5da8593b4bbfaff6"}, {"y": 603, "x": 1080, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4649d215dac0d20404b20a3f83db88c0afb8c2a"}], "s": {"y": 715, "x": 1280, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8"}, "id": "bs1v640z6cla1"}, "fg12i10z6cla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54204771d76ed62d30fc02a583d8b1b0991099c1"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98be7c74c9556d51c0ae1504cae664334b97c4f0"}, {"y": 155, "x": 320, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c136ca3af669f631fe1b17f24df01b8c19598354"}, {"y": 310, "x": 640, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e75a1bbc9c5aa64c2f435142b8a8036504f09364"}, {"y": 466, "x": 960, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a82a059df7e3260bf9e4464234173087fd7621f8"}, {"y": 524, "x": 1080, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46c9f56bac4513c28a1e280d1dcddaa000e1c80e"}], "s": {"y": 807, "x": 1661, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258"}, "id": "fg12i10z6cla1"}}, "name": "t3_11g49mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4ArVN60qwbBnxhf8nGKC0ReNzvMDiYYDKU8f5pUvBYk.jpg", "edited": 1677770018.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie question! The project I&amp;#39;m currently on is user clustering of a food delivery company.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at the preprocessing stage and I&amp;#39;m feeling stuck, and I&amp;#39;m having 2 dataframe columns with list and dict like structure. Any ideas how to deal with such columns?&lt;/p&gt;\n\n&lt;p&gt;All I can think about is data normalization as to convert those 2 columns to 2 separate dataframes,  but I don&amp;#39;t know if that is the common practice to such issue.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated, thanks so much in advance.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8\"&gt;https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258\"&gt;https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g49mz", "is_robot_indexable": true, "report_reasons": null, "author": "Hatasu98", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g49mz/how_to_deal_with_multiple_columns_containing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g49mz/how_to_deal_with_multiple_columns_containing/", "subreddit_subscribers": 853345, "created_utc": 1677767699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "posted by your anxious undergrad senior who can't even get an internship", "author_fullname": "t2_aghpz5g9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When do you think this tech recession will be over?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fqpnj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677725482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;posted by your anxious undergrad senior who can&amp;#39;t even get an internship&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fqpnj", "is_robot_indexable": true, "report_reasons": null, "author": "Careless-Tailor-2317", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fqpnj/when_do_you_think_this_tech_recession_will_be_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fqpnj/when_do_you_think_this_tech_recession_will_be_over/", "subreddit_subscribers": 853345, "created_utc": 1677725482.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}