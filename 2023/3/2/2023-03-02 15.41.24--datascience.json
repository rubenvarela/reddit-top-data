{"kind": "Listing", "data": {"after": "t3_11f88jq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started a job with a large R&amp;D company last year, with the anticipation that I would be stepping into a well oiled machine with crisp data management workflows\u2026. Yeah, no. A big part of my job has become just making old data useable. Many things are easily done in R (my language of choice) other things just straight up have to be done in excel, by hand. It\u2019s not at all what I expected but the realization has dawned on me that this is exactly why they hired me. I have other official responsibilities, but actually standardizing and consolidating data that is currently scattered across the cloud is where I sink 70% of my time. I wasn\u2019t hired for my niche skill set, I was hired to scroll files endlessly.", "author_fullname": "t2_59l9bdfsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you\u2019re entering a team as a \u201cnew guy\u201d, be prepared for the mundane.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f6roa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 382, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 382, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677684819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started a job with a large R&amp;amp;D company last year, with the anticipation that I would be stepping into a well oiled machine with crisp data management workflows\u2026. Yeah, no. A big part of my job has become just making old data useable. Many things are easily done in R (my language of choice) other things just straight up have to be done in excel, by hand. It\u2019s not at all what I expected but the realization has dawned on me that this is exactly why they hired me. I have other official responsibilities, but actually standardizing and consolidating data that is currently scattered across the cloud is where I sink 70% of my time. I wasn\u2019t hired for my niche skill set, I was hired to scroll files endlessly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f6roa", "is_robot_indexable": true, "report_reasons": null, "author": "ExtraSpecialCake", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f6roa/if_youre_entering_a_team_as_a_new_guy_be_prepared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f6roa/if_youre_entering_a_team_as_a_new_guy_be_prepared/", "subreddit_subscribers": 853244, "created_utc": 1677684819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What's the best way of measuring the effect of an ad campaign on revenues of advertised items. There wasn't any A/B testing done in a sense that there was a control and treatment group. I've seen articles talking about observational methods to estimate ad effects but couldn't quite nail down what tests or specific methods to use. Any suggestions?  \n\n\nBackground: A set of specific items (4 - 5 different items compared to about 200+ available) were advertised to all users for a period of 1 - 2 weeks at a time. Stakeholders want to determine if it was worth running these types of campaigns again. Campaigns of this sort were run a handful of times in the past, sometimes for the same items and sometimes for different sets of items. There is data available for various months before and after the two week campaign periods in most instances.", "author_fullname": "t2_6amb82kr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Measuring the effect of ad campaign", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fcduv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677696915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the best way of measuring the effect of an ad campaign on revenues of advertised items. There wasn&amp;#39;t any A/B testing done in a sense that there was a control and treatment group. I&amp;#39;ve seen articles talking about observational methods to estimate ad effects but couldn&amp;#39;t quite nail down what tests or specific methods to use. Any suggestions?  &lt;/p&gt;\n\n&lt;p&gt;Background: A set of specific items (4 - 5 different items compared to about 200+ available) were advertised to all users for a period of 1 - 2 weeks at a time. Stakeholders want to determine if it was worth running these types of campaigns again. Campaigns of this sort were run a handful of times in the past, sometimes for the same items and sometimes for different sets of items. There is data available for various months before and after the two week campaign periods in most instances.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fcduv", "is_robot_indexable": true, "report_reasons": null, "author": "jbcc_", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fcduv/measuring_the_effect_of_ad_campaign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fcduv/measuring_the_effect_of_ad_campaign/", "subreddit_subscribers": 853244, "created_utc": 1677696915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5o1cl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been working on a project in my spare time to make US Census data more accessible. If you or someone you know uses the Census data I would appreciate some feedback.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fb3vb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677694935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "census.report", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "http://census.report/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fb3vb", "is_robot_indexable": true, "report_reasons": null, "author": "johnthexiii", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fb3vb/ive_been_working_on_a_project_in_my_spare_time_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://census.report/", "subreddit_subscribers": 853244, "created_utc": 1677694935.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys. I can't find a single decent kafka tutorial on youtube. I have a Code with Mosh subscription but there's nothing on there either. Does anyone have a good recommendation? There's lots of videos that explain the theory but not a lot that put it into practice.\n\nThank you in advance!", "author_fullname": "t2_keo5p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good kafka tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g2rby", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677763643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. I can&amp;#39;t find a single decent kafka tutorial on youtube. I have a Code with Mosh subscription but there&amp;#39;s nothing on there either. Does anyone have a good recommendation? There&amp;#39;s lots of videos that explain the theory but not a lot that put it into practice.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g2rby", "is_robot_indexable": true, "report_reasons": null, "author": "niniox", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g2rby/good_kafka_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g2rby/good_kafka_tutorial/", "subreddit_subscribers": 853244, "created_utc": 1677763643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been struggling with staying organized as an MLE for quite a long time. \n\nI have multiple model classes to work on and multiple iteration per model class. Then each have experiments assigned or not. Some have resource constraints  that need to be resolved. Some models need to finish at the same time and be experimented simultanously, etcetra.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nWondering, how do you keep your self organized and the modelling pipeline progress smooth? Any app, toolbox, methodology helpful for this?", "author_fullname": "t2_e6ppgt2u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Meta] How do you stay organized as a machine learning engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fk7to", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677709591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been struggling with staying organized as an MLE for quite a long time. &lt;/p&gt;\n\n&lt;p&gt;I have multiple model classes to work on and multiple iteration per model class. Then each have experiments assigned or not. Some have resource constraints  that need to be resolved. Some models need to finish at the same time and be experimented simultanously, etcetra.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Wondering, how do you keep your self organized and the modelling pipeline progress smooth? Any app, toolbox, methodology helpful for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fk7to", "is_robot_indexable": true, "report_reasons": null, "author": "Which-Distance1384", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fk7to/meta_how_do_you_stay_organized_as_a_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fk7to/meta_how_do_you_stay_organized_as_a_machine/", "subreddit_subscribers": 853244, "created_utc": 1677709591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First-time poster so hopefully I am complying with the rules here. Basically, in my previous job I used an open-source tool that was super helpful in merging near-identical data fields. It was external to Excel but could intake xls/xlsvor csv files. It then had a variety of automated and semi-automated capabilities for identifying \"near-duplicates\" -- i.e. if one field is Walmart and the another is Wal-mart, it could figure that out. This included a \"nearest neighbor\" option that you could use to really widen the aperture.\n\nHoping someone can help point me in the right direction -- otherwise I'll be stuck manually identifying dupes in this very messy dataset...\n\nThanks so much in advance!\n\nEdit: it was Open Refine ([https://openrefine.org/](https://openrefine.org/)) in case any other lost souls find this post in the future.", "author_fullname": "t2_jz870", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a tool I used years ago...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8gfg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677724327.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677688811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First-time poster so hopefully I am complying with the rules here. Basically, in my previous job I used an open-source tool that was super helpful in merging near-identical data fields. It was external to Excel but could intake xls/xlsvor csv files. It then had a variety of automated and semi-automated capabilities for identifying &amp;quot;near-duplicates&amp;quot; -- i.e. if one field is Walmart and the another is Wal-mart, it could figure that out. This included a &amp;quot;nearest neighbor&amp;quot; option that you could use to really widen the aperture.&lt;/p&gt;\n\n&lt;p&gt;Hoping someone can help point me in the right direction -- otherwise I&amp;#39;ll be stuck manually identifying dupes in this very messy dataset...&lt;/p&gt;\n\n&lt;p&gt;Thanks so much in advance!&lt;/p&gt;\n\n&lt;p&gt;Edit: it was Open Refine (&lt;a href=\"https://openrefine.org/\"&gt;https://openrefine.org/&lt;/a&gt;) in case any other lost souls find this post in the future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f8gfg", "is_robot_indexable": true, "report_reasons": null, "author": "nicolo_martinez", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f8gfg/looking_for_a_tool_i_used_years_ago/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f8gfg/looking_for_a_tool_i_used_years_ago/", "subreddit_subscribers": 853244, "created_utc": 1677688811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Data Science Skills Roadmap](https://preview.redd.it/99v96wvc3cla1.jpg?width=2454&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=adb08f3a3435fe18431b62746c17ee1404349751)\n\nI launched an intro course on Udemy earlier this year [(which you can register for free at this link if you are interested).](https://www.udemy.com/course/core-data-science-and-machine-learning/?couponCode=63000A22ED5CDF1AD417) \n\nIn the process I made this skills roadmap visual that I thought would be of interest to this sub. \n\nLet know what you think or if I'm missing anything significant. [There is also a GitHub Repo of a bunch of related material including the source image.](https://github.com/isaacfab/data-science-road-map)", "author_fullname": "t2_m9qn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a data science 'roadmap' of skills for people starting out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"99v96wvc3cla1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fcf5284db997520d188e7f9fb8200c325c4ddb0"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0317d2f40700ead2a4c3b2f24ff182372c7afd5"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b603b73f83030e48d7631a35bb97be6d151018e"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d4f48873bcdba59435b08075817faa3b338bca2"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad74ba7964b5e1fefd8ac3656c86a0e6fb0da87b"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=877d7e01001bb8cd4555a9a8a5f9c43c727fa7c5"}], "s": {"y": 9560, "x": 2454, "u": "https://preview.redd.it/99v96wvc3cla1.jpg?width=2454&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=adb08f3a3435fe18431b62746c17ee1404349751"}, "id": "99v96wvc3cla1"}}, "name": "t3_11g3xcq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1aYM_2YBIMG6qobpWEyndJZB7zETE0OPdziHcNTiLqM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677766783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/99v96wvc3cla1.jpg?width=2454&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=adb08f3a3435fe18431b62746c17ee1404349751\"&gt;Data Science Skills Roadmap&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I launched an intro course on Udemy earlier this year &lt;a href=\"https://www.udemy.com/course/core-data-science-and-machine-learning/?couponCode=63000A22ED5CDF1AD417\"&gt;(which you can register for free at this link if you are interested).&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;In the process I made this skills roadmap visual that I thought would be of interest to this sub. &lt;/p&gt;\n\n&lt;p&gt;Let know what you think or if I&amp;#39;m missing anything significant. &lt;a href=\"https://github.com/isaacfab/data-science-road-map\"&gt;There is also a GitHub Repo of a bunch of related material including the source image.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0DjiJ4_XnaIct0gpvMqNZsCm2qjIDQdst7yFFHsdP_c.jpg?auto=webp&amp;v=enabled&amp;s=7a91bb7ecbe06289aaf3bdd0deddc2d10e4913d9", "width": 480, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/0DjiJ4_XnaIct0gpvMqNZsCm2qjIDQdst7yFFHsdP_c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87c12897bc77ac7eeb27481c2d9539cd6180e764", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/0DjiJ4_XnaIct0gpvMqNZsCm2qjIDQdst7yFFHsdP_c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c4ae28e0fac98e4113827cae4b5607b1ecd4b01", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/0DjiJ4_XnaIct0gpvMqNZsCm2qjIDQdst7yFFHsdP_c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7dc7ccfdd0d41c8beee43c99b0b36ae76693913", "width": 320, "height": 180}], "variants": {}, "id": "bBZsl2SUyFEP6s-J-laLZgWeS9fe8oGAbPwdkH94hFU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g3xcq", "is_robot_indexable": true, "report_reasons": null, "author": "isaacfab", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g3xcq/i_made_a_data_science_roadmap_of_skills_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g3xcq/i_made_a_data_science_roadmap_of_skills_for/", "subreddit_subscribers": 853244, "created_utc": 1677766783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! I'd love to hear your thoughts on my story. I applied for Slack DS internship early November. They reached out in December and I interviewed in mid-December. After the first round, they got me waiting for long. The recruiter reached out in Jan 20 finally and said I'm in for the second round which will be the last one ( except for the presentation round after that). I did my second interview on Jan 27 and again since then, they didn't get back to me. I emailed the recruiter - no response. I contacted the manager with whom I interviewed and she said she is not sure about the recruitment progress and that I should contact the recruiter. She also said that she will check with the recruiter herself. As of now, I'm still waiting. My workday status is interview. I know it isn't going right but can't stop thinking about what's happening. Is it just ghosting? Then why the manager got back with basically no updates? It just sucks to get no response whatsoever... \n\nThank you!", "author_fullname": "t2_31lqqzal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slack DS Summer Intern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11foffz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677719751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;d love to hear your thoughts on my story. I applied for Slack DS internship early November. They reached out in December and I interviewed in mid-December. After the first round, they got me waiting for long. The recruiter reached out in Jan 20 finally and said I&amp;#39;m in for the second round which will be the last one ( except for the presentation round after that). I did my second interview on Jan 27 and again since then, they didn&amp;#39;t get back to me. I emailed the recruiter - no response. I contacted the manager with whom I interviewed and she said she is not sure about the recruitment progress and that I should contact the recruiter. She also said that she will check with the recruiter herself. As of now, I&amp;#39;m still waiting. My workday status is interview. I know it isn&amp;#39;t going right but can&amp;#39;t stop thinking about what&amp;#39;s happening. Is it just ghosting? Then why the manager got back with basically no updates? It just sucks to get no response whatsoever... &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11foffz", "is_robot_indexable": true, "report_reasons": null, "author": "pdb29", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11foffz/slack_ds_summer_intern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11foffz/slack_ds_summer_intern/", "subreddit_subscribers": 853244, "created_utc": 1677719751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I'm a data scientist for almost 4 years now. Used to do lots of data science and ML before. But my current role(2 months so far) has been more on being a one man team. I'm helping the company get back to their feet after the pandemic. Unfortunately, I'm the only data person and I'm doing a lot of things from Data engineering, data governance, data science and ML, and MLOps. I can somehow handle it since I have some knowledge on all of these as an end user but it's all basic breadth knowledge as the depth of expertise is in data science and ML. Management says they'll hire more data people when they see I've increased their revenue. They've given me one year to make this happen. The pay is twice as much as my previous role. I kind of realized it's a big bump because there's lots to do. A part of me is pondering about finding a new role but other roles in my area don't offer remote work and pay is lower. Just a bit torn now. Any advice regarding my situation? Thank you!\n\n\nP.S\nSpecifically, I'm struggling to understand the current infrastructure because the old data team all left already. The software engineers don't have any idea how the data infra works too.", "author_fullname": "t2_urui9m59", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on wearing multiple hats at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8goj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677688825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m a data scientist for almost 4 years now. Used to do lots of data science and ML before. But my current role(2 months so far) has been more on being a one man team. I&amp;#39;m helping the company get back to their feet after the pandemic. Unfortunately, I&amp;#39;m the only data person and I&amp;#39;m doing a lot of things from Data engineering, data governance, data science and ML, and MLOps. I can somehow handle it since I have some knowledge on all of these as an end user but it&amp;#39;s all basic breadth knowledge as the depth of expertise is in data science and ML. Management says they&amp;#39;ll hire more data people when they see I&amp;#39;ve increased their revenue. They&amp;#39;ve given me one year to make this happen. The pay is twice as much as my previous role. I kind of realized it&amp;#39;s a big bump because there&amp;#39;s lots to do. A part of me is pondering about finding a new role but other roles in my area don&amp;#39;t offer remote work and pay is lower. Just a bit torn now. Any advice regarding my situation? Thank you!&lt;/p&gt;\n\n&lt;p&gt;P.S\nSpecifically, I&amp;#39;m struggling to understand the current infrastructure because the old data team all left already. The software engineers don&amp;#39;t have any idea how the data infra works too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f8goj", "is_robot_indexable": true, "report_reasons": null, "author": "Massive-Cricket-7469", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f8goj/advice_on_wearing_multiple_hats_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f8goj/advice_on_wearing_multiple_hats_at_work/", "subreddit_subscribers": 853244, "created_utc": 1677688825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a new graduate working as a data analyst for a large health organization. I was formally trained in Stata and have some experience using R and Python. Our organization uses SQL to query data, and is moving more towards SAS as the standard for analyses. I had always planned on moving away from Stata and focusing more on SQL, R and Python, but I am now expected to learn SAS. I would still like to be proficient in R and Python, however, I'm worried that trying to learn too many programs will limit my ability to really excel in any one of them.\n\nMy question is how many statistical programs do you have in your \"toolkit\", and how many can one learn before reaching a point of diminishing returns?", "author_fullname": "t2_129ywp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many statistical programs have you learned?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fjzre", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677709091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new graduate working as a data analyst for a large health organization. I was formally trained in Stata and have some experience using R and Python. Our organization uses SQL to query data, and is moving more towards SAS as the standard for analyses. I had always planned on moving away from Stata and focusing more on SQL, R and Python, but I am now expected to learn SAS. I would still like to be proficient in R and Python, however, I&amp;#39;m worried that trying to learn too many programs will limit my ability to really excel in any one of them.&lt;/p&gt;\n\n&lt;p&gt;My question is how many statistical programs do you have in your &amp;quot;toolkit&amp;quot;, and how many can one learn before reaching a point of diminishing returns?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fjzre", "is_robot_indexable": true, "report_reasons": null, "author": "amipregananant", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fjzre/how_many_statistical_programs_have_you_learned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fjzre/how_many_statistical_programs_have_you_learned/", "subreddit_subscribers": 853244, "created_utc": 1677709091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You have a bunch of time series data from some sensors attached to different parts of a machine and one or more parts get damaged, which, in principle, should reflect in the signals from corresponding sensors.\n\nWhat approaches come to mind in order to detect/localize anomalies in the data that correspond to the damaging event and/or predicting/forecasting the same?\n\nTime series is discontinuous in time as the machine is operating only certain hours a day, with several breaks in between.", "author_fullname": "t2_8cvbnc48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick and basic approaches for anomaly detection in time series data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fl6ht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677711781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You have a bunch of time series data from some sensors attached to different parts of a machine and one or more parts get damaged, which, in principle, should reflect in the signals from corresponding sensors.&lt;/p&gt;\n\n&lt;p&gt;What approaches come to mind in order to detect/localize anomalies in the data that correspond to the damaging event and/or predicting/forecasting the same?&lt;/p&gt;\n\n&lt;p&gt;Time series is discontinuous in time as the machine is operating only certain hours a day, with several breaks in between.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fl6ht", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious_Two_810", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fl6ht/quick_and_basic_approaches_for_anomaly_detection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fl6ht/quick_and_basic_approaches_for_anomaly_detection/", "subreddit_subscribers": 853244, "created_utc": 1677711781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I've found out that it doesn't give the same model parameters.", "author_fullname": "t2_6zlc2ji4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing for RMSE vs. R2, for feature selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11g416x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I&amp;#39;ve found out that it doesn&amp;#39;t give the same model parameters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g416x", "is_robot_indexable": true, "report_reasons": null, "author": "dilkur", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "subreddit_subscribers": 853244, "created_utc": 1677767070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is happening on a daily basis at my company. Managers complete everything from queries to slides. The DAs will present the slides at meetings, but will not be able to answer questions and the manager that did the analysis will jump in and answer for them. Why are they doing this? I understand that some employees will work for less than others, but why retain them if they can't complete work on their own?", "author_fullname": "t2_as8zs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would managers complete work for H1 DAs and let them pass it off as their own?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ffb2r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1677700606.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677700221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is happening on a daily basis at my company. Managers complete everything from queries to slides. The DAs will present the slides at meetings, but will not be able to answer questions and the manager that did the analysis will jump in and answer for them. Why are they doing this? I understand that some employees will work for less than others, but why retain them if they can&amp;#39;t complete work on their own?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ffb2r", "is_robot_indexable": true, "report_reasons": null, "author": "varicoseballs", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ffb2r/why_would_managers_complete_work_for_h1_das_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ffb2r/why_would_managers_complete_work_for_h1_das_and/", "subreddit_subscribers": 853244, "created_utc": 1677700221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is going to sound like the most generic post on here because I - like so many - have hit a point in my career after 6 years where I am not sure what I should do next. \n\nFor context, I have a pretty low undergraduate GPA. If this wasn't the case, I would probably directly apply to Masters programs. I didn't try very hard and actually started working full-time as a Data Analyst before I had even graduated with my Economics degree. Now I have 6 years of work experience going from intern to Senior DA (5 at a reputable company + 1 ongoing at a FAANG) and I would really like to work on a Masters degree. \n\nI did poorly in Economics, but I think I would do much better academically now that I am older and more mature and have worked with Data Science tools and techniques for so long. In the past 6 years while working full time I spent a ton of time on Udemy, Coursera and did dozens of courses that allowed me to pick up bigger projects at work. Everything I've learned about writing good code and statistical techniques and building performant models, I've either learned on the job from a willing mentor or from these kinds of certification courses. I love learning for the sake of 'immediately applying' what I learned and doing these kinds of Python projects in my spare time on weekends gives me a lot of passion. \n\nI recently discovered the EdX micromasters programs and realized that this might be a unique opportunity for me to add a stepping stone before applying to a Masters program. Has anyone had any experience with these? I think that doing a Micromasters + GRE could help overcome my bad undergraduate GPA in an MS application.\n\nIs trying my best to go get an MS the right path forward for me? Thank you advance for reading through this and any advice is very much appreciated.", "author_fullname": "t2_12sn5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Education Advice for mid-career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fe2ay", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677698802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is going to sound like the most generic post on here because I - like so many - have hit a point in my career after 6 years where I am not sure what I should do next. &lt;/p&gt;\n\n&lt;p&gt;For context, I have a pretty low undergraduate GPA. If this wasn&amp;#39;t the case, I would probably directly apply to Masters programs. I didn&amp;#39;t try very hard and actually started working full-time as a Data Analyst before I had even graduated with my Economics degree. Now I have 6 years of work experience going from intern to Senior DA (5 at a reputable company + 1 ongoing at a FAANG) and I would really like to work on a Masters degree. &lt;/p&gt;\n\n&lt;p&gt;I did poorly in Economics, but I think I would do much better academically now that I am older and more mature and have worked with Data Science tools and techniques for so long. In the past 6 years while working full time I spent a ton of time on Udemy, Coursera and did dozens of courses that allowed me to pick up bigger projects at work. Everything I&amp;#39;ve learned about writing good code and statistical techniques and building performant models, I&amp;#39;ve either learned on the job from a willing mentor or from these kinds of certification courses. I love learning for the sake of &amp;#39;immediately applying&amp;#39; what I learned and doing these kinds of Python projects in my spare time on weekends gives me a lot of passion. &lt;/p&gt;\n\n&lt;p&gt;I recently discovered the EdX micromasters programs and realized that this might be a unique opportunity for me to add a stepping stone before applying to a Masters program. Has anyone had any experience with these? I think that doing a Micromasters + GRE could help overcome my bad undergraduate GPA in an MS application.&lt;/p&gt;\n\n&lt;p&gt;Is trying my best to go get an MS the right path forward for me? Thank you advance for reading through this and any advice is very much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fe2ay", "is_robot_indexable": true, "report_reasons": null, "author": "AcridAcedia", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fe2ay/education_advice_for_midcareer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fe2ay/education_advice_for_midcareer/", "subreddit_subscribers": 853244, "created_utc": 1677698802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to catalog my personal online activity. For that, I will need to do a lot of manual data entry. But also be able to access and modify that data from code in real time (no exports and so on).\n\nI want to define objects such as accounts, nicknames, emails, and so on with strong schema and a lot of constraints (including fk). A relational database with complex types will be perfect, such as Postgres which I am used to working with. Maybe even a graph-relational database like EdgeDB be better.\n\nThe problem arises when I need to enter or modify data manually a lot and mix it with automatic data entry. Writing updates and inserts in SQL will take forever. I am looking for some Web UI that has basic functionality of displaying tables, and allowing to enter and modify data via simple forms. Also, simple filtering and sorting are required. Other requirements are for it to be open source, self-hosted and support complex data types (at least arrays). Finally, support for multiline text, i.e I want to have a `notes` attribute where I can want to comfortably write notes (that why said forms before).\n\nI am not a frontend developer, so writing such a UI myself is not the way I want to go.\n\nI have tried:\n* Excel - just no.\n* DBeaver - ce doesn't have a self-hosted web version. And not really great for manual data entry.\n\nThanks in advance", "author_fullname": "t2_68l9yl5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source tools for manual data entry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fcmp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677697197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to catalog my personal online activity. For that, I will need to do a lot of manual data entry. But also be able to access and modify that data from code in real time (no exports and so on).&lt;/p&gt;\n\n&lt;p&gt;I want to define objects such as accounts, nicknames, emails, and so on with strong schema and a lot of constraints (including fk). A relational database with complex types will be perfect, such as Postgres which I am used to working with. Maybe even a graph-relational database like EdgeDB be better.&lt;/p&gt;\n\n&lt;p&gt;The problem arises when I need to enter or modify data manually a lot and mix it with automatic data entry. Writing updates and inserts in SQL will take forever. I am looking for some Web UI that has basic functionality of displaying tables, and allowing to enter and modify data via simple forms. Also, simple filtering and sorting are required. Other requirements are for it to be open source, self-hosted and support complex data types (at least arrays). Finally, support for multiline text, i.e I want to have a &lt;code&gt;notes&lt;/code&gt; attribute where I can want to comfortably write notes (that why said forms before).&lt;/p&gt;\n\n&lt;p&gt;I am not a frontend developer, so writing such a UI myself is not the way I want to go.&lt;/p&gt;\n\n&lt;p&gt;I have tried:\n* Excel - just no.\n* DBeaver - ce doesn&amp;#39;t have a self-hosted web version. And not really great for manual data entry.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fcmp9", "is_robot_indexable": true, "report_reasons": null, "author": "dani0854", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fcmp9/open_source_tools_for_manual_data_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fcmp9/open_source_tools_for_manual_data_entry/", "subreddit_subscribers": 853244, "created_utc": 1677697197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jqb5kt26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Statistics on Data Scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_11g4gxp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yAfhCTWRJitkj1-X2MRO2vVzwSriJH52MUtDFF8-nDU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677768246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n5zn72cr8cla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n5zn72cr8cla1.png?auto=webp&amp;v=enabled&amp;s=3cfef72b03fb0a930829c69fc5e6338696efdec1", "width": 800, "height": 2000}, "resolutions": [{"url": "https://preview.redd.it/n5zn72cr8cla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=785813cc91171a85facf583c3ba7855c531fd9ff", "width": 108, "height": 216}, {"url": "https://preview.redd.it/n5zn72cr8cla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94a876a953f29b17f016a32b622095149f6829c5", "width": 216, "height": 432}, {"url": "https://preview.redd.it/n5zn72cr8cla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8c989f8a63029d0a399341100a92100ff753a74", "width": 320, "height": 640}, {"url": "https://preview.redd.it/n5zn72cr8cla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18b00bd590368b5a0ad6e9b09a9327074492fa6c", "width": 640, "height": 1280}], "variants": {}, "id": "kqScfC94YQwVOBZKbTZAsdiB-lKblph_UQzSD4isOT8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g4gxp", "is_robot_indexable": true, "report_reasons": null, "author": "SnthesisInc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g4gxp/current_statistics_on_data_scientists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n5zn72cr8cla1.png", "subreddit_subscribers": 853244, "created_utc": 1677768246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newbie question! The project I'm currently on is user clustering of a food delivery company.\n\nI'm at the preprocessing stage and I'm feeling stuck, and I'm having 2 dataframe columns with list and dict like structure. Any ideas how to deal with such columns?\n\nAll I can think about is data normalization as to convert those 2 columns to 2 separate dataframes,  but I don't know if that is the common practice to such issue.\n\nAny help is appreciated, thanks so much in advance.\n\nhttps://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8\n\nhttps://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258", "author_fullname": "t2_vn7kuoox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with multiple columns containing multiple values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"bs1v640z6cla1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=454c4224db2cad798461c9103d82e4be0ae27ca9"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1b16bbf2cb2ac0569897e7111bae07ec288507b"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89874ec0bfaf139c8c8026d65e82273922631f99"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2631e786d2e2d2bc2f1460cc94344291098036f4"}, {"y": 536, "x": 960, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fd074d9b9dbe14bcb28844e5da8593b4bbfaff6"}, {"y": 603, "x": 1080, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4649d215dac0d20404b20a3f83db88c0afb8c2a"}], "s": {"y": 715, "x": 1280, "u": "https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8"}, "id": "bs1v640z6cla1"}, "fg12i10z6cla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54204771d76ed62d30fc02a583d8b1b0991099c1"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98be7c74c9556d51c0ae1504cae664334b97c4f0"}, {"y": 155, "x": 320, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c136ca3af669f631fe1b17f24df01b8c19598354"}, {"y": 310, "x": 640, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e75a1bbc9c5aa64c2f435142b8a8036504f09364"}, {"y": 466, "x": 960, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a82a059df7e3260bf9e4464234173087fd7621f8"}, {"y": 524, "x": 1080, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46c9f56bac4513c28a1e280d1dcddaa000e1c80e"}], "s": {"y": 807, "x": 1661, "u": "https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258"}, "id": "fg12i10z6cla1"}}, "name": "t3_11g49mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4ArVN60qwbBnxhf8nGKC0ReNzvMDiYYDKU8f5pUvBYk.jpg", "edited": 1677770018.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie question! The project I&amp;#39;m currently on is user clustering of a food delivery company.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at the preprocessing stage and I&amp;#39;m feeling stuck, and I&amp;#39;m having 2 dataframe columns with list and dict like structure. Any ideas how to deal with such columns?&lt;/p&gt;\n\n&lt;p&gt;All I can think about is data normalization as to convert those 2 columns to 2 separate dataframes,  but I don&amp;#39;t know if that is the common practice to such issue.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated, thanks so much in advance.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8\"&gt;https://preview.redd.it/bs1v640z6cla1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d7e3eb5438f6fae82fe6833d6bd1e169e7629da8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258\"&gt;https://preview.redd.it/fg12i10z6cla1.png?width=1661&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a86879e57b51ccf7b317054e40a51e7e7809a258&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g49mz", "is_robot_indexable": true, "report_reasons": null, "author": "Hatasu98", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g49mz/how_to_deal_with_multiple_columns_containing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g49mz/how_to_deal_with_multiple_columns_containing/", "subreddit_subscribers": 853244, "created_utc": 1677767699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and to inside them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it's a proxy variable at the most and doesn't hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.\n\nNow I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I'd like to find.\n\nThanks.", "author_fullname": "t2_bvba4ue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find actual important variables for Proxies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fwel0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677742083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and to inside them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it&amp;#39;s a proxy variable at the most and doesn&amp;#39;t hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.&lt;/p&gt;\n\n&lt;p&gt;Now I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I&amp;#39;d like to find.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fwel0", "is_robot_indexable": true, "report_reasons": null, "author": "invincible_moron", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fwel0/how_to_find_actual_important_variables_for_proxies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fwel0/how_to_find_actual_important_variables_for_proxies/", "subreddit_subscribers": 853244, "created_utc": 1677742083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newly promoted to a senior data/analytics position at my company. Administrative question here. How do you all structure your folders and files? In general. If you were able to start from scratch in your current role, or if you just started a new job.. how do you organize? Aside from files and folders, do you leverage apps like OneNote, Evernote, databases, etc., to keep track of clients, projects, sandbox scripts and whatnot?", "author_fullname": "t2_gn8s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Folder Structuring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fu2ne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677734804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newly promoted to a senior data/analytics position at my company. Administrative question here. How do you all structure your folders and files? In general. If you were able to start from scratch in your current role, or if you just started a new job.. how do you organize? Aside from files and folders, do you leverage apps like OneNote, Evernote, databases, etc., to keep track of clients, projects, sandbox scripts and whatnot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fu2ne", "is_robot_indexable": true, "report_reasons": null, "author": "Thiseffingguy2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fu2ne/folder_structuring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fu2ne/folder_structuring/", "subreddit_subscribers": 853244, "created_utc": 1677734804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "* Curious what the typical setup is for data scientists on this channel at their companies.  Do they develop locally then deplot to github/bitbucket.  \n* Or is all development done via a VM?  Or something else?  \n* What is industry standard these days, if there even is one?", "author_fullname": "t2_dndjtxnl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you develop locally or on a VM? or something else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f9i7a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677691257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Curious what the typical setup is for data scientists on this channel at their companies.  Do they develop locally then deplot to github/bitbucket.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Or is all development done via a VM?  Or something else?&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;What is industry standard these days, if there even is one?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f9i7a", "is_robot_indexable": true, "report_reasons": null, "author": "jupyterpeak", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f9i7a/do_you_develop_locally_or_on_a_vm_or_something/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f9i7a/do_you_develop_locally_or_on_a_vm_or_something/", "subreddit_subscribers": 853244, "created_utc": 1677691257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to find articles that talk about AB Tests with a human element involved like a sales agent.", "author_fullname": "t2_2gjydo0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good articles on AB testing that involve a human element?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f65vg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677683397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find articles that talk about AB Tests with a human element involved like a sales agent.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f65vg", "is_robot_indexable": true, "report_reasons": null, "author": "BATTLECATHOTS", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f65vg/good_articles_on_ab_testing_that_involve_a_human/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f65vg/good_articles_on_ab_testing_that_involve_a_human/", "subreddit_subscribers": 853244, "created_utc": 1677683397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a report for school where I need to ask a data science professional some questions and then write a report on it. You don't have to answer all of them and the responses don't have to be that long they can be on the shorter side. Any help would be greatly appreciated. Thank you.\n\n1) As AI advances do you see any possible risk of mass job displacement in the future? Such as self driving cars replacing truck drivers, taxi drivers, etc. Do you think this will be a problem in the future or will it be the same as all the times we've automated something in the past and people will just adapt to the job market?\n\n\n2) Recently there has been some controversy around algorithmic bias, especially in data science. Such as automating parole decisions, job application screening, or applying for credit cards. Some people argue these machine learning algorithms have been somewhat racist/sexist in the past. Do you think data scientists should be doing their best to eliminate bias?\n\n\n3) With the recent release of chat bots like chatGPT students have been using it to help them write papers or help with their programming assignments. Do you see anything wrong with claiming chatGPT's responses as your own work? Do you consider it plagiarism?\n\n\n4) Art generation has gotten very popular recently and there have actually been some lawsuits against these AI's claiming they were trained on copyrighted images. Do you believe AI shouldn't be legally allowed to train on copyrighted material or will doing so significantly hinder AI's development as data scientists will have to be much more careful about how they obtain their datasets?\n\n\n5) As AI and image detection/recognition algorithms become more withspread do you think adversarial attacks will ever be a significant and practical problem?", "author_fullname": "t2_dj5j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working on a report for school, can someone answer a few ethics related data science questions for me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fpp9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677722890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a report for school where I need to ask a data science professional some questions and then write a report on it. You don&amp;#39;t have to answer all of them and the responses don&amp;#39;t have to be that long they can be on the shorter side. Any help would be greatly appreciated. Thank you.&lt;/p&gt;\n\n&lt;p&gt;1) As AI advances do you see any possible risk of mass job displacement in the future? Such as self driving cars replacing truck drivers, taxi drivers, etc. Do you think this will be a problem in the future or will it be the same as all the times we&amp;#39;ve automated something in the past and people will just adapt to the job market?&lt;/p&gt;\n\n&lt;p&gt;2) Recently there has been some controversy around algorithmic bias, especially in data science. Such as automating parole decisions, job application screening, or applying for credit cards. Some people argue these machine learning algorithms have been somewhat racist/sexist in the past. Do you think data scientists should be doing their best to eliminate bias?&lt;/p&gt;\n\n&lt;p&gt;3) With the recent release of chat bots like chatGPT students have been using it to help them write papers or help with their programming assignments. Do you see anything wrong with claiming chatGPT&amp;#39;s responses as your own work? Do you consider it plagiarism?&lt;/p&gt;\n\n&lt;p&gt;4) Art generation has gotten very popular recently and there have actually been some lawsuits against these AI&amp;#39;s claiming they were trained on copyrighted images. Do you believe AI shouldn&amp;#39;t be legally allowed to train on copyrighted material or will doing so significantly hinder AI&amp;#39;s development as data scientists will have to be much more careful about how they obtain their datasets?&lt;/p&gt;\n\n&lt;p&gt;5) As AI and image detection/recognition algorithms become more withspread do you think adversarial attacks will ever be a significant and practical problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fpp9o", "is_robot_indexable": true, "report_reasons": null, "author": "VelvetRevolver_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fpp9o/working_on_a_report_for_school_can_someone_answer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fpp9o/working_on_a_report_for_school_can_someone_answer/", "subreddit_subscribers": 853244, "created_utc": 1677722890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nI read a post here yesterday talking about common outlier detection methods that one can use like cusum or z scores and things like that but those don't seem able to address the problem I find myself running into a lot when trying to detect LOW outliers. \n\nFor the data I'm working with there can only be positive numbers or in some cases only can have numbers greater than a value like 1. When trying to run common outlier detection practices the lower bounds that are created are often negative (due to the standard deviation being high) which is basically useless since the underlying data cannot be negative. Since the aggregations are on the row level I cannot just play around with different z score thresholds to get a positive lower threshold value. Rather I need an equation that would recalculate a negative lower bound into a positive one if that makes sense. \n\nHas anyone run into something similar or have any ideas on how I should go about tackling this problem?\n\nThanks!", "author_fullname": "t2_kc2qc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting outlier detection problem I keep running into.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fbjy5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677695970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I read a post here yesterday talking about common outlier detection methods that one can use like cusum or z scores and things like that but those don&amp;#39;t seem able to address the problem I find myself running into a lot when trying to detect LOW outliers. &lt;/p&gt;\n\n&lt;p&gt;For the data I&amp;#39;m working with there can only be positive numbers or in some cases only can have numbers greater than a value like 1. When trying to run common outlier detection practices the lower bounds that are created are often negative (due to the standard deviation being high) which is basically useless since the underlying data cannot be negative. Since the aggregations are on the row level I cannot just play around with different z score thresholds to get a positive lower threshold value. Rather I need an equation that would recalculate a negative lower bound into a positive one if that makes sense. &lt;/p&gt;\n\n&lt;p&gt;Has anyone run into something similar or have any ideas on how I should go about tackling this problem?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11fbjy5", "is_robot_indexable": true, "report_reasons": null, "author": "Saniconspeep", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11fbjy5/interesting_outlier_detection_problem_i_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11fbjy5/interesting_outlier_detection_problem_i_keep/", "subreddit_subscribers": 853244, "created_utc": 1677695970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "today my work mainly consists of doing some data wrangling (mostly satellite image sequences) with python scripts run on a cloud instance, then using pytorch to build and train a deep learning model on a gpu instance on aws (I connect via ssh with vscode). I use tensorboard to monitor training. when it's done I usually pass the weights to other people and they will take care of making it available via an API.\n\nhow do I give the next step as a machine learning engineer? which tools to use? which concepts to learn?", "author_fullname": "t2_rhw2olfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to improve as a machine learning engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11flc7j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677712150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;today my work mainly consists of doing some data wrangling (mostly satellite image sequences) with python scripts run on a cloud instance, then using pytorch to build and train a deep learning model on a gpu instance on aws (I connect via ssh with vscode). I use tensorboard to monitor training. when it&amp;#39;s done I usually pass the weights to other people and they will take care of making it available via an API.&lt;/p&gt;\n\n&lt;p&gt;how do I give the next step as a machine learning engineer? which tools to use? which concepts to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11flc7j", "is_robot_indexable": true, "report_reasons": null, "author": "pocolai", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11flc7j/how_to_improve_as_a_machine_learning_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11flc7j/how_to_improve_as_a_machine_learning_engineer/", "subreddit_subscribers": 853244, "created_utc": 1677712150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking at the dashboard of the equity management platform our company use for the first time. I\u2019m confused at the numbers I\u2019m seeing.\n\nLet\u2019s say I join a startup that just closed Series A. They raised $10M and the post-money valuation is $40M. There are 80M fully diluted shares. The original issue price is $0.5, which I believe is $40M/80M.\n\nI\u2019m granted 0.1% or 800k shares. Why is the Fair Market Value of my shares (which is also my strike price) only $0.18 and not $0.5? Isn\u2019t it intuitive to think that if I own 0.1% of the shares, my shares are worth 0.1% of the company valuation?", "author_fullname": "t2_566oe2xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Familiar with Early Stage Startup Stock Options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f88jq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677688291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking at the dashboard of the equity management platform our company use for the first time. I\u2019m confused at the numbers I\u2019m seeing.&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say I join a startup that just closed Series A. They raised $10M and the post-money valuation is $40M. There are 80M fully diluted shares. The original issue price is $0.5, which I believe is $40M/80M.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m granted 0.1% or 800k shares. Why is the Fair Market Value of my shares (which is also my strike price) only $0.18 and not $0.5? Isn\u2019t it intuitive to think that if I own 0.1% of the shares, my shares are worth 0.1% of the company valuation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11f88jq", "is_robot_indexable": true, "report_reasons": null, "author": "pkklee2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11f88jq/anyone_familiar_with_early_stage_startup_stock/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11f88jq/anyone_familiar_with_early_stage_startup_stock/", "subreddit_subscribers": 853244, "created_utc": 1677688291.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}