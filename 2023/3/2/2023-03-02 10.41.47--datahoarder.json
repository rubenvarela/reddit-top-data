{"kind": "Listing", "data": {"after": "t3_11fjfok", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vtl8mp58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba to release 26TB HDDs this year, 30TB to come later", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "name": "t3_11fdf8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 517, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 517, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J7T3VLkEazJQLLqu31ZnA0Vy2fJuyQqCd3lyruKtDXE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677698077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pcgamer.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.pcgamer.com/toshiba-to-release-26tb-hdds-this-year-30tb-to-come-later/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?auto=webp&amp;v=enabled&amp;s=e9d7e95913e7fb9af7cde4e025cb516e407740ff", "width": 1024, "height": 659}, "resolutions": [{"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=241caf0c995f9f41e9b61bc639eb903d03a10e14", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36dea43da3b0d5d8428582e7af50e48f79ea96ab", "width": 216, "height": 139}, {"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=935e9f46b5748da673c3da50ef6336e02a72f9e2", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=417b7c38d88aeecf506c2358368430c965ade7a9", "width": 640, "height": 411}, {"url": "https://external-preview.redd.it/DjfJpKG2wyrMO3dtr4lGJK55BHj3NV_FwrEuZzuh7fk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fe6e1b7d443c750770231768d490405369acabc", "width": 960, "height": 617}], "variants": {}, "id": "DYxuRTkIcyn_-6WwslyFP7O_GtyekkDYZxrTiVM6kH0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fdf8t", "is_robot_indexable": true, "report_reasons": null, "author": "Phantom_Poops", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fdf8t/toshiba_to_release_26tb_hdds_this_year_30tb_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.pcgamer.com/toshiba-to-release-26tb-hdds-this-year-30tb-to-come-later/", "subreddit_subscribers": 671794, "created_utc": 1677698077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this depend on the models or is this true for every SATA SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11f07o0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 506, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_vm3gtntg", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 506, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3LZOebhhB8aiK3ERHqx0Rgd3MlBMOGtYoyBTTXPDwq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "mildlyinteresting", "selftext": "", "author_fullname": "t2_3z9fx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most of a solid state hard drive is just empty plastic.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/mildlyinteresting", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11e6hoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44793, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 44793, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/3LZOebhhB8aiK3ERHqx0Rgd3MlBMOGtYoyBTTXPDwq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1677592153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ddofzyxr6zka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?auto=webp&amp;v=enabled&amp;s=5c43ced6e8299e35064f21ed0628b3f37e81eeaf", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3092d2f742aabaf945befca3217bfaf956e3b9e5", "width": 108, "height": 144}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=601074ead030949853694b8c308615cb83080e0e", "width": 216, "height": 288}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20026a0b613f33da379778f73d105df5b702fd4c", "width": 320, "height": 426}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24d520e3b14b47542249d565a6a9838679bf44a9", "width": 640, "height": 853}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34c132f1483497f4a3541838f7a24eec476a46e9", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54929fcaee43caf5104c7c956bf075e0e0819dcf", "width": 1080, "height": 1440}], "variants": {}, "id": "D_Y6Vf-RM_cJrgDFiaEcU3-bYUGD61ZMp8QFJGYjOA4"}], "enabled": true}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_a67d649d-5aa5-407e-a98b-32fd9e3a9696", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "The more you know... Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Today I Learned", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ti4h", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11e6hoy", "is_robot_indexable": true, "report_reasons": null, "author": "Mindreeder93", "discussion_type": null, "num_comments": 2645, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/mildlyinteresting/comments/11e6hoy/most_of_a_solid_state_hard_drive_is_just_empty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ddofzyxr6zka1.jpg", "subreddit_subscribers": 21759474, "created_utc": 1677592153.0, "num_crossposts": 5, "media": null, "is_video": false}], "created": 1677665965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ddofzyxr6zka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?auto=webp&amp;v=enabled&amp;s=5c43ced6e8299e35064f21ed0628b3f37e81eeaf", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3092d2f742aabaf945befca3217bfaf956e3b9e5", "width": 108, "height": 144}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=601074ead030949853694b8c308615cb83080e0e", "width": 216, "height": 288}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20026a0b613f33da379778f73d105df5b702fd4c", "width": 320, "height": 426}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24d520e3b14b47542249d565a6a9838679bf44a9", "width": 640, "height": 853}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34c132f1483497f4a3541838f7a24eec476a46e9", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/ddofzyxr6zka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54929fcaee43caf5104c7c956bf075e0e0819dcf", "width": 1080, "height": 1440}], "variants": {}, "id": "D_Y6Vf-RM_cJrgDFiaEcU3-bYUGD61ZMp8QFJGYjOA4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f07o0", "is_robot_indexable": true, "report_reasons": null, "author": "nebzulifar", "discussion_type": null, "num_comments": 195, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11e6hoy", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f07o0/does_this_depend_on_the_models_or_is_this_true/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ddofzyxr6zka1.jpg", "subreddit_subscribers": 671794, "created_utc": 1677665965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I've been upgrading my PC over the last 2 years and during that I've found the wonderful world that is hoarding everything and anything. I started small, adding a \"big\" 2TB HDD I got from my brother during the pandemic. I thought I'd be set, considering how I only ever used little over 1TB in mixed forms over the last 5 or so years. \n\nCue now, where I've got 250gb in m.2, 250gb in an sdd 11TB between 3 different HDDs, and an 8TB HDD gamble coming from ebay (fingers crossed). \n\nTalking to a friend, a fellow hoarder, who's easily got close to 30TBs across multiple sources and is thinking of making his own server, suggested that I looked into the same, or for us to invest together in a bigger, better and more expensive server for both of us.\n\nI always thought making servers was something for people with, yknow, big important things cause of how costly they seem to build and maintain, but who knows, I could be wrong on that.\n\nSo, figured I'd ask here, what are y'all's thoughts? When is it, for you, worth it to ditch the PC storage method and invest in a server?", "author_fullname": "t2_1md50iw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what point do you think it's worth it to invest in a server rather than keep adding drives to a PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11frdmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677727245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been upgrading my PC over the last 2 years and during that I&amp;#39;ve found the wonderful world that is hoarding everything and anything. I started small, adding a &amp;quot;big&amp;quot; 2TB HDD I got from my brother during the pandemic. I thought I&amp;#39;d be set, considering how I only ever used little over 1TB in mixed forms over the last 5 or so years. &lt;/p&gt;\n\n&lt;p&gt;Cue now, where I&amp;#39;ve got 250gb in m.2, 250gb in an sdd 11TB between 3 different HDDs, and an 8TB HDD gamble coming from ebay (fingers crossed). &lt;/p&gt;\n\n&lt;p&gt;Talking to a friend, a fellow hoarder, who&amp;#39;s easily got close to 30TBs across multiple sources and is thinking of making his own server, suggested that I looked into the same, or for us to invest together in a bigger, better and more expensive server for both of us.&lt;/p&gt;\n\n&lt;p&gt;I always thought making servers was something for people with, yknow, big important things cause of how costly they seem to build and maintain, but who knows, I could be wrong on that.&lt;/p&gt;\n\n&lt;p&gt;So, figured I&amp;#39;d ask here, what are y&amp;#39;all&amp;#39;s thoughts? When is it, for you, worth it to ditch the PC storage method and invest in a server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11frdmz", "is_robot_indexable": true, "report_reasons": null, "author": "-Dusk-Fox", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11frdmz/at_what_point_do_you_think_its_worth_it_to_invest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11frdmz/at_what_point_do_you_think_its_worth_it_to_invest/", "subreddit_subscribers": 671794, "created_utc": 1677727245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SimpleX File Transfer Protocol (aka XFTP) \u2013 a new open-source protocol for sending large files efficiently, privately and securely \u2013 beta versions of XFTP relays and CLI are released!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fxcfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_7k499ptf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "PrivacyGuides", "selftext": "**XFTP** is a new file transfer protocol focussed on meta-data protection - it is based on the same principles as SimpleX Messaging Protocol used in [SimpleX Chat](https://simplex.chat) messenger:\n\n- asynchronous file delivery - the sender does not need to be online for file to be received, it is stored on XFTP relays for a limited time (currently, it is 48 hours) or until deleted by the sender.\n- padded e2e encryption of file content.\n- content padding and fixed size chunks sent via different XFTP relays, assembled back into the original file by the receiving client.\n- efficient sending to multiple recipients (the file needs to be uploaded only once).\n- no identifiers or ciphertext in common between sent and received relay traffic, same as for messages delivered by SMP relays.\n- protection of sender IP address from the recipients.\n\nYou can download XFTP CLI (Linux) to send files via the command line [here](https://github.com/simplex-chat/simplexmq/releases/tag/v5.0.0-beta.3) - you need the file named `xftp-ubuntu-20_04-x86-64`, rename it to `xftp`.\n\n**Send the file in 3 steps**:\n\n1. to send: `xftp send filename.ext`\n2. to share: pass the generated file description(s) to the recipient(s) via any secure channel, e.g. via SimpleX Chat.\n3. to receive: `xftp recv rcvN.xftp`\n\n**Please let us know what you think**, what downsides you see to this approach, and any ideas you have about how it can be improved.\n\nWe are currently integrating the support of XFTP protocol into SimpleX Chat that will allow sending videos and large files seamlessly and without the sender being online - it is coming soon!\n\nRead more details in this blog post: https://simplex.chat/blog/20230301-simplex-file-transfer-protocol.html\n\nThe source code: https://github.com/simplex-chat/simplexmq/tree/xftp", "author_fullname": "t2_13t18x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SimpleX File Transfer Protocol (aka XFTP) \u2013 a new open-source protocol for sending large files efficiently, privately and securely \u2013 beta versions of XFTP relays and CLI are released!", "link_flair_richtext": [{"e": "text", "t": "News"}], "subreddit_name_prefixed": "r/PrivacyGuides", "hidden": false, "pwls": 7, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fg9fa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": "", "subreddit_type": "public", "ups": 141, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 141, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [{"e": "text", "t": "Simplex founder"}], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677701359.0, "link_flair_type": "richtext", "wls": 7, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "self.PrivacyGuides", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;XFTP&lt;/strong&gt; is a new file transfer protocol focussed on meta-data protection - it is based on the same principles as SimpleX Messaging Protocol used in &lt;a href=\"https://simplex.chat\"&gt;SimpleX Chat&lt;/a&gt; messenger:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;asynchronous file delivery - the sender does not need to be online for file to be received, it is stored on XFTP relays for a limited time (currently, it is 48 hours) or until deleted by the sender.&lt;/li&gt;\n&lt;li&gt;padded e2e encryption of file content.&lt;/li&gt;\n&lt;li&gt;content padding and fixed size chunks sent via different XFTP relays, assembled back into the original file by the receiving client.&lt;/li&gt;\n&lt;li&gt;efficient sending to multiple recipients (the file needs to be uploaded only once).&lt;/li&gt;\n&lt;li&gt;no identifiers or ciphertext in common between sent and received relay traffic, same as for messages delivered by SMP relays.&lt;/li&gt;\n&lt;li&gt;protection of sender IP address from the recipients.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You can download XFTP CLI (Linux) to send files via the command line &lt;a href=\"https://github.com/simplex-chat/simplexmq/releases/tag/v5.0.0-beta.3\"&gt;here&lt;/a&gt; - you need the file named &lt;code&gt;xftp-ubuntu-20_04-x86-64&lt;/code&gt;, rename it to &lt;code&gt;xftp&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Send the file in 3 steps&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;to send: &lt;code&gt;xftp send filename.ext&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;to share: pass the generated file description(s) to the recipient(s) via any secure channel, e.g. via SimpleX Chat.&lt;/li&gt;\n&lt;li&gt;to receive: &lt;code&gt;xftp recv rcvN.xftp&lt;/code&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Please let us know what you think&lt;/strong&gt;, what downsides you see to this approach, and any ideas you have about how it can be improved.&lt;/p&gt;\n\n&lt;p&gt;We are currently integrating the support of XFTP protocol into SimpleX Chat that will allow sending videos and large files seamlessly and without the sender being online - it is coming soon!&lt;/p&gt;\n\n&lt;p&gt;Read more details in this blog post: &lt;a href=\"https://simplex.chat/blog/20230301-simplex-file-transfer-protocol.html\"&gt;https://simplex.chat/blog/20230301-simplex-file-transfer-protocol.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The source code: &lt;a href=\"https://github.com/simplex-chat/simplexmq/tree/xftp\"&gt;https://github.com/simplex-chat/simplexmq/tree/xftp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?auto=webp&amp;v=enabled&amp;s=889388775ee1c3fbd7bb2ea12a30fc6ebb7bcc52", "width": 320, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afff9106dad27a5f8a2442b818e24b9ea06cafbc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf9070c44fdda0fb8b9dd4c76cad6417a3450ded", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bec8ec72f16644ac73f507f40e9601a208de806", "width": 320, "height": 320}], "variants": {}, "id": "U3iCf8GjcquT1qPFC8OR00SlD9Hnw9Acft2_3PjJN9Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b4cdd4f0-2171-11ec-b47c-9a667d49ea89", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Simplex founder", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2p35dk", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11fg9fa", "is_robot_indexable": true, "report_reasons": null, "author": "epoberezkin", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "some_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/PrivacyGuides/comments/11fg9fa/simplex_file_transfer_protocol_aka_xftp_a_new/", "parent_whitelist_status": "some_ads", "stickied": false, "url": "https://old.reddit.com/r/PrivacyGuides/comments/11fg9fa/simplex_file_transfer_protocol_aka_xftp_a_new/", "subreddit_subscribers": 53656, "created_utc": 1677701359.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1677745270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PrivacyGuides", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/PrivacyGuides/comments/11fg9fa/simplex_file_transfer_protocol_aka_xftp_a_new/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?auto=webp&amp;v=enabled&amp;s=889388775ee1c3fbd7bb2ea12a30fc6ebb7bcc52", "width": 320, "height": 320}, "resolutions": [{"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afff9106dad27a5f8a2442b818e24b9ea06cafbc", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf9070c44fdda0fb8b9dd4c76cad6417a3450ded", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/PAfHS3IZ634_axqDop1LTgM5m7ZHZ3bNhL4kDYjWxxA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bec8ec72f16644ac73f507f40e9601a208de806", "width": 320, "height": 320}], "variants": {}, "id": "U3iCf8GjcquT1qPFC8OR00SlD9Hnw9Acft2_3PjJN9Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Collector", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fxcfx", "is_robot_indexable": true, "report_reasons": null, "author": "NXGZ", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11fg9fa", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11fxcfx/simplex_file_transfer_protocol_aka_xftp_a_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/PrivacyGuides/comments/11fg9fa/simplex_file_transfer_protocol_aka_xftp_a_new/", "subreddit_subscribers": 671794, "created_utc": 1677745270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Watching a foreign youtuber who is recently quitting and deleting their channel. I want to save what I can and understand what they are saying while replaying it back once I have archived it.", "author_fullname": "t2_2xwtod3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone figured out how to get auto-translation running on downloaded videos from youtube or ragtag archive? Currently trying to save as many vods as I can with my measly 200GB space.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11futxu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677737062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Watching a foreign youtuber who is recently quitting and deleting their channel. I want to save what I can and understand what they are saying while replaying it back once I have archived it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11futxu", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Historian97", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11futxu/has_anyone_figured_out_how_to_get_autotranslation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11futxu/has_anyone_figured_out_how_to_get_autotranslation/", "subreddit_subscribers": 671794, "created_utc": 1677737062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am in need of back up hd and i am try decide if i should stay with SATA which if it starts failing will give a warning such as cracking noise or go with SSD?", "author_fullname": "t2_csizh1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back up drive , SATA or SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11foxzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677721002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in need of back up hd and i am try decide if i should stay with SATA which if it starts failing will give a warning such as cracking noise or go with SSD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11foxzl", "is_robot_indexable": true, "report_reasons": null, "author": "looker009", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11foxzl/back_up_drive_sata_or_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11foxzl/back_up_drive_sata_or_ssd/", "subreddit_subscribers": 671794, "created_utc": 1677721002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just lost a lot of photos due to my dumbness and I want to avoid that happening again. I want to be able to easily organize them and back them up. I have old photos saved on flash drives/laptops and I have a lot of photos on my iphone that I want to back up. \n\nAny easy to use programs you can recommend? \n\nEdit: Forgot to mention I use Windows 10.", "author_fullname": "t2_3oje0kub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to back up and organize photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8eqx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677710644.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677688700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just lost a lot of photos due to my dumbness and I want to avoid that happening again. I want to be able to easily organize them and back them up. I have old photos saved on flash drives/laptops and I have a lot of photos on my iphone that I want to back up. &lt;/p&gt;\n\n&lt;p&gt;Any easy to use programs you can recommend? &lt;/p&gt;\n\n&lt;p&gt;Edit: Forgot to mention I use Windows 10.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f8eqx", "is_robot_indexable": true, "report_reasons": null, "author": "scaredycat07", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f8eqx/what_is_the_best_way_to_back_up_and_organize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11f8eqx/what_is_the_best_way_to_back_up_and_organize/", "subreddit_subscribers": 671794, "created_utc": 1677688700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about ten years' worth of PDFs (receipts, bills, tax returns, etc) and I desperately need something to organize them with. My file naming and organizing structure has been horrific over the years, so I'm looking for a software that can help me address this. My dream app has the ability to quickly add custom tags to files, edit file date metadata, and batch rename files using this metadata, but so far such a software has proven remarkably difficult to find. I've tried things like Forklift and File Commander, but they only seem to be able to do half of this. I know I could do it across different softwares, but that workflow seems too time consuming.\n\nWhat's the easiest way to systematically manage and rename a bunch of PDFs? Am I missing something obvious, or am I just going to have to do this manually through Finder?", "author_fullname": "t2_qvtu234m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Mac app for managing 1000s of PDFs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fugh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677735940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about ten years&amp;#39; worth of PDFs (receipts, bills, tax returns, etc) and I desperately need something to organize them with. My file naming and organizing structure has been horrific over the years, so I&amp;#39;m looking for a software that can help me address this. My dream app has the ability to quickly add custom tags to files, edit file date metadata, and batch rename files using this metadata, but so far such a software has proven remarkably difficult to find. I&amp;#39;ve tried things like Forklift and File Commander, but they only seem to be able to do half of this. I know I could do it across different softwares, but that workflow seems too time consuming.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the easiest way to systematically manage and rename a bunch of PDFs? Am I missing something obvious, or am I just going to have to do this manually through Finder?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fugh7", "is_robot_indexable": true, "report_reasons": null, "author": "minority_interest", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fugh7/best_mac_app_for_managing_1000s_of_pdfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fugh7/best_mac_app_for_managing_1000s_of_pdfs/", "subreddit_subscribers": 671794, "created_utc": 1677735940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If WD Gold 20 TB and  HGST 20 TB are \"intended\" for server/RAID drives (not \"normal\" drives), then whats inside WD Elements/MyBook 20 TB if WD Blue/Green doesnt exist with 20 TB, as especially \"WD Elements\" are made for home users.\n\nI prefer the WD Elements because its not encrypted so I can remove the drives if something happens to the enclosure.....\n\nOr should I go with WD HGST 20 TB (OptiNAND + 5 Year Warranty) + 3rd party external enclosure? WD Elements has only 2 years ?!?!?", "author_fullname": "t2_cda1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of drive is inside WD Elements 20 TB and MyBook 20 TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fk8d4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677709623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If WD Gold 20 TB and  HGST 20 TB are &amp;quot;intended&amp;quot; for server/RAID drives (not &amp;quot;normal&amp;quot; drives), then whats inside WD Elements/MyBook 20 TB if WD Blue/Green doesnt exist with 20 TB, as especially &amp;quot;WD Elements&amp;quot; are made for home users.&lt;/p&gt;\n\n&lt;p&gt;I prefer the WD Elements because its not encrypted so I can remove the drives if something happens to the enclosure.....&lt;/p&gt;\n\n&lt;p&gt;Or should I go with WD HGST 20 TB (OptiNAND + 5 Year Warranty) + 3rd party external enclosure? WD Elements has only 2 years ?!?!?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fk8d4", "is_robot_indexable": true, "report_reasons": null, "author": "deSSy2724", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fk8d4/what_kind_of_drive_is_inside_wd_elements_20_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fk8d4/what_kind_of_drive_is_inside_wd_elements_20_tb/", "subreddit_subscribers": 671794, "created_utc": 1677709623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted to bulk download some categories but not even one link works to download with yt dlp                (caused by &lt;HTTPError 403: 'Forbidden'&gt;)\n\nDoes someone know how to fix that or do i have to open a ticket on Github?", "author_fullname": "t2_w1ynydxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "cant download with yt dlp from \"Rule34Video.com\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fhg5d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677703421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to bulk download some categories but not even one link works to download with yt dlp                (caused by &amp;lt;HTTPError 403: &amp;#39;Forbidden&amp;#39;&amp;gt;)&lt;/p&gt;\n\n&lt;p&gt;Does someone know how to fix that or do i have to open a ticket on Github?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fhg5d", "is_robot_indexable": true, "report_reasons": null, "author": "No-End2814", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fhg5d/cant_download_with_yt_dlp_from_rule34videocom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fhg5d/cant_download_with_yt_dlp_from_rule34videocom/", "subreddit_subscribers": 671794, "created_utc": 1677703421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a Synology DS920+ NAS with 3 x 6TB WD Red disks (WD60EFRX). 2 of those disks are older and come from a previous NAS, while 1 of them is newer and was purchased with the DS920+.\n\nThe older disks have 6.3 years power on time by now and no SMART errors of any kind, everything running perfectly.\n\nHowever, the newer disk has only 2 years power on time, but is showing the following errors:\n\n* Drive re-identification count: 2\n* Multi Zone Error Rate: 1\n\nThese values are very low but still worrying to me. So here are my questions to the round:\n\n* do you think I should have this drive replaced under warranty, or rather, will WD honor the warranty for such low values? Or will they see the disk as \"fine\"?\n* do you think 6.3 years on the older drives is pushing it, and should I replace them just because they are old?\n\nI am evaluating several options. If I send the drive in under warranty, I cannot afford to be without redundancy for the time it takes for it to be replaced (as that usually takes 1-3 weeks from a local reseller), which would mean ordering a spare to cover the missing disk.\n\nAt the same time, ordering a 6 TB spare seems like wasted money to me as it's a rather small disk. Especially considering that the other 2 are quite old.\n\nSo here are my options:\n\n* order a 6 TB spare and have the disk with the SMART errors replaced under warranty (if they even do that)\n* order a WD Red Plus 14 TB, use that as a spare, have the disk with SMART errors replaced under warranty and put it back in service when it's fixed, and run with that setup until I need more space\n* order 2 x WD Red Plus 14 TB and throw the 3 x 6 TB disks out\n* order 3 x Samsung 870 QVO 8 TB SSDs and throw the 3 x 6 TB disks out\n\nPlease note that the NAS is in my home office so a quiet environment is a must. I don't have a basement or some other place to put the NAS. So WD Red disks are probably the quietest I can get, if I'm not going for SSDs.\n\nI know QLC SSDs are not recommended for NAS usage, but it's mainly a storage NAS where not much new data is being written, it mainly has a lot of read access (Plex server etc).\n\nWhat would you guys do? I'd appreciate some brainstorming on this. Thank you \ud83d\ude0a", "author_fullname": "t2_b1eqtae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS920+ with 3 x 6TB WD Red, disks getting old and 1 possible SMART error: how to proceed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fxh47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677745732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a Synology DS920+ NAS with 3 x 6TB WD Red disks (WD60EFRX). 2 of those disks are older and come from a previous NAS, while 1 of them is newer and was purchased with the DS920+.&lt;/p&gt;\n\n&lt;p&gt;The older disks have 6.3 years power on time by now and no SMART errors of any kind, everything running perfectly.&lt;/p&gt;\n\n&lt;p&gt;However, the newer disk has only 2 years power on time, but is showing the following errors:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Drive re-identification count: 2&lt;/li&gt;\n&lt;li&gt;Multi Zone Error Rate: 1&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These values are very low but still worrying to me. So here are my questions to the round:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;do you think I should have this drive replaced under warranty, or rather, will WD honor the warranty for such low values? Or will they see the disk as &amp;quot;fine&amp;quot;?&lt;/li&gt;\n&lt;li&gt;do you think 6.3 years on the older drives is pushing it, and should I replace them just because they are old?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am evaluating several options. If I send the drive in under warranty, I cannot afford to be without redundancy for the time it takes for it to be replaced (as that usually takes 1-3 weeks from a local reseller), which would mean ordering a spare to cover the missing disk.&lt;/p&gt;\n\n&lt;p&gt;At the same time, ordering a 6 TB spare seems like wasted money to me as it&amp;#39;s a rather small disk. Especially considering that the other 2 are quite old.&lt;/p&gt;\n\n&lt;p&gt;So here are my options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;order a 6 TB spare and have the disk with the SMART errors replaced under warranty (if they even do that)&lt;/li&gt;\n&lt;li&gt;order a WD Red Plus 14 TB, use that as a spare, have the disk with SMART errors replaced under warranty and put it back in service when it&amp;#39;s fixed, and run with that setup until I need more space&lt;/li&gt;\n&lt;li&gt;order 2 x WD Red Plus 14 TB and throw the 3 x 6 TB disks out&lt;/li&gt;\n&lt;li&gt;order 3 x Samsung 870 QVO 8 TB SSDs and throw the 3 x 6 TB disks out&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please note that the NAS is in my home office so a quiet environment is a must. I don&amp;#39;t have a basement or some other place to put the NAS. So WD Red disks are probably the quietest I can get, if I&amp;#39;m not going for SSDs.&lt;/p&gt;\n\n&lt;p&gt;I know QLC SSDs are not recommended for NAS usage, but it&amp;#39;s mainly a storage NAS where not much new data is being written, it mainly has a lot of read access (Plex server etc).&lt;/p&gt;\n\n&lt;p&gt;What would you guys do? I&amp;#39;d appreciate some brainstorming on this. Thank you \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fxh47", "is_robot_indexable": true, "report_reasons": null, "author": "theswissguy12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fxh47/ds920_with_3_x_6tb_wd_red_disks_getting_old_and_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fxh47/ds920_with_3_x_6tb_wd_red_disks_getting_old_and_1/", "subreddit_subscribers": 671794, "created_utc": 1677745732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Need some help understanding what I should do for my backup setup. I have a truenas machine setup and running raidz1. I bought a synology ds1821+ and was thinking I'll setup shr instead of shr2 because I have a truenas machine setup already, so feel that doing shr2 maybe a waste of space but not sure if that's the wrong though process to have. I want to replicate whatever is done to one to be replicated to the next. Would having this setup be fine? What is an easy way to replicate the data in Realtime? Any application for windows that will sync both network drives so if anything changes the other one will change as well.", "author_fullname": "t2_3hr19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Backup setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fuu5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677737082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need some help understanding what I should do for my backup setup. I have a truenas machine setup and running raidz1. I bought a synology ds1821+ and was thinking I&amp;#39;ll setup shr instead of shr2 because I have a truenas machine setup already, so feel that doing shr2 maybe a waste of space but not sure if that&amp;#39;s the wrong though process to have. I want to replicate whatever is done to one to be replicated to the next. Would having this setup be fine? What is an easy way to replicate the data in Realtime? Any application for windows that will sync both network drives so if anything changes the other one will change as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fuu5v", "is_robot_indexable": true, "report_reasons": null, "author": "xelu01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fuu5v/new_backup_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fuu5v/new_backup_setup/", "subreddit_subscribers": 671794, "created_utc": 1677737082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Parents have finally cracked it, over my multiple drives being on all the time and rising electricity prices, so they are getting me one unit, potentially a Synology, I know the storage is 100TB, cost is potentially 4 or 5K, and since I don\u2019t earn close to that, or can save money all that well (not my strong skill) I want that 100TB to last as long as possible.\n\nCurrent drive count is around 25, ranging from 1TB to 18TB, with two of those drives being aging synology units, an 8TB DS411j and a 16TB, as well as one aging 16TB WD Home Duo NAS.\n\nI know that not everything I have on those drives will migrate across, to the new unit, in the transfer process it will free up existing drives to then use as backups, but the thought of wanting to watch or archive something and having to physically connect the drive I need, every single time is driving me nuts.\n\nI have a rough idea in my head as it is, porn to a separate drive, old tv shows can be archived, but other methods I am just stressing out over.", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions for drastic downsizing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ftzp6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677734556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Parents have finally cracked it, over my multiple drives being on all the time and rising electricity prices, so they are getting me one unit, potentially a Synology, I know the storage is 100TB, cost is potentially 4 or 5K, and since I don\u2019t earn close to that, or can save money all that well (not my strong skill) I want that 100TB to last as long as possible.&lt;/p&gt;\n\n&lt;p&gt;Current drive count is around 25, ranging from 1TB to 18TB, with two of those drives being aging synology units, an 8TB DS411j and a 16TB, as well as one aging 16TB WD Home Duo NAS.&lt;/p&gt;\n\n&lt;p&gt;I know that not everything I have on those drives will migrate across, to the new unit, in the transfer process it will free up existing drives to then use as backups, but the thought of wanting to watch or archive something and having to physically connect the drive I need, every single time is driving me nuts.&lt;/p&gt;\n\n&lt;p&gt;I have a rough idea in my head as it is, porn to a separate drive, old tv shows can be archived, but other methods I am just stressing out over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ftzp6", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ftzp6/need_suggestions_for_drastic_downsizing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ftzp6/need_suggestions_for_drastic_downsizing/", "subreddit_subscribers": 671794, "created_utc": 1677734556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone,\n\nI'm having a major issue with my Google Drive that I'm hoping someone can help me with. For years now, my Drive has been sporadically duplicating files for some reason, and I now have over 8000 duplicate gdoc and gsheet files clogging up my storage. I want to keep all of this data forever, but I desperately need to get rid of these erroneous duplicates.\n\nI've tried using duplicate finder apps like Duplicate File Finder, but unfortunately, none of them seem to work with gdoc or gsheet files. I've also searched high and low for cloud-based file finder apps, but have come up short -- It seems none of them will touch gdoc or gsheet files.\n\nI'm wondering if anyone has any strategies or solutions that I could try to solve this problem without having to go through each of these 8000 files individually. \n\nAny help or advice would be greatly appreciated. Also, if this isn't the right place to ask, recommendations for alternate places to post would be appreciated -- data hoarders seem like a lot that might have some ideas for me. Thank you in advance!", "author_fullname": "t2_79w0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for dealing with over 8000 pure duplicate Google Drive files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ftdna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677732748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having a major issue with my Google Drive that I&amp;#39;m hoping someone can help me with. For years now, my Drive has been sporadically duplicating files for some reason, and I now have over 8000 duplicate gdoc and gsheet files clogging up my storage. I want to keep all of this data forever, but I desperately need to get rid of these erroneous duplicates.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried using duplicate finder apps like Duplicate File Finder, but unfortunately, none of them seem to work with gdoc or gsheet files. I&amp;#39;ve also searched high and low for cloud-based file finder apps, but have come up short -- It seems none of them will touch gdoc or gsheet files.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if anyone has any strategies or solutions that I could try to solve this problem without having to go through each of these 8000 files individually. &lt;/p&gt;\n\n&lt;p&gt;Any help or advice would be greatly appreciated. Also, if this isn&amp;#39;t the right place to ask, recommendations for alternate places to post would be appreciated -- data hoarders seem like a lot that might have some ideas for me. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ftdna", "is_robot_indexable": true, "report_reasons": null, "author": "plymouthvan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ftdna/ideas_for_dealing_with_over_8000_pure_duplicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ftdna/ideas_for_dealing_with_over_8000_pure_duplicate/", "subreddit_subscribers": 671794, "created_utc": 1677732748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ordered a 6TB Red but received a Black 10TB instead. Will the lifespan be noticeably shorter? Sees decent regular usage (Asustor).", "author_fullname": "t2_6bk9k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ordered a WD Red, received a Black instead. Are these ok in a NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fnfaf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677717207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ordered a 6TB Red but received a Black 10TB instead. Will the lifespan be noticeably shorter? Sees decent regular usage (Asustor).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fnfaf", "is_robot_indexable": true, "report_reasons": null, "author": "angrycommie", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fnfaf/ordered_a_wd_red_received_a_black_instead_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fnfaf/ordered_a_wd_red_received_a_black_instead_are/", "subreddit_subscribers": 671794, "created_utc": 1677717207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased one of those to connect a WD purple 8tb to my m70q, it works pretty well, has USAP,allows sleep, and are cheap, I want to purchase another one to connect another WD 8tb, and uncluster my setup of a lot of smaller disks, can I use a Y splitter and connect both cases with the same powerbrick? or should I use a 12V4A for safety of the hard drives? specially during the power peak as they start to spin.", "author_fullname": "t2_z2izm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ugreen 3.5 Inches USB 3.0 Hard Drive Enclosure: Can I power 2 of those with one 12V2A powerbrick?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fev5r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677699711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased one of those to connect a WD purple 8tb to my m70q, it works pretty well, has USAP,allows sleep, and are cheap, I want to purchase another one to connect another WD 8tb, and uncluster my setup of a lot of smaller disks, can I use a Y splitter and connect both cases with the same powerbrick? or should I use a 12V4A for safety of the hard drives? specially during the power peak as they start to spin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fev5r", "is_robot_indexable": true, "report_reasons": null, "author": "Maribel-han", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fev5r/ugreen_35_inches_usb_30_hard_drive_enclosure_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fev5r/ugreen_35_inches_usb_30_hard_drive_enclosure_can/", "subreddit_subscribers": 671794, "created_utc": 1677699711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it just my bad luck when it comes to getting old SAS drives from amazon sellers when they are marked as NEW? Last 3 time they have tried to pass used one off as new.", "author_fullname": "t2_2afjbn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS Drives from Amazon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fbjnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677695950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just my bad luck when it comes to getting old SAS drives from amazon sellers when they are marked as NEW? Last 3 time they have tried to pass used one off as new.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11fbjnz", "is_robot_indexable": true, "report_reasons": null, "author": "Boximus1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fbjnz/sas_drives_from_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fbjnz/sas_drives_from_amazon/", "subreddit_subscribers": 671794, "created_utc": 1677695950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want the expandability of Snapraid/Mergerfs with the COW checksumming of zfs. So my idea is to create a ZFS cache drive and download files to that location. Then do a verified copy to the Snapraid/MergerFs system. Then, once the Snapraid has run its scrubbing procedure I can compare the checksums between zfs and Snapraid for the new files. This would ensure Snapraid has the right checksums and that there hasnt been bitrot issues between me downloading the file and the Snapraid checksum.\n\nIs this a good idea?", "author_fullname": "t2_13g9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using zfs as an in-between drive fro Snapraid/Mergerfs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fb610", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677695079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want the expandability of Snapraid/Mergerfs with the COW checksumming of zfs. So my idea is to create a ZFS cache drive and download files to that location. Then do a verified copy to the Snapraid/MergerFs system. Then, once the Snapraid has run its scrubbing procedure I can compare the checksums between zfs and Snapraid for the new files. This would ensure Snapraid has the right checksums and that there hasnt been bitrot issues between me downloading the file and the Snapraid checksum.&lt;/p&gt;\n\n&lt;p&gt;Is this a good idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fb610", "is_robot_indexable": true, "report_reasons": null, "author": "linuxman1929", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fb610/using_zfs_as_an_inbetween_drive_fro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fb610/using_zfs_as_an_inbetween_drive_fro/", "subreddit_subscribers": 671794, "created_utc": 1677695079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I built an unRAID system years ago, but I'd like to update the internals. I don't completely understand backplanes and SATA limitations of the cases. Would there be any benefit either in performance or ease of build to switching cases? Thanks.", "author_fullname": "t2_wn6ma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any benefit to replacing a working Norco 4224 with a Rosewill 4412?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8vig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677689811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built an unRAID system years ago, but I&amp;#39;d like to update the internals. I don&amp;#39;t completely understand backplanes and SATA limitations of the cases. Would there be any benefit either in performance or ease of build to switching cases? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f8vig", "is_robot_indexable": true, "report_reasons": null, "author": "Foogyfoggy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f8vig/any_benefit_to_replacing_a_working_norco_4224/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11f8vig/any_benefit_to_replacing_a_working_norco_4224/", "subreddit_subscribers": 671794, "created_utc": 1677689811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anybody had any luck transferring large amounts of files from a managed Google Workspace docs or drive account to a personal account? \n\nA coworker is trying to migrate ~80,000 files from a managed account to his personal one, without converting to and from non-google formats as that will remove embedded youtube videos and throw up other quirks.\n\nIs there a way to download the .gdocs files directly? \n\nHe is currently using some script found online but it drops out after around 90 minutes and then needs manually restarting from the point it had reached.\n\nThank you.", "author_fullname": "t2_91ue4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating Google Workspace files to personal Google One?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8edw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677688676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody had any luck transferring large amounts of files from a managed Google Workspace docs or drive account to a personal account? &lt;/p&gt;\n\n&lt;p&gt;A coworker is trying to migrate ~80,000 files from a managed account to his personal one, without converting to and from non-google formats as that will remove embedded youtube videos and throw up other quirks.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to download the .gdocs files directly? &lt;/p&gt;\n\n&lt;p&gt;He is currently using some script found online but it drops out after around 90 minutes and then needs manually restarting from the point it had reached.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f8edw", "is_robot_indexable": true, "report_reasons": null, "author": "endresz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f8edw/migrating_google_workspace_files_to_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11f8edw/migrating_google_workspace_files_to_personal/", "subreddit_subscribers": 671794, "created_utc": 1677688676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So my company originally didn\u2019t want to bother with Google Drive and just decided we would use everyone\u2019s personal gmail accounts. Now everyone is complaining about their storage being full so we are finally switching to Google Workspace.\n\nThere is 0.5TB worth of data that has to get transferred over to the new Drive. \n\nAdditionally we have a Dropbox with 400GB of content that we also want to move to the new Drive.\n\nWhat\u2019s the best way to do this? What hardware, software?\n\nSorry if this is the wrong sub, not sure where to go this for this", "author_fullname": "t2_16yd2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Transfer: Google Drive and Dropbox", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f5i35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677681777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my company originally didn\u2019t want to bother with Google Drive and just decided we would use everyone\u2019s personal gmail accounts. Now everyone is complaining about their storage being full so we are finally switching to Google Workspace.&lt;/p&gt;\n\n&lt;p&gt;There is 0.5TB worth of data that has to get transferred over to the new Drive. &lt;/p&gt;\n\n&lt;p&gt;Additionally we have a Dropbox with 400GB of content that we also want to move to the new Drive.&lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best way to do this? What hardware, software?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong sub, not sure where to go this for this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f5i35", "is_robot_indexable": true, "report_reasons": null, "author": "zuccccccccccc", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f5i35/data_transfer_google_drive_and_dropbox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11f5i35/data_transfer_google_drive_and_dropbox/", "subreddit_subscribers": 671794, "created_utc": 1677681777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there,  \n\n\nI recently stumbled my way into trying tape storage as I am wanting a better way to archive my NAS. I opted to get a LTO4 IBM drive (IBM TS2340 3580 Express L43 LT04 External Tape Drive). New dedicated Win10 rig, SCSI card (I believe) and connections work great, however I need drivers for the tape drive. IBM has their Fix Center site but when attempting to obtain their indexed drivers they error out, it seems like they don't host them anymore, and their support ticket responses more or less boil down to \"You don't have an active support policy with us so good luck\".   \n\n\nI've searched for any archives but no luck so far, anyone got any wisdom/solutions or am I a little screwed? Thanks all.", "author_fullname": "t2_in0qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quest for IBM TS2340 LT04 Drivers. Anyone able to help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f4k53", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677679376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,  &lt;/p&gt;\n\n&lt;p&gt;I recently stumbled my way into trying tape storage as I am wanting a better way to archive my NAS. I opted to get a LTO4 IBM drive (IBM TS2340 3580 Express L43 LT04 External Tape Drive). New dedicated Win10 rig, SCSI card (I believe) and connections work great, however I need drivers for the tape drive. IBM has their Fix Center site but when attempting to obtain their indexed drivers they error out, it seems like they don&amp;#39;t host them anymore, and their support ticket responses more or less boil down to &amp;quot;You don&amp;#39;t have an active support policy with us so good luck&amp;quot;.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched for any archives but no luck so far, anyone got any wisdom/solutions or am I a little screwed? Thanks all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11f4k53", "is_robot_indexable": true, "report_reasons": null, "author": "yoshi278", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11f4k53/quest_for_ibm_ts2340_lt04_drivers_anyone_able_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11f4k53/quest_for_ibm_ts2340_lt04_drivers_anyone_able_to/", "subreddit_subscribers": 671794, "created_utc": 1677679376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok so I got a modern pc with bo optical drive support. I want to add the ability to rip multiple disc's at one. I was looking into one of these Copystars Duplicator case for build Blu-ray-CD-dvd-duplicator tower + power supply (5 bay) https://a.co/d/7zM8BPP. The problem that is it has no hook ups to a pc. The comments recommend Addonics HPM-XU 5-port Serial ATA Controller but is no longer sold. \n\nMy question is is there any other card like that or can I hook up one of these to my pc and would it work. https://www.newegg.com/lsi00333-sata-sas/p/N82E16816118188 Check this out! https://a.co/d/atIyISz \n\nWould really like help with this.", "author_fullname": "t2_o3l0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with DVD/ Bluray ripping", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fs1cg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677729005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok so I got a modern pc with bo optical drive support. I want to add the ability to rip multiple disc&amp;#39;s at one. I was looking into one of these Copystars Duplicator case for build Blu-ray-CD-dvd-duplicator tower + power supply (5 bay) &lt;a href=\"https://a.co/d/7zM8BPP\"&gt;https://a.co/d/7zM8BPP&lt;/a&gt;. The problem that is it has no hook ups to a pc. The comments recommend Addonics HPM-XU 5-port Serial ATA Controller but is no longer sold. &lt;/p&gt;\n\n&lt;p&gt;My question is is there any other card like that or can I hook up one of these to my pc and would it work. &lt;a href=\"https://www.newegg.com/lsi00333-sata-sas/p/N82E16816118188\"&gt;https://www.newegg.com/lsi00333-sata-sas/p/N82E16816118188&lt;/a&gt; Check this out! &lt;a href=\"https://a.co/d/atIyISz\"&gt;https://a.co/d/atIyISz&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Would really like help with this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fs1cg", "is_robot_indexable": true, "report_reasons": null, "author": "TheLawlessRaven", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fs1cg/need_help_with_dvd_bluray_ripping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fs1cg/need_help_with_dvd_bluray_ripping/", "subreddit_subscribers": 671794, "created_utc": 1677729005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two unraid servers. \n\nThe oldest has 8 drives + parity. The parity drive is a 10TB SAS drive + 2 8TB SAS drives. All SAS are seagate X0. The other 6 drives are other enterprise 8TB sata. When I move through folders with 300+ other folders or files its not that bad. Downloading or copying files to it is great. However on the new unraid server. being only 4 drives + parity. The parity is a seagate X16 14TB sata. The other drives are another 14TB x16 , and 3 8TB enterprise sata drives. When moving through folders is painfully slow. Both unraids are running the same OS version, hardware setup, and same cache drive step up.\n\nI don't know if the SAS drives are making it faster when going through folders or if the number of drives.", "author_fullname": "t2_2afjbn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unraid SAS vs SATA for parity.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fqrhe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677725622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two unraid servers. &lt;/p&gt;\n\n&lt;p&gt;The oldest has 8 drives + parity. The parity drive is a 10TB SAS drive + 2 8TB SAS drives. All SAS are seagate X0. The other 6 drives are other enterprise 8TB sata. When I move through folders with 300+ other folders or files its not that bad. Downloading or copying files to it is great. However on the new unraid server. being only 4 drives + parity. The parity is a seagate X16 14TB sata. The other drives are another 14TB x16 , and 3 8TB enterprise sata drives. When moving through folders is painfully slow. Both unraids are running the same OS version, hardware setup, and same cache drive step up.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if the SAS drives are making it faster when going through folders or if the number of drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fqrhe", "is_robot_indexable": true, "report_reasons": null, "author": "Boximus1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fqrhe/unraid_sas_vs_sata_for_parity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fqrhe/unraid_sas_vs_sata_for_parity/", "subreddit_subscribers": 671794, "created_utc": 1677725622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Apps such as Scannable (iOS) and OneDrive are able to use the mobile phone camera to \"scan\" documents and simultaneously fix orientation, contrast, lighting, etc., thus creating a file that looks like it was scanned using a scanner.\n\nI have a PDF document that requires the same treatment (someone just photographed a bunch of pages instead of using one of the above apps).\n\nIs there something I can use to \"fix\" the PDF that takes an existing PDF as input, as opposed to photographing the document?\n\n(Ideally free, just as the above mentioned apps are. Adobe is not an option.)", "author_fullname": "t2_1hrxlpqy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fix badly photographed document", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fjfok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677707843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apps such as Scannable (iOS) and OneDrive are able to use the mobile phone camera to &amp;quot;scan&amp;quot; documents and simultaneously fix orientation, contrast, lighting, etc., thus creating a file that looks like it was scanned using a scanner.&lt;/p&gt;\n\n&lt;p&gt;I have a PDF document that requires the same treatment (someone just photographed a bunch of pages instead of using one of the above apps).&lt;/p&gt;\n\n&lt;p&gt;Is there something I can use to &amp;quot;fix&amp;quot; the PDF that takes an existing PDF as input, as opposed to photographing the document?&lt;/p&gt;\n\n&lt;p&gt;(Ideally free, just as the above mentioned apps are. Adobe is not an option.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11fjfok", "is_robot_indexable": true, "report_reasons": null, "author": "croc_mcphee", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11fjfok/fix_badly_photographed_document/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11fjfok/fix_badly_photographed_document/", "subreddit_subscribers": 671794, "created_utc": 1677707843.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}