{"kind": "Listing", "data": {"after": "t3_1234afa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2he9afpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After over 15 years of ripping and downloading, my music library just reached 20TB. AMA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "name": "t3_122j0f3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 1636, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1636, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RREjcQuvpRXMQsS54A8KQmAJvAYhMVti0_p_dIpEk50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679829327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/c03bk4cmg2qa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?auto=webp&amp;v=enabled&amp;s=8a4245d424da24ebf1350d7700fadb3680ea1398", "width": 374, "height": 130}, "resolutions": [{"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4c762107b1e86dd66adabe7e6e3a5e02bf6d27b", "width": 108, "height": 37}, {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=531da5001d077fbcc7abee4967b0d7e2679818d8", "width": 216, "height": 75}, {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79d5dbb00f66d2d7bb1071060b303de3c1052736", "width": 320, "height": 111}], "variants": {}, "id": "ug80s_19BI1qle7GjGkuyxEhz2NmaVf8bMSSVoaYyKk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "122j0f3", "is_robot_indexable": true, "report_reasons": null, "author": "Casual_Tea_94", "discussion_type": null, "num_comments": 409, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122j0f3/after_over_15_years_of_ripping_and_downloading_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/c03bk4cmg2qa1.png", "subreddit_subscribers": 675546, "created_utc": 1679829327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "*Hi, I'm Far\\_Marsupial6303 and I'm a datahoarder...*\n\nI've written a number of times about how I've grown to hate my datahoarding. But I've crossed the line to true addiction and obsession. \n\nI'm absolutely anal about organizing my linux ISOs and therefore it takes days or weeks to get through TB. I currently have \\~30TB of files I haven't gotten to organizing and haven't watched anything for months. Yet, I still keep adding more! \\*SIGH\\*\n\n\"So just stop!\"\n\nEasy to say, hard to do. This is truly an addiction and obsession (defined by thinking about it and worrying about it several times a day, every day). \\*DOUBLE SIGH\\*\n\n*Thank you for reading my story.*", "author_fullname": "t2_7aj1lgdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My datahoarding confession of shame...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122u4f1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679853471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Hi, I&amp;#39;m Far_Marsupial6303 and I&amp;#39;m a datahoarder...&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve written a number of times about how I&amp;#39;ve grown to hate my datahoarding. But I&amp;#39;ve crossed the line to true addiction and obsession. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m absolutely anal about organizing my linux ISOs and therefore it takes days or weeks to get through TB. I currently have ~30TB of files I haven&amp;#39;t gotten to organizing and haven&amp;#39;t watched anything for months. Yet, I still keep adding more! *SIGH*&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;So just stop!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Easy to say, hard to do. This is truly an addiction and obsession (defined by thinking about it and worrying about it several times a day, every day). *DOUBLE SIGH*&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for reading my story.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "122u4f1", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Marsupial6303", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122u4f1/my_datahoarding_confession_of_shame/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122u4f1/my_datahoarding_confession_of_shame/", "subreddit_subscribers": 675546, "created_utc": 1679853471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone know how to automatically record from kick? I have tried to make a script that checks the status of kick and use yt-dlp to record but can\u2019t get it to work", "author_fullname": "t2_umg8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically record live streams from kick.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122czcs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679811233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679811001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know how to automatically record from kick? I have tried to make a script that checks the status of kick and use yt-dlp to record but can\u2019t get it to work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122czcs", "is_robot_indexable": true, "report_reasons": null, "author": "--Happy--", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122czcs/automatically_record_live_streams_from_kickcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122czcs/automatically_record_live_streams_from_kickcom/", "subreddit_subscribers": 675546, "created_utc": 1679811001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Internally, there is a mix of IDE and SATA DVD-ROMs, with adapters to convert to USB3, and then all of those are plugged into an internal USB3 hub.  On the PC I used custom batch files to rip all of them simultaneously.\n\nhttps://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6484f235739eca66ba228a2352e3f355a138e120", "author_fullname": "t2_2ky1uaug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scratch build DVD ripping tower", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"so5thftgu2qa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39e5900a5d683306a54900c8fc4932cdb6fd449b"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca3661629420c96e728495cd569a160c016db481"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6350b4fee68696980ae535457f9f6516de843ed6"}, {"y": 458, "x": 640, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f000dc8a841fd9544d7ecfeb7986737f2a2ee91"}, {"y": 688, "x": 960, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=368897c31ee21cc01b113b74b278a6152c017fd0"}, {"y": 774, "x": 1080, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31cfc89c2a845b2d0244f0ba2818ac98f80fb06d"}], "s": {"y": 1376, "x": 1920, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6484f235739eca66ba228a2352e3f355a138e120"}, "id": "so5thftgu2qa1"}}, "name": "t3_122kk8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NhiyryTK6wp5vpPSI7Cxd5EAMlSY-EPgHe2GyV58NF0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679833633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Internally, there is a mix of IDE and SATA DVD-ROMs, with adapters to convert to USB3, and then all of those are plugged into an internal USB3 hub.  On the PC I used custom batch files to rip all of them simultaneously.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6484f235739eca66ba228a2352e3f355a138e120\"&gt;https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6484f235739eca66ba228a2352e3f355a138e120&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122kk8s", "is_robot_indexable": true, "report_reasons": null, "author": "LydianM", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122kk8s/scratch_build_dvd_ripping_tower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122kk8s/scratch_build_dvd_ripping_tower/", "subreddit_subscribers": 675546, "created_utc": 1679833633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've always wondered this.  If there's fine dust on a BD-R disc (which is fairly common) how come that doesn't prevent a disc from getting burned properly?  A pit on a BD-R disk is 150 nanometers so any dust that's visible is gonna be bigger.  Does burning the disc work purely because of the extra error correction data written to each sector on the disc?  A full sector is only about 1/3 of a millimeter (if my math is right) which isn't that much larger than some specs of dust.  I would think the dust would cover a large portion of a sector.  Or is the laser used to burn the disc able to shine through tiny specs of dust?  Anyone know?", "author_fullname": "t2_mgmtm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Come Dust Doesn't Prevent BD-R Burning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122avij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679804656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve always wondered this.  If there&amp;#39;s fine dust on a BD-R disc (which is fairly common) how come that doesn&amp;#39;t prevent a disc from getting burned properly?  A pit on a BD-R disk is 150 nanometers so any dust that&amp;#39;s visible is gonna be bigger.  Does burning the disc work purely because of the extra error correction data written to each sector on the disc?  A full sector is only about 1/3 of a millimeter (if my math is right) which isn&amp;#39;t that much larger than some specs of dust.  I would think the dust would cover a large portion of a sector.  Or is the laser used to burn the disc able to shine through tiny specs of dust?  Anyone know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "122avij", "is_robot_indexable": true, "report_reasons": null, "author": "HarryMuscle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122avij/how_come_dust_doesnt_prevent_bdr_burning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122avij/how_come_dust_doesnt_prevent_bdr_burning/", "subreddit_subscribers": 675546, "created_utc": 1679804656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nintendo 3DS and Wii U eShop permanently shutting down in two days", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1230d5a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_xlxw6", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/kD1t4xtjieT_weReTKpTttSrPwYP_c1imPsPu1dRXb8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LeftistGamersUnion", "selftext": "", "author_fullname": "t2_604w21c5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nintendo 3DS and Wii U eShop permanently shutting down in two days", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LeftistGamersUnion", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_122vw4h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/kD1t4xtjieT_weReTKpTttSrPwYP_c1imPsPu1dRXb8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679857231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "digitalspy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.digitalspy.com/tech/a43416801/nintendo-3ds-wii-u-eshop-closing-soon/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?auto=webp&amp;v=enabled&amp;s=d2508aac7dd1c8e0a38e9e1fa8edb0a5798337c9", "width": 1200, "height": 602}, "resolutions": [{"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86d5bdefd8271b02f68c28860888436dfcdc1585", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ea407e90ccf6a3ff8098bc062397ef9a14e674a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=362630d41461db73c14d03628ce6ddd386cb003d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e35bb124bdaaba252694963b25dbede2db1c7aaa", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2cd7f19276031197b5566b5c2a29c2fd2c95806", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db7af360ef66e8fd26c60cd613f8191bb96a937f", "width": 1080, "height": 541}], "variants": {}, "id": "TFaL8O0G456e8qJGa0jZzv4TTXACVycX3ns-KHJEjm4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_ubm2e", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "122vw4h", "is_robot_indexable": true, "report_reasons": null, "author": "yuritopiaposadism", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LeftistGamersUnion/comments/122vw4h/nintendo_3ds_and_wii_u_eshop_permanently_shutting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.digitalspy.com/tech/a43416801/nintendo-3ds-wii-u-eshop-closing-soon/", "subreddit_subscribers": 17999, "created_utc": 1679857231.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679866214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "digitalspy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.digitalspy.com/tech/a43416801/nintendo-3ds-wii-u-eshop-closing-soon/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?auto=webp&amp;v=enabled&amp;s=d2508aac7dd1c8e0a38e9e1fa8edb0a5798337c9", "width": 1200, "height": 602}, "resolutions": [{"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86d5bdefd8271b02f68c28860888436dfcdc1585", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ea407e90ccf6a3ff8098bc062397ef9a14e674a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=362630d41461db73c14d03628ce6ddd386cb003d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e35bb124bdaaba252694963b25dbede2db1c7aaa", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2cd7f19276031197b5566b5c2a29c2fd2c95806", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/mo9GmKJ4svW4RoFz9VciEDjW97SLWE0DdCcQGBJsBV8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db7af360ef66e8fd26c60cd613f8191bb96a937f", "width": 1080, "height": 541}], "variants": {}, "id": "TFaL8O0G456e8qJGa0jZzv4TTXACVycX3ns-KHJEjm4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1230d5a", "is_robot_indexable": true, "report_reasons": null, "author": "focus_rising", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_122vw4h", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1230d5a/nintendo_3ds_and_wii_u_eshop_permanently_shutting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.digitalspy.com/tech/a43416801/nintendo-3ds-wii-u-eshop-closing-soon/", "subreddit_subscribers": 675546, "created_utc": 1679866214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found an old 2TB HDD that used to be in one of my laptops. It is detectable but stalls out on reads and has a large number of bad sectors in SMART. I am hoping to find somewhere with something like a rapidspar, or a similar byte-for-byte copy tool, to see if they can copy the data from the current drive onto an undamaged one. Anything more than that is probably not worth the cost. I dont know what is saved on the drive anymore. It is possible there is sensitive data on the drive because it is encrypted. It is also possible that all the important data on the drive was already backed up in the past and I forgot to physically mark the drive.\n\nIs there a way to search for reputable local data recovery services, or are things like yelp and google my best bets?", "author_fullname": "t2_qngs2dbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you find a reputable data recovery service?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122adr4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679803283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found an old 2TB HDD that used to be in one of my laptops. It is detectable but stalls out on reads and has a large number of bad sectors in SMART. I am hoping to find somewhere with something like a rapidspar, or a similar byte-for-byte copy tool, to see if they can copy the data from the current drive onto an undamaged one. Anything more than that is probably not worth the cost. I dont know what is saved on the drive anymore. It is possible there is sensitive data on the drive because it is encrypted. It is also possible that all the important data on the drive was already backed up in the past and I forgot to physically mark the drive.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to search for reputable local data recovery services, or are things like yelp and google my best bets?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122adr4", "is_robot_indexable": true, "report_reasons": null, "author": "ByteArchivist", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122adr4/how_do_you_find_a_reputable_data_recovery_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122adr4/how_do_you_find_a_reputable_data_recovery_service/", "subreddit_subscribers": 675546, "created_utc": 1679803283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the process of copying some old floppies I've been having in my basement for way too long, and some of them are in pretty bad shape. I've done quite a few already, but wondering if there are any hints/tips for how to best do the job? Setup: Some old floppy drives and a Catweasel 3 PCI card I had lying around. (Expecting a Greaseweazle to arrive in a few days)\n\nExperiences so far:\n- Retrying sometimes \"cleans up\" the platter of disks after a few full sweeps and make them more readable. Not sure how bad that is for the read heads though.\n- Some disks are so dirty they make the drive unable to read from one head until cleaned. But some times the cleaning disk seems to make things worse?\n- Not sure if it's better to focus on volume of disks vs trying to do deeper recovery of each disk, retrying bad tracks hundreds of times in the hopes that it eventually works (And in a lot of cases, it does work...after a while)\n- If you have disks that you think about dumping, better do it sooner than later. These have only gotten worse as time has gone by.", "author_fullname": "t2_45osc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for transferring a ton of old/musty 3.5 inch floppies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122j5tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679829758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of copying some old floppies I&amp;#39;ve been having in my basement for way too long, and some of them are in pretty bad shape. I&amp;#39;ve done quite a few already, but wondering if there are any hints/tips for how to best do the job? Setup: Some old floppy drives and a Catweasel 3 PCI card I had lying around. (Expecting a Greaseweazle to arrive in a few days)&lt;/p&gt;\n\n&lt;p&gt;Experiences so far:\n- Retrying sometimes &amp;quot;cleans up&amp;quot; the platter of disks after a few full sweeps and make them more readable. Not sure how bad that is for the read heads though.\n- Some disks are so dirty they make the drive unable to read from one head until cleaned. But some times the cleaning disk seems to make things worse?\n- Not sure if it&amp;#39;s better to focus on volume of disks vs trying to do deeper recovery of each disk, retrying bad tracks hundreds of times in the hopes that it eventually works (And in a lot of cases, it does work...after a while)\n- If you have disks that you think about dumping, better do it sooner than later. These have only gotten worse as time has gone by.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122j5tm", "is_robot_indexable": true, "report_reasons": null, "author": "ymgve", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122j5tm/best_practices_for_transferring_a_ton_of_oldmusty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122j5tm/best_practices_for_transferring_a_ton_of_oldmusty/", "subreddit_subscribers": 675546, "created_utc": 1679829758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm a noob to Hoarding, but would like to join you all soon.\n\nBased on my limited research, it sounds like I should perhaps get a 5 x bay Synology NAS with 12tb-18tb WD Red Drives and arrange them in RAID-5.\n\nBut, I figured I'd run this by you all first.\n\nAny advice?\n\nI'm planning on using it as a media server and would need remote management access as well.\n\nBonus question: What are the most valuable things to hoard that most people aren't hoarding? Books? Wikipedia? DNS databases?", "author_fullname": "t2_7zift", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a budget of between $2,000-$2,500 what should I buy for maximizing my storage + hoarding capabilities with as little maintenance as possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122b7oy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679805647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a noob to Hoarding, but would like to join you all soon.&lt;/p&gt;\n\n&lt;p&gt;Based on my limited research, it sounds like I should perhaps get a 5 x bay Synology NAS with 12tb-18tb WD Red Drives and arrange them in RAID-5.&lt;/p&gt;\n\n&lt;p&gt;But, I figured I&amp;#39;d run this by you all first.&lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using it as a media server and would need remote management access as well.&lt;/p&gt;\n\n&lt;p&gt;Bonus question: What are the most valuable things to hoard that most people aren&amp;#39;t hoarding? Books? Wikipedia? DNS databases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122b7oy", "is_robot_indexable": true, "report_reasons": null, "author": "aknalid", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122b7oy/with_a_budget_of_between_20002500_what_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122b7oy/with_a_budget_of_between_20002500_what_should_i/", "subreddit_subscribers": 675546, "created_utc": 1679805647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm hoping to get some recommendations for an app that can help me with document archiving.\n\nI looking for something for personal uses something that will let me the ability to throw documents with the knowledge that they are backed up in a safe place and cut back on paper all around my home", "author_fullname": "t2_2pclqfn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on a document archiving app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122eqq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679816441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hoping to get some recommendations for an app that can help me with document archiving.&lt;/p&gt;\n\n&lt;p&gt;I looking for something for personal uses something that will let me the ability to throw documents with the knowledge that they are backed up in a safe place and cut back on paper all around my home&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122eqq3", "is_robot_indexable": true, "report_reasons": null, "author": "AvgBlue", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122eqq3/seeking_advice_on_a_document_archiving_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122eqq3/seeking_advice_on_a_document_archiving_app/", "subreddit_subscribers": 675546, "created_utc": 1679816441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Per subject, just came across these and looking through the threads. \n\nFrom this thread at r/AskADataRecoveryPro [https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with\\_data\\_recovery\\_does\\_price\\_matter/](https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/)\n\n[https://www.datarecoveryprofessionals.org/](https://www.datarecoveryprofessionals.org/)", "author_fullname": "t2_7aj1lgdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just discovered: r/askadatarecoverypro and r/datarecovery for inquires about data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122bn0s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679806899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Per subject, just came across these and looking through the threads. &lt;/p&gt;\n\n&lt;p&gt;From this thread at &lt;a href=\"/r/AskADataRecoveryPro\"&gt;r/AskADataRecoveryPro&lt;/a&gt; &lt;a href=\"https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/\"&gt;https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datarecoveryprofessionals.org/\"&gt;https://www.datarecoveryprofessionals.org/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122bn0s", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Marsupial6303", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122bn0s/just_discovered_raskadatarecoverypro_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122bn0s/just_discovered_raskadatarecoverypro_and/", "subreddit_subscribers": 675546, "created_utc": 1679806899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone know of a tutorial for for creating a Winrar command line process for a periodic full folder back up for windows scheduler?  \nI've looked around the help file but not as straight forward as i would wish.", "author_fullname": "t2_12sxeu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tutorial for for creating Winrar command line back up for a folder for windows scheduler", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122wnb3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679858832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know of a tutorial for for creating a Winrar command line process for a periodic full folder back up for windows scheduler?&lt;br/&gt;\nI&amp;#39;ve looked around the help file but not as straight forward as i would wish.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122wnb3", "is_robot_indexable": true, "report_reasons": null, "author": "ctles", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122wnb3/tutorial_for_for_creating_winrar_command_line/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122wnb3/tutorial_for_for_creating_winrar_command_line/", "subreddit_subscribers": 675546, "created_utc": 1679858832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks. With the possible results of the internet archive removing content, i decided to start saving the important things locally.\n\nI have two basic questions though. \n\n1. I read everywhere people using HDD's instead of SSD'S to save content. Is that only because they are cheaper or are they considered more reliable in the long run?\n\n2. I need some kind of software to search my saved content. The basic name search in not enough. Maybe i need to find something by category. Problem is, if i just use folders to organize things, i will need to have multiple copies of the same file to find it on different categories.\n\nBetter ideas for organizing content? \n\nThank you so much in advance!", "author_fullname": "t2_aqp4qsth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help a newbie start hoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122hpoj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679825242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks. With the possible results of the internet archive removing content, i decided to start saving the important things locally.&lt;/p&gt;\n\n&lt;p&gt;I have two basic questions though. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I read everywhere people using HDD&amp;#39;s instead of SSD&amp;#39;S to save content. Is that only because they are cheaper or are they considered more reliable in the long run?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I need some kind of software to search my saved content. The basic name search in not enough. Maybe i need to find something by category. Problem is, if i just use folders to organize things, i will need to have multiple copies of the same file to find it on different categories.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Better ideas for organizing content? &lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122hpoj", "is_robot_indexable": true, "report_reasons": null, "author": "TheN1ght0w1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122hpoj/help_a_newbie_start_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122hpoj/help_a_newbie_start_hoarding/", "subreddit_subscribers": 675546, "created_utc": 1679825242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got a raidz array (1 disk of redundancy, the ZFS equivalent of RAID 5) with 5x 4TB drives. One of them seems to have failed.\n\nIt's certainly not unreasonable that the hardware just wore out. It's got a power-on time of about 6 years, as do the other drives in my array, and the SMART short self-test shows a failure.\n\nThe failed drive is a Western Digital Red Pro WDC WD4001FFSX-68JNUN0\n\nI'm running all five drives off of a used 3ware 9000 series HBA card I got for cheap 7 years ago. My 16TB array currently has 10TB used, and it's on an ubuntu server in an ATX desktop case.\n\nZFS has saved my data (as long as I don't have another problem), so that's great. But it's clearly time to retire this drive pool. What should I replace it with? \n\n&amp;#x200B;\n\nAre there any gotchas with newer drives that I should be aware of, that weren't true of hard drives 7 years ago?", "author_fullname": "t2_l13ss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive failed in raidz array. What should I replace it with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1232875", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679870992.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679870066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a raidz array (1 disk of redundancy, the ZFS equivalent of RAID 5) with 5x 4TB drives. One of them seems to have failed.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s certainly not unreasonable that the hardware just wore out. It&amp;#39;s got a power-on time of about 6 years, as do the other drives in my array, and the SMART short self-test shows a failure.&lt;/p&gt;\n\n&lt;p&gt;The failed drive is a Western Digital Red Pro WDC WD4001FFSX-68JNUN0&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m running all five drives off of a used 3ware 9000 series HBA card I got for cheap 7 years ago. My 16TB array currently has 10TB used, and it&amp;#39;s on an ubuntu server in an ATX desktop case.&lt;/p&gt;\n\n&lt;p&gt;ZFS has saved my data (as long as I don&amp;#39;t have another problem), so that&amp;#39;s great. But it&amp;#39;s clearly time to retire this drive pool. What should I replace it with? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any gotchas with newer drives that I should be aware of, that weren&amp;#39;t true of hard drives 7 years ago?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1232875", "is_robot_indexable": true, "report_reasons": null, "author": "squigish", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1232875/drive_failed_in_raidz_array_what_should_i_replace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1232875/drive_failed_in_raidz_array_what_should_i_replace/", "subreddit_subscribers": 675546, "created_utc": 1679870066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have poorly managed my data for years and now have about 4-5TB of data on a single hard drive. I want to start by copying it to an external HDD in order to provide some redundancy while I put together a more modern solution.\n\nThe data currently is on a Windows 7 system and I figured that Windows file transfer is not the best/safest/most efficient way to ensure my data is appropriately transferred. What suggestions would you have to move it to an external drive until I can build an UnRaid system or something similar. TY!", "author_fullname": "t2_aw54b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to copy/clone/backup 4TB....how?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123260w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679869933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have poorly managed my data for years and now have about 4-5TB of data on a single hard drive. I want to start by copying it to an external HDD in order to provide some redundancy while I put together a more modern solution.&lt;/p&gt;\n\n&lt;p&gt;The data currently is on a Windows 7 system and I figured that Windows file transfer is not the best/safest/most efficient way to ensure my data is appropriately transferred. What suggestions would you have to move it to an external drive until I can build an UnRaid system or something similar. TY!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "123260w", "is_robot_indexable": true, "report_reasons": null, "author": "delnith", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/123260w/need_to_copyclonebackup_4tbhow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/123260w/need_to_copyclonebackup_4tbhow/", "subreddit_subscribers": 675546, "created_utc": 1679869933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I don't know if that's the right place to post such a question, but I figured that maybe someone here has had the same issue I'm having. I stored around 650gb of data on an illimited google drive archive offered by my university, but I recently got an email telling me that this is going to change and that they are going to shrink the space available to students. So I bought an external 2tb SSD and decided to download everything I have on google drive there. I tried using google takeout but I think they made it very frustrating on purpouse: they split your data in multiple zip files and it's almost certain that you will get some error downloading the zip files. Long story short I managed to download only 6 zip files out of 16. So I'm looking for alternatives. I often used google colab to download content from another shared drive to my personal drive, and I was wondering if it was possibile to download folders from google drive to an external drive using it. That way I could just write the script, launch it and go to sleep. I'm also opened to basically anything else that would allow me to move my data out from google drive.  \n\n\nThanks in advance for your help. I apologize for my english (I'm not an english speaker) and if it wasn't the right place to post it.", "author_fullname": "t2_5a0gnoys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using google colab to download the entirety of google drive to external ssd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122y6w5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679861942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I don&amp;#39;t know if that&amp;#39;s the right place to post such a question, but I figured that maybe someone here has had the same issue I&amp;#39;m having. I stored around 650gb of data on an illimited google drive archive offered by my university, but I recently got an email telling me that this is going to change and that they are going to shrink the space available to students. So I bought an external 2tb SSD and decided to download everything I have on google drive there. I tried using google takeout but I think they made it very frustrating on purpouse: they split your data in multiple zip files and it&amp;#39;s almost certain that you will get some error downloading the zip files. Long story short I managed to download only 6 zip files out of 16. So I&amp;#39;m looking for alternatives. I often used google colab to download content from another shared drive to my personal drive, and I was wondering if it was possibile to download folders from google drive to an external drive using it. That way I could just write the script, launch it and go to sleep. I&amp;#39;m also opened to basically anything else that would allow me to move my data out from google drive.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help. I apologize for my english (I&amp;#39;m not an english speaker) and if it wasn&amp;#39;t the right place to post it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122y6w5", "is_robot_indexable": true, "report_reasons": null, "author": "L_ESIMIO", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122y6w5/using_google_colab_to_download_the_entirety_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122y6w5/using_google_colab_to_download_the_entirety_of/", "subreddit_subscribers": 675546, "created_utc": 1679861942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there I have question.\nI want to backup all of my on several stored HDDs to a cloud service.\nI came up with long time data storage so maybe I could also stored on tape drives. I don't use the data frequently but I don't know what's the best option.\nSo if not to a cloud service like opendrive.com where unlimited storage costs about 10$/ month would it be a better option to store it on a tape (which I don't have yet)?\n\nAlso the requirements of backupping is maybe necessary to sort the data manually over a longer period of time?\n\nHow you manage the data and sort it or store it if there is as much you want?\n\nI don't have as big as data is on hdd which is browseable with an sharkoon HDD duo and I have an lto tape drive what is used with Max. 500gb.\n\nA friend of mine also sold all of his HDDs because of the lack of room space.\nHe said he never used it and deleted all of his unnecessary data.\n\nWhat's your strategy to overcome data loss?\n\nAlso would the cost of an extra root server to only store data be cheaper?\n\nThanks in advance for your responses!", "author_fullname": "t2_csoia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upload about max 20 TB of data to a cloud provider", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122rxsz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679848898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there I have question.\nI want to backup all of my on several stored HDDs to a cloud service.\nI came up with long time data storage so maybe I could also stored on tape drives. I don&amp;#39;t use the data frequently but I don&amp;#39;t know what&amp;#39;s the best option.\nSo if not to a cloud service like opendrive.com where unlimited storage costs about 10$/ month would it be a better option to store it on a tape (which I don&amp;#39;t have yet)?&lt;/p&gt;\n\n&lt;p&gt;Also the requirements of backupping is maybe necessary to sort the data manually over a longer period of time?&lt;/p&gt;\n\n&lt;p&gt;How you manage the data and sort it or store it if there is as much you want?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have as big as data is on hdd which is browseable with an sharkoon HDD duo and I have an lto tape drive what is used with Max. 500gb.&lt;/p&gt;\n\n&lt;p&gt;A friend of mine also sold all of his HDDs because of the lack of room space.\nHe said he never used it and deleted all of his unnecessary data.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your strategy to overcome data loss?&lt;/p&gt;\n\n&lt;p&gt;Also would the cost of an extra root server to only store data be cheaper?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your responses!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122rxsz", "is_robot_indexable": true, "report_reasons": null, "author": "chiefdome", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122rxsz/upload_about_max_20_tb_of_data_to_a_cloud_provider/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122rxsz/upload_about_max_20_tb_of_data_to_a_cloud_provider/", "subreddit_subscribers": 675546, "created_utc": 1679848898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My dad recently made an acrylic flat rectangle panel for me to screw my HDD on it, and screw the acrylic on the too of the HDD cage. But will this DIY acrylic panel HDD mount cause vibration and damage my hdd?", "author_fullname": "t2_8siy7ss6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for PC with one HDD cage while doing 4 drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122hut7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679825716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad recently made an acrylic flat rectangle panel for me to screw my HDD on it, and screw the acrylic on the too of the HDD cage. But will this DIY acrylic panel HDD mount cause vibration and damage my hdd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122hut7", "is_robot_indexable": true, "report_reasons": null, "author": "SciencioGT", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122hut7/advice_for_pc_with_one_hdd_cage_while_doing_4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122hut7/advice_for_pc_with_one_hdd_cage_while_doing_4/", "subreddit_subscribers": 675546, "created_utc": 1679825716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently just finished a project where I digitized a lot of cassette tapes recorded by a late family member (I won't specify what, but in total it's about 221 30-45 minute audio files). They're all on youtube and [archive.org](https://archive.org/), but I wanted to make some DVDs that you could put into a player, have a menu with selection, and have it play the audio while a still image (the same from the youtube videos) is on the screen, and hopefully subtitles showing too.\n\n&amp;#x200B;\n\nI have dvds with 4.7gb of capacity, and I would split 6.33gb worth of Audio, Images, and Subtitles between two discs. I also got some of the 8.5 DL dvds incase I can't get that to work, as I was able to get mp4s of the \"videos\" (still just a still image with audio) down to about 10.3gb in total, which I can similarly spread between two of those discs.\n\n&amp;#x200B;\n\nI just don't really know how to do that. I downloaded dvdstyler, but it seems to demand the use of videos. I found this thread [https://sourceforge.net/p/dvdstyler/discussion/318795/thread/88406878/#1ec5](https://sourceforge.net/p/dvdstyler/discussion/318795/thread/88406878/#1ec5) which described a way to get it to work, but muxman is rejecting my ac3 audio. I did the previously mentioned video compressing and it didn't matter because dvdstyler seems to have a minimum video bitrate way higher than what is necessary for a still image, that would prevent it from fitting. I thought there's got to be some other program besides dvdstyler that will take still images natively or not limit minimum bandwidth.\n\n&amp;#x200B;\n\nI found DVD Flick, which seemed to accept setting the bandwidth low but after burning a test disc it was just buggy and blurry as all hell in the menu, and wouldn't play anything. If I attempted to select something from the title select screen, it wouldn't swap to the video, and just play 3-4 seconds of audio from it before freezing.\n\n&amp;#x200B;\n\nI heard some good things about Roxio creator studio/NXT but I'm not willing to pay 70 bucks for a \"maybe\". I know that there has to be a way to do this. I literally just want a menu that lets me select between a bunch of audio tracks and show an image and maybe subtitles while it plays. It's gotta be possible. Please help?", "author_fullname": "t2_q6u56", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to make audio DVDs with menus. Very stuck. Please help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122eyjw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679817159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently just finished a project where I digitized a lot of cassette tapes recorded by a late family member (I won&amp;#39;t specify what, but in total it&amp;#39;s about 221 30-45 minute audio files). They&amp;#39;re all on youtube and &lt;a href=\"https://archive.org/\"&gt;archive.org&lt;/a&gt;, but I wanted to make some DVDs that you could put into a player, have a menu with selection, and have it play the audio while a still image (the same from the youtube videos) is on the screen, and hopefully subtitles showing too.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have dvds with 4.7gb of capacity, and I would split 6.33gb worth of Audio, Images, and Subtitles between two discs. I also got some of the 8.5 DL dvds incase I can&amp;#39;t get that to work, as I was able to get mp4s of the &amp;quot;videos&amp;quot; (still just a still image with audio) down to about 10.3gb in total, which I can similarly spread between two of those discs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I just don&amp;#39;t really know how to do that. I downloaded dvdstyler, but it seems to demand the use of videos. I found this thread &lt;a href=\"https://sourceforge.net/p/dvdstyler/discussion/318795/thread/88406878/#1ec5\"&gt;https://sourceforge.net/p/dvdstyler/discussion/318795/thread/88406878/#1ec5&lt;/a&gt; which described a way to get it to work, but muxman is rejecting my ac3 audio. I did the previously mentioned video compressing and it didn&amp;#39;t matter because dvdstyler seems to have a minimum video bitrate way higher than what is necessary for a still image, that would prevent it from fitting. I thought there&amp;#39;s got to be some other program besides dvdstyler that will take still images natively or not limit minimum bandwidth.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I found DVD Flick, which seemed to accept setting the bandwidth low but after burning a test disc it was just buggy and blurry as all hell in the menu, and wouldn&amp;#39;t play anything. If I attempted to select something from the title select screen, it wouldn&amp;#39;t swap to the video, and just play 3-4 seconds of audio from it before freezing.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I heard some good things about Roxio creator studio/NXT but I&amp;#39;m not willing to pay 70 bucks for a &amp;quot;maybe&amp;quot;. I know that there has to be a way to do this. I literally just want a menu that lets me select between a bunch of audio tracks and show an image and maybe subtitles while it plays. It&amp;#39;s gotta be possible. Please help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122eyjw", "is_robot_indexable": true, "report_reasons": null, "author": "herma123", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122eyjw/trying_to_make_audio_dvds_with_menus_very_stuck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122eyjw/trying_to_make_audio_dvds_with_menus_very_stuck/", "subreddit_subscribers": 675546, "created_utc": 1679817159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any suggestions? distributing scimag to people in global south via physical media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1229tcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5juokasf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "libgen", "selftext": "Hi everyone! One of the goals for LibGen seeding project is making the science journal articles accessible for those in global south. Since scimag torrents total \\~73.5TB, I guess it's not gonna be possible for people in global south to download them easily!\n\nSo what should I do to distribute them to researchers in global south who need them? I figured to:\n\n1. download the torrents\n2. then get the SQL files which include the DOIs\n3. Unpack all the zip files to external HDDs e.g. 4x 20TB\n4. Ship the HDDs to the ppl who need them, and can duplicate + pass them around to their friends!\n\nIt all sounded feasible, until I thought abt unpacking the archives! Does anyone know how much storage I will need after unpacking them?\n\nHas anyone done this? Is there a protocol for it? I'm a bit of a neophyte! Thanks!\n\nEdit: changing a word", "author_fullname": "t2_644lcri6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributing scimag to people in global south via physical media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/libgen", "hidden": false, "pwls": 7, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1220iuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679783435.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679781213.0, "link_flair_type": "text", "wls": 7, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! One of the goals for LibGen seeding project is making the science journal articles accessible for those in global south. Since scimag torrents total ~73.5TB, I guess it&amp;#39;s not gonna be possible for people in global south to download them easily!&lt;/p&gt;\n\n&lt;p&gt;So what should I do to distribute them to researchers in global south who need them? I figured to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;download the torrents&lt;/li&gt;\n&lt;li&gt;then get the SQL files which include the DOIs&lt;/li&gt;\n&lt;li&gt;Unpack all the zip files to external HDDs e.g. 4x 20TB&lt;/li&gt;\n&lt;li&gt;Ship the HDDs to the ppl who need them, and can duplicate + pass them around to their friends!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It all sounded feasible, until I thought abt unpacking the archives! Does anyone know how much storage I will need after unpacking them?&lt;/p&gt;\n\n&lt;p&gt;Has anyone done this? Is there a protocol for it? I&amp;#39;m a bit of a neophyte! Thanks!&lt;/p&gt;\n\n&lt;p&gt;Edit: changing a word&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_31p7i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1220iuq", "is_robot_indexable": true, "report_reasons": null, "author": "KoalasWelcomeHere", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "some_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "parent_whitelist_status": "some_ads", "stickied": false, "url": "https://old.reddit.com/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "subreddit_subscribers": 50490, "created_utc": 1679781213.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679801710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1229tcc", "is_robot_indexable": true, "report_reasons": null, "author": "n0noTAGAinnxw4Yn3wp7", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1220iuq", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1229tcc/any_suggestions_distributing_scimag_to_people_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "subreddit_subscribers": 675546, "created_utc": 1679801710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Everyone,\n\nI picked up a EXOS x18 drive for my unraid server which has front mounted hot swap bays.  When I went push it into a slot, it became stuck.  I immediately pulled it back out and realized that the drive was slightly taller than other drives I have picked up in the past.  Are newer/larger capacity drives not fit in older hot swap bays OR since it was a reman/renewed drive, was it not standard for some reason.  I have been using ironwolf drives for a while now with no problem but they are 8-10TB drives.  Thoughts?", "author_fullname": "t2_7e3nvygl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New drive doesn't fit in unraid server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1228ca6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679797858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I picked up a EXOS x18 drive for my unraid server which has front mounted hot swap bays.  When I went push it into a slot, it became stuck.  I immediately pulled it back out and realized that the drive was slightly taller than other drives I have picked up in the past.  Are newer/larger capacity drives not fit in older hot swap bays OR since it was a reman/renewed drive, was it not standard for some reason.  I have been using ironwolf drives for a while now with no problem but they are 8-10TB drives.  Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1228ca6", "is_robot_indexable": true, "report_reasons": null, "author": "Usual_Plant_5853", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1228ca6/new_drive_doesnt_fit_in_unraid_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1228ca6/new_drive_doesnt_fit_in_unraid_server/", "subreddit_subscribers": 675546, "created_utc": 1679797858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Moving some videos from my wifes portable harddrive to my server, and almost all of the videos have spots where they freeze frame and play max volume static for about one second before continuing on and doing it again.\n\n\nEverything else on here seems OK, no issues with pictures, music, or other files.\n\nAny suggestions as to the best effort to recover these? (I'm thinking some kind of utility that will just cut out the static/frozen bits)", "author_fullname": "t2_4upw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Videos recovered off a portable harddrive pause and play loud static every few seconds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1236vpm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679880757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Moving some videos from my wifes portable harddrive to my server, and almost all of the videos have spots where they freeze frame and play max volume static for about one second before continuing on and doing it again.&lt;/p&gt;\n\n&lt;p&gt;Everything else on here seems OK, no issues with pictures, music, or other files.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions as to the best effort to recover these? (I&amp;#39;m thinking some kind of utility that will just cut out the static/frozen bits)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1236vpm", "is_robot_indexable": true, "report_reasons": null, "author": "Doggins", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1236vpm/videos_recovered_off_a_portable_harddrive_pause/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1236vpm/videos_recovered_off_a_portable_harddrive_pause/", "subreddit_subscribers": 675546, "created_utc": 1679880757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any chance anyone here has the Japanese dubs for any Power Ranger series here? All the links I could find are dead out there.", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power Rangers Japanese Dub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12365v3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679879091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any chance anyone here has the Japanese dubs for any Power Ranger series here? All the links I could find are dead out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12365v3", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12365v3/power_rangers_japanese_dub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12365v3/power_rangers_japanese_dub/", "subreddit_subscribers": 675546, "created_utc": 1679879091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have a sea gate 2tb hdd. I plan on backing my pictures up to that but also want to put my pictures on two USB hard drives just in case. Can someone recommend the best USB drive for this! Thanks all!", "author_fullname": "t2_6fj0q1f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best USB drive to store photos on?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1234ddw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679874866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a sea gate 2tb hdd. I plan on backing my pictures up to that but also want to put my pictures on two USB hard drives just in case. Can someone recommend the best USB drive for this! Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1234ddw", "is_robot_indexable": true, "report_reasons": null, "author": "treeguy541", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1234ddw/best_usb_drive_to_store_photos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1234ddw/best_usb_drive_to_store_photos_on/", "subreddit_subscribers": 675546, "created_utc": 1679874866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I'm transferring about 8tb from an internal 8tb SSD to a new QNAP NAS that's running two 16tb HDD's set up as a single RAID1 volume. \n\nOver the course of the several days that the files have been copying, I'm getting some intermittent error messages regarding the transfer. Here's a few examples: \n\n&amp;#x200B;\n\n&gt;10:48:11: Created: 230324-144811-493-737.db  \n10:48:58: Copying...  \n10:48:58: Source: F:\\\\  \n10:48:58: Target: \\\\\\\\NASStorage\\\\SSDDATA  \n12:48:24: F:\\\\Games\\\\Arcade\\\\MAME 0.250 EXTRAs\\\\covers\\_SL.zip  \n12:48:24: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392  \n12:48:24: ------------  \n12:48:56: F:\\\\Games\\\\Arcade\\\\MAME 0.250 EXTRAs\\\\devices.zip  \n12:48:56: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392  \n12:48:56: ------------  \n13:06:23: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\3countb\\\\3countb.txt  \n13:06:23: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392  \n13:06:23: ------------  \n13:08:15: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\iron\\\\01 Demo.mp3  \n13:08:15: Error opening source file. The system cannot find the file specified. Code: 2  \n13:08:15: ------------  \n13:08:55: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\mslug3\\\\07 First Contracts.mp3  \n13:08:55: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392  \n13:08:55: ------------  \n13:08:55: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\mslug3\\\\08 Escape.mp3  \n13:08:55: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392  \n13:08:55: ------------  \n13:09:53: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\vendetta\\\\12 Bay Area (Stage 4).mp3  \n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2  \n13:09:53: ------------  \n13:09:53: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\vendetta\\\\13 The Armageddon (Final Boss).mp3  \n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2  \n13:09:53: ------------\n\n So far, it appears to only be throwing errors with files in the MAME directory.  \n\n\nI navigated over to F:\\\\Games\\\\Arcade\\\\MAME 0.250 EXTRAs and tried to open covers\\_SL.zip with 7zip and it throws the same error. Weird. I'm not sure how these files became corrupted. So TeraCopy won't even copy them over if it's discovered the archives are corrupted? I guess that's fine since I don't have any use for corrupted files.  \n\n\nNow I just navigated to F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\3countb and 3countb.txt doesn't even exist (even if viewing hidden files)...what the hell? \n\n I also just navigated over to the directory for these errors:  \n\n\nF:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\vendetta\\\\12 Bay Area (Stage 4).mp3  \n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2  \n13:09:53: ------------  \n13:09:53: F:\\\\Games\\\\Arcade\\\\MAME 0.250 Multimedia\\\\soundtrack\\\\vendetta\\\\13 The Armageddon (Final Boss).mp3  \n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2  \n\n\nThose files are also missing from the directory...  \n\n\nBut tracks 1 through 11 and 14 on, are all there.  \n\n\nI don't get it. They \\*were\\* there until TeraCopy went to copy them and then they...disappeared? Teracopy...removed them? Either that, or Teracopy somehow knows they're supposed to be there and is expecting them, and they've always not been there. I'm assuming that's highly unlikely. \n\nSo...the files were there enough for Teracopy to see them and try to copy them, and then they immediately stopped existing, and then Teracopy logged the error in the...what?  \n\n\nThis is getting really strange now.", "author_fullname": "t2_96z9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Teracopy deleting my files during transfer? Something really strange is going on here...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1234afa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679874678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m transferring about 8tb from an internal 8tb SSD to a new QNAP NAS that&amp;#39;s running two 16tb HDD&amp;#39;s set up as a single RAID1 volume. &lt;/p&gt;\n\n&lt;p&gt;Over the course of the several days that the files have been copying, I&amp;#39;m getting some intermittent error messages regarding the transfer. Here&amp;#39;s a few examples: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;10:48:11: Created: 230324-144811-493-737.db&lt;br/&gt;\n10:48:58: Copying...&lt;br/&gt;\n10:48:58: Source: F:\\&lt;br/&gt;\n10:48:58: Target: \\\\NASStorage\\SSDDATA&lt;br/&gt;\n12:48:24: F:\\Games\\Arcade\\MAME 0.250 EXTRAs\\covers_SL.zip&lt;br/&gt;\n12:48:24: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392&lt;br/&gt;\n12:48:24: ------------&lt;br/&gt;\n12:48:56: F:\\Games\\Arcade\\MAME 0.250 EXTRAs\\devices.zip&lt;br/&gt;\n12:48:56: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392&lt;br/&gt;\n12:48:56: ------------&lt;br/&gt;\n13:06:23: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\3countb\\3countb.txt&lt;br/&gt;\n13:06:23: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392&lt;br/&gt;\n13:06:23: ------------&lt;br/&gt;\n13:08:15: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\iron\\01 Demo.mp3&lt;br/&gt;\n13:08:15: Error opening source file. The system cannot find the file specified. Code: 2&lt;br/&gt;\n13:08:15: ------------&lt;br/&gt;\n13:08:55: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\mslug3\\07 First Contracts.mp3&lt;br/&gt;\n13:08:55: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392&lt;br/&gt;\n13:08:55: ------------&lt;br/&gt;\n13:08:55: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\mslug3\\08 Escape.mp3&lt;br/&gt;\n13:08:55: Error opening source file. The file or directory is corrupted and unreadable. Code: 1392&lt;br/&gt;\n13:08:55: ------------&lt;br/&gt;\n13:09:53: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\vendetta\\12 Bay Area (Stage 4).mp3&lt;br/&gt;\n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2&lt;br/&gt;\n13:09:53: ------------&lt;br/&gt;\n13:09:53: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\vendetta\\13 The Armageddon (Final Boss).mp3&lt;br/&gt;\n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2&lt;br/&gt;\n13:09:53: ------------&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So far, it appears to only be throwing errors with files in the MAME directory.  &lt;/p&gt;\n\n&lt;p&gt;I navigated over to F:\\Games\\Arcade\\MAME 0.250 EXTRAs and tried to open covers_SL.zip with 7zip and it throws the same error. Weird. I&amp;#39;m not sure how these files became corrupted. So TeraCopy won&amp;#39;t even copy them over if it&amp;#39;s discovered the archives are corrupted? I guess that&amp;#39;s fine since I don&amp;#39;t have any use for corrupted files.  &lt;/p&gt;\n\n&lt;p&gt;Now I just navigated to F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\3countb and 3countb.txt doesn&amp;#39;t even exist (even if viewing hidden files)...what the hell? &lt;/p&gt;\n\n&lt;p&gt;I also just navigated over to the directory for these errors:  &lt;/p&gt;\n\n&lt;p&gt;F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\vendetta\\12 Bay Area (Stage 4).mp3&lt;br/&gt;\n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2&lt;br/&gt;\n13:09:53: ------------&lt;br/&gt;\n13:09:53: F:\\Games\\Arcade\\MAME 0.250 Multimedia\\soundtrack\\vendetta\\13 The Armageddon (Final Boss).mp3&lt;br/&gt;\n13:09:53: Error opening source file. The system cannot find the file specified. Code: 2  &lt;/p&gt;\n\n&lt;p&gt;Those files are also missing from the directory...  &lt;/p&gt;\n\n&lt;p&gt;But tracks 1 through 11 and 14 on, are all there.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t get it. They *were* there until TeraCopy went to copy them and then they...disappeared? Teracopy...removed them? Either that, or Teracopy somehow knows they&amp;#39;re supposed to be there and is expecting them, and they&amp;#39;ve always not been there. I&amp;#39;m assuming that&amp;#39;s highly unlikely. &lt;/p&gt;\n\n&lt;p&gt;So...the files were there enough for Teracopy to see them and try to copy them, and then they immediately stopped existing, and then Teracopy logged the error in the...what?  &lt;/p&gt;\n\n&lt;p&gt;This is getting really strange now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1234afa", "is_robot_indexable": true, "report_reasons": null, "author": "ultranothing", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1234afa/is_teracopy_deleting_my_files_during_transfer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1234afa/is_teracopy_deleting_my_files_during_transfer/", "subreddit_subscribers": 675546, "created_utc": 1679874678.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}