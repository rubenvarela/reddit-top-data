{"kind": "Listing", "data": {"after": "t3_123bh8x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Aspiring DE here, would love to get advice from seniors.\n\nI feel like I\u2019d love to become specialized in Azure platforms like Data Lake, Synapse Analytics, SSIS, Analysis Services.. etc but there\u2019s also a lot of demand for AWS and GCP out there. Would it be career smart to specialize in Azure and not learn much about the others? I don\u2019t wanna limit myself, but also I wanna become a sharp knife in an avenue.", "author_fullname": "t2_m9qt65bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it smart to specialize in a cloud environment or be diverse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1232nsl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679871015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Aspiring DE here, would love to get advice from seniors.&lt;/p&gt;\n\n&lt;p&gt;I feel like I\u2019d love to become specialized in Azure platforms like Data Lake, Synapse Analytics, SSIS, Analysis Services.. etc but there\u2019s also a lot of demand for AWS and GCP out there. Would it be career smart to specialize in Azure and not learn much about the others? I don\u2019t wanna limit myself, but also I wanna become a sharp knife in an avenue.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1232nsl", "is_robot_indexable": true, "report_reasons": null, "author": "beakyblindar", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1232nsl/is_it_smart_to_specialize_in_a_cloud_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1232nsl/is_it_smart_to_specialize_in_a_cloud_environment/", "subreddit_subscribers": 94574, "created_utc": 1679871015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&gt; It is simply a remnant of olden times, when it was used in contrast to batch processing. \"Online\" here means \"interactive\", that is, requests to the database are processed as they come and responses are given more or less immediately, or at least as soon as they are available. Batch processing would collect requests into, well, batches, and execute them on schedule; responses would be given after the entire batch execution (e.g. next morning).\n&gt;\n&gt;Abbreviations OLAP and OLTP hint at another historical artifact: [\"on-line\" used to be the more common spelling](https://english.stackexchange.com/questions/42044/which-is-correct-on-line-or-online) until mid-1980s.\n\nQuestion by user Zeruno answered by user mustaccio on StackExchange: https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp", "author_fullname": "t2_2yhiey78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exactly is the 'online' in OLAP and OLTP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123ie4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679911893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It is simply a remnant of olden times, when it was used in contrast to batch processing. &amp;quot;Online&amp;quot; here means &amp;quot;interactive&amp;quot;, that is, requests to the database are processed as they come and responses are given more or less immediately, or at least as soon as they are available. Batch processing would collect requests into, well, batches, and execute them on schedule; responses would be given after the entire batch execution (e.g. next morning).&lt;/p&gt;\n\n&lt;p&gt;Abbreviations OLAP and OLTP hint at another historical artifact: &lt;a href=\"https://english.stackexchange.com/questions/42044/which-is-correct-on-line-or-online\"&gt;&amp;quot;on-line&amp;quot; used to be the more common spelling&lt;/a&gt; until mid-1980s.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Question by user Zeruno answered by user mustaccio on StackExchange: &lt;a href=\"https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp\"&gt;https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?auto=webp&amp;v=enabled&amp;s=74121b8dbe2d32656e0828dd46b7915292ff355f", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6f8f5dd5b697e40a402a89c3a14d4e0c06cf737", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fbff4349eb0afb2c9e14bdf8d8fd62d5e1953fc3", "width": 216, "height": 216}], "variants": {}, "id": "soV_PhsRxi7AgK_X5wV0MsICON67aUdimkXPFGxvnRg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Architect / Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123ie4i", "is_robot_indexable": true, "report_reasons": null, "author": "sib_n", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/123ie4i/what_exactly_is_the_online_in_olap_and_oltp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123ie4i/what_exactly_is_the_online_in_olap_and_oltp/", "subreddit_subscribers": 94574, "created_utc": 1679911893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Preface this post with I graduate with me BS in May and I already have 2 years of help desk on my resume but I know I would love to break into data engineering at some point in my career so I\u2019m looking for some recommendations on learning material as it pertains to a general data engineering job so that I can better understand and already have experience with what is most likely to be expected in the day to day of a DE. I\u2019ve looked through the wiki and I\u2019m just wondering if there are items or methods not currently listed that most of you use.\n\nI know how to operate the basic kinds of programs and languages like SSMS, SSAS, Python, workbench, etc\u2026", "author_fullname": "t2_bygsfu8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for learning material?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122yg7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679862445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preface this post with I graduate with me BS in May and I already have 2 years of help desk on my resume but I know I would love to break into data engineering at some point in my career so I\u2019m looking for some recommendations on learning material as it pertains to a general data engineering job so that I can better understand and already have experience with what is most likely to be expected in the day to day of a DE. I\u2019ve looked through the wiki and I\u2019m just wondering if there are items or methods not currently listed that most of you use.&lt;/p&gt;\n\n&lt;p&gt;I know how to operate the basic kinds of programs and languages like SSMS, SSAS, Python, workbench, etc\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122yg7u", "is_robot_indexable": true, "report_reasons": null, "author": "AJohnM_IT", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122yg7u/recommendations_for_learning_material/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122yg7u/recommendations_for_learning_material/", "subreddit_subscribers": 94574, "created_utc": 1679862445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow vs Dagster - side by side comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_123d9st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-uBTubhIxv2SrqYtjAjOyGy9itDShCPfy9EhdbN5Y8I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679896868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decube.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decube.io/post/apache-airflow-vs-dagster-side-by-side-comparison", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?auto=webp&amp;v=enabled&amp;s=c5f35e689cc56793fcdee93ccbf45d6127a92486", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e015e48a5988af103a576e83103edb2df4ab6b56", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33c69037e3fb9b9cabcfedd695007b219d0d1770", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=466ae7a5652f7acc420034ed8dd1870be6a49634", "width": 320, "height": 168}], "variants": {}, "id": "_FuosWqJIC8e662XQzsbk2Y6-CMMfZ8p7TNNNHh6lPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "123d9st", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123d9st/apache_airflow_vs_dagster_side_by_side_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decube.io/post/apache-airflow-vs-dagster-side-by-side-comparison", "subreddit_subscribers": 94574, "created_utc": 1679896868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to start working on a project where a good most of it will be messy JSON files (100TB), very small CSV files (lets say around a few MBs), and possibly some data coming from a REST API. The data is at rest, and not streaming. I don't quite have a concrete idea yet of what the data looks like (much of it is very large heavily nested JSON files) or how it will be \"delivered\" but most likely it will be a DW with some kind of dash boarding layer on top of it (Tableau, Looker, etc). \n\nRight now it is in kind of in a \"exploratory\" phase, as I don't know how valuable or useable the data will be and I'm new to some of the technologies (parquet, spark, etc). As such minimizing cost is important and there are two big problems which I will have to deal with and one smaller one:\n\n1) backup storage costs: putting all 100TB+ of raw, COMPRESSED JSON data in S3 is ~$2.4k/mo or GCP standard is $2.1k\nI could cut this in half by using \"hot\" and \"cold\": S3 + Glacier or a combo of GCP std and nearline \n\nOR\n\nI could write a script to download each file, preprocess and convert each to parquet before backing up, but the files often have some additional data which is metadata about the file and some which doesn't fit the same schema as the rest (how can I keep that data grouped with parquet files without throwing it away?). Estimate this would shrink data 10x. Is this common practice though?\n\n\n2) using a single platform like Databricks' Lakehouse or Snowflake vs S3/EMR/Redshift\nI have biases toward AWS simply because I am most familiar with it. I've never used the rest. My gut says AWS will be more expensive, because I won't be separating storage and compute.\n\n\n3) lastly, creating a Postgres DB as an intermediary between raw data and DW, with all the duplicate and erroneous data\n\nWould I benefit from doing such? Since the 100TB of data is split amongst various entities with their own batch of files, I am considering it and would also likely help me in case a ETL job fails for any of the entities. \n\nAlso it means I could skip \u201cingestion\u201d entirely and use this database of preprocessed data as my backup, keeping snapshots of the DB as well. Also would not have to read data for each entity in its entirety and thus read significantly less data in memory. I could take each file, DL it, process it a little bit, dump it in a DB, rinse and repeat. Essentially meaning I don\u2019t have to keep any pure raw data.", "author_fullname": "t2_e0uj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Cloud Architecture for processing and analyzing 100TB+ of semistructured data? AWS Stack (S3/EMR/Redshift) vs Snowflake vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12345rl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679885009.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679874378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to start working on a project where a good most of it will be messy JSON files (100TB), very small CSV files (lets say around a few MBs), and possibly some data coming from a REST API. The data is at rest, and not streaming. I don&amp;#39;t quite have a concrete idea yet of what the data looks like (much of it is very large heavily nested JSON files) or how it will be &amp;quot;delivered&amp;quot; but most likely it will be a DW with some kind of dash boarding layer on top of it (Tableau, Looker, etc). &lt;/p&gt;\n\n&lt;p&gt;Right now it is in kind of in a &amp;quot;exploratory&amp;quot; phase, as I don&amp;#39;t know how valuable or useable the data will be and I&amp;#39;m new to some of the technologies (parquet, spark, etc). As such minimizing cost is important and there are two big problems which I will have to deal with and one smaller one:&lt;/p&gt;\n\n&lt;p&gt;1) backup storage costs: putting all 100TB+ of raw, COMPRESSED JSON data in S3 is ~$2.4k/mo or GCP standard is $2.1k\nI could cut this in half by using &amp;quot;hot&amp;quot; and &amp;quot;cold&amp;quot;: S3 + Glacier or a combo of GCP std and nearline &lt;/p&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;p&gt;I could write a script to download each file, preprocess and convert each to parquet before backing up, but the files often have some additional data which is metadata about the file and some which doesn&amp;#39;t fit the same schema as the rest (how can I keep that data grouped with parquet files without throwing it away?). Estimate this would shrink data 10x. Is this common practice though?&lt;/p&gt;\n\n&lt;p&gt;2) using a single platform like Databricks&amp;#39; Lakehouse or Snowflake vs S3/EMR/Redshift\nI have biases toward AWS simply because I am most familiar with it. I&amp;#39;ve never used the rest. My gut says AWS will be more expensive, because I won&amp;#39;t be separating storage and compute.&lt;/p&gt;\n\n&lt;p&gt;3) lastly, creating a Postgres DB as an intermediary between raw data and DW, with all the duplicate and erroneous data&lt;/p&gt;\n\n&lt;p&gt;Would I benefit from doing such? Since the 100TB of data is split amongst various entities with their own batch of files, I am considering it and would also likely help me in case a ETL job fails for any of the entities. &lt;/p&gt;\n\n&lt;p&gt;Also it means I could skip \u201cingestion\u201d entirely and use this database of preprocessed data as my backup, keeping snapshots of the DB as well. Also would not have to read data for each entity in its entirety and thus read significantly less data in memory. I could take each file, DL it, process it a little bit, dump it in a DB, rinse and repeat. Essentially meaning I don\u2019t have to keep any pure raw data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "12345rl", "is_robot_indexable": true, "report_reasons": null, "author": "sinuspane", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12345rl/best_cloud_architecture_for_processing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12345rl/best_cloud_architecture_for_processing_and/", "subreddit_subscribers": 94574, "created_utc": 1679874378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently been reading the \"Data Mesh\" book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.\n\nThe author discusses the idea of \u201cdata as an asset\u201d and how it has dominated our big data management approach. The point the author makes is that \u201cdata as an asset\u201d mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.\n\nSince I don't have first-hand experience about it, I wanted to ask about the metrics currently being used to measure 'success of data. I know that hoarding data for the sake of it is an existing problem, but I'm hoping there are other measurement systems put in place\n\nThis is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.\n\n**TLDR**: *How do you measure the quality/success of your data independent from the value extraction process?*", "author_fullname": "t2_vbmhoyul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the value of data apart from the process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123mypf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679924461.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679923758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently been reading the &amp;quot;Data Mesh&amp;quot; book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.&lt;/p&gt;\n\n&lt;p&gt;The author discusses the idea of \u201cdata as an asset\u201d and how it has dominated our big data management approach. The point the author makes is that \u201cdata as an asset\u201d mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.&lt;/p&gt;\n\n&lt;p&gt;Since I don&amp;#39;t have first-hand experience about it, I wanted to ask about the metrics currently being used to measure &amp;#39;success of data. I know that hoarding data for the sake of it is an existing problem, but I&amp;#39;m hoping there are other measurement systems put in place&lt;/p&gt;\n\n&lt;p&gt;This is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: &lt;em&gt;How do you measure the quality/success of your data independent from the value extraction process?&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123mypf", "is_robot_indexable": true, "report_reasons": null, "author": "Immediate-Mud-2996", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123mypf/how_to_measure_the_value_of_data_apart_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123mypf/how_to_measure_the_value_of_data_apart_from_the/", "subreddit_subscribers": 94574, "created_utc": 1679923758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm interested to hear what other people's first DE role entailed. I've been in my first DE role for over 2 months and I'm having some doubts about it. I came from an analyst job where I was an important member of the team and I knew I made a difference, to a DE team where I feel like I haven't progressed at all in.\n\nIn my time as a DE all I've really done is learn and try to pass certificates, which is good for my CV, but it hasn't made me any more knowledgeable about the job I'm doing. In the few non-certificate tasks I've been doing (pipelines, data processing in notebooks etc) I've not really had the support or training to complete the tasks and I get blocked/stuck very easily, which makes me feel very stupid. It often takes my manager a day to get round to helping me too, which leads me to looking back at the certificates.\n\nI just want to know if this is normal or not when you are starting out? Should I give it time? Are there DE jobs out there where you get hands on training by a colleague which takes precedence over doing certificates?\n\nThanks!", "author_fullname": "t2_igpqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your first experience as a DE like? few concerns about mine..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123l9ua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679919356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested to hear what other people&amp;#39;s first DE role entailed. I&amp;#39;ve been in my first DE role for over 2 months and I&amp;#39;m having some doubts about it. I came from an analyst job where I was an important member of the team and I knew I made a difference, to a DE team where I feel like I haven&amp;#39;t progressed at all in.&lt;/p&gt;\n\n&lt;p&gt;In my time as a DE all I&amp;#39;ve really done is learn and try to pass certificates, which is good for my CV, but it hasn&amp;#39;t made me any more knowledgeable about the job I&amp;#39;m doing. In the few non-certificate tasks I&amp;#39;ve been doing (pipelines, data processing in notebooks etc) I&amp;#39;ve not really had the support or training to complete the tasks and I get blocked/stuck very easily, which makes me feel very stupid. It often takes my manager a day to get round to helping me too, which leads me to looking back at the certificates.&lt;/p&gt;\n\n&lt;p&gt;I just want to know if this is normal or not when you are starting out? Should I give it time? Are there DE jobs out there where you get hands on training by a colleague which takes precedence over doing certificates?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123l9ua", "is_robot_indexable": true, "report_reasons": null, "author": "fastidiousthoughts", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123l9ua/what_was_your_first_experience_as_a_de_like_few/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123l9ua/what_was_your_first_experience_as_a_de_like_few/", "subreddit_subscribers": 94574, "created_utc": 1679919356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello together,\n\nMy job is about automating data processing for subsequent data science purposes. I'm curious to exchange knowledge with you and learn from each other!\n\nSo, I'm curious to learn what data processing techniques you use in your job? What data pipeline tools do you use/ dont use? What are the biggest challenges you face? \n\nThank you for your contributions!", "author_fullname": "t2_7yyt4sc3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does data processing look like at our work? Let's learn from each other!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123gnes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679906469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello together,&lt;/p&gt;\n\n&lt;p&gt;My job is about automating data processing for subsequent data science purposes. I&amp;#39;m curious to exchange knowledge with you and learn from each other!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m curious to learn what data processing techniques you use in your job? What data pipeline tools do you use/ dont use? What are the biggest challenges you face? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your contributions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123gnes", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzled-Lime141", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123gnes/how_does_data_processing_look_like_at_our_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123gnes/how_does_data_processing_look_like_at_our_work/", "subreddit_subscribers": 94574, "created_utc": 1679906469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My role was originally an Administrator but progressed to me turning a huge spreadsheet into multiple pages of easy to read tables that collected all of the data.\n\nFor example, some tables would count up how many Doctors reviewed and and approved job descriptions, and could be sorted and filtered by date, region, hospital etc. This was for a seperate data analysis team.\n\nUsually Data Analysis involved actually coming to conclusions from data, and Data Engineering seems to involve actual SQL databses and Python. All of my work was Excel only though the whole project was very long and complex.\n\nObviously I dont want to mislead employers, but at the same time I feel like I was doing more than just Data Entry in Excel and want to show it off. Is there a title for this or do I just have to stick with including it as the description (bullet points)?", "author_fullname": "t2_oek7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call someone who compiles raw data into organised tables in Excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12389wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679883925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My role was originally an Administrator but progressed to me turning a huge spreadsheet into multiple pages of easy to read tables that collected all of the data.&lt;/p&gt;\n\n&lt;p&gt;For example, some tables would count up how many Doctors reviewed and and approved job descriptions, and could be sorted and filtered by date, region, hospital etc. This was for a seperate data analysis team.&lt;/p&gt;\n\n&lt;p&gt;Usually Data Analysis involved actually coming to conclusions from data, and Data Engineering seems to involve actual SQL databses and Python. All of my work was Excel only though the whole project was very long and complex.&lt;/p&gt;\n\n&lt;p&gt;Obviously I dont want to mislead employers, but at the same time I feel like I was doing more than just Data Entry in Excel and want to show it off. Is there a title for this or do I just have to stick with including it as the description (bullet points)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12389wf", "is_robot_indexable": true, "report_reasons": null, "author": "Christian159260", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12389wf/what_do_you_call_someone_who_compiles_raw_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12389wf/what_do_you_call_someone_who_compiles_raw_data/", "subreddit_subscribers": 94574, "created_utc": 1679883925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a new initiative, and I need a data visualization tool that can be syndicated out to internal teams as well as external 3rd parties (business partners) to share common dashboards.\n\nI have not used Looker in a loooooong time (Pre-Google acquisition), so I am taking a fresh look at the new [https://datastudio.withgoogle.com/](https://datastudio.withgoogle.com/) thingy.  \nAre people using it in this kind of set-up? \n\nIt would be a high latency (\\~ twice daily refresh) setup with just a handful of KPIs on the dash.", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happened to Looker/Google Data Studio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123tojm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679937452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a new initiative, and I need a data visualization tool that can be syndicated out to internal teams as well as external 3rd parties (business partners) to share common dashboards.&lt;/p&gt;\n\n&lt;p&gt;I have not used Looker in a loooooong time (Pre-Google acquisition), so I am taking a fresh look at the new &lt;a href=\"https://datastudio.withgoogle.com/\"&gt;https://datastudio.withgoogle.com/&lt;/a&gt; thingy.&lt;br/&gt;\nAre people using it in this kind of set-up? &lt;/p&gt;\n\n&lt;p&gt;It would be a high latency (~ twice daily refresh) setup with just a handful of KPIs on the dash.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123tojm", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123tojm/what_happened_to_lookergoogle_data_studio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123tojm/what_happened_to_lookergoogle_data_studio/", "subreddit_subscribers": 94574, "created_utc": 1679937452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many layers should there be in a typical data warehouse? I know my question is broad and not specific. For instance, at the company I am currently working at, we have three layers, the first one being the raw layer which we call acquisition, the second one being the conformed layer where we create normalized tables like Inmon suggests, and finally the third layer which we call Semantic which is basically fact and dimensions modelled in a Kimball way. I am curious to see if there is any literature on this topic and how one should go about architecting a data warehouse?", "author_fullname": "t2_7gmjdawc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehouse architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123hsbw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679910114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many layers should there be in a typical data warehouse? I know my question is broad and not specific. For instance, at the company I am currently working at, we have three layers, the first one being the raw layer which we call acquisition, the second one being the conformed layer where we create normalized tables like Inmon suggests, and finally the third layer which we call Semantic which is basically fact and dimensions modelled in a Kimball way. I am curious to see if there is any literature on this topic and how one should go about architecting a data warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123hsbw", "is_robot_indexable": true, "report_reasons": null, "author": "afnan_shahid1992", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123hsbw/data_warehouse_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123hsbw/data_warehouse_architecture/", "subreddit_subscribers": 94574, "created_utc": 1679910114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've recently built a POC for Synapse Dedicated Pool, I used Synapse Pipelines to pull data from on premise, landed it in to the Data Lake and then in to an import table in a Dedicated Pool, then ran transformations with SPROC's (every 15 minutes)\n\nI landed the data in the data lake for two reasons:\n\n1) Polybase load in to Dedicated Pool\n2) To have a year/month/day/.. record of data loaded\n\nFor my main fact I have to join around 10-12 tables together, any of which could change, ranging from an order date of today back to 2008, so I couldn't see any way around having staging tables (other than using Spark &amp; Delta Lake, but I didn't want to spend even more on compute!)\n\nForgetting Dedicated Pool for a minute, the Synapse Pipelines alone for 50 or so tables is too expensive (running every 15 minutes)\n\nMy questions are:\n\n1) Does this architecture make sense?\n2) Is the cloud just expensive?  Or am I missing something?\n\nAny help or advice would be appreciated as I'm pulling my hair out with all the different options out there!\n\nFor context we're probably generating around 15GB of data a day, our key tables are a couple of hundred million rows.  We want to incrementally refresh every 15 minutes.", "author_fullname": "t2_9h6gf9pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Stack Help/Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123tztx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679938095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently built a POC for Synapse Dedicated Pool, I used Synapse Pipelines to pull data from on premise, landed it in to the Data Lake and then in to an import table in a Dedicated Pool, then ran transformations with SPROC&amp;#39;s (every 15 minutes)&lt;/p&gt;\n\n&lt;p&gt;I landed the data in the data lake for two reasons:&lt;/p&gt;\n\n&lt;p&gt;1) Polybase load in to Dedicated Pool\n2) To have a year/month/day/.. record of data loaded&lt;/p&gt;\n\n&lt;p&gt;For my main fact I have to join around 10-12 tables together, any of which could change, ranging from an order date of today back to 2008, so I couldn&amp;#39;t see any way around having staging tables (other than using Spark &amp;amp; Delta Lake, but I didn&amp;#39;t want to spend even more on compute!)&lt;/p&gt;\n\n&lt;p&gt;Forgetting Dedicated Pool for a minute, the Synapse Pipelines alone for 50 or so tables is too expensive (running every 15 minutes)&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;p&gt;1) Does this architecture make sense?\n2) Is the cloud just expensive?  Or am I missing something?&lt;/p&gt;\n\n&lt;p&gt;Any help or advice would be appreciated as I&amp;#39;m pulling my hair out with all the different options out there!&lt;/p&gt;\n\n&lt;p&gt;For context we&amp;#39;re probably generating around 15GB of data a day, our key tables are a couple of hundred million rows.  We want to incrementally refresh every 15 minutes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123tztx", "is_robot_indexable": true, "report_reasons": null, "author": "V10Matt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123tztx/modern_stack_helpadvice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123tztx/modern_stack_helpadvice/", "subreddit_subscribers": 94574, "created_utc": 1679938095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like some advice from this sub on this.\n\nAt my place of work, a datawarehouse was developed using the DV 2.0 architecture but never put in production because client changed direction and bunch of other stuff happened. But a bunch of money was spent doing this.\n\nI now have the opportunity to re-do this venture and I am stuck with the dilemma of re-using the work that was done or starting scratch with a traditional EDW using Dimension modeling / Star Schema etc.. you get the picture.\n\nI am familiar with the traditional method and not averse to learning new tricks (DV 2.0). DV 2.0 looks like a lot of work with its hubs-&gt;links-&gt;satellite rigidity and the benefits don't seem like its worth the squeeze. I don't have the luxury to experiment for too long either.\n\nI'd like some sensible independent opinions on this matter please. I hate the idea of throwing away all that work but also don't want to dive head first into somewhat of an unknown.", "author_fullname": "t2_7vr2noa4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault or Traditional?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122wyyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679859508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like some advice from this sub on this.&lt;/p&gt;\n\n&lt;p&gt;At my place of work, a datawarehouse was developed using the DV 2.0 architecture but never put in production because client changed direction and bunch of other stuff happened. But a bunch of money was spent doing this.&lt;/p&gt;\n\n&lt;p&gt;I now have the opportunity to re-do this venture and I am stuck with the dilemma of re-using the work that was done or starting scratch with a traditional EDW using Dimension modeling / Star Schema etc.. you get the picture.&lt;/p&gt;\n\n&lt;p&gt;I am familiar with the traditional method and not averse to learning new tricks (DV 2.0). DV 2.0 looks like a lot of work with its hubs-&amp;gt;links-&amp;gt;satellite rigidity and the benefits don&amp;#39;t seem like its worth the squeeze. I don&amp;#39;t have the luxury to experiment for too long either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like some sensible independent opinions on this matter please. I hate the idea of throwing away all that work but also don&amp;#39;t want to dive head first into somewhat of an unknown.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "122wyyr", "is_robot_indexable": true, "report_reasons": null, "author": "papa-yaaga", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122wyyr/data_vault_or_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122wyyr/data_vault_or_traditional/", "subreddit_subscribers": 94574, "created_utc": 1679859508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, for example, you have dimensional models and so on, but you also have pdfs, images etc.\n\nHow would you go about it? \n\nI cannot find any good articles/resources on this.\n\nFrom the very few resources I've found, it appears that you can either:\n\n* have a table e.g. customer, which also has column(s) containing pointers to a separate  path of the delta lake containing some kind of file (e.g. image)\n* turn the image to binary file, and create a table with it, containing as columns metadata, like user\\_id, file\\_format (and anything else you want) and save it as table with saveAsTable. The only drawback here is the input/output bottleneck since this would include moving huge amounts of data back and forth.\n\n&amp;#x200B;\n\nIf you go with the first approach, you practically dump whatever unstructured data you have, in a location inside delta lake. But what best practices would you want to keep in mind? Would just dumping files at department/project/item/date be ok? \n\nI understand that this would get hectic really really fast.  Any documentation/article etc would be greatly appreciated.\n\n&amp;#x200B;\n\nThanks in advance.", "author_fullname": "t2_3cuv2cgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model Structured and Unstructured Data together in Delta Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123ieya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679911960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, for example, you have dimensional models and so on, but you also have pdfs, images etc.&lt;/p&gt;\n\n&lt;p&gt;How would you go about it? &lt;/p&gt;\n\n&lt;p&gt;I cannot find any good articles/resources on this.&lt;/p&gt;\n\n&lt;p&gt;From the very few resources I&amp;#39;ve found, it appears that you can either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;have a table e.g. customer, which also has column(s) containing pointers to a separate  path of the delta lake containing some kind of file (e.g. image)&lt;/li&gt;\n&lt;li&gt;turn the image to binary file, and create a table with it, containing as columns metadata, like user_id, file_format (and anything else you want) and save it as table with saveAsTable. The only drawback here is the input/output bottleneck since this would include moving huge amounts of data back and forth.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you go with the first approach, you practically dump whatever unstructured data you have, in a location inside delta lake. But what best practices would you want to keep in mind? Would just dumping files at department/project/item/date be ok? &lt;/p&gt;\n\n&lt;p&gt;I understand that this would get hectic really really fast.  Any documentation/article etc would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123ieya", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent-Style6371", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123ieya/model_structured_and_unstructured_data_together/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123ieya/model_structured_and_unstructured_data_together/", "subreddit_subscribers": 94574, "created_utc": 1679911960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Databricks first bring out this concept. However, I think they described a big dream but hasn't made it come true. The performance of querying data in a data lake still cannot be compared with querying data in a data warehouse. Are you using data lakes now? Do you think Lakehouse can be a promising direction?", "author_fullname": "t2_7opejf1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think about the Lakehouse concept?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123h5li", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679908068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Databricks first bring out this concept. However, I think they described a big dream but hasn&amp;#39;t made it come true. The performance of querying data in a data lake still cannot be compared with querying data in a data warehouse. Are you using data lakes now? Do you think Lakehouse can be a promising direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123h5li", "is_robot_indexable": true, "report_reasons": null, "author": "creatstar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123h5li/what_do_you_think_about_the_lakehouse_concept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123h5li/what_do_you_think_about_the_lakehouse_concept/", "subreddit_subscribers": 94574, "created_utc": 1679908068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys\u2026 first time here.\nI don\u2019t know if we had this kind of discussion before, but I would like some guidance here\n\nI have a long experience with Analytics and Data transformation\u2026 but never had a DE job.\nMy last job was as Analytics Engineer and my scope was the same as DE. Now I am a digital transformation coordinator and totally frustrated. \nThey sold me an opportunity of create a data lake from zero, create and architecture and train data analysts\u2026 I ended creating power points and using excel to create data flows. \n\nBut since I have zero experience as data engineer, it is quite complicated to land a job. I know how make API requests, create an ingestion flow\u2026 but I am no software engineer. \nI don\u2019t have knowledge in Kubernetes, Helm, NOSQL,and DevOps. I only know Python, Spark, SQL, AWS S3, RDS, EMR\u2026 and a little bit of Flink and Kafka. \nMy degree was in Materials Engineering but I shifted my area to BI/DA 6 years ago. Dataviz, Modeling, Analytics.. I can handle easily.\n\nI am no junior\u2026 but I believe I am no senior. My job is frustrating and these layoffs worsen my mental health, in terms of find a new opportunity.\n\nWhat should I do to go back to what I really love, that is Data Engineering.\n\nThanks in advance, I feel lighter talking about it here.", "author_fullname": "t2_b614u9x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to place myself in DE career ladder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_123w6io", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679942571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys\u2026 first time here.\nI don\u2019t know if we had this kind of discussion before, but I would like some guidance here&lt;/p&gt;\n\n&lt;p&gt;I have a long experience with Analytics and Data transformation\u2026 but never had a DE job.\nMy last job was as Analytics Engineer and my scope was the same as DE. Now I am a digital transformation coordinator and totally frustrated. \nThey sold me an opportunity of create a data lake from zero, create and architecture and train data analysts\u2026 I ended creating power points and using excel to create data flows. &lt;/p&gt;\n\n&lt;p&gt;But since I have zero experience as data engineer, it is quite complicated to land a job. I know how make API requests, create an ingestion flow\u2026 but I am no software engineer. \nI don\u2019t have knowledge in Kubernetes, Helm, NOSQL,and DevOps. I only know Python, Spark, SQL, AWS S3, RDS, EMR\u2026 and a little bit of Flink and Kafka. \nMy degree was in Materials Engineering but I shifted my area to BI/DA 6 years ago. Dataviz, Modeling, Analytics.. I can handle easily.&lt;/p&gt;\n\n&lt;p&gt;I am no junior\u2026 but I believe I am no senior. My job is frustrating and these layoffs worsen my mental health, in terms of find a new opportunity.&lt;/p&gt;\n\n&lt;p&gt;What should I do to go back to what I really love, that is Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, I feel lighter talking about it here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "123w6io", "is_robot_indexable": true, "report_reasons": null, "author": "EmployeeNo7189", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123w6io/how_to_place_myself_in_de_career_ladder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123w6io/how_to_place_myself_in_de_career_ladder/", "subreddit_subscribers": 94574, "created_utc": 1679942571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_20a1cwjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting Data from Wikidata Using SPARQL and Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_123vw7d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b9i_Vv35fsfz7a5uQgZekF1l8Pd2gbSchgq7_NgN2M8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679941992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jelle.vankerkvoorde/extracting-data-from-wikidata-using-sparql-and-python-59e0037996f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?auto=webp&amp;v=enabled&amp;s=694ec3da828a3bbbc14a0f430f98694efd741d66", "width": 960, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c30b51cf895b75d2ca0924e5012462104163f3f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=200ed081790522c6a86dbcef8aec6f091d784813", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e4ef087c1aaffea665b395faecd5a12f7275dce", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6960866b9cfe547403cdd4112a5790001ca4641e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f454652383797a23f4cc9493376712b9da85d6f0", "width": 960, "height": 540}], "variants": {}, "id": "1tu1M-UZ6LVJB9xkVokCrmIdNeD935qI6tYyQkiRgRw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "123vw7d", "is_robot_indexable": true, "report_reasons": null, "author": "jkspiderdog", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123vw7d/extracting_data_from_wikidata_using_sparql_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jelle.vankerkvoorde/extracting-data-from-wikidata-using-sparql-and-python-59e0037996f", "subreddit_subscribers": 94574, "created_utc": 1679941992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I made it to the second round for a data engineering interview. Contrary to the first interview being a 1 hour video call, the 2nd interview is a 1 hour in-person interview. It's a remote job, so they are aware I am a 2.5 hour train trip away from the offices where the interview will be held. \n\nI've asked what format the interview will take and the answer was vague: \"they just want to ask more technical questions to gauge your experience and how they can support you in the role\".\n\nI like to prepare, and I like to prepare well. So my question to this sub-reddit is: what could they possibly want from me in-person that requires a 5 hour round trip commute that they cannot get in a video call?\n\nAre you thinking tests and live coding?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens at an in-person 2nd round interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_123vraz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679941725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made it to the second round for a data engineering interview. Contrary to the first interview being a 1 hour video call, the 2nd interview is a 1 hour in-person interview. It&amp;#39;s a remote job, so they are aware I am a 2.5 hour train trip away from the offices where the interview will be held. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve asked what format the interview will take and the answer was vague: &amp;quot;they just want to ask more technical questions to gauge your experience and how they can support you in the role&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I like to prepare, and I like to prepare well. So my question to this sub-reddit is: what could they possibly want from me in-person that requires a 5 hour round trip commute that they cannot get in a video call?&lt;/p&gt;\n\n&lt;p&gt;Are you thinking tests and live coding?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "123vraz", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123vraz/what_happens_at_an_inperson_2nd_round_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123vraz/what_happens_at_an_inperson_2nd_round_interview/", "subreddit_subscribers": 94574, "created_utc": 1679941725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nWant to know, What strategy you apply to find root cause of duplicates in your final datsset (Hive table).\n\nIf a Spark job consume data from multiple Hive tables daily and perform operations like filter, join, aggregation on it in a quite a complex way,  How you will check at which step the duplicates are creeping in your data? \n\nThis happens once or twice in a month but I am finding it hard and time consuming to find out the root cause of duplicates. The job run time is in hours and running and  checking every step of the job in a  spark-shell is time consuming.\n\nSo want to know what you guys do when you face such a problem?", "author_fullname": "t2_gzyg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Duplicate Record Issue - Finding root cause", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123teoq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679936900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Want to know, What strategy you apply to find root cause of duplicates in your final datsset (Hive table).&lt;/p&gt;\n\n&lt;p&gt;If a Spark job consume data from multiple Hive tables daily and perform operations like filter, join, aggregation on it in a quite a complex way,  How you will check at which step the duplicates are creeping in your data? &lt;/p&gt;\n\n&lt;p&gt;This happens once or twice in a month but I am finding it hard and time consuming to find out the root cause of duplicates. The job run time is in hours and running and  checking every step of the job in a  spark-shell is time consuming.&lt;/p&gt;\n\n&lt;p&gt;So want to know what you guys do when you face such a problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123teoq", "is_robot_indexable": true, "report_reasons": null, "author": "ps2931", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123teoq/duplicate_record_issue_finding_root_cause/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123teoq/duplicate_record_issue_finding_root_cause/", "subreddit_subscribers": 94574, "created_utc": 1679936900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, r/dataengineering! I\u2019m conducting a short [survey](https://www.abegong.com/surveys/data-storytelling) of data practitioners, and challenges we face around analytics and storytelling. The survey focuses on three things:\n\n1. How data practitioners spend time\n2. How they think about storytelling as part of their role\n3. How responsive organizations react to data and stories\n\nOnce I've got enough responses, I'll share results.  \n\n\nYou can fill out the survey here: [https://www.abegong.com/surveys/data-storytelling](https://www.abegong.com/surveys/data-storytelling)  \n\n\nReposts and signal boosting would be very welcome! I'm also open to feedback on the survey itself.", "author_fullname": "t2_3yoo0aat", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey about storytelling with data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123ou12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679928021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I\u2019m conducting a short &lt;a href=\"https://www.abegong.com/surveys/data-storytelling\"&gt;survey&lt;/a&gt; of data practitioners, and challenges we face around analytics and storytelling. The survey focuses on three things:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How data practitioners spend time&lt;/li&gt;\n&lt;li&gt;How they think about storytelling as part of their role&lt;/li&gt;\n&lt;li&gt;How responsive organizations react to data and stories&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Once I&amp;#39;ve got enough responses, I&amp;#39;ll share results.  &lt;/p&gt;\n\n&lt;p&gt;You can fill out the survey here: &lt;a href=\"https://www.abegong.com/surveys/data-storytelling\"&gt;https://www.abegong.com/surveys/data-storytelling&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Reposts and signal boosting would be very welcome! I&amp;#39;m also open to feedback on the survey itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123ou12", "is_robot_indexable": true, "report_reasons": null, "author": "abegong", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123ou12/survey_about_storytelling_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123ou12/survey_about_storytelling_with_data/", "subreddit_subscribers": 94574, "created_utc": 1679928021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DSA For The Rest Of Us - Part 2 Introduction to Binary Search with Rust.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_123oh8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/S7UlphpRUMHrVNJDrAI4tyLrrmtDabHr5bZTNY0Gnvc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679927284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/dsa-for-the-rest-of-us-part-2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e6WBLD3hcFSbmqyhv9NWHC0utX2bCV0SVmUGue922mo.jpg?auto=webp&amp;v=enabled&amp;s=4a731b0aa2233d786c9dc5e42f70e1a9f1efe0b9", "width": 900, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/e6WBLD3hcFSbmqyhv9NWHC0utX2bCV0SVmUGue922mo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf90517b4facab6f9c3f0c03a65d84814ee4138c", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/e6WBLD3hcFSbmqyhv9NWHC0utX2bCV0SVmUGue922mo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49c29a1ae82bc1511dd75da22ad8b206ea4d1985", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/e6WBLD3hcFSbmqyhv9NWHC0utX2bCV0SVmUGue922mo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9c3aa1d9652d2eb83dbcf2bedd275199c9bd94d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/e6WBLD3hcFSbmqyhv9NWHC0utX2bCV0SVmUGue922mo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84949c4ec4f383952ccca85b8c2bd39479912143", "width": 640, "height": 426}], "variants": {}, "id": "IZbkcYLfUauMmdrPVo8ymcrXWL6KIP1X40EgzaB8qZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "123oh8h", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123oh8h/dsa_for_the_rest_of_us_part_2_introduction_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/dsa-for-the-rest-of-us-part-2", "subreddit_subscribers": 94574, "created_utc": 1679927284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nDoes anyone know if it's possible to validate if only the values of df1.column1 are in df2.column1 using the dataframe model approach? \nSimilarly to the already supported check of isin=[List] but instead of hardcoding the values, they'd be coming from another dataframe.", "author_fullname": "t2_69qy80ee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandera data quality validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123kieg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679917215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nDoes anyone know if it&amp;#39;s possible to validate if only the values of df1.column1 are in df2.column1 using the dataframe model approach? \nSimilarly to the already supported check of isin=[List] but instead of hardcoding the values, they&amp;#39;d be coming from another dataframe.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123kieg", "is_robot_indexable": true, "report_reasons": null, "author": "Shiwatari", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123kieg/pandera_data_quality_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123kieg/pandera_data_quality_validation/", "subreddit_subscribers": 94574, "created_utc": 1679917215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently been reading the \"Data Mesh\" book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.\n\nThe author discusses the idea of 'data as an asset' and how it has dominated our big data management approach. The point the author makes is that 'data as an asset' mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.\n\nSince I don't have first-hand experience about it, I wanted to ask about the metrics currently being used to measure 'success of data'. I know that hoarding data for the sake of it is an existing problem, but I'm hoping there are other measurement systems put in place.\n\nThis is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.\n\nI'd love to hear your thoughts and experience on this issue.  \n\n\n**TL,DR**: *How do you measure the quality/success of your data independent from the value extraction process?*", "author_fullname": "t2_vdotraaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the value of data apart from the process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123fhrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679902856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently been reading the &amp;quot;Data Mesh&amp;quot; book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.&lt;/p&gt;\n\n&lt;p&gt;The author discusses the idea of &amp;#39;data as an asset&amp;#39; and how it has dominated our big data management approach. The point the author makes is that &amp;#39;data as an asset&amp;#39; mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.&lt;/p&gt;\n\n&lt;p&gt;Since I don&amp;#39;t have first-hand experience about it, I wanted to ask about the metrics currently being used to measure &amp;#39;success of data&amp;#39;. I know that hoarding data for the sake of it is an existing problem, but I&amp;#39;m hoping there are other measurement systems put in place.&lt;/p&gt;\n\n&lt;p&gt;This is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts and experience on this issue.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL,DR&lt;/strong&gt;: &lt;em&gt;How do you measure the quality/success of your data independent from the value extraction process?&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123fhrx", "is_robot_indexable": true, "report_reasons": null, "author": "data_dynamo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123fhrx/how_to_measure_the_value_of_data_apart_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123fhrx/how_to_measure_the_value_of_data_apart_from_the/", "subreddit_subscribers": 94574, "created_utc": 1679902856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Where did you pick up data engineering? Taught on the job? Learned in school?\n\nI am a data science major who's intrigued on picking up a little data engineering skills, but am very intimidated after I overestimated the overlap DE had with DS. I was hoping if there's any people here who started from a DS/DA/ML background first, and if there's any advice about how they transferred over.\n\nSo to preface, my major doesn't touch enough on DE. We only had 1 class about it, where we \\*conceptually\\* learned things like AWS, learned about parquet, and pyspark, but there was no hands-on assignment at all.\n\nIn my business analyst internship, I'd entirely read from csv's onto pandas. The data came from Snowflake, which I would then query it down with SQL until I got the data I needed, and either A), download the resulting csv, to read with pandas and do sklearn pipelines on (I had never bothered to learn how to connect snowflake directly to the python, assuming I would have even been permitted to do that), or B) query it down with SQL and link it to tableau to make pretty maps.\n\nAll these terms like dbt, jinja, OLAP, or apache airflow is very new to me, so I am a bit worried that neither my school nor work experience prepared me enough. What should I do next? Learn on my own and create  my own projects? Is that acceptable on a resume? I'm also worried, won't such a project cost alot given AWS and well you know?", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where did you pick up data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123cy7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679896661.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679895909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where did you pick up data engineering? Taught on the job? Learned in school?&lt;/p&gt;\n\n&lt;p&gt;I am a data science major who&amp;#39;s intrigued on picking up a little data engineering skills, but am very intimidated after I overestimated the overlap DE had with DS. I was hoping if there&amp;#39;s any people here who started from a DS/DA/ML background first, and if there&amp;#39;s any advice about how they transferred over.&lt;/p&gt;\n\n&lt;p&gt;So to preface, my major doesn&amp;#39;t touch enough on DE. We only had 1 class about it, where we *conceptually* learned things like AWS, learned about parquet, and pyspark, but there was no hands-on assignment at all.&lt;/p&gt;\n\n&lt;p&gt;In my business analyst internship, I&amp;#39;d entirely read from csv&amp;#39;s onto pandas. The data came from Snowflake, which I would then query it down with SQL until I got the data I needed, and either A), download the resulting csv, to read with pandas and do sklearn pipelines on (I had never bothered to learn how to connect snowflake directly to the python, assuming I would have even been permitted to do that), or B) query it down with SQL and link it to tableau to make pretty maps.&lt;/p&gt;\n\n&lt;p&gt;All these terms like dbt, jinja, OLAP, or apache airflow is very new to me, so I am a bit worried that neither my school nor work experience prepared me enough. What should I do next? Learn on my own and create  my own projects? Is that acceptable on a resume? I&amp;#39;m also worried, won&amp;#39;t such a project cost alot given AWS and well you know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123cy7c", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123cy7c/where_did_you_pick_up_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123cy7c/where_did_you_pick_up_data_engineering/", "subreddit_subscribers": 94574, "created_utc": 1679895909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on writing some basic azure data factory pipelines, and i'm new to this.\n\nWe have a private network behind a firewall, with an on-prem sql server database I'm connecting to. I thought I could use a self-hosted runtime, but when I try to run a data flow, it instead tells me I need to use a \"managed VNet using Private Endpoint. \"\n\nI read the microsoft doc on it and still can't quite wrap my head around what this is, and if I actually need it. The self-hosted runtime seems to allow me to connect to the server, just not run a data flow, so I'm confused what the difference is.\n\nAny thoughts/tips/tricks/similar experiences to share on this? TY!", "author_fullname": "t2_ezn9dzzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help understanding managed VNet using Private Endpoint for azure data factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123bh8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679891685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on writing some basic azure data factory pipelines, and i&amp;#39;m new to this.&lt;/p&gt;\n\n&lt;p&gt;We have a private network behind a firewall, with an on-prem sql server database I&amp;#39;m connecting to. I thought I could use a self-hosted runtime, but when I try to run a data flow, it instead tells me I need to use a &amp;quot;managed VNet using Private Endpoint. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I read the microsoft doc on it and still can&amp;#39;t quite wrap my head around what this is, and if I actually need it. The self-hosted runtime seems to allow me to connect to the server, just not run a data flow, so I&amp;#39;m confused what the difference is.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts/tips/tricks/similar experiences to share on this? TY!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123bh8x", "is_robot_indexable": true, "report_reasons": null, "author": "packetpupper", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123bh8x/help_understanding_managed_vnet_using_private/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123bh8x/help_understanding_managed_vnet_using_private/", "subreddit_subscribers": 94574, "created_utc": 1679891685.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}