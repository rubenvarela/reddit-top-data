{"kind": "Listing", "data": {"after": "t3_126hwo4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v4ncd2zz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality Dimensions: Assuring Your Data Quality with Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_126xzgl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vxW6yKxL_uIdOOs_dhYanpb5sNvNou78xQb6Vi2irzg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680207344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kdnuggets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?auto=webp&amp;v=enabled&amp;s=6e28deaf9d61b6f2e808a77bdc1e85f5e11912c9", "width": 2560, "height": 1708}, "resolutions": [{"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c07ff6bf8c4537dbcd36879b8886afe29c532ef", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0d40d7cdef11fda0f7a38e867c29f85df661486", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a32dafa5a3d7fc38d3fe4f325e8099791159d1ce", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3ddddd558e0d87c2d89bf1505239fdeb0dd1fa3", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd5b4b5aa4b5b4dd70531d531077bcd090f837fb", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/mkFX_SpUbJ-b-gJeCgbprqpuYuBSGqTesHPLoWaR7pM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b14b84416602cada4c2439589b214c1c25169f13", "width": 1080, "height": 720}], "variants": {}, "id": "iZTm0qzDgfWWGB-_lEEW4O8YNVUAmVnPBocMOw9AbYU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "126xzgl", "is_robot_indexable": true, "report_reasons": null, "author": "dahmedahe", "discussion_type": null, "num_comments": 9, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126xzgl/data_quality_dimensions_assuring_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html", "subreddit_subscribers": 95146, "created_utc": 1680207344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nJust wondering if anyone working in the UK is member of a union or if one even exists that we can join ? And do people think there\u2019s any merit in doing so ? \n\nCheers", "author_fullname": "t2_3rmk7fjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126i5bs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680170278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone working in the UK is member of a union or if one even exists that we can join ? And do people think there\u2019s any merit in doing so ? &lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "126i5bs", "is_robot_indexable": true, "report_reasons": null, "author": "sandonandfriends", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126i5bs/unions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126i5bs/unions/", "subreddit_subscribers": 95146, "created_utc": 1680170278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[dbt-excel](https://dbt-excel.com/) seamlessly integrates Excel into dbt, so you can take advantage of the dbt's rigor and Excel's flexibility.", "author_fullname": "t2_36lyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a data warehouse on top of Excel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126r6zx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680191974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dbt-excel.com/\"&gt;dbt-excel&lt;/a&gt; seamlessly integrates Excel into dbt, so you can take advantage of the dbt&amp;#39;s rigor and Excel&amp;#39;s flexibility.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "126r6zx", "is_robot_indexable": true, "report_reasons": null, "author": "BasL", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126r6zx/build_a_data_warehouse_on_top_of_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126r6zx/build_a_data_warehouse_on_top_of_excel/", "subreddit_subscribers": 95146, "created_utc": 1680191974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm newish to Databricks and Pyspark but not new to analytics and Python + Pandas. Now I need to build some workflows. \n\nAre there certain DOs and DON'T when handling Pyspark dataframes and views? \n\nAt a high level, I'm doing something like this:\n\n1. Read tables from Snowflake to df -&gt; df.createOrReplaceTempView('df\\_view')\n2. Get data from S3 with spark.read.format(\"csv\") etc. -&gt; create 's3\\_view'\n3. Do a bunch of joins and transformations using spark.sql(\"select \\* from df\\_view join s3\\_view...\")\n\nWhat I'd like to know is, for example: \n\nAre there performance differences between df.join vs. spark.sql(\"select....join\")? Or it just goes through the API and is handled the same in the end? \n\nIs there unnecessary overhead with createOrReplaceTempView if I can process the df directly?\n\nIt seemed to work fine for the first two joins but now a third one is taking too long. \n\nTIA!", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In terms of efficiency, what are DOs and DON'Ts when working with Pyspark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126qavy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680190067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m newish to Databricks and Pyspark but not new to analytics and Python + Pandas. Now I need to build some workflows. &lt;/p&gt;\n\n&lt;p&gt;Are there certain DOs and DON&amp;#39;T when handling Pyspark dataframes and views? &lt;/p&gt;\n\n&lt;p&gt;At a high level, I&amp;#39;m doing something like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read tables from Snowflake to df -&amp;gt; df.createOrReplaceTempView(&amp;#39;df_view&amp;#39;)&lt;/li&gt;\n&lt;li&gt;Get data from S3 with spark.read.format(&amp;quot;csv&amp;quot;) etc. -&amp;gt; create &amp;#39;s3_view&amp;#39;&lt;/li&gt;\n&lt;li&gt;Do a bunch of joins and transformations using spark.sql(&amp;quot;select * from df_view join s3_view...&amp;quot;)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What I&amp;#39;d like to know is, for example: &lt;/p&gt;\n\n&lt;p&gt;Are there performance differences between df.join vs. spark.sql(&amp;quot;select....join&amp;quot;)? Or it just goes through the API and is handled the same in the end? &lt;/p&gt;\n\n&lt;p&gt;Is there unnecessary overhead with createOrReplaceTempView if I can process the df directly?&lt;/p&gt;\n\n&lt;p&gt;It seemed to work fine for the first two joins but now a third one is taking too long. &lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126qavy", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126qavy/in_terms_of_efficiency_what_are_dos_and_donts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126qavy/in_terms_of_efficiency_what_are_dos_and_donts/", "subreddit_subscribers": 95146, "created_utc": 1680190067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My friend Matthew Brandt ([Matty\\_TwoShoes](https://www.twitch.tv/matty_twoshoes) on twitch) is doing a Twitch steam next Thursday where he'll try dbt for the first time! (note: that's \"dbt\".....not \"dmt\".) Matthew brandt is not trying dmt over a live stream. That'd be incredibly inappropriate.\n\nIf you're interested in seeing what it's like to learn and implement dbt, check it out with me!\n\nMatthew  will uncover the all the easiest + hardest aspects of learning dbt, and you'll get to enjoy watching all his successes and failures from the comfort of your home \ud83e\udd23\n\nIf you'd like to add the event to your calendar, sign up below! Or you can simply join the event on 4/6 @ 12pm PT!  \n\n\nhttps://www.operationalanalytics.club/events/unboxing-dbt-a-twitch-livestream-w-matthew-brandt-1", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitch Steam - Learning + applying dbt for the first time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126qcwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680192282.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680190200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend Matthew Brandt (&lt;a href=\"https://www.twitch.tv/matty_twoshoes\"&gt;Matty_TwoShoes&lt;/a&gt; on twitch) is doing a Twitch steam next Thursday where he&amp;#39;ll try dbt for the first time! (note: that&amp;#39;s &amp;quot;dbt&amp;quot;.....not &amp;quot;dmt&amp;quot;.) Matthew brandt is not trying dmt over a live stream. That&amp;#39;d be incredibly inappropriate.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in seeing what it&amp;#39;s like to learn and implement dbt, check it out with me!&lt;/p&gt;\n\n&lt;p&gt;Matthew  will uncover the all the easiest + hardest aspects of learning dbt, and you&amp;#39;ll get to enjoy watching all his successes and failures from the comfort of your home \ud83e\udd23&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to add the event to your calendar, sign up below! Or you can simply join the event on 4/6 @ 12pm PT!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.operationalanalytics.club/events/unboxing-dbt-a-twitch-livestream-w-matthew-brandt-1\"&gt;https://www.operationalanalytics.club/events/unboxing-dbt-a-twitch-livestream-w-matthew-brandt-1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gTKOSywxggZQmBXKnYDDkzm-APGaoSTJR7BHbOLDklM.jpg?auto=webp&amp;v=enabled&amp;s=f34786d607d5ca8ad4048c1283f81a50fe534c14", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/gTKOSywxggZQmBXKnYDDkzm-APGaoSTJR7BHbOLDklM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc4b7f22f675e723e5fe13b5361d6a346e45775d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/gTKOSywxggZQmBXKnYDDkzm-APGaoSTJR7BHbOLDklM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fbfe3721096fd45ef51beb74fae398a644788f1f", "width": 216, "height": 216}], "variants": {}, "id": "6DDlLAI5lezemVFbNcDzZ_LQBoX1Pr6PSzAbKmDFsSA"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "award_43f3bf99-92d6-47ab-8205-130d26e7929f", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=28bcf1fa8447dcf1563b7c63ed570ab965425571", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=5cb627bc2b0a04381d6a570414a9c8f4a3b6670e", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=8975c1e0714534392b9f9b673cabadc86775523b", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=51b7632b328de4bd198bc8aee3304cb9b359a7b5", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=57e90461b9efe2487f5337b5a45f13f4ce77225f", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "This hits me right in the feels", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Tearing Up", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=28bcf1fa8447dcf1563b7c63ed570ab965425571", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=5cb627bc2b0a04381d6a570414a9c8f4a3b6670e", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=8975c1e0714534392b9f9b673cabadc86775523b", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=51b7632b328de4bd198bc8aee3304cb9b359a7b5", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=57e90461b9efe2487f5337b5a45f13f4ce77225f", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/lop66ut2wnf51_TearingUp.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126qcwk", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126qcwk/twitch_steam_learning_applying_dbt_for_the_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126qcwk/twitch_steam_learning_applying_dbt_for_the_first/", "subreddit_subscribers": 95146, "created_utc": 1680190200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have little experience with Airflow, but I am looking for new orchestration tool for personal project.\n\nMy initial thought is to set up managed airflow server on GCP because I have worked with airflow for few months in one of my client engagements.\n\nHowever reading more about orchestration tools, it seems that Dagster might be a better choice in terms of usability and that it tackles the shortcomings of Airflow (e.g. passing data between DAGs, etc.)\n\nFor those who have worked with both, I would like to hear your subjective opinions on which one you prefer, and if Airflow is in any aspect better than Dagster.\n\nAny opinions are welcome", "author_fullname": "t2_tux1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those who have worked with Airflow and Dagster. Is Airflow in any aspect better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126js1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680174582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have little experience with Airflow, but I am looking for new orchestration tool for personal project.&lt;/p&gt;\n\n&lt;p&gt;My initial thought is to set up managed airflow server on GCP because I have worked with airflow for few months in one of my client engagements.&lt;/p&gt;\n\n&lt;p&gt;However reading more about orchestration tools, it seems that Dagster might be a better choice in terms of usability and that it tackles the shortcomings of Airflow (e.g. passing data between DAGs, etc.)&lt;/p&gt;\n\n&lt;p&gt;For those who have worked with both, I would like to hear your subjective opinions on which one you prefer, and if Airflow is in any aspect better than Dagster.&lt;/p&gt;\n\n&lt;p&gt;Any opinions are welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126js1x", "is_robot_indexable": true, "report_reasons": null, "author": "caksters", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126js1x/for_those_who_have_worked_with_airflow_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126js1x/for_those_who_have_worked_with_airflow_and/", "subreddit_subscribers": 95146, "created_utc": 1680174582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been casually browsing the LinkedIn/Google but it is so disappointing that I can\u2019t find any entry level data engineer job. Most \u201centry-level data engineer\u201d jobs require 2-3years of experience, I mean is it really still entry level in that case? My goal is to become a data engineer in financial services/banking industry, it just adds more difficulties into the job search having a particular industry to get in. Do people just ignore the experience and send their resume in for application anyway? I would imagine that that will get rejected by the ATS.", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there really still any entry level data engineer job in market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1273nls", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680220535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been casually browsing the LinkedIn/Google but it is so disappointing that I can\u2019t find any entry level data engineer job. Most \u201centry-level data engineer\u201d jobs require 2-3years of experience, I mean is it really still entry level in that case? My goal is to become a data engineer in financial services/banking industry, it just adds more difficulties into the job search having a particular industry to get in. Do people just ignore the experience and send their resume in for application anyway? I would imagine that that will get rejected by the ATS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1273nls", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1273nls/is_there_really_still_any_entry_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1273nls/is_there_really_still_any_entry_level_data/", "subreddit_subscribers": 95146, "created_utc": 1680220535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A couple years ago I needed a job and took one on a hybrid data/full stack team, thought days engineering sounded cool. We had a reorg and I was moved from there to a data platform team. At first I kinda dug it since we had a good manager, but he got laid off, we share one manager with two other teams now so it's chaotic. \n\nOn top of that it just doesn't feel like I actually build anything, it's just writing pipelines, dealing with different warehousing tools that someone else built, making sure all of the tables are organized for other people to use, and hooking up integrations for various tools. I feel like my engineering skills have gotten rusty, and I've applied around for other jobs but since I was too chicken to make a move during last years wild market I feel pigeonholed into data now that employers are pickier, and it's just going to get worse the longer I'm here. Doesn't help that I'm starting to realize that data engineers seem to make less for some reason.\n\nI'm kinda just venting but I'm really tired of feeling like a back room data monkey, this job has me burnt out on coding overall and wanting to try to switch to product, or just move out of tech to do I don't even know what.", "author_fullname": "t2_4w2a6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone else moved into data engineering just to discover they hate it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_127aca3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680237682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A couple years ago I needed a job and took one on a hybrid data/full stack team, thought days engineering sounded cool. We had a reorg and I was moved from there to a data platform team. At first I kinda dug it since we had a good manager, but he got laid off, we share one manager with two other teams now so it&amp;#39;s chaotic. &lt;/p&gt;\n\n&lt;p&gt;On top of that it just doesn&amp;#39;t feel like I actually build anything, it&amp;#39;s just writing pipelines, dealing with different warehousing tools that someone else built, making sure all of the tables are organized for other people to use, and hooking up integrations for various tools. I feel like my engineering skills have gotten rusty, and I&amp;#39;ve applied around for other jobs but since I was too chicken to make a move during last years wild market I feel pigeonholed into data now that employers are pickier, and it&amp;#39;s just going to get worse the longer I&amp;#39;m here. Doesn&amp;#39;t help that I&amp;#39;m starting to realize that data engineers seem to make less for some reason.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kinda just venting but I&amp;#39;m really tired of feeling like a back room data monkey, this job has me burnt out on coding overall and wanting to try to switch to product, or just move out of tech to do I don&amp;#39;t even know what.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "127aca3", "is_robot_indexable": true, "report_reasons": null, "author": "KookaB", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/127aca3/has_anyone_else_moved_into_data_engineering_just/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/127aca3/has_anyone_else_moved_into_data_engineering_just/", "subreddit_subscribers": 95146, "created_utc": 1680237682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m so burnt out and feel so undervalued at my job. I\u2019m applying for jobs basically every minute of the day I\u2019m not working. I feel like I\u2019d be able to put much greater effort into interviewing and prep if I wasn\u2019t currently working. \n\nThis is kind of a cry for help more than anything else. I\u2019m leaning toward getting a part time job just so I\u2019m not completely jobless and quitting as soon as I can. I\u2019m so fucking exhausted and sad.", "author_fullname": "t2_3tfxvg7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quitting job without a new one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126x35m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680205238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m so burnt out and feel so undervalued at my job. I\u2019m applying for jobs basically every minute of the day I\u2019m not working. I feel like I\u2019d be able to put much greater effort into interviewing and prep if I wasn\u2019t currently working. &lt;/p&gt;\n\n&lt;p&gt;This is kind of a cry for help more than anything else. I\u2019m leaning toward getting a part time job just so I\u2019m not completely jobless and quitting as soon as I can. I\u2019m so fucking exhausted and sad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "126x35m", "is_robot_indexable": true, "report_reasons": null, "author": "ridgewoodchick", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126x35m/quitting_job_without_a_new_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126x35m/quitting_job_without_a_new_one/", "subreddit_subscribers": 95146, "created_utc": 1680205238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Documentation. We live and die by it (or something like that).   \n\n\nBut as you no doubt know, it's inconsistent from place to place.   \n\n\n1. What tips/tools do you have to help you create documentation?\n2. What prevent you (or your org) from achieving good documentation?\n3. What do you see as the primary value of documentation?  \n\n\n**BONUS: How do you like to receive documentation?**  \n\n\n\\- Embedded learning (in your workflow)\n\n\\- Videos w/ screen shares\n\n\\- Long-form text?\n\n\\- Other?", "author_fullname": "t2_1dwwrlbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some best (and worst practices) for creating documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126m46x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680180903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Documentation. We live and die by it (or something like that).   &lt;/p&gt;\n\n&lt;p&gt;But as you no doubt know, it&amp;#39;s inconsistent from place to place.   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What tips/tools do you have to help you create documentation?&lt;/li&gt;\n&lt;li&gt;What prevent you (or your org) from achieving good documentation?&lt;/li&gt;\n&lt;li&gt;What do you see as the primary value of documentation?&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;BONUS: How do you like to receive documentation?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;- Embedded learning (in your workflow)&lt;/p&gt;\n\n&lt;p&gt;- Videos w/ screen shares&lt;/p&gt;\n\n&lt;p&gt;- Long-form text?&lt;/p&gt;\n\n&lt;p&gt;- Other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126m46x", "is_robot_indexable": true, "report_reasons": null, "author": "Deepinthemaze", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126m46x/what_are_some_best_and_worst_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126m46x/what_are_some_best_and_worst_practices_for/", "subreddit_subscribers": 95146, "created_utc": 1680180903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which Python library do you use on regular basis and why?", "author_fullname": "t2_vnumk75p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126nb43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680183603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which Python library do you use on regular basis and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126nb43", "is_robot_indexable": true, "report_reasons": null, "author": "Tiny-Tell3680", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126nb43/python_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126nb43/python_library/", "subreddit_subscribers": 95146, "created_utc": 1680183603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've all had them...   \n\n\n**Awful managers.**   \n\n\nBut what about them was so terrible? And what qualities should hiring leaders look out for when hiring an engineering manager?   \n\n\n* What skills are overvalued? \n* What skills are undervalued?  \n\n\n**What do you think makes someone a great engineering manager?**   \n\n\nEx. Gave great constructive feedback.   \nEx. Berated everyone on the team.\n\nFeel free to share your experiences. Thanks!", "author_fullname": "t2_1dwwrlbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What qualities make a great engineering manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126hxgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680169479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve all had them...   &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Awful managers.&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;But what about them was so terrible? And what qualities should hiring leaders look out for when hiring an engineering manager?   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What skills are overvalued? &lt;/li&gt;\n&lt;li&gt;What skills are undervalued?&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What do you think makes someone a great engineering manager?&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;Ex. Gave great constructive feedback.&lt;br/&gt;\nEx. Berated everyone on the team.&lt;/p&gt;\n\n&lt;p&gt;Feel free to share your experiences. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126hxgo", "is_robot_indexable": true, "report_reasons": null, "author": "Deepinthemaze", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126hxgo/what_qualities_make_a_great_engineering_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126hxgo/what_qualities_make_a_great_engineering_manager/", "subreddit_subscribers": 95146, "created_utc": 1680169479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for, and failing to find an example data warehouse that I can load locally. I'm wanting to see a real-life example of a Kimball designed database, with at least 5 fact tables. I'm curious to see naming conventions, relationships and general design.\n\nHas anyone come across this online as a .sql file that I can import locally?", "author_fullname": "t2_o72dwjd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kimball's approach to Data warehouse example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126zdk9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680210584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for, and failing to find an example data warehouse that I can load locally. I&amp;#39;m wanting to see a real-life example of a Kimball designed database, with at least 5 fact tables. I&amp;#39;m curious to see naming conventions, relationships and general design.&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across this online as a .sql file that I can import locally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "126zdk9", "is_robot_indexable": true, "report_reasons": null, "author": "Active-Proposal-932", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126zdk9/kimballs_approach_to_data_warehouse_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126zdk9/kimballs_approach_to_data_warehouse_example/", "subreddit_subscribers": 95146, "created_utc": 1680210584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have an example of a (git) branching strategy that they believe acts as a model for others to follow. This problem isn't really a DE specific issue, just happens to be related to DE tools in our case. \n\nOur background as an Azure Data Lakehouse shop:\n\nCore Components:  \n\n\n* Resource Groups for: Dev, QA, Prod\n   * Each RG has its own instance of : \n      * Single Storage Account (Raw, Query, and Refined zones are stored as parquet/delta tables here as folders within the SA)\n      * Azure DataFactory\n      * Azure Databricks\n      * KeyVault\n      * other ancillary services\n* Azure DataFactory Pipelines to hydrate Raw and Query zones\n* Databricks to build relational and dimensional models (refined zone)\n* Azure DevOps to host git projects (for ADF and DBX)\n   * Pipelines trigger on commits \n      * Typically only trigger on \\`main\\` and \\`release\\` branches (feature/\\* and fix/\\* branches, can be manually run against a pipeline if desired)\n   * Deployment artifacts are built during pipeline runs\n   * Artifacts are deployed to Dev -&gt; QA -&gt; Prod environments. Typically QA and Prod require manual approval by a member of the team.\n      * Prod has branch control policy to enforce that only \"release\" branch builds can be deployed here\n\nWhen Developers are building a change:  \n\n\n1. new branch off \\`main\\` (either feature/...  or fix/....)\n2. Change is implemented, run directly in that branch during development. \n3. Once completed, a PR is submitted to merge this branch back into \\`main\\`\n   1. Approval is required from another team member (to force a second reviewer)\n4. \\`main\\` commit triggers to dev environment \n5. Once the change is verified, a PR is submitted to \\`release\\` to trigger a build into QA (for User Testing/evaluation)\n6. Once the team is ready for the changes to go to prod, an approval is made on the Pipeline. \n\nKey challenge here is that multiple changes can be made into release before getting deployed to Production, so managing knowing what is getting changed can get out of control. \n\nI suspect the crux of the issue is that we essentially have a linear deployment path with a funnel on release. Additionally, while we manage ADF changes and DBX changes separately, each is stored in its own monolithic repo (1 repo for all pipelines, and 1 repo for all notebooks in DBX).", "author_fullname": "t2_3l6wi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "git branching strategy for DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126pz15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680189333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have an example of a (git) branching strategy that they believe acts as a model for others to follow. This problem isn&amp;#39;t really a DE specific issue, just happens to be related to DE tools in our case. &lt;/p&gt;\n\n&lt;p&gt;Our background as an Azure Data Lakehouse shop:&lt;/p&gt;\n\n&lt;p&gt;Core Components:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Resource Groups for: Dev, QA, Prod\n\n&lt;ul&gt;\n&lt;li&gt;Each RG has its own instance of : \n\n&lt;ul&gt;\n&lt;li&gt;Single Storage Account (Raw, Query, and Refined zones are stored as parquet/delta tables here as folders within the SA)&lt;/li&gt;\n&lt;li&gt;Azure DataFactory&lt;/li&gt;\n&lt;li&gt;Azure Databricks&lt;/li&gt;\n&lt;li&gt;KeyVault&lt;/li&gt;\n&lt;li&gt;other ancillary services&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Azure DataFactory Pipelines to hydrate Raw and Query zones&lt;/li&gt;\n&lt;li&gt;Databricks to build relational and dimensional models (refined zone)&lt;/li&gt;\n&lt;li&gt;Azure DevOps to host git projects (for ADF and DBX)\n\n&lt;ul&gt;\n&lt;li&gt;Pipelines trigger on commits \n\n&lt;ul&gt;\n&lt;li&gt;Typically only trigger on `main` and `release` branches (feature/* and fix/* branches, can be manually run against a pipeline if desired)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Deployment artifacts are built during pipeline runs&lt;/li&gt;\n&lt;li&gt;Artifacts are deployed to Dev -&amp;gt; QA -&amp;gt; Prod environments. Typically QA and Prod require manual approval by a member of the team.\n\n&lt;ul&gt;\n&lt;li&gt;Prod has branch control policy to enforce that only &amp;quot;release&amp;quot; branch builds can be deployed here&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;When Developers are building a change:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;new branch off `main` (either feature/...  or fix/....)&lt;/li&gt;\n&lt;li&gt;Change is implemented, run directly in that branch during development. &lt;/li&gt;\n&lt;li&gt;Once completed, a PR is submitted to merge this branch back into `main`\n\n&lt;ol&gt;\n&lt;li&gt;Approval is required from another team member (to force a second reviewer)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;`main` commit triggers to dev environment &lt;/li&gt;\n&lt;li&gt;Once the change is verified, a PR is submitted to `release` to trigger a build into QA (for User Testing/evaluation)&lt;/li&gt;\n&lt;li&gt;Once the team is ready for the changes to go to prod, an approval is made on the Pipeline. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Key challenge here is that multiple changes can be made into release before getting deployed to Production, so managing knowing what is getting changed can get out of control. &lt;/p&gt;\n\n&lt;p&gt;I suspect the crux of the issue is that we essentially have a linear deployment path with a funnel on release. Additionally, while we manage ADF changes and DBX changes separately, each is stored in its own monolithic repo (1 repo for all pipelines, and 1 repo for all notebooks in DBX).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126pz15", "is_robot_indexable": true, "report_reasons": null, "author": "lear64", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126pz15/git_branching_strategy_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126pz15/git_branching_strategy_for_de/", "subreddit_subscribers": 95146, "created_utc": 1680189333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This class has everything I was looking for but is a good starting point https://coursera.org/specializations/python-bash-sql-data-engineering-duke and is the azure data engineer cert worth the work?  Thanks in advance.", "author_fullname": "t2_15106c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is class a good starting point for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1279fhc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680235050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This class has everything I was looking for but is a good starting point &lt;a href=\"https://coursera.org/specializations/python-bash-sql-data-engineering-duke\"&gt;https://coursera.org/specializations/python-bash-sql-data-engineering-duke&lt;/a&gt; and is the azure data engineer cert worth the work?  Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?auto=webp&amp;v=enabled&amp;s=98199436a00c613976f46604660e3cb2750dde3c", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec45a327d4935a99eee3a5f3cc7581deec2f5e1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edab6033ae2e309e1b38b4376d8ccb8d58ef3201", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afdf1d01d5807b45146d869f60d5e7832e82d0cc", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82c8c23d5cac610eeac0979afed11104ccfefb57", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47b75fd9dc722af973773044d496b9502a42aa01", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/I8JoIiZ64fRWJvX82IiRFOKRdqQzwAhJM6lNpCm_-oQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abceeb4811e555ddc2545cbb56b78f490794bf11", "width": 1080, "height": 565}], "variants": {}, "id": "cY0llg-mM3tRSwcZbB78P56I2x1KIpjtCQeklGLfc40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1279fhc", "is_robot_indexable": true, "report_reasons": null, "author": "SuperBiteSize", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1279fhc/is_class_a_good_starting_point_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1279fhc/is_class_a_good_starting_point_for_data/", "subreddit_subscribers": 95146, "created_utc": 1680235050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello and welcome to yet another \"Hey, I got X job and I need help figuring thing out\". And. Hum. Well. This is precisely my situation so let's move on.\n\nI've got a new job as a \"Data Manager\" in a service that does market analysis for an industrial company:\n\n* Data is rather scarce. The almost 30 years old \"database\" (it's more or less an Excel table, but they call everything \"database\"). Is less than 100,000 rows. So the volume is very manageable.\n* There is not automatic collection of data. Eveything is hand input by analysts.\n* The service produces a shitload of reports. \"Visuals\" production is really an issue. All visuals are produced by god-awful pivot-tables sandwiches.\n* Data is slow. If reports are refreshed 3 times a year, that's enough.\n* There is PowerBI in the landscape.\n\nIn a few words. Excel everything: input, manipulation, graphics...\n\nAnd there is me. I'm a self-taught data specialist. I'm very confortable with SQL, Power BI, Excel and getting there with Python. And also basic \"home lab\" server stuff: linux shell, docker... I have some knowledge of Snowflake.\n\nSo here is my grand plan and I'm all ears for ideas and remarks.\n\n1. **Excel rebuilding**. I keep most of the legacy Excel file but I rework them to be more consistent across the board. I also do lots of deduplication: e.g. \"products\" info goes into \"product file\", no need to input some version of it accross 3 files. All the Excel are storred in Sharepoint.\n\n2. **Data warehousing**. I need to ingest maybe once a month all of these Excel file and transform them into a target format that makes sense for data analysis. I've little to no experience with ETL tools. I don't think I need a proper ETL tool and might get away with Python. But I don't know how (tool wise) to have a server run the code and warehouse the data. I've read about airflow to run the code but I have no ideas about how to store data? \n\n3. Use the data. I have a \"dashboard\" pipeline that would be PowerBI based. So PowerBI needs to be able to connect to the warehouse.\n\n4. Use the data again. The other pipeline is the \"report visual/lab\". Basically, I'm OK with Jupyter Notebooks. Because having a bunch of text that acts as a documentation for a given visual and the code next to it is great. So far I've done it with a mixture of Python and DuckDB (DUCKDB IS AWESOME).\n\nSo basically the big question mark is around ETL and datawarehousing. I need to find a solution that ticks some boxes:\n\n* Not cloud based. Eveything cloud-based is forbidden by IT security. So it should be hosted on premise. I might be able to request a server. \n* Able to work with Sharepoint (where the excel files are) and PowerBI.", "author_fullname": "t2_cr1c7y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New job as a Data Manager. The data is a bunch of excel files.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1271cb2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680215191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello and welcome to yet another &amp;quot;Hey, I got X job and I need help figuring thing out&amp;quot;. And. Hum. Well. This is precisely my situation so let&amp;#39;s move on.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a new job as a &amp;quot;Data Manager&amp;quot; in a service that does market analysis for an industrial company:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data is rather scarce. The almost 30 years old &amp;quot;database&amp;quot; (it&amp;#39;s more or less an Excel table, but they call everything &amp;quot;database&amp;quot;). Is less than 100,000 rows. So the volume is very manageable.&lt;/li&gt;\n&lt;li&gt;There is not automatic collection of data. Eveything is hand input by analysts.&lt;/li&gt;\n&lt;li&gt;The service produces a shitload of reports. &amp;quot;Visuals&amp;quot; production is really an issue. All visuals are produced by god-awful pivot-tables sandwiches.&lt;/li&gt;\n&lt;li&gt;Data is slow. If reports are refreshed 3 times a year, that&amp;#39;s enough.&lt;/li&gt;\n&lt;li&gt;There is PowerBI in the landscape.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In a few words. Excel everything: input, manipulation, graphics...&lt;/p&gt;\n\n&lt;p&gt;And there is me. I&amp;#39;m a self-taught data specialist. I&amp;#39;m very confortable with SQL, Power BI, Excel and getting there with Python. And also basic &amp;quot;home lab&amp;quot; server stuff: linux shell, docker... I have some knowledge of Snowflake.&lt;/p&gt;\n\n&lt;p&gt;So here is my grand plan and I&amp;#39;m all ears for ideas and remarks.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Excel rebuilding&lt;/strong&gt;. I keep most of the legacy Excel file but I rework them to be more consistent across the board. I also do lots of deduplication: e.g. &amp;quot;products&amp;quot; info goes into &amp;quot;product file&amp;quot;, no need to input some version of it accross 3 files. All the Excel are storred in Sharepoint.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data warehousing&lt;/strong&gt;. I need to ingest maybe once a month all of these Excel file and transform them into a target format that makes sense for data analysis. I&amp;#39;ve little to no experience with ETL tools. I don&amp;#39;t think I need a proper ETL tool and might get away with Python. But I don&amp;#39;t know how (tool wise) to have a server run the code and warehouse the data. I&amp;#39;ve read about airflow to run the code but I have no ideas about how to store data? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use the data. I have a &amp;quot;dashboard&amp;quot; pipeline that would be PowerBI based. So PowerBI needs to be able to connect to the warehouse.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use the data again. The other pipeline is the &amp;quot;report visual/lab&amp;quot;. Basically, I&amp;#39;m OK with Jupyter Notebooks. Because having a bunch of text that acts as a documentation for a given visual and the code next to it is great. So far I&amp;#39;ve done it with a mixture of Python and DuckDB (DUCKDB IS AWESOME).&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So basically the big question mark is around ETL and datawarehousing. I need to find a solution that ticks some boxes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Not cloud based. Eveything cloud-based is forbidden by IT security. So it should be hosted on premise. I might be able to request a server. &lt;/li&gt;\n&lt;li&gt;Able to work with Sharepoint (where the excel files are) and PowerBI.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1271cb2", "is_robot_indexable": true, "report_reasons": null, "author": "raymondstanz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1271cb2/new_job_as_a_data_manager_the_data_is_a_bunch_of/", "subreddit_subscribers": 95146, "created_utc": 1680215191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w70zh2x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust in Action", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_126l5ds", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/iYJ6bLITZsI?list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Rust in Action \u2022 Tim McNamara &amp; Richard Feldman \u2022 GOTO 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/iYJ6bLITZsI?list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/iYJ6bLITZsI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/iYJ6bLITZsI?list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/126l5ds", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/WivsmIIj8QxCO6x9egc4sbCmY1T2KGg8fdxLD9ETg68.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680178394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=iYJ6bLITZsI&amp;list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zz3xGyG2YOdI8ZdK4FvabuHp8B2BuoYyHfswpIbu8lU.jpg?auto=webp&amp;v=enabled&amp;s=1c7993b2d799b1098e62ecae43441ff462596fda", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/zz3xGyG2YOdI8ZdK4FvabuHp8B2BuoYyHfswpIbu8lU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93024971caba1105f7c1979d490bfaa76efdd915", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/zz3xGyG2YOdI8ZdK4FvabuHp8B2BuoYyHfswpIbu8lU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daafaa6d1ed74247df9c08369e04389acc19d81f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/zz3xGyG2YOdI8ZdK4FvabuHp8B2BuoYyHfswpIbu8lU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e0393e7c7cb88e8ab896fa85b96f3afc989d8ee", "width": 320, "height": 240}], "variants": {}, "id": "5kkjojkOnjf3JoKvv5VDJSUYRwDBGH6296sXXiP2z8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "126l5ds", "is_robot_indexable": true, "report_reasons": null, "author": "Juggernaut20023", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126l5ds/rust_in_action/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=iYJ6bLITZsI&amp;list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra", "subreddit_subscribers": 95146, "created_utc": 1680178394.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Rust in Action \u2022 Tim McNamara &amp; Richard Feldman \u2022 GOTO 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/iYJ6bLITZsI?list=PLEx5khR4g7PJbSLmADahf0LOpTLifiCra\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/iYJ6bLITZsI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, with over 10 years of experience in the bi and analytics field, last year I got a gcp pde cert and found a new project, looking for a career change/refresh.\n\nSo, for the first time hired as 'data engineer', I got assigned a lot of stories being just etl pipelines (airflow) to load csvs to bq, but then they assigned me a story which required a lot of working with business stakeholders to understand calculations they wanted, and this one required a lot of data logic (programed at sql level) to deliver resulting data in a table. I am experienced doing this kind of stuff (from etl to reporting) so I did it with no problem.\n\nBut now I'm getting assigned more of those kind of stories and found my activities more similar to what I was doing previously of becoming a DE, so this made me ask: is this kind of stuff considered part of data engineering duties?", "author_fullname": "t2_14crgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are business analysis tasks part of data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1277uk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680231412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, with over 10 years of experience in the bi and analytics field, last year I got a gcp pde cert and found a new project, looking for a career change/refresh.&lt;/p&gt;\n\n&lt;p&gt;So, for the first time hired as &amp;#39;data engineer&amp;#39;, I got assigned a lot of stories being just etl pipelines (airflow) to load csvs to bq, but then they assigned me a story which required a lot of working with business stakeholders to understand calculations they wanted, and this one required a lot of data logic (programed at sql level) to deliver resulting data in a table. I am experienced doing this kind of stuff (from etl to reporting) so I did it with no problem.&lt;/p&gt;\n\n&lt;p&gt;But now I&amp;#39;m getting assigned more of those kind of stories and found my activities more similar to what I was doing previously of becoming a DE, so this made me ask: is this kind of stuff considered part of data engineering duties?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1277uk7", "is_robot_indexable": true, "report_reasons": null, "author": "untalmau", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1277uk7/are_business_analysis_tasks_part_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1277uk7/are_business_analysis_tasks_part_of_data/", "subreddit_subscribers": 95146, "created_utc": 1680231412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently creating a POC about orchestration tool, and I found airflow and ADF for my team\u2019s use case but I\u2019m now leaning towards airflow. I\u2019m curious to know, how did you guys deployed your company\u2019s airflow instance?\n\nWhat are the drawbacks of your decision?\n\nWhat policy/system did you make to enable distributed teams (dags living in different repositories) unify all of their works into one place?\n\n\nEdit: We are using Azure cloud, and as I\u2019ve seen, azure recently launched a managed airflow service running on top of ADF.", "author_fullname": "t2_5owlarij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DAGS Deployment Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1273mxx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680223960.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680220491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently creating a POC about orchestration tool, and I found airflow and ADF for my team\u2019s use case but I\u2019m now leaning towards airflow. I\u2019m curious to know, how did you guys deployed your company\u2019s airflow instance?&lt;/p&gt;\n\n&lt;p&gt;What are the drawbacks of your decision?&lt;/p&gt;\n\n&lt;p&gt;What policy/system did you make to enable distributed teams (dags living in different repositories) unify all of their works into one place?&lt;/p&gt;\n\n&lt;p&gt;Edit: We are using Azure cloud, and as I\u2019ve seen, azure recently launched a managed airflow service running on top of ADF.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1273mxx", "is_robot_indexable": true, "report_reasons": null, "author": "_Dark_mage", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1273mxx/airflow_dags_deployment_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1273mxx/airflow_dags_deployment_strategy/", "subreddit_subscribers": 95146, "created_utc": 1680220491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are transforming some data (in Java) and write the output to a Postgres database. We'd like to test the data in the database using SQL tests (because it's very accessible) and I am not sure how to manage those. There will probably be a couple hundred tests ranging from simple constraint validations (not null, enums, ranges, ...) to more complex validations that require joins and window functions.\n\nI'm used to utilising dbt and defining my tests there (along with [dbt-utils](https://github.com/dbt-labs/dbt-utils) or [https://github.com/calogica/dbt-expectations](https://github.com/calogica/dbt-expectations)): I simply add a list item to a column definition and can already define a great number of tests without having to copy code. I can even extend the pre-defined using generic tests. Writing custom tests also integrates nicely. Additionally it's very convenient to tag tests or define a severity. The learning curve for a business engineer is almost flat as long as they know some SQL.\n\nSetting up dbt just to run tests, though, seems like way too much technical debt because I'd only use a small part of its features. I could just put all test files in a directory and execute them but then I'd still have to define some configuration for common tests (like constraints) or accept that we copy code and just replace a column name (doesn't feel right, either).\n\nHow do you approach such a scenario? Perhaps allowing business engineers to write tests is not even the way to go and they should rather focus on writing BDD requirements?", "author_fullname": "t2_564s442i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing SQL Tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126l3p9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680178262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are transforming some data (in Java) and write the output to a Postgres database. We&amp;#39;d like to test the data in the database using SQL tests (because it&amp;#39;s very accessible) and I am not sure how to manage those. There will probably be a couple hundred tests ranging from simple constraint validations (not null, enums, ranges, ...) to more complex validations that require joins and window functions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m used to utilising dbt and defining my tests there (along with &lt;a href=\"https://github.com/dbt-labs/dbt-utils\"&gt;dbt-utils&lt;/a&gt; or &lt;a href=\"https://github.com/calogica/dbt-expectations\"&gt;https://github.com/calogica/dbt-expectations&lt;/a&gt;): I simply add a list item to a column definition and can already define a great number of tests without having to copy code. I can even extend the pre-defined using generic tests. Writing custom tests also integrates nicely. Additionally it&amp;#39;s very convenient to tag tests or define a severity. The learning curve for a business engineer is almost flat as long as they know some SQL.&lt;/p&gt;\n\n&lt;p&gt;Setting up dbt just to run tests, though, seems like way too much technical debt because I&amp;#39;d only use a small part of its features. I could just put all test files in a directory and execute them but then I&amp;#39;d still have to define some configuration for common tests (like constraints) or accept that we copy code and just replace a column name (doesn&amp;#39;t feel right, either).&lt;/p&gt;\n\n&lt;p&gt;How do you approach such a scenario? Perhaps allowing business engineers to write tests is not even the way to go and they should rather focus on writing BDD requirements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?auto=webp&amp;v=enabled&amp;s=f31a8dd4ddb671f4530951726876a6b45c6abc9d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b7390656863cda660dfaeb2a845a65cd33c5534", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e90707db5c1a2be160bce7e131dc6e29fdc2d056", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7258819e9dcba04afeef5d3e7d639b66b78e0049", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64e3cd225d044871504eaff55b688961143cc7bb", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fda6193853f8bae15a15b05a5caa20e70f8792ed", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/M4oMiZwUQ5qNYM8FmSOgdnCQ6y25kIfHSEDXPoAt7GA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=319b1206ce7bd89a3b177b7d2765c81f0794bf8c", "width": 1080, "height": 540}], "variants": {}, "id": "woMjpl8NsBukTu0VdO0-jW_H5wo6GLnde2z4SbpQSk8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126l3p9", "is_robot_indexable": true, "report_reasons": null, "author": "_temmink", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/126l3p9/managing_sql_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126l3p9/managing_sql_tests/", "subreddit_subscribers": 95146, "created_utc": 1680178262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for a simple solution to schedule R and Python scripts. \n\nMy IT department won\u2019t enable the \u201cLog on as a batch job\u201d user right so I\u2019m unable to use Windows Task Scheduler.\n\nDo I have any other options on a Windows system?", "author_fullname": "t2_ntcrompa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Script scheduler available to users without admin privileges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126xaby", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680205698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a simple solution to schedule R and Python scripts. &lt;/p&gt;\n\n&lt;p&gt;My IT department won\u2019t enable the \u201cLog on as a batch job\u201d user right so I\u2019m unable to use Windows Task Scheduler.&lt;/p&gt;\n\n&lt;p&gt;Do I have any other options on a Windows system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "126xaby", "is_robot_indexable": true, "report_reasons": null, "author": "AltraSol", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126xaby/script_scheduler_available_to_users_without_admin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126xaby/script_scheduler_available_to_users_without_admin/", "subreddit_subscribers": 95146, "created_utc": 1680205698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ui4m14ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New on AWS: Datazone \u2014 share, search, and discover data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126qydm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1680191445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@anupmoncy/new-on-aws-datazone-share-search-and-discover-data-601c5ec9b246", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "126qydm", "is_robot_indexable": true, "report_reasons": null, "author": "Alarmed-Sock4915", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126qydm/new_on_aws_datazone_share_search_and_discover_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@anupmoncy/new-on-aws-datazone-share-search-and-discover-data-601c5ec9b246", "subreddit_subscribers": 95146, "created_utc": 1680191445.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone\nI try to Put my Data in a Star Schema and I've got a table that contains data about offers that I receive. In this Table there is an offer number, informational columns about the seller, the purchase price and one column that contains The offer's Status (new, checked, declined, accepted) which gets updated accordingly. When I buy an Object nothing happens aside from the updated status column in the aforementioned Table.\n\nShould i try to create three fact tables using the status changes (checked,declined,accepted) and have two dimensional tables (offer Info, seller) or should I only have dimensional tables Here that I Update according to kimbals \"slowly changing dimensions\"? \n\nLooking forward to your answers.", "author_fullname": "t2_as1vw8gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Offer Table in Star Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126p2zf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680187272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone\nI try to Put my Data in a Star Schema and I&amp;#39;ve got a table that contains data about offers that I receive. In this Table there is an offer number, informational columns about the seller, the purchase price and one column that contains The offer&amp;#39;s Status (new, checked, declined, accepted) which gets updated accordingly. When I buy an Object nothing happens aside from the updated status column in the aforementioned Table.&lt;/p&gt;\n\n&lt;p&gt;Should i try to create three fact tables using the status changes (checked,declined,accepted) and have two dimensional tables (offer Info, seller) or should I only have dimensional tables Here that I Update according to kimbals &amp;quot;slowly changing dimensions&amp;quot;? &lt;/p&gt;\n\n&lt;p&gt;Looking forward to your answers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126p2zf", "is_robot_indexable": true, "report_reasons": null, "author": "One_Indication_6921", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126p2zf/offer_table_in_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126p2zf/offer_table_in_star_schema/", "subreddit_subscribers": 95146, "created_utc": 1680187272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to know how'd guys setup airflow in Azure on your company if you have different teams building different pipelines?", "author_fullname": "t2_86jl5xyy5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting Up Airflow for Distributed Teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126ijuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680171654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to know how&amp;#39;d guys setup airflow in Azure on your company if you have different teams building different pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "126ijuc", "is_robot_indexable": true, "report_reasons": null, "author": "x-GenPipe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126ijuc/setting_up_airflow_for_distributed_teams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126ijuc/setting_up_airflow_for_distributed_teams/", "subreddit_subscribers": 95146, "created_utc": 1680171654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The data in s3 is stored in year and month format:\nStructure :\n\n```s3:schema/table/year/month/data and manifest file```\n\nEach year, month data have individual manifest file\n\nMy task is to reload this data back to redshift table\nI have thought of two solution:\n   * create a small table for each year_month than create a staging table from all the small tables.\\\n   Later do an upsert on the orginal table from the staging table.\n   \n   * I realized that i can one staging table and keep running multiple copy command on it from each year_month manifest and then do an upsert on the orginal table from it.\n\nIs there a better way to implement this.\nI am trying to reach for a more elegant and efficient solution.", "author_fullname": "t2_l38csc3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reload data from s3 back to redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126hwo4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680169398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data in s3 is stored in year and month format:\nStructure :&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;s3:schema/table/year/month/data and manifest file&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Each year, month data have individual manifest file&lt;/p&gt;\n\n&lt;p&gt;My task is to reload this data back to redshift table\nI have thought of two solution:\n   * create a small table for each year_month than create a staging table from all the small tables.\\\n   Later do an upsert on the orginal table from the staging table.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I realized that i can one staging table and keep running multiple copy command on it from each year_month manifest and then do an upsert on the orginal table from it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is there a better way to implement this.\nI am trying to reach for a more elegant and efficient solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "126hwo4", "is_robot_indexable": true, "report_reasons": null, "author": "AdSure744", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/126hwo4/reload_data_from_s3_back_to_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/126hwo4/reload_data_from_s3_back_to_redshift/", "subreddit_subscribers": 95146, "created_utc": 1680169398.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}