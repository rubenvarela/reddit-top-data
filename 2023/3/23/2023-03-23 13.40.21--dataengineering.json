{"kind": "Listing", "data": {"after": "t3_11yupcg", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do any of you guys like doing DevOps work as a DE. I hate it so much, it\u2019s just extremely boring for me, and for some reason all the DEs in my team are always prioritizing IaC (terraform), akyless integration for rotating keys, cicd templates, etc. I always vote to prioritize on data quality initiatives but I guess no on likes that lol. \n\nAnd is not that I like data quality, just that my mind thinks as a business stakeholder not as an engineer. Data quality is way more important for the business (better data aka more money) than doing all this fancy DevOps work. Off course, that work is important but there are more critical things to do. \n\nWhat are your opinions?", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Devops work as a DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ymha3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679498895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do any of you guys like doing DevOps work as a DE. I hate it so much, it\u2019s just extremely boring for me, and for some reason all the DEs in my team are always prioritizing IaC (terraform), akyless integration for rotating keys, cicd templates, etc. I always vote to prioritize on data quality initiatives but I guess no on likes that lol. &lt;/p&gt;\n\n&lt;p&gt;And is not that I like data quality, just that my mind thinks as a business stakeholder not as an engineer. Data quality is way more important for the business (better data aka more money) than doing all this fancy DevOps work. Off course, that work is important but there are more critical things to do. &lt;/p&gt;\n\n&lt;p&gt;What are your opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ymha3", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ymha3/devops_work_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ymha3/devops_work_as_a_de/", "subreddit_subscribers": 94086, "created_utc": 1679498895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[RedfinScraper](https://github.com/ryansherby/RedfinScraper) is a scalable Python library that leverages Redfin's unofficial Stringray API to quickly scrape thousands of housing records.\n\n It is super easy to download into any Python environment using `pip install redfin-scraper`.\n\nLet me know what improvements you'd like to see!", "author_fullname": "t2_v406kvhe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scrape Thousands of Housing Records in Minutes!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yxoz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679529769.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679521221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/ryansherby/RedfinScraper\"&gt;RedfinScraper&lt;/a&gt; is a scalable Python library that leverages Redfin&amp;#39;s unofficial Stringray API to quickly scrape thousands of housing records.&lt;/p&gt;\n\n&lt;p&gt;It is super easy to download into any Python environment using &lt;code&gt;pip install redfin-scraper&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Let me know what improvements you&amp;#39;d like to see!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?auto=webp&amp;v=enabled&amp;s=768a08ea993fe0fc8b18c234f3c8d9d80c8fad9b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9164da55bfe548723ae44cfc4aad6dcb5c045313", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cab7af29b5d61a98c1ebb41572cebaed954e0e43", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c20d7a6d17ee0c2259d6a79db11603cee297114a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccb3ef25adfe8f78e8e6a969190098e04f686a13", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a1f71832279410921b638330874b5fdfa5a62b4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DxNV56QuPSA9lsd7Jl-nmryeyUOsfURy1UlI8DJjMU8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a217fb3dbec4f5112885a2b06fcdcf7e8b883d0f", "width": 1080, "height": 540}], "variants": {}, "id": "YyO3Be5fgoh7IParczUdCf7kd5nIUSuQH4C7pa4rXBE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11yxoz3", "is_robot_indexable": true, "report_reasons": null, "author": "ryan_s007", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yxoz3/scrape_thousands_of_housing_records_in_minutes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yxoz3/scrape_thousands_of_housing_records_in_minutes/", "subreddit_subscribers": 94086, "created_utc": 1679521221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any ML engineers use DBT after they introduced python support? What has been your experience so far?", "author_fullname": "t2_f9hl9ddw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt for ML Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yvb2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679516426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any ML engineers use DBT after they introduced python support? What has been your experience so far?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yvb2j", "is_robot_indexable": true, "report_reasons": null, "author": "Own-Staff3774", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yvb2j/dbt_for_ml_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yvb2j/dbt_for_ml_engineering/", "subreddit_subscribers": 94086, "created_utc": 1679516426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am fairly new to DE, learning Python since December 2022, and coming from a non-tech background. I took part in the [DataTalksClub Zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp). I started using these tools used in the project in January 2023.\n\nProject link: [GitHub repo for Magic: The Gathering](https://github.com/VincenzoGalante/magic-the-gathering)\n\nProject background:\n\n* I used to play Magic: The Gathering a lot back in the 90s\n* I wanted to understand the game from a meta perspective and tried to answer questions that I was interested in\n\nTechnologies used:\n\n* Infrastructure via terraform, and GCP as cloud\n* I read the [scryfall API](https://scryfall.com/) for card data\n* Push them to my storage bucket\n* Push needed data points to BigQuery \n* Transform the data there with DBT\n* Visualize the final dataset with [Looker](https://lookerstudio.google.com/u/0/reporting/ebdf68e1-27f7-435b-8add-a4018681f801)\n\nI am somewhat proud to having finished this, as I never would have thought to learn all this. I did put a lot of long evenings, early mornings and weekends into this. In the future I plan to do more projects and apply for a Data Engineering  or Analytics Engineering position - preferably at my current company. \n\nPlease feel free to leave constructive feedback on code, visualization or any other part of the project. \n\nThanks \ud83e\uddd9\ud83c\udffc\u200d\u2642\ufe0f \ud83d\udd2e", "author_fullname": "t2_9v9dakww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Magic: The Gathering dashboard | First complete DE project ever | Feedback welcome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11zh526", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679570002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am fairly new to DE, learning Python since December 2022, and coming from a non-tech background. I took part in the &lt;a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp\"&gt;DataTalksClub Zoomcamp&lt;/a&gt;. I started using these tools used in the project in January 2023.&lt;/p&gt;\n\n&lt;p&gt;Project link: &lt;a href=\"https://github.com/VincenzoGalante/magic-the-gathering\"&gt;GitHub repo for Magic: The Gathering&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Project background:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I used to play Magic: The Gathering a lot back in the 90s&lt;/li&gt;\n&lt;li&gt;I wanted to understand the game from a meta perspective and tried to answer questions that I was interested in&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Technologies used:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Infrastructure via terraform, and GCP as cloud&lt;/li&gt;\n&lt;li&gt;I read the &lt;a href=\"https://scryfall.com/\"&gt;scryfall API&lt;/a&gt; for card data&lt;/li&gt;\n&lt;li&gt;Push them to my storage bucket&lt;/li&gt;\n&lt;li&gt;Push needed data points to BigQuery &lt;/li&gt;\n&lt;li&gt;Transform the data there with DBT&lt;/li&gt;\n&lt;li&gt;Visualize the final dataset with &lt;a href=\"https://lookerstudio.google.com/u/0/reporting/ebdf68e1-27f7-435b-8add-a4018681f801\"&gt;Looker&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am somewhat proud to having finished this, as I never would have thought to learn all this. I did put a lot of long evenings, early mornings and weekends into this. In the future I plan to do more projects and apply for a Data Engineering  or Analytics Engineering position - preferably at my current company. &lt;/p&gt;\n\n&lt;p&gt;Please feel free to leave constructive feedback on code, visualization or any other part of the project. &lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83e\uddd9\ud83c\udffc\u200d\u2642\ufe0f \ud83d\udd2e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?auto=webp&amp;v=enabled&amp;s=83f6d7073810fc04132f56cb6694c8f9c77444c0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20b3bc67ee12567332a921735a377d6abcf31cf2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2de7559bc67fe76000812e3b1acc6538b606f281", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f8ee1b176c836306e11d6525413dc377e6e18ba", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12e9804b53447054fc055f12fc0bca009ef437a7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1367f27d01f625a055bba846dffd3b49683e94f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/UP24YQbevMeVQ7eAgprRRrdgDYnfm51aIMxYq-kKtAQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0031fac9c725d1e9b544a846b715262ae8d96a47", "width": 1080, "height": 540}], "variants": {}, "id": "ng8HCr_WX70Vc-qUwMn5fx44rorz4-R6-GD1-BLB9pM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data &amp; Analytics Engineer in training", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "11zh526", "is_robot_indexable": true, "report_reasons": null, "author": "binchentso", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11zh526/magic_the_gathering_dashboard_first_complete_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zh526/magic_the_gathering_dashboard_first_complete_de/", "subreddit_subscribers": 94086, "created_utc": 1679570002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on some personal projects and as some of you guys may have read my prior requests, I am new to this coming from a BI Analyst background.\n\nOne of my current projects, I working on a pipeline using python that will be containerized with docker. As of now, it's single table that is being pushed to cloud storage. I plan on the building a warehouse in Big Query to query off and of course create a dashboard. I had taken partially the DE Zoomcamp where we installed Terraform but I didn't complete it the camp. I'm sorry guys. \n\nI guess I am trying to figure out where Terrafrom or  infrastructure-as-code comes into play or whether for smaller projects if it's even necessary.", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Terraform necessary for personal projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z50in", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679536781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on some personal projects and as some of you guys may have read my prior requests, I am new to this coming from a BI Analyst background.&lt;/p&gt;\n\n&lt;p&gt;One of my current projects, I working on a pipeline using python that will be containerized with docker. As of now, it&amp;#39;s single table that is being pushed to cloud storage. I plan on the building a warehouse in Big Query to query off and of course create a dashboard. I had taken partially the DE Zoomcamp where we installed Terraform but I didn&amp;#39;t complete it the camp. I&amp;#39;m sorry guys. &lt;/p&gt;\n\n&lt;p&gt;I guess I am trying to figure out where Terrafrom or  infrastructure-as-code comes into play or whether for smaller projects if it&amp;#39;s even necessary.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11z50in", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11z50in/is_terraform_necessary_for_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11z50in/is_terraform_necessary_for_personal_projects/", "subreddit_subscribers": 94086, "created_utc": 1679536781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I\u2019m currently employed as a data analyst at a large F500 company and work on a very small team. I mainly use big query / tableau as well as mssql server to run reports / make dashboards. I would like to eventually try to transition my way into data engineering and I figured that learning how our data gets extracted and loaded into our databases would be a good starting point, in terms of context.\n\nHowever, my small \u201cteam\u201d is actually two different teams. I work with a few other people on the business side running reports / dashboarding, and the other team consists of software engineers that maintain  the etl (?) of the data, as well as other stuff I\u2019m not aware of. Our teams do no interact save for a few times a month we have a group meeting to talk about business problems.\n\nBecause I work for a large company, everything is locked behind ARP\u2019s, so I can\u2019t view anything that I do not have access to.\n\nI\u2019m not looking to play around with the processes as I realize that I don\u2019t have experience and could mess shit up, I am just curious about how it is done, so I can learn. I\u2019m not sure the best way to go about learning as I don\u2019t know if I can just ask people from the other team how they manage the data, if they would get annoyed or they have more important stuff to do. I\u2019m pretty new to the corporate world bc it\u2019s my first job out of college and I\u2019ve been here around 9 months.\n\nAny advice would be helpful, thanks.", "author_fullname": "t2_6kk09i634", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to understand data pipelines at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z25eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679538998.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679530334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m currently employed as a data analyst at a large F500 company and work on a very small team. I mainly use big query / tableau as well as mssql server to run reports / make dashboards. I would like to eventually try to transition my way into data engineering and I figured that learning how our data gets extracted and loaded into our databases would be a good starting point, in terms of context.&lt;/p&gt;\n\n&lt;p&gt;However, my small \u201cteam\u201d is actually two different teams. I work with a few other people on the business side running reports / dashboarding, and the other team consists of software engineers that maintain  the etl (?) of the data, as well as other stuff I\u2019m not aware of. Our teams do no interact save for a few times a month we have a group meeting to talk about business problems.&lt;/p&gt;\n\n&lt;p&gt;Because I work for a large company, everything is locked behind ARP\u2019s, so I can\u2019t view anything that I do not have access to.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not looking to play around with the processes as I realize that I don\u2019t have experience and could mess shit up, I am just curious about how it is done, so I can learn. I\u2019m not sure the best way to go about learning as I don\u2019t know if I can just ask people from the other team how they manage the data, if they would get annoyed or they have more important stuff to do. I\u2019m pretty new to the corporate world bc it\u2019s my first job out of college and I\u2019ve been here around 9 months.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be helpful, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11z25eb", "is_robot_indexable": true, "report_reasons": null, "author": "GiveMeThePinecone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11z25eb/trying_to_understand_data_pipelines_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11z25eb/trying_to_understand_data_pipelines_at_work/", "subreddit_subscribers": 94086, "created_utc": 1679530334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a legacy database (SQL Server) in which have some views and stored procedures that we maintain and update.\n\nWhat is the best practice to version control these views and stored procedures as well as creating PRs for the updates to review them before pushing them to production?", "author_fullname": "t2_a3lkw6g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PRs for views and stored procedures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yvujo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679517520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a legacy database (SQL Server) in which have some views and stored procedures that we maintain and update.&lt;/p&gt;\n\n&lt;p&gt;What is the best practice to version control these views and stored procedures as well as creating PRs for the updates to review them before pushing them to production?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yvujo", "is_robot_indexable": true, "report_reasons": null, "author": "nobel-001", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yvujo/prs_for_views_and_stored_procedures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yvujo/prs_for_views_and_stored_procedures/", "subreddit_subscribers": 94086, "created_utc": 1679517520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any interest in this group for supporting shared data sets?  It's a DE's mission to make data available for other people.  We're replicating the same work, and we're not self serving.\n\nHow many people here have considered pulling MCC codes out of PDFs or some rando's github?  Besides being incomplete and unmaintained, it's lacking peer review. \n\nThere are many public datasets with paywalls or without good origins:\n\n* MCC Codes\n* Geoip \n* Zipcode\n* BLS-esk data/Market information\n* Data Engineering Jobs / metrics", "author_fullname": "t2_14x8l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared DE Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yre5o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679508650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any interest in this group for supporting shared data sets?  It&amp;#39;s a DE&amp;#39;s mission to make data available for other people.  We&amp;#39;re replicating the same work, and we&amp;#39;re not self serving.&lt;/p&gt;\n\n&lt;p&gt;How many people here have considered pulling MCC codes out of PDFs or some rando&amp;#39;s github?  Besides being incomplete and unmaintained, it&amp;#39;s lacking peer review. &lt;/p&gt;\n\n&lt;p&gt;There are many public datasets with paywalls or without good origins:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MCC Codes&lt;/li&gt;\n&lt;li&gt;Geoip &lt;/li&gt;\n&lt;li&gt;Zipcode&lt;/li&gt;\n&lt;li&gt;BLS-esk data/Market information&lt;/li&gt;\n&lt;li&gt;Data Engineering Jobs / metrics&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yre5o", "is_robot_indexable": true, "report_reasons": null, "author": "rovertus", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yre5o/shared_de_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yre5o/shared_de_datasets/", "subreddit_subscribers": 94086, "created_utc": 1679508650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 Best Data Engineering Projects &amp; Ideas for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11zdr4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ndf90pibFNltR724a-NNtXVmXs8OoFKEluY087o0fQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679560183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "trendsmezone.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.trendsmezone.com/5-best-data-engineering-projects-ideas-for-beginners/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mSMLu5cSJkK_VBMCFz6ZINstwuznP-r40MQZLi8qbPs.jpg?auto=webp&amp;v=enabled&amp;s=bf56ea637ba18f8721b11011af6af19ec83a1982", "width": 300, "height": 169}, "resolutions": [{"url": "https://external-preview.redd.it/mSMLu5cSJkK_VBMCFz6ZINstwuznP-r40MQZLi8qbPs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=965aebbc1cabdebdde54bfd89e7a555b24c94128", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/mSMLu5cSJkK_VBMCFz6ZINstwuznP-r40MQZLi8qbPs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44f67da1aa361a5eaa13b373a6b3e584f14944ec", "width": 216, "height": 121}], "variants": {}, "id": "Fa0T0c5UNPZGrMIf2qhKNVtzwo7DGRHlKz--XeEHBEo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11zdr4c", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zdr4c/5_best_data_engineering_projects_ideas_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.trendsmezone.com/5-best-data-engineering-projects-ideas-for-beginners/", "subreddit_subscribers": 94086, "created_utc": 1679560183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im at a new job with lots of dispirate databases that is trying to create an analytics database with one sole source of truth. Its an extremely old school manufacturer that is trying to get into having an analytics cloud to set their prices. Of the 5 major options(Snowflake, Databricks, AWS, Azure and Google) which one would you set the database up in?  Right now they have flows in alteryx that go to one off datamarts in postgres with no real structure. \n\nLet me know your thoughts", "author_fullname": "t2_6ra3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IF you were to start from scratch what tech would you use.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yjs1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679493175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im at a new job with lots of dispirate databases that is trying to create an analytics database with one sole source of truth. Its an extremely old school manufacturer that is trying to get into having an analytics cloud to set their prices. Of the 5 major options(Snowflake, Databricks, AWS, Azure and Google) which one would you set the database up in?  Right now they have flows in alteryx that go to one off datamarts in postgres with no real structure. &lt;/p&gt;\n\n&lt;p&gt;Let me know your thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yjs1x", "is_robot_indexable": true, "report_reasons": null, "author": "deemerritt", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yjs1x/if_you_were_to_start_from_scratch_what_tech_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yjs1x/if_you_were_to_start_from_scratch_what_tech_would/", "subreddit_subscribers": 94086, "created_utc": 1679493175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So once the physical data model is forwarded engineered into actual tables in a database, how are the relationships between the tables created? is there any actual connection between the newly tables as shown in the ERD? for example, take a simple two table diagram with a relationship drawn between them, how will this connection relationship actualize in the database?", "author_fullname": "t2_6mct0oth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumb Data Modeling Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11z2sk3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679531754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So once the physical data model is forwarded engineered into actual tables in a database, how are the relationships between the tables created? is there any actual connection between the newly tables as shown in the ERD? for example, take a simple two table diagram with a relationship drawn between them, how will this connection relationship actualize in the database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11z2sk3", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Baseball89", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11z2sk3/dumb_data_modeling_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11z2sk3/dumb_data_modeling_question/", "subreddit_subscribers": 94086, "created_utc": 1679531754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good day to you amazing folks in data, I am learning a lot from the conversations in this community. Thank you all for all the engagement.\n\nAs a data product lead developing a course on data product management, I want to learn about your experience working with data product managers.\n\nI am going to ask a few super open ended questions and follow the discussion:\n\nIf you are in a team where there are product managers, how is your experience working with product managers?\n\n* What are the top 3 benefits that you have experienced of having product managers in the group?\n* What are the top 3 challenges that you have experienced of having product managers in the group?\n* What does your interactions look like with the product managers on your teams?\n* How do you communicate? - how often, around what topics\n* As data engineers, do you have a vision for how you think a world with or without product managers should progress to help realize the outcomes that\n   * you are pursuing in your career\n   * the business is expecting from the data\n   * the customers are looking for in the data product\n\nLooking forward to your thoughts and commentary on this one.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with data product managers and data as a product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yr6h0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679508247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day to you amazing folks in data, I am learning a lot from the conversations in this community. Thank you all for all the engagement.&lt;/p&gt;\n\n&lt;p&gt;As a data product lead developing a course on data product management, I want to learn about your experience working with data product managers.&lt;/p&gt;\n\n&lt;p&gt;I am going to ask a few super open ended questions and follow the discussion:&lt;/p&gt;\n\n&lt;p&gt;If you are in a team where there are product managers, how is your experience working with product managers?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are the top 3 benefits that you have experienced of having product managers in the group?&lt;/li&gt;\n&lt;li&gt;What are the top 3 challenges that you have experienced of having product managers in the group?&lt;/li&gt;\n&lt;li&gt;What does your interactions look like with the product managers on your teams?&lt;/li&gt;\n&lt;li&gt;How do you communicate? - how often, around what topics&lt;/li&gt;\n&lt;li&gt;As data engineers, do you have a vision for how you think a world with or without product managers should progress to help realize the outcomes that\n\n&lt;ul&gt;\n&lt;li&gt;you are pursuing in your career&lt;/li&gt;\n&lt;li&gt;the business is expecting from the data&lt;/li&gt;\n&lt;li&gt;the customers are looking for in the data product&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Looking forward to your thoughts and commentary on this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yr6h0", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yr6h0/working_with_data_product_managers_and_data_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yr6h0/working_with_data_product_managers_and_data_as_a/", "subreddit_subscribers": 94086, "created_utc": 1679508247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently tried and tired of aqua data studio and dbeaver for postgres and Click house. Are there any better alternatives? What do you use?", "author_fullname": "t2_6zaja793", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are better sql ides for postgres and click house?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yqa5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679506662.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679506475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently tried and tired of aqua data studio and dbeaver for postgres and Click house. Are there any better alternatives? What do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yqa5r", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious_Cucumber96", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yqa5r/what_are_better_sql_ides_for_postgres_and_click/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yqa5r/what_are_better_sql_ides_for_postgres_and_click/", "subreddit_subscribers": 94086, "created_utc": 1679506475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interested to hear stories of people using Iceberg in production, been looking into it and keen to hear some success and failure stories\n\nHow was the state of your data pre and post Iceberg? \n\nWhat (if any) specific problems did it solve; has it made your data management easier in any way?\n\nWhat was the deployment overhead?", "author_fullname": "t2_k7hdbro6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg in production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yywaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679523602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interested to hear stories of people using Iceberg in production, been looking into it and keen to hear some success and failure stories&lt;/p&gt;\n\n&lt;p&gt;How was the state of your data pre and post Iceberg? &lt;/p&gt;\n\n&lt;p&gt;What (if any) specific problems did it solve; has it made your data management easier in any way?&lt;/p&gt;\n\n&lt;p&gt;What was the deployment overhead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yywaw", "is_robot_indexable": true, "report_reasons": null, "author": "Still-Mango8469", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yywaw/apache_iceberg_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yywaw/apache_iceberg_in_production/", "subreddit_subscribers": 94086, "created_utc": 1679523602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a small suite of python scripts for extracting data from SaaS APIs and loading it into our data lake.  It generally works ok.  But I'm trying to make the process as robust as possible.  \n\nCan anyone recommend any blogs, articles or example code that highlights best practices for using python for E/L?\n\nMy googling typically comes back with either hits for python ETL frameworks like petl, or basic introductory stuff.", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yvrfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679517343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a small suite of python scripts for extracting data from SaaS APIs and loading it into our data lake.  It generally works ok.  But I&amp;#39;m trying to make the process as robust as possible.  &lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend any blogs, articles or example code that highlights best practices for using python for E/L?&lt;/p&gt;\n\n&lt;p&gt;My googling typically comes back with either hits for python ETL frameworks like petl, or basic introductory stuff.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11yvrfs", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yvrfs/python_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yvrfs/python_best_practices/", "subreddit_subscribers": 94086, "created_utc": 1679517343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Guys, I was just wondering on the best approach to add missing attributes to the dynamic json based on schema. The schema i\u2019m using is pretty large (&gt;1000 lines). I\u2019m trying to add missing attributes to the dynamic json payload that I\u2019m getting from an API based off of this schema. Any input is much appreciated. Thank you.", "author_fullname": "t2_d9h3fwrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding attributes to dynamic json based on schema through PySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yrbq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679508532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys, I was just wondering on the best approach to add missing attributes to the dynamic json based on schema. The schema i\u2019m using is pretty large (&amp;gt;1000 lines). I\u2019m trying to add missing attributes to the dynamic json payload that I\u2019m getting from an API based off of this schema. Any input is much appreciated. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11yrbq5", "is_robot_indexable": true, "report_reasons": null, "author": "Franknstein26", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yrbq5/adding_attributes_to_dynamic_json_based_on_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yrbq5/adding_attributes_to_dynamic_json_based_on_schema/", "subreddit_subscribers": 94086, "created_utc": 1679508532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have several dags and each dag uses mainly KubernetesPodOperator to run some data processing apps in our on-prem Kubernetes cluster (same as Airflow is in). I would like to have an option to run some of the tasks also in cloud. I was thinking of maybe providing different cluster-context to the Operator which would point to the cloud instance of Kubernetes cluster? Does that makes sense? \n\nOr I thought of instead of running the tasks as containers, run it in AWS Lambda but that would require rewriting of the dag and also I am not sure how I would pass the actual app to the lambda to be executed (probably path to repo so Lambda would clone and run it?). Any ideas?\n\nPS. On question \u201cwhy?\u201d: sometimes when backfilling long history we would need to speedup the process - therefore use more resources from the cloud.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping Airflow tasks \u201ccloud-native\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11zczvt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679557889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have several dags and each dag uses mainly KubernetesPodOperator to run some data processing apps in our on-prem Kubernetes cluster (same as Airflow is in). I would like to have an option to run some of the tasks also in cloud. I was thinking of maybe providing different cluster-context to the Operator which would point to the cloud instance of Kubernetes cluster? Does that makes sense? &lt;/p&gt;\n\n&lt;p&gt;Or I thought of instead of running the tasks as containers, run it in AWS Lambda but that would require rewriting of the dag and also I am not sure how I would pass the actual app to the lambda to be executed (probably path to repo so Lambda would clone and run it?). Any ideas?&lt;/p&gt;\n\n&lt;p&gt;PS. On question \u201cwhy?\u201d: sometimes when backfilling long history we would need to speedup the process - therefore use more resources from the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11zczvt", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zczvt/keeping_airflow_tasks_cloudnative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zczvt/keeping_airflow_tasks_cloudnative/", "subreddit_subscribers": 94086, "created_utc": 1679557889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT with DuckDB and CloudQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yqfaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1679506763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/exploring-api-data-with-duckdb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11yqfaj", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yqfaj/elt_with_duckdb_and_cloudquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/exploring-api-data-with-duckdb", "subreddit_subscribers": 94086, "created_utc": 1679506763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am trying to set two variables in a snowflake worksheet.\n\nLastT = date of last Thursday \nLastLastT = date of Thursday from last year for same week \n\nCould anybody give me some help?\n\nIn sas I coded this as\nLet lastT = sysfunc(putn(sysfunc(intnx(week.5,(sysfunc(today())),date9.));", "author_fullname": "t2_7xrbvyn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake: Date Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yit7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679490886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am trying to set two variables in a snowflake worksheet.&lt;/p&gt;\n\n&lt;p&gt;LastT = date of last Thursday \nLastLastT = date of Thursday from last year for same week &lt;/p&gt;\n\n&lt;p&gt;Could anybody give me some help?&lt;/p&gt;\n\n&lt;p&gt;In sas I coded this as\nLet lastT = sysfunc(putn(sysfunc(intnx(week.5,(sysfunc(today())),date9.));&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11yit7c", "is_robot_indexable": true, "report_reasons": null, "author": "KMG3IU", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yit7c/snowflake_date_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yit7c/snowflake_date_functions/", "subreddit_subscribers": 94086, "created_utc": 1679490886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have received a software-data engineering project. And I need some advice on the best practices for it. I am using Asp .net core for backend, Angular TS for Frontend and MSSQL Server for DB. The project infrastructure is built on Azure. There are two websites. One with public access logs in through AADB2C. \nThe other website Is for internal organization members and uses Azure AD for login. The repo is configured with CI/CD to the app services and sql db using Azure Devops yaml pipelines.\n\nEarlier the web application was used just by a set of people in England. Now this new project is like an extension of it at the global level. So there's an office of this international organization in US, Australia, France and the organization wants that each team in different regions will have access to their own country's data. Like internal teams would see transactions for their own country onlyonly on UI. Data from different dbs could be stored in a DW later for reporting purposes. The manager has the privilege to explore the data for different regions by having accessing to different parts of the website.\n\n\nI came up with the understanding of the architecture for it. Single tenant application but having different dbs depending on regions. Ill configure my .net app with repository manager to handle multiple dbs in runtime. But in a recent meeting they said that the functionality of the web system may also change depending on how different teams from different countries want the transaction workflow to be. This has confused me like they want a single website but for different regions which could have different functionalities. I really need help from senior software/data engineers regarding what is the best approach to follow for setting up the infrastructure for such project. What kind of db approach should I use. Can I handle tbis project with a single db? Will the deployment processs be affected? I heard theres something called containerized deployment. What tools I may need to use additionally If needed and What things to keep in mind.\n\n\nThanks, I'll appreciate any response.", "author_fullname": "t2_7wrmlk77", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi regional web application having separate databases and user data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11zjfyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679575905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have received a software-data engineering project. And I need some advice on the best practices for it. I am using Asp .net core for backend, Angular TS for Frontend and MSSQL Server for DB. The project infrastructure is built on Azure. There are two websites. One with public access logs in through AADB2C. \nThe other website Is for internal organization members and uses Azure AD for login. The repo is configured with CI/CD to the app services and sql db using Azure Devops yaml pipelines.&lt;/p&gt;\n\n&lt;p&gt;Earlier the web application was used just by a set of people in England. Now this new project is like an extension of it at the global level. So there&amp;#39;s an office of this international organization in US, Australia, France and the organization wants that each team in different regions will have access to their own country&amp;#39;s data. Like internal teams would see transactions for their own country onlyonly on UI. Data from different dbs could be stored in a DW later for reporting purposes. The manager has the privilege to explore the data for different regions by having accessing to different parts of the website.&lt;/p&gt;\n\n&lt;p&gt;I came up with the understanding of the architecture for it. Single tenant application but having different dbs depending on regions. Ill configure my .net app with repository manager to handle multiple dbs in runtime. But in a recent meeting they said that the functionality of the web system may also change depending on how different teams from different countries want the transaction workflow to be. This has confused me like they want a single website but for different regions which could have different functionalities. I really need help from senior software/data engineers regarding what is the best approach to follow for setting up the infrastructure for such project. What kind of db approach should I use. Can I handle tbis project with a single db? Will the deployment processs be affected? I heard theres something called containerized deployment. What tools I may need to use additionally If needed and What things to keep in mind.&lt;/p&gt;\n\n&lt;p&gt;Thanks, I&amp;#39;ll appreciate any response.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11zjfyr", "is_robot_indexable": true, "report_reasons": null, "author": "Spare_Barracuda7631", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zjfyr/multi_regional_web_application_having_separate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zjfyr/multi_regional_web_application_having_separate/", "subreddit_subscribers": 94086, "created_utc": 1679575905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As new Arrow-based and server-less products drive in-memory pipelines back into the limelight, I've been thinking about how I can keep tabs on memory usage during dev and execution.\n\nI've used the databricks SparkUI a lot to check for spill, skew etc, but now I'm seeing more recommendations for pulling data out of databases, writing to storage as parquet or delta files and rather than coordinating a cluster of overhead, querying the data with a Fargate task and a python script. This approach doesn't come with a SparkUI.\n\nI thought about attempting this recently on a moderate 8M row / 8GB postgres table requiring some pretty serious queries and just wanted to measure memory usage the same as as timing. \n\nI'm aware of the memory-profiler module, but before I'll have time to dig into it, I'm keen to know what/if you're watching your mem usage within job runs?", "author_fullname": "t2_so5msnka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How/Do you measure memory usage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11zftvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679566425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As new Arrow-based and server-less products drive in-memory pipelines back into the limelight, I&amp;#39;ve been thinking about how I can keep tabs on memory usage during dev and execution.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used the databricks SparkUI a lot to check for spill, skew etc, but now I&amp;#39;m seeing more recommendations for pulling data out of databases, writing to storage as parquet or delta files and rather than coordinating a cluster of overhead, querying the data with a Fargate task and a python script. This approach doesn&amp;#39;t come with a SparkUI.&lt;/p&gt;\n\n&lt;p&gt;I thought about attempting this recently on a moderate 8M row / 8GB postgres table requiring some pretty serious queries and just wanted to measure memory usage the same as as timing. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware of the memory-profiler module, but before I&amp;#39;ll have time to dig into it, I&amp;#39;m keen to know what/if you&amp;#39;re watching your mem usage within job runs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11zftvl", "is_robot_indexable": true, "report_reasons": null, "author": "Playful_Rate31", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zftvl/howdo_you_measure_memory_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zftvl/howdo_you_measure_memory_usage/", "subreddit_subscribers": 94086, "created_utc": 1679566425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "They're advertising as an open source direct competitor with Snowflake, with the ability to store data in parquet files. Github repo (5.6k stars) [here](https://github.com/datafuselabs/databend).\n\nOn the face of it, it seems like a data lakehouse that doesn't need spark.\n\nHas anyone had a play with it, or got access to the private beta cloud offering? Curious to know what your thoughts are. \n\nP.S. if you work for Databend, and can fast-track my private beta request and get me an access code, that would be awesome!", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have experience with Databend (local or cloud)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11zflzc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679565800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They&amp;#39;re advertising as an open source direct competitor with Snowflake, with the ability to store data in parquet files. Github repo (5.6k stars) &lt;a href=\"https://github.com/datafuselabs/databend\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;On the face of it, it seems like a data lakehouse that doesn&amp;#39;t need spark.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had a play with it, or got access to the private beta cloud offering? Curious to know what your thoughts are. &lt;/p&gt;\n\n&lt;p&gt;P.S. if you work for Databend, and can fast-track my private beta request and get me an access code, that would be awesome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?auto=webp&amp;v=enabled&amp;s=d1a26bd6af2a22e2ff1bcb415da34e7840b9d08f", "width": 1279, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a692d465013b766cc1080df43c5660f367bc1c3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f98d48a1af9262163ee6d698e9885118a75ff3c0", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cc7756e1519fe822588d4903b182613107e2e8c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9ea3d44e44aa85455bf5e49f7b225f5ed1de099", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6dd6dc0e5b4542387b5db4a0f677e24e5f920241", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/oa-JFz6w0DTRQIg8NbFrSyV4PYwiE-PJR2ohCYPtUgE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b26658f94a9d3445725b206ab895b4bf0bb9770", "width": 1080, "height": 540}], "variants": {}, "id": "VJU9D7fLYfxUSbrNEIB8bYqirFg5E0yxPKNjTH6EscY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11zflzc", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zflzc/anyone_have_experience_with_databend_local_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zflzc/anyone_have_experience_with_databend_local_or/", "subreddit_subscribers": 94086, "created_utc": 1679565800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are using AWS'  Database Migration Service to integrate various sources like oracle, mysql, etc... into the cloud (Databricks/AWS). In the development phase we need to test each table. This means to run several easy statements to see if e.g. the row count matches, insert/update/delete is working as it is supposed to be.\n\nIn the very first beginning we had to run these statements manually, for each and every table. This process, which is not only redundant, extremeley time consuming (took us 2-3 hours per table) but just blatantly time/money wasting. So, as first improvement, one of the devs coded a python script that should automate the majority of this process. But, sometimes we spend the most time on reporting bugs of this script, rather than saving time.\n\nSo, my question is, is there any framework that helps us to unit test this correct db onboaring to Databricks/AWS? Something that let's me easily write these tests, connect source and Databricks to talk to each other, simply run these test once/on schedule?", "author_fullname": "t2_4fb1g9yu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Unit Testing framework in Database Migration Process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11zbwv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679559279.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679554618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are using AWS&amp;#39;  Database Migration Service to integrate various sources like oracle, mysql, etc... into the cloud (Databricks/AWS). In the development phase we need to test each table. This means to run several easy statements to see if e.g. the row count matches, insert/update/delete is working as it is supposed to be.&lt;/p&gt;\n\n&lt;p&gt;In the very first beginning we had to run these statements manually, for each and every table. This process, which is not only redundant, extremeley time consuming (took us 2-3 hours per table) but just blatantly time/money wasting. So, as first improvement, one of the devs coded a python script that should automate the majority of this process. But, sometimes we spend the most time on reporting bugs of this script, rather than saving time.&lt;/p&gt;\n\n&lt;p&gt;So, my question is, is there any framework that helps us to unit test this correct db onboaring to Databricks/AWS? Something that let&amp;#39;s me easily write these tests, connect source and Databricks to talk to each other, simply run these test once/on schedule?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11zbwv5", "is_robot_indexable": true, "report_reasons": null, "author": "cptstoneee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11zbwv5/looking_for_unit_testing_framework_in_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11zbwv5/looking_for_unit_testing_framework_in_database/", "subreddit_subscribers": 94086, "created_utc": 1679554618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am tempted to choose the meme flair but that would be unkind!\n\nhttps://preview.redd.it/ncccykle0fpa1.png?width=716&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=107b8db83dc91fafdd603a898f1a778822f8fe0d", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on this Fivetran + DBT + Snowflake query?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ncccykle0fpa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 128, "x": 108, "u": "https://preview.redd.it/ncccykle0fpa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63c44ec23a489540f890ed070f0c4dc3908663d0"}, {"y": 256, "x": 216, "u": "https://preview.redd.it/ncccykle0fpa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=325959af477bd6f3d3532e8f1879c7e6f160145a"}, {"y": 379, "x": 320, "u": "https://preview.redd.it/ncccykle0fpa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e3bd221f895eb787e720f7ce62de32b4799e2cb"}, {"y": 758, "x": 640, "u": "https://preview.redd.it/ncccykle0fpa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=673e14bbbf3d1a1016d85e9e8a3a2c2f183d5545"}], "s": {"y": 849, "x": 716, "u": "https://preview.redd.it/ncccykle0fpa1.png?width=716&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=107b8db83dc91fafdd603a898f1a778822f8fe0d"}, "id": "ncccykle0fpa1"}}, "name": "t3_11z8jp4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9a0bf6Fh7D-aSI0QjLiSKxNIzXNI0MCd-DP6j2Uo9rA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679545197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am tempted to choose the meme flair but that would be unkind!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ncccykle0fpa1.png?width=716&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=107b8db83dc91fafdd603a898f1a778822f8fe0d\"&gt;https://preview.redd.it/ncccykle0fpa1.png?width=716&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=107b8db83dc91fafdd603a898f1a778822f8fe0d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11z8jp4", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11z8jp4/what_are_your_thoughts_on_this_fivetran_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11z8jp4/what_are_your_thoughts_on_this_fivetran_dbt/", "subreddit_subscribers": 94086, "created_utc": 1679545197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good day,\n\nFor anyone using databricks, how do you handle \"test\" data in production systems? Do you filter the test records in silver layer or create new data models in gold layer with test data filtered out? Thanks", "author_fullname": "t2_77mz0n8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle test data in production db?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yupcg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679515195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day,&lt;/p&gt;\n\n&lt;p&gt;For anyone using databricks, how do you handle &amp;quot;test&amp;quot; data in production systems? Do you filter the test records in silver layer or create new data models in gold layer with test data filtered out? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11yupcg", "is_robot_indexable": true, "report_reasons": null, "author": "Programmer_Virtual", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11yupcg/how_do_you_handle_test_data_in_production_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11yupcg/how_do_you_handle_test_data_in_production_db/", "subreddit_subscribers": 94086, "created_utc": 1679515195.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}