{"kind": "Listing", "data": {"after": "t3_11gl11f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.", "author_fullname": "t2_da67df26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Unprofessional to leave after a year?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gh1yv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 280, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 280, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gh1yv", "is_robot_indexable": true, "report_reasons": null, "author": "Subject-Resort5893", "discussion_type": null, "num_comments": 159, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "subreddit_subscribers": 853493, "created_utc": 1677795987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: [**quix-streams**](https://github.com/quixio/quix-streams))   \nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: \n\n    def on_parameter_data_handler(df: pd.DataFrame):\n    \n        # If the braking force applied is more than 50%, we mark HardBraking with True\n        df[\"HardBraking\"] = df.apply(lambda row: \"True\" if row.Brake &gt; 0.5 else \"False\", axis=1)\n    \n        stream_producer.timeseries.publish(df)  # Send data back to the stream\n\n Anyway, just posting it here with the hope that it makes someone\u2019s job easier.", "author_fullname": "t2_byx12w8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A more accessible python library for interacting with Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g68dw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: &lt;a href=\"https://github.com/quixio/quix-streams\"&gt;&lt;strong&gt;quix-streams&lt;/strong&gt;&lt;/a&gt;)&lt;br/&gt;\nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def on_parameter_data_handler(df: pd.DataFrame):\n\n    # If the braking force applied is more than 50%, we mark HardBraking with True\n    df[&amp;quot;HardBraking&amp;quot;] = df.apply(lambda row: &amp;quot;True&amp;quot; if row.Brake &amp;gt; 0.5 else &amp;quot;False&amp;quot;, axis=1)\n\n    stream_producer.timeseries.publish(df)  # Send data back to the stream\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Anyway, just posting it here with the hope that it makes someone\u2019s job easier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?auto=webp&amp;v=enabled&amp;s=78d5675a84f6726e7618cd3c42250b7d51c363fa", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13a6a9b0f62ec4033e162a3122ec7f912271ca6a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc65e91fc8010c02faecf87eb3e910a374973c22", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42f0e4e73e3e4a79267bd8b98e97ca66836c96e6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19838c0ac27c309b1e866cc3aaae3b447bdd9671", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7215b5d40310d21d5d1e4a91848bac7d3147f437", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fdcf5eafb0a7070f4aea6e4bdfacc90c0c14c34d", "width": 1080, "height": 540}], "variants": {}, "id": "ZuoT62YF_0noD68oqz7qPsTsv9obcPgozqhj0lnVZyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g68dw", "is_robot_indexable": true, "report_reasons": null, "author": "Jota_Blanco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "subreddit_subscribers": 853493, "created_utc": 1677772668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a master\u2019s degree in computer science from a top school in USA. I have a gpa of 3.9 and internship experience in data science where I worked on healthcare data. I\u2019m all in all a pretty smart dude, although I hate to admit it. I have good creative thinking, I have good communication skills, I also did the google data analytics certification to become \u201cjob ready\u201d whatever that means. On paper, I feel like I\u2019m a half decent candidate. Yet, I\u2019m finding job search incredibly challenging. I am ready to work in data analytics or data science, I am graduating this spring and I am applying to so many positions and getting rejected constantly. Being an international student, I know that most job\u2019s aren\u2019t open for me. But not getting a single interview except a few scam callers, is extremely demotivating. What am I doing wrong? And how can I improve my job search? These constant rejections have taken a huge toll on my health and wellbeing. Any help is appreciated. I have attached my resume for reference.\n\n[click me for resume](https://drive.google.com/file/d/1ODaok5gjNXwxiR29kZWhF8U226w8KaUg/view?usp=drivesdk)", "author_fullname": "t2_11otp57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job search is making me lose my mind", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gi0vc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677797036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a master\u2019s degree in computer science from a top school in USA. I have a gpa of 3.9 and internship experience in data science where I worked on healthcare data. I\u2019m all in all a pretty smart dude, although I hate to admit it. I have good creative thinking, I have good communication skills, I also did the google data analytics certification to become \u201cjob ready\u201d whatever that means. On paper, I feel like I\u2019m a half decent candidate. Yet, I\u2019m finding job search incredibly challenging. I am ready to work in data analytics or data science, I am graduating this spring and I am applying to so many positions and getting rejected constantly. Being an international student, I know that most job\u2019s aren\u2019t open for me. But not getting a single interview except a few scam callers, is extremely demotivating. What am I doing wrong? And how can I improve my job search? These constant rejections have taken a huge toll on my health and wellbeing. Any help is appreciated. I have attached my resume for reference.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/file/d/1ODaok5gjNXwxiR29kZWhF8U226w8KaUg/view?usp=drivesdk\"&gt;click me for resume&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?auto=webp&amp;v=enabled&amp;s=01f44c2bcbd2a6338da12a4f437fe002d69be2d0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ed78f1f45c3be2ecd96db039907171f8daca74", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7aefa9ef4909a73e136a59c8df00ef54d4017f63", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e977f7ac48cb854bd59f24283417a7694a3a69a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4c5ded83d7c0f4772e89cc7027055bba93c7f82", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75d98a415b6247233b72ee58675578413837dbbb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c2972b092f69fd542992a86955bf25808f036d6", "width": 1080, "height": 567}], "variants": {}, "id": "hxU87z_CxEKc-ClNMKtxEK2A4X4IRz7rjk3ifiq6hwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gi0vc", "is_robot_indexable": true, "report_reasons": null, "author": "ryanhiga2019", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gi0vc/job_search_is_making_me_lose_my_mind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gi0vc/job_search_is_making_me_lose_my_mind/", "subreddit_subscribers": 853493, "created_utc": 1677797036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.\n\nI am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.\n\nThere seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.\n\nHere\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.\n\nDo I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.\n\nTL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?", "author_fullname": "t2_zeb0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Dashboard Solution, leaning Dash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ggw1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.&lt;/p&gt;\n\n&lt;p&gt;I am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.&lt;/p&gt;\n\n&lt;p&gt;There seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.&lt;/p&gt;\n\n&lt;p&gt;Do I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ggw1n", "is_robot_indexable": true, "report_reasons": null, "author": "GeneCreemers69", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "subreddit_subscribers": 853493, "created_utc": 1677795812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We have a model that's trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.\n\nProblem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn't too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. \n\nBut, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can't say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won't have to impute the missing values?\n\nAny tips would be highly appreciated \ud83d\ude4f", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Missing data related", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g8u9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677778919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a model that&amp;#39;s trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.&lt;/p&gt;\n\n&lt;p&gt;Problem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn&amp;#39;t too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. &lt;/p&gt;\n\n&lt;p&gt;But, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can&amp;#39;t say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won&amp;#39;t have to impute the missing values?&lt;/p&gt;\n\n&lt;p&gt;Any tips would be highly appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g8u9w", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g8u9w/missing_data_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g8u9w/missing_data_related/", "subreddit_subscribers": 853493, "created_utc": 1677778919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I've found out that it doesn't give the same model parameters.", "author_fullname": "t2_6zlc2ji4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing for RMSE vs. R2, for feature selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g416x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I&amp;#39;ve found out that it doesn&amp;#39;t give the same model parameters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g416x", "is_robot_indexable": true, "report_reasons": null, "author": "dilkur", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "subreddit_subscribers": 853493, "created_utc": 1677767070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey All--\n\nHas anyone tried taking any SWE or DevOps courses for DS/ML?\n\nI've noticed that the field is moving in that direction and want to prepare for that shift as best I can. It's also probably my weakest area.", "author_fullname": "t2_vhqp49rd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DevOps or SWE Courses for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnghl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All--&lt;/p&gt;\n\n&lt;p&gt;Has anyone tried taking any SWE or DevOps courses for DS/ML?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve noticed that the field is moving in that direction and want to prepare for that shift as best I can. It&amp;#39;s also probably my weakest area.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnghl", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Sky-6190", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "subreddit_subscribers": 853493, "created_utc": 1677807340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m excited to share **ActiveLab**, a better algorithm for practical active learning.\n\nhttps://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441\n\nWe recently published a [paper](https://arxiv.org/abs/2301.11856) introducing this novel method and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we've made a quick [Jupyter tutorial](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) to run ActiveLab on your own data. For ML researchers, we've made all of our [benchmarking code](https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks) available for reproducibility so you can see for yourself how effective ActiveLab is in practice.\n\nLabeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: **which new data should I label, or which of my current labels should be checked again?**\n\nhttps://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532\n\nActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).\n\nIf you're interested in reading more, check out our blogpost: [https://cleanlab.ai/blog/active-learning/](https://cleanlab.ai/blog/active-learning/)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ActiveLab: Active Learning with Data Re-Labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": false, "media_metadata": {"txcqiokmndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/txcqiokmndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7d8d67e9a27f3e9285d527d97e3e4eb02745a31"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/txcqiokmndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e76a85cb7aed17de368f294442b8ebaf67689a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/txcqiokmndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58229ab58467ee7a78e93c80393f1add5197ce9d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/txcqiokmndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef92c312f65f5cb27f47322c13cd7da812bc331"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f7dc49616689bbf2494f80cdef7b794eb239377"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532"}, "id": "txcqiokmndla1"}, "j2payaxlndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/j2payaxlndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01d685cfe0e84c7330b2a6c8539f6a4962a6f49f"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/j2payaxlndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee839ef82870e92011aa669f688ae342c0ccfe5a"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/j2payaxlndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01bb7951a8dd486e1fcb47e6afa8342c061092cb"}, {"y": 521, "x": 640, "u": "https://preview.redd.it/j2payaxlndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32109a8f100ca18f84d51c80feaf5f12e7cbde28"}, {"y": 782, "x": 960, "u": "https://preview.redd.it/j2payaxlndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=376c6267681605bba52a5b4571dd3b35efa4c285"}, {"y": 879, "x": 1080, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcdddc82c386ea077c6ab26e82746573fb30e394"}], "s": {"y": 1258, "x": 1544, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441"}, "id": "j2payaxlndla1"}}, "name": "t3_11gbjgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvoqFpUhmlzuenpEc3NFwOVAKwdWZiUsqZ7tUQ83SYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677785412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m excited to share &lt;strong&gt;ActiveLab&lt;/strong&gt;, a better algorithm for practical active learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441\"&gt;https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We recently published a &lt;a href=\"https://arxiv.org/abs/2301.11856\"&gt;paper&lt;/a&gt; introducing this novel method and an &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;open-source&lt;/a&gt; Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we&amp;#39;ve made a quick &lt;a href=\"https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb\"&gt;Jupyter tutorial&lt;/a&gt; to run ActiveLab on your own data. For ML researchers, we&amp;#39;ve made all of our &lt;a href=\"https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks\"&gt;benchmarking code&lt;/a&gt; available for reproducibility so you can see for yourself how effective ActiveLab is in practice.&lt;/p&gt;\n\n&lt;p&gt;Labeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: &lt;strong&gt;which new data should I label, or which of my current labels should be checked again?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532\"&gt;https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in reading more, check out our blogpost: &lt;a href=\"https://cleanlab.ai/blog/active-learning/\"&gt;https://cleanlab.ai/blog/active-learning/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbjgm", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "subreddit_subscribers": 853493, "created_utc": 1677785412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.\n\nEDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.", "author_fullname": "t2_bvyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/Cons of Moving over to Exclusively Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbv79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.&lt;/p&gt;\n\n&lt;p&gt;EDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbv79", "is_robot_indexable": true, "report_reasons": null, "author": "robml", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "subreddit_subscribers": 853493, "created_utc": 1677786167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tl;dr: **How \"static\" should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?**\n\nFor example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?\n\n\\---\n\nI was having an argument with a colleague of mine where he argued the point *that a new holdout dataset should be created every time we train a new model*, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.\n\nHis reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn't make sense.\n\nMy argument was *in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time*. \n\nMy reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.", "author_fullname": "t2_u1cec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How \"static\" should holdout datasets be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g60h8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr: &lt;strong&gt;How &amp;quot;static&amp;quot; should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I was having an argument with a colleague of mine where he argued the point &lt;em&gt;that a new holdout dataset should be created every time we train a new model&lt;/em&gt;, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.&lt;/p&gt;\n\n&lt;p&gt;His reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn&amp;#39;t make sense.&lt;/p&gt;\n\n&lt;p&gt;My argument was &lt;em&gt;in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;My reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g60h8", "is_robot_indexable": true, "report_reasons": null, "author": "fferegrino", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "subreddit_subscribers": 853493, "created_utc": 1677772142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI've seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. \n\nI am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). \n\nI've heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.\n\nI'm sure there's a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people's experiences and if this is something possible within data science.\n\nThank you in advance!", "author_fullname": "t2_62z9s6lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote and travel jobs or consultant roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gqhz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677815670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. &lt;/p&gt;\n\n&lt;p&gt;I am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people&amp;#39;s experiences and if this is something possible within data science.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gqhz7", "is_robot_indexable": true, "report_reasons": null, "author": "TibialCuriosity", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "subreddit_subscribers": 853493, "created_utc": 1677815670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For those coming from top-tier competitive programs. I've interviewed for a few positions and salaries seem to be lower than what I expected.", "author_fullname": "t2_7wgr2t9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What sort of salary offers are you getting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gmkwd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677805038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those coming from top-tier competitive programs. I&amp;#39;ve interviewed for a few positions and salaries seem to be lower than what I expected.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gmkwd", "is_robot_indexable": true, "report_reasons": null, "author": "myco_mark", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gmkwd/what_sort_of_salary_offers_are_you_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gmkwd/what_sort_of_salary_offers_are_you_getting/", "subreddit_subscribers": 853493, "created_utc": 1677805038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\n[https://aseandse.org/thecompetition/](https://aseandse.org/thecompetition/)\n\nI looking for a partner(Malaysian studying in any institution in ASEAN countries ) to take participate with me in the ASEAN data exploration competition. The comp requires me to participate with a fellow Malaysian. I am studying in Singapore so a bit hard to find people, so i am posting this here. The comp would be using SAP analytics. U don't necessary need to have the technical skills, if u have the domain knowledge of any of the SDGs mentioned on the website would be pretty good. If anyone is interested in participating with me, just give a dm.", "author_fullname": "t2_5jzu8cvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a Partner for competition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11gxsne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677840990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://aseandse.org/thecompetition/\"&gt;https://aseandse.org/thecompetition/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I looking for a partner(Malaysian studying in any institution in ASEAN countries ) to take participate with me in the ASEAN data exploration competition. The comp requires me to participate with a fellow Malaysian. I am studying in Singapore so a bit hard to find people, so i am posting this here. The comp would be using SAP analytics. U don&amp;#39;t necessary need to have the technical skills, if u have the domain knowledge of any of the SDGs mentioned on the website would be pretty good. If anyone is interested in participating with me, just give a dm.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gxsne", "is_robot_indexable": true, "report_reasons": null, "author": "Someerandomguy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gxsne/need_a_partner_for_competition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gxsne/need_a_partner_for_competition/", "subreddit_subscribers": 853493, "created_utc": 1677840990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As we need to scale the training data before fitting it to the model, how would using validation\\_split prevent us from giving information leakage? \n\nSo far from what I have learned, we can only fit the scaler on the training set, and then apply the fitted scaler to the test set. In this case, I believe we are treating validation set as a \"test set\" during training to improve the model's performance, hence the confusion. Because if we scale the entire training set, we will end up not having unseen data for the validation set.\n\nThank you.\n\n&amp;#x200B;\n\nAdding notes:\n\nTo copy from Keras' official explanation:\n\n&gt;validation\\_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling. This argument is not supported when x is a dataset, generator or keras.utils.Sequence instance. If both validation\\_data and validation\\_split are provided, validation\\_data will override validation\\_split. validation\\_split is not yet supported with tf.distribute.experimental.ParameterServerStrategy.", "author_fullname": "t2_dnekp18a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Keras validation_split prevent information leakage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11gx5mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677838561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we need to scale the training data before fitting it to the model, how would using validation_split prevent us from giving information leakage? &lt;/p&gt;\n\n&lt;p&gt;So far from what I have learned, we can only fit the scaler on the training set, and then apply the fitted scaler to the test set. In this case, I believe we are treating validation set as a &amp;quot;test set&amp;quot; during training to improve the model&amp;#39;s performance, hence the confusion. Because if we scale the entire training set, we will end up not having unseen data for the validation set.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Adding notes:&lt;/p&gt;\n\n&lt;p&gt;To copy from Keras&amp;#39; official explanation:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling. This argument is not supported when x is a dataset, generator or keras.utils.Sequence instance. If both validation_data and validation_split are provided, validation_data will override validation_split. validation_split is not yet supported with tf.distribute.experimental.ParameterServerStrategy.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gx5mz", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Deer8805", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gx5mz/how_does_keras_validation_split_prevent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gx5mz/how_does_keras_validation_split_prevent/", "subreddit_subscribers": 853493, "created_utc": 1677838561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone here in data science field with adhd? How do you find the field you are working? Could you share your experiences?\n\nI am thinking of doing software engineering or data science for my bsc but cannot decide which field would be better for my adhd brain.\n\nThanks", "author_fullname": "t2_lhuh6mwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science with adhd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gv4ly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677830668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here in data science field with adhd? How do you find the field you are working? Could you share your experiences?&lt;/p&gt;\n\n&lt;p&gt;I am thinking of doing software engineering or data science for my bsc but cannot decide which field would be better for my adhd brain.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gv4ly", "is_robot_indexable": true, "report_reasons": null, "author": "No_Language99", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gv4ly/data_science_with_adhd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gv4ly/data_science_with_adhd/", "subreddit_subscribers": 853493, "created_utc": 1677830668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says, if you want to model space elasticity of demand ( i.e. how the demand of a product is affected by the space allocated to it), how do you approach it from a modeling perspective? \n\nA couple of papers I came across:\n\nhttps://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf\n\nhttps://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf\n\nThanks", "author_fullname": "t2_vqwkfiup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail DS: To model space elasticity of demand, are GBMs widely used? If not, what do you prefer to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gtvoe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677831942.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677826151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, if you want to model space elasticity of demand ( i.e. how the demand of a product is affected by the space allocated to it), how do you approach it from a modeling perspective? &lt;/p&gt;\n\n&lt;p&gt;A couple of papers I came across:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf\"&gt;https://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf\"&gt;https://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gtvoe", "is_robot_indexable": true, "report_reasons": null, "author": "Living_Teaching9410", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gtvoe/retail_ds_to_model_space_elasticity_of_demand_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gtvoe/retail_ds_to_model_space_elasticity_of_demand_are/", "subreddit_subscribers": 853493, "created_utc": 1677826151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/\n\ncould anyone shed some light on what I should expect from this role?\n\nThanks", "author_fullname": "t2_9wyrffxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect from an wget level data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnec8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/&lt;/p&gt;\n\n&lt;p&gt;could anyone shed some light on what I should expect from this role?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnec8", "is_robot_indexable": true, "report_reasons": null, "author": "Appropriate-Item-162", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "subreddit_subscribers": 853493, "created_utc": 1677807189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?", "author_fullname": "t2_cps0d40y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Degrees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkmie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gkmie", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Matress27", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gkmie/data_engineering_degrees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gkmie/data_engineering_degrees/", "subreddit_subscribers": 853493, "created_utc": 1677800304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it's a proxy variable at the most and doesn't hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.\n\nNow I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I'd like to find.\n\nThanks!", "author_fullname": "t2_bvba4ue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify underlying features for the Proxy variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gjlor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677808449.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677798772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it&amp;#39;s a proxy variable at the most and doesn&amp;#39;t hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.&lt;/p&gt;\n\n&lt;p&gt;Now I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I&amp;#39;d like to find.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gjlor", "is_robot_indexable": true, "report_reasons": null, "author": "invincible_moron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "subreddit_subscribers": 853493, "created_utc": 1677798772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to classify proteins based on certain properties, some of which are matrices. \n\nSome features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.\n\nWhatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.\n\nHow do I solve for this?", "author_fullname": "t2_15k55n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with vectors as features in a dataset for classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g7srv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677776438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to classify proteins based on certain properties, some of which are matrices. &lt;/p&gt;\n\n&lt;p&gt;Some features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.&lt;/p&gt;\n\n&lt;p&gt;Whatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.&lt;/p&gt;\n\n&lt;p&gt;How do I solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g7srv", "is_robot_indexable": true, "report_reasons": null, "author": "colouredzindagi", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "subreddit_subscribers": 853493, "created_utc": 1677776438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vflmkqsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Master Data Science in 30 Days: A Step-by-Step Guide for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": true, "name": "t3_11gxhgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mqho88VrhVWjNuedMpOW02O-YQwljABFK-Djmqjp-MY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677839818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codelivly.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.codelivly.com/how-to-master-data-science-in-30-days-a-step-by-step-guide-for-beginners/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?auto=webp&amp;v=enabled&amp;s=b0a8114f1414be84f050c3b2eea1f10c22575efe", "width": 1000, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1880996fb243a50e9dc6598565726059aab8488", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=217fdc7a4dda111a9e25336f0ec5801aebddbe57", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77c62e2e391e6bc66c534ce88b7b73662fcd14af", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=653c8fc18251a1fe670c0dfd2af6642fa18582d0", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/tAlAxItlSyNi1G71iezXikeV5gAdJvJCMX_smmhm2GE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeaca587728443b624dbffd8e1393b05ee3174a6", "width": 960, "height": 672}], "variants": {}, "id": "K_KeTT4pPYflw-8MEYAOowdd9Cr7zP20egQmjw0kIiU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gxhgh", "is_robot_indexable": true, "report_reasons": null, "author": "glum-platimium", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gxhgh/how_to_master_data_science_in_30_days_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.codelivly.com/how-to-master-data-science-in-30-days-a-step-by-step-guide-for-beginners/", "subreddit_subscribers": 853493, "created_utc": 1677839818.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi fellow analysts, \n\nI am looking for courses + certificates for Data Analytics/Data Science related project management. \n\nI checked out the Data Science Process Alliance courses, but I have never heard about them before. Any experiences here? \n\nTopics the course should cover: \n\nProject Definition  \nData Story Telling  \nData Quality  \nData Privacy  \nCloud Architectures  \nAgile Tools  \nCoordination of Data Engineers, Data Scientists and ML/AI Engineers\n\nAny recommendations are highly appreciated.", "author_fullname": "t2_arbz8km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Project Management Certificates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11gwl8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677836342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow analysts, &lt;/p&gt;\n\n&lt;p&gt;I am looking for courses + certificates for Data Analytics/Data Science related project management. &lt;/p&gt;\n\n&lt;p&gt;I checked out the Data Science Process Alliance courses, but I have never heard about them before. Any experiences here? &lt;/p&gt;\n\n&lt;p&gt;Topics the course should cover: &lt;/p&gt;\n\n&lt;p&gt;Project Definition&lt;br/&gt;\nData Story Telling&lt;br/&gt;\nData Quality&lt;br/&gt;\nData Privacy&lt;br/&gt;\nCloud Architectures&lt;br/&gt;\nAgile Tools&lt;br/&gt;\nCoordination of Data Engineers, Data Scientists and ML/AI Engineers&lt;/p&gt;\n\n&lt;p&gt;Any recommendations are highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gwl8b", "is_robot_indexable": true, "report_reasons": null, "author": "Lagiol", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gwl8b/data_project_management_certificates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gwl8b/data_project_management_certificates/", "subreddit_subscribers": 853493, "created_utc": 1677836342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Integrate GPT models: Our Internal Research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11guxws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_59kxi4ej", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "artificial", "selftext": "Hey guys, I'm joining the ChatGPT madness with research on how to integrate GPT models into sites and applications. The article also describes the most popular use cases of these models for recommender systems, computer vision tasks, copywriting and more. \n\nHope it will give you some new insights.\n\n[Read the article](https://mobidev.biz/blog/advanced-ways-to-implement-chatgpt-models-in-your-app-website)", "author_fullname": "t2_59kxi4ej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Integrate GPT models: Our Internal Research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/artificial", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11guoy3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677829050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.artificial", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m joining the ChatGPT madness with research on how to integrate GPT models into sites and applications. The article also describes the most popular use cases of these models for recommender systems, computer vision tasks, copywriting and more. &lt;/p&gt;\n\n&lt;p&gt;Hope it will give you some new insights.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://mobidev.biz/blog/advanced-ways-to-implement-chatgpt-models-in-your-app-website\"&gt;Read the article&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?auto=webp&amp;v=enabled&amp;s=a5d802d575113df048976456e8bc91a3f7ae70c6", "width": 1600, "height": 710}, "resolutions": [{"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=069699c0795a8bd5171b5d9c508311fb4283f0fe", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5e5f695af85192a3ac0d62ffa34b46ca91d8d2a", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c00710a7cbf27ab36c4704c5cfc650e3e55fef", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a42a7d2819f355e6689e1e7d86050326aba1cfcd", "width": 640, "height": 284}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38551fbe721c13d1e0bca3f84b15e5352c016924", "width": 960, "height": 426}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49914ffbdf764323f3bb727a851d5525d8180a7d", "width": 1080, "height": 479}], "variants": {}, "id": "5iSIUTsq6qdE2hYu3NO8fAx4zg2he3qmGnmXDaxbE1M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8244fc74-82c9-11e3-9460-12313d224170", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhfb", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "11guoy3", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Power", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/artificial/comments/11guoy3/how_to_integrate_gpt_models_our_internal_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/artificial/comments/11guoy3/how_to_integrate_gpt_models_our_internal_research/", "subreddit_subscribers": 181625, "created_utc": 1677829050.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1677829998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.artificial", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/artificial/comments/11guoy3/how_to_integrate_gpt_models_our_internal_research/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?auto=webp&amp;v=enabled&amp;s=a5d802d575113df048976456e8bc91a3f7ae70c6", "width": 1600, "height": 710}, "resolutions": [{"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=069699c0795a8bd5171b5d9c508311fb4283f0fe", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5e5f695af85192a3ac0d62ffa34b46ca91d8d2a", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c00710a7cbf27ab36c4704c5cfc650e3e55fef", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a42a7d2819f355e6689e1e7d86050326aba1cfcd", "width": 640, "height": 284}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38551fbe721c13d1e0bca3f84b15e5352c016924", "width": 960, "height": 426}, {"url": "https://external-preview.redd.it/WpwBx2TCtd--dgcOE-CGa3EQGNi0YH6mMH7T51Aa_Uc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49914ffbdf764323f3bb727a851d5525d8180a7d", "width": 1080, "height": 479}], "variants": {}, "id": "5iSIUTsq6qdE2hYu3NO8fAx4zg2he3qmGnmXDaxbE1M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11guxws", "is_robot_indexable": true, "report_reasons": null, "author": "Data-Power", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11guoy3", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11guxws/how_to_integrate_gpt_models_our_internal_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/artificial/comments/11guoy3/how_to_integrate_gpt_models_our_internal_research/", "subreddit_subscribers": 853493, "created_utc": 1677829998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_iikq8tv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to import data from Microsoft azure to SQL server in batches by running a service every week such that it gets appended to the already existing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gmimx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677804872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gmimx", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Lawyer-3877", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "subreddit_subscribers": 853493, "created_utc": 1677804872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi r/datascience!\n\ni recently built this mentor network for new college/masters grads or current professionals looking to switch industries or who are preparing to recruit. they can match with available mentors (primarily in tech / banking / consulting) and do a 1:1 session virtually. they can use the time however they like, but generally people like to do interview prep, resume review, general career advice.\n\nfeel free to check it out! link to the website \\[[here](https://mentorme.squarespace.com)\\]. \n\nalso - this is my first website so any feedback would be appreciated!", "author_fullname": "t2_12xkb1xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "built something y'all might be interested in", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gl11f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677801165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;i recently built this mentor network for new college/masters grads or current professionals looking to switch industries or who are preparing to recruit. they can match with available mentors (primarily in tech / banking / consulting) and do a 1:1 session virtually. they can use the time however they like, but generally people like to do interview prep, resume review, general career advice.&lt;/p&gt;\n\n&lt;p&gt;feel free to check it out! link to the website [&lt;a href=\"https://mentorme.squarespace.com\"&gt;here&lt;/a&gt;]. &lt;/p&gt;\n\n&lt;p&gt;also - this is my first website so any feedback would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?auto=webp&amp;v=enabled&amp;s=b87edbe8c930b52e20588134ddba11dae22f59c6", "width": 726, "height": 344}, "resolutions": [{"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd7c8282ba436697397e91ed952cb56f2ad8f43", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d2ccaba2009492edce67bf3fd9a0b64d6d23227", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75af5f33aa31a26d2a6fd13573ed72c84a050e16", "width": 320, "height": 151}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fb9534ab641d1ed234975d6d0833cedcdfc4980", "width": 640, "height": 303}], "variants": {}, "id": "Rxwa8JHZURQb0aeY40iZiC5kJEJxImxZwykFQiO53I0"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "award_19860e30-3331-4bac-b3d1-bd28de0c7974", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=7434e8ec65f434b811666ff6be1cbc18e675c5bf", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=aacfdc98efb123d6d4464d6a227aff2f9d90a3fb", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=af6b886c9a013bed09f09ef8bb3757f14a1286b9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=0e3debe040221236e3cdde5840d9ea8f67d7dca9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=bd5fb5fe09c1ac5e0d58faed4fc7e9108f6f7718", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I needed this today", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Heartwarming", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=7434e8ec65f434b811666ff6be1cbc18e675c5bf", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=aacfdc98efb123d6d4464d6a227aff2f9d90a3fb", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=af6b886c9a013bed09f09ef8bb3757f14a1286b9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=0e3debe040221236e3cdde5840d9ea8f67d7dca9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=bd5fb5fe09c1ac5e0d58faed4fc7e9108f6f7718", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gl11f", "is_robot_indexable": true, "report_reasons": null, "author": "nong-shim-shin-RAMEN", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gl11f/built_something_yall_might_be_interested_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gl11f/built_something_yall_might_be_interested_in/", "subreddit_subscribers": 853493, "created_utc": 1677801165.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}