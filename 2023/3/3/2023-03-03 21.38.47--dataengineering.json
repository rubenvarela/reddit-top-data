{"kind": "Listing", "data": {"after": "t3_11h4swz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_170m1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Geospatial DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11grme8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677818969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tech.marksblogg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tech.marksblogg.com/duckdb-geospatial-gis.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11grme8", "is_robot_indexable": true, "report_reasons": null, "author": "marklit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11grme8/geospatial_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tech.marksblogg.com/duckdb-geospatial-gis.html", "subreddit_subscribers": 91798, "created_utc": 1677818969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have developed a strong liking for data engineering, although I am VERY new to fundamentals. I want to know what is more relevant for an entry role, and if I should add, skip, or change order to my roadmap. Very proud of the hours I'm putting in learning Python along CS fundamentals. List is in order of what I will learn, courses already owned. \n\n* SQL (Udemy) \n* Data Warehouse Fundamentals / Guide (Udemy)\n* Harenslak B. Data Pipelines with Apache Airflow 2021 (Book)\n* Data Warehousing and Engineering using Snowflake and AWS Cloud  (Udemy)\n* Microsoft Azure Data Fundamentals (Udemy) \n\nProjects:\n\n[https://www.startdataengineering.com/post/data-engineering-project-for-beginners-stream-edition/](https://www.startdataengineering.com/post/data-engineering-project-for-beginners-stream-edition/)\n\n[https://www.linkedin.com/posts/vimanyu\\_data-engineering-roadmap-2023-ugcPost-7015647693871955969-hVYe/](https://www.linkedin.com/posts/vimanyu_data-engineering-roadmap-2023-ugcPost-7015647693871955969-hVYe/)\n\n[https://www.udemy.com/course/big-data-hadoop-spark-project/](https://www.udemy.com/course/big-data-hadoop-spark-project/)\n\nI'd like to add that I appreciate all of the feedback, and I enjoy Udemy courses since they allow me to devote consistent time to learning every day. Nonetheless, I am open to learning from any additional resources and suggestions. I try to LC one to two problems a day as well, but I don't know how much time I should devote to LC yet.", "author_fullname": "t2_pwk2f3iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on roadmap?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gwrrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677837080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have developed a strong liking for data engineering, although I am VERY new to fundamentals. I want to know what is more relevant for an entry role, and if I should add, skip, or change order to my roadmap. Very proud of the hours I&amp;#39;m putting in learning Python along CS fundamentals. List is in order of what I will learn, courses already owned. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SQL (Udemy) &lt;/li&gt;\n&lt;li&gt;Data Warehouse Fundamentals / Guide (Udemy)&lt;/li&gt;\n&lt;li&gt;Harenslak B. Data Pipelines with Apache Airflow 2021 (Book)&lt;/li&gt;\n&lt;li&gt;Data Warehousing and Engineering using Snowflake and AWS Cloud  (Udemy)&lt;/li&gt;\n&lt;li&gt;Microsoft Azure Data Fundamentals (Udemy) &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Projects:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.startdataengineering.com/post/data-engineering-project-for-beginners-stream-edition/\"&gt;https://www.startdataengineering.com/post/data-engineering-project-for-beginners-stream-edition/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/posts/vimanyu_data-engineering-roadmap-2023-ugcPost-7015647693871955969-hVYe/\"&gt;https://www.linkedin.com/posts/vimanyu_data-engineering-roadmap-2023-ugcPost-7015647693871955969-hVYe/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/big-data-hadoop-spark-project/\"&gt;https://www.udemy.com/course/big-data-hadoop-spark-project/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to add that I appreciate all of the feedback, and I enjoy Udemy courses since they allow me to devote consistent time to learning every day. Nonetheless, I am open to learning from any additional resources and suggestions. I try to LC one to two problems a day as well, but I don&amp;#39;t know how much time I should devote to LC yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?auto=webp&amp;v=enabled&amp;s=11d9fe646b5fd9572a0798f75b4d2af7cabbf383", "width": 2268, "height": 1246}, "resolutions": [{"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad9cdb31fe1936dcc9d70c2b74804002c95301fd", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4d8407177694fed1b7d4eca4535ad4cdd7d0fc5", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c51c0cd95b885ff969f027d30b53625881c2c63b", "width": 320, "height": 175}, {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9141bba968d1ed94cbb92068ac7492f691b419a", "width": 640, "height": 351}, {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8537505186e02da3028af1a03b26f1031aac4691", "width": 960, "height": 527}, {"url": "https://external-preview.redd.it/qwdRPD5dUDYPZ-aMyXXdcvRD1F6NjOpjcul8RAmBXDg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=966a495c0005156f9c3504ae416db02e7a091007", "width": 1080, "height": 593}], "variants": {}, "id": "DLfJ9empmBiS7hqzG321qwo6BRPqMvm7FfDoxu_YvLw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11gwrrw", "is_robot_indexable": true, "report_reasons": null, "author": "CowUnfair4318", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gwrrw/suggestions_on_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gwrrw/suggestions_on_roadmap/", "subreddit_subscribers": 91798, "created_utc": 1677837080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many applications are you getting? and how many of them are actual qualified applicants?\n\nJust trying to get some actual information on this to inform people on the job search. I'll sometimes pass on applying to a company that already has like 200+ applications on Linkedin.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question for people who are hiring or have hired recently. How many applications are you getting? and how many of them are actual qualified applicants?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h1xff", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677853177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many applications are you getting? and how many of them are actual qualified applicants?&lt;/p&gt;\n\n&lt;p&gt;Just trying to get some actual information on this to inform people on the job search. I&amp;#39;ll sometimes pass on applying to a company that already has like 200+ applications on Linkedin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h1xff", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11h1xff/question_for_people_who_are_hiring_or_have_hired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h1xff/question_for_people_who_are_hiring_or_have_hired/", "subreddit_subscribers": 91798, "created_utc": 1677853177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! I was wondering what are your best practices for your team around using AWS Lambda for extracting and loading data from sources to target?", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for AWS Lambda with using it for EL data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gksbw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! I was wondering what are your best practices for your team around using AWS Lambda for extracting and loading data from sources to target?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11gksbw", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gksbw/best_practices_for_aws_lambda_with_using_it_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gksbw/best_practices_for_aws_lambda_with_using_it_for/", "subreddit_subscribers": 91798, "created_utc": 1677800638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a 100% PostgreSQL-based data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_11h2aqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Blp6Wl_N-GH0byJRXZbC5s32tLjK_aG6-l6NPAL2Gb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677854140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/full-stack-architecture/elt-data-platforms-and-sql-extracting-and-transforming-data-from-restful-services-cc8b2e059972", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?auto=webp&amp;v=enabled&amp;s=17464a227155bb693c618d139c0a40247798bbfb", "width": 630, "height": 472}, "resolutions": [{"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46d60896c58dd64134396b4210797d4fb810372e", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8dff35778af8a41a4b222dee69ab8690dcee35b", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1a7cdf35e048bd844714f61e67fa23f59370b67", "width": 320, "height": 239}], "variants": {}, "id": "4pYoDEXa-f44_Nlw1mGsRh73X7lw0TPA7IP0H1LW6F8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11h2aqp", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11h2aqp/building_a_100_postgresqlbased_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/full-stack-architecture/elt-data-platforms-and-sql-extracting-and-transforming-data-from-restful-services-cc8b2e059972", "subreddit_subscribers": 91798, "created_utc": 1677854140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are currently the best tools out there for ML Ops? How is MLFLow on databricks,Azure ML etc?\n\nHow is the security, real time inferencing  and other important scenarios in both cases? \n\nAm I right , in my understanding ,that MLFLow will run externally to a databricks cluster", "author_fullname": "t2_4i7lkn0i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML Ops : Tools In Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gx87d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677838830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are currently the best tools out there for ML Ops? How is MLFLow on databricks,Azure ML etc?&lt;/p&gt;\n\n&lt;p&gt;How is the security, real time inferencing  and other important scenarios in both cases? &lt;/p&gt;\n\n&lt;p&gt;Am I right , in my understanding ,that MLFLow will run externally to a databricks cluster&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11gx87d", "is_robot_indexable": true, "report_reasons": null, "author": "SouthernEnthusiasm82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gx87d/ml_ops_tools_in_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gx87d/ml_ops_tools_in_comparison/", "subreddit_subscribers": 91798, "created_utc": 1677838830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://rockset.com/blog/introducing-compute-compute-separation/](https://rockset.com/blog/introducing-compute-compute-separation/)", "author_fullname": "t2_6z7i3sub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compute-compute separation for real-time analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h9iwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677866953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://rockset.com/blog/introducing-compute-compute-separation/\"&gt;https://rockset.com/blog/introducing-compute-compute-separation/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?auto=webp&amp;v=enabled&amp;s=89dd38ed783c6f7b7fd7f8a17627b8e8f1da0e7a", "width": 2560, "height": 1340}, "resolutions": [{"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=247a68b121d0b644ebe5bfe9f0f1c683d2b524d1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dc2f025685a904f8a4eb25e207e532356d455aa", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bf9ab91a5de48ce74898c29cba065fb8af49a77", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d05cdbfcd757cfa3878eeda6a6ec5c64397d018", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f83a112bf05ab56fce8e857edd29a6c0f2e5eff", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7954c4e0cd0bb31f7443964e591d1812196391ea", "width": 1080, "height": 565}], "variants": {}, "id": "HgiipNxAl6VoCgJ3fWfRmRgX0dMxHDG92I8seBbhnKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11h9iwd", "is_robot_indexable": true, "report_reasons": null, "author": "jmills2010", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h9iwd/computecompute_separation_for_realtime_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h9iwd/computecompute_separation_for_realtime_analytics/", "subreddit_subscribers": 91798, "created_utc": 1677866953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are many different descriptions of these two careers. Some of them say they are totally different things, others equate them or say that BI development is part of DE. How do you differentiate these two?\n\nAs a Data Analyst who is steering his career towards DE, should I consider BI dev as a solid entry point?\n\nEdit for clarification: BI developer is different than BI analyst.", "author_fullname": "t2_nmja4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the knowledge gaps between BI developer and Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h87vp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677872525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677865491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many different descriptions of these two careers. Some of them say they are totally different things, others equate them or say that BI development is part of DE. How do you differentiate these two?&lt;/p&gt;\n\n&lt;p&gt;As a Data Analyst who is steering his career towards DE, should I consider BI dev as a solid entry point?&lt;/p&gt;\n\n&lt;p&gt;Edit for clarification: BI developer is different than BI analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h87vp", "is_robot_indexable": true, "report_reasons": null, "author": "we_need_more_lumber", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h87vp/what_are_the_knowledge_gaps_between_bi_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h87vp/what_are_the_knowledge_gaps_between_bi_developer/", "subreddit_subscribers": 91798, "created_utc": 1677865491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone found any good guides for using FHIR? I\u2019m trying to get into it, and while there is tons of documentation on how to structure the data, there seems to be absolutely nothing on how to actually do anything. I feel like I\u2019ve watched hours of videos where they explain what everything is, but there is absolutely nothing on the how to part.", "author_fullname": "t2_7otsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure FHIR Guides?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gv0wv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677830317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone found any good guides for using FHIR? I\u2019m trying to get into it, and while there is tons of documentation on how to structure the data, there seems to be absolutely nothing on how to actually do anything. I feel like I\u2019ve watched hours of videos where they explain what everything is, but there is absolutely nothing on the how to part.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11gv0wv", "is_robot_indexable": true, "report_reasons": null, "author": "FightingDucks", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gv0wv/azure_fhir_guides/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gv0wv/azure_fhir_guides/", "subreddit_subscribers": 91798, "created_utc": 1677830317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Brainstorming on possible solutions for pipeline we're working on.\n\nWe've been given access to a client's S3 buckets (7 buckets with ~8 folders each) which receive new data every few mins or so. Files are small (~10kB)\n\nGoal is to transform the data with an existing Airflow pattern and load it into a Redshift cluster\n\n`Client S3 --&gt; ??? --&gt; Landing S3 --&gt; Airflow (dbt/Athena) --&gt; Transformed S3 --&gt; ??? --&gt; Redshift`\n\nWe're trying to figure out what should go in the ??? at each end. \n\nFor `Client S3 --&gt; Landing S3`, would something like this be appropriate:\n\n`Client S3 --&gt; SQS --&gt; EventBridge --&gt; Lambda --&gt; Firehose --&gt; Landing S3`\n\nFor `Transformed S3 --&gt; Redshift`, what about:\n\n`Transformed S3 --&gt; SNS --&gt; Redshift Spectrum --&gt; Redshift`\n\nAre we over complicating things? \n\nDoes anything seem superfluous? (excluding the Airflow component as that's required)", "author_fullname": "t2_2ck87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS - Data Pipeline Suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gldb2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677801967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Brainstorming on possible solutions for pipeline we&amp;#39;re working on.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been given access to a client&amp;#39;s S3 buckets (7 buckets with ~8 folders each) which receive new data every few mins or so. Files are small (~10kB)&lt;/p&gt;\n\n&lt;p&gt;Goal is to transform the data with an existing Airflow pattern and load it into a Redshift cluster&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Client S3 --&amp;gt; ??? --&amp;gt; Landing S3 --&amp;gt; Airflow (dbt/Athena) --&amp;gt; Transformed S3 --&amp;gt; ??? --&amp;gt; Redshift&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re trying to figure out what should go in the ??? at each end. &lt;/p&gt;\n\n&lt;p&gt;For &lt;code&gt;Client S3 --&amp;gt; Landing S3&lt;/code&gt;, would something like this be appropriate:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Client S3 --&amp;gt; SQS --&amp;gt; EventBridge --&amp;gt; Lambda --&amp;gt; Firehose --&amp;gt; Landing S3&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;For &lt;code&gt;Transformed S3 --&amp;gt; Redshift&lt;/code&gt;, what about:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Transformed S3 --&amp;gt; SNS --&amp;gt; Redshift Spectrum --&amp;gt; Redshift&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Are we over complicating things? &lt;/p&gt;\n\n&lt;p&gt;Does anything seem superfluous? (excluding the Airflow component as that&amp;#39;s required)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Custodian", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11gldb2", "is_robot_indexable": true, "report_reasons": null, "author": "elus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11gldb2/aws_data_pipeline_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gldb2/aws_data_pipeline_suggestions/", "subreddit_subscribers": 91798, "created_utc": 1677801967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thank you!\n\nI've searched on YouTube and even asked ChatGPT with limited information.\n\nGoogle search results kept telling me some marketing term like multi cloud orchestration. I still don't understand what that means.", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could someone help me understand what exactly is common storage layer? How does it sit in a tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkmwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched on YouTube and even asked ChatGPT with limited information.&lt;/p&gt;\n\n&lt;p&gt;Google search results kept telling me some marketing term like multi cloud orchestration. I still don&amp;#39;t understand what that means.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11gkmwr", "is_robot_indexable": true, "report_reasons": null, "author": "[deleted]", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11gkmwr/could_someone_help_me_understand_what_exactly_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gkmwr/could_someone_help_me_understand_what_exactly_is/", "subreddit_subscribers": 91798, "created_utc": 1677800327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did you know how to fix issue where in loggs it says etc/environment not accessible?", "author_fullname": "t2_4as7wsm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Out of mind trying to make spark logging works on Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkiep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did you know how to fix issue where in loggs it says etc/environment not accessible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11gkiep", "is_robot_indexable": true, "report_reasons": null, "author": "Dawido090", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gkiep/out_of_mind_trying_to_make_spark_logging_works_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gkiep/out_of_mind_trying_to_make_spark_logging_works_on/", "subreddit_subscribers": 91798, "created_utc": 1677800083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb](https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a\n\n In today\u2019s data-driven world, processing large volumes of data in real-time has become essential for many organizations. The Extract, Transform, Load (ETL) process is a common way to manage the flow of data between systems. In this article, we\u2019ll walk through how to build a scalable ETL pipeline using Apache Airflow, Kafka, and Python, Mongo and Flask \n\nIn this pipeline, the RSS feeds are scraped using a Python library called feedparser. This library is used to parse the XML data in the RSS feeds and extract the relevant information. The parsed data is then transformed into a standardized JSON format using Python's built-in json library. This format includes fields such as title, summary, link, published\\_date, and language, which make the data easier to analyze and consume.", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Scalable RSS Feed Pipeline with Apache Airflow, Kafka, and MongoDB, Flask Api", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"cw0ny0xe3lla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=906a9e84c5c3b27a02ead564d9094ab316759988"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6731aebac6fb9bfc8d7d74b85cad5fc0a1d70f34"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0eee400b3475883b825d5980b3355998bbac6b8e"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a"}, "id": "cw0ny0xe3lla1"}}, "name": "t3_11hdy54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sZ25bG-V-FiLzLwMOO2O-bnR-pdaidqQq5_4ymlblrI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677875379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb\"&gt;https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a\"&gt;https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In today\u2019s data-driven world, processing large volumes of data in real-time has become essential for many organizations. The Extract, Transform, Load (ETL) process is a common way to manage the flow of data between systems. In this article, we\u2019ll walk through how to build a scalable ETL pipeline using Apache Airflow, Kafka, and Python, Mongo and Flask &lt;/p&gt;\n\n&lt;p&gt;In this pipeline, the RSS feeds are scraped using a Python library called feedparser. This library is used to parse the XML data in the RSS feeds and extract the relevant information. The parsed data is then transformed into a standardized JSON format using Python&amp;#39;s built-in json library. This format includes fields such as title, summary, link, published_date, and language, which make the data easier to analyze and consume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?auto=webp&amp;v=enabled&amp;s=ee9818bce162ebfcb69268e842d337c035e5b567", "width": 1200, "height": 564}, "resolutions": [{"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f784cea76c85073a0a9074b20d4bd68ab7d68ce", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce84ff7be54e3fcfb68e870f63fa6e2d4603aba5", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52a34c1619925b79c20f923f917be2348dafe8dc", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43ff471735006a845946aa4e4cecba39fdab0d48", "width": 640, "height": 300}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83bf78180fbb5a751676350b1bb13764c353f73e", "width": 960, "height": 451}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7a04270a792befa0fafc11e1cdcb8e490969047", "width": 1080, "height": 507}], "variants": {}, "id": "tH9jmMo8wbU5z-SQC6-NTsGwT9qhuVhdZXUeDxBZR1c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "11hdy54", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hdy54/building_a_scalable_rss_feed_pipeline_with_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hdy54/building_a_scalable_rss_feed_pipeline_with_apache/", "subreddit_subscribers": 91798, "created_utc": 1677875379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently on an internship and I think I\u2019ll be able to have the choice of choosing what role or department to go to, and I\u2019m really tending towards data engineering. \n\nI\u2019m interested in programming, and think back end is something I would enjoy most. Things I was looking at were \n\n1) stress / work life balance / flexibility\n2) pay \n3) how much time is spent on meetings v coding/building \n4) development - continuous learning and enjoyment. Will I be able to move to other roles easily if this doesn\u2019t work out or after being in the role for a few years etc\n5) whether I would struggle at the work - needs to be something I can complete. \n\nI feel like when you have so many fields that look appealing it feels like a really difficult decision to make when starting your career out. I\u2019ve been thinking about this for so long. \n\nFrom the U.K. if that makes a difference. And I have limited programming experience in terms of python. Not much on SQL.\n\nThanks!", "author_fullname": "t2_3f2ev3jx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know if this is for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h16th", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677851235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently on an internship and I think I\u2019ll be able to have the choice of choosing what role or department to go to, and I\u2019m really tending towards data engineering. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested in programming, and think back end is something I would enjoy most. Things I was looking at were &lt;/p&gt;\n\n&lt;p&gt;1) stress / work life balance / flexibility\n2) pay \n3) how much time is spent on meetings v coding/building \n4) development - continuous learning and enjoyment. Will I be able to move to other roles easily if this doesn\u2019t work out or after being in the role for a few years etc\n5) whether I would struggle at the work - needs to be something I can complete. &lt;/p&gt;\n\n&lt;p&gt;I feel like when you have so many fields that look appealing it feels like a really difficult decision to make when starting your career out. I\u2019ve been thinking about this for so long. &lt;/p&gt;\n\n&lt;p&gt;From the U.K. if that makes a difference. And I have limited programming experience in terms of python. Not much on SQL.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11h16th", "is_robot_indexable": true, "report_reasons": null, "author": "studying4exams", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h16th/how_do_i_know_if_this_is_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h16th/how_do_i_know_if_this_is_for_me/", "subreddit_subscribers": 91798, "created_utc": 1677851235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In past years, I have been through a few projects that include a database with CRM and billing data model. \n\nLike open source projects, is there any open data model repository of common used data models like CRM systems or billing/invoicing systems.  \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n\\*\\* By data model I mean good old school crowfoot ER diagrams :)", "author_fullname": "t2_71zj27dw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there ready baseline data model for CRM and billing system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gsmqd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677822057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In past years, I have been through a few projects that include a database with CRM and billing data model. &lt;/p&gt;\n\n&lt;p&gt;Like open source projects, is there any open data model repository of common used data models like CRM systems or billing/invoicing systems.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;** By data model I mean good old school crowfoot ER diagrams :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11gsmqd", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryHunt753", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gsmqd/is_there_ready_baseline_data_model_for_crm_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gsmqd/is_there_ready_baseline_data_model_for_crm_and/", "subreddit_subscribers": 91798, "created_utc": 1677822057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've recently been told that Data Vault doesn't belongs to the modern lake house world where data is stored differently compared to the traditional RDBMS. \n\nWhat's your opinion on that, which modeling approach would make the most sense for a lakehouse architecture like databricks?", "author_fullname": "t2_uetytl1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault on Databricks - Non Sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gr26p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677817294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve recently been told that Data Vault doesn&amp;#39;t belongs to the modern lake house world where data is stored differently compared to the traditional RDBMS. &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your opinion on that, which modeling approach would make the most sense for a lakehouse architecture like databricks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11gr26p", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Book-6052", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11gr26p/data_vault_on_databricks_non_sense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11gr26p/data_vault_on_databricks_non_sense/", "subreddit_subscribers": 91798, "created_utc": 1677817294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I\u2019m looking to do some research on building a potential SDK model for my company\u2019s data visualization platform. Hoping to better understand what value we can add rather than just being a data viz SDK. If you could wish for any features in a data visualization SDK what would it be? Thank you in advance \ud83d\ude0a", "author_fullname": "t2_5mmilr0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you could have anything in a data viz SDK Model what would you wish for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11he6z1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677875932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I\u2019m looking to do some research on building a potential SDK model for my company\u2019s data visualization platform. Hoping to better understand what value we can add rather than just being a data viz SDK. If you could wish for any features in a data visualization SDK what would it be? Thank you in advance \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11he6z1", "is_robot_indexable": true, "report_reasons": null, "author": "frozenbutterstick", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11he6z1/if_you_could_have_anything_in_a_data_viz_sdk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11he6z1/if_you_could_have_anything_in_a_data_viz_sdk/", "subreddit_subscribers": 91798, "created_utc": 1677875932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About to start job hunting in the US.\n\nMid-career professional with 7 YOE.  ", "author_fullname": "t2_gff2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you include a summary section in your resume in the USA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hbyzq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677870830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About to start job hunting in the US.&lt;/p&gt;\n\n&lt;p&gt;Mid-career professional with 7 YOE.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11hbyzq", "is_robot_indexable": true, "report_reasons": null, "author": "tiggat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hbyzq/do_you_include_a_summary_section_in_your_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hbyzq/do_you_include_a_summary_section_in_your_resume/", "subreddit_subscribers": 91798, "created_utc": 1677870830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys, Currently a Sharepoint list containing some images and we have a requirement to migrate that list to either ADW or Azure SQL Server. I am not sure how we can achieve that, I tried to move via ADF it's load the data but only that was present in column it skipped the images column. Can you plz guide me how can I achieve this?", "author_fullname": "t2_rhr52nlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Store images in Azure Datawarehouse or Azure SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hay9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677868755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, Currently a Sharepoint list containing some images and we have a requirement to migrate that list to either ADW or Azure SQL Server. I am not sure how we can achieve that, I tried to move via ADF it&amp;#39;s load the data but only that was present in column it skipped the images column. Can you plz guide me how can I achieve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11hay9z", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant-Seat-3013", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hay9z/store_images_in_azure_datawarehouse_or_azure_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hay9z/store_images_in_azure_datawarehouse_or_azure_sql/", "subreddit_subscribers": 91798, "created_utc": 1677868755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://youtu.be/L5glYDaeQV8", "author_fullname": "t2_66513e19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your views on this interesting datahub use case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h9wch", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677867362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtu.be/L5glYDaeQV8\"&gt;https://youtu.be/L5glYDaeQV8&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rt5TXzpG3id0ddEhatidkQrBu7TKOFc4eFvuw-li-q8.jpg?auto=webp&amp;v=enabled&amp;s=e00798b20c43b2600e2d373af02d6b6148fe7e79", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/rt5TXzpG3id0ddEhatidkQrBu7TKOFc4eFvuw-li-q8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3691ed958fb81db288a00f7f47d70263e1f5a5c2", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/rt5TXzpG3id0ddEhatidkQrBu7TKOFc4eFvuw-li-q8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6894368715a948f6a87c602892e244c1bf079c46", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/rt5TXzpG3id0ddEhatidkQrBu7TKOFc4eFvuw-li-q8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bdc965f0d53e6a936dbbfed23e46eef8655591da", "width": 320, "height": 240}], "variants": {}, "id": "PhlDBafU2OZr5wZAQFG_AuAjLyw6kF3WvbYSwatpKHw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h9wch", "is_robot_indexable": true, "report_reasons": null, "author": "nikiii_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h9wch/what_are_your_views_on_this_interesting_datahub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h9wch/what_are_your_views_on_this_interesting_datahub/", "subreddit_subscribers": 91798, "created_utc": 1677867362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello any DV2 gurus,\n\nMy team is in the middle of formulating a data vault strategy for a new system.  We're all relatively new to DV concepts.  There is one concept we're having a hard time finding a rule for - attribute naming.  It is a prevailing theme in DV but seems to be the least discussed.  It's a big concern of ours, especially when discussing lineage and testing.  Finding a \"best practice\" is tough.\n\nTo frame what \"renaming\" means in this context, it is converting a cryptic source name \"PPL\\_FNDS\" to something the end user would understand, \"CustomerFunds\".\n\nWe are using dbt and dbt-vault.\n\nOur team currently has 2 camps.  One wants this translation to happen in the raw vault.  The other camp wants this to happen in the information mart.  The arguments are that the names in the raw vault are what the true concepts are and there is no possible way anybody would think differently while the other says customers change their minds and this level of translation is application specific, handled in whatever designs the user level query.\n\nWe do not have a handle yet on how lineage is even going to work.  The docs command in dbt is neat but we're not sure that is enough.\n\nThe renaming of columns is becoming an issue when we test that a hop loaded correctly from the prior hop.  That seems to be an issue at every hop as columns change along the way.", "author_fullname": "t2_33sjvqg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault 2: Renaming of Source Columns/Attributes, which hop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h9g81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677866868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello any DV2 gurus,&lt;/p&gt;\n\n&lt;p&gt;My team is in the middle of formulating a data vault strategy for a new system.  We&amp;#39;re all relatively new to DV concepts.  There is one concept we&amp;#39;re having a hard time finding a rule for - attribute naming.  It is a prevailing theme in DV but seems to be the least discussed.  It&amp;#39;s a big concern of ours, especially when discussing lineage and testing.  Finding a &amp;quot;best practice&amp;quot; is tough.&lt;/p&gt;\n\n&lt;p&gt;To frame what &amp;quot;renaming&amp;quot; means in this context, it is converting a cryptic source name &amp;quot;PPL_FNDS&amp;quot; to something the end user would understand, &amp;quot;CustomerFunds&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;We are using dbt and dbt-vault.&lt;/p&gt;\n\n&lt;p&gt;Our team currently has 2 camps.  One wants this translation to happen in the raw vault.  The other camp wants this to happen in the information mart.  The arguments are that the names in the raw vault are what the true concepts are and there is no possible way anybody would think differently while the other says customers change their minds and this level of translation is application specific, handled in whatever designs the user level query.&lt;/p&gt;\n\n&lt;p&gt;We do not have a handle yet on how lineage is even going to work.  The docs command in dbt is neat but we&amp;#39;re not sure that is enough.&lt;/p&gt;\n\n&lt;p&gt;The renaming of columns is becoming an issue when we test that a hop loaded correctly from the prior hop.  That seems to be an issue at every hop as columns change along the way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11h9g81", "is_robot_indexable": true, "report_reasons": null, "author": "Captain_Coffee_III", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h9g81/data_vault_2_renaming_of_source_columnsattributes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h9g81/data_vault_2_renaming_of_source_columnsattributes/", "subreddit_subscribers": 91798, "created_utc": 1677866868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I gave an interview for a data engineer role. Questions were all about Hadoop and Spark architecture. I'm good at programming in Pyspark and SparkSQL, but I have no knowledge on architecture. How important is it to know the architecture? In my current role I'm doing well without any knowledge.", "author_fullname": "t2_tme0hylh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is it to know Hadoop architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h7uhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677865074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I gave an interview for a data engineer role. Questions were all about Hadoop and Spark architecture. I&amp;#39;m good at programming in Pyspark and SparkSQL, but I have no knowledge on architecture. How important is it to know the architecture? In my current role I&amp;#39;m doing well without any knowledge.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11h7uhj", "is_robot_indexable": true, "report_reasons": null, "author": "fightinmee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h7uhj/how_important_is_it_to_know_hadoop_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h7uhj/how_important_is_it_to_know_hadoop_architecture/", "subreddit_subscribers": 91798, "created_utc": 1677865074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the overlap in your organization between Data Engineering, which is usually discussed in the context of providing data for some sort of BI, and Data Integration, connecting systems (internal, external) with the data they need to operate.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overlap Between Integration and Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h7f4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677864605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the overlap in your organization between Data Engineering, which is usually discussed in the context of providing data for some sort of BI, and Data Integration, connecting systems (internal, external) with the data they need to operate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h7f4c", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h7f4c/overlap_between_integration_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h7f4c/overlap_between_integration_and_data_engineering/", "subreddit_subscribers": 91798, "created_utc": 1677864605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, Hope youre doing well.\n\nI wanted to know the approach you would take to get the result. Every person I have talked to has literally said it is way too complicated. So, I came to Reddit for help. Im really new to this please help me. The excel sheets does not have the scores updated but this is what it looks like. I am mainly targeting Under 2.5. For eg Team A vs Team B is 1-1. When we add then up it is less than 2, so it has passed &amp; if it was 2-1, it becomes 3, so it has failed. [This](https://docs.google.com/spreadsheets/d/1JCdi9JfjInZdw9G5DAKYJAiCt1IJ4yLWBJaESNfAldU/edit?usp=sharing) is the excel sheet.\n\nAt the end of the analysis, I would want a measure, as in, something like,\" After analyzing 4000 matches, if you filter the home formula section to show only less than 40, make the away score show values between 0.5 to 3 &amp; final % to show less than 10 then you will get 95% success. There were 600 matches that fit the criteria and they were 95% successful\"\n\nso I have a data set of 4000 football matches, and every column is almost interlinked with each other.\n\nSo, let me break down the column and formulas for you.\n\n\\- home score average = average goals scored by the home team ( team on the left) for 24 matches\n\n\\- away score average= average goals scored by the away team ( team on the right) for 24 matches\n\n\\- overall home score average = is the average no of Goals scored by the home team in matches played at away venues\n\n\\- overall away score average = is the average no of Goals scored by the away team in matches played at away venues\n\n\\- The home score conceded average= is the avg goals conceded at home by the home team\n\n\\- away score conceded average= the avg goals conceded away by the away team\n\n\\- overall home conceded= is avg goals conceded away &amp; home by the home team\n\n\\- overall home conceded= is avg goals conceded away &amp; home by the away team\n\n100-(EXP(-x)\\*100) = the formula we use for the home formula, away formula, overall home formula, and overall away formula in these formulas we replace x with their respective averages which I mentioned earlier.\n\nSo in the home formula, we use the value we got in the home score average as x &amp; away score average for the away formula, overall home score average for the overall home formula &amp; overall away score average for the overall away formula.\n\nso home formula = home score average, away formula = away score average, overall home formula = overall home score average, and likewise, we don't use any formula for conceded section.\n\nNow,\n\n\\- overall % to score is = overall home formula \\* overall away formula /100\n\n\\- % to score is = home formula \\*away formula /100\n\nand,\n\n\\- final result is = overall % to score \\* % to score/100", "author_fullname": "t2_5czj94cq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help to analyze a very complex data set that predicts match outcomes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h6ncn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677863747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, Hope youre doing well.&lt;/p&gt;\n\n&lt;p&gt;I wanted to know the approach you would take to get the result. Every person I have talked to has literally said it is way too complicated. So, I came to Reddit for help. Im really new to this please help me. The excel sheets does not have the scores updated but this is what it looks like. I am mainly targeting Under 2.5. For eg Team A vs Team B is 1-1. When we add then up it is less than 2, so it has passed &amp;amp; if it was 2-1, it becomes 3, so it has failed. &lt;a href=\"https://docs.google.com/spreadsheets/d/1JCdi9JfjInZdw9G5DAKYJAiCt1IJ4yLWBJaESNfAldU/edit?usp=sharing\"&gt;This&lt;/a&gt; is the excel sheet.&lt;/p&gt;\n\n&lt;p&gt;At the end of the analysis, I would want a measure, as in, something like,&amp;quot; After analyzing 4000 matches, if you filter the home formula section to show only less than 40, make the away score show values between 0.5 to 3 &amp;amp; final % to show less than 10 then you will get 95% success. There were 600 matches that fit the criteria and they were 95% successful&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;so I have a data set of 4000 football matches, and every column is almost interlinked with each other.&lt;/p&gt;\n\n&lt;p&gt;So, let me break down the column and formulas for you.&lt;/p&gt;\n\n&lt;p&gt;- home score average = average goals scored by the home team ( team on the left) for 24 matches&lt;/p&gt;\n\n&lt;p&gt;- away score average= average goals scored by the away team ( team on the right) for 24 matches&lt;/p&gt;\n\n&lt;p&gt;- overall home score average = is the average no of Goals scored by the home team in matches played at away venues&lt;/p&gt;\n\n&lt;p&gt;- overall away score average = is the average no of Goals scored by the away team in matches played at away venues&lt;/p&gt;\n\n&lt;p&gt;- The home score conceded average= is the avg goals conceded at home by the home team&lt;/p&gt;\n\n&lt;p&gt;- away score conceded average= the avg goals conceded away by the away team&lt;/p&gt;\n\n&lt;p&gt;- overall home conceded= is avg goals conceded away &amp;amp; home by the home team&lt;/p&gt;\n\n&lt;p&gt;- overall home conceded= is avg goals conceded away &amp;amp; home by the away team&lt;/p&gt;\n\n&lt;p&gt;100-(EXP(-x)*100) = the formula we use for the home formula, away formula, overall home formula, and overall away formula in these formulas we replace x with their respective averages which I mentioned earlier.&lt;/p&gt;\n\n&lt;p&gt;So in the home formula, we use the value we got in the home score average as x &amp;amp; away score average for the away formula, overall home score average for the overall home formula &amp;amp; overall away score average for the overall away formula.&lt;/p&gt;\n\n&lt;p&gt;so home formula = home score average, away formula = away score average, overall home formula = overall home score average, and likewise, we don&amp;#39;t use any formula for conceded section.&lt;/p&gt;\n\n&lt;p&gt;Now,&lt;/p&gt;\n\n&lt;p&gt;- overall % to score is = overall home formula * overall away formula /100&lt;/p&gt;\n\n&lt;p&gt;- % to score is = home formula *away formula /100&lt;/p&gt;\n\n&lt;p&gt;and,&lt;/p&gt;\n\n&lt;p&gt;- final result is = overall % to score * % to score/100&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?auto=webp&amp;v=enabled&amp;s=b56a990e8a1dd14c69d2d0665ccff04a9c58ea06", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03dbebcfdaa974176b2dbc20690bf7bd3dc953b2", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49a67455774027bf43e125ebcec8e8c59761c5d3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c28f151a3f5b00dc1173b591012f2324eed6c77", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7e5447fc93c510014eb1423830077fbb2bc2d64", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edbfc89dc19d7990ea30da74a6fc0c9fbd6fb1d9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9BYxxLj8l4vTne32fgGSpFRQGy9pCTW6PJGgQFfTTxw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98eb918b5e6e77a8b384c8d4218a78d633082a2c", "width": 1080, "height": 567}], "variants": {}, "id": "boA0N9RwTQ-9wNgQ3syjgIt8o2WOTcD7DBCszNyk9xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h6ncn", "is_robot_indexable": true, "report_reasons": null, "author": "Environmental-Bet-37", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h6ncn/i_need_help_to_analyze_a_very_complex_data_set/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h6ncn/i_need_help_to_analyze_a_very_complex_data_set/", "subreddit_subscribers": 91798, "created_utc": 1677863747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hybrid Transactional &amp; Analytical Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11h4swz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_0xW5Vgza2mJiYs2m5rSvGv-V57Gu6noy1HZNqlKYwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677860520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/hybrid-transactional-and-analytical?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?auto=webp&amp;v=enabled&amp;s=46650c7b2e994f7c1d3845c332a27ece26698bca", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58a307be1a6f03aae6744bc0213fe1aa39517298", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8df11889bf9945312cd40dca4b4c09179ff513e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2e6141ff6dcf098356028f38cea6bef7c6e8d32", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16aab14568c44e77e3c553ecda810a87b2856458", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a182910f265c4eacdf6112bbdb02265c47ad8352", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/kVle39QydTVYuwZPawYPkNmc_14RyIDfF1xTeR5bHzU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23c6006af004808deada0e0f860d3346ea39c123", "width": 1080, "height": 540}], "variants": {}, "id": "F4kAJ-nmXKrhwuVjOv0mbH8_wNBvV_maL71cx841E-g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11h4swz", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h4swz/hybrid_transactional_analytical_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/hybrid-transactional-and-analytical?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 91798, "created_utc": 1677860520.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}