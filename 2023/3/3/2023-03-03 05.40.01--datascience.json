{"kind": "Listing", "data": {"after": "t3_11gkhjs", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.", "author_fullname": "t2_da67df26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Unprofessional to leave after a year?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gh1yv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 197, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 197, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gh1yv", "is_robot_indexable": true, "report_reasons": null, "author": "Subject-Resort5893", "discussion_type": null, "num_comments": 126, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "subreddit_subscribers": 853443, "created_utc": 1677795987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: [**quix-streams**](https://github.com/quixio/quix-streams))   \nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: \n\n    def on_parameter_data_handler(df: pd.DataFrame):\n    \n        # If the braking force applied is more than 50%, we mark HardBraking with True\n        df[\"HardBraking\"] = df.apply(lambda row: \"True\" if row.Brake &gt; 0.5 else \"False\", axis=1)\n    \n        stream_producer.timeseries.publish(df)  # Send data back to the stream\n\n Anyway, just posting it here with the hope that it makes someone\u2019s job easier.", "author_fullname": "t2_byx12w8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A more accessible python library for interacting with Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g68dw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. My team has just open sourced a Python library that hopefully makes Kafka a bit more user-friendly for data Science and ML folks (you can find it here: &lt;a href=\"https://github.com/quixio/quix-streams\"&gt;&lt;strong&gt;quix-streams&lt;/strong&gt;&lt;/a&gt;)&lt;br/&gt;\nWhat I like about it is that you can send Pandas DataFrames straight to Kafka without any kind of conversion which makes things easier\u2014i.e. like this: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def on_parameter_data_handler(df: pd.DataFrame):\n\n    # If the braking force applied is more than 50%, we mark HardBraking with True\n    df[&amp;quot;HardBraking&amp;quot;] = df.apply(lambda row: &amp;quot;True&amp;quot; if row.Brake &amp;gt; 0.5 else &amp;quot;False&amp;quot;, axis=1)\n\n    stream_producer.timeseries.publish(df)  # Send data back to the stream\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Anyway, just posting it here with the hope that it makes someone\u2019s job easier.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?auto=webp&amp;v=enabled&amp;s=78d5675a84f6726e7618cd3c42250b7d51c363fa", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13a6a9b0f62ec4033e162a3122ec7f912271ca6a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc65e91fc8010c02faecf87eb3e910a374973c22", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42f0e4e73e3e4a79267bd8b98e97ca66836c96e6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19838c0ac27c309b1e866cc3aaae3b447bdd9671", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7215b5d40310d21d5d1e4a91848bac7d3147f437", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7J1m6iMTVT8_bsCsiQK-bnfSYSw1FFcL5AAAxKD45tw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fdcf5eafb0a7070f4aea6e4bdfacc90c0c14c34d", "width": 1080, "height": 540}], "variants": {}, "id": "ZuoT62YF_0noD68oqz7qPsTsv9obcPgozqhj0lnVZyk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g68dw", "is_robot_indexable": true, "report_reasons": null, "author": "Jota_Blanco", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g68dw/a_more_accessible_python_library_for_interacting/", "subreddit_subscribers": 853443, "created_utc": 1677772668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.\n\nI am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.\n\nThere seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.\n\nHere\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.\n\nDo I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.\n\nTL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?", "author_fullname": "t2_zeb0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Dashboard Solution, leaning Dash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ggw1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.&lt;/p&gt;\n\n&lt;p&gt;I am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.&lt;/p&gt;\n\n&lt;p&gt;There seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.&lt;/p&gt;\n\n&lt;p&gt;Do I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ggw1n", "is_robot_indexable": true, "report_reasons": null, "author": "GeneCreemers69", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "subreddit_subscribers": 853443, "created_utc": 1677795812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We have a model that's trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.\n\nProblem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn't too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. \n\nBut, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can't say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won't have to impute the missing values?\n\nAny tips would be highly appreciated \ud83d\ude4f", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Missing data related", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g8u9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677778919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a model that&amp;#39;s trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.&lt;/p&gt;\n\n&lt;p&gt;Problem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn&amp;#39;t too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. &lt;/p&gt;\n\n&lt;p&gt;But, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can&amp;#39;t say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won&amp;#39;t have to impute the missing values?&lt;/p&gt;\n\n&lt;p&gt;Any tips would be highly appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g8u9w", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g8u9w/missing_data_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g8u9w/missing_data_related/", "subreddit_subscribers": 853443, "created_utc": 1677778919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I've found out that it doesn't give the same model parameters.", "author_fullname": "t2_6zlc2ji4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing for RMSE vs. R2, for feature selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g416x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677767070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently employing forward selection on a large dataset, and wondering, should one be striving for minimizing the RMSE, or maximizing the R2 score? I&amp;#39;ve found out that it doesn&amp;#39;t give the same model parameters.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g416x", "is_robot_indexable": true, "report_reasons": null, "author": "dilkur", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g416x/optimizing_for_rmse_vs_r2_for_feature_selection/", "subreddit_subscribers": 853443, "created_utc": 1677767070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a master\u2019s degree in computer science from a top school in USA. I have a gpa of 3.9 and internship experience in data science where I worked on healthcare data. I\u2019m all in all a pretty smart dude, although I hate to admit it. I have good creative thinking, I have good communication skills, I also did the google data analytics certification to become \u201cjob ready\u201d whatever that means. On paper, I feel like I\u2019m a half decent candidate. Yet, I\u2019m finding job search incredibly challenging. I am ready to work in data analytics or data science, I am graduating this spring and I am applying to so many positions and getting rejected constantly. Being an international student, I know that most job\u2019s aren\u2019t open for me. But not getting a single interview except a few scam callers, is extremely demotivating. What am I doing wrong? And how can I improve my job search? These constant rejections have taken a huge toll on my health and wellbeing. Any help is appreciated. I have attached my resume for reference.\n\n[click me for resume](https://drive.google.com/file/d/1ODaok5gjNXwxiR29kZWhF8U226w8KaUg/view?usp=drivesdk)", "author_fullname": "t2_11otp57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job search is making me lose my mind", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gi0vc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677797036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a master\u2019s degree in computer science from a top school in USA. I have a gpa of 3.9 and internship experience in data science where I worked on healthcare data. I\u2019m all in all a pretty smart dude, although I hate to admit it. I have good creative thinking, I have good communication skills, I also did the google data analytics certification to become \u201cjob ready\u201d whatever that means. On paper, I feel like I\u2019m a half decent candidate. Yet, I\u2019m finding job search incredibly challenging. I am ready to work in data analytics or data science, I am graduating this spring and I am applying to so many positions and getting rejected constantly. Being an international student, I know that most job\u2019s aren\u2019t open for me. But not getting a single interview except a few scam callers, is extremely demotivating. What am I doing wrong? And how can I improve my job search? These constant rejections have taken a huge toll on my health and wellbeing. Any help is appreciated. I have attached my resume for reference.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/file/d/1ODaok5gjNXwxiR29kZWhF8U226w8KaUg/view?usp=drivesdk\"&gt;click me for resume&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?auto=webp&amp;v=enabled&amp;s=01f44c2bcbd2a6338da12a4f437fe002d69be2d0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ed78f1f45c3be2ecd96db039907171f8daca74", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7aefa9ef4909a73e136a59c8df00ef54d4017f63", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e977f7ac48cb854bd59f24283417a7694a3a69a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4c5ded83d7c0f4772e89cc7027055bba93c7f82", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75d98a415b6247233b72ee58675578413837dbbb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Mns0qPV3m1slwpBRlLjdTGCa_4wL1tQ6KMW7bk-8DNo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c2972b092f69fd542992a86955bf25808f036d6", "width": 1080, "height": 567}], "variants": {}, "id": "hxU87z_CxEKc-ClNMKtxEK2A4X4IRz7rjk3ifiq6hwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gi0vc", "is_robot_indexable": true, "report_reasons": null, "author": "ryanhiga2019", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gi0vc/job_search_is_making_me_lose_my_mind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gi0vc/job_search_is_making_me_lose_my_mind/", "subreddit_subscribers": 853443, "created_utc": 1677797036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m excited to share **ActiveLab**, a better algorithm for practical active learning.\n\nhttps://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441\n\nWe recently published a [paper](https://arxiv.org/abs/2301.11856) introducing this novel method and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we've made a quick [Jupyter tutorial](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) to run ActiveLab on your own data. For ML researchers, we've made all of our [benchmarking code](https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks) available for reproducibility so you can see for yourself how effective ActiveLab is in practice.\n\nLabeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: **which new data should I label, or which of my current labels should be checked again?**\n\nhttps://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532\n\nActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).\n\nIf you're interested in reading more, check out our blogpost: [https://cleanlab.ai/blog/active-learning/](https://cleanlab.ai/blog/active-learning/)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ActiveLab: Active Learning with Data Re-Labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": false, "media_metadata": {"txcqiokmndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/txcqiokmndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7d8d67e9a27f3e9285d527d97e3e4eb02745a31"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/txcqiokmndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e76a85cb7aed17de368f294442b8ebaf67689a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/txcqiokmndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58229ab58467ee7a78e93c80393f1add5197ce9d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/txcqiokmndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef92c312f65f5cb27f47322c13cd7da812bc331"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f7dc49616689bbf2494f80cdef7b794eb239377"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532"}, "id": "txcqiokmndla1"}, "j2payaxlndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/j2payaxlndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01d685cfe0e84c7330b2a6c8539f6a4962a6f49f"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/j2payaxlndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee839ef82870e92011aa669f688ae342c0ccfe5a"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/j2payaxlndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01bb7951a8dd486e1fcb47e6afa8342c061092cb"}, {"y": 521, "x": 640, "u": "https://preview.redd.it/j2payaxlndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32109a8f100ca18f84d51c80feaf5f12e7cbde28"}, {"y": 782, "x": 960, "u": "https://preview.redd.it/j2payaxlndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=376c6267681605bba52a5b4571dd3b35efa4c285"}, {"y": 879, "x": 1080, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcdddc82c386ea077c6ab26e82746573fb30e394"}], "s": {"y": 1258, "x": 1544, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441"}, "id": "j2payaxlndla1"}}, "name": "t3_11gbjgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvoqFpUhmlzuenpEc3NFwOVAKwdWZiUsqZ7tUQ83SYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677785412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m excited to share &lt;strong&gt;ActiveLab&lt;/strong&gt;, a better algorithm for practical active learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441\"&gt;https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We recently published a &lt;a href=\"https://arxiv.org/abs/2301.11856\"&gt;paper&lt;/a&gt; introducing this novel method and an &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;open-source&lt;/a&gt; Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we&amp;#39;ve made a quick &lt;a href=\"https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb\"&gt;Jupyter tutorial&lt;/a&gt; to run ActiveLab on your own data. For ML researchers, we&amp;#39;ve made all of our &lt;a href=\"https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks\"&gt;benchmarking code&lt;/a&gt; available for reproducibility so you can see for yourself how effective ActiveLab is in practice.&lt;/p&gt;\n\n&lt;p&gt;Labeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: &lt;strong&gt;which new data should I label, or which of my current labels should be checked again?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532\"&gt;https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in reading more, check out our blogpost: &lt;a href=\"https://cleanlab.ai/blog/active-learning/\"&gt;https://cleanlab.ai/blog/active-learning/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbjgm", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "subreddit_subscribers": 853443, "created_utc": 1677785412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tl;dr: **How \"static\" should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?**\n\nFor example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?\n\n\\---\n\nI was having an argument with a colleague of mine where he argued the point *that a new holdout dataset should be created every time we train a new model*, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.\n\nHis reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn't make sense.\n\nMy argument was *in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time*. \n\nMy reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.", "author_fullname": "t2_u1cec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How \"static\" should holdout datasets be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g60h8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677772142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr: &lt;strong&gt;How &amp;quot;static&amp;quot; should holdout datasets be? should we have a single dataset that we compare against no matter how many times we retrain the model? should a new holdout dataset be created every time training happens?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For example, should we create a new holdout dataset each time we train the model so that then we can assert that the recently trained model performs well in the new data compared to the old model?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I was having an argument with a colleague of mine where he argued the point &lt;em&gt;that a new holdout dataset should be created every time we train a new model&lt;/em&gt;, it is against this holdout dataset that we should then perform a model comparison between what we currently have in production and the recently trained model. This holdout dataset would then be used to perform data drift checks in production, to guarantee that the model is receiving similar data to the one we trained the model on.&lt;/p&gt;\n\n&lt;p&gt;His reasoning is that if we are retraining a model every-so-often is because we assume data will change often, and having a static dataset doesn&amp;#39;t make sense.&lt;/p&gt;\n\n&lt;p&gt;My argument was &lt;em&gt;in favour of having a single, static holdout dataset that we then use to validate both the data we will use to train the model, as well as data we are receiving at inference time&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;My reasoning is that yes, while we are retraining often, we probably want a fair measure of how far our data has drifted from the point we made decisions on how the model was built, and selecting the holdout data from the same distribution the model is being trained on is not ideal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g60h8", "is_robot_indexable": true, "report_reasons": null, "author": "fferegrino", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g60h8/how_static_should_holdout_datasets_be/", "subreddit_subscribers": 853443, "created_utc": 1677772142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey All--\n\nHas anyone tried taking any SWE or DevOps courses for DS/ML?\n\nI've noticed that the field is moving in that direction and want to prepare for that shift as best I can. It's also probably my weakest area.", "author_fullname": "t2_vhqp49rd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DevOps or SWE Courses for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnghl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All--&lt;/p&gt;\n\n&lt;p&gt;Has anyone tried taking any SWE or DevOps courses for DS/ML?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve noticed that the field is moving in that direction and want to prepare for that shift as best I can. It&amp;#39;s also probably my weakest area.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnghl", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Sky-6190", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "subreddit_subscribers": 853443, "created_utc": 1677807340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/\n\ncould anyone shed some light on what I should expect from this role?\n\nThanks", "author_fullname": "t2_9wyrffxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect from an wget level data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnec8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/&lt;/p&gt;\n\n&lt;p&gt;could anyone shed some light on what I should expect from this role?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnec8", "is_robot_indexable": true, "report_reasons": null, "author": "Appropriate-Item-162", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "subreddit_subscribers": 853443, "created_utc": 1677807189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it's a proxy variable at the most and doesn't hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.\n\nNow I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I'd like to find.\n\nThanks!", "author_fullname": "t2_bvba4ue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify underlying features for the Proxy variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gjlor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677808449.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677798772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it&amp;#39;s a proxy variable at the most and doesn&amp;#39;t hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.&lt;/p&gt;\n\n&lt;p&gt;Now I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I&amp;#39;d like to find.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gjlor", "is_robot_indexable": true, "report_reasons": null, "author": "invincible_moron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "subreddit_subscribers": 853443, "created_utc": 1677798772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.\n\nEDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.", "author_fullname": "t2_bvyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/Cons of Moving over to Exclusively Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbv79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.&lt;/p&gt;\n\n&lt;p&gt;EDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbv79", "is_robot_indexable": true, "report_reasons": null, "author": "robml", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "subreddit_subscribers": 853443, "created_utc": 1677786167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i am just starting of learning data science can anyone steer me in the right direction where should I start what resources are perfect for a beginner etc .......", "author_fullname": "t2_ofd53vwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11gqo3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677816137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i am just starting of learning data science can anyone steer me in the right direction where should I start what resources are perfect for a beginner etc .......&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gqo3n", "is_robot_indexable": true, "report_reasons": null, "author": "RayTaglioferro", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gqo3n/need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gqo3n/need_help/", "subreddit_subscribers": 853443, "created_utc": 1677816137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI've seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. \n\nI am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). \n\nI've heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.\n\nI'm sure there's a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people's experiences and if this is something possible within data science.\n\nThank you in advance!", "author_fullname": "t2_62z9s6lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote and travel jobs or consultant roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11gqhz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677815670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. &lt;/p&gt;\n\n&lt;p&gt;I am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people&amp;#39;s experiences and if this is something possible within data science.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gqhz7", "is_robot_indexable": true, "report_reasons": null, "author": "TibialCuriosity", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "subreddit_subscribers": 853443, "created_utc": 1677815670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 5 Data Science Certifications In-demand By Fortune 500 Firms in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11gozlz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jpa5zGKrPsBmU9gp5M9PGwa3zHgupMrX8a--NOxfPvE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677811460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/codex/top-5-data-science-certifications-in-demand-by-fortune-500-firms-in-2022-362ad4e26b0f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?auto=webp&amp;v=enabled&amp;s=1c7a5544bf71733a972cefe6863d291dec613af5", "width": 1000, "height": 563}, "resolutions": [{"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eefd80013962403fd9b30b73e330356382cc8202", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d527d6f2191a5aff97aaf1b96d6e5d47786d53ce", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9b7e9765ebea52917b8a64d02570d92119162e5", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=536916a7cb830462627a2989f7ea7c64bc945e01", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/xGmIuwEqE46coAbcDQfF2YOt12tJD5NYz5Nb_VdiBTo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=154b74547d1db222b20dce59d962a7cda0350951", "width": 960, "height": 540}], "variants": {}, "id": "jWKnS51U-GO64pHhrfL8emOGvtr2S14HtdjBSM3fEoo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gozlz", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gozlz/top_5_data_science_certifications_indemand_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/codex/top-5-data-science-certifications-in-demand-by-fortune-500-firms-in-2022-362ad4e26b0f", "subreddit_subscribers": 853443, "created_utc": 1677811460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For those coming from top-tier competitive programs. I've interviewed for a few positions and salaries seem to be lower than what I expected.", "author_fullname": "t2_7wgr2t9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What sort of salary offers are you getting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gmkwd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677805038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those coming from top-tier competitive programs. I&amp;#39;ve interviewed for a few positions and salaries seem to be lower than what I expected.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gmkwd", "is_robot_indexable": true, "report_reasons": null, "author": "myco_mark", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gmkwd/what_sort_of_salary_offers_are_you_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gmkwd/what_sort_of_salary_offers_are_you_getting/", "subreddit_subscribers": 853443, "created_utc": 1677805038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_iikq8tv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to import data from Microsoft azure to SQL server in batches by running a service every week such that it gets appended to the already existing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gmimx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677804872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gmimx", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Lawyer-3877", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "subreddit_subscribers": 853443, "created_utc": 1677804872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi r/datascience!\n\ni recently built this mentor network for new college/masters grads or current professionals looking to switch industries or who are preparing to recruit. they can match with available mentors (primarily in tech / banking / consulting) and do a 1:1 session virtually. they can use the time however they like, but generally people like to do interview prep, resume review, general career advice.\n\nfeel free to check it out! link to the website \\[[here](https://mentorme.squarespace.com)\\]. \n\nalso - this is my first website so any feedback would be appreciated!", "author_fullname": "t2_12xkb1xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "built something y'all might be interested in", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gl11f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677801165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;i recently built this mentor network for new college/masters grads or current professionals looking to switch industries or who are preparing to recruit. they can match with available mentors (primarily in tech / banking / consulting) and do a 1:1 session virtually. they can use the time however they like, but generally people like to do interview prep, resume review, general career advice.&lt;/p&gt;\n\n&lt;p&gt;feel free to check it out! link to the website [&lt;a href=\"https://mentorme.squarespace.com\"&gt;here&lt;/a&gt;]. &lt;/p&gt;\n\n&lt;p&gt;also - this is my first website so any feedback would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?auto=webp&amp;v=enabled&amp;s=b87edbe8c930b52e20588134ddba11dae22f59c6", "width": 726, "height": 344}, "resolutions": [{"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bd7c8282ba436697397e91ed952cb56f2ad8f43", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d2ccaba2009492edce67bf3fd9a0b64d6d23227", "width": 216, "height": 102}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75af5f33aa31a26d2a6fd13573ed72c84a050e16", "width": 320, "height": 151}, {"url": "https://external-preview.redd.it/f8z5lYvxh35YSBc_WemM1zOgVcDTuFn29W7SlG3kMro.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fb9534ab641d1ed234975d6d0833cedcdfc4980", "width": 640, "height": 303}], "variants": {}, "id": "Rxwa8JHZURQb0aeY40iZiC5kJEJxImxZwykFQiO53I0"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "award_19860e30-3331-4bac-b3d1-bd28de0c7974", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=7434e8ec65f434b811666ff6be1cbc18e675c5bf", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=aacfdc98efb123d6d4464d6a227aff2f9d90a3fb", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=af6b886c9a013bed09f09ef8bb3757f14a1286b9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=0e3debe040221236e3cdde5840d9ea8f67d7dca9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=bd5fb5fe09c1ac5e0d58faed4fc7e9108f6f7718", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I needed this today", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Heartwarming", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=7434e8ec65f434b811666ff6be1cbc18e675c5bf", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=aacfdc98efb123d6d4464d6a227aff2f9d90a3fb", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=af6b886c9a013bed09f09ef8bb3757f14a1286b9", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=0e3debe040221236e3cdde5840d9ea8f67d7dca9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=bd5fb5fe09c1ac5e0d58faed4fc7e9108f6f7718", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/v1mxw8i6wnf51_Heartwarming.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gl11f", "is_robot_indexable": true, "report_reasons": null, "author": "nong-shim-shin-RAMEN", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gl11f/built_something_yall_might_be_interested_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gl11f/built_something_yall_might_be_interested_in/", "subreddit_subscribers": 853443, "created_utc": 1677801165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?", "author_fullname": "t2_cps0d40y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Degrees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkmie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gkmie", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Matress27", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gkmie/data_engineering_degrees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gkmie/data_engineering_degrees/", "subreddit_subscribers": 853443, "created_utc": 1677800304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to learn data collection using webscraping and APIs, and I also want to really learn how to process data. Can you guys hook me up with some free resources?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do i learn data collection and processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gj0v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677798138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn data collection using webscraping and APIs, and I also want to really learn how to process data. Can you guys hook me up with some free resources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gj0v1", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gj0v1/how_do_i_learn_data_collection_and_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gj0v1/how_do_i_learn_data_collection_and_processing/", "subreddit_subscribers": 853443, "created_utc": 1677798138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title states. I am going to start job searching soon, probably in the next 1-2 weeks.\n\nAny suggestions for interesting data to collect during this whole process?", "author_fullname": "t2_tmggpdhm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soon I will start sending out job applications. What data do would be interesting to collect regarding the job hunting process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gidud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677797434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title states. I am going to start job searching soon, probably in the next 1-2 weeks.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for interesting data to collect during this whole process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gidud", "is_robot_indexable": true, "report_reasons": null, "author": "49-eggs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gidud/soon_i_will_start_sending_out_job_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gidud/soon_i_will_start_sending_out_job_applications/", "subreddit_subscribers": 853443, "created_utc": 1677797434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for some options on new visualization tools that are 508 compliant. AWS QS puts it on their roadmap for some time next year. I know PowerBI and Tableau are compliant but they're also very expensive to deploy and support a large numbers of users. I'm honestly looking for a more custom option like a shiny dashboard that I could custom code but it seems like making a compliant shiny dashboard would be a nightmare to maintain. Anyone have any experience with these types of requirements and have tooling suggestions?", "author_fullname": "t2_gepu6ks7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "508 Compliant Visualization Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbuzh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some options on new visualization tools that are 508 compliant. AWS QS puts it on their roadmap for some time next year. I know PowerBI and Tableau are compliant but they&amp;#39;re also very expensive to deploy and support a large numbers of users. I&amp;#39;m honestly looking for a more custom option like a shiny dashboard that I could custom code but it seems like making a compliant shiny dashboard would be a nightmare to maintain. Anyone have any experience with these types of requirements and have tooling suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbuzh", "is_robot_indexable": true, "report_reasons": null, "author": "Empty_Search6446", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbuzh/508_compliant_visualization_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbuzh/508_compliant_visualization_tools/", "subreddit_subscribers": 853443, "created_utc": 1677786150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to classify proteins based on certain properties, some of which are matrices. \n\nSome features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.\n\nWhatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.\n\nHow do I solve for this?", "author_fullname": "t2_15k55n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with vectors as features in a dataset for classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g7srv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677776438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to classify proteins based on certain properties, some of which are matrices. &lt;/p&gt;\n\n&lt;p&gt;Some features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.&lt;/p&gt;\n\n&lt;p&gt;Whatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.&lt;/p&gt;\n\n&lt;p&gt;How do I solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g7srv", "is_robot_indexable": true, "report_reasons": null, "author": "colouredzindagi", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "subreddit_subscribers": 853443, "created_utc": 1677776438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone \u270c\ud83c\udffc\n\nI have been building a model where I forecast the volume of calls per month based on the historical data of each service desk (the company provides call center infrastructure for multiple services).\n\nI started with using Triple Exponential Smoothing for the task, but due to the large sample of data and the period extention sometimes when I run the code it takes ages to solve it, I understand that the model computes the pattern, trend and seasons of the data to provide the best output based on the previous history.\n\nThe problem is that it takes too long to calculate the results (probably it's due to the lack of computing power of the company's laptop).\n\nCould you recommend me to use another model?\nWhich one would think is a better option?\n\nAnd I'm interested in adding variables, so the model consider other inputs like vacations, special dates that the company knows it will have high volume of calls, etc.\nIs there any algorithm that could allow me to Forecast based on historical data with variables created by the business criteria?", "author_fullname": "t2_gtrwejrw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ways to Forecast Volume of incoming Calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gl412", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677801361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone \u270c\ud83c\udffc&lt;/p&gt;\n\n&lt;p&gt;I have been building a model where I forecast the volume of calls per month based on the historical data of each service desk (the company provides call center infrastructure for multiple services).&lt;/p&gt;\n\n&lt;p&gt;I started with using Triple Exponential Smoothing for the task, but due to the large sample of data and the period extention sometimes when I run the code it takes ages to solve it, I understand that the model computes the pattern, trend and seasons of the data to provide the best output based on the previous history.&lt;/p&gt;\n\n&lt;p&gt;The problem is that it takes too long to calculate the results (probably it&amp;#39;s due to the lack of computing power of the company&amp;#39;s laptop).&lt;/p&gt;\n\n&lt;p&gt;Could you recommend me to use another model?\nWhich one would think is a better option?&lt;/p&gt;\n\n&lt;p&gt;And I&amp;#39;m interested in adding variables, so the model consider other inputs like vacations, special dates that the company knows it will have high volume of calls, etc.\nIs there any algorithm that could allow me to Forecast based on historical data with variables created by the business criteria?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gl412", "is_robot_indexable": true, "report_reasons": null, "author": "_techmaniac_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gl412/ways_to_forecast_volume_of_incoming_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gl412/ways_to_forecast_volume_of_incoming_calls/", "subreddit_subscribers": 853443, "created_utc": 1677801361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Preface: I know this is the DS sub, but I haven\u2019t gotten a response from anyone in the DE sub.**\n\nI'm currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I'm developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB's to Azure and add them to elastic pools - nothing crazy.\n\nI'm currently working on my MS in DS while working full time. It's quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp; Finance.\n\nI've been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I'm extremely interested in and I was ecstatic to find out I got an interview. \n\nLong story short, I have just completed the 3rd and final interview they\u2019ve offered me the position. I\u2019m just worried I might struggle to balance the masters workload and the new job. \n\nBelow are the general job duties:\n\n* Identifying and implementing optimal cloud-based solutions, including team education and training\n* Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance\n* Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science\n* Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures\n* Orchestrating and automating cloud operations and processes\n* Collaborating with stakeholders across the business to balance competing objectives\n* Working with third-party vendors to meet business requirements.\n\nAs I mentioned before, I don't have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide's, but nothing in terms of actual development.\n\nA few questions/concerns:\n\n* Firstly, does it seem like I have imposter syndrome? I worry that I'm just not qualified for this job and I won't deliver what they expect\n* Do I continue my MS if I'm getting legitimate experience as a Cloud Engineer?\n* If I do continue my MS, am I going to be able to manage the workload with this new role?\n* The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?\n\nThank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice Wanted", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkhjs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677800312.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Preface: I know this is the DS sub, but I haven\u2019t gotten a response from anyone in the DE sub.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data Migration Analyst for a tech startup. I enjoy the job, as I&amp;#39;m developing a diverse set of skills. I work with a ton of SQL, JSON and Azure. In regards to Azure, I generally just deploy DB&amp;#39;s to Azure and add them to elastic pools - nothing crazy.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on my MS in DS while working full time. It&amp;#39;s quite a bit of work, but I WFH so I do school work during the day as well. I also have an undergrad double major in Data Analytics &amp;amp; Finance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been interviewing for a WFH  Jr. Cloud Engineer job. The company is in a field I&amp;#39;m extremely interested in and I was ecstatic to find out I got an interview. &lt;/p&gt;\n\n&lt;p&gt;Long story short, I have just completed the 3rd and final interview they\u2019ve offered me the position. I\u2019m just worried I might struggle to balance the masters workload and the new job. &lt;/p&gt;\n\n&lt;p&gt;Below are the general job duties:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identifying and implementing optimal cloud-based solutions, including team education and training&lt;/li&gt;\n&lt;li&gt;Participating in the software development life cycle, including planning, requirements, development, testing, and quality assurance&lt;/li&gt;\n&lt;li&gt;Building tools and systems to improve the time to market of product offerings in partnership with Product, Trading, and Data Science&lt;/li&gt;\n&lt;li&gt;Troubleshooting incidents, identifying root causes, fixing and documenting problems, and implementing preventive measures&lt;/li&gt;\n&lt;li&gt;Orchestrating and automating cloud operations and processes&lt;/li&gt;\n&lt;li&gt;Collaborating with stakeholders across the business to balance competing objectives&lt;/li&gt;\n&lt;li&gt;Working with third-party vendors to meet business requirements.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As I mentioned before, I don&amp;#39;t have any experience in building a Cloud pipeline by any means. I understand the functionalities of  Cloud platforms and how they interact with SQL ide&amp;#39;s, but nothing in terms of actual development.&lt;/p&gt;\n\n&lt;p&gt;A few questions/concerns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Firstly, does it seem like I have imposter syndrome? I worry that I&amp;#39;m just not qualified for this job and I won&amp;#39;t deliver what they expect&lt;/li&gt;\n&lt;li&gt;Do I continue my MS if I&amp;#39;m getting legitimate experience as a Cloud Engineer?&lt;/li&gt;\n&lt;li&gt;If I do continue my MS, am I going to be able to manage the workload with this new role?&lt;/li&gt;\n&lt;li&gt;The expected pay is about $10,000 higher in the new role with a better job title - if my current job offers a similar pay raise and a new title + added responsibilities, should I just stay?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for reading and any advice would be awesome. I love the field of Data in general and the helpfulness of the community, you guys are the best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gkhjs", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gkhjs/career_advice_wanted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gkhjs/career_advice_wanted/", "subreddit_subscribers": 853443, "created_utc": 1677800039.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}