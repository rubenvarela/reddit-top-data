{"kind": "Listing", "data": {"after": "t3_11gxsne", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.", "author_fullname": "t2_da67df26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Unprofessional to leave after a year?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gh1yv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 351, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 351, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been offered a 50 percent pay bump to be a data scientist at a Fortune 500 company in my home town. It\u2019s everything I\u2019d want in a career, but I\u2019d feel so guilty leaving my current company (a small startup with a small data team) after only 13 months or so. Would it be unprofessional to leave? Would it come off as flipping the bird to my current team? Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gh1yv", "is_robot_indexable": true, "report_reasons": null, "author": "Subject-Resort5893", "discussion_type": null, "num_comments": 213, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gh1yv/how_unprofessional_to_leave_after_a_year/", "subreddit_subscribers": 853568, "created_utc": 1677795987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tldr; if i don't google it, my model making process suck haaaaard and that make me feel like a fraud, and even with learning so much over the past few years, my model making didn't change, i feel like i ve gotten good at researching/knowing what to research but without googling to well find it i suck......(Add in my not even mediocre knowledge in programming) It feels like no matter what i do, i am stuck at the start not making progress, the only thing improving is knowing how to google and what to google.\n\nHello, this is probably my first post, been a long time reddit lurker but just recently created an account.\n\nI am a student in DS, currently in my final year internship (it lasts 6 months).  \nI feel like i don't know the basics at all, that i don't even know how to deal with the data i am given.\n\nIf you ask me to code smtg make a model etc, i will be able to do it, if you tell me it sucks and must improve this and this , i will be able to do it, the problem is that i spend most of the time just googling to remind myself of X concept and how to properly apply it (like data cleaning), if i don't google it, i have no proper flow when it comes to dealing with a data, if you gave me a data and asked me to create a model on it without doing much research here is what i would do :  \n1 \\_ Clean it by : Removing gibberish data aka data that is corrupted, replace the missing values with an appropriate value if possible, if very few i simply toss them (like less than \\~5% of my data), otherwise i replace by using the mean value of my data (unless there is too much missing but never happened), i keep searching for \"abnoraml things\" in my data and mostly just remove them or find an explanation for them (like outliers)  \n2 \\_ DataViz : I just do very simple graphs checking the distro of my variables, have no constant way to deal with outliers other than removing them if they obvious input mistakes....Corr Matrix, i usually drop highly correlated value if i am using logistic reg, but usually i just keep them for interpretation.  \n3 \\_ Model : Unless obvious, i simply test many models and choose the one with the better metrics for the current problem...\n\nyeah quite ..lacking, for school projects and such i always had to research a lot (for god's sake i have to return every single time to pandas docs and i ve been using it for so long)  \n that's it.....i have knowledge in DataWarehousing, using hadoop, a bit of spark, ETL but no huge application or work standard just me screwing around with the concepts, creating small time projects from time to time, some background in statistics/optimization..i didn't even know what GIL was in python until recently, i don't understand the diff btw concurrent and multithreading or when to use them.. i mainly code in python but have dabbled in C, Java and Lisp (i rarely use object programming but i do understand it and it's usefuleness, planning on learning Clojure in the future...) (coded some data struct in C library, but when i look at my code i am like : did i code that ?)  \nMy few postives is that : It doesn't take much to \"relearn\" whathever concept i forgot. I have a good background in math and i understand quite fast mathematical concepts. I am a nerd when it comes to researching a specific thing or needing a specific tool/concept for a pet project or any work in general, but i usually tend to forget such knowledge by the time i start a new project....i feel like i am just a fraud that is constantly using google and would't even be able to do shit without googling, most of school projects are : Me coding some stuff, see a nice github project, take a part of it or the whole project, revamp it for my need and that's it....  \nMy current internship concerns creating a Data Quality Framework (don't know shit about it just started learning it this week), and since i am not going to be making ML (let's not even talk about DL or NLP whom i love but i am clearly just researching papers and applying whtever they do and revamping it a bit..i suck at knowing how many layers i should put etc etc..) models i fear like this gap will just increase....  \n\n\nSry too much writing, i am kinda feeling lost and don't know what to do next, i feel that whathever i spend time on would be wasting time i shoudl use to return to the fundamentals.....i don't even know how to correctly express this sick feeling...if you remove google i am just some random guy who know how to do some \"high-level\" math ( and even in math i started googling some concepts just because it's been a while (since most libraries do them in my place).", "author_fullname": "t2_fcv4rhtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like a fraud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h03rt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677848223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tldr; if i don&amp;#39;t google it, my model making process suck haaaaard and that make me feel like a fraud, and even with learning so much over the past few years, my model making didn&amp;#39;t change, i feel like i ve gotten good at researching/knowing what to research but without googling to well find it i suck......(Add in my not even mediocre knowledge in programming) It feels like no matter what i do, i am stuck at the start not making progress, the only thing improving is knowing how to google and what to google.&lt;/p&gt;\n\n&lt;p&gt;Hello, this is probably my first post, been a long time reddit lurker but just recently created an account.&lt;/p&gt;\n\n&lt;p&gt;I am a student in DS, currently in my final year internship (it lasts 6 months).&lt;br/&gt;\nI feel like i don&amp;#39;t know the basics at all, that i don&amp;#39;t even know how to deal with the data i am given.&lt;/p&gt;\n\n&lt;p&gt;If you ask me to code smtg make a model etc, i will be able to do it, if you tell me it sucks and must improve this and this , i will be able to do it, the problem is that i spend most of the time just googling to remind myself of X concept and how to properly apply it (like data cleaning), if i don&amp;#39;t google it, i have no proper flow when it comes to dealing with a data, if you gave me a data and asked me to create a model on it without doing much research here is what i would do :&lt;br/&gt;\n1 _ Clean it by : Removing gibberish data aka data that is corrupted, replace the missing values with an appropriate value if possible, if very few i simply toss them (like less than ~5% of my data), otherwise i replace by using the mean value of my data (unless there is too much missing but never happened), i keep searching for &amp;quot;abnoraml things&amp;quot; in my data and mostly just remove them or find an explanation for them (like outliers)&lt;br/&gt;\n2 _ DataViz : I just do very simple graphs checking the distro of my variables, have no constant way to deal with outliers other than removing them if they obvious input mistakes....Corr Matrix, i usually drop highly correlated value if i am using logistic reg, but usually i just keep them for interpretation.&lt;br/&gt;\n3 _ Model : Unless obvious, i simply test many models and choose the one with the better metrics for the current problem...&lt;/p&gt;\n\n&lt;p&gt;yeah quite ..lacking, for school projects and such i always had to research a lot (for god&amp;#39;s sake i have to return every single time to pandas docs and i ve been using it for so long)&lt;br/&gt;\n that&amp;#39;s it.....i have knowledge in DataWarehousing, using hadoop, a bit of spark, ETL but no huge application or work standard just me screwing around with the concepts, creating small time projects from time to time, some background in statistics/optimization..i didn&amp;#39;t even know what GIL was in python until recently, i don&amp;#39;t understand the diff btw concurrent and multithreading or when to use them.. i mainly code in python but have dabbled in C, Java and Lisp (i rarely use object programming but i do understand it and it&amp;#39;s usefuleness, planning on learning Clojure in the future...) (coded some data struct in C library, but when i look at my code i am like : did i code that ?)&lt;br/&gt;\nMy few postives is that : It doesn&amp;#39;t take much to &amp;quot;relearn&amp;quot; whathever concept i forgot. I have a good background in math and i understand quite fast mathematical concepts. I am a nerd when it comes to researching a specific thing or needing a specific tool/concept for a pet project or any work in general, but i usually tend to forget such knowledge by the time i start a new project....i feel like i am just a fraud that is constantly using google and would&amp;#39;t even be able to do shit without googling, most of school projects are : Me coding some stuff, see a nice github project, take a part of it or the whole project, revamp it for my need and that&amp;#39;s it....&lt;br/&gt;\nMy current internship concerns creating a Data Quality Framework (don&amp;#39;t know shit about it just started learning it this week), and since i am not going to be making ML (let&amp;#39;s not even talk about DL or NLP whom i love but i am clearly just researching papers and applying whtever they do and revamping it a bit..i suck at knowing how many layers i should put etc etc..) models i fear like this gap will just increase....  &lt;/p&gt;\n\n&lt;p&gt;Sry too much writing, i am kinda feeling lost and don&amp;#39;t know what to do next, i feel that whathever i spend time on would be wasting time i shoudl use to return to the fundamentals.....i don&amp;#39;t even know how to correctly express this sick feeling...if you remove google i am just some random guy who know how to do some &amp;quot;high-level&amp;quot; math ( and even in math i started googling some concepts just because it&amp;#39;s been a while (since most libraries do them in my place).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h03rt", "is_robot_indexable": true, "report_reasons": null, "author": "Still-W1", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h03rt/i_feel_like_a_fraud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h03rt/i_feel_like_a_fraud/", "subreddit_subscribers": 853568, "created_utc": 1677848223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.\n\nI am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.\n\nThere seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.\n\nHere\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.\n\nDo I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.\n\nTL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?", "author_fullname": "t2_zeb0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Dashboard Solution, leaning Dash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ggw1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677795812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently started as the first data-related (or any tech-related, for that matter) hire at a marketing startup. My top priority is to create an interactive, web-based dashboard, customizable to each client\u2019s needs and relevant data.&lt;/p&gt;\n\n&lt;p&gt;I am leaning Plotly Dash because I want to grow my Python skills, and I think it\u2019d be free\u2014a big part of my uncertainty here.&lt;/p&gt;\n\n&lt;p&gt;There seems to be a lot of steps to host a Dash app on a web server without purchasing Dash Enterprise. I have no web dev experience, and only foundational Plotly experience. This has made it difficult to understand what I\u2019m really up against and whether I can truly do this for free (I\u2019m thinking charges for using Google Cloud or the like). From what I understand, I could deploy a Dash app with ContainDS Dashboards relatively easily, but PLEASE interject here if this is not ideal, considering security and privacy are important.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s more info on my background: I came from an entry-level data analyst job where I used Power BI and Excel primarily, but have spent free time learning data manipulation and visualization with Python (pandas, matplotlib/seaborn, foundational Plotly). I also have experience using Tableau. I recognize that deploying a Dash app is outside of my reach right now, but I really am wanting to make a leap in my technical ability. I have a DataCamp subscription, which has been a primary learning tool FWIW.&lt;/p&gt;\n\n&lt;p&gt;Do I continue pursuing Dash as the solution or do I just spend budget on Power BI or Tableau? Any input, advice, resources, etc. is appreciated. Especially related to goals of A) a dashboard solution for my employer and B) pursuing the right Python skills to keep me relevant in the data space in general.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: should this noob try to deploy a Dash app or just buy a Tableau license and spend Python-skill-building energy elsewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ggw1n", "is_robot_indexable": true, "report_reasons": null, "author": "GeneCreemers69", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ggw1n/web_dashboard_solution_leaning_dash/", "subreddit_subscribers": 853568, "created_utc": 1677795812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We have a model that's trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.\n\nProblem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn't too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. \n\nBut, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can't say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won't have to impute the missing values?\n\nAny tips would be highly appreciated \ud83d\ude4f", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Missing data related", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g8u9w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677778919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a model that&amp;#39;s trained on the end of month data. But we need to use it to get predictions before end of month - at the end of each week.&lt;/p&gt;\n\n&lt;p&gt;Problem is, for some features end of month missing percentage is ~10%, so that was the training data and we used median imputes which isn&amp;#39;t too terrible in this case. But at the beginning this missing rate is about 50% - these are the scoring data. &lt;/p&gt;\n\n&lt;p&gt;But, what to do with these columns with 50% missing in scoring data? Imputing them with training data mean will inflate these values and we can&amp;#39;t say missing is 0 since 0 is a valid data in these cols. Is using tree based algos RF/XG or CatBoost a better alternative since then we won&amp;#39;t have to impute the missing values?&lt;/p&gt;\n\n&lt;p&gt;Any tips would be highly appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g8u9w", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g8u9w/missing_data_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g8u9w/missing_data_related/", "subreddit_subscribers": 853568, "created_utc": 1677778919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey All--\n\nHas anyone tried taking any SWE or DevOps courses for DS/ML?\n\nI've noticed that the field is moving in that direction and want to prepare for that shift as best I can. It's also probably my weakest area.", "author_fullname": "t2_vhqp49rd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DevOps or SWE Courses for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnghl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All--&lt;/p&gt;\n\n&lt;p&gt;Has anyone tried taking any SWE or DevOps courses for DS/ML?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve noticed that the field is moving in that direction and want to prepare for that shift as best I can. It&amp;#39;s also probably my weakest area.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnghl", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Sky-6190", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnghl/devops_or_swe_courses_for_ml/", "subreddit_subscribers": 853568, "created_utc": 1677807340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m excited to share **ActiveLab**, a better algorithm for practical active learning.\n\nhttps://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441\n\nWe recently published a [paper](https://arxiv.org/abs/2301.11856) introducing this novel method and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we've made a quick [Jupyter tutorial](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) to run ActiveLab on your own data. For ML researchers, we've made all of our [benchmarking code](https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks) available for reproducibility so you can see for yourself how effective ActiveLab is in practice.\n\nLabeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: **which new data should I label, or which of my current labels should be checked again?**\n\nhttps://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532\n\nActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).\n\nIf you're interested in reading more, check out our blogpost: [https://cleanlab.ai/blog/active-learning/](https://cleanlab.ai/blog/active-learning/)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ActiveLab: Active Learning with Data Re-Labeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": false, "media_metadata": {"txcqiokmndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/txcqiokmndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7d8d67e9a27f3e9285d527d97e3e4eb02745a31"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/txcqiokmndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e76a85cb7aed17de368f294442b8ebaf67689a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/txcqiokmndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58229ab58467ee7a78e93c80393f1add5197ce9d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/txcqiokmndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef92c312f65f5cb27f47322c13cd7da812bc331"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f7dc49616689bbf2494f80cdef7b794eb239377"}], "s": {"y": 540, "x": 960, "u": "https://preview.redd.it/txcqiokmndla1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=33d07e3d61846b539163056f8ce2477cc1155532"}, "id": "txcqiokmndla1"}, "j2payaxlndla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/j2payaxlndla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01d685cfe0e84c7330b2a6c8539f6a4962a6f49f"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/j2payaxlndla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee839ef82870e92011aa669f688ae342c0ccfe5a"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/j2payaxlndla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01bb7951a8dd486e1fcb47e6afa8342c061092cb"}, {"y": 521, "x": 640, "u": "https://preview.redd.it/j2payaxlndla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32109a8f100ca18f84d51c80feaf5f12e7cbde28"}, {"y": 782, "x": 960, "u": "https://preview.redd.it/j2payaxlndla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=376c6267681605bba52a5b4571dd3b35efa4c285"}, {"y": 879, "x": 1080, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcdddc82c386ea077c6ab26e82746573fb30e394"}], "s": {"y": 1258, "x": 1544, "u": "https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a20bea467c3691780e9927d83d54f541a1888441"}, "id": "j2payaxlndla1"}}, "name": "t3_11gbjgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TvoqFpUhmlzuenpEc3NFwOVAKwdWZiUsqZ7tUQ83SYQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677785412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m excited to share &lt;strong&gt;ActiveLab&lt;/strong&gt;, a better algorithm for practical active learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441\"&gt;https://preview.redd.it/j2payaxlndla1.png?width=1544&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a20bea467c3691780e9927d83d54f541a1888441&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We recently published a &lt;a href=\"https://arxiv.org/abs/2301.11856\"&gt;paper&lt;/a&gt; introducing this novel method and an &lt;a href=\"https://github.com/cleanlab/cleanlab\"&gt;open-source&lt;/a&gt; Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, we&amp;#39;ve made a quick &lt;a href=\"https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb\"&gt;Jupyter tutorial&lt;/a&gt; to run ActiveLab on your own data. For ML researchers, we&amp;#39;ve made all of our &lt;a href=\"https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks\"&gt;benchmarking code&lt;/a&gt; available for reproducibility so you can see for yourself how effective ActiveLab is in practice.&lt;/p&gt;\n\n&lt;p&gt;Labeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: &lt;strong&gt;which new data should I label, or which of my current labels should be checked again?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532\"&gt;https://preview.redd.it/txcqiokmndla1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=33d07e3d61846b539163056f8ce2477cc1155532&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in reading more, check out our blogpost: &lt;a href=\"https://cleanlab.ai/blog/active-learning/\"&gt;https://cleanlab.ai/blog/active-learning/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbjgm", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbjgm/activelab_active_learning_with_data_relabeling/", "subreddit_subscribers": 853568, "created_utc": 1677785412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vkom8wkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teaching old labels new tricks in heterogeneous graphs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_11gyrvc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/mx7688FCXPqQneOt9I3WPsbALwYMQi6HiMYVMAGcfl4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677844284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ai.googleblog.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ai.googleblog.com/2023/03/teaching-old-labels-new-tricks-in.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?auto=webp&amp;v=enabled&amp;s=36133f75c409b5a868d0813e1d0ab28abfa8a2b7", "width": 1068, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e44e8f9c31dfcdee03cdb1372d4501eee249e064", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=872706d82e7e75e7c0634bfc390774bfd634cebc", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b27a6bc6d361bf469c74916adfdefb703b1bc4b5", "width": 320, "height": 188}, {"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3f07943e2dbf34f797e695521b23a859cd40335", "width": 640, "height": 377}, {"url": "https://external-preview.redd.it/obT1mqpBYbd9CNjcIX39XBQC_egaX-MFVd0BI7RFVkk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ae958206040613c6b352910dfbbc24775befce9", "width": 960, "height": 566}], "variants": {}, "id": "xs2XEVDmp5X-0kJK5mvYbVsZqqqj3UI00l4Gw3jfy4Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gyrvc", "is_robot_indexable": true, "report_reasons": null, "author": "JuYuJu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gyrvc/teaching_old_labels_new_tricks_in_heterogeneous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ai.googleblog.com/2023/03/teaching-old-labels-new-tricks-in.html", "subreddit_subscribers": 853568, "created_utc": 1677844284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just got my hand slapped by Google so I'm looking for suggestions. I am using \"distance\" as a machine learning feature, and have been using the Google Maps API to 1) find the geocoordinates associated with an address, and 2) find the driving distance from that location to a fixed point. My account has just been temporarily suspended due to a violation of \"scraping\" policy.\n\nDoes anyone have experience with a similar service that is more suited/friendly to data science applications?", "author_fullname": "t2_7f862m8z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API for Geolocation and Distance Matrices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11h3te5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677858134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got my hand slapped by Google so I&amp;#39;m looking for suggestions. I am using &amp;quot;distance&amp;quot; as a machine learning feature, and have been using the Google Maps API to 1) find the geocoordinates associated with an address, and 2) find the driving distance from that location to a fixed point. My account has just been temporarily suspended due to a violation of &amp;quot;scraping&amp;quot; policy.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience with a similar service that is more suited/friendly to data science applications?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h3te5", "is_robot_indexable": true, "report_reasons": null, "author": "djrit", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h3te5/api_for_geolocation_and_distance_matrices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h3te5/api_for_geolocation_and_distance_matrices/", "subreddit_subscribers": 853568, "created_utc": 1677858134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ll admit that I occasionally let myself drift through LinkedIn and look at the profiles of others in the field and while I recognize that a great deal of LinkedIn is embellished, something I do notice on profiles a good deal is the submissions of papers to journals or to conferences in the field. \n\nNow, I view these things as high achievement. I\u2019ve even seen a good portion of job descriptions that have these things as requirements. I have to admit, I don\u2019t even have a clue where to start and that\u2019s frustrating.\n\nDo people write these papers in their free time or as part of their work? (And I\u2019m not talking about blogs here either.) Do they request speaking opportunities at conferences? I would strive towards it but I don\u2019t know the path.\n\nI kind of feel like there exists this entire world of professional DS that I can\u2019t actually reach. \n\nIf you have written or coauthored articles for these journals or been a presenter at a conference, can you offer any advice here?", "author_fullname": "t2_4dmjsv6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Professional Article Submissions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11h2zf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677855944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll admit that I occasionally let myself drift through LinkedIn and look at the profiles of others in the field and while I recognize that a great deal of LinkedIn is embellished, something I do notice on profiles a good deal is the submissions of papers to journals or to conferences in the field. &lt;/p&gt;\n\n&lt;p&gt;Now, I view these things as high achievement. I\u2019ve even seen a good portion of job descriptions that have these things as requirements. I have to admit, I don\u2019t even have a clue where to start and that\u2019s frustrating.&lt;/p&gt;\n\n&lt;p&gt;Do people write these papers in their free time or as part of their work? (And I\u2019m not talking about blogs here either.) Do they request speaking opportunities at conferences? I would strive towards it but I don\u2019t know the path.&lt;/p&gt;\n\n&lt;p&gt;I kind of feel like there exists this entire world of professional DS that I can\u2019t actually reach. &lt;/p&gt;\n\n&lt;p&gt;If you have written or coauthored articles for these journals or been a presenter at a conference, can you offer any advice here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h2zf2", "is_robot_indexable": true, "report_reasons": null, "author": "sonictoddler", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h2zf2/professional_article_submissions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h2zf2/professional_article_submissions/", "subreddit_subscribers": 853568, "created_utc": 1677855944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3it27rt0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does research publications help while applying for Data Scientist job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11h2t1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677855495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h2t1a", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Opinion_5729", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h2t1a/does_research_publications_help_while_applying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h2t1a/does_research_publications_help_while_applying/", "subreddit_subscribers": 853568, "created_utc": 1677855495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone here in data science field with adhd? How do you find the field you are working? Could you share your experiences?\n\nI am thinking of doing software engineering or data science for my bsc but cannot decide which field would be better for my adhd brain.\n\nThanks", "author_fullname": "t2_lhuh6mwn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science with adhd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gv4ly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677830668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here in data science field with adhd? How do you find the field you are working? Could you share your experiences?&lt;/p&gt;\n\n&lt;p&gt;I am thinking of doing software engineering or data science for my bsc but cannot decide which field would be better for my adhd brain.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gv4ly", "is_robot_indexable": true, "report_reasons": null, "author": "No_Language99", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gv4ly/data_science_with_adhd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gv4ly/data_science_with_adhd/", "subreddit_subscribers": 853568, "created_utc": 1677830668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.\n\nEDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.", "author_fullname": "t2_bvyiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pros/Cons of Moving over to Exclusively Linux?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gbv79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677786167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For most of my work I would use Windows as my base OS and Linux either dual-boot or via a VM or WSL. However, as of late, when reorganizing my stack and workflow I realized I could pretty much get everything done on Linux and would want to migrate there fully. I wanted to ask other practitioners here about their work set up, any issues and limitations they experienced, and their own recommendations as reorganizing can be periodically useful to avoid unnecessary clutter.&lt;/p&gt;\n\n&lt;p&gt;EDIT: most of my model training and computation heavy work is done in the cloud, my set up is purely for development and prototyping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gbv79", "is_robot_indexable": true, "report_reasons": null, "author": "robml", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gbv79/proscons_of_moving_over_to_exclusively_linux/", "subreddit_subscribers": 853568, "created_utc": 1677786167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For the data scientists in the UK how is the job market right now given the recent layoffs. And how about the freshers out of MSc, is it tough to break in as a fresher and what can be the salary expectation?", "author_fullname": "t2_scmjnhvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science jobs in the UK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h0vqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677850368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data scientists in the UK how is the job market right now given the recent layoffs. And how about the freshers out of MSc, is it tough to break in as a fresher and what can be the salary expectation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h0vqn", "is_robot_indexable": true, "report_reasons": null, "author": "0ke1vin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h0vqn/data_science_jobs_in_the_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h0vqn/data_science_jobs_in_the_uk/", "subreddit_subscribers": 853568, "created_utc": 1677850368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As we need to scale the training data before fitting it to the model, how would using validation\\_split prevent us from giving information leakage? \n\nSo far from what I have learned, we can only fit the scaler on the training set, and then apply the fitted scaler to the test set. In this case, I believe we are treating validation set as a \"test set\" during training to improve the model's performance, hence the confusion. Because if we scale the entire training set, we will end up not having unseen data for the validation set.\n\nThank you.\n\n&amp;#x200B;\n\nAdding notes:\n\nTo copy from Keras' official explanation:\n\n&gt;validation\\_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling. This argument is not supported when x is a dataset, generator or keras.utils.Sequence instance. If both validation\\_data and validation\\_split are provided, validation\\_data will override validation\\_split. validation\\_split is not yet supported with tf.distribute.experimental.ParameterServerStrategy.", "author_fullname": "t2_dnekp18a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Keras validation_split prevent information leakage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gx5mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677838561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we need to scale the training data before fitting it to the model, how would using validation_split prevent us from giving information leakage? &lt;/p&gt;\n\n&lt;p&gt;So far from what I have learned, we can only fit the scaler on the training set, and then apply the fitted scaler to the test set. In this case, I believe we are treating validation set as a &amp;quot;test set&amp;quot; during training to improve the model&amp;#39;s performance, hence the confusion. Because if we scale the entire training set, we will end up not having unseen data for the validation set.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Adding notes:&lt;/p&gt;\n\n&lt;p&gt;To copy from Keras&amp;#39; official explanation:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling. This argument is not supported when x is a dataset, generator or keras.utils.Sequence instance. If both validation_data and validation_split are provided, validation_data will override validation_split. validation_split is not yet supported with tf.distribute.experimental.ParameterServerStrategy.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gx5mz", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Deer8805", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gx5mz/how_does_keras_validation_split_prevent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gx5mz/how_does_keras_validation_split_prevent/", "subreddit_subscribers": 853568, "created_utc": 1677838561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says, if you want to model space elasticity of demand ( i.e. how the demand of a product is affected by the space allocated to it), how do you approach it from a modeling perspective? \n\nA couple of papers I came across:\n\nhttps://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf\n\nhttps://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf\n\nThanks", "author_fullname": "t2_vqwkfiup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail DS: To model space elasticity of demand, are GBMs widely used? If not, what do you prefer to use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gtvoe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677831942.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677826151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, if you want to model space elasticity of demand ( i.e. how the demand of a product is affected by the space allocated to it), how do you approach it from a modeling perspective? &lt;/p&gt;\n\n&lt;p&gt;A couple of papers I came across:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf\"&gt;https://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf\"&gt;https://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gtvoe", "is_robot_indexable": true, "report_reasons": null, "author": "Living_Teaching9410", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gtvoe/retail_ds_to_model_space_elasticity_of_demand_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gtvoe/retail_ds_to_model_space_elasticity_of_demand_are/", "subreddit_subscribers": 853568, "created_utc": 1677826151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/\n\ncould anyone shed some light on what I should expect from this role?\n\nThanks", "author_fullname": "t2_9wyrffxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect from an wget level data engineering role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gnec8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677807189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m about to start my first job after doing a masters in data science, I will be an analytics engineer (more precisely) and I\u2019m nervous for that impostor feeling :/&lt;/p&gt;\n\n&lt;p&gt;could anyone shed some light on what I should expect from this role?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gnec8", "is_robot_indexable": true, "report_reasons": null, "author": "Appropriate-Item-162", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gnec8/what_to_expect_from_an_wget_level_data/", "subreddit_subscribers": 853568, "created_utc": 1677807189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?", "author_fullname": "t2_cps0d40y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Degrees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gkmie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677800304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best graduate degrees to go for if you were to switching from an analyst/scientist career path to a data engineer path. Are there any specific \u201cData Engineering\u201d tailored programs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gkmie", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Matress27", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gkmie/data_engineering_degrees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gkmie/data_engineering_degrees/", "subreddit_subscribers": 853568, "created_utc": 1677800304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Trying to classify proteins based on certain properties, some of which are matrices. \n\nSome features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.\n\nWhatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.\n\nHow do I solve for this?", "author_fullname": "t2_15k55n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with vectors as features in a dataset for classification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11g7srv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677776438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to classify proteins based on certain properties, some of which are matrices. &lt;/p&gt;\n\n&lt;p&gt;Some features of the dataset I have contain integers, floats, and text. However, there are vectors and matrices too.&lt;/p&gt;\n\n&lt;p&gt;Whatever algorithm I use to classify these proteins returns an error because it can\u2019t handle the matrices/vectors as a single value.&lt;/p&gt;\n\n&lt;p&gt;How do I solve for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11g7srv", "is_robot_indexable": true, "report_reasons": null, "author": "colouredzindagi", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11g7srv/how_to_deal_with_vectors_as_features_in_a_dataset/", "subreddit_subscribers": 853568, "created_utc": 1677776438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, we are four data science students looking to start our Kaggle adventure. We have little experience with Kaggle itself (apart from the basic tutorials etc. and use of datasets for uni).\n\nWhat is a good completed competition which we can give a go at seriously for the first time? (The idea is to get the feel of how we can tackle a real competition, and then compare our first try with real team's solutions)\n\nAll topics welcome.\n\nMany thanks!", "author_fullname": "t2_mxisf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kaggle Competition Suggestion for a beginner team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11h46pf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677859085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, we are four data science students looking to start our Kaggle adventure. We have little experience with Kaggle itself (apart from the basic tutorials etc. and use of datasets for uni).&lt;/p&gt;\n\n&lt;p&gt;What is a good completed competition which we can give a go at seriously for the first time? (The idea is to get the feel of how we can tackle a real competition, and then compare our first try with real team&amp;#39;s solutions)&lt;/p&gt;\n\n&lt;p&gt;All topics welcome.&lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h46pf", "is_robot_indexable": true, "report_reasons": null, "author": "Im_jayco", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h46pf/kaggle_competition_suggestion_for_a_beginner_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h46pf/kaggle_competition_suggestion_for_a_beginner_team/", "subreddit_subscribers": 853568, "created_utc": 1677859085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I'm starting my very first project to sharpen my skills but have a few questions... Should I typically do all my data manipulation in some SQL tool before moving it into python / r to build my models, or is there a better way (eg in some notebook like tool)? Also should I do the preliminary descriptive analyses etc in SQL first? My SQL is really strong but I don't want to rely too heavily on that if its not going to be the best way in the long run.", "author_fullname": "t2_tqq2eqk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data manipulation/analysis in SQL first?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h111u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677850794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m starting my very first project to sharpen my skills but have a few questions... Should I typically do all my data manipulation in some SQL tool before moving it into python / r to build my models, or is there a better way (eg in some notebook like tool)? Also should I do the preliminary descriptive analyses etc in SQL first? My SQL is really strong but I don&amp;#39;t want to rely too heavily on that if its not going to be the best way in the long run.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11h111u", "is_robot_indexable": true, "report_reasons": null, "author": "Sadly_prolapsed_anus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11h111u/data_manipulationanalysis_in_sql_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11h111u/data_manipulationanalysis_in_sql_first/", "subreddit_subscribers": 853568, "created_utc": 1677850794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI've seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. \n\nI am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). \n\nI've heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.\n\nI'm sure there's a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people's experiences and if this is something possible within data science.\n\nThank you in advance!", "author_fullname": "t2_62z9s6lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote and travel jobs or consultant roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gqhz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677815670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen on this subreddit and in job postings that hybrid and remote jobs are fairly common in this field. &lt;/p&gt;\n\n&lt;p&gt;I am curious if anyone works for a company or is currently in a role that allows them to travel while they work (mainly thinking of EU and Aus based roles). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of Expensify as a company that is quite flexible and happy for individuals to be based wherever but their employee base seems to be more software engineers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s a few extenuating circumstances (e.g., a countries specific rules on being out of country while working), but would love to hear people&amp;#39;s experiences and if this is something possible within data science.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gqhz7", "is_robot_indexable": true, "report_reasons": null, "author": "TibialCuriosity", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gqhz7/remote_and_travel_jobs_or_consultant_roles/", "subreddit_subscribers": 853568, "created_utc": 1677815670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_iikq8tv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to import data from Microsoft azure to SQL server in batches by running a service every week such that it gets appended to the already existing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gmimx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677804872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gmimx", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Lawyer-3877", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gmimx/how_to_import_data_from_microsoft_azure_to_sql/", "subreddit_subscribers": 853568, "created_utc": 1677804872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it's a proxy variable at the most and doesn't hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.\n\nNow I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I'd like to find.\n\nThanks!", "author_fullname": "t2_bvba4ue8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identify underlying features for the Proxy variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gjlor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677808449.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677798772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I trained a classification model using XGboost.. Before the classification, I also performed EDA to understand which Variables could be important and include them. I noticed a variable which is showing significant correlation with the Target variable but I know from my domain knowledge that it&amp;#39;s a proxy variable at the most and doesn&amp;#39;t hold any predictive value on its own.\nTo confirm the importance of the features used in Boosting, I also plotted the inbuilt Feature importance and this proxy variable still came on top.&lt;/p&gt;\n\n&lt;p&gt;Now I wanna understand how can I go about identifying the actual features this proxy represents and to include them in the dataset.\nContext : the proxy variable is just an ID of Ad campaigns but shows heavy correlation and predictive importance to Clicks on display advertising. We know campaign ID is just a placeholder for actual campaign features but which one is what I&amp;#39;d like to find.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gjlor", "is_robot_indexable": true, "report_reasons": null, "author": "invincible_moron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gjlor/identify_underlying_features_for_the_proxy/", "subreddit_subscribers": 853568, "created_utc": 1677798772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to learn data collection using webscraping and APIs, and I also want to really learn how to process data. Can you guys hook me up with some free resources?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do i learn data collection and processing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gj0v1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677798138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn data collection using webscraping and APIs, and I also want to really learn how to process data. Can you guys hook me up with some free resources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gj0v1", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gj0v1/how_do_i_learn_data_collection_and_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gj0v1/how_do_i_learn_data_collection_and_processing/", "subreddit_subscribers": 853568, "created_utc": 1677798138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\n[https://aseandse.org/thecompetition/](https://aseandse.org/thecompetition/)\n\nI looking for a partner(Malaysian studying in any institution in ASEAN countries ) to take participate with me in the ASEAN data exploration competition. The comp requires me to participate with a fellow Malaysian. I am studying in Singapore so a bit hard to find people, so i am posting this here. The comp would be using SAP analytics. U don't necessary need to have the technical skills, if u have the domain knowledge of any of the SDGs mentioned on the website would be pretty good. If anyone is interested in participating with me, just give a dm.", "author_fullname": "t2_5jzu8cvi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a Partner for competition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11gxsne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677840990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://aseandse.org/thecompetition/\"&gt;https://aseandse.org/thecompetition/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I looking for a partner(Malaysian studying in any institution in ASEAN countries ) to take participate with me in the ASEAN data exploration competition. The comp requires me to participate with a fellow Malaysian. I am studying in Singapore so a bit hard to find people, so i am posting this here. The comp would be using SAP analytics. U don&amp;#39;t necessary need to have the technical skills, if u have the domain knowledge of any of the SDGs mentioned on the website would be pretty good. If anyone is interested in participating with me, just give a dm.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11gxsne", "is_robot_indexable": true, "report_reasons": null, "author": "Someerandomguy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11gxsne/need_a_partner_for_competition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11gxsne/need_a_partner_for_competition/", "subreddit_subscribers": 853568, "created_utc": 1677840990.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}