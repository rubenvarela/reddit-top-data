{"kind": "Listing", "data": {"after": "t3_11xwf09", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_ayza6h03", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "DPReview.com to close on April 10 after 25 years of operation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11xlnk3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1040, "total_awards_received": 2, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1040, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/YUHkG0lUQaFQ1mpt_mwTicsNeYMO8ESFTs-iVcTsE6U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679415346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dpreview.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dpreview.com/news/5901145460/dpreview-com-to-close", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?auto=webp&amp;v=enabled&amp;s=62800be361d0e710877115d585fc54f6bc091987", "width": 745, "height": 745}, "resolutions": [{"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c85ecc4153f61d9a247d4758d9430569622282d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a74b7694c73ea2345e65d9ea046b7453dce349cd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dbcef5e3e8892307008a8899734f8a2c64159c5", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b46d7621039f2b84e5eb82a6de9d0d1874068788", "width": 640, "height": 640}], "variants": {}, "id": "KDAVLRZTXaBom3MDvF95i0FH6bCPweDv6BPK8qmCi6E"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=25880d00e4283ff6a3851b64c83fea465c3fac48", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=67fae0c2af26488b9d70cb7afe877086707cf1d1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=3033c6583809a27b998883b7c56c158102cb0420", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=cccb48d7518eaba72894a7ac4214bb70c7120793", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=4101e0eff424bbd818195853387db358bec74ed0", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xlnk3", "is_robot_indexable": true, "report_reasons": null, "author": "ufs2", "discussion_type": null, "num_comments": 246, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xlnk3/dpreviewcom_to_close_on_april_10_after_25_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dpreview.com/news/5901145460/dpreview-com-to-close", "subreddit_subscribers": 674653, "created_utc": 1679415346.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_atk8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive Down, will be up and running soon (i hope).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11xzejt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 178, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;We are working to bring &lt;a href=\"https://t.co/rvOhn0byKe\"&gt;https://t.co/rvOhn0byKe&lt;/a&gt; back online.&lt;/p&gt;&amp;mdash; Internet Archive (@internetarchive) &lt;a href=\"https://twitter.com/internetarchive/status/1638320898854854656?ref_src=twsrc%5Etfw\"&gt;March 21, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/internetarchive/status/1638320898854854656", "author_name": "Internet Archive", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;We are working to bring &lt;a href=\"https://t.co/rvOhn0byKe\"&gt;https://t.co/rvOhn0byKe&lt;/a&gt; back online.&lt;/p&gt;&amp;mdash; Internet Archive (@internetarchive) &lt;a href=\"https://twitter.com/internetarchive/status/1638320898854854656?ref_src=twsrc%5Etfw\"&gt;March 21, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/internetarchive", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;We are working to bring &lt;a href=\"https://t.co/rvOhn0byKe\"&gt;https://t.co/rvOhn0byKe&lt;/a&gt; back online.&lt;/p&gt;&amp;mdash; Internet Archive (@internetarchive) &lt;a href=\"https://twitter.com/internetarchive/status/1638320898854854656?ref_src=twsrc%5Etfw\"&gt;March 21, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11xzejt", "height": 200}, "link_flair_text": "News", "can_mod_post": false, "score": 178, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/tqgdsDfDQZT83Qzw4jicbx0RArdnZceWVFtJm8svtq4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679442384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/internetarchive/status/1638320898854854656", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/umd_-mqB_KluVeFVS9oV3RJT58Ne8lrRBve2xbUVQf8.jpg?auto=webp&amp;v=enabled&amp;s=023c94964c7e4d9dd02915525f6582fceefe8af0", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/umd_-mqB_KluVeFVS9oV3RJT58Ne8lrRBve2xbUVQf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75bda627627dda1c4c596f56c929ff4672b22279", "width": 108, "height": 108}], "variants": {}, "id": "BGBZWjavT5mjy_urIqzYK992VMCUpGfrLOb1fOeNURk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xzejt", "is_robot_indexable": true, "report_reasons": null, "author": "Litecoin_Messiah", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xzejt/internet_archive_down_will_be_up_and_running_soon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/internetarchive/status/1638320898854854656", "subreddit_subscribers": 674653, "created_utc": 1679442384.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/internetarchive/status/1638320898854854656", "author_name": "Internet Archive", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;We are working to bring &lt;a href=\"https://t.co/rvOhn0byKe\"&gt;https://t.co/rvOhn0byKe&lt;/a&gt; back online.&lt;/p&gt;&amp;mdash; Internet Archive (@internetarchive) &lt;a href=\"https://twitter.com/internetarchive/status/1638320898854854656?ref_src=twsrc%5Etfw\"&gt;March 21, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/internetarchive", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "From what I see online, instagram/FB are notoriously hard to download from. Most tools are iffy at best and you'll probably get rate locked. But look up sites like Picuki, Bigsta, etc. and they can fully access/download public IG accounts and fulfill (what i assume is) thousands of requests.\n\nAre they just smarter with evading anti bot measures or do they have some sort of API access?", "author_fullname": "t2_vc2i89uo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are people able to mass download from Instagram without hitting limits?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xyc78", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679440193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I see online, instagram/FB are notoriously hard to download from. Most tools are iffy at best and you&amp;#39;ll probably get rate locked. But look up sites like Picuki, Bigsta, etc. and they can fully access/download public IG accounts and fulfill (what i assume is) thousands of requests.&lt;/p&gt;\n\n&lt;p&gt;Are they just smarter with evading anti bot measures or do they have some sort of API access?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xyc78", "is_robot_indexable": true, "report_reasons": null, "author": "protonicscientist", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xyc78/how_are_people_able_to_mass_download_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xyc78/how_are_people_able_to_mass_download_from/", "subreddit_subscribers": 674653, "created_utc": 1679440193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few weeks back I wrote that I had bought an autoloader FC LTO5 Ultrium tape drive in error (intending to get a SAS one for use with regular consumer versions of Windows; it was a two-windows-open-bought-the-wrong-one user error) and wondered if I would be able to get it to work. I didn't get any replies but I did get upvotes, so I'm guessing no one really knew, but people might be interested to know how it turned out.\n\nThe short version is, yes, I got it working, YAY!\n\nThe longer version of what went right and wrong could be useful for others who are working through any version of this in the future. (Potentially including me, long after I've forgotten it all!) The longer version goes like this.\n\n**First challenge: Getting an interface.** My understanding of these drives is they all shipped as standard with a SAS connector, but HP also sold a fibre channel (FC) upgrade kit - the only evidence of which I can find is a couple of old supplier listings. Now, if my drive is anything to go by, the kit seems to be designed for professional installer use (maybe even HP's own people) and is destructive to the SAS connector. (Part of the connector is visible, but you can't attach to it). I don't believe it's possible to \"un-kit\" it and go back to SAS. So I had to get a FC card. \n\nHP does publish compatibility information for the tape drives, but they don't cover FC cards (this is probably an inclusion with the FC upgrade kit doco which is nowhere to be found online). So I was shooting in the dark. But I figured a HP branded one had the best odds of being compatible. So I picked up a \"HP / QLOGIC QLE2560-HP 8GB SINGLE PORT F/CARD w/ SFP P/N: 489190-001, 584776-001\" off eBay, and got lucky first try - it was compatible with both the drive and my system.\n\n**Side note about my system:** I bought a system specifically to run this drive and other home file sharing and backup tasks, and I got a refurbished HP Z420, a high-end-in-2012 business workstation listed as compatible with the HP tape drives. It came with an upgraded i7 CPU, budget-gaming NVIDIA graphics card, and SSD/HDD, intended as a budget gaming machine. It was AUD$350 or so. I suspect this choice allowed me to bypass a lot of issues around compatibility with the drive and the FC card, although it did create other challenges, see below.\n\n**Second challenge: Installing in the case.** First I had to remove the rack sleeve surrounding the tape drive. This was screwed on, but also had cable connectors, at least one of which was really tough, so I wound up having to slide it out as far as the cables would let it, and then bend the back panel open to get it free of the cables from behind. There's also an ethernet connection on my rack sleeve that I think is used in server settings to communicate directly with the drive to troubleshoot.\n\nNext, I had to install the drive in the Z420 case. You can only use the top two 5.25\" bay slots, because any lower has the back hitting the memory. The Z420 has a system of tracks and large screws that slot in to the tracks. They actually give you spare screws, screwed into the side of the rack, but unless you know what they are, they look like part of the rack and it seems like there is no way to secure anything. (The Z420 has one side of the case riveted in place so you can only use their system to secure things each side - or, of course, get a new case). It was one of those things that was easy once you knew the trick, but took a ridiculous amount of angst to solve.\n\n**Third challenge: Cable connection between tape drive and FC card.** Let me save you some angst here and explain that the cable needed is an LC-LC multimode/duplex fibre patch cable. LC is the connector type, multimode and duplex means the signals can travel in both directions, patch means (in this context) that both ends are male. Single mode tends to be a yellow cable and multimode is blue/aqua (but I wouldn't choose on colour alone). Because FC interfaces aren't aimed at consumers, it's not particularly simple to find any of this out. Also, the FC upgrade kit used to add fibre to HP drives installed two FC connectors, but only one of them worked - not sure if this is normal/firmware controlled/something or one was just broken. Regardless, when I was troubleshooting, changing ports got me further in. Also, the FC card only has a port on the outside, so I had to send the FC cable out by removing one of the PCI card cover plates and plug it in there. Fortunately my FC cable is a metre long so it was long enough to do this. Also, these cables have standards OM1, OM2, OM3, etc - completely irrelevant for this purpose. The standard relates to how far apart the devices can be, and they're all much longer than will happen in a single case, even a rackmount case. The cables come with little white protective covers on each end \"pin.\" If you plug it in with the covers still on, it will go in partway but not lock in. That's your clue that you need to take them off.\n\n**Fourth challenge: Getting my system to use the FC card.** This part was easy. The Device Manager saw the FC card immediately and showed it with a warning icon (you may need to use Show Hidden Devices to see it). I had to manually find and install drivers for it to accept it fully. Piece of cake. The main thing to know about FC cards is that underneath the hardware, they use ethernet protocols to communicate. So don't worry like I did when you see references to networking and ethernet - Windows has not misidentified the card.\n\n**Fifth challenge: Getting my system to see the drive.** Getting my system to see the drive was pretty easy. Once I'd installed drivers for the FC card, the tape drive showed up in Device Manager straight away with a question mark, which means you need to do more stuff to make it fully ready for use. The \"do more stuff\" means manually tracking down and installing drivers.\n\n**Sidenote on what happened next:** I had made a mistake a few steps back - I had a unidrectional rather than duplex FC cable in place. This created a horrendous half-working situation that kept me trying things for weeks. Various pieces of software could read data from the drive fine (eg, extracting information about the drive), but all software would crash when I tried to send info the other way (eg tape quality tests, which write data, or create a drive mapping). At this point the tape drive would turn into a hidden device in Device Manager, that is, Device Manager saw it as disconnected - not sure if the tape drive was reacting to the failed attempt and disconnecting, or Windows was doing it as some sort of fault detection/attempt at error correction.\n\nMy research in trying to solve this sent me ALL around the virtual world. I tried drivers and utilities and software from anyone who ever co-branded these drives (including Quantum, IBM, and Dell), I got a lead in archived forum discussions that Windows 10 support was initially buggy, so I installed dual-boot Windows 8.1 only to have the same problem, so then I installed Linux as well. (My machine is now triple boot). At some point a second FC cable I'd ordered arrived (I'd gotten impatient so I'd ordered one with faster shipping) and I noticed the difference in labelling and colour. I thought about it and realised that the communication was always from PC drive to the drive when it crashed, so I tried the new cable and the drive worked just fine in Windows 10. Then I did some more reading on FC cables and reverse-engineered an understanding of what was happening here. (I will have to decide at some point whether I have any need for the other two OS, but that's a decision for another day).\n\n**Sixth challenge: Getting the tape drive to be useful.** For my use case, what I really wanted was LTFS, which is something that started with LTO5 which lets you mount a tape as a \"drive\" and lets you interact with it like you would any other drive. The required component for this is LTFS. Now, HP's tape tools utilities includes LTFS, but it doesn't really say so, you only find this out by digging in to the underlying files. Because I was scrambling to figure out my problem with communicating the drive, I was looking for this separately. I could find other brands' LTFS, but it didn't solve my problem, so I thought there was a missing piece. There wasn't, but it took me a long time to figure that out. \n\nOne thing that is really useful, though, is an LTFS configuring utility. I've lost track of whose one I'm using at this point, but IBM and Quantum both have standalone utilities for this, and what it does it create a drive mapping. If your backups routines revolve around command line scripts as mine do, that's probably all you need to make your drive useful.\n\nEarly tape drive usage was very reliant on cataloguing. Your backup would include external cataloguing so you could find content again, there was no ability to show an index from the tape itself. The change made in LTO5 that made using it as a regular drive possible was a system to catalogue the file list on the tape. It's not necessarily fast, but it is there.\n\nAt this point we're getting beyond my use case, but just to fill in a bit further, if you do need a backup solution with cataloguing capabilities, most are paid, and priced for commercial use. But there is one free option, Bacula Community Edition. This thing is a bastard to figure out on your own, but there are a few videos on YouTube that make it much easier to understand what the hell it's doing and how to use it. That would be my suggested first stop if you're looking to add a solution on top for older pre-LTO5 systems (or later if your system is big enough to warrant cataloguing).\n\nSo that's what I know at the end of my little adventure. I hope it's useful for other people on adventures of their own. Happy hoarding!", "author_fullname": "t2_komty5a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update on TIFU and bought the wrong tape drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y45bk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679472843.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679452786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few weeks back I wrote that I had bought an autoloader FC LTO5 Ultrium tape drive in error (intending to get a SAS one for use with regular consumer versions of Windows; it was a two-windows-open-bought-the-wrong-one user error) and wondered if I would be able to get it to work. I didn&amp;#39;t get any replies but I did get upvotes, so I&amp;#39;m guessing no one really knew, but people might be interested to know how it turned out.&lt;/p&gt;\n\n&lt;p&gt;The short version is, yes, I got it working, YAY!&lt;/p&gt;\n\n&lt;p&gt;The longer version of what went right and wrong could be useful for others who are working through any version of this in the future. (Potentially including me, long after I&amp;#39;ve forgotten it all!) The longer version goes like this.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First challenge: Getting an interface.&lt;/strong&gt; My understanding of these drives is they all shipped as standard with a SAS connector, but HP also sold a fibre channel (FC) upgrade kit - the only evidence of which I can find is a couple of old supplier listings. Now, if my drive is anything to go by, the kit seems to be designed for professional installer use (maybe even HP&amp;#39;s own people) and is destructive to the SAS connector. (Part of the connector is visible, but you can&amp;#39;t attach to it). I don&amp;#39;t believe it&amp;#39;s possible to &amp;quot;un-kit&amp;quot; it and go back to SAS. So I had to get a FC card. &lt;/p&gt;\n\n&lt;p&gt;HP does publish compatibility information for the tape drives, but they don&amp;#39;t cover FC cards (this is probably an inclusion with the FC upgrade kit doco which is nowhere to be found online). So I was shooting in the dark. But I figured a HP branded one had the best odds of being compatible. So I picked up a &amp;quot;HP / QLOGIC QLE2560-HP 8GB SINGLE PORT F/CARD w/ SFP P/N: 489190-001, 584776-001&amp;quot; off eBay, and got lucky first try - it was compatible with both the drive and my system.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Side note about my system:&lt;/strong&gt; I bought a system specifically to run this drive and other home file sharing and backup tasks, and I got a refurbished HP Z420, a high-end-in-2012 business workstation listed as compatible with the HP tape drives. It came with an upgraded i7 CPU, budget-gaming NVIDIA graphics card, and SSD/HDD, intended as a budget gaming machine. It was AUD$350 or so. I suspect this choice allowed me to bypass a lot of issues around compatibility with the drive and the FC card, although it did create other challenges, see below.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second challenge: Installing in the case.&lt;/strong&gt; First I had to remove the rack sleeve surrounding the tape drive. This was screwed on, but also had cable connectors, at least one of which was really tough, so I wound up having to slide it out as far as the cables would let it, and then bend the back panel open to get it free of the cables from behind. There&amp;#39;s also an ethernet connection on my rack sleeve that I think is used in server settings to communicate directly with the drive to troubleshoot.&lt;/p&gt;\n\n&lt;p&gt;Next, I had to install the drive in the Z420 case. You can only use the top two 5.25&amp;quot; bay slots, because any lower has the back hitting the memory. The Z420 has a system of tracks and large screws that slot in to the tracks. They actually give you spare screws, screwed into the side of the rack, but unless you know what they are, they look like part of the rack and it seems like there is no way to secure anything. (The Z420 has one side of the case riveted in place so you can only use their system to secure things each side - or, of course, get a new case). It was one of those things that was easy once you knew the trick, but took a ridiculous amount of angst to solve.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Third challenge: Cable connection between tape drive and FC card.&lt;/strong&gt; Let me save you some angst here and explain that the cable needed is an LC-LC multimode/duplex fibre patch cable. LC is the connector type, multimode and duplex means the signals can travel in both directions, patch means (in this context) that both ends are male. Single mode tends to be a yellow cable and multimode is blue/aqua (but I wouldn&amp;#39;t choose on colour alone). Because FC interfaces aren&amp;#39;t aimed at consumers, it&amp;#39;s not particularly simple to find any of this out. Also, the FC upgrade kit used to add fibre to HP drives installed two FC connectors, but only one of them worked - not sure if this is normal/firmware controlled/something or one was just broken. Regardless, when I was troubleshooting, changing ports got me further in. Also, the FC card only has a port on the outside, so I had to send the FC cable out by removing one of the PCI card cover plates and plug it in there. Fortunately my FC cable is a metre long so it was long enough to do this. Also, these cables have standards OM1, OM2, OM3, etc - completely irrelevant for this purpose. The standard relates to how far apart the devices can be, and they&amp;#39;re all much longer than will happen in a single case, even a rackmount case. The cables come with little white protective covers on each end &amp;quot;pin.&amp;quot; If you plug it in with the covers still on, it will go in partway but not lock in. That&amp;#39;s your clue that you need to take them off.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Fourth challenge: Getting my system to use the FC card.&lt;/strong&gt; This part was easy. The Device Manager saw the FC card immediately and showed it with a warning icon (you may need to use Show Hidden Devices to see it). I had to manually find and install drivers for it to accept it fully. Piece of cake. The main thing to know about FC cards is that underneath the hardware, they use ethernet protocols to communicate. So don&amp;#39;t worry like I did when you see references to networking and ethernet - Windows has not misidentified the card.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Fifth challenge: Getting my system to see the drive.&lt;/strong&gt; Getting my system to see the drive was pretty easy. Once I&amp;#39;d installed drivers for the FC card, the tape drive showed up in Device Manager straight away with a question mark, which means you need to do more stuff to make it fully ready for use. The &amp;quot;do more stuff&amp;quot; means manually tracking down and installing drivers.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Sidenote on what happened next:&lt;/strong&gt; I had made a mistake a few steps back - I had a unidrectional rather than duplex FC cable in place. This created a horrendous half-working situation that kept me trying things for weeks. Various pieces of software could read data from the drive fine (eg, extracting information about the drive), but all software would crash when I tried to send info the other way (eg tape quality tests, which write data, or create a drive mapping). At this point the tape drive would turn into a hidden device in Device Manager, that is, Device Manager saw it as disconnected - not sure if the tape drive was reacting to the failed attempt and disconnecting, or Windows was doing it as some sort of fault detection/attempt at error correction.&lt;/p&gt;\n\n&lt;p&gt;My research in trying to solve this sent me ALL around the virtual world. I tried drivers and utilities and software from anyone who ever co-branded these drives (including Quantum, IBM, and Dell), I got a lead in archived forum discussions that Windows 10 support was initially buggy, so I installed dual-boot Windows 8.1 only to have the same problem, so then I installed Linux as well. (My machine is now triple boot). At some point a second FC cable I&amp;#39;d ordered arrived (I&amp;#39;d gotten impatient so I&amp;#39;d ordered one with faster shipping) and I noticed the difference in labelling and colour. I thought about it and realised that the communication was always from PC drive to the drive when it crashed, so I tried the new cable and the drive worked just fine in Windows 10. Then I did some more reading on FC cables and reverse-engineered an understanding of what was happening here. (I will have to decide at some point whether I have any need for the other two OS, but that&amp;#39;s a decision for another day).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Sixth challenge: Getting the tape drive to be useful.&lt;/strong&gt; For my use case, what I really wanted was LTFS, which is something that started with LTO5 which lets you mount a tape as a &amp;quot;drive&amp;quot; and lets you interact with it like you would any other drive. The required component for this is LTFS. Now, HP&amp;#39;s tape tools utilities includes LTFS, but it doesn&amp;#39;t really say so, you only find this out by digging in to the underlying files. Because I was scrambling to figure out my problem with communicating the drive, I was looking for this separately. I could find other brands&amp;#39; LTFS, but it didn&amp;#39;t solve my problem, so I thought there was a missing piece. There wasn&amp;#39;t, but it took me a long time to figure that out. &lt;/p&gt;\n\n&lt;p&gt;One thing that is really useful, though, is an LTFS configuring utility. I&amp;#39;ve lost track of whose one I&amp;#39;m using at this point, but IBM and Quantum both have standalone utilities for this, and what it does it create a drive mapping. If your backups routines revolve around command line scripts as mine do, that&amp;#39;s probably all you need to make your drive useful.&lt;/p&gt;\n\n&lt;p&gt;Early tape drive usage was very reliant on cataloguing. Your backup would include external cataloguing so you could find content again, there was no ability to show an index from the tape itself. The change made in LTO5 that made using it as a regular drive possible was a system to catalogue the file list on the tape. It&amp;#39;s not necessarily fast, but it is there.&lt;/p&gt;\n\n&lt;p&gt;At this point we&amp;#39;re getting beyond my use case, but just to fill in a bit further, if you do need a backup solution with cataloguing capabilities, most are paid, and priced for commercial use. But there is one free option, Bacula Community Edition. This thing is a bastard to figure out on your own, but there are a few videos on YouTube that make it much easier to understand what the hell it&amp;#39;s doing and how to use it. That would be my suggested first stop if you&amp;#39;re looking to add a solution on top for older pre-LTO5 systems (or later if your system is big enough to warrant cataloguing).&lt;/p&gt;\n\n&lt;p&gt;So that&amp;#39;s what I know at the end of my little adventure. I hope it&amp;#39;s useful for other people on adventures of their own. Happy hoarding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11y45bk", "is_robot_indexable": true, "report_reasons": null, "author": "nurseynurseygander", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11y45bk/update_on_tifu_and_bought_the_wrong_tape_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11y45bk/update_on_tifu_and_bought_the_wrong_tape_drive/", "subreddit_subscribers": 674653, "created_utc": 1679452786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, [DPReview is to close](https://www.dpreview.com/news/5901145460/dpreview-com-to-close) soon. It's one of the top photography knowledge bases for many people.\n\nIs someone up to mirror it?\n\nI seem to have a bandwidth and a couple terabytes of disk space to spare but I need community help regarding the mirroring script.", "author_fullname": "t2_82kd8i0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DPReview.com is going down effective April 10.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y9t40", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679467240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;a href=\"https://www.dpreview.com/news/5901145460/dpreview-com-to-close\"&gt;DPReview is to close&lt;/a&gt; soon. It&amp;#39;s one of the top photography knowledge bases for many people.&lt;/p&gt;\n\n&lt;p&gt;Is someone up to mirror it?&lt;/p&gt;\n\n&lt;p&gt;I seem to have a bandwidth and a couple terabytes of disk space to spare but I need community help regarding the mirroring script.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?auto=webp&amp;v=enabled&amp;s=62800be361d0e710877115d585fc54f6bc091987", "width": 745, "height": 745}, "resolutions": [{"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c85ecc4153f61d9a247d4758d9430569622282d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a74b7694c73ea2345e65d9ea046b7453dce349cd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dbcef5e3e8892307008a8899734f8a2c64159c5", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ZAqZhSYKYUMc8wiSF_ZZK9w4kocyx4S8ml9u-bjPOy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b46d7621039f2b84e5eb82a6de9d0d1874068788", "width": 640, "height": 640}], "variants": {}, "id": "KDAVLRZTXaBom3MDvF95i0FH6bCPweDv6BPK8qmCi6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11y9t40", "is_robot_indexable": true, "report_reasons": null, "author": "roentgen256", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11y9t40/dpreviewcom_is_going_down_effective_april_10/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11y9t40/dpreviewcom_is_going_down_effective_april_10/", "subreddit_subscribers": 674653, "created_utc": 1679467240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone and good evening or day wherever you may be on the globe.\n\nAs a musician constantly logging and archiving very long and uncompressed music every day, sometimes with a sprinkle of video leading to very huge files, I'm now in dire need of some long-term storage.\n\nI do not want to get an LTO drive (way above my means), build a server with HDDs or anything that will require constant power, or for that data be on remote severs, instead I'd like a physical format that can be stored en masse in boxes, that could be dug out 15 years from now and still be accessible, just like we would with analogue tape. However I don't mind not being able to access it in real time if that changes anything.\nSo far here's what I've been considering :\n\n- BD-Rs : cheap and effective, fits the bill but I'm unsure about longevity or how my current drive (SBW-06D2X-U) burns them and if I'm not wasting my time on those. It's a bit of a whimsical device and I didn't dare burning anything above 2x because of that. I've used Verbatim media, and despite getting no errors upon verification, the discs clearly look like there are at least 6 different sessions on them.\n\n- USB drives : not sure about the bit rot part but I definitely don't trust them for long term use\n\n- NVMe drives  : I haven't tried these out but I'm not sure about the long term part either.\n\nWhat would be your suggestions ?\n\nThanks folks.", "author_fullname": "t2_hd0aw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk set-and-forget storage needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xlyaj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679415936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone and good evening or day wherever you may be on the globe.&lt;/p&gt;\n\n&lt;p&gt;As a musician constantly logging and archiving very long and uncompressed music every day, sometimes with a sprinkle of video leading to very huge files, I&amp;#39;m now in dire need of some long-term storage.&lt;/p&gt;\n\n&lt;p&gt;I do not want to get an LTO drive (way above my means), build a server with HDDs or anything that will require constant power, or for that data be on remote severs, instead I&amp;#39;d like a physical format that can be stored en masse in boxes, that could be dug out 15 years from now and still be accessible, just like we would with analogue tape. However I don&amp;#39;t mind not being able to access it in real time if that changes anything.\nSo far here&amp;#39;s what I&amp;#39;ve been considering :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;BD-Rs : cheap and effective, fits the bill but I&amp;#39;m unsure about longevity or how my current drive (SBW-06D2X-U) burns them and if I&amp;#39;m not wasting my time on those. It&amp;#39;s a bit of a whimsical device and I didn&amp;#39;t dare burning anything above 2x because of that. I&amp;#39;ve used Verbatim media, and despite getting no errors upon verification, the discs clearly look like there are at least 6 different sessions on them.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;USB drives : not sure about the bit rot part but I definitely don&amp;#39;t trust them for long term use&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;NVMe drives  : I haven&amp;#39;t tried these out but I&amp;#39;m not sure about the long term part either.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What would be your suggestions ?&lt;/p&gt;\n\n&lt;p&gt;Thanks folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xlyaj", "is_robot_indexable": true, "report_reasons": null, "author": "MetaKnaves", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xlyaj/bulk_setandforget_storage_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xlyaj/bulk_setandforget_storage_needed/", "subreddit_subscribers": 674653, "created_utc": 1679415936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings! Apologizing in advance for a long post.\n\nI am a career photographer currently using the dumbest backup system, and I need advice on the most practical solution. Right now, I have two WD 14TB USB 2.0 HDDs that I am manually mirroring. I am a Mac user running a 2019 15\" MBP as my primary computer. I also have a 2013 27\" iMac that's been in the box for years doing nothing.\n\nFor a time, I was backing up the contents to Amazon Photos, but the app was insanely unreliable and crashed or disconnected daily. I then started using Crash Plan, but I'm aware of their policy change in 2021 that wipes backups after 90 days, and trying to dump 14tb to the internet from a USB 2.0 HDD on wifi is obviously not practical - I try to run these drives as little as possible to keep wear and tear to a minimum. Crash Plan is more for my local drive, and the 1TB external SSDs I use for extending storage and scratch disk space.\n\nIdeal short term solution - install some kind of software that will act as a RAID manager and automatically mirror these two drives (without having to wipe them since they are my archive). I could hook these drives up to the iMac and use that as my 'server'. I'd also love to automatically back up my laptop to this system, and have it all dump to a cloud server.\n\nIdeal Long term solution - proper home RAID setup with multiple redundant drives, wirelessly archiving everything on my laptop and every external that I own. This would all be backed up in a cloud server in case of fire, theft, acts of god etc.\n\nQuestions- does the software to set up a RAID system on mac for wired and wireless transfers exist?- what cloud backups exist that won't delete files older than 90 days?\n\nI can do all my own hardware research etc. but I haven't been able to find any software solutions through google searches. Thanks for your help", "author_fullname": "t2_7hf68rbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving My Neolithic Backup System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xhqzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679407252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings! Apologizing in advance for a long post.&lt;/p&gt;\n\n&lt;p&gt;I am a career photographer currently using the dumbest backup system, and I need advice on the most practical solution. Right now, I have two WD 14TB USB 2.0 HDDs that I am manually mirroring. I am a Mac user running a 2019 15&amp;quot; MBP as my primary computer. I also have a 2013 27&amp;quot; iMac that&amp;#39;s been in the box for years doing nothing.&lt;/p&gt;\n\n&lt;p&gt;For a time, I was backing up the contents to Amazon Photos, but the app was insanely unreliable and crashed or disconnected daily. I then started using Crash Plan, but I&amp;#39;m aware of their policy change in 2021 that wipes backups after 90 days, and trying to dump 14tb to the internet from a USB 2.0 HDD on wifi is obviously not practical - I try to run these drives as little as possible to keep wear and tear to a minimum. Crash Plan is more for my local drive, and the 1TB external SSDs I use for extending storage and scratch disk space.&lt;/p&gt;\n\n&lt;p&gt;Ideal short term solution - install some kind of software that will act as a RAID manager and automatically mirror these two drives (without having to wipe them since they are my archive). I could hook these drives up to the iMac and use that as my &amp;#39;server&amp;#39;. I&amp;#39;d also love to automatically back up my laptop to this system, and have it all dump to a cloud server.&lt;/p&gt;\n\n&lt;p&gt;Ideal Long term solution - proper home RAID setup with multiple redundant drives, wirelessly archiving everything on my laptop and every external that I own. This would all be backed up in a cloud server in case of fire, theft, acts of god etc.&lt;/p&gt;\n\n&lt;p&gt;Questions- does the software to set up a RAID system on mac for wired and wireless transfers exist?- what cloud backups exist that won&amp;#39;t delete files older than 90 days?&lt;/p&gt;\n\n&lt;p&gt;I can do all my own hardware research etc. but I haven&amp;#39;t been able to find any software solutions through google searches. Thanks for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xhqzr", "is_robot_indexable": true, "report_reasons": null, "author": "Mother_Show8790", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xhqzr/improving_my_neolithic_backup_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xhqzr/improving_my_neolithic_backup_system/", "subreddit_subscribers": 674653, "created_utc": 1679407252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I want to download a library's worth of the internet incase we lose access to the web. I know what I want to download but I'm not sure what the best way to store it for later retrieval. I started looking at external drives but it seems the market is ripe with fraud and I am trying to work with a budget, I would like to start with 2-4TB of data and something I could just plug into a PC and download info. I dont mind slow speeds with data transfer I am more concerned with longevity and stability. My plan to is have this as a post apocalyptic bible of information so if anyone has any suggestions I would really appreciate it. Also I am good with making a PC or server from scratch so if it's cheaper/better to just use a couple of hard drives and a cheap motherboard then please let me know. Lastly I did look over the wiki and got some info from there I am just wondering what other suggestions you may have for this.", "author_fullname": "t2_pf9t1t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to hoard downloaded website data, not sure what setup I need", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y0exg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679444532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I want to download a library&amp;#39;s worth of the internet incase we lose access to the web. I know what I want to download but I&amp;#39;m not sure what the best way to store it for later retrieval. I started looking at external drives but it seems the market is ripe with fraud and I am trying to work with a budget, I would like to start with 2-4TB of data and something I could just plug into a PC and download info. I dont mind slow speeds with data transfer I am more concerned with longevity and stability. My plan to is have this as a post apocalyptic bible of information so if anyone has any suggestions I would really appreciate it. Also I am good with making a PC or server from scratch so if it&amp;#39;s cheaper/better to just use a couple of hard drives and a cheap motherboard then please let me know. Lastly I did look over the wiki and got some info from there I am just wondering what other suggestions you may have for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11y0exg", "is_robot_indexable": true, "report_reasons": null, "author": "TransVictoriaGlory", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11y0exg/i_want_to_hoard_downloaded_website_data_not_sure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11y0exg/i_want_to_hoard_downloaded_website_data_not_sure/", "subreddit_subscribers": 674653, "created_utc": 1679444532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "for context: there's a forum that i want to archive because the moderators delete posts very often without providing an explanation, so i need to download the posts as they get posted (with attached files preferrably), anyone know of an archiving tool for that?", "author_fullname": "t2_38i5p5tn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best tool for downloading forum posts in real-time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xyq9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679441001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;for context: there&amp;#39;s a forum that i want to archive because the moderators delete posts very often without providing an explanation, so i need to download the posts as they get posted (with attached files preferrably), anyone know of an archiving tool for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xyq9k", "is_robot_indexable": true, "report_reasons": null, "author": "Nep_Soundfont", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xyq9k/best_tool_for_downloading_forum_posts_in_realtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xyq9k/best_tool_for_downloading_forum_posts_in_realtime/", "subreddit_subscribers": 674653, "created_utc": 1679441001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, can someone help me to understand is there any real difference in read/write speeds between SATA 6 Gb/s vs SAS 12 Gb/s interfaces 3.5 hard drives? Previously I thought mechanical SAS drives are twice faster than mechanical SATA hard drives.\n\nAs far as I understood after some research 6 Gb/s and 12 Gb/s are just interface bandwidth and all 3.5 hard drives with 7200 rpm  will roughly have the same read/write speed performance at around 200-250 MB/s no matter if it is SATA or SAS. I tried to search on Youtube and could not find any real world 3.5 mechanical hard drives read/write performance reviews.\n\nExample SATA and SAS 20TB drives:\n\n[https://documents.westerndigital.com/content/dam/doc-library/en\\_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc560.pdf](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc560.pdf)\n\n[https://www.seagate.com/content/dam/seagate/migrated-assets/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en\\_GB.pdf](https://www.seagate.com/content/dam/seagate/migrated-assets/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en_GB.pdf)\n\n&amp;#x200B;\n\nBackground: I have a server case with SAS 12gb/s backplane for 3.5 hard drives, and should decide which hard drives to buy.", "author_fullname": "t2_7chglbbu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3.5 7200 rpm hard drives: SATA 6 Gb/s vs SAS 12 Gb/s interface speed comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xwojp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679436829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, can someone help me to understand is there any real difference in read/write speeds between SATA 6 Gb/s vs SAS 12 Gb/s interfaces 3.5 hard drives? Previously I thought mechanical SAS drives are twice faster than mechanical SATA hard drives.&lt;/p&gt;\n\n&lt;p&gt;As far as I understood after some research 6 Gb/s and 12 Gb/s are just interface bandwidth and all 3.5 hard drives with 7200 rpm  will roughly have the same read/write speed performance at around 200-250 MB/s no matter if it is SATA or SAS. I tried to search on Youtube and could not find any real world 3.5 mechanical hard drives read/write performance reviews.&lt;/p&gt;\n\n&lt;p&gt;Example SATA and SAS 20TB drives:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc560.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc560.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.seagate.com/content/dam/seagate/migrated-assets/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en_GB.pdf\"&gt;https://www.seagate.com/content/dam/seagate/migrated-assets/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en_GB.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Background: I have a server case with SAS 12gb/s backplane for 3.5 hard drives, and should decide which hard drives to buy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11xwojp", "is_robot_indexable": true, "report_reasons": null, "author": "Computingss", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xwojp/35_7200_rpm_hard_drives_sata_6_gbs_vs_sas_12_gbs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xwojp/35_7200_rpm_hard_drives_sata_6_gbs_vs_sas_12_gbs/", "subreddit_subscribers": 674653, "created_utc": 1679436829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay. I'm relatively new to data hoarding.\n\nI recently setup a 'NAS' (a second hand enterprise Windows PC with an external drive bay attached) and filled it with drives. I remote into it using Chrome Remote Desktop from my personal PC or iPad as and when required. It's primary function is as a Plex server, game server, and data backup.\n\nWhat I'm trying to work out is if there is a bit of software that would enable me to automatically backup all my data from Google  Drive (that I use as my primary document and photo storage location), or any local storage, to the NAS, without having to use Google Takeout once every 2 months or manually copy/pasting. I tried mirroring using Drive's inbuilt functionality, but I don't want anything I accidentally do to the HDD version of the files to mirror onto Drive in the cloud, so that's not the right solution.\n\nI'm imagining something exists. I've taken a look at the FAQ but couldn't find quite what I was looking for, so would appreciate any first hand advice!", "author_fullname": "t2_5eotj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software for automating backup of Google Drive to NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xwbsv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679436143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay. I&amp;#39;m relatively new to data hoarding.&lt;/p&gt;\n\n&lt;p&gt;I recently setup a &amp;#39;NAS&amp;#39; (a second hand enterprise Windows PC with an external drive bay attached) and filled it with drives. I remote into it using Chrome Remote Desktop from my personal PC or iPad as and when required. It&amp;#39;s primary function is as a Plex server, game server, and data backup.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m trying to work out is if there is a bit of software that would enable me to automatically backup all my data from Google  Drive (that I use as my primary document and photo storage location), or any local storage, to the NAS, without having to use Google Takeout once every 2 months or manually copy/pasting. I tried mirroring using Drive&amp;#39;s inbuilt functionality, but I don&amp;#39;t want anything I accidentally do to the HDD version of the files to mirror onto Drive in the cloud, so that&amp;#39;s not the right solution.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m imagining something exists. I&amp;#39;ve taken a look at the FAQ but couldn&amp;#39;t find quite what I was looking for, so would appreciate any first hand advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xwbsv", "is_robot_indexable": true, "report_reasons": null, "author": "smellsmell1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xwbsv/software_for_automating_backup_of_google_drive_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xwbsv/software_for_automating_backup_of_google_drive_to/", "subreddit_subscribers": 674653, "created_utc": 1679436143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_a65nr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found these at my work. These are the Molex -&gt; SATA adapters that are actually okay to use, aren\u2019t they?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11xs61j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WJcMu0ln_6DJ4i__Vp6nkJXd8ZXiAZ5ZcYu9DV-BKJc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679428205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/x3vpqa7au6pa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?auto=webp&amp;v=enabled&amp;s=a013e50b16e84aa76508f6f0701b3460414503aa", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4873c198b6deead8a1e4a1b9ffaa6dfeaf1fe7a", "width": 108, "height": 144}, {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd0e472c90b75e9abc153c8bb62165c4522b6819", "width": 216, "height": 288}, {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccdca15e97da895d45e92aed607d3f791f2ed540", "width": 320, "height": 426}, {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dc1b3993691bfff482e40ac9e456ce21a5079aa", "width": 640, "height": 853}, {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30669e5411f6f81d33478b1c4c78dc5896bc4601", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/x3vpqa7au6pa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e01ca4927a0fc371547574486f355c68e765d857", "width": 1080, "height": 1440}], "variants": {}, "id": "uQjuZFEOH6vEBRPdme4DnXEI3CYXIUoF7oHE08gX67k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xs61j", "is_robot_indexable": true, "report_reasons": null, "author": "Gymnastboatman", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xs61j/found_these_at_my_work_these_are_the_molex_sata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/x3vpqa7au6pa1.jpg", "subreddit_subscribers": 674653, "created_utc": 1679428205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Some buying options in my country (ITA):\n\n* 4TB CMR 120\\~130\u20ac\n* 3TB CMR 75\\~90\u20ac\n* 4TB SMR 70\\~90\u20ac\n\nConsidering the cheapest ones like Seagate, WD and Toshiba.\n\nThank you for any advice", "author_fullname": "t2_feulr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth to sacrifice 1TB for getting a CRM disk for generic storage purposes (no RAID)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11yfd35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679489186.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679482788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some buying options in my country (ITA):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4TB CMR 120~130\u20ac&lt;/li&gt;\n&lt;li&gt;3TB CMR 75~90\u20ac&lt;/li&gt;\n&lt;li&gt;4TB SMR 70~90\u20ac&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Considering the cheapest ones like Seagate, WD and Toshiba.&lt;/p&gt;\n\n&lt;p&gt;Thank you for any advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11yfd35", "is_robot_indexable": true, "report_reasons": null, "author": "tonyromero", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11yfd35/is_it_worth_to_sacrifice_1tb_for_getting_a_crm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11yfd35/is_it_worth_to_sacrifice_1tb_for_getting_a_crm/", "subreddit_subscribers": 674653, "created_utc": 1679482788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_r687it3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple script for calculating total torrent size in a folder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_11xxg1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4En7OOeurAXi_7YoaBR35UgGFbwb7VyPIcKyzPG-WR4.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679438333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/wr3mo9tv66pa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?auto=webp&amp;v=enabled&amp;s=49cdcb6994a2f7cf3c78ded122ffad454c6a37f2", "width": 1376, "height": 629}, "resolutions": [{"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e148f97c669f406be35b881d112db7339b2c625", "width": 108, "height": 49}, {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e56c146c74e8f76dd69fe4dcd434021723121768", "width": 216, "height": 98}, {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89d1f120a07178d1631e9253674e4ced0e3a26d8", "width": 320, "height": 146}, {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad39b51dfd3dbdb4a3436215c8d2fc865898ad17", "width": 640, "height": 292}, {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a3cad254a42379a24a01e53900eeccf6f348b3b", "width": 960, "height": 438}, {"url": "https://preview.redd.it/wr3mo9tv66pa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93d917d2a3f7a6f78b981fccef5838a38b5bdca5", "width": 1080, "height": 493}], "variants": {}, "id": "GKzwH5GhHloaDa5CNP_WflO6pwg1lN6PJ36tHXFG8Lw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "45 TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xxg1d", "is_robot_indexable": true, "report_reasons": null, "author": "lemmeanon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11xxg1d/simple_script_for_calculating_total_torrent_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/wr3mo9tv66pa1.png", "subreddit_subscribers": 674653, "created_utc": 1679438333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey DataHoarders,\n\nI wouldn't say that I am a big data hoarder and actually this post is more along the lines of Anti-DataHoarding but I reckon that some people may want to free some backup space to keep the really special things they want.\n\nInstead of backing up files that are easily available such as latest films and pretty common stuff which let's face it due to the digital age will probably live longer than the earth you could just git-annex them.\n\nThe way it works is you set up a git-annex in your host. This will basically take the files and put them inside .git and replace them with symbolic links. Then you can git clone this annex somewhere either locally or in the network. This effectively means that you can keep track/version control your inventory of things without having to back them up and waste a lot of disk space. My assumption is that since these are easily available that you can survive with a single copy.\n\nIf you guys like it I will provide more specific details.", "author_fullname": "t2_14d1hc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "git-annex is awesome for reducing backup space for common online media files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xqu4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679428253.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679425619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DataHoarders,&lt;/p&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t say that I am a big data hoarder and actually this post is more along the lines of Anti-DataHoarding but I reckon that some people may want to free some backup space to keep the really special things they want.&lt;/p&gt;\n\n&lt;p&gt;Instead of backing up files that are easily available such as latest films and pretty common stuff which let&amp;#39;s face it due to the digital age will probably live longer than the earth you could just git-annex them.&lt;/p&gt;\n\n&lt;p&gt;The way it works is you set up a git-annex in your host. This will basically take the files and put them inside .git and replace them with symbolic links. Then you can git clone this annex somewhere either locally or in the network. This effectively means that you can keep track/version control your inventory of things without having to back them up and waste a lot of disk space. My assumption is that since these are easily available that you can survive with a single copy.&lt;/p&gt;\n\n&lt;p&gt;If you guys like it I will provide more specific details.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xqu4f", "is_robot_indexable": true, "report_reasons": null, "author": "Satrapes1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xqu4f/gitannex_is_awesome_for_reducing_backup_space_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xqu4f/gitannex_is_awesome_for_reducing_backup_space_for/", "subreddit_subscribers": 674653, "created_utc": 1679425619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI need some help planning out a storage expansion, and I'm hoping I can borrow some expertise here.  This is in a business environment.\n\nI'm currently running a Dell PowerEdge R7515 with 10x 2.4TB SAS drives in RAID 6.  It's almost out of space, and I'm looking at expansion options.\n\nUse case is a marketing company of about 20 staff.  Lots of large files, rapidly growing dataset, primarily graphics/photoshop data.  Important considerations are performance, expandability, and reliability.\n\nI'm looking at a Dell PowerVault MD1400 DAS full of 4TB SAS drives.  Would this be a sensible option?  How would you suggest configuring this for a good balance of performance/reliability?\n\nI'm tossing up between RAID6 and Windows Storage Spaces, possibly with some SSD cache drives (not sure what the right number would be).\n\nThoughts?", "author_fullname": "t2_ajpev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enterprise storage - RAID vs Storage Spaces?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xollw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679421180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I need some help planning out a storage expansion, and I&amp;#39;m hoping I can borrow some expertise here.  This is in a business environment.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently running a Dell PowerEdge R7515 with 10x 2.4TB SAS drives in RAID 6.  It&amp;#39;s almost out of space, and I&amp;#39;m looking at expansion options.&lt;/p&gt;\n\n&lt;p&gt;Use case is a marketing company of about 20 staff.  Lots of large files, rapidly growing dataset, primarily graphics/photoshop data.  Important considerations are performance, expandability, and reliability.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at a Dell PowerVault MD1400 DAS full of 4TB SAS drives.  Would this be a sensible option?  How would you suggest configuring this for a good balance of performance/reliability?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m tossing up between RAID6 and Windows Storage Spaces, possibly with some SSD cache drives (not sure what the right number would be).&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xollw", "is_robot_indexable": true, "report_reasons": null, "author": "Pirateguybrush", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xollw/enterprise_storage_raid_vs_storage_spaces/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xollw/enterprise_storage_raid_vs_storage_spaces/", "subreddit_subscribers": 674653, "created_utc": 1679421180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So couple of weeks/months ago one of my HDDs- WD Red 3TB - EFRX - 8,3 Years old (!) failed on me. I had backups and was still able to get vast majority of the data directly from the drive. So data-wise im ok. \n\nMy questions is other: What to do with the drive now...? I took several pictures from SMART and hdd tests etc. and im posting it here. HD Tune pro and other programs (MiniTool Partition Wizard) found damaged sectors on the drive. The copying from these sectors were even like 2 Kb per second speed wise :-D...\n\nSo what can i do with this drive now...? Can it be \"saved\" somehow? Can i \"fix\" the damage sectors somehow? Can i at least \"mark them\" so the HDD doesnt use them anymore... (and still use the drive)? Will the damaged sectors \"spread\"...?\n\nIt appears that like the 1st half of the drive, or even first 2 terabytes (out of three) are OK... Can i make new \"partitions\" on the drive and use the 1st partition somewhat safely , and do NOT use the 2nd one with the damages sectors...? \n\nLike its a 3 TB drive, I dont wanna just throw it in trash like that...\n\nCan i fix the drive somehow? Can i still use the drive somewhat reliably...? Or is the drive now good only for like a doorstop?\n\n&amp;#x200B;\n\n[https://prnt.sc/jultghOArCkk](https://prnt.sc/jultghOArCkk)\n\n[https://prnt.sc/aakBEpqLyRVY](https://prnt.sc/aakBEpqLyRVY)\n\n[https://prnt.sc/NHuRwUBvT3\\_n](https://prnt.sc/NHuRwUBvT3_n)\n\n[https://prnt.sc/dVceUguoPDbD](https://prnt.sc/dVceUguoPDbD)\n\n[https://prnt.sc/2xVf57TQXkTt](https://prnt.sc/2xVf57TQXkTt)\n\n[https://prnt.sc/5SXVMacnchHh](https://prnt.sc/5SXVMacnchHh)\n\n[https://prnt.sc/QnfDFcHUzHdJ](https://prnt.sc/QnfDFcHUzHdJ)\n\n[https://prnt.sc/YQ4zwLsv6kiP](https://prnt.sc/YQ4zwLsv6kiP)", "author_fullname": "t2_1sl55e5m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failed 8,3 Years old WD Red drive 3TB (EFRX) - what now...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xo9xs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679420517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So couple of weeks/months ago one of my HDDs- WD Red 3TB - EFRX - 8,3 Years old (!) failed on me. I had backups and was still able to get vast majority of the data directly from the drive. So data-wise im ok. &lt;/p&gt;\n\n&lt;p&gt;My questions is other: What to do with the drive now...? I took several pictures from SMART and hdd tests etc. and im posting it here. HD Tune pro and other programs (MiniTool Partition Wizard) found damaged sectors on the drive. The copying from these sectors were even like 2 Kb per second speed wise :-D...&lt;/p&gt;\n\n&lt;p&gt;So what can i do with this drive now...? Can it be &amp;quot;saved&amp;quot; somehow? Can i &amp;quot;fix&amp;quot; the damage sectors somehow? Can i at least &amp;quot;mark them&amp;quot; so the HDD doesnt use them anymore... (and still use the drive)? Will the damaged sectors &amp;quot;spread&amp;quot;...?&lt;/p&gt;\n\n&lt;p&gt;It appears that like the 1st half of the drive, or even first 2 terabytes (out of three) are OK... Can i make new &amp;quot;partitions&amp;quot; on the drive and use the 1st partition somewhat safely , and do NOT use the 2nd one with the damages sectors...? &lt;/p&gt;\n\n&lt;p&gt;Like its a 3 TB drive, I dont wanna just throw it in trash like that...&lt;/p&gt;\n\n&lt;p&gt;Can i fix the drive somehow? Can i still use the drive somewhat reliably...? Or is the drive now good only for like a doorstop?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/jultghOArCkk\"&gt;https://prnt.sc/jultghOArCkk&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/aakBEpqLyRVY\"&gt;https://prnt.sc/aakBEpqLyRVY&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/NHuRwUBvT3_n\"&gt;https://prnt.sc/NHuRwUBvT3_n&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/dVceUguoPDbD\"&gt;https://prnt.sc/dVceUguoPDbD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/2xVf57TQXkTt\"&gt;https://prnt.sc/2xVf57TQXkTt&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/5SXVMacnchHh\"&gt;https://prnt.sc/5SXVMacnchHh&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/QnfDFcHUzHdJ\"&gt;https://prnt.sc/QnfDFcHUzHdJ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://prnt.sc/YQ4zwLsv6kiP\"&gt;https://prnt.sc/YQ4zwLsv6kiP&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uUmSEf47TC2DHDge51lvg90NND79H3dbrKLJr1IcFP4.jpg?auto=webp&amp;v=enabled&amp;s=7382c9e7d06a53475f4e2bbf938b5d00acedc319", "width": 642, "height": 749}, "resolutions": [{"url": "https://external-preview.redd.it/uUmSEf47TC2DHDge51lvg90NND79H3dbrKLJr1IcFP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b202b80dc580f4188b18d41b563e0a540e5d498e", "width": 108, "height": 126}, {"url": "https://external-preview.redd.it/uUmSEf47TC2DHDge51lvg90NND79H3dbrKLJr1IcFP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64e466eec9b0b283107da6c9b9fb0f9b2d72e2fe", "width": 216, "height": 252}, {"url": "https://external-preview.redd.it/uUmSEf47TC2DHDge51lvg90NND79H3dbrKLJr1IcFP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=979489a1242510a4d6664ab46c3f45c49b495edc", "width": 320, "height": 373}, {"url": "https://external-preview.redd.it/uUmSEf47TC2DHDge51lvg90NND79H3dbrKLJr1IcFP4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7a16fb9ad730b9a81670f446d507908e72e34c1", "width": 640, "height": 746}], "variants": {}, "id": "qS4o-6aegMAeJTXL78d8DOC-KRf_s9TfwK74nq3jvtU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11xo9xs", "is_robot_indexable": true, "report_reasons": null, "author": "ThomasHasThomas", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xo9xs/failed_83_years_old_wd_red_drive_3tb_efrx_what_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xo9xs/failed_83_years_old_wd_red_drive_3tb_efrx_what_now/", "subreddit_subscribers": 674653, "created_utc": 1679420517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello folks. I have several portable SSDs that I use for a variety of projects, mainly video editing. I recently had an issue with one of them and nearly lost the data, and had to pay $600 to a data recovery center to rectify the issue.\n\nNot entirely sure why I didn\u2019t have a backup system setup before hand but it\u2019s long past time for me to set something up. I wanted to know what would be a good setup for backing up up to around 6-8TB of data? I am unsure if the answer is to use a server or a RAID system or whatnot. I also don\u2019t know if there\u2019s a program that can assist that will automatically match the backup at night or something.\n\nI apologize now if this is a stupid question. Thank you for your time.\n\nEdit: In case I\u2019m asked about what I need the storage for:\n\n2TB - Main SSD with music video projects and assets (about 600GB used)\n\n2TB - Smash SSD with gameplay footage and edited montages (about 1.2TB used)\n\n1TB - Music SSD with music projects and assets (about 200GB used)\n\n1TB - \u201cHomework\u201d SSD (about 350GB used)\n\n500GB - Work SSD with work projects and footage (about 300GB used)", "author_fullname": "t2_utzyfi0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about routinely backing up about 6TB of data from several portable SSDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xli09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679415382.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679415041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks. I have several portable SSDs that I use for a variety of projects, mainly video editing. I recently had an issue with one of them and nearly lost the data, and had to pay $600 to a data recovery center to rectify the issue.&lt;/p&gt;\n\n&lt;p&gt;Not entirely sure why I didn\u2019t have a backup system setup before hand but it\u2019s long past time for me to set something up. I wanted to know what would be a good setup for backing up up to around 6-8TB of data? I am unsure if the answer is to use a server or a RAID system or whatnot. I also don\u2019t know if there\u2019s a program that can assist that will automatically match the backup at night or something.&lt;/p&gt;\n\n&lt;p&gt;I apologize now if this is a stupid question. Thank you for your time.&lt;/p&gt;\n\n&lt;p&gt;Edit: In case I\u2019m asked about what I need the storage for:&lt;/p&gt;\n\n&lt;p&gt;2TB - Main SSD with music video projects and assets (about 600GB used)&lt;/p&gt;\n\n&lt;p&gt;2TB - Smash SSD with gameplay footage and edited montages (about 1.2TB used)&lt;/p&gt;\n\n&lt;p&gt;1TB - Music SSD with music projects and assets (about 200GB used)&lt;/p&gt;\n\n&lt;p&gt;1TB - \u201cHomework\u201d SSD (about 350GB used)&lt;/p&gt;\n\n&lt;p&gt;500GB - Work SSD with work projects and footage (about 300GB used)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xli09", "is_robot_indexable": true, "report_reasons": null, "author": "S-X-A", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xli09/how_would_i_go_about_routinely_backing_up_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xli09/how_would_i_go_about_routinely_backing_up_about/", "subreddit_subscribers": 674653, "created_utc": 1679415041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "tried looking online but got no idea except that it tells the error rate caused due to movement in laptops and that raw value doesnt matter, would also appreciated if someone can explain what is load cycle count\n\nhttps://preview.redd.it/pcp8h1i9t9pa1.png?width=861&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=09e0c99cc3f2b4c48bf5770802a3d66eac4d61e1", "author_fullname": "t2_8qf9xwkn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "G-sense error rate value 10 ok?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pcp8h1i9t9pa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/pcp8h1i9t9pa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1590195979332b3d516529188183541b082ec6ac"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/pcp8h1i9t9pa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faf22e44fee1e9576f62338ab09f2ed6dd3bb60e"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/pcp8h1i9t9pa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80a2b4cd95e0789cbeea642b2fc936275d7e9de1"}, {"y": 170, "x": 640, "u": "https://preview.redd.it/pcp8h1i9t9pa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78ac30f0c41ee171d32bc6d6689ee358ef1d9bc2"}], "s": {"y": 230, "x": 861, "u": "https://preview.redd.it/pcp8h1i9t9pa1.png?width=861&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=09e0c99cc3f2b4c48bf5770802a3d66eac4d61e1"}, "id": "pcp8h1i9t9pa1"}}, "name": "t3_11yf4e2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QNX-BqC5vqzliD8Ur1Oxoon-42J3GBoOid9gkzWMDQU.jpg", "edited": 1679482919.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679482156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tried looking online but got no idea except that it tells the error rate caused due to movement in laptops and that raw value doesnt matter, would also appreciated if someone can explain what is load cycle count&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pcp8h1i9t9pa1.png?width=861&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=09e0c99cc3f2b4c48bf5770802a3d66eac4d61e1\"&gt;https://preview.redd.it/pcp8h1i9t9pa1.png?width=861&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=09e0c99cc3f2b4c48bf5770802a3d66eac4d61e1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11yf4e2", "is_robot_indexable": true, "report_reasons": null, "author": "Additional-Builder72", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11yf4e2/gsense_error_rate_value_10_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11yf4e2/gsense_error_rate_value_10_ok/", "subreddit_subscribers": 674653, "created_utc": 1679482156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.amazon.com/gp/aw/d/B0B518QX3G/ref=sspa_mw_detail_0?ie=UTF8&amp;psc=1&amp;sp_csd=d2lkZ2V0TmFtZT1zcF9waG9uZV9kZXRhaWwp13NParams", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can this charger charge a Qnap Tr004 DAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11yex2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679481616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/aw/d/B0B518QX3G/ref=sspa_mw_detail_0?ie=UTF8&amp;amp;psc=1&amp;amp;sp_csd=d2lkZ2V0TmFtZT1zcF9waG9uZV9kZXRhaWwp13NParams\"&gt;https://www.amazon.com/gp/aw/d/B0B518QX3G/ref=sspa_mw_detail_0?ie=UTF8&amp;amp;psc=1&amp;amp;sp_csd=d2lkZ2V0TmFtZT1zcF9waG9uZV9kZXRhaWwp13NParams&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11yex2p", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11yex2p/can_this_charger_charge_a_qnap_tr004_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11yex2p/can_this_charger_charge_a_qnap_tr004_das/", "subreddit_subscribers": 674653, "created_utc": 1679481616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Latest version of [changedetection.io](https://changedetection.io) now has a filter/plugin to monitor a product page to know if it's out of stock or not, hope it helps someone out there!\n\nhttps://preview.redd.it/cs62k3nz59pa1.png?width=1131&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a3f7f77a1bd28dbb9c26900640b94526446e2ca0", "author_fullname": "t2_7o8xvpq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "changedetection.io self hosted app now has a 'Product Restock' alert so you can grab out of stock hard-drives and rPi's as soon as they restock", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cs62k3nz59pa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9c11c141a051deafaf0e9b4850611d70828d033"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab4988d77feb724a1255d77cba4dc8d0e06f2bc5"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a87a5725437e9dd4f616c35a606b043b464070f1"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e13d0fb0112627c8f6e4ca2ee34c70bbf70d721"}, {"y": 460, "x": 960, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c4ed5d7c1b152bd349418d756978eadd20a120b"}, {"y": 517, "x": 1080, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80c9eab7804b901d21566b2533176c4c2684a54e"}], "s": {"y": 542, "x": 1131, "u": "https://preview.redd.it/cs62k3nz59pa1.png?width=1131&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a3f7f77a1bd28dbb9c26900640b94526446e2ca0"}, "id": "cs62k3nz59pa1"}}, "name": "t3_11ycarl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I1gaZrRPScWI7ZHEjmgTrvxkNW5vwFloNiEABiyqiOo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1679474387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Latest version of &lt;a href=\"https://changedetection.io\"&gt;changedetection.io&lt;/a&gt; now has a filter/plugin to monitor a product page to know if it&amp;#39;s out of stock or not, hope it helps someone out there!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cs62k3nz59pa1.png?width=1131&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a3f7f77a1bd28dbb9c26900640b94526446e2ca0\"&gt;https://preview.redd.it/cs62k3nz59pa1.png?width=1131&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a3f7f77a1bd28dbb9c26900640b94526446e2ca0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?auto=webp&amp;v=enabled&amp;s=571d9016e570aa0c7fb06f0b6019f714e5f001bd", "width": 1131, "height": 542}, "resolutions": [{"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bc0095754b21aab34f2899184ead7b38dfdce60", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d9ec5a2a92e7c68511642247fba8f7ab53136b1", "width": 216, "height": 103}, {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8c2fa192600d6a57d85e43be5c873b78846a7e9", "width": 320, "height": 153}, {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5737f092a8fa82037c1404ae50e06e3fc89fb670", "width": 640, "height": 306}, {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a101bc93b15cdd113efe55192c29d6c3ea9e2d0", "width": 960, "height": 460}, {"url": "https://external-preview.redd.it/aCCqzneAVm74c7b-5PqApltxUj1pd4nJfr1DlCqHtRU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e134668a86b5f13bbce0bbd2d42125a058feb23f", "width": 1080, "height": 517}], "variants": {}, "id": "eQx5fX0oKNFXo8obrh2FrNQ7PtzTTntGu1QQTsJhmXY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ycarl", "is_robot_indexable": true, "report_reasons": null, "author": "dgtlmoon123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ycarl/changedetectionio_self_hosted_app_now_has_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ycarl/changedetectionio_self_hosted_app_now_has_a/", "subreddit_subscribers": 674653, "created_utc": 1679474387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have begun the long and laborious process of backing up my family's collection of old VHS tapes, starting with home movies and the like.\n\nCurrently, I have just a consumer VHS player and an adapter for the VHSC tapes and a tuner card on my computer that I'm using to capture everything. Right now, I have to manually start recording on the PC, start the tape, wait for the tape to finish, manually stop the recording. Let the program I'm using spit on a MPEG4, then manually split up the file into smaller files, because home movies, and then use handbrake to convert everything to mkv files.\n\nI get that the latter part I'm probably stuck doing manually. I don't expect to find any program that can parse through one big file with no Metadata and split it up into smaller ones.\n\nBut surely there's a better way for me to capture what's on the tapes. I just want to be able to load up a tape, hit go and come back later and it be done and not have to babysit it to catch the end of the tape.\n\nAnyone have any suggestions?", "author_fullname": "t2_mdsa5f1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I automate backing up VHS tapes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y61wn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679457273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have begun the long and laborious process of backing up my family&amp;#39;s collection of old VHS tapes, starting with home movies and the like.&lt;/p&gt;\n\n&lt;p&gt;Currently, I have just a consumer VHS player and an adapter for the VHSC tapes and a tuner card on my computer that I&amp;#39;m using to capture everything. Right now, I have to manually start recording on the PC, start the tape, wait for the tape to finish, manually stop the recording. Let the program I&amp;#39;m using spit on a MPEG4, then manually split up the file into smaller files, because home movies, and then use handbrake to convert everything to mkv files.&lt;/p&gt;\n\n&lt;p&gt;I get that the latter part I&amp;#39;m probably stuck doing manually. I don&amp;#39;t expect to find any program that can parse through one big file with no Metadata and split it up into smaller ones.&lt;/p&gt;\n\n&lt;p&gt;But surely there&amp;#39;s a better way for me to capture what&amp;#39;s on the tapes. I just want to be able to load up a tape, hit go and come back later and it be done and not have to babysit it to catch the end of the tape.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11y61wn", "is_robot_indexable": true, "report_reasons": null, "author": "oldmanAF", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11y61wn/can_i_automate_backing_up_vhs_tapes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11y61wn/can_i_automate_backing_up_vhs_tapes/", "subreddit_subscribers": 674653, "created_utc": 1679457273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, a friend has asked me to make some small modifications to a website for him. I'm familiar with HTML &amp; CSS, but turned to HTTrack and wget as an initial way to accelerate the process.\n\n&amp;#x200B;\n\nHowever, I've been able to download the pages, but the internal links are not working. And I am banging my head against the wall trying to figure this out. For reference, I'm working on this website: [http://www.controlreps.com/](http://www.controlreps.com/)\n\n&amp;#x200B;\n\n*For HTTrack:* I was using the multiple mirror option.  \n*For wget:* I used the following script.\n\n    wget --wait=2 --level=inf --limit-rate=20K --recursive --page-requisites --user-agent=Mozilla --no-parent --convert-links --adjust-extension --no-clobber -e robots=off https://example.com\n\n&amp;#x200B;\n\nAlso, it should be noted that I was able to successfully implement the wget procedure on a different site. So is there something blocking it on this site? Thank you!", "author_fullname": "t2_fh5wwy3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading A Small Website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y0suz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679445365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, a friend has asked me to make some small modifications to a website for him. I&amp;#39;m familiar with HTML &amp;amp; CSS, but turned to HTTrack and wget as an initial way to accelerate the process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve been able to download the pages, but the internal links are not working. And I am banging my head against the wall trying to figure this out. For reference, I&amp;#39;m working on this website: &lt;a href=\"http://www.controlreps.com/\"&gt;http://www.controlreps.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;For HTTrack:&lt;/em&gt; I was using the multiple mirror option.&lt;br/&gt;\n&lt;em&gt;For wget:&lt;/em&gt; I used the following script.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;wget --wait=2 --level=inf --limit-rate=20K --recursive --page-requisites --user-agent=Mozilla --no-parent --convert-links --adjust-extension --no-clobber -e robots=off https://example.com\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, it should be noted that I was able to successfully implement the wget procedure on a different site. So is there something blocking it on this site? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?auto=webp&amp;v=enabled&amp;s=325cab6e8ae8b7123ff77777a2df62ca69befc74", "width": 1600, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc7e6effe45b3cb1edc1736f4492300e06f04972", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b365a31c8b6a55bf36f3cb8808307a5b06254c7b", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40495364bc78c0a5113334a6bc446783de7c5b40", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51f3387f088cf63c6566ebf5696b0394f359fbd0", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4e62e8638150b01da7156701e454040b2c72a8a", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/EWHfiY7r7Shjq1O0X8OJcJdfHUdHtDtBuHG6Hfc6v1w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af010cb9f9d629048c63ed868410821005d362dd", "width": 1080, "height": 675}], "variants": {}, "id": "vPAUwd4TQtBSgy6coimyT9GgnVIFInUC7kCufqr-4EE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11y0suz", "is_robot_indexable": true, "report_reasons": null, "author": "StrivingOnwards01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11y0suz/downloading_a_small_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11y0suz/downloading_a_small_website/", "subreddit_subscribers": 674653, "created_utc": 1679445365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Problem: I currently have 4 NAS boxes.  Currently configured as follows:\n\nNAS 1 \u2013 backup of movies volume. Hardware: 8 bay Synology ds1812+ with a 5 bay dx511 expansion enclosure.  This NAS has 9 \u2013 4tb drives, 2-5tb drives, and 1 3tb drive in a SHR2 raid configuration.  All of these drives are way too old and need to be put out to pasture.  This volume is completely full.\n\nNAS 2 \u2013 backup of tv show volume. Hardware: Synology ds1815+ with a 5 bay dx513 expansion enclosure.  This NAS has 13 \u2013 8TB drives in a SHR2 raid configuration. This volume is completely full.\n\nNAS 3 \u2013 TV shows volume. Hardware: Synology DS2119+.  This NAS has 12 10TB drives in a SHR2 raid configuration. This volume has 76.9TB / 87.3TB used.\n\nNAS 4 \u2013 Movies Library volume. Hardware Synology DS2415+. This NAS has 6 \u2013 16TB drives in a SHR2 raid configuration and has 40.3TB of 41.9TB used.\n\nI want to purchase new drives to expand the TV volume to the maximum volume size of 108TB (F-you Synology), and best utilize the other drives by shuffling drives between NAS volumes to increase movies volume for some breathing room and provide sufficient space on the backup volumes.  I am almost certainly going to go down to SHR1 on the backups if not JBOD.  I am much more focused on expansion and preservation of TV media vs movies.\n\nWhat would you do?", "author_fullname": "t2_cs4ok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you do - Case study of a home media storage nightmare/conundrum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xxh00", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679438388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Problem: I currently have 4 NAS boxes.  Currently configured as follows:&lt;/p&gt;\n\n&lt;p&gt;NAS 1 \u2013 backup of movies volume. Hardware: 8 bay Synology ds1812+ with a 5 bay dx511 expansion enclosure.  This NAS has 9 \u2013 4tb drives, 2-5tb drives, and 1 3tb drive in a SHR2 raid configuration.  All of these drives are way too old and need to be put out to pasture.  This volume is completely full.&lt;/p&gt;\n\n&lt;p&gt;NAS 2 \u2013 backup of tv show volume. Hardware: Synology ds1815+ with a 5 bay dx513 expansion enclosure.  This NAS has 13 \u2013 8TB drives in a SHR2 raid configuration. This volume is completely full.&lt;/p&gt;\n\n&lt;p&gt;NAS 3 \u2013 TV shows volume. Hardware: Synology DS2119+.  This NAS has 12 10TB drives in a SHR2 raid configuration. This volume has 76.9TB / 87.3TB used.&lt;/p&gt;\n\n&lt;p&gt;NAS 4 \u2013 Movies Library volume. Hardware Synology DS2415+. This NAS has 6 \u2013 16TB drives in a SHR2 raid configuration and has 40.3TB of 41.9TB used.&lt;/p&gt;\n\n&lt;p&gt;I want to purchase new drives to expand the TV volume to the maximum volume size of 108TB (F-you Synology), and best utilize the other drives by shuffling drives between NAS volumes to increase movies volume for some breathing room and provide sufficient space on the backup volumes.  I am almost certainly going to go down to SHR1 on the backups if not JBOD.  I am much more focused on expansion and preservation of TV media vs movies.&lt;/p&gt;\n\n&lt;p&gt;What would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xxh00", "is_robot_indexable": true, "report_reasons": null, "author": "jasonmichaeljones", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xxh00/what_would_you_do_case_study_of_a_home_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xxh00/what_would_you_do_case_study_of_a_home_media/", "subreddit_subscribers": 674653, "created_utc": 1679438388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Last night I was downloading mkvs to my 14TB shucked Easystore (purchased 11/2021 for Plex usage and storage) when I noticed that the drive was showing 100% disk usage in Task Manager and the downloads were telling me they were going to take 4 hours. When I stop the downloads, 100% usage continues until I reboot, which then takes forever because of the drive. It's also extra noisy, but its always been noisy since I got it. I have been using the WD Dashboard to run SMART tests and getting some weird results:\n\n* \"SMART Diagnostic Short Test\" will either pass with 0 errors, or fail with Code 2 \"The self-test routine was interrupted by the host with a hardware or software reset. Retest after checking the connections. Replace the drive if the error repeats.\"\n* \"SMART Diagnostic Extended Test\" just hourglasses, or fails with Code 2. I have tried both tests in safe mode.\n\nI read that this may be related to a bad SATA cable, but the above persists after switching out. Clearly the drive is failing, yes? I was curious if the attached SMART Data from CrystalDisk  and the WD Dashboard might help anyone tell me whats going on. Event Viewer isnt giving me any info either. The drive is backed up 1:1 so no losses, but I'd like someone more experienced to give me their opinion. Thank you.\n\nEDIT-Little more info: Moving a file from the Easystore anywhere else is fine, but when writing to the drive it goes nuts.\n\nhttps://imgur.com/a/KSlr6gY", "author_fullname": "t2_xcj4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some help interpreting SMART Data/potential pending drive failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xwf09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679437153.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679436313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last night I was downloading mkvs to my 14TB shucked Easystore (purchased 11/2021 for Plex usage and storage) when I noticed that the drive was showing 100% disk usage in Task Manager and the downloads were telling me they were going to take 4 hours. When I stop the downloads, 100% usage continues until I reboot, which then takes forever because of the drive. It&amp;#39;s also extra noisy, but its always been noisy since I got it. I have been using the WD Dashboard to run SMART tests and getting some weird results:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;SMART Diagnostic Short Test&amp;quot; will either pass with 0 errors, or fail with Code 2 &amp;quot;The self-test routine was interrupted by the host with a hardware or software reset. Retest after checking the connections. Replace the drive if the error repeats.&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;SMART Diagnostic Extended Test&amp;quot; just hourglasses, or fails with Code 2. I have tried both tests in safe mode.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I read that this may be related to a bad SATA cable, but the above persists after switching out. Clearly the drive is failing, yes? I was curious if the attached SMART Data from CrystalDisk  and the WD Dashboard might help anyone tell me whats going on. Event Viewer isnt giving me any info either. The drive is backed up 1:1 so no losses, but I&amp;#39;d like someone more experienced to give me their opinion. Thank you.&lt;/p&gt;\n\n&lt;p&gt;EDIT-Little more info: Moving a file from the Easystore anywhere else is fine, but when writing to the drive it goes nuts.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/KSlr6gY\"&gt;https://imgur.com/a/KSlr6gY&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VM3NMaAka86XW7sNytrv1-d8VwHKQd4yNgfRN1TYDH4.jpg?auto=webp&amp;v=enabled&amp;s=0203a19c4d0dcfbc5aa2e16f1bb02352f465ea3c", "width": 677, "height": 696}, "resolutions": [{"url": "https://external-preview.redd.it/VM3NMaAka86XW7sNytrv1-d8VwHKQd4yNgfRN1TYDH4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c1aee4e9738043e3d77457040e6494112089ca2", "width": 108, "height": 111}, {"url": "https://external-preview.redd.it/VM3NMaAka86XW7sNytrv1-d8VwHKQd4yNgfRN1TYDH4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=741967776fecb02ca2471130fa85e1283a96eb65", "width": 216, "height": 222}, {"url": "https://external-preview.redd.it/VM3NMaAka86XW7sNytrv1-d8VwHKQd4yNgfRN1TYDH4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75678855b28eae26b6c32fd8a8103d4b23af187c", "width": 320, "height": 328}, {"url": "https://external-preview.redd.it/VM3NMaAka86XW7sNytrv1-d8VwHKQd4yNgfRN1TYDH4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef3b5500062c6d1e66daf80d995ff3742e6731bf", "width": 640, "height": 657}], "variants": {}, "id": "6yfy_wPGuHkYLRjJbXHPMjzDN5pzklDEAnz150rKdrE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11xwf09", "is_robot_indexable": true, "report_reasons": null, "author": "joeysaleri", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11xwf09/need_some_help_interpreting_smart_datapotential/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11xwf09/need_some_help_interpreting_smart_datapotential/", "subreddit_subscribers": 674653, "created_utc": 1679436313.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}