{"kind": "Listing", "data": {"after": "t3_11xqjlx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted this on another thread but felt like more data engineers should be aware of these issues with Fivetran and other ELT tools:\n\nFivetran is terrible for these reasons:\n\n- slow to fix issues or problems when they are discovered\n- they alter field names and change data structure thereby making it very difficult to migrate to other options if the need arises.\n- for some data sources they force you to ingest all objects thereby increasing your costs - great for them as it makes them more money\n- they constantly have issues - we would get emails very regularly identifying problems with their system\n- within 6 months of us cancelling we identified an issue where Fivetran was incorrectly identifying primary keys with the Pendo trackevents object.  We raised this with the support team and they denied there was an issue.  Maybe 4 weeks later they sent out an email admitting they had an issue and refused to credit us for the reprocessing of data we incurred trying to fix it.  Their fix also took about 2 months to implement.  We later learned we had dropped over 1 billion rows of data due to this issue.\n- lack of transparency with all the transformations and adjustments they make (yes I know they have schema charts but the transparency goes beyond this)\n- enormous expenses for loading data - we were getting charged around 30k to reload Pendo data when we were able to do it ourselves for about 3k.\n- SLAs are non existent.  They have a 12 hour buffer.  Most integrations get flagged as \u201cdelayed\u201d and there are no clear answers why.\n- They pick and chose what data on each object they pull in.  Don\u2019t assume they bring in all fields that are available on all endpoints.\n\nWe used fivetran for a few years and got off it last November.  \n\nIf you have the skill set to develop and support your own integration framework (Python in our case) I highly recommend it. It is much cheaper, you have full visibility into your data, you don\u2019t get locked into anyone\u2019s architecture, you can troubleshoot issues very quickly, and you can validate the accuracy of the data you are receiving.\n\nFor reference we are supporting over 700 objects with only one headcount.  If you build out a strong well thought out foundation you don\u2019t need a ton of people.", "author_fullname": "t2_fer0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beware of Fivetran and other ELT tools.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xbpjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 103, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 103, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679423038.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679390010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted this on another thread but felt like more data engineers should be aware of these issues with Fivetran and other ELT tools:&lt;/p&gt;\n\n&lt;p&gt;Fivetran is terrible for these reasons:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;slow to fix issues or problems when they are discovered&lt;/li&gt;\n&lt;li&gt;they alter field names and change data structure thereby making it very difficult to migrate to other options if the need arises.&lt;/li&gt;\n&lt;li&gt;for some data sources they force you to ingest all objects thereby increasing your costs - great for them as it makes them more money&lt;/li&gt;\n&lt;li&gt;they constantly have issues - we would get emails very regularly identifying problems with their system&lt;/li&gt;\n&lt;li&gt;within 6 months of us cancelling we identified an issue where Fivetran was incorrectly identifying primary keys with the Pendo trackevents object.  We raised this with the support team and they denied there was an issue.  Maybe 4 weeks later they sent out an email admitting they had an issue and refused to credit us for the reprocessing of data we incurred trying to fix it.  Their fix also took about 2 months to implement.  We later learned we had dropped over 1 billion rows of data due to this issue.&lt;/li&gt;\n&lt;li&gt;lack of transparency with all the transformations and adjustments they make (yes I know they have schema charts but the transparency goes beyond this)&lt;/li&gt;\n&lt;li&gt;enormous expenses for loading data - we were getting charged around 30k to reload Pendo data when we were able to do it ourselves for about 3k.&lt;/li&gt;\n&lt;li&gt;SLAs are non existent.  They have a 12 hour buffer.  Most integrations get flagged as \u201cdelayed\u201d and there are no clear answers why.&lt;/li&gt;\n&lt;li&gt;They pick and chose what data on each object they pull in.  Don\u2019t assume they bring in all fields that are available on all endpoints.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We used fivetran for a few years and got off it last November.  &lt;/p&gt;\n\n&lt;p&gt;If you have the skill set to develop and support your own integration framework (Python in our case) I highly recommend it. It is much cheaper, you have full visibility into your data, you don\u2019t get locked into anyone\u2019s architecture, you can troubleshoot issues very quickly, and you can validate the accuracy of the data you are receiving.&lt;/p&gt;\n\n&lt;p&gt;For reference we are supporting over 700 objects with only one headcount.  If you build out a strong well thought out foundation you don\u2019t need a ton of people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xbpjy", "is_robot_indexable": true, "report_reasons": null, "author": "TheCauthon", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xbpjy/beware_of_fivetran_and_other_elt_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xbpjy/beware_of_fivetran_and_other_elt_tools/", "subreddit_subscribers": 93897, "created_utc": 1679390010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand it's an in process OLAP database. Ok, fine, that's what everyone have been saying since its inception.  I understand it's great and everyone loves it.\n\nI also have no ducking clue what I'm supposed to do with it. Is it supposed to be a drop in replacement for pandas? Or spark?\n\nOr am I supposed to ship it alongside an analytics app to make fast calculations, like Hex does?\n\nOr maybe run it in a pod and use that to perform the T in ETL? Or all of the above?\n\n\\---\n\nCan you ELI5 it to me?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't understand DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xcy2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679394460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand it&amp;#39;s an in process OLAP database. Ok, fine, that&amp;#39;s what everyone have been saying since its inception.  I understand it&amp;#39;s great and everyone loves it.&lt;/p&gt;\n\n&lt;p&gt;I also have no ducking clue what I&amp;#39;m supposed to do with it. Is it supposed to be a drop in replacement for pandas? Or spark?&lt;/p&gt;\n\n&lt;p&gt;Or am I supposed to ship it alongside an analytics app to make fast calculations, like Hex does?&lt;/p&gt;\n\n&lt;p&gt;Or maybe run it in a pod and use that to perform the T in ETL? Or all of the above?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Can you ELI5 it to me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xcy2g", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 105, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xcy2g/i_dont_understand_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xcy2g/i_dont_understand_duckdb/", "subreddit_subscribers": 93897, "created_utc": 1679394460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d5whm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How fast is DuckDB really?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11xzsd3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1Ho7qn66_m7sexfwdNZhdU9MLLUrMPBL6DsAYIiaCiE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679443206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "fivetran.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.fivetran.com/blog/how-fast-is-duckdb-really", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?auto=webp&amp;v=enabled&amp;s=a65049fa01863e0c8f89de2bc437fe4e89eb1ee0", "width": 1920, "height": 960}, "resolutions": [{"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5db0e91c0f77dd7d800ef75bb2b5e7a159d63456", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7feef260f56c9c6839c3177915d0f17a58dcaea", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa1b40c24920cab8a1f0682a4b5afd25ac2c8df5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6143d3b9d8c7111a0dece1279bd894d64a86ac0c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b0c37e0347a20d2a5d7322a5c918934d6bbbaad", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/r3Lgvd_pZPUXaKXVYlMigAspSxLIU05goZtIBV6_sRo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9a6e81a1af4283b86f2593d1b8ff0e9a20da8fa", "width": 1080, "height": 540}], "variants": {}, "id": "GABl6QSTXj3nfyEY-7iduI1mEjK6RJN8fQWhPTc7saA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11xzsd3", "is_robot_indexable": true, "report_reasons": null, "author": "georgewfraser", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xzsd3/how_fast_is_duckdb_really/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.fivetran.com/blog/how-fast-is-duckdb-really", "subreddit_subscribers": 93897, "created_utc": 1679443206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Suppose you are hiring and your requirement is that an individual should have 2+ years of DE experience. But, would you hire someone who doesn't have 2+ years of DE experience, but have done some really good DE personal projects? And what could those projects be? Or what is something that if you saw it on their resume that would compensate for that lack of 2+ years of DE experience?", "author_fullname": "t2_mu0etwaj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Projects to get hired", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjkoy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679446535.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679411183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose you are hiring and your requirement is that an individual should have 2+ years of DE experience. But, would you hire someone who doesn&amp;#39;t have 2+ years of DE experience, but have done some really good DE personal projects? And what could those projects be? Or what is something that if you saw it on their resume that would compensate for that lack of 2+ years of DE experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11xjkoy", "is_robot_indexable": true, "report_reasons": null, "author": "Chance_Ad_3105", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjkoy/data_engineering_projects_to_get_hired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjkoy/data_engineering_projects_to_get_hired/", "subreddit_subscribers": 93897, "created_utc": 1679411183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Two years in the industry, came from a non-tech background, but landed a job as a data engineer. I have worked on small tasks such as maintaining an already built ETL pipeline.\n\nBut I want to learn more. I want to build things from scratch.\n\nData modelling, data cleaning, ETL, etc.\n\nMidnlessly solving SQL and python problems won't get me there.\n\n\nAny help?\n\n\nNote: This is for LEARNING. I don't want to sneak ANYTHING into my resume. I want to get my hands dirty.", "author_fullname": "t2_6zz659ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find online projects end-to-end?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y6b3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679458291.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679457875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two years in the industry, came from a non-tech background, but landed a job as a data engineer. I have worked on small tasks such as maintaining an already built ETL pipeline.&lt;/p&gt;\n\n&lt;p&gt;But I want to learn more. I want to build things from scratch.&lt;/p&gt;\n\n&lt;p&gt;Data modelling, data cleaning, ETL, etc.&lt;/p&gt;\n\n&lt;p&gt;Midnlessly solving SQL and python problems won&amp;#39;t get me there.&lt;/p&gt;\n\n&lt;p&gt;Any help?&lt;/p&gt;\n\n&lt;p&gt;Note: This is for LEARNING. I don&amp;#39;t want to sneak ANYTHING into my resume. I want to get my hands dirty.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11y6b3o", "is_robot_indexable": true, "report_reasons": null, "author": "Aick_Aleck", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11y6b3o/where_can_i_find_online_projects_endtoend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11y6b3o/where_can_i_find_online_projects_endtoend/", "subreddit_subscribers": 93897, "created_utc": 1679457875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mostly see this on Reddit, but sometimes in real life too.  I've talked with friends who are engineers who have said that now is a great time to look for a job, but I literally don't see jobs.  I live in a city with a large amount of tech companies too, and the only data engineering jobs I see are at consulting companies.\n\n\n\nEven laid off engineers from top tech companies are having a hard time getting interviews.\n\n\n\n\nI work at a well known tech company, and even I am finding it hard to get interviews at companies that were trying to recruit me a year ago.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do so many tech workers say the job market is amazing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xw98m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679436022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mostly see this on Reddit, but sometimes in real life too.  I&amp;#39;ve talked with friends who are engineers who have said that now is a great time to look for a job, but I literally don&amp;#39;t see jobs.  I live in a city with a large amount of tech companies too, and the only data engineering jobs I see are at consulting companies.&lt;/p&gt;\n\n&lt;p&gt;Even laid off engineers from top tech companies are having a hard time getting interviews.&lt;/p&gt;\n\n&lt;p&gt;I work at a well known tech company, and even I am finding it hard to get interviews at companies that were trying to recruit me a year ago.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xw98m", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11xw98m/why_do_so_many_tech_workers_say_the_job_market_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xw98m/why_do_so_many_tech_workers_say_the_job_market_is/", "subreddit_subscribers": 93897, "created_utc": 1679436022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Including how to format ctes, variables etc.?", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a standard whitespace format for SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjgjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679410943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Including how to format ctes, variables etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xjgjn", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjgjn/is_there_a_standard_whitespace_format_for_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjgjn/is_there_a_standard_whitespace_format_for_sql/", "subreddit_subscribers": 93897, "created_utc": 1679410943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't wait to do a KT session on this.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_11xpphg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/N6s58Z_wGH9_M0Zv5Itr5dZ_beQUoEq5TMOEdPba-jI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679423320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u5qr6r58y4pa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?auto=webp&amp;v=enabled&amp;s=bdf68ed9a33beab092a344bd127dd12645b32e07", "width": 1423, "height": 958}, "resolutions": [{"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28d015d4784521000a2ae0ed0d307569ff8a58ae", "width": 108, "height": 72}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0509656cdac75f04603924cabdd99085c0d89500", "width": 216, "height": 145}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c47edc67369d19c714037bd69eb1300247b5408", "width": 320, "height": 215}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dbb0a991dce5cb875beb540e76f83402ffc8f1e", "width": 640, "height": 430}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb1230597cfccd5a8080d87dbf983960ff76721e", "width": 960, "height": 646}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed1ad18dd5dfb6d4532871f08532a575ff527202", "width": 1080, "height": 727}], "variants": {}, "id": "mZ7Q8_k2hf4U-_KFlay9qPpRO4P8KGuMYa6D6g-viKA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "11xpphg", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xpphg/cant_wait_to_do_a_kt_session_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u5qr6r58y4pa1.jpg", "subreddit_subscribers": 93897, "created_utc": 1679423320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see people keep repeating they use tools like databricks / dbt. So, anyone use glue? Pros/cons?", "author_fullname": "t2_7arnqer5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on AWS GLUE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xwc5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679436161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see people keep repeating they use tools like databricks / dbt. So, anyone use glue? Pros/cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xwc5g", "is_robot_indexable": true, "report_reasons": null, "author": "puripy", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xwc5g/thoughts_on_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xwc5g/thoughts_on_aws_glue/", "subreddit_subscribers": 93897, "created_utc": 1679436161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve read similar threads, worked with both models. I\u2019m still confused where the threshold between OBT and Star Schema choice is. This question is about looking for right questions to ask given use case, rather than comparing pros &amp; cons of two data models. Please, amend my ways.\n\n**Question**: would you choose OBT or Star Schema for my use case? If it depends, how decision tree looks like in your opinion?\n\n**Use case**: you were asked to implement a new \u201cfeature\u201d (=reports) at medium-big product company, where data engineering is split into dozen of domain-specific teams. These reports are going to be consumed by a few internal business teams (i.e. marketing, sales, etc.), they should also be able to do ad-hoc data exploration. At the moment there is no explicit requirement to combine/conform your reports with any other reports, but as a newcomer you can\u2019t estimate the future trajectory precisely. Billions of rows at report tables, dozens-hundreds of TBs of historical data at ETL layer. Batch ETL - S3/Spark, data exploration \u2013 Athena/Trino, DWH (if needed) \u2013 Snowflake.\n\n**P.S. (terminology)**: despite OBT can be used over star schema, here by OBT I mean absense of division into facts and dimensions.\n\n\\--------------------------------------------------------------------------------------------------------------------------\n\n**^(Optional to read)**^(: my current undestanding, which doesn't cover current use case because it's somewhere in the middle)\n\n^(One side of the spectrum -) **^(use only OBT)**^(:)\n\n* ^(Cost-performance over query-model flexibility-extensibility (i.e. B2C dashboards for thousands of external web customers, where it isn\u2019t possible to give them full freedom of querying under reasonable cost))\n* ^(Implementation speed and simplicity over query-model flexibility-extensibility (i.e. DS/ML use case, where data model is very use case specific, people work in experimentation manner and prefer quick preparation over super universal models))\n\n^(Another side of the spectrum -) **^(use only Star Schema)**^(:)\n\n* ^(Query-model flexibility over initial implementation speed(i.e. BI with dozens++ of reports/business-users, complex ETL with hundreds/thousands of tables. Star Schema benefits overweight modeling effort: it gives more flexibility and optimization room for BI reports developers, narrow/de-composed tables usually give more straightforward data flow and better reporting performance, regular schema upgrades or ad-hoc dimension updates become easier, historical results become queriable by end users))\n* ^(Drill-across multiple business processes is required(OBTs won\u2019t scale here, need Star Schema and conformed dimensions))", "author_fullname": "t2_26jx1rij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you choose between star schema vs one big table (OBT) data models for big data reporting without explicit enterprise data warehouse requirements?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjsyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679411664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve read similar threads, worked with both models. I\u2019m still confused where the threshold between OBT and Star Schema choice is. This question is about looking for right questions to ask given use case, rather than comparing pros &amp;amp; cons of two data models. Please, amend my ways.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: would you choose OBT or Star Schema for my use case? If it depends, how decision tree looks like in your opinion?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: you were asked to implement a new \u201cfeature\u201d (=reports) at medium-big product company, where data engineering is split into dozen of domain-specific teams. These reports are going to be consumed by a few internal business teams (i.e. marketing, sales, etc.), they should also be able to do ad-hoc data exploration. At the moment there is no explicit requirement to combine/conform your reports with any other reports, but as a newcomer you can\u2019t estimate the future trajectory precisely. Billions of rows at report tables, dozens-hundreds of TBs of historical data at ETL layer. Batch ETL - S3/Spark, data exploration \u2013 Athena/Trino, DWH (if needed) \u2013 Snowflake.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. (terminology)&lt;/strong&gt;: despite OBT can be used over star schema, here by OBT I mean absense of division into facts and dimensions.&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;sup&gt;Optional to read&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;: my current undestanding, which doesn&amp;#39;t cover current use case because it&amp;#39;s somewhere in the middle&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;One side of the spectrum -&lt;/sup&gt; &lt;strong&gt;&lt;sup&gt;use only OBT&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;:&lt;/sup&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;sup&gt;Cost-performance over query-model flexibility-extensibility (i.e. B2C dashboards for thousands of external web customers, where it isn\u2019t possible to give them full freedom of querying under reasonable cost&lt;/sup&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;sup&gt;Implementation speed and simplicity over query-model flexibility-extensibility (i.e. DS/ML use case, where data model is very use case specific, people work in experimentation manner and prefer quick preparation over super universal models&lt;/sup&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;sup&gt;Another side of the spectrum -&lt;/sup&gt; &lt;strong&gt;&lt;sup&gt;use only Star Schema&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;:&lt;/sup&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;sup&gt;Query-model flexibility over initial implementation speed(i.e. BI with dozens++ of reports/business-users, complex ETL with hundreds/thousands of tables. Star Schema benefits overweight modeling effort: it gives more flexibility and optimization room for BI reports developers, narrow/de-composed tables usually give more straightforward data flow and better reporting performance, regular schema upgrades or ad-hoc dimension updates become easier, historical results become queriable by end users&lt;/sup&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;sup&gt;Drill-across multiple business processes is required(OBTs won\u2019t scale here, need Star Schema and conformed dimensions&lt;/sup&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xjsyl", "is_robot_indexable": true, "report_reasons": null, "author": "Volody_", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjsyl/how_would_you_choose_between_star_schema_vs_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjsyl/how_would_you_choose_between_star_schema_vs_one/", "subreddit_subscribers": 93897, "created_utc": 1679411664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I\u2019m one of the founders at EqualTo. \n\nWe\u2019re currently building a \u2018spreadsheets as a service\u2019 to help developers integrate spreadsheets. I\u2019d love to hear your thoughts on the concept, and whether you\u2019ve ever experienced any issues with integrating or embedding spreadsheets into apps or websites in the past? \n\nWe\u2019ve just launched our [open beta](https://sheets.equalto.com/#/license/request) if you\u2019d like to check it out!", "author_fullname": "t2_553i0uk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A dev-friendly spreadsheet product - yay or nay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xhuu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679407483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I\u2019m one of the founders at EqualTo. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re currently building a \u2018spreadsheets as a service\u2019 to help developers integrate spreadsheets. I\u2019d love to hear your thoughts on the concept, and whether you\u2019ve ever experienced any issues with integrating or embedding spreadsheets into apps or websites in the past? &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve just launched our &lt;a href=\"https://sheets.equalto.com/#/license/request\"&gt;open beta&lt;/a&gt; if you\u2019d like to check it out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xhuu4", "is_robot_indexable": true, "report_reasons": null, "author": "PinksFunnyFarm", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xhuu4/a_devfriendly_spreadsheet_product_yay_or_nay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xhuu4/a_devfriendly_spreadsheet_product_yay_or_nay/", "subreddit_subscribers": 93897, "created_utc": 1679407483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_11093gvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"No Code\" data tools and approaches are the placebo for unwanted complexity, not the medicine.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xh7we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1679406040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ucovi-data.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "http://www.ucovi-data.com/BlogLatest", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xh7we", "is_robot_indexable": true, "report_reasons": null, "author": "UCOVINed", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xh7we/no_code_data_tools_and_approaches_are_the_placebo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://www.ucovi-data.com/BlogLatest", "subreddit_subscribers": 93897, "created_utc": 1679406040.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI am looking for best practices to consume files arriving at high frequency in S3 , we are using a native  integration tool that is using S3 as queue/dump rather than a landing zone controlling the dumps, sending files every sub-second/2-seconds, files are dumped in `daily` partitions containing these live dumps, but not less than daily ( eg hourly  ). I want a way to control picking up these files, and transforming them,  then loading it into a DWH.\n\nRight now we are running an ETL as  a D-1, and is kinda stable , but I want to achieve more frequent updates, we target an Hourly run.\n\nWhat would be your best practice architecture suggestions here.\n\nThanks !", "author_fullname": "t2_ce0xxymx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices : High frequency dumps in S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xodtv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679420731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am looking for best practices to consume files arriving at high frequency in S3 , we are using a native  integration tool that is using S3 as queue/dump rather than a landing zone controlling the dumps, sending files every sub-second/2-seconds, files are dumped in &lt;code&gt;daily&lt;/code&gt; partitions containing these live dumps, but not less than daily ( eg hourly  ). I want a way to control picking up these files, and transforming them,  then loading it into a DWH.&lt;/p&gt;\n\n&lt;p&gt;Right now we are running an ETL as  a D-1, and is kinda stable , but I want to achieve more frequent updates, we target an Hourly run.&lt;/p&gt;\n\n&lt;p&gt;What would be your best practice architecture suggestions here.&lt;/p&gt;\n\n&lt;p&gt;Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xodtv", "is_robot_indexable": true, "report_reasons": null, "author": "Wingsofpeace7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xodtv/best_practices_high_frequency_dumps_in_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xodtv/best_practices_high_frequency_dumps_in_s3/", "subreddit_subscribers": 93897, "created_utc": 1679420731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: Mid-level FAANG SWE wants to transition to a data infra SWE (kind of like Zach Wilson on LinkedIn), but has no data-related skills / idea of how to make it happen.\n\nHey all,\n\nI'm an SWE with 2 YoE at a FAANG company. I work on an ML-related team; specifically, the team productionizes and operates ML models (developed by scientists) to extract structured entities from natural language text.\n\nThis sounds really cool (especially when I tell people we get to deal with ChatGPT-like LLMs), and it was great for career growth (got promoted quickly since I joined when the team was totally greenfield), but I really haven't learned a lot.\n\nThe team name has \"data\" in it, but we don't get to deal with it since we onboard models to a Spark-based inference orchestration platform owned by another team. As a result, that team gets to deal with (and brag about) all the big data aspects of running 55,000+ ML models. I also haven't built many real SWE skills either since we haven't implemented a single API yet (we have no external customers).\n\nI didn't care about these things originally due to the fast career growth, but as I get more senior, I want to specialize (which means having actual skills).\n\nSince I worked on a \"data\" team, I thought I'd try to position myself as a data infra dev (so that I don't have to \"start over\" domain-wise), but I really don't have the skills for that. For context, I don't even know proper SQL since every design I've seen around here auto-assumes the same NoSQL database.\n\nMy question to you guys is -- how do I go from my current state to someone like Zach Wilson on LinkedIn without taking a big hit career and/or comp-wise?\n\nDo I try self-study SQL, DBMSs, popular big data platforms (e.g. Spark) and internally transfer to a data-oriented product in our public cloud (e.g. AWS EMR, Azure HDInsight, Spark on GCloud)?\n\nOr get a pure DE role in a smaller company?", "author_fullname": "t2_72c7qtwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice: SWE on a \"data\" team to data infra SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11y10i1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679446137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679445825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: Mid-level FAANG SWE wants to transition to a data infra SWE (kind of like Zach Wilson on LinkedIn), but has no data-related skills / idea of how to make it happen.&lt;/p&gt;\n\n&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an SWE with 2 YoE at a FAANG company. I work on an ML-related team; specifically, the team productionizes and operates ML models (developed by scientists) to extract structured entities from natural language text.&lt;/p&gt;\n\n&lt;p&gt;This sounds really cool (especially when I tell people we get to deal with ChatGPT-like LLMs), and it was great for career growth (got promoted quickly since I joined when the team was totally greenfield), but I really haven&amp;#39;t learned a lot.&lt;/p&gt;\n\n&lt;p&gt;The team name has &amp;quot;data&amp;quot; in it, but we don&amp;#39;t get to deal with it since we onboard models to a Spark-based inference orchestration platform owned by another team. As a result, that team gets to deal with (and brag about) all the big data aspects of running 55,000+ ML models. I also haven&amp;#39;t built many real SWE skills either since we haven&amp;#39;t implemented a single API yet (we have no external customers).&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t care about these things originally due to the fast career growth, but as I get more senior, I want to specialize (which means having actual skills).&lt;/p&gt;\n\n&lt;p&gt;Since I worked on a &amp;quot;data&amp;quot; team, I thought I&amp;#39;d try to position myself as a data infra dev (so that I don&amp;#39;t have to &amp;quot;start over&amp;quot; domain-wise), but I really don&amp;#39;t have the skills for that. For context, I don&amp;#39;t even know proper SQL since every design I&amp;#39;ve seen around here auto-assumes the same NoSQL database.&lt;/p&gt;\n\n&lt;p&gt;My question to you guys is -- how do I go from my current state to someone like Zach Wilson on LinkedIn without taking a big hit career and/or comp-wise?&lt;/p&gt;\n\n&lt;p&gt;Do I try self-study SQL, DBMSs, popular big data platforms (e.g. Spark) and internally transfer to a data-oriented product in our public cloud (e.g. AWS EMR, Azure HDInsight, Spark on GCloud)?&lt;/p&gt;\n\n&lt;p&gt;Or get a pure DE role in a smaller company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11y10i1", "is_robot_indexable": true, "report_reasons": null, "author": "hopelessaspirant23", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11y10i1/career_advice_swe_on_a_data_team_to_data_infra_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11y10i1/career_advice_swe_on_a_data_team_to_data_infra_swe/", "subreddit_subscribers": 93897, "created_utc": 1679445825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking into data observability for the team I work on, and am hoping to hear the experiences that others have.\n\nI want to have the typical things, like understanding when incoming data differs from what is typical, and when the volumes have changed significantly, etc.  Hoping to hear how your experiences are with different platforms and whether the value realized by your company was sufficient for the investment or if it would have been better to focus on a few core concerns with a home-grown solution.\n\nMy tendency is to prefer open-source technologies, but it feels like there isn't really anything out there at this point.  Lacking that, I would hope for a lightweight model for integrating with my systems.", "author_fullname": "t2_itkzoxly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability Tooling (Kensu, Metaplane, Monte Carlo, etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xqdxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679424709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking into data observability for the team I work on, and am hoping to hear the experiences that others have.&lt;/p&gt;\n\n&lt;p&gt;I want to have the typical things, like understanding when incoming data differs from what is typical, and when the volumes have changed significantly, etc.  Hoping to hear how your experiences are with different platforms and whether the value realized by your company was sufficient for the investment or if it would have been better to focus on a few core concerns with a home-grown solution.&lt;/p&gt;\n\n&lt;p&gt;My tendency is to prefer open-source technologies, but it feels like there isn&amp;#39;t really anything out there at this point.  Lacking that, I would hope for a lightweight model for integrating with my systems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xqdxw", "is_robot_indexable": true, "report_reasons": null, "author": "StingingNarwhal", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xqdxw/data_observability_tooling_kensu_metaplane_monte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xqdxw/data_observability_tooling_kensu_metaplane_monte/", "subreddit_subscribers": 93897, "created_utc": 1679424709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm currently a Data Engineer who made the switch from Data Science last August. I've been learning quite a bit since I joined, but I'm starting to question my current position due to the nature of the tasks I've been assigned.\n\nMost of the complexity in my tasks comes from navigating the intricate systems, rather than the tasks themselves. For instance, I'm currently working on a ticket to change the CI/CD pipeline handling some config files for Airflow. It's been a bit of a nightmare, honestly. So far, I have 12 open pull requests on Github, and I'm still not done. I feel like I'm losing track of the overall picture, and it's beginning to weigh on me.\n\nTo make matters worse, a lot of the work I do is specific to my employer's architecture. I'm finding this quite demotivating because I'm not developing generic skills that I can apply in other situations. This is in stark contrast to my previous experience as a Data Scientist, where most of the skills I acquired were transferable and broadly applicable.\n\nI'd love to hear from other Data Engineers: is this a common experience in the field? Should I expect the majority of my tasks to involve this level of complexity and specificity? And if so, do you have any tips or advice for managing these challenges?\n\nThank you in advance for any input you can provide!", "author_fullname": "t2_2rt9q2bl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with complexity in Data Engineering after switching from Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xyjnj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679440627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m currently a Data Engineer who made the switch from Data Science last August. I&amp;#39;ve been learning quite a bit since I joined, but I&amp;#39;m starting to question my current position due to the nature of the tasks I&amp;#39;ve been assigned.&lt;/p&gt;\n\n&lt;p&gt;Most of the complexity in my tasks comes from navigating the intricate systems, rather than the tasks themselves. For instance, I&amp;#39;m currently working on a ticket to change the CI/CD pipeline handling some config files for Airflow. It&amp;#39;s been a bit of a nightmare, honestly. So far, I have 12 open pull requests on Github, and I&amp;#39;m still not done. I feel like I&amp;#39;m losing track of the overall picture, and it&amp;#39;s beginning to weigh on me.&lt;/p&gt;\n\n&lt;p&gt;To make matters worse, a lot of the work I do is specific to my employer&amp;#39;s architecture. I&amp;#39;m finding this quite demotivating because I&amp;#39;m not developing generic skills that I can apply in other situations. This is in stark contrast to my previous experience as a Data Scientist, where most of the skills I acquired were transferable and broadly applicable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear from other Data Engineers: is this a common experience in the field? Should I expect the majority of my tasks to involve this level of complexity and specificity? And if so, do you have any tips or advice for managing these challenges?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any input you can provide!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11xyjnj", "is_robot_indexable": true, "report_reasons": null, "author": "Random-Random-Person", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xyjnj/struggling_with_complexity_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xyjnj/struggling_with_complexity_in_data_engineering/", "subreddit_subscribers": 93897, "created_utc": 1679440627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI recently joined a new company and have been given a unique opportunity to evaluate the current azure architecture. The current processes are pretty slow and there is definitely room for improvement. The current is as follows: \n\n30 different source systems\nEach source system has 100 tables of like data \nEach table / source system gets its own folder in azure gen 2 storage like: SS/year/month/day/table/ data \n\nThis process works pretty good, ingestion query runs, puts data in folder\u2026.\n\nThe next part grabs the data using ADF polybase copy data function and copies the data into synapse, then there are stored procs that handle the transformation / type 2 updates called from adf\n \nAll of this is done from a dedicated sql pool\n\n The transformations being in sql stored procs are killing us, which I think is where we can start to leverage pyspark. \n\nMy question is,  where best can we leverage pyspark? \n\nThe ingestion from source to AZDL gen 2 doesn\u2019t make sense because that process doesn\u2019t take long (why rebuild something that isn\u2019t broken). \n\nThe next possible place is to replace the polybase copy / transformations from AZDL to synapse, which is where I think we could get the most impact w/o rebuilding everything. \n\nThinking through, using pyspark, my thought is to read the data from the data lake, perform transformations, then load data to delta table then update delta table for type2 changes. \n\nWould it be best to load the delta table to a staging table or load the delta table to the production table?  Or am I just thinking about this wrong.\n\nAny help is appreciated!", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark VS copy data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xwwli", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679437263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently joined a new company and have been given a unique opportunity to evaluate the current azure architecture. The current processes are pretty slow and there is definitely room for improvement. The current is as follows: &lt;/p&gt;\n\n&lt;p&gt;30 different source systems\nEach source system has 100 tables of like data \nEach table / source system gets its own folder in azure gen 2 storage like: SS/year/month/day/table/ data &lt;/p&gt;\n\n&lt;p&gt;This process works pretty good, ingestion query runs, puts data in folder\u2026.&lt;/p&gt;\n\n&lt;p&gt;The next part grabs the data using ADF polybase copy data function and copies the data into synapse, then there are stored procs that handle the transformation / type 2 updates called from adf&lt;/p&gt;\n\n&lt;p&gt;All of this is done from a dedicated sql pool&lt;/p&gt;\n\n&lt;p&gt;The transformations being in sql stored procs are killing us, which I think is where we can start to leverage pyspark. &lt;/p&gt;\n\n&lt;p&gt;My question is,  where best can we leverage pyspark? &lt;/p&gt;\n\n&lt;p&gt;The ingestion from source to AZDL gen 2 doesn\u2019t make sense because that process doesn\u2019t take long (why rebuild something that isn\u2019t broken). &lt;/p&gt;\n\n&lt;p&gt;The next possible place is to replace the polybase copy / transformations from AZDL to synapse, which is where I think we could get the most impact w/o rebuilding everything. &lt;/p&gt;\n\n&lt;p&gt;Thinking through, using pyspark, my thought is to read the data from the data lake, perform transformations, then load data to delta table then update delta table for type2 changes. &lt;/p&gt;\n\n&lt;p&gt;Would it be best to load the delta table to a staging table or load the delta table to the production table?  Or am I just thinking about this wrong.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xwwli", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xwwli/pyspark_vs_copy_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xwwli/pyspark_vs_copy_data/", "subreddit_subscribers": 93897, "created_utc": 1679437263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to start my career as a machine learning engineer.  I'm passionate about machine learning and would love to build machine learning products hence why I chose ML engineering.\n\nI have basic knowledge of machine learning algorithms and deep learning with Pytorch\n\nI was told that it would be tough to get an entry level role as a machine learning engineer. So I had three choices, either to start out as a DE, DS or DA. \n\nI chose DE because i wanted to learn software engineering practices (version control, git etc) and how to build data pipelines. I believe I could leverage this skill when building machine learning pipelines\n\nI want to ask if this is the correct path and be sure that I'm not making any incorrect assumptions\n\nWould appreciate any feedback", "author_fullname": "t2_w0tlyiws", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE to Machine Learning Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xy5w2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679439824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to start my career as a machine learning engineer.  I&amp;#39;m passionate about machine learning and would love to build machine learning products hence why I chose ML engineering.&lt;/p&gt;\n\n&lt;p&gt;I have basic knowledge of machine learning algorithms and deep learning with Pytorch&lt;/p&gt;\n\n&lt;p&gt;I was told that it would be tough to get an entry level role as a machine learning engineer. So I had three choices, either to start out as a DE, DS or DA. &lt;/p&gt;\n\n&lt;p&gt;I chose DE because i wanted to learn software engineering practices (version control, git etc) and how to build data pipelines. I believe I could leverage this skill when building machine learning pipelines&lt;/p&gt;\n\n&lt;p&gt;I want to ask if this is the correct path and be sure that I&amp;#39;m not making any incorrect assumptions&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any feedback&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11xy5w2", "is_robot_indexable": true, "report_reasons": null, "author": "United-Award2767", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xy5w2/de_to_machine_learning_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xy5w2/de_to_machine_learning_engineer/", "subreddit_subscribers": 93897, "created_utc": 1679439824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! We have a supplier who have a REST API with the form &lt;host&gt;/&lt;entity type&gt;/&lt;id&gt;.  \nI wish to fetch about a million of these entities, and unfortunately they dont have a bulk endpoint. \n\nOne solution is a Cloud Function that fetches and stores each call, fed from a pub/sub queue holding the unfetched ids (in Google Cloud), but I dont see how I would rate limit the Cloud Function, as to not cause their DDOS protection to kick in.\n\nHow would you have done this? Is there any SAAS that does this that I am not aware of?", "author_fullname": "t2_82s0a64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fetch a million entities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xk6l4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679412462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! We have a supplier who have a REST API with the form &amp;lt;host&amp;gt;/&amp;lt;entity type&amp;gt;/&amp;lt;id&amp;gt;.&lt;br/&gt;\nI wish to fetch about a million of these entities, and unfortunately they dont have a bulk endpoint. &lt;/p&gt;\n\n&lt;p&gt;One solution is a Cloud Function that fetches and stores each call, fed from a pub/sub queue holding the unfetched ids (in Google Cloud), but I dont see how I would rate limit the Cloud Function, as to not cause their DDOS protection to kick in.&lt;/p&gt;\n\n&lt;p&gt;How would you have done this? Is there any SAAS that does this that I am not aware of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xk6l4", "is_robot_indexable": true, "report_reasons": null, "author": "Ootoootooo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xk6l4/fetch_a_million_entities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xk6l4/fetch_a_million_entities/", "subreddit_subscribers": 93897, "created_utc": 1679412462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried and tested Codon yet ,\n\n[https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314](https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314)\n\n&amp;#x200B;\n\nBrain Storming to see how the code and future in house or OS implementations would be implemented with Codon,\n\nif anyone has any industry news on future roadmaps of other python frameworks being refactored with its use  please share ?", "author_fullname": "t2_kqhkj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Codon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xei7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679399434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried and tested Codon yet ,&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314\"&gt;https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Brain Storming to see how the code and future in house or OS implementations would be implemented with Codon,&lt;/p&gt;\n\n&lt;p&gt;if anyone has any industry news on future roadmaps of other python frameworks being refactored with its use  please share ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?auto=webp&amp;v=enabled&amp;s=20358f89bb763869cda6461b01461cf4a811bb10", "width": 1500, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8299e4f06021e65c937356ab6c9730c0bc194771", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b222338636277f5f2d62d528c7102aa40f4b77f5", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=868cbe581e483597e18765e592a40d06204f64f7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c81813067a6724ef8e7b2e88a33ed3742bfe4933", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbfbd11b20a1602c1e1971eaa75b555abff08a1e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc1bb809dc94e16946345af82e9d5d530ec8292a", "width": 1080, "height": 720}], "variants": {}, "id": "q8mXD_72YdtfxqBVGJrRf6ZHbP-LoRsgm1Vj9MJySu0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xei7c", "is_robot_indexable": true, "report_reasons": null, "author": "audyoga", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xei7c/python_codon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xei7c/python_codon/", "subreddit_subscribers": 93897, "created_utc": 1679399434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a python coding assessment I must complete to move on to the next round of interviews\nIs there a resource that is kind of a quick python refresher specifically for data engineering or data integration?\n\nI do typically use python for my day to day tasks but I guess I would have peace of mind with a quick review before taking on this assessment.\nIt just wouldn't hurt to review also honestly.\n\nWhat would you guys recommend?", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Review for coding assessment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xvudc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679435228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a python coding assessment I must complete to move on to the next round of interviews\nIs there a resource that is kind of a quick python refresher specifically for data engineering or data integration?&lt;/p&gt;\n\n&lt;p&gt;I do typically use python for my day to day tasks but I guess I would have peace of mind with a quick review before taking on this assessment.\nIt just wouldn&amp;#39;t hurt to review also honestly.&lt;/p&gt;\n\n&lt;p&gt;What would you guys recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11xvudc", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xvudc/python_review_for_coding_assessment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xvudc/python_review_for_coding_assessment/", "subreddit_subscribers": 93897, "created_utc": 1679435228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe I don\u2019t fully know what data engineering is, but I think I\u2019ve actually been more data engineer than DevOps engineer despite selling myself as the latter\u2026\n\nAre these the typical job duties of Data Engineering?\n\nJob 1) Deploying clusters and building ML training pipelines using TF/Keras, Python, and GCP. Did some model work as well but mostly handled the platform.\n\nJob 2) DevOps/sysadmin for CI tool, evolved into being the \u201cdata and API guy\u201d for all developer tools to create reports on security, licensing, churn, and CI usage.\n\nJob 3) Build a message parsing and normalization pipeline using Python+Beam and GCP Dataflow for clients.\n\nBasically I work on the pipeline from collected data to processing and storage. What I don\u2019t have is the stats background that it seems lots of data people have.", "author_fullname": "t2_2hr24ff0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just realized I\u2019ve been a Data Engineer more than a DevOps Engineer most of my (short) career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xqis4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679424994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe I don\u2019t fully know what data engineering is, but I think I\u2019ve actually been more data engineer than DevOps engineer despite selling myself as the latter\u2026&lt;/p&gt;\n\n&lt;p&gt;Are these the typical job duties of Data Engineering?&lt;/p&gt;\n\n&lt;p&gt;Job 1) Deploying clusters and building ML training pipelines using TF/Keras, Python, and GCP. Did some model work as well but mostly handled the platform.&lt;/p&gt;\n\n&lt;p&gt;Job 2) DevOps/sysadmin for CI tool, evolved into being the \u201cdata and API guy\u201d for all developer tools to create reports on security, licensing, churn, and CI usage.&lt;/p&gt;\n\n&lt;p&gt;Job 3) Build a message parsing and normalization pipeline using Python+Beam and GCP Dataflow for clients.&lt;/p&gt;\n\n&lt;p&gt;Basically I work on the pipeline from collected data to processing and storage. What I don\u2019t have is the stats background that it seems lots of data people have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11xqis4", "is_robot_indexable": true, "report_reasons": null, "author": "roll_left_420", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xqis4/i_just_realized_ive_been_a_data_engineer_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xqis4/i_just_realized_ive_been_a_data_engineer_more/", "subreddit_subscribers": 93897, "created_utc": 1679424994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer: I'm totally new to DE; this is my first DE job, and I don't have full understanding of DE concepts and technologies yet.\n\nDoes Databricks provide a sandbox environment to practise the Lab exercises from the Databricks Customer Academy? Am I missing something? Am I expected to practise on my company's workspace? In that case, they don't have a learning environment yet... How can I practise?\n\nThanks in advance.", "author_fullname": "t2_14zmwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workspace to practise Lab \u2014 Databricks Customer Academy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xlus1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679420048.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679415741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I&amp;#39;m totally new to DE; this is my first DE job, and I don&amp;#39;t have full understanding of DE concepts and technologies yet.&lt;/p&gt;\n\n&lt;p&gt;Does Databricks provide a sandbox environment to practise the Lab exercises from the Databricks Customer Academy? Am I missing something? Am I expected to practise on my company&amp;#39;s workspace? In that case, they don&amp;#39;t have a learning environment yet... How can I practise?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xlus1", "is_robot_indexable": true, "report_reasons": null, "author": "silcap", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xlus1/workspace_to_practise_lab_databricks_customer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xlus1/workspace_to_practise_lab_databricks_customer/", "subreddit_subscribers": 93897, "created_utc": 1679415741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any sort of workaround to enable the use of type hints for PySpark SQL dataframes. I know that Pandas API on PySpark dataframes support type hints.\n\nCurrently, I struggle to infer the columns available on a dataframe as in my project, we do multiple joins and add different columns in various places. Having a static typing will help me in those cases.\n\nExample:\n```\ndef add_age_col(df: DataFrame[\"id\": int, \"name\": str) -&gt; DataFrame[\"id\": int, \"name\": str, \"age\": int]:\n    ...\n```\n\nWhen I run this, I get an error saying that DataFrame is not subscriptable, which means it doesn't support type hints.\n\nDoes anybody know if it's coming to PySpark anytime soon?", "author_fullname": "t2_179cg5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Static type hints for PySpark SQL dataframes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xefye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679399258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any sort of workaround to enable the use of type hints for PySpark SQL dataframes. I know that Pandas API on PySpark dataframes support type hints.&lt;/p&gt;\n\n&lt;p&gt;Currently, I struggle to infer the columns available on a dataframe as in my project, we do multiple joins and add different columns in various places. Having a static typing will help me in those cases.&lt;/p&gt;\n\n&lt;p&gt;Example:\n&lt;code&gt;\ndef add_age_col(df: DataFrame[&amp;quot;id&amp;quot;: int, &amp;quot;name&amp;quot;: str) -&amp;gt; DataFrame[&amp;quot;id&amp;quot;: int, &amp;quot;name&amp;quot;: str, &amp;quot;age&amp;quot;: int]:\n    ...\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;When I run this, I get an error saying that DataFrame is not subscriptable, which means it doesn&amp;#39;t support type hints.&lt;/p&gt;\n\n&lt;p&gt;Does anybody know if it&amp;#39;s coming to PySpark anytime soon?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xefye", "is_robot_indexable": true, "report_reasons": null, "author": "pavi2410", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xefye/static_type_hints_for_pyspark_sql_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xefye/static_type_hints_for_pyspark_sql_dataframes/", "subreddit_subscribers": 93897, "created_utc": 1679399258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've joined a new team and the ingestion pipeline they have in place looks clumsy to me. It's very, very slow (it takes 1 min to ingest 2MB of data!!!) and just doesn't look like a best practice approach.\n\n- one script checks if files have been ingested before - it checks logs in a Redshift table, stores data in lists, iterates over lists... This can be optimised, but it makes sense to only load data that hasn't been loaded before \n- we have metadata stored in JSON files such as expected file size, file type, columns and data types for each parquet file\n- parquet files are ingested from another AWS account and read with Pyarrow to compare columns with the expected metadata in JSON files. These checks take quite some time and include file size and file type checks. The tech lead decided against using Glue so we can't use PySpark to read schemas, but to be fair we also don't have a lot of data. \n- all parquet are copied into our bucket once all metadata checks have passed successfully - if some checks have failed they are copied from the landing zone into a rejected folder. This means that files are loaded when they contain additional columns, but these columns won't be added to Redshift. If columns are missing or data types are inconsistent, the entire table is rejected for the specific day\n- if files are rejected, the data producer needs to fix them manually and we have to re-run our pipeline which can be done by adjusting a cron job in prod (the pipeline runs once a day and doesn't have a retry mechanism -&gt; these are all custom Python script running in containers) \n\nIs any of this best practice? Wouldn't it make more sense to copy new data first into a landing zone and then run checks? The comparison with a JSON file also seems odd to me. Isn't this something I would do with a data catalogue?", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this ingestion pipeline make sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xqjlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679425043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve joined a new team and the ingestion pipeline they have in place looks clumsy to me. It&amp;#39;s very, very slow (it takes 1 min to ingest 2MB of data!!!) and just doesn&amp;#39;t look like a best practice approach.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;one script checks if files have been ingested before - it checks logs in a Redshift table, stores data in lists, iterates over lists... This can be optimised, but it makes sense to only load data that hasn&amp;#39;t been loaded before &lt;/li&gt;\n&lt;li&gt;we have metadata stored in JSON files such as expected file size, file type, columns and data types for each parquet file&lt;/li&gt;\n&lt;li&gt;parquet files are ingested from another AWS account and read with Pyarrow to compare columns with the expected metadata in JSON files. These checks take quite some time and include file size and file type checks. The tech lead decided against using Glue so we can&amp;#39;t use PySpark to read schemas, but to be fair we also don&amp;#39;t have a lot of data. &lt;/li&gt;\n&lt;li&gt;all parquet are copied into our bucket once all metadata checks have passed successfully - if some checks have failed they are copied from the landing zone into a rejected folder. This means that files are loaded when they contain additional columns, but these columns won&amp;#39;t be added to Redshift. If columns are missing or data types are inconsistent, the entire table is rejected for the specific day&lt;/li&gt;\n&lt;li&gt;if files are rejected, the data producer needs to fix them manually and we have to re-run our pipeline which can be done by adjusting a cron job in prod (the pipeline runs once a day and doesn&amp;#39;t have a retry mechanism -&amp;gt; these are all custom Python script running in containers) &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is any of this best practice? Wouldn&amp;#39;t it make more sense to copy new data first into a landing zone and then run checks? The comparison with a JSON file also seems odd to me. Isn&amp;#39;t this something I would do with a data catalogue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xqjlx", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xqjlx/does_this_ingestion_pipeline_make_sense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xqjlx/does_this_ingestion_pipeline_make_sense/", "subreddit_subscribers": 93897, "created_utc": 1679425043.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}