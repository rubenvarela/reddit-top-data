{"kind": "Listing", "data": {"after": "t3_1223tq7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As we all know, this loss against the big publishers has IA appealing, with the risk that they could lose the appeals court too. While the fact that this lawsuit only applies to their books, the truly dangerous part is the legal ramifications IA has to pay if they happen to lose the war. Face it, if the amount of money owed to the publishers is beyond what IA can handle to keep their project running, to quote Numbuh 4, all their info will be \"J-A-W-N, GONE!\"\n\nBut in all seriousness, I was proposing that we backup every last bit of info they have on their site and build a new one in its place if IA does end up having to shut down. Or at the very least donate every last penny we can spare to make sure they have enough to keep going even if they do end up losing. Or will IA come back rebranded, rising from the ashes? I wanna find some way to spread hope, the fact that all isn't lost in spite of the potential legal ramifications.", "author_fullname": "t2_nyv7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for the worst outcome for Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121uif6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 279, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 279, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679768678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, this loss against the big publishers has IA appealing, with the risk that they could lose the appeals court too. While the fact that this lawsuit only applies to their books, the truly dangerous part is the legal ramifications IA has to pay if they happen to lose the war. Face it, if the amount of money owed to the publishers is beyond what IA can handle to keep their project running, to quote Numbuh 4, all their info will be &amp;quot;J-A-W-N, GONE!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;But in all seriousness, I was proposing that we backup every last bit of info they have on their site and build a new one in its place if IA does end up having to shut down. Or at the very least donate every last penny we can spare to make sure they have enough to keep going even if they do end up losing. Or will IA come back rebranded, rising from the ashes? I wanna find some way to spread hope, the fact that all isn&amp;#39;t lost in spite of the potential legal ramifications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "121uif6", "is_robot_indexable": true, "report_reasons": null, "author": "SuperFightingSaiyan", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121uif6/preparing_for_the_worst_outcome_for_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121uif6/preparing_for_the_worst_outcome_for_internet/", "subreddit_subscribers": 675282, "created_utc": 1679768678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_a7kq8bkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive Ruling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "name": "t3_121mmot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gLmexXD_sumhGyylboFQCuN1I9I2WfuScPvWUCmmxGg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679752667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "apnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://apnews.com/article/0674119646bd920492f87490e8d2027b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?auto=webp&amp;v=enabled&amp;s=269713ea00bd4cef48ce4ecef7f7ecb05ffc1c22", "width": 700, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=020b844ba9242930016a8b75af9198e33a67d8a5", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=115e7ee575c2ee0ccf7972be5f495f8f9e42ac0f", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed2f002bf68f11af1260a7ffa902fdd06c835646", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85d3fca289ea340eaec0a7e8f6217b2689d598df", "width": 640, "height": 411}], "variants": {}, "id": "R2LP5YXZK5pskfP-9eZMdFi42my_VF_Bgzy0IdiKrJQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121mmot", "is_robot_indexable": true, "report_reasons": null, "author": "TomBel71", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121mmot/archive_ruling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://apnews.com/article/0674119646bd920492f87490e8d2027b", "subreddit_subscribers": 675282, "created_utc": 1679752667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_a65nr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dead HDD from UnRaid. Any harm in taking it apart to see where the error is? (Stuck read head?) It\u2019s not important enough to pay for a recovery.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_121puru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/qjixqlh56ypa1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/qjixqlh56ypa1/DASH_96.mp4", "dash_url": "https://v.redd.it/qjixqlh56ypa1/DASHPlaylist.mpd?a=1682391010%2CNzliNjljNzcwNjRhMDJkYjczZTRhNGE2MTE4MGZhOWYyNGRkNmY1MGZiYzc0YmNlNDI2ZGU5OTFkN2UwYTFiNg%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/qjixqlh56ypa1/HLSPlaylist.m3u8?a=1682391010%2CNjY2YWUwZWY2NTM4ZDJkY2UzM2NmZTA4ZjExYjVlMzQ4NzhkMzI4NmZhNGVmZmU4OWJmZDc2OTdkMTVmMzAwMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0IlRpZoSQTR-GwGKQfPFQ2IeMeyZbFtSUWvhq3Y_al4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679759142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/qjixqlh56ypa1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e03f9dae2b11d5a69099063a09d050cf0198a132", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0e709af1ae4281845560089a0cc1dacb7d514db3", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2cb096187d8d10c54f2580c40820ccb1ff539b03", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6c4504396770473a1a7bbafca11d9f704bed2559", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0eb3727381cf6f020fc0329266dce3f91cb43e00", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8dcbc076c596124773d79e118f2331bbf82b19f6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/-meyBwS0_DCtx1TSytQYDuWlOdUODM8D5XqDbHmqeCU.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=41d01dcb20bc31fb1989e20bfa1e7a1ef0625c86", "width": 1080, "height": 607}], "variants": {}, "id": "1QOrCUVNOR9gpq0TCvSqKvw-v1-CW_LjvaKdZxj3riE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121puru", "is_robot_indexable": true, "report_reasons": null, "author": "Gymnastboatman", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121puru/dead_hdd_from_unraid_any_harm_in_taking_it_apart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/qjixqlh56ypa1", "subreddit_subscribers": 675282, "created_utc": 1679759142.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/qjixqlh56ypa1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/qjixqlh56ypa1/DASH_96.mp4", "dash_url": "https://v.redd.it/qjixqlh56ypa1/DASHPlaylist.mpd?a=1682391010%2CNzliNjljNzcwNjRhMDJkYjczZTRhNGE2MTE4MGZhOWYyNGRkNmY1MGZiYzc0YmNlNDI2ZGU5OTFkN2UwYTFiNg%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/qjixqlh56ypa1/HLSPlaylist.m3u8?a=1682391010%2CNjY2YWUwZWY2NTM4ZDJkY2UzM2NmZTA4ZjExYjVlMzQ4NzhkMzI4NmZhNGVmZmU4OWJmZDc2OTdkMTVmMzAwMQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I wanted to ask how y\u2019all transfer your main storage on your pc to a new drive? (500 GB SSD to 2TB SSD in my case) without failures or data loss? \nI have a 14TB external drive in storage, should I move the stuff from 500SSD there? \n\n\nHow do I move system files that aren\u2019t transferable by clicking and dragging? \n\nIdk how backups work technically- I\u2019m not sure if using my 14TB as a backup will wipe what\u2019s already on there.\n\nThanks in advance for any answers!", "author_fullname": "t2_4f7g5wsh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noobie scared of transferring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121bhjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679720956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wanted to ask how y\u2019all transfer your main storage on your pc to a new drive? (500 GB SSD to 2TB SSD in my case) without failures or data loss? \nI have a 14TB external drive in storage, should I move the stuff from 500SSD there? &lt;/p&gt;\n\n&lt;p&gt;How do I move system files that aren\u2019t transferable by clicking and dragging? &lt;/p&gt;\n\n&lt;p&gt;Idk how backups work technically- I\u2019m not sure if using my 14TB as a backup will wipe what\u2019s already on there.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any answers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121bhjq", "is_robot_indexable": true, "report_reasons": null, "author": "juneloner", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121bhjq/noobie_scared_of_transferring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121bhjq/noobie_scared_of_transferring/", "subreddit_subscribers": 675282, "created_utc": 1679720956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In light of the new IA court decision, I\u2019m wondering if its possible to locally save the entirety of a single website off of the Wayback Machine so that it\u2019ll be preserved if Wayback gets taken down. I don\u2019t want to save all of Wayback, just the snapshot of this one website thats hosted on it, since it\u2019s only available to access via the Wayback Machine. Any help is appreciated, I\u2019m not well versed in stuff like this.", "author_fullname": "t2_5jbs77k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Saving a website off of Wayback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121mea7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679752126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In light of the new IA court decision, I\u2019m wondering if its possible to locally save the entirety of a single website off of the Wayback Machine so that it\u2019ll be preserved if Wayback gets taken down. I don\u2019t want to save all of Wayback, just the snapshot of this one website thats hosted on it, since it\u2019s only available to access via the Wayback Machine. Any help is appreciated, I\u2019m not well versed in stuff like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121mea7", "is_robot_indexable": true, "report_reasons": null, "author": "fakepunkk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121mea7/saving_a_website_off_of_wayback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121mea7/saving_a_website_off_of_wayback/", "subreddit_subscribers": 675282, "created_utc": 1679752126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey y'all, \n\nI've been searching and searching but I can't seem to find something written in layman's terms talking about the differences and advantages of the Wayback Machine and/or [archive.today](https://archive.today).\n\nI'm a researcher, so really I'd just like to make sure that I'm using the best database to archive websites for future use by other researchers. As a music researcher, I'm usually just recording things like news articles and occasionally old blogs. I'm not super worried about re-downloading webpages or if the language is CSS or HTML, I'd mostly just like to make sure that text and images on websites are archived.\n\nSo far, I've been using the Wayback Machine, but should I make the switch?\n\nthanks!", "author_fullname": "t2_6k6lkegt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wayback Machine vs. Archive.today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121m0z4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679751273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching and searching but I can&amp;#39;t seem to find something written in layman&amp;#39;s terms talking about the differences and advantages of the Wayback Machine and/or &lt;a href=\"https://archive.today\"&gt;archive.today&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a researcher, so really I&amp;#39;d just like to make sure that I&amp;#39;m using the best database to archive websites for future use by other researchers. As a music researcher, I&amp;#39;m usually just recording things like news articles and occasionally old blogs. I&amp;#39;m not super worried about re-downloading webpages or if the language is CSS or HTML, I&amp;#39;d mostly just like to make sure that text and images on websites are archived.&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve been using the Wayback Machine, but should I make the switch?&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cMsDEjZcw1yJ2-Oox97YXjr_B80QoYA7KKKBUw8desk.jpg?auto=webp&amp;v=enabled&amp;s=70049ac5e4587eb732d86f2bf3c7f941a6314e91", "width": 144, "height": 144}, "resolutions": [{"url": "https://external-preview.redd.it/cMsDEjZcw1yJ2-Oox97YXjr_B80QoYA7KKKBUw8desk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81d09b8bf08f6c2e49210b8e709ad2fba21fef5", "width": 108, "height": 108}], "variants": {}, "id": "5WAXcyxu5qzeFIANl2gYNgI5-HT3q1BW7sA5zqtskZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121m0z4", "is_robot_indexable": true, "report_reasons": null, "author": "nicguynicecar", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121m0z4/wayback_machine_vs_archivetoday/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121m0z4/wayback_machine_vs_archivetoday/", "subreddit_subscribers": 675282, "created_utc": 1679751273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I used to download from z-library before the shutdown. However, since they came back I am unable to find how to download the books. Do I just have too much brain fog? I've signed up but don't see a way to access the titles. Can someone guide me through the steps like I'm not very bright? (which is the reality, lol). Sorry if it's too silly!", "author_fullname": "t2_6evlg7ee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading from z-library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1224gjt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679789509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I used to download from z-library before the shutdown. However, since they came back I am unable to find how to download the books. Do I just have too much brain fog? I&amp;#39;ve signed up but don&amp;#39;t see a way to access the titles. Can someone guide me through the steps like I&amp;#39;m not very bright? (which is the reality, lol). Sorry if it&amp;#39;s too silly!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1224gjt", "is_robot_indexable": true, "report_reasons": null, "author": "aeritia", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1224gjt/downloading_from_zlibrary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1224gjt/downloading_from_zlibrary/", "subreddit_subscribers": 675282, "created_utc": 1679789509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Soooo, just joined the NAS 96TB club. Dumped about 17 drives and 10 years of photography into it.  \n\nNow to sort. I've gone through all the threads about duplicates, but no one has talked about keeping all the variations of an image, just the highest quality of each.\n\nNote: the programs that I've tried just say it's the \"newer\" version and want to write over it, re: Beyond Compare. \n\nIf you're familiar with photography, it's the same image, just various edits exported through lightroom.\n\nIs there a program capable of this?", "author_fullname": "t2_4vd01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deleting duplicates without deleting imperceptibly minor edits?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12179bt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679710379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Soooo, just joined the NAS 96TB club. Dumped about 17 drives and 10 years of photography into it.  &lt;/p&gt;\n\n&lt;p&gt;Now to sort. I&amp;#39;ve gone through all the threads about duplicates, but no one has talked about keeping all the variations of an image, just the highest quality of each.&lt;/p&gt;\n\n&lt;p&gt;Note: the programs that I&amp;#39;ve tried just say it&amp;#39;s the &amp;quot;newer&amp;quot; version and want to write over it, re: Beyond Compare. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re familiar with photography, it&amp;#39;s the same image, just various edits exported through lightroom.&lt;/p&gt;\n\n&lt;p&gt;Is there a program capable of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12179bt", "is_robot_indexable": true, "report_reasons": null, "author": "UABSamurai", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12179bt/deleting_duplicates_without_deleting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12179bt/deleting_duplicates_without_deleting/", "subreddit_subscribers": 675282, "created_utc": 1679710379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 1U Dell Poweredge R630, completely chock full of 1.92TB enterprise ssd's, it runs proxmox and really... it does everything I need it to. It's my home router, I have some hosted applications on it, I've done home IT experiments on it, pretty much whatever. It's my \"do it all box\" I'm happy with it, apart from using it for mass storage.\n\nI have an ancient 4 bay Seagate NAS that I desperately need to get rid of. Really I'd like to replace it with a simple VM, running Linux/ZFS. But to do this I need to attach drives to the 1U server /somehow/\n\nThis led me down the roads of JBOD enclosures, especially since these days ZFS exists which is awesome in case your server dies... get another one and just run \"zfs import &lt;poolname&gt;\" and you're good.\n\nBut most of these seem to hold a lot of drives, and really... 4-8 is enough for me considering I have 2TB drives in the 4-bay NAS at the moment.\n\nIs there something smaller/low cost I could just stick on top of the 1U server and plug it in to an external SAS card? (I feel like that's best... USB seems wrong to me for this use case).   \n\n\nAlso... any way to salvage my old NAS? Just use the bays and directly wire the drives to an external SAS card? \n\nSidenote: I usually only buy used hardware. So feel free to suggest literally anything LOL Cost efficiency is a big consideration, and simple hardware seems to last a while, so I really don't care about buying used.\n\nSidenote 2: Yeah I could get another server, but I feel like just attaching a JBOD enclosure to the existing one is more power efficient. The R630 has dual Xeon E5-2697v3's so it's got plenty of horsepower... too much actually", "author_fullname": "t2_gatwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a a smallish external JBOD enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121pik4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679758396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 1U Dell Poweredge R630, completely chock full of 1.92TB enterprise ssd&amp;#39;s, it runs proxmox and really... it does everything I need it to. It&amp;#39;s my home router, I have some hosted applications on it, I&amp;#39;ve done home IT experiments on it, pretty much whatever. It&amp;#39;s my &amp;quot;do it all box&amp;quot; I&amp;#39;m happy with it, apart from using it for mass storage.&lt;/p&gt;\n\n&lt;p&gt;I have an ancient 4 bay Seagate NAS that I desperately need to get rid of. Really I&amp;#39;d like to replace it with a simple VM, running Linux/ZFS. But to do this I need to attach drives to the 1U server /somehow/&lt;/p&gt;\n\n&lt;p&gt;This led me down the roads of JBOD enclosures, especially since these days ZFS exists which is awesome in case your server dies... get another one and just run &amp;quot;zfs import &amp;lt;poolname&amp;gt;&amp;quot; and you&amp;#39;re good.&lt;/p&gt;\n\n&lt;p&gt;But most of these seem to hold a lot of drives, and really... 4-8 is enough for me considering I have 2TB drives in the 4-bay NAS at the moment.&lt;/p&gt;\n\n&lt;p&gt;Is there something smaller/low cost I could just stick on top of the 1U server and plug it in to an external SAS card? (I feel like that&amp;#39;s best... USB seems wrong to me for this use case).   &lt;/p&gt;\n\n&lt;p&gt;Also... any way to salvage my old NAS? Just use the bays and directly wire the drives to an external SAS card? &lt;/p&gt;\n\n&lt;p&gt;Sidenote: I usually only buy used hardware. So feel free to suggest literally anything LOL Cost efficiency is a big consideration, and simple hardware seems to last a while, so I really don&amp;#39;t care about buying used.&lt;/p&gt;\n\n&lt;p&gt;Sidenote 2: Yeah I could get another server, but I feel like just attaching a JBOD enclosure to the existing one is more power efficient. The R630 has dual Xeon E5-2697v3&amp;#39;s so it&amp;#39;s got plenty of horsepower... too much actually&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121pik4", "is_robot_indexable": true, "report_reasons": null, "author": "bcredeur97", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121pik4/looking_for_a_a_smallish_external_jbod_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121pik4/looking_for_a_a_smallish_external_jbod_enclosure/", "subreddit_subscribers": 675282, "created_utc": 1679758396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody,\n\nI have a LaCie D2 Quadra that came with a 2tb hard drive inside. I recently got a 6tb wd red hard drive that I wanted to replace the 2tb with. The problem is only 1.5tb is being recognized when plugging it into my computer. \n\nI\u2019ve tried multiple operating systems, and formatting the drive in multiple formats.\n\nThe problem is definitely with the LaCie because of I plug the drive directly into my computer it shows 6tb.\n\nIf I bought a 2tb LaCie, will it work with 6tb with replacing the drive?", "author_fullname": "t2_5clepggb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LaCie D2 Quadra Media only showing 1.5TB for 6TB drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121p8k8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679757788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody,&lt;/p&gt;\n\n&lt;p&gt;I have a LaCie D2 Quadra that came with a 2tb hard drive inside. I recently got a 6tb wd red hard drive that I wanted to replace the 2tb with. The problem is only 1.5tb is being recognized when plugging it into my computer. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve tried multiple operating systems, and formatting the drive in multiple formats.&lt;/p&gt;\n\n&lt;p&gt;The problem is definitely with the LaCie because of I plug the drive directly into my computer it shows 6tb.&lt;/p&gt;\n\n&lt;p&gt;If I bought a 2tb LaCie, will it work with 6tb with replacing the drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121p8k8", "is_robot_indexable": true, "report_reasons": null, "author": "franco84732", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121p8k8/lacie_d2_quadra_media_only_showing_15tb_for_6tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121p8k8/lacie_d2_quadra_media_only_showing_15tb_for_6tb/", "subreddit_subscribers": 675282, "created_utc": 1679757788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings All - I am trying to start on scanning some works (old anime artbooks, interviews, production materials, etc) and have been having real trouble achieving 'archive' quality. I have access through the uni I work at to good overhead scanners (can hit 400 DPI, not ideal ofc but certainly fine) for non-destructive scanning, which you would need to preserve artbooks at any quality that is worth it. But its the finnicky mechanics that are really tripping me - keeping a page flat on the scanner without having fingers in the scan, not having weird light bands on the page, etc. My most frustrating moment was using binder clips to keep the pages pinned, and the metal of the binding caused refraction lines along the whole page, ugh!\n\nThese should in some way be solveable issues, so I thought I would post. Googling doesn't give you too many tips, I have searched including this community and only found a post or two. I have seen the idea of a glass sheet you could put over the page that would flatten but not interfere with the scan, but not where to obtain one. I feel like \"book pinning rigs\" should exist but nothing comes up. I may bite the bullet resort to destructive scanning if I can't find answer, but I thought I would ask and see what ideas people who do this have - surely this is a 'solved problem'?", "author_fullname": "t2_h8cfb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on Mechanics of Scanning Books w/ Academic Library Overhead Scanner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121p79c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679757711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings All - I am trying to start on scanning some works (old anime artbooks, interviews, production materials, etc) and have been having real trouble achieving &amp;#39;archive&amp;#39; quality. I have access through the uni I work at to good overhead scanners (can hit 400 DPI, not ideal ofc but certainly fine) for non-destructive scanning, which you would need to preserve artbooks at any quality that is worth it. But its the finnicky mechanics that are really tripping me - keeping a page flat on the scanner without having fingers in the scan, not having weird light bands on the page, etc. My most frustrating moment was using binder clips to keep the pages pinned, and the metal of the binding caused refraction lines along the whole page, ugh!&lt;/p&gt;\n\n&lt;p&gt;These should in some way be solveable issues, so I thought I would post. Googling doesn&amp;#39;t give you too many tips, I have searched including this community and only found a post or two. I have seen the idea of a glass sheet you could put over the page that would flatten but not interfere with the scan, but not where to obtain one. I feel like &amp;quot;book pinning rigs&amp;quot; should exist but nothing comes up. I may bite the bullet resort to destructive scanning if I can&amp;#39;t find answer, but I thought I would ask and see what ideas people who do this have - surely this is a &amp;#39;solved problem&amp;#39;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121p79c", "is_robot_indexable": true, "report_reasons": null, "author": "Memes_Of_Production", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121p79c/help_on_mechanics_of_scanning_books_w_academic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121p79c/help_on_mechanics_of_scanning_books_w_academic/", "subreddit_subscribers": 675282, "created_utc": 1679757711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For a single drive, is there any point in writing multiple duplicated versions of the same files to the drive?\n\nMy heuristics tells me that in the case of bit rot or bad sectors surely not all sectors are going to be affected. If you have multiple versions of, say a Word document, you will have a higher chance of finding a version that is not corrupted, right?", "author_fullname": "t2_whddz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filling a drive with duplicates to protect against bit rot and drive failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121glkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679736610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a single drive, is there any point in writing multiple duplicated versions of the same files to the drive?&lt;/p&gt;\n\n&lt;p&gt;My heuristics tells me that in the case of bit rot or bad sectors surely not all sectors are going to be affected. If you have multiple versions of, say a Word document, you will have a higher chance of finding a version that is not corrupted, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121glkm", "is_robot_indexable": true, "report_reasons": null, "author": "--Arete", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121glkm/filling_a_drive_with_duplicates_to_protect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121glkm/filling_a_drive_with_duplicates_to_protect/", "subreddit_subscribers": 675282, "created_utc": 1679736610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi guys, i'm torn between getting a desktop hd or an ssd or a NAS.\n\nany recommendations for data storage that goes up to 10+ years for time machine backups + photos and videos? \n\ni'm a videographer looking to have a permanent backup drive for all my files. i have some external hdds + ssds but those are starting to get full. don't wanna keep purchasing them if i need more storage lol. thank you!", "author_fullname": "t2_bsg2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused on what's best to get for permanent data backup :(", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121fs8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679733917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi guys, i&amp;#39;m torn between getting a desktop hd or an ssd or a NAS.&lt;/p&gt;\n\n&lt;p&gt;any recommendations for data storage that goes up to 10+ years for time machine backups + photos and videos? &lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m a videographer looking to have a permanent backup drive for all my files. i have some external hdds + ssds but those are starting to get full. don&amp;#39;t wanna keep purchasing them if i need more storage lol. thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121fs8l", "is_robot_indexable": true, "report_reasons": null, "author": "tujuh777", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121fs8l/confused_on_whats_best_to_get_for_permanent_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121fs8l/confused_on_whats_best_to_get_for_permanent_data/", "subreddit_subscribers": 675282, "created_utc": 1679733917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone\n\nFor people using Google Drive, how are you all using it?\n\nI use rclone. To work around the 750GB upload limit, the way I've been working around is with service accounts. \n\nI created all of them. Then I created a group with the emails. I then create a new shared drive and add the group email.\n\nMy workflow is to get my stuff organized locally. I then copy my data via rclone to a crypt remote that points to a shared drive. My only issue with using shared drives is that there's a limit to the files it holds.\n\nI've thought of copying from shared drive to my drive, but not sure if it's being done by my user, if the 750GB daily limit applies (have to check unless someone else can tell me).\n\nMy other part is that I mount my shared drives as read only so that I can work on my files locally. If the download limit is hit, I can just rotate to another service account.\n\nNo idea if service accounts can be used to upload to my drive.\n\nAnyway, what are you all doing with google drive? How do you all manage things?", "author_fullname": "t2_5h10m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive organization and workflow. Shared Drives, SA's, multiple users, etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1225krb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679791995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone&lt;/p&gt;\n\n&lt;p&gt;For people using Google Drive, how are you all using it?&lt;/p&gt;\n\n&lt;p&gt;I use rclone. To work around the 750GB upload limit, the way I&amp;#39;ve been working around is with service accounts. &lt;/p&gt;\n\n&lt;p&gt;I created all of them. Then I created a group with the emails. I then create a new shared drive and add the group email.&lt;/p&gt;\n\n&lt;p&gt;My workflow is to get my stuff organized locally. I then copy my data via rclone to a crypt remote that points to a shared drive. My only issue with using shared drives is that there&amp;#39;s a limit to the files it holds.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve thought of copying from shared drive to my drive, but not sure if it&amp;#39;s being done by my user, if the 750GB daily limit applies (have to check unless someone else can tell me).&lt;/p&gt;\n\n&lt;p&gt;My other part is that I mount my shared drives as read only so that I can work on my files locally. If the download limit is hit, I can just rotate to another service account.&lt;/p&gt;\n\n&lt;p&gt;No idea if service accounts can be used to upload to my drive.&lt;/p&gt;\n\n&lt;p&gt;Anyway, what are you all doing with google drive? How do you all manage things?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "\u224827TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1225krb", "is_robot_indexable": true, "report_reasons": null, "author": "mrcaptncrunch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1225krb/google_drive_organization_and_workflow_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1225krb/google_drive_organization_and_workflow_shared/", "subreddit_subscribers": 675282, "created_utc": 1679791995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wanna start with ik i was stupid and uneducated. Now I found a good local deal on 3 sea gate exos 8tb sas drives for $30 each, I\u2019ve never dealt with sas before but I know you need a seperate controller so I went on eBay and bought a sas HBA, a LSI SAS 9200-8I, I assumed that a sas HBA would come with sas cables but this was not the case, so what do I need to do to hook up my drives, I can\u2019t really figure it out with google as I\u2019m getting confusing results and either I\u2019m asking the wrong question or I\u2019m the only stupid one out there. I found like a \u201cSata to sas\u201d physical adapter that in my mind would work, but then there are also some cables from the port on the card to a sas break out. Any help would be appreciated, and a link for purchase would also be apriciated if that\u2019s the solution, also keep in mind I would rather have a little jank than buy something stupid expensive.", "author_fullname": "t2_2l8s5g1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete noob, how to connect SAS drives to an HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121wd4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679772431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanna start with ik i was stupid and uneducated. Now I found a good local deal on 3 sea gate exos 8tb sas drives for $30 each, I\u2019ve never dealt with sas before but I know you need a seperate controller so I went on eBay and bought a sas HBA, a LSI SAS 9200-8I, I assumed that a sas HBA would come with sas cables but this was not the case, so what do I need to do to hook up my drives, I can\u2019t really figure it out with google as I\u2019m getting confusing results and either I\u2019m asking the wrong question or I\u2019m the only stupid one out there. I found like a \u201cSata to sas\u201d physical adapter that in my mind would work, but then there are also some cables from the port on the card to a sas break out. Any help would be appreciated, and a link for purchase would also be apriciated if that\u2019s the solution, also keep in mind I would rather have a little jank than buy something stupid expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121wd4t", "is_robot_indexable": true, "report_reasons": null, "author": "Ripnicyv", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121wd4t/complete_noob_how_to_connect_sas_drives_to_an_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121wd4t/complete_noob_how_to_connect_sas_drives_to_an_hba/", "subreddit_subscribers": 675282, "created_utc": 1679772431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if this is the right place to ask this or not but I have something weird going on with my RAID setup.  I\u2019m on Mac OS and I have four disks setup as JBOD.  It works fine except for when I restart.  When that happens, three of the disks in the RAID are missing/corrupt, but when I completely shut down the machine and turn it back on it works just fine.  Does anyone have any ideas why this might be?  Thanks!", "author_fullname": "t2_4mnuju67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121pb1v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679757938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right place to ask this or not but I have something weird going on with my RAID setup.  I\u2019m on Mac OS and I have four disks setup as JBOD.  It works fine except for when I restart.  When that happens, three of the disks in the RAID are missing/corrupt, but when I completely shut down the machine and turn it back on it works just fine.  Does anyone have any ideas why this might be?  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121pb1v", "is_robot_indexable": true, "report_reasons": null, "author": "ward_travis07", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121pb1v/raid_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121pb1v/raid_question/", "subreddit_subscribers": 675282, "created_utc": 1679757938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been trying to figure this out for a couple of days now, and I wanted to see if anyone on here has any advice. I have a collection of games on itch.io that I want to archive the devlogs for. The problem is that I only want a section of a page to be downloaded, so no comments section below the post, or other parts of the website. Now obviously I can do this by hand, problem is I'm talking about around 1000 games, each with who knows how many devlogs, so anything I can do to speed up the process would be really helpful. I've been able to find the section I want to download with the inspect tool, but that's as far as my limited knowledge can get me. If anyone knows any tools or scripts that could help me, it would be much appreciated. Thank you so much.\n\nHere is an example of a devlog page so you can see what I mean - https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now", "author_fullname": "t2_ciglcn3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically downloading only specific sections of website as a pdf?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121fr76", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679733823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to figure this out for a couple of days now, and I wanted to see if anyone on here has any advice. I have a collection of games on itch.io that I want to archive the devlogs for. The problem is that I only want a section of a page to be downloaded, so no comments section below the post, or other parts of the website. Now obviously I can do this by hand, problem is I&amp;#39;m talking about around 1000 games, each with who knows how many devlogs, so anything I can do to speed up the process would be really helpful. I&amp;#39;ve been able to find the section I want to download with the inspect tool, but that&amp;#39;s as far as my limited knowledge can get me. If anyone knows any tools or scripts that could help me, it would be much appreciated. Thank you so much.&lt;/p&gt;\n\n&lt;p&gt;Here is an example of a devlog page so you can see what I mean - &lt;a href=\"https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now\"&gt;https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?auto=webp&amp;v=enabled&amp;s=79877c8a54f6df80ac24693492241a4605cea412", "width": 822, "height": 618}, "resolutions": [{"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7a9729310b232847fedd6134f72722335ef8ad8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33f00c72cf83df5764e8588cb397203ecabdfe71", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d10eae4aa5f724b510d8eabff5ec39866e7f24fd", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51045ff1f318feaeb7bb2618d9c7e90cc61fb713", "width": 640, "height": 481}], "variants": {}, "id": "S2yIyabmqY8JphdEv5Him23A3z_iYFiPUT5XuSsvrpM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121fr76", "is_robot_indexable": true, "report_reasons": null, "author": "ImRikun", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121fr76/automatically_downloading_only_specific_sections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121fr76/automatically_downloading_only_specific_sections/", "subreddit_subscribers": 675282, "created_utc": 1679733823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased a new HDD and apparently these larger format drives have a different hole pattern and they don't fit my drive rail attachments. I bought new ones that I thought would fit but they didn't.\nI am not sure what to even search for to find ones that fit. Any help would be much appreciated.", "author_fullname": "t2_6376g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At my wit's end. Tooless drive rail attachment that will fit the hole pattern for my 14TB WD Red?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12252sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679790871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased a new HDD and apparently these larger format drives have a different hole pattern and they don&amp;#39;t fit my drive rail attachments. I bought new ones that I thought would fit but they didn&amp;#39;t.\nI am not sure what to even search for to find ones that fit. Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12252sv", "is_robot_indexable": true, "report_reasons": null, "author": "ricker182", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12252sv/at_my_wits_end_tooless_drive_rail_attachment_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12252sv/at_my_wits_end_tooless_drive_rail_attachment_that/", "subreddit_subscribers": 675282, "created_utc": 1679790871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a good tool that can scan media files (anything from mp4, mkv, avi, jpg, etc) to tell if the file is corrupted? I'd like to do a scrub of my collection and see if anything needs replacement. I figure on structured data like this, even if you don't have a checksummed filesystem, the file contents themselves should be able to indicate if the data is properly intact.\n\nI've moved a media collection around a lot over the years - backed up, restored, moved to the cloud, moved back, saved from a dying RAID, etc. Pretty sure 99% is intact, but would be good to know what/if anything needs to be replaced.", "author_fullname": "t2_35b7wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good tool for detecting media corruption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1220zk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679782172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a good tool that can scan media files (anything from mp4, mkv, avi, jpg, etc) to tell if the file is corrupted? I&amp;#39;d like to do a scrub of my collection and see if anything needs replacement. I figure on structured data like this, even if you don&amp;#39;t have a checksummed filesystem, the file contents themselves should be able to indicate if the data is properly intact.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved a media collection around a lot over the years - backed up, restored, moved to the cloud, moved back, saved from a dying RAID, etc. Pretty sure 99% is intact, but would be good to know what/if anything needs to be replaced.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "158TB (7x10TB+11x8TB)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1220zk4", "is_robot_indexable": true, "report_reasons": null, "author": "diamondsw", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1220zk4/good_tool_for_detecting_media_corruption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1220zk4/good_tool_for_detecting_media_corruption/", "subreddit_subscribers": 675282, "created_utc": 1679782172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3qy6a9q0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me make up my mind. Should I buy Western Digital Ultrastar 18TB 7200 RPM SAS 12Gb/s 3.5in Recertified Hard Drive. Would you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_121leiy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jx5mKxGOe0p63vBEZ-2QXQva9ua9ezjAzo9IHzia19k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679749809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serverpartdeals.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serverpartdeals.com/collections/wd-ultrastar-sas-hard-drives/products/western-digital-ultrastar-dc-hc550-wuh721818al4204-0f38303-18tb-7200-rpm-sas-12gb-s-3-5-recertified-hard-drive", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?auto=webp&amp;v=enabled&amp;s=2a63b8f579a8915184929b2bf51529eb551f8988", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b266cef6413a35690ece208383b940898890ba8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c98802eef8f3ce10500444212341e2b98115d9b0", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=858ca155cb76e5ed8181028acaf66740ad2e3eb6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=500cd0da37e94780d66e528812b7eb5a2b4f83b8", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0044812aed387f19d6f79b2549f4fead03ed1074", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/sa7dLXZ0X5gYuLaLGaW1wcgf-ANBAQFuloUW-vra5T8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6eae30dea6ebd0640d8ac1e3269f806576c5a53", "width": 1080, "height": 1080}], "variants": {}, "id": "7rnMu6KMjbLjh1VoaEL4F2DnXem4IffuOItfyEZdUoU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121leiy", "is_robot_indexable": true, "report_reasons": null, "author": "Elliot9874", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121leiy/help_me_make_up_my_mind_should_i_buy_western/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serverpartdeals.com/collections/wd-ultrastar-sas-hard-drives/products/western-digital-ultrastar-dc-hc550-wuh721818al4204-0f38303-18tb-7200-rpm-sas-12gb-s-3-5-recertified-hard-drive", "subreddit_subscribers": 675282, "created_utc": 1679749809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I\u2019ll start off by saying I\u2019m brand new to this sub and don\u2019t even know if this is the right place to ask this so if theres a better place to ask or I\u2019m doing something wrong let me know. Anyways here\u2019s my question. I\u2019m a photographer and have been just keeping my files on SD cards and not reusing them. I\u2019ve decided to start storing them on my computer instead so I can invest in a really good SD card. So I\u2019m planning on buying 2 8tb hard drives (for now) and having one at each of my main locations I edit my photos at (different houses). I\u2019m wondering if I put one in each of these PC\u2019s if there\u2019s any way to sync the data between the two so there basically backups of each other. Thanks in advance and lmk if there\u2019s any more details I can add about my question.", "author_fullname": "t2_7xmsjgu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about syncing hard drives from 2 locations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_12273hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679794859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I\u2019ll start off by saying I\u2019m brand new to this sub and don\u2019t even know if this is the right place to ask this so if theres a better place to ask or I\u2019m doing something wrong let me know. Anyways here\u2019s my question. I\u2019m a photographer and have been just keeping my files on SD cards and not reusing them. I\u2019ve decided to start storing them on my computer instead so I can invest in a really good SD card. So I\u2019m planning on buying 2 8tb hard drives (for now) and having one at each of my main locations I edit my photos at (different houses). I\u2019m wondering if I put one in each of these PC\u2019s if there\u2019s any way to sync the data between the two so there basically backups of each other. Thanks in advance and lmk if there\u2019s any more details I can add about my question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12273hx", "is_robot_indexable": true, "report_reasons": null, "author": "matrix11223", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12273hx/question_about_syncing_hard_drives_from_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12273hx/question_about_syncing_hard_drives_from_2/", "subreddit_subscribers": 675282, "created_utc": 1679794859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "for example, lets say theres a picture called in directory /food/bar/cat.png\n\nbut this image also exists in\n\n/foo/bar/dogs/cat2.png\n\ncat.png and cat2.png are the only files, and cat2 is a duplicate.\n\nWhen I run Czkawka, will it show be only cat2 or both cat and cat2 which I will need to manually decide what I want to keep.\n\nI have 1.46Tb of found duplicates....", "author_fullname": "t2_bn6e3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does Czkawka inclusively show me every file that has a duplicate, or only the duplicates of that file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1226t51", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679794183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;for example, lets say theres a picture called in directory /food/bar/cat.png&lt;/p&gt;\n\n&lt;p&gt;but this image also exists in&lt;/p&gt;\n\n&lt;p&gt;/foo/bar/dogs/cat2.png&lt;/p&gt;\n\n&lt;p&gt;cat.png and cat2.png are the only files, and cat2 is a duplicate.&lt;/p&gt;\n\n&lt;p&gt;When I run Czkawka, will it show be only cat2 or both cat and cat2 which I will need to manually decide what I want to keep.&lt;/p&gt;\n\n&lt;p&gt;I have 1.46Tb of found duplicates....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1226t51", "is_robot_indexable": true, "report_reasons": null, "author": "InadequateUsername", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1226t51/does_czkawka_inclusively_show_me_every_file_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1226t51/does_czkawka_inclusively_show_me_every_file_that/", "subreddit_subscribers": 675282, "created_utc": 1679794183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there. After seeing a few of my favorite YouTube videos get deleted, and after seeing games like TF2 and TF2 being abandoned by their host companies (even when still somewhat popular) I have lost a bit of faith in the public cloud/service model.\n\nI was wondering if you guys recommended a certain brand of NAS, and an alternative format for long term archival storage of video and text files. Right now I'm thinking that four terabyte capacity stored across 3-4 drives in a RAID would be good. Do you guys have suggestions for machines or brands off the top of your head? I'm  right now looking at synology NAS's on amazon.\n\nI also saw another post that recommended storing blu-rays in a bank deposit box as a form of off-site storage. I wanted to get a second opinion here though to see if that would be a good course of action.", "author_fullname": "t2_t7rjci3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on home NAS, brand &amp; alternative format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1225hr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679791808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there. After seeing a few of my favorite YouTube videos get deleted, and after seeing games like TF2 and TF2 being abandoned by their host companies (even when still somewhat popular) I have lost a bit of faith in the public cloud/service model.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if you guys recommended a certain brand of NAS, and an alternative format for long term archival storage of video and text files. Right now I&amp;#39;m thinking that four terabyte capacity stored across 3-4 drives in a RAID would be good. Do you guys have suggestions for machines or brands off the top of your head? I&amp;#39;m  right now looking at synology NAS&amp;#39;s on amazon.&lt;/p&gt;\n\n&lt;p&gt;I also saw another post that recommended storing blu-rays in a bank deposit box as a form of off-site storage. I wanted to get a second opinion here though to see if that would be a good course of action.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1225hr8", "is_robot_indexable": true, "report_reasons": null, "author": "DirkyLeSpowl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1225hr8/looking_for_advice_on_home_nas_brand_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1225hr8/looking_for_advice_on_home_nas_brand_alternative/", "subreddit_subscribers": 675282, "created_utc": 1679791808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow DataHoarders! \n\n&amp;#x200B;\n\nCurrently I have a \"multimedia sever\", a WinPC with a Dell Perc H310 (IT mode) that is connected to a DS4243 with 18 disks of different sizes (100Tb total approx). All disks are organized as a pool with StableBit DrivePool. That server is not in 24/7, I switch it on only when needed.\n\n&amp;#x200B;\n\nThen I have an \"XPenology\" server with 4 disks and finally another WinPC doing several stuff, including a VirtualBox VM with Debian for HomeAssitant.\n\n&amp;#x200B;\n\nRecently I was able to buy a Dell R720 (2 x 2695v2 / 96Gb / 8xLFF no disks) with the idea to move all the OSs to Proxmox and migrate DrivePool to Unraid in a VM.\n\n&amp;#x200B;\n\nI was thinking to use the internal controller of R720, a H710 mini (also flashed to IT mode), to expose the 8xLFF disks to Proxmox to have a RAIDZ2 storage for the VMs.\n\n&amp;#x200B;\n\nBut I'm not sure how to move to Unraid. Is it possible to do a a passthrough of the H310 (the other HBA card I had) to a WinPC VM where I can have DrivePool, and also do a passthrough at the same time to antoher VM for Unraid? This way I can have 2 VMs that can see the disks on DS4243 and start moving the disks bit a bit (I have some extra disks that can help on this). \n\n&amp;#x200B;\n\nIf this is not possible which other alternatives I have to move from DrivePool to Unraid ?\n\n&amp;#x200B;\n\nAnother question is, once I have everything running under Proxmox/Unraid, will be feasible to switch on the Unraid VM and the DS4243 (through a smart plug from homeassistant) only when needed? Will the H310 passthrough work this way?\n\n&amp;#x200B;\n\nThank you very much in advance!", "author_fullname": "t2_2y98rrqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving from Frankenstein infra to a nice R720", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1224bse", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679789212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DataHoarders! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Currently I have a &amp;quot;multimedia sever&amp;quot;, a WinPC with a Dell Perc H310 (IT mode) that is connected to a DS4243 with 18 disks of different sizes (100Tb total approx). All disks are organized as a pool with StableBit DrivePool. That server is not in 24/7, I switch it on only when needed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Then I have an &amp;quot;XPenology&amp;quot; server with 4 disks and finally another WinPC doing several stuff, including a VirtualBox VM with Debian for HomeAssitant.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Recently I was able to buy a Dell R720 (2 x 2695v2 / 96Gb / 8xLFF no disks) with the idea to move all the OSs to Proxmox and migrate DrivePool to Unraid in a VM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was thinking to use the internal controller of R720, a H710 mini (also flashed to IT mode), to expose the 8xLFF disks to Proxmox to have a RAIDZ2 storage for the VMs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure how to move to Unraid. Is it possible to do a a passthrough of the H310 (the other HBA card I had) to a WinPC VM where I can have DrivePool, and also do a passthrough at the same time to antoher VM for Unraid? This way I can have 2 VMs that can see the disks on DS4243 and start moving the disks bit a bit (I have some extra disks that can help on this). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this is not possible which other alternatives I have to move from DrivePool to Unraid ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Another question is, once I have everything running under Proxmox/Unraid, will be feasible to switch on the Unraid VM and the DS4243 (through a smart plug from homeassistant) only when needed? Will the H310 passthrough work this way?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you very much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1224bse", "is_robot_indexable": true, "report_reasons": null, "author": "pilfos", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1224bse/moving_from_frankenstein_infra_to_a_nice_r720/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1224bse/moving_from_frankenstein_infra_to_a_nice_r720/", "subreddit_subscribers": 675282, "created_utc": 1679789212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We all know that the online cloud storage offerings are a huge rip off whether it's google, apple, Samsung or dropbox. 2TB for $120 a year? 4 years thats $480. I bought a 10TB Seagate storage for half of that price for 4 times the storage with no limit of who can connect to it, and God knows what those tech companies are doing with our stored data.\n\nNow the problem is how I can get all the devices of all my family to connect to it at any location. My computer and mobile devices automatically can find the storage when on the same wifi network, but when I'm at a coffee shop or on the go, I cannot access the storage.\n\nThere must be a way to setup a APN for the storage, but I don't know how, so that i can access my local seagate from anywhere with that URL. Anyone with experience with this would be greatly appreciated \n\nThanks", "author_fullname": "t2_70on99ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to setup URL for local storage so that family can access from any device at any location?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1223tq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679788164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We all know that the online cloud storage offerings are a huge rip off whether it&amp;#39;s google, apple, Samsung or dropbox. 2TB for $120 a year? 4 years thats $480. I bought a 10TB Seagate storage for half of that price for 4 times the storage with no limit of who can connect to it, and God knows what those tech companies are doing with our stored data.&lt;/p&gt;\n\n&lt;p&gt;Now the problem is how I can get all the devices of all my family to connect to it at any location. My computer and mobile devices automatically can find the storage when on the same wifi network, but when I&amp;#39;m at a coffee shop or on the go, I cannot access the storage.&lt;/p&gt;\n\n&lt;p&gt;There must be a way to setup a APN for the storage, but I don&amp;#39;t know how, so that i can access my local seagate from anywhere with that URL. Anyone with experience with this would be greatly appreciated &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1223tq7", "is_robot_indexable": true, "report_reasons": null, "author": "SnooMemesjellies7591", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1223tq7/how_to_setup_url_for_local_storage_so_that_family/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1223tq7/how_to_setup_url_for_local_storage_so_that_family/", "subreddit_subscribers": 675282, "created_utc": 1679788164.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}