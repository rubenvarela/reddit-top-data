{"kind": "Listing", "data": {"after": "t3_1222ttb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As we all know, this loss against the big publishers has IA appealing, with the risk that they could lose the appeals court too. While the fact that this lawsuit only applies to their books, the truly dangerous part is the legal ramifications IA has to pay if they happen to lose the war. Face it, if the amount of money owed to the publishers is beyond what IA can handle to keep their project running, to quote Numbuh 4, all their info will be \"J-A-W-N, GONE!\"\n\nBut in all seriousness, I was proposing that we backup every last bit of info they have on their site and build a new one in its place if IA does end up having to shut down. Or at the very least donate every last penny we can spare to make sure they have enough to keep going even if they do end up losing. Or will IA come back rebranded, rising from the ashes? I wanna find some way to spread hope, the fact that all isn't lost in spite of the potential legal ramifications.", "author_fullname": "t2_nyv7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preparing for the worst outcome for Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121uif6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 624, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 624, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679768678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we all know, this loss against the big publishers has IA appealing, with the risk that they could lose the appeals court too. While the fact that this lawsuit only applies to their books, the truly dangerous part is the legal ramifications IA has to pay if they happen to lose the war. Face it, if the amount of money owed to the publishers is beyond what IA can handle to keep their project running, to quote Numbuh 4, all their info will be &amp;quot;J-A-W-N, GONE!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;But in all seriousness, I was proposing that we backup every last bit of info they have on their site and build a new one in its place if IA does end up having to shut down. Or at the very least donate every last penny we can spare to make sure they have enough to keep going even if they do end up losing. Or will IA come back rebranded, rising from the ashes? I wanna find some way to spread hope, the fact that all isn&amp;#39;t lost in spite of the potential legal ramifications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "121uif6", "is_robot_indexable": true, "report_reasons": null, "author": "SuperFightingSaiyan", "discussion_type": null, "num_comments": 123, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121uif6/preparing_for_the_worst_outcome_for_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121uif6/preparing_for_the_worst_outcome_for_internet/", "subreddit_subscribers": 675459, "created_utc": 1679768678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2he9afpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After over 15 years of ripping and downloading, my music library just reached 20TB. AMA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "name": "t3_122j0f3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 757, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 757, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/RREjcQuvpRXMQsS54A8KQmAJvAYhMVti0_p_dIpEk50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679829327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/c03bk4cmg2qa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?auto=webp&amp;v=enabled&amp;s=8a4245d424da24ebf1350d7700fadb3680ea1398", "width": 374, "height": 130}, "resolutions": [{"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4c762107b1e86dd66adabe7e6e3a5e02bf6d27b", "width": 108, "height": 37}, {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=531da5001d077fbcc7abee4967b0d7e2679818d8", "width": 216, "height": 75}, {"url": "https://preview.redd.it/c03bk4cmg2qa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79d5dbb00f66d2d7bb1071060b303de3c1052736", "width": 320, "height": 111}], "variants": {}, "id": "ug80s_19BI1qle7GjGkuyxEhz2NmaVf8bMSSVoaYyKk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "122j0f3", "is_robot_indexable": true, "report_reasons": null, "author": "Casual_Tea_94", "discussion_type": null, "num_comments": 202, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122j0f3/after_over_15_years_of_ripping_and_downloading_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/c03bk4cmg2qa1.png", "subreddit_subscribers": 675459, "created_utc": 1679829327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone know how to automatically record from kick? I have tried to make a script that checks the status of kick and use yt-dlp to record but can\u2019t get it to work", "author_fullname": "t2_umg8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically record live streams from kick.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122czcs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679811233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679811001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone know how to automatically record from kick? I have tried to make a script that checks the status of kick and use yt-dlp to record but can\u2019t get it to work&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122czcs", "is_robot_indexable": true, "report_reasons": null, "author": "--Happy--", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122czcs/automatically_record_live_streams_from_kickcom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122czcs/automatically_record_live_streams_from_kickcom/", "subreddit_subscribers": 675459, "created_utc": 1679811001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I used to download from z-library before the shutdown. However, since they came back I am unable to find how to download the books. Do I just have too much brain fog? I've signed up but don't see a way to access the titles. Can someone guide me through the steps like I'm not very bright? (which is the reality, lol). Sorry if it's too silly!", "author_fullname": "t2_6evlg7ee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading from z-library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1224gjt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679789509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I used to download from z-library before the shutdown. However, since they came back I am unable to find how to download the books. Do I just have too much brain fog? I&amp;#39;ve signed up but don&amp;#39;t see a way to access the titles. Can someone guide me through the steps like I&amp;#39;m not very bright? (which is the reality, lol). Sorry if it&amp;#39;s too silly!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1224gjt", "is_robot_indexable": true, "report_reasons": null, "author": "aeritia", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1224gjt/downloading_from_zlibrary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1224gjt/downloading_from_zlibrary/", "subreddit_subscribers": 675459, "created_utc": 1679789509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've always wondered this.  If there's fine dust on a BD-R disc (which is fairly common) how come that doesn't prevent a disc from getting burned properly?  A pit on a BD-R disk is 150 nanometers so any dust that's visible is gonna be bigger.  Does burning the disc work purely because of the extra error correction data written to each sector on the disc?  A full sector is only about 1/3 of a millimeter (if my math is right) which isn't that much larger than some specs of dust.  I would think the dust would cover a large portion of a sector.  Or is the laser used to burn the disc able to shine through tiny specs of dust?  Anyone know?", "author_fullname": "t2_mgmtm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Come Dust Doesn't Prevent BD-R Burning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122avij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679804656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve always wondered this.  If there&amp;#39;s fine dust on a BD-R disc (which is fairly common) how come that doesn&amp;#39;t prevent a disc from getting burned properly?  A pit on a BD-R disk is 150 nanometers so any dust that&amp;#39;s visible is gonna be bigger.  Does burning the disc work purely because of the extra error correction data written to each sector on the disc?  A full sector is only about 1/3 of a millimeter (if my math is right) which isn&amp;#39;t that much larger than some specs of dust.  I would think the dust would cover a large portion of a sector.  Or is the laser used to burn the disc able to shine through tiny specs of dust?  Anyone know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "122avij", "is_robot_indexable": true, "report_reasons": null, "author": "HarryMuscle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122avij/how_come_dust_doesnt_prevent_bdr_burning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122avij/how_come_dust_doesnt_prevent_bdr_burning/", "subreddit_subscribers": 675459, "created_utc": 1679804656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found an old 2TB HDD that used to be in one of my laptops. It is detectable but stalls out on reads and has a large number of bad sectors in SMART. I am hoping to find somewhere with something like a rapidspar, or a similar byte-for-byte copy tool, to see if they can copy the data from the current drive onto an undamaged one. Anything more than that is probably not worth the cost. I dont know what is saved on the drive anymore. It is possible there is sensitive data on the drive because it is encrypted. It is also possible that all the important data on the drive was already backed up in the past and I forgot to physically mark the drive.\n\nIs there a way to search for reputable local data recovery services, or are things like yelp and google my best bets?", "author_fullname": "t2_qngs2dbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you find a reputable data recovery service?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122adr4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679803283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found an old 2TB HDD that used to be in one of my laptops. It is detectable but stalls out on reads and has a large number of bad sectors in SMART. I am hoping to find somewhere with something like a rapidspar, or a similar byte-for-byte copy tool, to see if they can copy the data from the current drive onto an undamaged one. Anything more than that is probably not worth the cost. I dont know what is saved on the drive anymore. It is possible there is sensitive data on the drive because it is encrypted. It is also possible that all the important data on the drive was already backed up in the past and I forgot to physically mark the drive.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to search for reputable local data recovery services, or are things like yelp and google my best bets?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122adr4", "is_robot_indexable": true, "report_reasons": null, "author": "ByteArchivist", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122adr4/how_do_you_find_a_reputable_data_recovery_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122adr4/how_do_you_find_a_reputable_data_recovery_service/", "subreddit_subscribers": 675459, "created_utc": 1679803283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased a new HDD and apparently these larger format drives have a different hole pattern and they don't fit my drive rail attachments. I bought new ones that I thought would fit but they didn't.\nI am not sure what to even search for to find ones that fit. Any help would be much appreciated.", "author_fullname": "t2_6376g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At my wit's end. Tooless drive rail attachment that will fit the hole pattern for my 14TB WD Red?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12252sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679790871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased a new HDD and apparently these larger format drives have a different hole pattern and they don&amp;#39;t fit my drive rail attachments. I bought new ones that I thought would fit but they didn&amp;#39;t.\nI am not sure what to even search for to find ones that fit. Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12252sv", "is_robot_indexable": true, "report_reasons": null, "author": "ricker182", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12252sv/at_my_wits_end_tooless_drive_rail_attachment_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12252sv/at_my_wits_end_tooless_drive_rail_attachment_that/", "subreddit_subscribers": 675459, "created_utc": 1679790871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Internally, there is a mix of IDE and SATA DVD-ROMs, with adapters to convert to USB3, and then all of those are plugged into an internal USB3 hub.  On the PC I used custom batch files to rip all of them simultaneously.\n\nhttps://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6484f235739eca66ba228a2352e3f355a138e120", "author_fullname": "t2_2ky1uaug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scratch build DVD ripping tower", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"so5thftgu2qa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39e5900a5d683306a54900c8fc4932cdb6fd449b"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca3661629420c96e728495cd569a160c016db481"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6350b4fee68696980ae535457f9f6516de843ed6"}, {"y": 458, "x": 640, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f000dc8a841fd9544d7ecfeb7986737f2a2ee91"}, {"y": 688, "x": 960, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=368897c31ee21cc01b113b74b278a6152c017fd0"}, {"y": 774, "x": 1080, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31cfc89c2a845b2d0244f0ba2818ac98f80fb06d"}], "s": {"y": 1376, "x": 1920, "u": "https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6484f235739eca66ba228a2352e3f355a138e120"}, "id": "so5thftgu2qa1"}}, "name": "t3_122kk8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NhiyryTK6wp5vpPSI7Cxd5EAMlSY-EPgHe2GyV58NF0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679833633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Internally, there is a mix of IDE and SATA DVD-ROMs, with adapters to convert to USB3, and then all of those are plugged into an internal USB3 hub.  On the PC I used custom batch files to rip all of them simultaneously.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6484f235739eca66ba228a2352e3f355a138e120\"&gt;https://preview.redd.it/so5thftgu2qa1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6484f235739eca66ba228a2352e3f355a138e120&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122kk8s", "is_robot_indexable": true, "report_reasons": null, "author": "LydianM", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122kk8s/scratch_build_dvd_ripping_tower/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122kk8s/scratch_build_dvd_ripping_tower/", "subreddit_subscribers": 675459, "created_utc": 1679833633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the process of copying some old floppies I've been having in my basement for way too long, and some of them are in pretty bad shape. I've done quite a few already, but wondering if there are any hints/tips for how to best do the job? Setup: Some old floppy drives and a Catweasel 3 PCI card I had lying around. (Expecting a Greaseweazle to arrive in a few days)\n\nExperiences so far:\n- Retrying sometimes \"cleans up\" the platter of disks after a few full sweeps and make them more readable. Not sure how bad that is for the read heads though.\n- Some disks are so dirty they make the drive unable to read from one head until cleaned. But some times the cleaning disk seems to make things worse?\n- Not sure if it's better to focus on volume of disks vs trying to do deeper recovery of each disk, retrying bad tracks hundreds of times in the hopes that it eventually works (And in a lot of cases, it does work...after a while)\n- If you have disks that you think about dumping, better do it sooner than later. These have only gotten worse as time has gone by.", "author_fullname": "t2_45osc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for transferring a ton of old/musty 3.5 inch floppies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122j5tm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679829758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of copying some old floppies I&amp;#39;ve been having in my basement for way too long, and some of them are in pretty bad shape. I&amp;#39;ve done quite a few already, but wondering if there are any hints/tips for how to best do the job? Setup: Some old floppy drives and a Catweasel 3 PCI card I had lying around. (Expecting a Greaseweazle to arrive in a few days)&lt;/p&gt;\n\n&lt;p&gt;Experiences so far:\n- Retrying sometimes &amp;quot;cleans up&amp;quot; the platter of disks after a few full sweeps and make them more readable. Not sure how bad that is for the read heads though.\n- Some disks are so dirty they make the drive unable to read from one head until cleaned. But some times the cleaning disk seems to make things worse?\n- Not sure if it&amp;#39;s better to focus on volume of disks vs trying to do deeper recovery of each disk, retrying bad tracks hundreds of times in the hopes that it eventually works (And in a lot of cases, it does work...after a while)\n- If you have disks that you think about dumping, better do it sooner than later. These have only gotten worse as time has gone by.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122j5tm", "is_robot_indexable": true, "report_reasons": null, "author": "ymgve", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122j5tm/best_practices_for_transferring_a_ton_of_oldmusty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122j5tm/best_practices_for_transferring_a_ton_of_oldmusty/", "subreddit_subscribers": 675459, "created_utc": 1679829758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm hoping to get some recommendations for an app that can help me with document archiving.\n\nI looking for something for personal uses something that will let me the ability to throw documents with the knowledge that they are backed up in a safe place and cut back on paper all around my home", "author_fullname": "t2_2pclqfn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on a document archiving app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122eqq3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679816441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hoping to get some recommendations for an app that can help me with document archiving.&lt;/p&gt;\n\n&lt;p&gt;I looking for something for personal uses something that will let me the ability to throw documents with the knowledge that they are backed up in a safe place and cut back on paper all around my home&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122eqq3", "is_robot_indexable": true, "report_reasons": null, "author": "AvgBlue", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122eqq3/seeking_advice_on_a_document_archiving_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122eqq3/seeking_advice_on_a_document_archiving_app/", "subreddit_subscribers": 675459, "created_utc": 1679816441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Per subject, just came across these and looking through the threads. \n\nFrom this thread at r/AskADataRecoveryPro [https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with\\_data\\_recovery\\_does\\_price\\_matter/](https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/)\n\n[https://www.datarecoveryprofessionals.org/](https://www.datarecoveryprofessionals.org/)", "author_fullname": "t2_7aj1lgdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just discovered: r/askadatarecoverypro and r/datarecovery for inquires about data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122bn0s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679806899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Per subject, just came across these and looking through the threads. &lt;/p&gt;\n\n&lt;p&gt;From this thread at &lt;a href=\"/r/AskADataRecoveryPro\"&gt;r/AskADataRecoveryPro&lt;/a&gt; &lt;a href=\"https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/\"&gt;https://www.reddit.com/r/AskADataRecoveryPro/comments/11cbd16/with_data_recovery_does_price_matter/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datarecoveryprofessionals.org/\"&gt;https://www.datarecoveryprofessionals.org/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122bn0s", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Marsupial6303", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122bn0s/just_discovered_raskadatarecoverypro_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122bn0s/just_discovered_raskadatarecoverypro_and/", "subreddit_subscribers": 675459, "created_utc": 1679806899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a good tool that can scan media files (anything from mp4, mkv, avi, jpg, etc) to tell if the file is corrupted? I'd like to do a scrub of my collection and see if anything needs replacement. I figure on structured data like this, even if you don't have a checksummed filesystem, the file contents themselves should be able to indicate if the data is properly intact.\n\nI've moved a media collection around a lot over the years - backed up, restored, moved to the cloud, moved back, saved from a dying RAID, etc. Pretty sure 99% is intact, but would be good to know what/if anything needs to be replaced.", "author_fullname": "t2_35b7wo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good tool for detecting media corruption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1220zk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679782172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a good tool that can scan media files (anything from mp4, mkv, avi, jpg, etc) to tell if the file is corrupted? I&amp;#39;d like to do a scrub of my collection and see if anything needs replacement. I figure on structured data like this, even if you don&amp;#39;t have a checksummed filesystem, the file contents themselves should be able to indicate if the data is properly intact.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve moved a media collection around a lot over the years - backed up, restored, moved to the cloud, moved back, saved from a dying RAID, etc. Pretty sure 99% is intact, but would be good to know what/if anything needs to be replaced.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "158TB (7x10TB+11x8TB)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1220zk4", "is_robot_indexable": true, "report_reasons": null, "author": "diamondsw", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1220zk4/good_tool_for_detecting_media_corruption/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1220zk4/good_tool_for_detecting_media_corruption/", "subreddit_subscribers": 675459, "created_utc": 1679782172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wanna start with ik i was stupid and uneducated. Now I found a good local deal on 3 sea gate exos 8tb sas drives for $30 each, I\u2019ve never dealt with sas before but I know you need a seperate controller so I went on eBay and bought a sas HBA, a LSI SAS 9200-8I, I assumed that a sas HBA would come with sas cables but this was not the case, so what do I need to do to hook up my drives, I can\u2019t really figure it out with google as I\u2019m getting confusing results and either I\u2019m asking the wrong question or I\u2019m the only stupid one out there. I found like a \u201cSata to sas\u201d physical adapter that in my mind would work, but then there are also some cables from the port on the card to a sas break out. Any help would be appreciated, and a link for purchase would also be apriciated if that\u2019s the solution, also keep in mind I would rather have a little jank than buy something stupid expensive.", "author_fullname": "t2_2l8s5g1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete noob, how to connect SAS drives to an HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121wd4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679772431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanna start with ik i was stupid and uneducated. Now I found a good local deal on 3 sea gate exos 8tb sas drives for $30 each, I\u2019ve never dealt with sas before but I know you need a seperate controller so I went on eBay and bought a sas HBA, a LSI SAS 9200-8I, I assumed that a sas HBA would come with sas cables but this was not the case, so what do I need to do to hook up my drives, I can\u2019t really figure it out with google as I\u2019m getting confusing results and either I\u2019m asking the wrong question or I\u2019m the only stupid one out there. I found like a \u201cSata to sas\u201d physical adapter that in my mind would work, but then there are also some cables from the port on the card to a sas break out. Any help would be appreciated, and a link for purchase would also be apriciated if that\u2019s the solution, also keep in mind I would rather have a little jank than buy something stupid expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121wd4t", "is_robot_indexable": true, "report_reasons": null, "author": "Ripnicyv", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121wd4t/complete_noob_how_to_connect_sas_drives_to_an_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121wd4t/complete_noob_how_to_connect_sas_drives_to_an_hba/", "subreddit_subscribers": 675459, "created_utc": 1679772431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks. With the possible results of the internet archive removing content, i decided to start saving the important things locally.\n\nI have two basic questions though. \n\n1. I read everywhere people using HDD's instead of SSD'S to save content. Is that only because they are cheaper or are they considered more reliable in the long run?\n\n2. I need some kind of software to search my saved content. The basic name search in not enough. Maybe i need to find something by category. Problem is, if i just use folders to organize things, i will need to have multiple copies of the same file to find it on different categories.\n\nBetter ideas for organizing content? \n\nThank you so much in advance!", "author_fullname": "t2_aqp4qsth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help a newbie start hoarding?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122hpoj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679825242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks. With the possible results of the internet archive removing content, i decided to start saving the important things locally.&lt;/p&gt;\n\n&lt;p&gt;I have two basic questions though. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I read everywhere people using HDD&amp;#39;s instead of SSD&amp;#39;S to save content. Is that only because they are cheaper or are they considered more reliable in the long run?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I need some kind of software to search my saved content. The basic name search in not enough. Maybe i need to find something by category. Problem is, if i just use folders to organize things, i will need to have multiple copies of the same file to find it on different categories.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Better ideas for organizing content? &lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122hpoj", "is_robot_indexable": true, "report_reasons": null, "author": "TheN1ght0w1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122hpoj/help_a_newbie_start_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122hpoj/help_a_newbie_start_hoarding/", "subreddit_subscribers": 675459, "created_utc": 1679825242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm a noob to Hoarding, but would like to join you all soon.\n\nBased on my limited research, it sounds like I should perhaps get a 5 x bay Synology NAS with 12tb-18tb WD Red Drives and arrange them in RAID-5.\n\nBut, I figured I'd run this by you all first.\n\nAny advice?\n\nI'm planning on using it as a media server and would need remote management access as well.\n\nBonus question: What are the most valuable things to hoard that most people aren't hoarding? Books? Wikipedia? DNS databases?", "author_fullname": "t2_7zift", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a budget of between $2,000-$2,500 what should I buy for maximizing my storage + hoarding capabilities with as little maintenance as possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122b7oy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679805647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a noob to Hoarding, but would like to join you all soon.&lt;/p&gt;\n\n&lt;p&gt;Based on my limited research, it sounds like I should perhaps get a 5 x bay Synology NAS with 12tb-18tb WD Red Drives and arrange them in RAID-5.&lt;/p&gt;\n\n&lt;p&gt;But, I figured I&amp;#39;d run this by you all first.&lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on using it as a media server and would need remote management access as well.&lt;/p&gt;\n\n&lt;p&gt;Bonus question: What are the most valuable things to hoard that most people aren&amp;#39;t hoarding? Books? Wikipedia? DNS databases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122b7oy", "is_robot_indexable": true, "report_reasons": null, "author": "aknalid", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122b7oy/with_a_budget_of_between_20002500_what_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122b7oy/with_a_budget_of_between_20002500_what_should_i/", "subreddit_subscribers": 675459, "created_utc": 1679805647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We all know that the online cloud storage offerings are a huge rip off whether it's google, apple, Samsung or dropbox. 2TB for $120 a year? 4 years thats $480. I bought a 10TB Seagate storage for half of that price for 4 times the storage with no limit of who can connect to it, and God knows what those tech companies are doing with our stored data.\n\nNow the problem is how I can get all the devices of all my family to connect to it at any location. My computer and mobile devices automatically can find the storage when on the same wifi network, but when I'm at a coffee shop or on the go, I cannot access the storage.\n\nThere must be a way to setup a APN for the storage, but I don't know how, so that i can access my local seagate from anywhere with that URL. Anyone with experience with this would be greatly appreciated \n\nThanks", "author_fullname": "t2_70on99ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to setup URL for local storage so that family can access from any device at any location?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1223tq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679788164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We all know that the online cloud storage offerings are a huge rip off whether it&amp;#39;s google, apple, Samsung or dropbox. 2TB for $120 a year? 4 years thats $480. I bought a 10TB Seagate storage for half of that price for 4 times the storage with no limit of who can connect to it, and God knows what those tech companies are doing with our stored data.&lt;/p&gt;\n\n&lt;p&gt;Now the problem is how I can get all the devices of all my family to connect to it at any location. My computer and mobile devices automatically can find the storage when on the same wifi network, but when I&amp;#39;m at a coffee shop or on the go, I cannot access the storage.&lt;/p&gt;\n\n&lt;p&gt;There must be a way to setup a APN for the storage, but I don&amp;#39;t know how, so that i can access my local seagate from anywhere with that URL. Anyone with experience with this would be greatly appreciated &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1223tq7", "is_robot_indexable": true, "report_reasons": null, "author": "SnooMemesjellies7591", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1223tq7/how_to_setup_url_for_local_storage_so_that_family/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1223tq7/how_to_setup_url_for_local_storage_so_that_family/", "subreddit_subscribers": 675459, "created_utc": 1679788164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a large set of files (A little over 50GB) on my google drive. I need to transfer them to my OneDrive. Is there any way to do this without downloading the files and then uploading them again?", "author_fullname": "t2_vat9aqvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferring large files from google drive to OneDrive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121r6gr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679762025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large set of files (A little over 50GB) on my google drive. I need to transfer them to my OneDrive. Is there any way to do this without downloading the files and then uploading them again?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121r6gr", "is_robot_indexable": true, "report_reasons": null, "author": "PlayfulCobbler1497", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121r6gr/transferring_large_files_from_google_drive_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121r6gr/transferring_large_files_from_google_drive_to/", "subreddit_subscribers": 675459, "created_utc": 1679762025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My dad recently made an acrylic flat rectangle panel for me to screw my HDD on it, and screw the acrylic on the too of the HDD cage. But will this DIY acrylic panel HDD mount cause vibration and damage my hdd?", "author_fullname": "t2_8siy7ss6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for PC with one HDD cage while doing 4 drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122hut7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679825716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My dad recently made an acrylic flat rectangle panel for me to screw my HDD on it, and screw the acrylic on the too of the HDD cage. But will this DIY acrylic panel HDD mount cause vibration and damage my hdd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122hut7", "is_robot_indexable": true, "report_reasons": null, "author": "SciencioGT", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122hut7/advice_for_pc_with_one_hdd_cage_while_doing_4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122hut7/advice_for_pc_with_one_hdd_cage_while_doing_4/", "subreddit_subscribers": 675459, "created_utc": 1679825716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an HDD that I am backup-ing with AOMEI back upper I am leaving soon but I need to copy 2 TB of data to 2 different SSD from an 8TB HDD\n\nso let's say HDD 1 is backup-ing to HDD 2 \n\nand HDD 3 is copying to SSD 1 and SSD 2 \n\nthe question is\n\n will HDD 1 &amp; 2 activity affect HDD 3 copy speed?\n\nand will it be better to copy both SSD at once or one by one", "author_fullname": "t2_727v9dea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copying situation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122dwhc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679813851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an HDD that I am backup-ing with AOMEI back upper I am leaving soon but I need to copy 2 TB of data to 2 different SSD from an 8TB HDD&lt;/p&gt;\n\n&lt;p&gt;so let&amp;#39;s say HDD 1 is backup-ing to HDD 2 &lt;/p&gt;\n\n&lt;p&gt;and HDD 3 is copying to SSD 1 and SSD 2 &lt;/p&gt;\n\n&lt;p&gt;the question is&lt;/p&gt;\n\n&lt;p&gt;will HDD 1 &amp;amp; 2 activity affect HDD 3 copy speed?&lt;/p&gt;\n\n&lt;p&gt;and will it be better to copy both SSD at once or one by one&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "122dwhc", "is_robot_indexable": true, "report_reasons": null, "author": "OkAd5119", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/122dwhc/copying_situation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/122dwhc/copying_situation/", "subreddit_subscribers": 675459, "created_utc": 1679813851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any suggestions? distributing scimag to people in global south via physical media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1229tcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5juokasf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "libgen", "selftext": "Hi everyone! One of the goals for LibGen seeding project is making the science journal articles accessible for those in global south. Since scimag torrents total \\~73.5TB, I guess it's not gonna be possible for people in global south to download them easily!\n\nSo what should I do to distribute them to researchers in global south who need them? I figured to:\n\n1. download the torrents\n2. then get the SQL files which include the DOIs\n3. Unpack all the zip files to external HDDs e.g. 4x 20TB\n4. Ship the HDDs to the ppl who need them, and can duplicate + pass them around to their friends!\n\nIt all sounded feasible, until I thought abt unpacking the archives! Does anyone know how much storage I will need after unpacking them?\n\nHas anyone done this? Is there a protocol for it? I'm a bit of a neophyte! Thanks!\n\nEdit: changing a word", "author_fullname": "t2_644lcri6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distributing scimag to people in global south via physical media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/libgen", "hidden": false, "pwls": 7, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1220iuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679783435.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679781213.0, "link_flair_type": "text", "wls": 7, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! One of the goals for LibGen seeding project is making the science journal articles accessible for those in global south. Since scimag torrents total ~73.5TB, I guess it&amp;#39;s not gonna be possible for people in global south to download them easily!&lt;/p&gt;\n\n&lt;p&gt;So what should I do to distribute them to researchers in global south who need them? I figured to:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;download the torrents&lt;/li&gt;\n&lt;li&gt;then get the SQL files which include the DOIs&lt;/li&gt;\n&lt;li&gt;Unpack all the zip files to external HDDs e.g. 4x 20TB&lt;/li&gt;\n&lt;li&gt;Ship the HDDs to the ppl who need them, and can duplicate + pass them around to their friends!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It all sounded feasible, until I thought abt unpacking the archives! Does anyone know how much storage I will need after unpacking them?&lt;/p&gt;\n\n&lt;p&gt;Has anyone done this? Is there a protocol for it? I&amp;#39;m a bit of a neophyte! Thanks!&lt;/p&gt;\n\n&lt;p&gt;Edit: changing a word&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_31p7i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1220iuq", "is_robot_indexable": true, "report_reasons": null, "author": "KoalasWelcomeHere", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "some_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "parent_whitelist_status": "some_ads", "stickied": false, "url": "https://old.reddit.com/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "subreddit_subscribers": 50456, "created_utc": 1679781213.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679801710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.libgen", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1229tcc", "is_robot_indexable": true, "report_reasons": null, "author": "n0noTAGAinnxw4Yn3wp7", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1220iuq", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1229tcc/any_suggestions_distributing_scimag_to_people_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/libgen/comments/1220iuq/distributing_scimag_to_people_in_global_south_via/", "subreddit_subscribers": 675459, "created_utc": 1679801710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I\u2019ll start off by saying I\u2019m brand new to this sub and don\u2019t even know if this is the right place to ask this so if theres a better place to ask or I\u2019m doing something wrong let me know. Anyways here\u2019s my question. I\u2019m a photographer and have been just keeping my files on SD cards and not reusing them. I\u2019ve decided to start storing them on my computer instead so I can invest in a really good SD card. So I\u2019m planning on buying 2 8tb hard drives (for now) and having one at each of my main locations I edit my photos at (different houses). I\u2019m wondering if I put one in each of these PC\u2019s if there\u2019s any way to sync the data between the two so there basically backups of each other. Thanks in advance and lmk if there\u2019s any more details I can add about my question.", "author_fullname": "t2_7xmsjgu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about syncing hard drives from 2 locations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12273hx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679794859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I\u2019ll start off by saying I\u2019m brand new to this sub and don\u2019t even know if this is the right place to ask this so if theres a better place to ask or I\u2019m doing something wrong let me know. Anyways here\u2019s my question. I\u2019m a photographer and have been just keeping my files on SD cards and not reusing them. I\u2019ve decided to start storing them on my computer instead so I can invest in a really good SD card. So I\u2019m planning on buying 2 8tb hard drives (for now) and having one at each of my main locations I edit my photos at (different houses). I\u2019m wondering if I put one in each of these PC\u2019s if there\u2019s any way to sync the data between the two so there basically backups of each other. Thanks in advance and lmk if there\u2019s any more details I can add about my question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12273hx", "is_robot_indexable": true, "report_reasons": null, "author": "matrix11223", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12273hx/question_about_syncing_hard_drives_from_2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12273hx/question_about_syncing_hard_drives_from_2/", "subreddit_subscribers": 675459, "created_utc": 1679794859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone\n\nFor people using Google Drive, how are you all using it?\n\nI use rclone. To work around the 750GB upload limit, the way I've been working around is with service accounts. \n\nI created all of them. Then I created a group with the emails. I then create a new shared drive and add the group email.\n\nMy workflow is to get my stuff organized locally. I then copy my data via rclone to a crypt remote that points to a shared drive. My only issue with using shared drives is that there's a limit to the files it holds.\n\nI've thought of copying from shared drive to my drive, but not sure if it's being done by my user, if the 750GB daily limit applies (have to check unless someone else can tell me).\n\nMy other part is that I mount my shared drives as read only so that I can work on my files locally. If the download limit is hit, I can just rotate to another service account.\n\nNo idea if service accounts can be used to upload to my drive.\n\nAnyway, what are you all doing with google drive? How do you all manage things?", "author_fullname": "t2_5h10m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive organization and workflow. Shared Drives, SA's, multiple users, etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1225krb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": "", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679791995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone&lt;/p&gt;\n\n&lt;p&gt;For people using Google Drive, how are you all using it?&lt;/p&gt;\n\n&lt;p&gt;I use rclone. To work around the 750GB upload limit, the way I&amp;#39;ve been working around is with service accounts. &lt;/p&gt;\n\n&lt;p&gt;I created all of them. Then I created a group with the emails. I then create a new shared drive and add the group email.&lt;/p&gt;\n\n&lt;p&gt;My workflow is to get my stuff organized locally. I then copy my data via rclone to a crypt remote that points to a shared drive. My only issue with using shared drives is that there&amp;#39;s a limit to the files it holds.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve thought of copying from shared drive to my drive, but not sure if it&amp;#39;s being done by my user, if the 750GB daily limit applies (have to check unless someone else can tell me).&lt;/p&gt;\n\n&lt;p&gt;My other part is that I mount my shared drives as read only so that I can work on my files locally. If the download limit is hit, I can just rotate to another service account.&lt;/p&gt;\n\n&lt;p&gt;No idea if service accounts can be used to upload to my drive.&lt;/p&gt;\n\n&lt;p&gt;Anyway, what are you all doing with google drive? How do you all manage things?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "\u224827TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1225krb", "is_robot_indexable": true, "report_reasons": null, "author": "mrcaptncrunch", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1225krb/google_drive_organization_and_workflow_shared/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1225krb/google_drive_organization_and_workflow_shared/", "subreddit_subscribers": 675459, "created_utc": 1679791995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there. After seeing a few of my favorite YouTube videos get deleted, and after seeing games like TF2 and TF2 being abandoned by their host companies (even when still somewhat popular) I have lost a bit of faith in the public cloud/service model.\n\nI was wondering if you guys recommended a certain brand of NAS, and an alternative format for long term archival storage of video and text files. Right now I'm thinking that four terabyte capacity stored across 3-4 drives in a RAID would be good. Do you guys have suggestions for machines or brands off the top of your head? I'm  right now looking at synology NAS's on amazon.\n\nI also saw another post that recommended storing blu-rays in a bank deposit box as a form of off-site storage. I wanted to get a second opinion here though to see if that would be a good course of action.", "author_fullname": "t2_t7rjci3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on home NAS, brand &amp; alternative format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1225hr8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679791808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there. After seeing a few of my favorite YouTube videos get deleted, and after seeing games like TF2 and TF2 being abandoned by their host companies (even when still somewhat popular) I have lost a bit of faith in the public cloud/service model.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if you guys recommended a certain brand of NAS, and an alternative format for long term archival storage of video and text files. Right now I&amp;#39;m thinking that four terabyte capacity stored across 3-4 drives in a RAID would be good. Do you guys have suggestions for machines or brands off the top of your head? I&amp;#39;m  right now looking at synology NAS&amp;#39;s on amazon.&lt;/p&gt;\n\n&lt;p&gt;I also saw another post that recommended storing blu-rays in a bank deposit box as a form of off-site storage. I wanted to get a second opinion here though to see if that would be a good course of action.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1225hr8", "is_robot_indexable": true, "report_reasons": null, "author": "DirkyLeSpowl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1225hr8/looking_for_advice_on_home_nas_brand_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1225hr8/looking_for_advice_on_home_nas_brand_alternative/", "subreddit_subscribers": 675459, "created_utc": 1679791808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow DataHoarders! \n\n&amp;#x200B;\n\nCurrently I have a \"multimedia sever\", a WinPC with a Dell Perc H310 (IT mode) that is connected to a DS4243 with 18 disks of different sizes (100Tb total approx). All disks are organized as a pool with StableBit DrivePool. That server is not in 24/7, I switch it on only when needed.\n\n&amp;#x200B;\n\nThen I have an \"XPenology\" server with 4 disks and finally another WinPC doing several stuff, including a VirtualBox VM with Debian for HomeAssitant.\n\n&amp;#x200B;\n\nRecently I was able to buy a Dell R720 (2 x 2695v2 / 96Gb / 8xLFF no disks) with the idea to move all the OSs to Proxmox and migrate DrivePool to Unraid in a VM.\n\n&amp;#x200B;\n\nI was thinking to use the internal controller of R720, a H710 mini (also flashed to IT mode), to expose the 8xLFF disks to Proxmox to have a RAIDZ2 storage for the VMs.\n\n&amp;#x200B;\n\nBut I'm not sure how to move to Unraid. Is it possible to do a a passthrough of the H310 (the other HBA card I had) to a WinPC VM where I can have DrivePool, and also do a passthrough at the same time to antoher VM for Unraid? This way I can have 2 VMs that can see the disks on DS4243 and start moving the disks bit a bit (I have some extra disks that can help on this). \n\n&amp;#x200B;\n\nIf this is not possible which other alternatives I have to move from DrivePool to Unraid ?\n\n&amp;#x200B;\n\nAnother question is, once I have everything running under Proxmox/Unraid, will be feasible to switch on the Unraid VM and the DS4243 (through a smart plug from homeassistant) only when needed? Will the H310 passthrough work this way?\n\n&amp;#x200B;\n\nThank you very much in advance!", "author_fullname": "t2_2y98rrqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving from Frankenstein infra to a nice R720", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1224bse", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679789212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DataHoarders! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Currently I have a &amp;quot;multimedia sever&amp;quot;, a WinPC with a Dell Perc H310 (IT mode) that is connected to a DS4243 with 18 disks of different sizes (100Tb total approx). All disks are organized as a pool with StableBit DrivePool. That server is not in 24/7, I switch it on only when needed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Then I have an &amp;quot;XPenology&amp;quot; server with 4 disks and finally another WinPC doing several stuff, including a VirtualBox VM with Debian for HomeAssitant.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Recently I was able to buy a Dell R720 (2 x 2695v2 / 96Gb / 8xLFF no disks) with the idea to move all the OSs to Proxmox and migrate DrivePool to Unraid in a VM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was thinking to use the internal controller of R720, a H710 mini (also flashed to IT mode), to expose the 8xLFF disks to Proxmox to have a RAIDZ2 storage for the VMs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m not sure how to move to Unraid. Is it possible to do a a passthrough of the H310 (the other HBA card I had) to a WinPC VM where I can have DrivePool, and also do a passthrough at the same time to antoher VM for Unraid? This way I can have 2 VMs that can see the disks on DS4243 and start moving the disks bit a bit (I have some extra disks that can help on this). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If this is not possible which other alternatives I have to move from DrivePool to Unraid ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Another question is, once I have everything running under Proxmox/Unraid, will be feasible to switch on the Unraid VM and the DS4243 (through a smart plug from homeassistant) only when needed? Will the H310 passthrough work this way?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you very much in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1224bse", "is_robot_indexable": true, "report_reasons": null, "author": "pilfos", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1224bse/moving_from_frankenstein_infra_to_a_nice_r720/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1224bse/moving_from_frankenstein_infra_to_a_nice_r720/", "subreddit_subscribers": 675459, "created_utc": 1679789212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 6 HDD in various sizes; from 4TB to 10TB.\n\nLooking for a USB Enclosure that I can do JBODs and connect to a windows 10 machine.\n\nIdeas ????", "author_fullname": "t2_9s0a8kc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD USB Enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1222ttb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679786061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 6 HDD in various sizes; from 4TB to 10TB.&lt;/p&gt;\n\n&lt;p&gt;Looking for a USB Enclosure that I can do JBODs and connect to a windows 10 machine.&lt;/p&gt;\n\n&lt;p&gt;Ideas ????&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1222ttb", "is_robot_indexable": true, "report_reasons": null, "author": "BBMKV", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1222ttb/hdd_usb_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1222ttb/hdd_usb_enclosure/", "subreddit_subscribers": 675459, "created_utc": 1679786061.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}