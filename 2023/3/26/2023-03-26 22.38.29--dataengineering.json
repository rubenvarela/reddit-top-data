{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was asked to migrate 2500 tables from SQL Server to MariaDB and the ETL tool (Cdata sync) doesn\u2019t work for ~20 tables because they\u2019re too big and it keeps timing out. So I tried importing the data for the missing tables by expiring the CSVs through DBeaver then importing them and it still times out. Now I am trying to import the tables using python but my code errors out because of some issue with how it\u2019s reading the data. I don\u2019t even know if that\u2019s worth fixing because it\u2019s going to take forever to read in the tables with ~5 million records and other have even more or about the same. Whenever I use \u201cread_csv\u201d there is an error with tokenizing the data and when I use \u201cwith open\u201d\u2026 it says some error that hit all the data types converted. \n\nI told my manager(s) this and my co worker whom I was told to reach out to help for. I bounced some ideas off of my conworker and he said if I can come up with something in python that would be cool. I was like okay I don\u2019t know what I\u2019m doing is this ok?? What would be cool?? My manager said he\u2019s depending on me to do this and my co worker but idk what I\u2019m doing and when I ask for help they\u2019re like I don\u2019t know?? Like i dont know either what the fuck do you want from me?? I hesitate to download other tools like new ones and start over again. I need to find a way to automate increments of data too so I can\u2019t just manually import them and use the stupid failed ETL tool for others?  Like I don\u2019t know what to say anymore I am stuck and out of ideas?? I don\u2019t know what to say for my standup on Monday.", "author_fullname": "t2_8ewmlf41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m struggling with how to ask for help with my task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1226vlf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679794333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked to migrate 2500 tables from SQL Server to MariaDB and the ETL tool (Cdata sync) doesn\u2019t work for ~20 tables because they\u2019re too big and it keeps timing out. So I tried importing the data for the missing tables by expiring the CSVs through DBeaver then importing them and it still times out. Now I am trying to import the tables using python but my code errors out because of some issue with how it\u2019s reading the data. I don\u2019t even know if that\u2019s worth fixing because it\u2019s going to take forever to read in the tables with ~5 million records and other have even more or about the same. Whenever I use \u201cread_csv\u201d there is an error with tokenizing the data and when I use \u201cwith open\u201d\u2026 it says some error that hit all the data types converted. &lt;/p&gt;\n\n&lt;p&gt;I told my manager(s) this and my co worker whom I was told to reach out to help for. I bounced some ideas off of my conworker and he said if I can come up with something in python that would be cool. I was like okay I don\u2019t know what I\u2019m doing is this ok?? What would be cool?? My manager said he\u2019s depending on me to do this and my co worker but idk what I\u2019m doing and when I ask for help they\u2019re like I don\u2019t know?? Like i dont know either what the fuck do you want from me?? I hesitate to download other tools like new ones and start over again. I need to find a way to automate increments of data too so I can\u2019t just manually import them and use the stupid failed ETL tool for others?  Like I don\u2019t know what to say anymore I am stuck and out of ideas?? I don\u2019t know what to say for my standup on Monday.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1226vlf", "is_robot_indexable": true, "report_reasons": null, "author": "jumpfordespair", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1226vlf/im_struggling_with_how_to_ask_for_help_with_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1226vlf/im_struggling_with_how_to_ask_for_help_with_my/", "subreddit_subscribers": 94479, "created_utc": 1679794333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Usually in OLTP systems, we have a PK constraint that is enforced. In OLAP side, I see that Snowflake, Databricks, GCP BigQuery - None of them have a PK that is enforced. I understand that it causes data performance issues, but given that all of them store data in columnar fashion, how does checking a unique id in column affects performance?\n\nEven while working with MERGE statements, the system is going to compare the columns to check whether it needs to do INSERT OR UPDATE, then a PK column with corresponding index might increase the query performance right?", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do Data warehouses don't have a Primary Key check that is enforced?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122eo0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679816204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Usually in OLTP systems, we have a PK constraint that is enforced. In OLAP side, I see that Snowflake, Databricks, GCP BigQuery - None of them have a PK that is enforced. I understand that it causes data performance issues, but given that all of them store data in columnar fashion, how does checking a unique id in column affects performance?&lt;/p&gt;\n\n&lt;p&gt;Even while working with MERGE statements, the system is going to compare the columns to check whether it needs to do INSERT OR UPDATE, then a PK column with corresponding index might increase the query performance right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122eo0k", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122eo0k/why_do_data_warehouses_dont_have_a_primary_key/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122eo0k/why_do_data_warehouses_dont_have_a_primary_key/", "subreddit_subscribers": 94479, "created_utc": 1679816204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Noob here. I heard it somewhere and have been wondering why this ks the case.", "author_fullname": "t2_8k2n3mqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it correct that OLTP systems are highly normalized and OLAP systems are not normalized? Can someone please explain the reasoning behind it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122qe2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679845686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Noob here. I heard it somewhere and have been wondering why this ks the case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122qe2z", "is_robot_indexable": true, "report_reasons": null, "author": "Pra987885", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122qe2z/is_it_correct_that_oltp_systems_are_highly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122qe2z/is_it_correct_that_oltp_systems_are_highly/", "subreddit_subscribers": 94479, "created_utc": 1679845686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI've been mentoring a couple of folks on entering the data engineering space and realized that with the changing climate, there is more demand for data engineers and also more requirements. \n\nI'm seeking some advice on how to break into data engineering. For someone with a background in computer science, that is not sure where to begin when it comes to data engineering.\n\nHow would you explain what data engineering is and what skills are necessary to be successful in this field? Are there any online courses or resources you would recommend for someone who is just starting out?\n\nAlso, what advice do you have for someone who is looking to break into the data engineering space? \n\nIs there an entry-level job opportunity in this field for someone with entry-level skills, and what should they do to prepare for it?\n\nWith this financial climate, which area should they focus on more, BI, Infra, ML? \n\nAny advice or insights you can share would be greatly appreciated. Thank you in advance!", "author_fullname": "t2_2f6uepg8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for Newbies on Entering the Data Engineering Space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122n9xl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679839965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been mentoring a couple of folks on entering the data engineering space and realized that with the changing climate, there is more demand for data engineers and also more requirements. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeking some advice on how to break into data engineering. For someone with a background in computer science, that is not sure where to begin when it comes to data engineering.&lt;/p&gt;\n\n&lt;p&gt;How would you explain what data engineering is and what skills are necessary to be successful in this field? Are there any online courses or resources you would recommend for someone who is just starting out?&lt;/p&gt;\n\n&lt;p&gt;Also, what advice do you have for someone who is looking to break into the data engineering space? &lt;/p&gt;\n\n&lt;p&gt;Is there an entry-level job opportunity in this field for someone with entry-level skills, and what should they do to prepare for it?&lt;/p&gt;\n\n&lt;p&gt;With this financial climate, which area should they focus on more, BI, Infra, ML? &lt;/p&gt;\n\n&lt;p&gt;Any advice or insights you can share would be greatly appreciated. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "122n9xl", "is_robot_indexable": true, "report_reasons": null, "author": "AdiPolak", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122n9xl/advice_for_newbies_on_entering_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122n9xl/advice_for_newbies_on_entering_the_data/", "subreddit_subscribers": 94479, "created_utc": 1679839965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "r/PostgreSQL as the New Default Database Choice?\n\nI have been using r/getdbt with r/bigquery for three years now. \n\nI just noticed DBT Cloud does not have r/mysql as a native adapter, or MySQL does as part of the web setup flow! \n\nAs someone who has primarily worked with SQL Server throughout my 24-year career, I have limited experience with performance tuning, concurrency issues or the maintainability of MySQL.\n\nAfter seeing Google bring out AlloyDB for PostgreSQL and noticing that DBT is not supporting MySQL. \n\n \n\n* Want to understand the current consensus when selecting MySQL or PostgreSQL in a management environment like Amazon RDS or Google Cloud SQL? \n* Should PostgreSQL be the default choice when building a new project with AWS RDS or GCP Cloud SQL? \n* Should I read into DBT not having a native MySQL adapter as the world is moving on from MySQL? \n* Is all the new energy and development behind PostgreSQL when it comes to open-source RDBMS?  \n\n\nI love to hear what people are seeing and thinking about the future on this topic.", "author_fullname": "t2_afs0syb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AlloyDB and DBT for PostgreSQL! Where does this leave MySQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122slf2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679850251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/r/PostgreSQL\"&gt;r/PostgreSQL&lt;/a&gt; as the New Default Database Choice?&lt;/p&gt;\n\n&lt;p&gt;I have been using &lt;a href=\"/r/getdbt\"&gt;r/getdbt&lt;/a&gt; with &lt;a href=\"/r/bigquery\"&gt;r/bigquery&lt;/a&gt; for three years now. &lt;/p&gt;\n\n&lt;p&gt;I just noticed DBT Cloud does not have &lt;a href=\"/r/mysql\"&gt;r/mysql&lt;/a&gt; as a native adapter, or MySQL does as part of the web setup flow! &lt;/p&gt;\n\n&lt;p&gt;As someone who has primarily worked with SQL Server throughout my 24-year career, I have limited experience with performance tuning, concurrency issues or the maintainability of MySQL.&lt;/p&gt;\n\n&lt;p&gt;After seeing Google bring out AlloyDB for PostgreSQL and noticing that DBT is not supporting MySQL. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Want to understand the current consensus when selecting MySQL or PostgreSQL in a management environment like Amazon RDS or Google Cloud SQL? &lt;/li&gt;\n&lt;li&gt;Should PostgreSQL be the default choice when building a new project with AWS RDS or GCP Cloud SQL? &lt;/li&gt;\n&lt;li&gt;Should I read into DBT not having a native MySQL adapter as the world is moving on from MySQL? &lt;/li&gt;\n&lt;li&gt;Is all the new energy and development behind PostgreSQL when it comes to open-source RDBMS?&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I love to hear what people are seeing and thinking about the future on this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122slf2", "is_robot_indexable": true, "report_reasons": null, "author": "Rif-SQL", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122slf2/alloydb_and_dbt_for_postgresql_where_does_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122slf2/alloydb_and_dbt_for_postgresql_where_does_this/", "subreddit_subscribers": 94479, "created_utc": 1679850251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Keen to know any managed service on data governance or Ranger gives the best bang for buck.\n\n[View Poll](https://www.reddit.com/poll/122cbp0)", "author_fullname": "t2_74eqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data governance tool are you folks using?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122cbp0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679808990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keen to know any managed service on data governance or Ranger gives the best bang for buck.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/122cbp0\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122cbp0", "is_robot_indexable": true, "report_reasons": null, "author": "shabaab", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1680068191004, "options": [{"text": "Apache Ranger", "id": "22248299"}, {"text": "Privacera", "id": "22248300"}, {"text": "Immuta", "id": "22248301"}, {"text": "Atlan", "id": "22248302"}, {"text": "Others (please comment)", "id": "22248303"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 273, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122cbp0/what_data_governance_tool_are_you_folks_using/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/122cbp0/what_data_governance_tool_are_you_folks_using/", "subreddit_subscribers": 94479, "created_utc": 1679808990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, \n\nI'm a commercial analyst attached to the analytics and insights division at a large financial trading firm. My team handles options pricing and general forecasting/data exploration support functions for the various other departments in the company. Currently, most of their ETL processes consist of manual data pulls from something like two dozen unique data sources, coupled with VBA scripts and a little bit of MATLAB, and I was recently asked to help develop a comprehensive data tool that would allow the team to automate their rote manual processes and give them a single endpoint through which they would be able to access their data. \n\nFor context, my background is primarily in data analytics and management, and while I have had some training on Azure and AWS, I don't really have a DE background. My boss is not really a technical guy either, and doesn't really have a strong sense for how hard this project will be, however he did give me broad authority to build out this tool for the team, and has offered to get me support from the data science team if I need it (I need it). \n\nI think I have a basic idea how to get this done with Azure and snowflake, but I also feel like I might be in a little over my head technically on this one. For that reason my tentative plan is to run this more like a project manager, so I was hoping you guys might be able to help me get a better idea of how heavy a lift this will be and what kind of team I would need to do this successfully.\n\nThanks for your help!", "author_fullname": "t2_27n5u7c0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you effectively project manage a data pipeline project consisting of the integration of 20ish data sources into a single data storage and analytics service like snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122vg55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679856310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a commercial analyst attached to the analytics and insights division at a large financial trading firm. My team handles options pricing and general forecasting/data exploration support functions for the various other departments in the company. Currently, most of their ETL processes consist of manual data pulls from something like two dozen unique data sources, coupled with VBA scripts and a little bit of MATLAB, and I was recently asked to help develop a comprehensive data tool that would allow the team to automate their rote manual processes and give them a single endpoint through which they would be able to access their data. &lt;/p&gt;\n\n&lt;p&gt;For context, my background is primarily in data analytics and management, and while I have had some training on Azure and AWS, I don&amp;#39;t really have a DE background. My boss is not really a technical guy either, and doesn&amp;#39;t really have a strong sense for how hard this project will be, however he did give me broad authority to build out this tool for the team, and has offered to get me support from the data science team if I need it (I need it). &lt;/p&gt;\n\n&lt;p&gt;I think I have a basic idea how to get this done with Azure and snowflake, but I also feel like I might be in a little over my head technically on this one. For that reason my tentative plan is to run this more like a project manager, so I was hoping you guys might be able to help me get a better idea of how heavy a lift this will be and what kind of team I would need to do this successfully.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "122vg55", "is_robot_indexable": true, "report_reasons": null, "author": "shadowfax12221", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122vg55/how_would_you_effectively_project_manage_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122vg55/how_would_you_effectively_project_manage_a_data/", "subreddit_subscribers": 94479, "created_utc": 1679856310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I am recent graduate in Elx &amp;Communication Engineering who loves programming. I have understanding of python , django, drf etc from making projects. Recently I got to know about Data Engineering and there is fellowship opening in DE. I am confused between choosing Backend Development and Data engineering.  and making career on long term.\n\nI would appreciate if anyone could show me some lights regarding this topic.", "author_fullname": "t2_ejqvvey8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help to choose between DE and Backend Development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122pvvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679844657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I am recent graduate in Elx &amp;amp;Communication Engineering who loves programming. I have understanding of python , django, drf etc from making projects. Recently I got to know about Data Engineering and there is fellowship opening in DE. I am confused between choosing Backend Development and Data engineering.  and making career on long term.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate if anyone could show me some lights regarding this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "122pvvz", "is_robot_indexable": true, "report_reasons": null, "author": "tenzo-8", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122pvvz/help_to_choose_between_de_and_backend_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122pvvz/help_to_choose_between_de_and_backend_development/", "subreddit_subscribers": 94479, "created_utc": 1679844657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Is there any difference at all (between saving as delta table vs saving as files using delta format) when writing data back to delta lake?  \n\n&amp;#x200B;\n\nEventually, when you use these data later on, using the Dataframe API to read them, what difference does it make whether you are reading from a delta table, or files?", "author_fullname": "t2_3cuv2cgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks saveAsTable VS write.format(\"delta\").save(path)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122uv48", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679855052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any difference at all (between saving as delta table vs saving as files using delta format) when writing data back to delta lake?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Eventually, when you use these data later on, using the Dataframe API to read them, what difference does it make whether you are reading from a delta table, or files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122uv48", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent-Style6371", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122uv48/databricks_saveastable_vs_writeformatdeltasavepath/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122uv48/databricks_saveastable_vs_writeformatdeltasavepath/", "subreddit_subscribers": 94479, "created_utc": 1679855052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like some advice from this sub on this.\n\nAt my place of work, a datawarehouse was developed using the DV 2.0 architecture but never put in production because client changed direction and bunch of other stuff happened. But a bunch of money was spent doing this.\n\nI now have the opportunity to re-do this venture and I am stuck with the dilemma of re-using the work that was done or starting scratch with a traditional EDW using Dimension modeling / Star Schema etc.. you get the picture.\n\nI am familiar with the traditional method and not averse to learning new tricks (DV 2.0). DV 2.0 looks like a lot of work with its hubs-&gt;links-&gt;satellite rigidity and the benefits don't seem like its worth the squeeze. I don't have the luxury to experiment for too long either.\n\nI'd like some sensible independent opinions on this matter please. I hate the idea of throwing away all that work but also don't want to dive head first into somewhat of an unknown.", "author_fullname": "t2_7vr2noa4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault or Traditional?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122wyyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679859508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like some advice from this sub on this.&lt;/p&gt;\n\n&lt;p&gt;At my place of work, a datawarehouse was developed using the DV 2.0 architecture but never put in production because client changed direction and bunch of other stuff happened. But a bunch of money was spent doing this.&lt;/p&gt;\n\n&lt;p&gt;I now have the opportunity to re-do this venture and I am stuck with the dilemma of re-using the work that was done or starting scratch with a traditional EDW using Dimension modeling / Star Schema etc.. you get the picture.&lt;/p&gt;\n\n&lt;p&gt;I am familiar with the traditional method and not averse to learning new tricks (DV 2.0). DV 2.0 looks like a lot of work with its hubs-&amp;gt;links-&amp;gt;satellite rigidity and the benefits don&amp;#39;t seem like its worth the squeeze. I don&amp;#39;t have the luxury to experiment for too long either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like some sensible independent opinions on this matter please. I hate the idea of throwing away all that work but also don&amp;#39;t want to dive head first into somewhat of an unknown.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "122wyyr", "is_robot_indexable": true, "report_reasons": null, "author": "papa-yaaga", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122wyyr/data_vault_or_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122wyyr/data_vault_or_traditional/", "subreddit_subscribers": 94479, "created_utc": 1679859508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just curious, as I can't seem to find anything relatable online. \n\nIs it possible to query, for example, a sqlite file on a remote Ceph cluster using PySpark? \n\nIf it's possible, how would one do it, if its not possible, why not?", "author_fullname": "t2_sy57joj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to query a remote Ceph cluster using Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122n0t8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679839441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just curious, as I can&amp;#39;t seem to find anything relatable online. &lt;/p&gt;\n\n&lt;p&gt;Is it possible to query, for example, a sqlite file on a remote Ceph cluster using PySpark? &lt;/p&gt;\n\n&lt;p&gt;If it&amp;#39;s possible, how would one do it, if its not possible, why not?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122n0t8", "is_robot_indexable": true, "report_reasons": null, "author": "pioneeringwork", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122n0t8/is_it_possible_to_query_a_remote_ceph_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122n0t8/is_it_possible_to_query_a_remote_ceph_cluster/", "subreddit_subscribers": 94479, "created_utc": 1679839441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "No, not the sql function lol\nHas anyone used this product? Pros, cons, thoughts? \nThanks!", "author_fullname": "t2_9rbxc91v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coalesce for Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122a093", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679802235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No, not the sql function lol\nHas anyone used this product? Pros, cons, thoughts? \nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122a093", "is_robot_indexable": true, "report_reasons": null, "author": "AnnualDepth8843", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122a093/coalesce_for_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122a093/coalesce_for_snowflake/", "subreddit_subscribers": 94479, "created_utc": 1679802235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Preface this post with I graduate with me BS in May and I already have 2 years of help desk on my resume but I know I would love to break into data engineering at some point in my career so I\u2019m looking for some recommendations on learning material as it pertains to a general data engineering job so that I can better understand and already have experience with what is most likely to be expected in the day to day of a DE. I\u2019ve looked through the wiki and I\u2019m just wondering if there are items or methods not currently listed that most of you use.\n\nI know how to operate the basic kinds of programs and languages like SSMS, SSAS, Python, workbench, etc\u2026", "author_fullname": "t2_bygsfu8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for learning material?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122yg7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679862445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preface this post with I graduate with me BS in May and I already have 2 years of help desk on my resume but I know I would love to break into data engineering at some point in my career so I\u2019m looking for some recommendations on learning material as it pertains to a general data engineering job so that I can better understand and already have experience with what is most likely to be expected in the day to day of a DE. I\u2019ve looked through the wiki and I\u2019m just wondering if there are items or methods not currently listed that most of you use.&lt;/p&gt;\n\n&lt;p&gt;I know how to operate the basic kinds of programs and languages like SSMS, SSAS, Python, workbench, etc\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122yg7u", "is_robot_indexable": true, "report_reasons": null, "author": "AJohnM_IT", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122yg7u/recommendations_for_learning_material/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122yg7u/recommendations_for_learning_material/", "subreddit_subscribers": 94479, "created_utc": 1679862445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Modern Data Stack (Demystified)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122yczk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1679862266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/blog/what-is-the-modern-data-stack", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "122yczk", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122yczk/the_modern_data_stack_demystified/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/blog/what-is-the-modern-data-stack", "subreddit_subscribers": 94479, "created_utc": 1679862266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I use RazorSQL to navigate in a DynamoDB database. What's the rationale behind the column order? http://i.stack.imgur.com/Lgcqr.png\n\nI am asking as the import tool uses the same order (which means if I import a CSV file it needs to be in the same ordering as the RazorSQL's column order): http://i.stack.imgur.com/fDyBL.png\n\nI use RazorSQL 6.3.14 with Windows 7 SP1 x64 Ultimate.", "author_fullname": "t2_kprlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Column order in a DynamoDB table browsed through RazorSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12237ot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679786885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use RazorSQL to navigate in a DynamoDB database. What&amp;#39;s the rationale behind the column order? &lt;a href=\"http://i.stack.imgur.com/Lgcqr.png\"&gt;http://i.stack.imgur.com/Lgcqr.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am asking as the import tool uses the same order (which means if I import a CSV file it needs to be in the same ordering as the RazorSQL&amp;#39;s column order): &lt;a href=\"http://i.stack.imgur.com/fDyBL.png\"&gt;http://i.stack.imgur.com/fDyBL.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I use RazorSQL 6.3.14 with Windows 7 SP1 x64 Ultimate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1HCf9QrSJkHQ0xOEkNIY3cR_7HgL5mGBprd5xwpQl18.png?auto=webp&amp;v=enabled&amp;s=e29d2560fcbf6f1c014341065dce924e6c06b93a", "width": 480, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/1HCf9QrSJkHQ0xOEkNIY3cR_7HgL5mGBprd5xwpQl18.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c399fdb73c0bf1a1159a61a0b0f9135bd69311be", "width": 108, "height": 162}, {"url": "https://external-preview.redd.it/1HCf9QrSJkHQ0xOEkNIY3cR_7HgL5mGBprd5xwpQl18.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a209863b315b2a004a8e9a57fc36c15bc327991e", "width": 216, "height": 324}, {"url": "https://external-preview.redd.it/1HCf9QrSJkHQ0xOEkNIY3cR_7HgL5mGBprd5xwpQl18.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9b497a7303e48a07900f1b9c1ff681cb15a66ca", "width": 320, "height": 480}], "variants": {}, "id": "LHrO0Nr6RjYhrhTbc1QR71XCyuantZcywjo_QIkTKlw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12237ot", "is_robot_indexable": true, "report_reasons": null, "author": "Franck_Dernoncourt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12237ot/column_order_in_a_dynamodb_table_browsed_through/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12237ot/column_order_in_a_dynamodb_table_browsed_through/", "subreddit_subscribers": 94479, "created_utc": 1679786885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It doesn't make sense to me how data can really be considered anonymized if an internal member of a company still has access to it and can find out who it belongs to.", "author_fullname": "t2_ijf7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can data truly be anonymized for consumers while still being governed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122yhe7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679862510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It doesn&amp;#39;t make sense to me how data can really be considered anonymized if an internal member of a company still has access to it and can find out who it belongs to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "122yhe7", "is_robot_indexable": true, "report_reasons": null, "author": "SurelyForever", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122yhe7/can_data_truly_be_anonymized_for_consumers_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122yhe7/can_data_truly_be_anonymized_for_consumers_while/", "subreddit_subscribers": 94479, "created_utc": 1679862510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if there was a way to go above and beyond in regards do dbt documentation , without buying a software. Ie taking their free html output and making it a lot better ?", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone ever use dbt code and generate docs https://docs.getdbt.com/reference/commands/cmd-docs ; and instead of hosting the documentation website on your own per many blogs \u2014 you every create your own cool webpage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1223bq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679787113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if there was a way to go above and beyond in regards do dbt documentation , without buying a software. Ie taking their free html output and making it a lot better ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1223bq2", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1223bq2/anyone_ever_use_dbt_code_and_generate_docs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1223bq2/anyone_ever_use_dbt_code_and_generate_docs/", "subreddit_subscribers": 94479, "created_utc": 1679787113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I've got sort of an unusual research question. Basically, I'd like to perform a comprehensive review of all the literature of a particular topic. To do this, I'd like to use combinations of search terms. For example, I'd conduct a search using terms \"A\" and \"B\", then I'd conduct another search using terms \"A\" and \"C\", then again using \"A\" and \"D\", etc. The problem with this is that there's a decent amount of overlap of search results among these different combinations and there are thousands of search results for each combination so I want to minimize redundancy as much as possible in order to save time. Is there a way for me to conduct an initial search (e.g., A + B) and then conduct each subsequent search (A + C, A + D, etc.) that will only show search results that are NOT included in the initial A + B search?\n\nI'm using OVID Medline as the search database, but I'd be open to any general workaround solutions as well. From my limited knowledge on a possible solution, I was wondering if it's possible to export all the search results, copy them as a list into a column within Excel, and then use the Excel function that can highlight duplicate values. This method would allow me to avoid redundant search results from each search iteration. This isn't an elegant solution imo, but I imagined a possible solution like this. The most ideal solution would be for the database to filter out redundant search results for me automatically.\n\nI can explain or clarify the problem further if that's helpful. Thank you for any help or suggestions with this problem!!", "author_fullname": "t2_179w2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Literature review - how to filter out redundant search results from similar search iterations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122cs7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679810401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;ve got sort of an unusual research question. Basically, I&amp;#39;d like to perform a comprehensive review of all the literature of a particular topic. To do this, I&amp;#39;d like to use combinations of search terms. For example, I&amp;#39;d conduct a search using terms &amp;quot;A&amp;quot; and &amp;quot;B&amp;quot;, then I&amp;#39;d conduct another search using terms &amp;quot;A&amp;quot; and &amp;quot;C&amp;quot;, then again using &amp;quot;A&amp;quot; and &amp;quot;D&amp;quot;, etc. The problem with this is that there&amp;#39;s a decent amount of overlap of search results among these different combinations and there are thousands of search results for each combination so I want to minimize redundancy as much as possible in order to save time. Is there a way for me to conduct an initial search (e.g., A + B) and then conduct each subsequent search (A + C, A + D, etc.) that will only show search results that are NOT included in the initial A + B search?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using OVID Medline as the search database, but I&amp;#39;d be open to any general workaround solutions as well. From my limited knowledge on a possible solution, I was wondering if it&amp;#39;s possible to export all the search results, copy them as a list into a column within Excel, and then use the Excel function that can highlight duplicate values. This method would allow me to avoid redundant search results from each search iteration. This isn&amp;#39;t an elegant solution imo, but I imagined a possible solution like this. The most ideal solution would be for the database to filter out redundant search results for me automatically.&lt;/p&gt;\n\n&lt;p&gt;I can explain or clarify the problem further if that&amp;#39;s helpful. Thank you for any help or suggestions with this problem!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "122cs7c", "is_robot_indexable": true, "report_reasons": null, "author": "pantaloonsss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122cs7c/literature_review_how_to_filter_out_redundant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122cs7c/literature_review_how_to_filter_out_redundant/", "subreddit_subscribers": 94479, "created_utc": 1679810401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n1. Apache Spark\n2. Apache Airflow\n3. Apache Beam\n4. Kubeflow", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which of the following programming frameworks are the most demanded and pay the highest salaries in data engineering job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_122kfa6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679840730.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679833273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;Apache Spark&lt;/li&gt;\n&lt;li&gt;Apache Airflow&lt;/li&gt;\n&lt;li&gt;Apache Beam&lt;/li&gt;\n&lt;li&gt;Kubeflow&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "122kfa6", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/122kfa6/which_of_the_following_programming_frameworks_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/122kfa6/which_of_the_following_programming_frameworks_are/", "subreddit_subscribers": 94479, "created_utc": 1679833273.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}