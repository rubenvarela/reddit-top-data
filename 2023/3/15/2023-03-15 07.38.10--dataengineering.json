{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Feel free to open issues, PR, check the paper, etc.: [https://github.com/citiususc/pyplexity](https://github.com/citiususc/pyplexity)", "author_fullname": "t2_7dah3w1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyPlexity: A simple tool for cleaning web scraped data (better than BS4!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r5jrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678799034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feel free to open issues, PR, check the paper, etc.: &lt;a href=\"https://github.com/citiususc/pyplexity\"&gt;https://github.com/citiususc/pyplexity&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?auto=webp&amp;v=enabled&amp;s=b159e29da3627b06d73bb3646d456f80c3cd2a0f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7d1c21bc9df8d656f065b60db15e2233b856f30", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=126c8cae4e70856f5d58c5f935249fa52946aae5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9528a90fae946c7e0a539589bbcd59d79cd7aef", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2affbc104595e3cf4e7a37d08b83377a9c4be0f2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02d554a94e8f751b722daa27582fa4a7ee70ce9f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/OPE7PevR--udpyatYXqVYE4LO79MIc65cIyLogx5IX4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40d87ffd85f8df2bc318f6f03d3adde7c32afe44", "width": 1080, "height": 540}], "variants": {}, "id": "dHqIfQ-Oj6Z1uL6Zlz_hjC2b36yAFK7OM8WSu88RywA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11r5jrh", "is_robot_indexable": true, "report_reasons": null, "author": "usc-ur", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r5jrh/pyplexity_a_simple_tool_for_cleaning_web_scraped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r5jrh/pyplexity_a_simple_tool_for_cleaning_web_scraped/", "subreddit_subscribers": 93062, "created_utc": 1678799034.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At which time of one's career do you think should be mandatory the knowledge of distributed systems? \n\nLet's say one has 2/3 yrs of experience, he knows reasonably well SQL, Python, Git, but has no idea of how distributed systems work. He skimmed over the dedicated chapter in DDIA but it just felt like arabic to him (he's not arabic). Would you find that acceptable?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Knowledge of distributed systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ra1sh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678809590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At which time of one&amp;#39;s career do you think should be mandatory the knowledge of distributed systems? &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say one has 2/3 yrs of experience, he knows reasonably well SQL, Python, Git, but has no idea of how distributed systems work. He skimmed over the dedicated chapter in DDIA but it just felt like arabic to him (he&amp;#39;s not arabic). Would you find that acceptable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ra1sh", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ra1sh/knowledge_of_distributed_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ra1sh/knowledge_of_distributed_systems/", "subreddit_subscribers": 93062, "created_utc": 1678809590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,\n\nI was wondering if anyone of you successfully managed to implement a simple system to have proper CI/CD within the context of AWS Glue jobs, without having to resort to intricate shenanigans and Cloudformation stacks.\n\nI know that recently AWS released version control for glue jobs within the console, but I find that experience absolutely abysmal.\n\nWhat's your experience with this?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CI/CD for AWS Glue jobs ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r87ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678805496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone of you successfully managed to implement a simple system to have proper CI/CD within the context of AWS Glue jobs, without having to resort to intricate shenanigans and Cloudformation stacks.&lt;/p&gt;\n\n&lt;p&gt;I know that recently AWS released version control for glue jobs within the console, but I find that experience absolutely abysmal.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your experience with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r87ki", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r87ki/cicd_for_aws_glue_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r87ki/cicd_for_aws_glue_jobs/", "subreddit_subscribers": 93062, "created_utc": 1678805496.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, looking for some guidance around stack selection in a greenfield business. I'm very aware of the dangers of picking a modern data stack solution 'off the shelf' because it's all nice and shiny rather than selecting off of business requirements but need to check my thinking.\n\nThe company I work for uses Azure, currently table storage for JSON data storage (one column for payloads) but longer term, could use blob storage for system data extracts. Data size isn't massive at present, we're talking &lt;10gb at present but potential for IOT data down the line which could ramp that very quickly. My immediate focus is on getting the exec team setup with performance reporting e.g. nailing down metric definitions, centralising what is now 'Excel Hell' so that things are consistent, improving the timeliness of the reporting etc.\n\nMy original plan was to throw something like Databricks or Snowflake over the top, mainly to avoid vendor lock with something like Synapse and because they both work with Azure storage (avoiding multi cloud). Then I can use dbt to start organising and cleaning the source data ready for some PowerBI schemas. My thinking was, as I'm comfortable with SQL and some data engineering fundamentals, this would allow me to standup something relatively quickly but also provides a pretty solid foundation to build from longer term.\n\nThe other option I'm now entertaining through is just using ADF to fire straight into something like Azure SQL and serving PowerBI from there. It would be cheaper than databricks or snowflake for sure and I believe dbt has a community adapter for it that I can explore too.\n\nQuestion is, if I have the budget, would the first option (snowflake, Databricks) be more sensible as it should save me time to focus on other things and likely be a better longer term solution should data volumes start to scale or am I am I succumbing to the tempation of MDS?\n\nIf anyone has experience in these types of trade offs or the products themselves, I'd love to hear it!", "author_fullname": "t2_t12o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Realistic Stack for One Person to implement/ maintain in an SMB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rbrh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678813280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, looking for some guidance around stack selection in a greenfield business. I&amp;#39;m very aware of the dangers of picking a modern data stack solution &amp;#39;off the shelf&amp;#39; because it&amp;#39;s all nice and shiny rather than selecting off of business requirements but need to check my thinking.&lt;/p&gt;\n\n&lt;p&gt;The company I work for uses Azure, currently table storage for JSON data storage (one column for payloads) but longer term, could use blob storage for system data extracts. Data size isn&amp;#39;t massive at present, we&amp;#39;re talking &amp;lt;10gb at present but potential for IOT data down the line which could ramp that very quickly. My immediate focus is on getting the exec team setup with performance reporting e.g. nailing down metric definitions, centralising what is now &amp;#39;Excel Hell&amp;#39; so that things are consistent, improving the timeliness of the reporting etc.&lt;/p&gt;\n\n&lt;p&gt;My original plan was to throw something like Databricks or Snowflake over the top, mainly to avoid vendor lock with something like Synapse and because they both work with Azure storage (avoiding multi cloud). Then I can use dbt to start organising and cleaning the source data ready for some PowerBI schemas. My thinking was, as I&amp;#39;m comfortable with SQL and some data engineering fundamentals, this would allow me to standup something relatively quickly but also provides a pretty solid foundation to build from longer term.&lt;/p&gt;\n\n&lt;p&gt;The other option I&amp;#39;m now entertaining through is just using ADF to fire straight into something like Azure SQL and serving PowerBI from there. It would be cheaper than databricks or snowflake for sure and I believe dbt has a community adapter for it that I can explore too.&lt;/p&gt;\n\n&lt;p&gt;Question is, if I have the budget, would the first option (snowflake, Databricks) be more sensible as it should save me time to focus on other things and likely be a better longer term solution should data volumes start to scale or am I am I succumbing to the tempation of MDS?&lt;/p&gt;\n\n&lt;p&gt;If anyone has experience in these types of trade offs or the products themselves, I&amp;#39;d love to hear it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=32add54efce28cc8ce035c5e2bc89a27286a815e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dfb00ece05340570177df7cfa1af6d2737c0910b", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8b0b87b868f6cd6313e2c90975dac636e4a0412", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=2a3ad7ec2ccc57b6c65b17e2b57647a81f335039", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d4a8ca64b391e8b057408067d77f503752c29b7e", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=4efb20a46b5cee58042da74830ee914d1547236c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=83e8bea70baef2140842017e967f163a9f530a9d", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=14fb29ce140b35a21a7cc7ee1c4d212ce0b1179d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=533b05085677b48f15004bd7f9ff19ec5b29099f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=6f767b3c289e5cb2a733b24da5f4c46d9c079bc7", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11rbrh1", "is_robot_indexable": true, "report_reasons": null, "author": "KingslyLear", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rbrh1/realistic_stack_for_one_person_to_implement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rbrh1/realistic_stack_for_one_person_to_implement/", "subreddit_subscribers": 93062, "created_utc": 1678813280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a big advocate of Kafka so it is a bit of a surprise when a company that I recently joined has a retrofitted solution of using SNS+SQS in their stack to achieve what Kafka offers out of the box. In your opinion what is the advantage of using that? AFAIK Kafka provides everything that the company needs and it is not that hard to setup these days with confluent cloud or MSK.", "author_fullname": "t2_8n43xmar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SNS/SQS vs Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r01xo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678780215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a big advocate of Kafka so it is a bit of a surprise when a company that I recently joined has a retrofitted solution of using SNS+SQS in their stack to achieve what Kafka offers out of the box. In your opinion what is the advantage of using that? AFAIK Kafka provides everything that the company needs and it is not that hard to setup these days with confluent cloud or MSK.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r01xo", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-River1467", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r01xo/snssqs_vs_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r01xo/snssqs_vs_kafka/", "subreddit_subscribers": 93062, "created_utc": 1678780215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i prefer to keep numbers as numbers instead of varchar.  but everyone is obsessed with keeping leading zeros for their id's.\n\nwhat's the logic here?", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what do you guys do with leading zeros", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r5rdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678799590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i prefer to keep numbers as numbers instead of varchar.  but everyone is obsessed with keeping leading zeros for their id&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;what&amp;#39;s the logic here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r5rdw", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r5rdw/what_do_you_guys_do_with_leading_zeros/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r5rdw/what_do_you_guys_do_with_leading_zeros/", "subreddit_subscribers": 93062, "created_utc": 1678799590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know everyone is different but I\u2019m interested to see what jobs most of the Data Engineers in this sub have stopped at along the way to the posit hey are in now.\n\nExample: Help desk -&gt; ? -&gt; ? -&gt; Data engineer(junior/senior/etc\u2026)", "author_fullname": "t2_bygsfu8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What has been your career path?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rm2wy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678854673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know everyone is different but I\u2019m interested to see what jobs most of the Data Engineers in this sub have stopped at along the way to the posit hey are in now.&lt;/p&gt;\n\n&lt;p&gt;Example: Help desk -&amp;gt; ? -&amp;gt; ? -&amp;gt; Data engineer(junior/senior/etc\u2026)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11rm2wy", "is_robot_indexable": true, "report_reasons": null, "author": "AJohnM_IT", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rm2wy/what_has_been_your_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rm2wy/what_has_been_your_career_path/", "subreddit_subscribers": 93062, "created_utc": 1678854673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I recently switched to a data engineering position after spending 4 years in data science. It has been 6 months since I joined this new role, and I have noticed that my job is completely technical. All decisions regarding the project are made by the project owner in coordination with the lead developer. I receive a ticket with a vague description of what should be achieved, and it is my responsibility to figure out the details and do the implementation.\n\nI am wondering if this is typical for a data engineering position? I expected more collaboration and involvement in the decision-making process. Is it common for data engineers to be given vague instructions and left to figure out the details on their own?\n\nI would appreciate any insights or experiences you could share on this topic. Thank you in advance for your help.", "author_fullname": "t2_72y83w8x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collaboration and decision making as a data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1ws5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678787248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently switched to a data engineering position after spending 4 years in data science. It has been 6 months since I joined this new role, and I have noticed that my job is completely technical. All decisions regarding the project are made by the project owner in coordination with the lead developer. I receive a ticket with a vague description of what should be achieved, and it is my responsibility to figure out the details and do the implementation.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if this is typical for a data engineering position? I expected more collaboration and involvement in the decision-making process. Is it common for data engineers to be given vague instructions and left to figure out the details on their own?&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any insights or experiences you could share on this topic. Thank you in advance for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11r1ws5", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Sun_3031", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1ws5/collaboration_and_decision_making_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r1ws5/collaboration_and_decision_making_as_a_data/", "subreddit_subscribers": 93062, "created_utc": 1678787248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've been working on this for a while now, a completely unbiased, peer-built, crowd-sourced data stack assembly wizard to make sense of the data tooling landscape.\n\n[**https://stackwizard.com**](https://stackwizard.com)\n\nWe approached the project intending to shorten the time needed for feature mapping and integration compatibility when evaluating new data stack components. Google searches, combing through documentation, and sitting through demos just to see if a tool is compatible seem to take so much time.\n\nAll you have to do is choose a data tool category, select your requirements, and StackWizard will instantly rank currently available, pre-investigated, data tools - producing a \\*\\*100% unbiased\\*\\* ranking, based only on your individual requirements. Total time &lt;60 seconds.\n\nCurrently mapped categories are data governance &amp; access, data lakes, data observability, data quality, data warehouses, management &amp; monitoring, ETL, and reverse ETL.\n\nQuery engines, rdbs, BI platforms, NoSQL, NewSQL, and visualization tools will be online next.\n\nSince this is from all of us, for all of us, we would sincerely appreciate all thoughts and feedback in order to make it even better and more effective.", "author_fullname": "t2_ff7f8okm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "StackWizard is finalllllly live! Seeking thoughts and all feedback.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rjmo9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678849794.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678847878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been working on this for a while now, a completely unbiased, peer-built, crowd-sourced data stack assembly wizard to make sense of the data tooling landscape.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://stackwizard.com\"&gt;&lt;strong&gt;https://stackwizard.com&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We approached the project intending to shorten the time needed for feature mapping and integration compatibility when evaluating new data stack components. Google searches, combing through documentation, and sitting through demos just to see if a tool is compatible seem to take so much time.&lt;/p&gt;\n\n&lt;p&gt;All you have to do is choose a data tool category, select your requirements, and StackWizard will instantly rank currently available, pre-investigated, data tools - producing a **100% unbiased** ranking, based only on your individual requirements. Total time &amp;lt;60 seconds.&lt;/p&gt;\n\n&lt;p&gt;Currently mapped categories are data governance &amp;amp; access, data lakes, data observability, data quality, data warehouses, management &amp;amp; monitoring, ETL, and reverse ETL.&lt;/p&gt;\n\n&lt;p&gt;Query engines, rdbs, BI platforms, NoSQL, NewSQL, and visualization tools will be online next.&lt;/p&gt;\n\n&lt;p&gt;Since this is from all of us, for all of us, we would sincerely appreciate all thoughts and feedback in order to make it even better and more effective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11rjmo9", "is_robot_indexable": true, "report_reasons": null, "author": "hesanastronaut", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rjmo9/stackwizard_is_finalllllly_live_seeking_thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rjmo9/stackwizard_is_finalllllly_live_seeking_thoughts/", "subreddit_subscribers": 93062, "created_utc": 1678847878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been working as a data scientist for quite some time but I haven\u2019t been exposed to the practical aspects of deploying a model to a functional application yet. I\u2019m not a software or CS engineer by education but I want to learn techniques like CI/CD, Airflow, Docker/Kubernetes, spark/kafka. Basically tools which will help me figure out how my model fits into the overall application architecture.\n\nLooking for advice regarding what would be the best platforms to learn these.", "author_fullname": "t2_4tw0vacm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn tools and technologies to put my models into production.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ren4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678819509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been working as a data scientist for quite some time but I haven\u2019t been exposed to the practical aspects of deploying a model to a functional application yet. I\u2019m not a software or CS engineer by education but I want to learn techniques like CI/CD, Airflow, Docker/Kubernetes, spark/kafka. Basically tools which will help me figure out how my model fits into the overall application architecture.&lt;/p&gt;\n\n&lt;p&gt;Looking for advice regarding what would be the best platforms to learn these.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11ren4f", "is_robot_indexable": true, "report_reasons": null, "author": "prankh2403", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ren4f/how_to_learn_tools_and_technologies_to_put_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ren4f/how_to_learn_tools_and_technologies_to_put_my/", "subreddit_subscribers": 93062, "created_utc": 1678819509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI have a Spark Glue job that uses jdbc to retrieve data from 10 lake formation tables. I then enter this data into an S3 bucket, use that bucket to create a MySQL query, and then insert that query back into an S3 bucket. The first stage of the Spark task takes longer than 4 hours to finish. Can someone give me some advice on how to optimise it?\n\nAnd in next step, I am using the loaded data to run complex Oracle SQL query for transformation by using Spark Sql, but spark Sql doesn't support a lot of Oracle SQL function and i Don't know how i am going to chnage it.\n\nAnd, i am using the right approach? Please suggest \n\nNote: For the larger databases, I already use Partition and S3 for data appending.", "author_fullname": "t2_a19a2f0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark on Glue for ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r26ob", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678788297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I have a Spark Glue job that uses jdbc to retrieve data from 10 lake formation tables. I then enter this data into an S3 bucket, use that bucket to create a MySQL query, and then insert that query back into an S3 bucket. The first stage of the Spark task takes longer than 4 hours to finish. Can someone give me some advice on how to optimise it?&lt;/p&gt;\n\n&lt;p&gt;And in next step, I am using the loaded data to run complex Oracle SQL query for transformation by using Spark Sql, but spark Sql doesn&amp;#39;t support a lot of Oracle SQL function and i Don&amp;#39;t know how i am going to chnage it.&lt;/p&gt;\n\n&lt;p&gt;And, i am using the right approach? Please suggest &lt;/p&gt;\n\n&lt;p&gt;Note: For the larger databases, I already use Partition and S3 for data appending.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11r26ob", "is_robot_indexable": true, "report_reasons": null, "author": "anurag_pandit1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r26ob/spark_on_glue_for_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r26ob/spark_on_glue_for_etl/", "subreddit_subscribers": 93062, "created_utc": 1678788297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks! There wasn\u2019t a \u201ctools\u201d flair, so hopefully discussion is ok. A couple of us at Materialize have been thinking of ways to make it easier for our users to produce fake data to Kafka and thought this might be useful for others to play with. We built a little datagen CLI that can generate relational data. We hope y\u2019all have fun with it! \n\n- [https://github.com/MaterializeInc/datagen](https://github.com/MaterializeInc/datagen)\n\nThere are existing data generation tools, but they tend either to be inflexible, hard to use, less stream-y more batch-y, don\u2019t generate relational data, or require Kafka Connect.\n\nRelational data is especially important because Materialize specializes in joins. With randomly generated keys, joins will often be empty because that join condition will hardly ever happen, if ever.\n\nHere is a typical example.\n\n```\ndatagen /\n  --schema my-schema.json /\n  --format avro /\n  --number 100\n```\n\nThis takes an input json schema file and produces 100 iterations of Kafka records in Avro format, taking advantage of Schema Registry.\n\nHere is an example json schema input that produces relational data for users, posts, and comments for a fake blog site:\n- [https://github.com/MaterializeInc/datagen/blob/main/examples/blog.json](https://github.com/MaterializeInc/datagen/blob/main/examples/blog.json)\n\nCheck out [https://fakerjs.dev/api/](https://fakerjs.dev/api/) to customize your datasets and let us know of some fun stuff you come up with!", "author_fullname": "t2_5p00kusf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datagen CLI: Stream Fake Relational Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r8hqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678806132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks! There wasn\u2019t a \u201ctools\u201d flair, so hopefully discussion is ok. A couple of us at Materialize have been thinking of ways to make it easier for our users to produce fake data to Kafka and thought this might be useful for others to play with. We built a little datagen CLI that can generate relational data. We hope y\u2019all have fun with it! &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/MaterializeInc/datagen\"&gt;https://github.com/MaterializeInc/datagen&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There are existing data generation tools, but they tend either to be inflexible, hard to use, less stream-y more batch-y, don\u2019t generate relational data, or require Kafka Connect.&lt;/p&gt;\n\n&lt;p&gt;Relational data is especially important because Materialize specializes in joins. With randomly generated keys, joins will often be empty because that join condition will hardly ever happen, if ever.&lt;/p&gt;\n\n&lt;p&gt;Here is a typical example.&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\ndatagen /\n  --schema my-schema.json /\n  --format avro /\n  --number 100\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;This takes an input json schema file and produces 100 iterations of Kafka records in Avro format, taking advantage of Schema Registry.&lt;/p&gt;\n\n&lt;p&gt;Here is an example json schema input that produces relational data for users, posts, and comments for a fake blog site:\n- &lt;a href=\"https://github.com/MaterializeInc/datagen/blob/main/examples/blog.json\"&gt;https://github.com/MaterializeInc/datagen/blob/main/examples/blog.json&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Check out &lt;a href=\"https://fakerjs.dev/api/\"&gt;https://fakerjs.dev/api/&lt;/a&gt; to customize your datasets and let us know of some fun stuff you come up with!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?auto=webp&amp;v=enabled&amp;s=9c12cb51df876c88f2cf05c19e6b68c68b723356", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0212ae688898bf17d80d7fab732502c0d826ff3b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cbee5741c5ab9fc49f4121390b0262e303199d5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bef8a2b2ecb290c3c5685f06a4d2ff3c25fc39b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fb57c803dc04e61f5880c3df1969e62b20e6779", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d97e3f92a11158bfa8d98e0bbef3f02d211c750a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Nx8-lRu-7pkUstp5M7dtzR296VsUBRd05aPVqyWt0Oo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49bccaed9c9268cd6f3fd663be2b28e524434595", "width": 1080, "height": 540}], "variants": {}, "id": "8Lb7tWp9fKuz-piShWXccpGbf7rPEFAydRsqX5IjAJw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11r8hqq", "is_robot_indexable": true, "report_reasons": null, "author": "Chuck-Alt-Delete", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r8hqq/datagen_cli_stream_fake_relational_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r8hqq/datagen_cli_stream_fake_relational_data/", "subreddit_subscribers": 93062, "created_utc": 1678806132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ffabopog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Release 0.3.2 of qbeast-spark!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1rvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vLGM2nBY967FIk5MwT_I8a3evKVU2-89wvBv7MzAT50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678786733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?auto=webp&amp;v=enabled&amp;s=40774221d1d7609640287f4898a7ea01362475ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cd2ce838278cab83bb59db8b37b7a83b679c08f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da4f45b435cc24fb8c31eb9d4c9af8ea7985bdf5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d86deeb3c26311d920a94007bc9cdd4916705ab5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcb955610383ca9306a42e5a3855723ff1866135", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06ce954553450a34086d63a9f3eb20e997c929da", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xoaps7fQrGI-RdO9BdALAz-PJ1imQSLUlNAWh8uS9j0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e39fd0e2ac6886df8a0ef789ef67a03da872cbe", "width": 1080, "height": 540}], "variants": {}, "id": "zsPu7xyD_cgcv-Dld3-pRZ9zs0RcGQAHGo8eO30FFac"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11r1rvv", "is_robot_indexable": true, "report_reasons": null, "author": "paolapardo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1rvv/release_032_of_qbeastspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Qbeast-io/qbeast-spark/releases/tag/v0.3.2", "subreddit_subscribers": 93062, "created_utc": 1678786733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIs anyone aware of a downloadable example data warehouse built using Data Vault?\n\nThere are lots of concepts, and I feel like lots of important things that get skimmed over. Examples might include how many hashdiffs in sources if you\u2019re splitting into multiple satellites? How to handle source tables that join when the join isn\u2019t a business key? If a customer table has a created by and modified by field, does this mean the satellite will sit off a link between customer and team member (twice), or is it still just coming off the customer hub? etc.\n\nIn the Microsoft world there is the Contoso db, and the Jaffle Shop in dbt land.\n\nI don\u2019t really care about the technology - Postgres, MS SQL etc., but I do care about the examples of how it\u2019s actually put together.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault example db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qzdxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678780571.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678777707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of a downloadable example data warehouse built using Data Vault?&lt;/p&gt;\n\n&lt;p&gt;There are lots of concepts, and I feel like lots of important things that get skimmed over. Examples might include how many hashdiffs in sources if you\u2019re splitting into multiple satellites? How to handle source tables that join when the join isn\u2019t a business key? If a customer table has a created by and modified by field, does this mean the satellite will sit off a link between customer and team member (twice), or is it still just coming off the customer hub? etc.&lt;/p&gt;\n\n&lt;p&gt;In the Microsoft world there is the Contoso db, and the Jaffle Shop in dbt land.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really care about the technology - Postgres, MS SQL etc., but I do care about the examples of how it\u2019s actually put together.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11qzdxo", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11qzdxo/data_vault_example_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11qzdxo/data_vault_example_db/", "subreddit_subscribers": 93062, "created_utc": 1678777707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nHave a question regarding mapping a nested structure into a dimension table. We have `movie_watch_events` and corresponding `movie_details` data. The fact table would have `movie_id`.  The movie\\_details document however has genre which is a nested structure, i.e. a movie can belong to multiple genres. \n\n    {\n        movie_id : 13,\n    movie_name : &lt;name&gt;,\n    genre : [{ genre_id: 1,\n                      genre_name: 'drama',\n                       } , ...]\n      ....\n    }\n\nIn such a case, what are the rules to be followed to create a dimension table for movies having this genre information mapped out?\n\n&amp;#x200B;\n\nTIA", "author_fullname": "t2_a40fenez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Star Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rmybj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678857487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;Have a question regarding mapping a nested structure into a dimension table. We have &lt;code&gt;movie_watch_events&lt;/code&gt; and corresponding &lt;code&gt;movie_details&lt;/code&gt; data. The fact table would have &lt;code&gt;movie_id&lt;/code&gt;.  The movie_details document however has genre which is a nested structure, i.e. a movie can belong to multiple genres. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n    movie_id : 13,\nmovie_name : &amp;lt;name&amp;gt;,\ngenre : [{ genre_id: 1,\n                  genre_name: &amp;#39;drama&amp;#39;,\n                   } , ...]\n  ....\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In such a case, what are the rules to be followed to create a dimension table for movies having this genre information mapped out?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11rmybj", "is_robot_indexable": true, "report_reasons": null, "author": "puzzled-cognition", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rmybj/star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rmybj/star_schema/", "subreddit_subscribers": 93062, "created_utc": 1678857487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nFor context, I'm a bit of a novice engineer. I am the first data hire at my new company and have read access to a remote replica production MySQL database along prod access to my own instance of MySQL, both are hosted on AWS. I'm trying to migrate the data from the replica to my own instance, but they are pulling from and loading to two separate database/schema names, which the migration wizard in mysql workbench doesnt seem to allow me to do. I dont have permissions to create new schemas or dbs in my personal instance, so I'm not sure if there is a workaround here. \n\nWhat would the best approach be for something like this? \n\nThank you!", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help migrating data from one instance of MySQL to another", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rixna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678846222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m a bit of a novice engineer. I am the first data hire at my new company and have read access to a remote replica production MySQL database along prod access to my own instance of MySQL, both are hosted on AWS. I&amp;#39;m trying to migrate the data from the replica to my own instance, but they are pulling from and loading to two separate database/schema names, which the migration wizard in mysql workbench doesnt seem to allow me to do. I dont have permissions to create new schemas or dbs in my personal instance, so I&amp;#39;m not sure if there is a workaround here. &lt;/p&gt;\n\n&lt;p&gt;What would the best approach be for something like this? &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11rixna", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rixna/need_help_migrating_data_from_one_instance_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rixna/need_help_migrating_data_from_one_instance_of/", "subreddit_subscribers": 93062, "created_utc": 1678846222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_79p1h62w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do You Think You Have What It Takes to Be a Successful Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 49, "top_awarded_type": null, "hide_score": false, "name": "t3_11rn3rj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/h4C6BO3HUiTYVxeTWGxjZPzS4FChBbaZ4ZpwoTZ4udw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678857995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mircari.co.uk", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://mircari.co.uk/do-you-think-you-have-what-it-takes-to-be-a-successful-data-engineer/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?auto=webp&amp;v=enabled&amp;s=74ae59cd7e56e3c6a54b7e25e478fe94df05eea7", "width": 1140, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a6f27daad7c4daaa83ba87f72387960c88380c6", "width": 108, "height": 37}, {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=234588ea7bb4996025f64338adc3bc91e4fcb6b3", "width": 216, "height": 75}, {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e5f062e669ed6d8d9fb8d713e6830378660b5119", "width": 320, "height": 112}, {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d89e166f1cfaf6bcb12e72b5ee7446abb9b12389", "width": 640, "height": 224}, {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11ba4af40f6300d74ab9d2b46ea4b72c9b7274ce", "width": 960, "height": 336}, {"url": "https://external-preview.redd.it/PuzC8_Js8tCWn9gHLOz2r78Y_DeFjVSIUOpemZdpb38.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a1df8928edd4f7eb711d93deaeaa0e74035056e", "width": 1080, "height": 378}], "variants": {}, "id": "lES-231vtHlMgOEL-hyTpvTlVAMSEvkyJDTKtDNovew"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11rn3rj", "is_robot_indexable": true, "report_reasons": null, "author": "Shradha_Singh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rn3rj/do_you_think_you_have_what_it_takes_to_be_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mircari.co.uk/do-you-think-you-have-what-it-takes-to-be-a-successful-data-engineer/", "subreddit_subscribers": 93062, "created_utc": 1678857995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4mcloivn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CNCF V6d: Zero-Copy In-Memory Sharing of Large (Distributed) Immutable Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1ysy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ommIxXhOwG222qnjLx6sMKQw4JhQvjIZTFtUr5df4Ts.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678787477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "infoq.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.infoq.com/news/2023/03/zero-copy-v6d/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?auto=webp&amp;v=enabled&amp;s=ddfcbe3b1ae5a7fe4f552123b0c61dcbcd39548a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2c8027d53fbf771ae38279d4a9a58d6535d2679", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3717aa4d9e6b38c3a3b586a23ab7e8289c031d4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d747347e39ad4a2ab83c394b4e22ea989ea873f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fb08955324624c3b8fd9258c82a743dcbe1e19e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d523e063be20e74b3ae6111ffe137a01feda2f6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/HDLLP_IlHg-5H-4EFJR3U1JHkfGTs-Lb04S2tZA5i1k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bdd8a330d21ebde844bc830eddafd56ef9ab89c", "width": 1080, "height": 567}], "variants": {}, "id": "qV6JvCFADPX8WWVLFXzanKi3Nji5fB-K1tbd5HX4pBg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11r1ysy", "is_robot_indexable": true, "report_reasons": null, "author": "ElrasX", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1ysy/cncf_v6d_zerocopy_inmemory_sharing_of_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.infoq.com/news/2023/03/zero-copy-v6d/", "subreddit_subscribers": 93062, "created_utc": 1678787477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to post here because I am concerned about the jobs marketing today (2023). I hope this is the right place to ask questions about automation and  ETL. Someone told me once that automation can make me lay off quickly. \u2013I was unsure if it was true. I do not mind hearing the reality with the job market....\n\nTo tell you more about myself, I am currently job searching and a pro bono data analyst. Plus, I specialize in Tableau, Python, and ETL. \u2013I hesitate to re-study Airflow and SQL servers to automate my ETL. As you can see, I NEVER have had a paid job, and I have concerns about what the companies are trying to achieve with ETL automation and publishing Tableau simultaneously.\n\nOnce you finish their projects with automation, will you get laid off quickly? If not, I would like to know how the company works with ETL automation and keeps employees longer.\n\nAlso, I would be grateful for an alternative suggestion of what to do next for my future career.\n\nThank you so much.", "author_fullname": "t2_l6g1m3u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will Automation can make me layoff quickly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rd3ti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678816175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to post here because I am concerned about the jobs marketing today (2023). I hope this is the right place to ask questions about automation and  ETL. Someone told me once that automation can make me lay off quickly. \u2013I was unsure if it was true. I do not mind hearing the reality with the job market....&lt;/p&gt;\n\n&lt;p&gt;To tell you more about myself, I am currently job searching and a pro bono data analyst. Plus, I specialize in Tableau, Python, and ETL. \u2013I hesitate to re-study Airflow and SQL servers to automate my ETL. As you can see, I NEVER have had a paid job, and I have concerns about what the companies are trying to achieve with ETL automation and publishing Tableau simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Once you finish their projects with automation, will you get laid off quickly? If not, I would like to know how the company works with ETL automation and keeps employees longer.&lt;/p&gt;\n\n&lt;p&gt;Also, I would be grateful for an alternative suggestion of what to do next for my future career.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11rd3ti", "is_robot_indexable": true, "report_reasons": null, "author": "JustRevolution9686", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rd3ti/will_automation_can_make_me_layoff_quickly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rd3ti/will_automation_can_make_me_layoff_quickly/", "subreddit_subscribers": 93062, "created_utc": 1678816175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nRecently, I have been applying the DE in US for a short while. But the response rate is a little low &lt;3%.\n\nIt is frustrating and I'm not sure it is my problem or the job marketing itself right now.I'm kind of the new grad in the DE role since I was DS before but having some experience with ETL and cloud.", "author_fullname": "t2_4fjdns9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the job marketing right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r8x0u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678807338.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678807072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Recently, I have been applying the DE in US for a short while. But the response rate is a little low &amp;lt;3%.&lt;/p&gt;\n\n&lt;p&gt;It is frustrating and I&amp;#39;m not sure it is my problem or the job marketing itself right now.I&amp;#39;m kind of the new grad in the DE role since I was DS before but having some experience with ETL and cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11r8x0u", "is_robot_indexable": true, "report_reasons": null, "author": "Free-Physics-8294", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r8x0u/how_is_the_job_marketing_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r8x0u/how_is_the_job_marketing_right_now/", "subreddit_subscribers": 93062, "created_utc": 1678807072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I had a piece of content I was working on. I'm an engineer and not a content writer so I would appreciate your feedback :D \n\n \n\nIn today\u2019s dynamic environment, the main data processing steps include: data ingestion from a source, data storage, data transformation, data cleansing, and data validation. After these steps, data can be stored and used in further analyses and data analytics applications.\n\nData analysts are eager to find new ways of processing data since this kind of information always grows in both volume and variety, and data-processing tools are being constantly updated (multiple times every year).\n\n\u200d\n\n##### What Is Data Ingestion?\n\nData ingestion is the process of transporting data from one or more sources to a target site for further processing and analysis. The data can be taken from multiple sources, including data pools, SaaS applications, IoT devices, on-premises databases, etc., and would usually end up in different target environments, including cloud data marts and data warehouses.\n\n\u200d\n\n##### Why Is Data Ingestion Important?\n\nData ingestion reorganizes company data to the desired format and helps ease its usage, especially during the extract, transform, and load (ETL) operations. Tools for data ingestion can both process a variety of data formats while simultaneously reorganizing large volumes of unstructured (raw) data.\n\nOnce data is ingested, organizations can employ analytical tools to get useful BI insights from multiple data sources. Companies can improve their applications and offer different features and services derived from the insights that are produced by ingested data sets. With proper data inputs, businesses can provide data analytics to authorized individuals more efficiently. Additionally, data ingestion brings the data to programs that need the most up-to-date data. For example, real-time data, when applied to the public transport system, can improve its efficiency (fuel consumption and traffic patterns), minimize arrival times, avoid congestion etc.\n\n\u200d\n\n##### How To Best Conduct Data Ingestion?\n\nData ingestion can be done in 3 different ways. More specifically, this can be completed through either real-time, batches or a combination of both processes, known otherwise as lambda (or micro-batch approach). Companies can choose one of the three types depending on their business objectives, IT infrastructures, and financial feasibility.\n\n1. **Real-time data ingestion** is the process of the collection and transfer of data from multiple sources in real-time using tools such as change data capture (CDC). CDC continually monitors the transaction logs and moves the changed data without interfering with the database workload. Real-time ingestion is crucial in time-limited use cases, such as power grid monitoring or stock market trading, especially when companies need to react rapidly to new information. Real-time data pipelines are also important in making quick operational decisions and defining actions based on new insights.\n2. **Batch-based data ingestion**, on the other hand, is the process of the collection and transfer of data in batches but in pre-specified time intervals. The ingestion process will collect data based on certain conditions, event triggers, or some forms of logical order. Batch-based ingestion is applicable when companies need to collect specific data on a less rigorous daily basis and or simply don\u2019t need a constant inflow of data for real-time decision-making. An example could be a printed newspaper that collects information over 24 hours and publishes it (part of it) at a certain time.\n3. **Micro-batch ingestion** is a data ingestion process that consists of both real-time and batch methods. The process includes the batch, serving, and speed layers. The first two layers index data in batches, and the speed layer instantly indexes the data that should otherwise be picked up by the slower batch and serving layers. This ongoing data transfer between different layers ensures that data is available for querying with no delay.\n\n \n\n##### The Benefits of Data Ingestion\n\nThese Data ingestion techniques provide various benefits, enabling firms to manage data while also improving their market positions effectively. Some of the advantages include the following:\n\n* Companies can save time and money: Data ingestion automates some of the tasks that are previously done manually by developers. With an automated system in place, however, critical developers can instead dedicate their time to other, more important tasks.\n* Dev-teams can improve their software applications: After implementation, dev-teams can utilize data ingestion techniques to ensure that their applications transfer data quickly and provide a smooth experience directly to the end-users.\n* Data is promptly available: Companies can gather data stored across various servers and move them all together to a unified environment available for immediate access and further analysis.\n* Data simplified: Data ingestion implementation, together with ETL tools, will convert different data types into pre-defined formats and then transfer them to a single data warehouse.\n* Improved decision-making: Real-time data ingestion allows businesses to uncover problems and opportunities on the spot, thereby making the right decisions at the right time.\n\n&amp;#x200B;\n\n \n\n##### The Must-Have Features For 2023 / Incoming Trends in 2023\n\nData ingestion tools can gather and transfer all structured, semi-structured, and unstructured data from multiple sources to target destinations. These tools automate manual ingestion processes and undertake processing steps that move data from one point to another. Other important features to pay attention to in the upcoming period are as follows:\n\n* **Data integration tools:** Traditional data integration platforms incorporate features for every step of the data value chain, and namely, the aforementioned data cleaning, data consolidation, ETL processes, data virtualization, and transfer and storage. They enable a regulated (and secure) flow of simplified data operations through increasing productivity without any processing delays.\n* **AI-powered search**: An AI-Powered Search can bring site visitors what they need right off the spot, and this will help business owners achieve better customer satisfaction, higher conversion rates, and increased revenues. An AI-based search engine will display results that are personalized to individual users based on their profiles, desires, and various other tendencies.\n* **Video-based search**: Implementing automated captions helps people consume media content effectively. With Omnisearch, you can utilize our advanced search functionality to find the exact video you need or navigate the database using filters such as topics, dates, and many more. Additionally, when you search for specific files, Omnisearch automatically tells you the relevance of various files to your search terms; this makes it quick and easy to navigate through your massive database to find and locate exactly what you need.", "author_fullname": "t2_o5qmz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The importance of Data ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r2wf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678790911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I had a piece of content I was working on. I&amp;#39;m an engineer and not a content writer so I would appreciate your feedback :D &lt;/p&gt;\n\n&lt;p&gt;In today\u2019s dynamic environment, the main data processing steps include: data ingestion from a source, data storage, data transformation, data cleansing, and data validation. After these steps, data can be stored and used in further analyses and data analytics applications.&lt;/p&gt;\n\n&lt;p&gt;Data analysts are eager to find new ways of processing data since this kind of information always grows in both volume and variety, and data-processing tools are being constantly updated (multiple times every year).&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;h5&gt;What Is Data Ingestion?&lt;/h5&gt;\n\n&lt;p&gt;Data ingestion is the process of transporting data from one or more sources to a target site for further processing and analysis. The data can be taken from multiple sources, including data pools, SaaS applications, IoT devices, on-premises databases, etc., and would usually end up in different target environments, including cloud data marts and data warehouses.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;h5&gt;Why Is Data Ingestion Important?&lt;/h5&gt;\n\n&lt;p&gt;Data ingestion reorganizes company data to the desired format and helps ease its usage, especially during the extract, transform, and load (ETL) operations. Tools for data ingestion can both process a variety of data formats while simultaneously reorganizing large volumes of unstructured (raw) data.&lt;/p&gt;\n\n&lt;p&gt;Once data is ingested, organizations can employ analytical tools to get useful BI insights from multiple data sources. Companies can improve their applications and offer different features and services derived from the insights that are produced by ingested data sets. With proper data inputs, businesses can provide data analytics to authorized individuals more efficiently. Additionally, data ingestion brings the data to programs that need the most up-to-date data. For example, real-time data, when applied to the public transport system, can improve its efficiency (fuel consumption and traffic patterns), minimize arrival times, avoid congestion etc.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;h5&gt;How To Best Conduct Data Ingestion?&lt;/h5&gt;\n\n&lt;p&gt;Data ingestion can be done in 3 different ways. More specifically, this can be completed through either real-time, batches or a combination of both processes, known otherwise as lambda (or micro-batch approach). Companies can choose one of the three types depending on their business objectives, IT infrastructures, and financial feasibility.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Real-time data ingestion&lt;/strong&gt; is the process of the collection and transfer of data from multiple sources in real-time using tools such as change data capture (CDC). CDC continually monitors the transaction logs and moves the changed data without interfering with the database workload. Real-time ingestion is crucial in time-limited use cases, such as power grid monitoring or stock market trading, especially when companies need to react rapidly to new information. Real-time data pipelines are also important in making quick operational decisions and defining actions based on new insights.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Batch-based data ingestion&lt;/strong&gt;, on the other hand, is the process of the collection and transfer of data in batches but in pre-specified time intervals. The ingestion process will collect data based on certain conditions, event triggers, or some forms of logical order. Batch-based ingestion is applicable when companies need to collect specific data on a less rigorous daily basis and or simply don\u2019t need a constant inflow of data for real-time decision-making. An example could be a printed newspaper that collects information over 24 hours and publishes it (part of it) at a certain time.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Micro-batch ingestion&lt;/strong&gt; is a data ingestion process that consists of both real-time and batch methods. The process includes the batch, serving, and speed layers. The first two layers index data in batches, and the speed layer instantly indexes the data that should otherwise be picked up by the slower batch and serving layers. This ongoing data transfer between different layers ensures that data is available for querying with no delay.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h5&gt;The Benefits of Data Ingestion&lt;/h5&gt;\n\n&lt;p&gt;These Data ingestion techniques provide various benefits, enabling firms to manage data while also improving their market positions effectively. Some of the advantages include the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Companies can save time and money: Data ingestion automates some of the tasks that are previously done manually by developers. With an automated system in place, however, critical developers can instead dedicate their time to other, more important tasks.&lt;/li&gt;\n&lt;li&gt;Dev-teams can improve their software applications: After implementation, dev-teams can utilize data ingestion techniques to ensure that their applications transfer data quickly and provide a smooth experience directly to the end-users.&lt;/li&gt;\n&lt;li&gt;Data is promptly available: Companies can gather data stored across various servers and move them all together to a unified environment available for immediate access and further analysis.&lt;/li&gt;\n&lt;li&gt;Data simplified: Data ingestion implementation, together with ETL tools, will convert different data types into pre-defined formats and then transfer them to a single data warehouse.&lt;/li&gt;\n&lt;li&gt;Improved decision-making: Real-time data ingestion allows businesses to uncover problems and opportunities on the spot, thereby making the right decisions at the right time.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h5&gt;The Must-Have Features For 2023 / Incoming Trends in 2023&lt;/h5&gt;\n\n&lt;p&gt;Data ingestion tools can gather and transfer all structured, semi-structured, and unstructured data from multiple sources to target destinations. These tools automate manual ingestion processes and undertake processing steps that move data from one point to another. Other important features to pay attention to in the upcoming period are as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data integration tools:&lt;/strong&gt; Traditional data integration platforms incorporate features for every step of the data value chain, and namely, the aforementioned data cleaning, data consolidation, ETL processes, data virtualization, and transfer and storage. They enable a regulated (and secure) flow of simplified data operations through increasing productivity without any processing delays.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AI-powered search&lt;/strong&gt;: An AI-Powered Search can bring site visitors what they need right off the spot, and this will help business owners achieve better customer satisfaction, higher conversion rates, and increased revenues. An AI-based search engine will display results that are personalized to individual users based on their profiles, desires, and various other tendencies.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Video-based search&lt;/strong&gt;: Implementing automated captions helps people consume media content effectively. With Omnisearch, you can utilize our advanced search functionality to find the exact video you need or navigate the database using filters such as topics, dates, and many more. Additionally, when you search for specific files, Omnisearch automatically tells you the relevance of various files to your search terms; this makes it quick and easy to navigate through your massive database to find and locate exactly what you need.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11r2wf0", "is_robot_indexable": true, "report_reasons": null, "author": "marin_smiljanic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r2wf0/the_importance_of_data_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11r2wf0/the_importance_of_data_ingestion/", "subreddit_subscribers": 93062, "created_utc": 1678790911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.\n\nTraditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)\n\n[View Poll](https://www.reddit.com/poll/11r1c0z)", "author_fullname": "t2_svzav4ot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1c0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678785050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.&lt;/p&gt;\n\n&lt;p&gt;Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11r1c0z\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r1c0z", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceIntelligent6910", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679389850291, "options": [{"text": "Traditional Data Engineering Approach (Tool Based)", "id": "22056451"}, {"text": "Cloud based Data Engineering Approach (Cloud Services)", "id": "22056452"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 100, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "subreddit_subscribers": 93062, "created_utc": 1678785050.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}