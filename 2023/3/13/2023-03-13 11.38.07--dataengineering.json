{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've heard of a rumor that azure synapse won't be getting any new features, rather azure data factory will be developed further.\n\nDoes anyone have any information on that rumor? \n\nThis would not make any sense to me, as azure synapse is the data warehousing solution within azure. However, I still see ADF getting new features lately.\n\nThanks for your comments.", "author_fullname": "t2_ug93cwsp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Analytics - Development stop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pd7ox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678623494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve heard of a rumor that azure synapse won&amp;#39;t be getting any new features, rather azure data factory will be developed further.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any information on that rumor? &lt;/p&gt;\n\n&lt;p&gt;This would not make any sense to me, as azure synapse is the data warehousing solution within azure. However, I still see ADF getting new features lately.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11pd7ox", "is_robot_indexable": true, "report_reasons": null, "author": "RoleSuspicious6537", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pd7ox/azure_synapse_analytics_development_stop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11pd7ox/azure_synapse_analytics_development_stop/", "subreddit_subscribers": 92878, "created_utc": 1678623494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is data mesh? Architecture and best practice guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 117, "top_awarded_type": null, "hide_score": false, "name": "t3_11pxhjg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hsya157aSJrvTbUdwRUKMoyyr0uQIyxtynuWmPry9vA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678674359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decube.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decube.io/post/what-is-data-mesh-architecture-and-best-practice-guide", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qh_eAQ-56luTPOu8na1eC6xHCqSmUFSRwGD8HpsThZM.jpg?auto=webp&amp;v=enabled&amp;s=9519365fc6e6428f8fbb66e02e3403c94df76dd1", "width": 489, "height": 411}, "resolutions": [{"url": "https://external-preview.redd.it/qh_eAQ-56luTPOu8na1eC6xHCqSmUFSRwGD8HpsThZM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f4925db4f9f7e7b68b02acd9bf371dc23c5eb55", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/qh_eAQ-56luTPOu8na1eC6xHCqSmUFSRwGD8HpsThZM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2fab7b250b0d1fe9c5c6192e62c880d81d975ac7", "width": 216, "height": 181}, {"url": "https://external-preview.redd.it/qh_eAQ-56luTPOu8na1eC6xHCqSmUFSRwGD8HpsThZM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f9ec407adec9c77cd64b0655d4cf5921759fd74", "width": 320, "height": 268}], "variants": {}, "id": "PBjKK5y9PIoBCQ347JXguPfKRk-QjN7xviBOG6DvRVU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11pxhjg", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 14, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pxhjg/what_is_data_mesh_architecture_and_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decube.io/post/what-is-data-mesh-architecture-and-best-practice-guide", "subreddit_subscribers": 92878, "created_utc": 1678674359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm lately learning a lot about AWS products for my upcoming Job. I wondered if cloud service solutions are nowadays really as advanced as they advertise to be. To me it seems that I could basically just build an orchestrated or choreographed microservice infrastructure where everything is glued together with eventbridge and lambdas (I'm aware of the max. 15min execution time limit) from end to end without having to worry about provisioning anything myself.\n\nIs a pure serverless architecture possible nowadays when starting new projects? How would budgeting differ from a pure serverless architecture, compared to an architecture that relies on EC2/EKS/ECS?", "author_fullname": "t2_bc2rrdnd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with complete serverless pipelines on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ppa7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678653988.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678653799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m lately learning a lot about AWS products for my upcoming Job. I wondered if cloud service solutions are nowadays really as advanced as they advertise to be. To me it seems that I could basically just build an orchestrated or choreographed microservice infrastructure where everything is glued together with eventbridge and lambdas (I&amp;#39;m aware of the max. 15min execution time limit) from end to end without having to worry about provisioning anything myself.&lt;/p&gt;\n\n&lt;p&gt;Is a pure serverless architecture possible nowadays when starting new projects? How would budgeting differ from a pure serverless architecture, compared to an architecture that relies on EC2/EKS/ECS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ppa7k", "is_robot_indexable": true, "report_reasons": null, "author": "AndyMacht58", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ppa7k/experience_with_complete_serverless_pipelines_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ppa7k/experience_with_complete_serverless_pipelines_on/", "subreddit_subscribers": 92878, "created_utc": 1678653799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ive been using DuckDB for most of my in memory queries, but have been told that maybe I should consider PySpark. Can anyone tell me what the main difference of the two would be? Right now they seem quite similar and I cant find much info on differences. \n\nAlso im curious if DuckDB also uses parallell/distributed computing when possible. Any insights are welcome thanks!", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB vs. Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pef92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678627297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ive been using DuckDB for most of my in memory queries, but have been told that maybe I should consider PySpark. Can anyone tell me what the main difference of the two would be? Right now they seem quite similar and I cant find much info on differences. &lt;/p&gt;\n\n&lt;p&gt;Also im curious if DuckDB also uses parallell/distributed computing when possible. Any insights are welcome thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11pef92", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pef92/duckdb_vs_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11pef92/duckdb_vs_spark/", "subreddit_subscribers": 92878, "created_utc": 1678627297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.\n\nFor the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.\n\nEvery day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn't. I kept procrastinating.\n\nI was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, \"One last test,\" and that's when I accidentally deleted all my code.\n\nThe main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that's how I lost everything.\n\nI was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn't. Now, I don't even feel like coding anymore.\n\n(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, \"What could go wrong?\")", "author_fullname": "t2_a7urc8tl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's all gone... in a sec", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q1gyr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678686543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.&lt;/p&gt;\n\n&lt;p&gt;For the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.&lt;/p&gt;\n\n&lt;p&gt;Every day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn&amp;#39;t. I kept procrastinating.&lt;/p&gt;\n\n&lt;p&gt;I was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, &amp;quot;One last test,&amp;quot; and that&amp;#39;s when I accidentally deleted all my code.&lt;/p&gt;\n\n&lt;p&gt;The main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that&amp;#39;s how I lost everything.&lt;/p&gt;\n\n&lt;p&gt;I was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn&amp;#39;t. Now, I don&amp;#39;t even feel like coding anymore.&lt;/p&gt;\n\n&lt;p&gt;(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, &amp;quot;What could go wrong?&amp;quot;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11q1gyr", "is_robot_indexable": true, "report_reasons": null, "author": "Taylankab", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q1gyr/its_all_gone_in_a_sec/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q1gyr/its_all_gone_in_a_sec/", "subreddit_subscribers": 92878, "created_utc": 1678686543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to give the Google Data Engineer certification exam and looking for any course that can help my preparation. \nDidn't find any better course in Udemy for this exam. Can anyone please point to a better course apart from documentation. Thanks", "author_fullname": "t2_8h8kwca0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Data Engineer Exam - which course is better", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pdudp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678625535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to give the Google Data Engineer certification exam and looking for any course that can help my preparation. \nDidn&amp;#39;t find any better course in Udemy for this exam. Can anyone please point to a better course apart from documentation. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11pdudp", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Veterinarian-45", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pdudp/gcp_data_engineer_exam_which_course_is_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11pdudp/gcp_data_engineer_exam_which_course_is_better/", "subreddit_subscribers": 92878, "created_utc": 1678625535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bmbzd7qm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Too anxious when pandas decommission df.append() and half my code throws error in prod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_11q33tk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ILSpscr7MvI7cN5IE1UBZc4IFLwIwoXQ6CYmLKdrpV0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678692488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8s9abitm2ina1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?auto=webp&amp;v=enabled&amp;s=4b18febfd595c0a532f871d5496956089e51ec14", "width": 2098, "height": 917}, "resolutions": [{"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36fc5aa7862e0be804ac339e7294d9b484937755", "width": 108, "height": 47}, {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ecf52054765356ce4183d30d85d8a124c7be8b6", "width": 216, "height": 94}, {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f611ae5455e4384faea5456489a1e5ab4cf4c1f3", "width": 320, "height": 139}, {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1088198b5ef5e3ab5f348a3b5dcec8795a3315b3", "width": 640, "height": 279}, {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c06db468c7e38ba2bedd6a5baf4461e4e3698f7", "width": 960, "height": 419}, {"url": "https://preview.redd.it/8s9abitm2ina1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba1911766d7bcae8efda2151427e84a454b47a03", "width": 1080, "height": 472}], "variants": {}, "id": "bF-hGWah9OcAtrEQAfIeY1PNyp-c4lnUAFrwiK5Oh-U"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "11q33tk", "is_robot_indexable": true, "report_reasons": null, "author": "Apprehensive_Bad_818", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q33tk/too_anxious_when_pandas_decommission_dfappend_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8s9abitm2ina1.jpg", "subreddit_subscribers": 92878, "created_utc": 1678692488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am quite new in the field and I would like to know where you source new things from the data industry like blogs, videos, persons, etc. Thanks!", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you learn new things?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q2ua4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678691506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am quite new in the field and I would like to know where you source new things from the data industry like blogs, videos, persons, etc. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11q2ua4", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q2ua4/where_do_you_learn_new_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q2ua4/where_do_you_learn_new_things/", "subreddit_subscribers": 92878, "created_utc": 1678691506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I'm one of the contributors to OpenDataDiscovery platform and would like to share a release update and/or introduce you to ODD as well!\n\n&amp;#x200B;\n\nFor the ones who're not familiar, the ODD Platform is an open-source data discovery and observability tool that enables businesses to standardize data collection, improve the compatibility of different data catalogs, augment and expand their data lineage capabilities, and improve the way data quality and observability are implemented.\n\n&amp;#x200B;\n\nSo, the v0.11 release of the ODD Platform introduces the following enhancements:\n\n\\- Metrics: With the implementation of Open Metrics Specification, ODD Platform introduces enhanced Metrics support. Users can ingest metrics for their data entities or dataset fields and observe the last metric values, right within the platform.\n\n\\- Search explanations: It is crucial to understand why a certain entity has appeared in search results. The ODD Platform can now display all user query entries in a specific entity in the Search API.\n\n\\- New Dataset Structure UI: The Dataset Structure UI has been reworked and enhanced, to provide a better experience for users in the Data Discovery phase.\n\n&amp;#x200B;\n\nGet to know about OpenDataDiscovery: [https://opendatadiscovery.org/](https://opendatadiscovery.org/)\n\nSource code: [https://github.com/opendatadiscovery/odd-platform](https://github.com/opendatadiscovery/odd-platform)", "author_fullname": "t2_ttr4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Release 0.11 of OpenDataDiscovery Platform w/ metrics, search explanations &amp; new dataset structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11q5zrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678703954.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678703185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m one of the contributors to OpenDataDiscovery platform and would like to share a release update and/or introduce you to ODD as well!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For the ones who&amp;#39;re not familiar, the ODD Platform is an open-source data discovery and observability tool that enables businesses to standardize data collection, improve the compatibility of different data catalogs, augment and expand their data lineage capabilities, and improve the way data quality and observability are implemented.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So, the v0.11 release of the ODD Platform introduces the following enhancements:&lt;/p&gt;\n\n&lt;p&gt;- Metrics: With the implementation of Open Metrics Specification, ODD Platform introduces enhanced Metrics support. Users can ingest metrics for their data entities or dataset fields and observe the last metric values, right within the platform.&lt;/p&gt;\n\n&lt;p&gt;- Search explanations: It is crucial to understand why a certain entity has appeared in search results. The ODD Platform can now display all user query entries in a specific entity in the Search API.&lt;/p&gt;\n\n&lt;p&gt;- New Dataset Structure UI: The Dataset Structure UI has been reworked and enhanced, to provide a better experience for users in the Data Discovery phase.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Get to know about OpenDataDiscovery: &lt;a href=\"https://opendatadiscovery.org/\"&gt;https://opendatadiscovery.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Source code: &lt;a href=\"https://github.com/opendatadiscovery/odd-platform\"&gt;https://github.com/opendatadiscovery/odd-platform&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11q5zrv", "is_robot_indexable": true, "report_reasons": null, "author": "Haarolean", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q5zrv/release_011_of_opendatadiscovery_platform_w/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q5zrv/release_011_of_opendatadiscovery_platform_w/", "subreddit_subscribers": 92878, "created_utc": 1678703185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have made a script to transform excel workbook and output analysis in one worksheet and a pivot table in the other worksheet. \n\nMy initial thought is as below \n1. Script on lambda function\n2. User upload the excel data to S3 host website, then the data is sent to S3\n3. Once the excel data is landed in S3, it triggers lambda to process the data, and it generates the downloadable link to the user. \n\nI would like to keep the website as an internal tool. So shall I create some limited access user to use this flow. \n\nIt seems I am over complicating this data flow. \ud83e\udd7a", "author_fullname": "t2_pd2piq1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hosting Python data processing scripts on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q4i43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678697795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have made a script to transform excel workbook and output analysis in one worksheet and a pivot table in the other worksheet. &lt;/p&gt;\n\n&lt;p&gt;My initial thought is as below \n1. Script on lambda function\n2. User upload the excel data to S3 host website, then the data is sent to S3\n3. Once the excel data is landed in S3, it triggers lambda to process the data, and it generates the downloadable link to the user. &lt;/p&gt;\n\n&lt;p&gt;I would like to keep the website as an internal tool. So shall I create some limited access user to use this flow. &lt;/p&gt;\n\n&lt;p&gt;It seems I am over complicating this data flow. \ud83e\udd7a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11q4i43", "is_robot_indexable": true, "report_reasons": null, "author": "uk_dataguy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q4i43/hosting_python_data_processing_scripts_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q4i43/hosting_python_data_processing_scripts_on_aws/", "subreddit_subscribers": 92878, "created_utc": 1678697795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working on this issue for the past few years. Here are some resources I find helpful!\n\nSpreadsheets to Python: (I'm an author) [https://blog.trymito.io/automating-spreadsheets-with-python-101/](https://blog.trymito.io/automating-spreadsheets-with-python-101/)\n\nConnecting google sheets to Amazon S3 [https://www.youtube.com/watch?v=ksnrlkY55fI](https://www.youtube.com/watch?v=ksnrlkY55fI)\n\nExcel to google sheets: [https://hevodata.com/learn/sync-excel-to-google-sheets/](https://hevodata.com/learn/sync-excel-to-google-sheets/)\n\nSpreadsheets to Data Warehouse:[https://docs.getdbt.com/blog/moving-spreadsheet-data](https://docs.getdbt.com/blog/moving-spreadsheet-data)", "author_fullname": "t2_7vpi3es9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources on Connecting Spreadsheets to Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q3qwm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678694880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working on this issue for the past few years. Here are some resources I find helpful!&lt;/p&gt;\n\n&lt;p&gt;Spreadsheets to Python: (I&amp;#39;m an author) &lt;a href=\"https://blog.trymito.io/automating-spreadsheets-with-python-101/\"&gt;https://blog.trymito.io/automating-spreadsheets-with-python-101/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Connecting google sheets to Amazon S3 &lt;a href=\"https://www.youtube.com/watch?v=ksnrlkY55fI\"&gt;https://www.youtube.com/watch?v=ksnrlkY55fI&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Excel to google sheets: &lt;a href=\"https://hevodata.com/learn/sync-excel-to-google-sheets/\"&gt;https://hevodata.com/learn/sync-excel-to-google-sheets/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Spreadsheets to Data Warehouse:&lt;a href=\"https://docs.getdbt.com/blog/moving-spreadsheet-data\"&gt;https://docs.getdbt.com/blog/moving-spreadsheet-data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?auto=webp&amp;v=enabled&amp;s=9ff7051f337e335d18563c726d7c244b133f26f4", "width": 5000, "height": 3500}, "resolutions": [{"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=423a950d1ce38a96ec3d95381ba4ba06f8832d06", "width": 108, "height": 75}, {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88c25a286ea85640bd3cb07259c63ea6cbfe83e0", "width": 216, "height": 151}, {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a7eedcb5bf84c9d992b1f3717f71362f6c7d461", "width": 320, "height": 224}, {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f93fd7b09f37f6edca1890c7772ae3885179953d", "width": 640, "height": 448}, {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3ea872b87df9eceff2d292b887f72a4ffb69c6f", "width": 960, "height": 672}, {"url": "https://external-preview.redd.it/whO-tUhkl6k_Jl0DFM1C0ogOq9520RUjbhSlKdCysv0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dcf46e9d404e8246243dac4c10b27d234c2806f", "width": 1080, "height": 756}], "variants": {}, "id": "4Y55QpCpbLy1dJdjtwk3WSaENOBK22AizVs8dftlcFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11q3qwm", "is_robot_indexable": true, "report_reasons": null, "author": "Jake_Stack808", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q3qwm/resources_on_connecting_spreadsheets_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q3qwm/resources_on_connecting_spreadsheets_to_data/", "subreddit_subscribers": 92878, "created_utc": 1678694880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello,\n\nPivoting from java engineering into spark/pyspark. Setting up environments now and researching ropes to train on\n\nI have some experience but while studying,  if anyone has any suggestions, any responses or suggestions are heartfelt appreciated. Beside anything else, some help on a few queries specifically would help immeasurably !\n\n\\- tips on specifics in knowledge bases to impress/ shine things up with.\n\n\\- timeframe to land interviews/positions.\n\n\\- rigorous/ technical demand expected in interviews.\n\n\\- any exciting resume projects of quintessential interview technicalities.\n\nThanks for any thoughts! even if just a glance! :)", "author_fullname": "t2_b356h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyspark interviews/demand", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q0m7s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678683590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Pivoting from java engineering into spark/pyspark. Setting up environments now and researching ropes to train on&lt;/p&gt;\n\n&lt;p&gt;I have some experience but while studying,  if anyone has any suggestions, any responses or suggestions are heartfelt appreciated. Beside anything else, some help on a few queries specifically would help immeasurably !&lt;/p&gt;\n\n&lt;p&gt;- tips on specifics in knowledge bases to impress/ shine things up with.&lt;/p&gt;\n\n&lt;p&gt;- timeframe to land interviews/positions.&lt;/p&gt;\n\n&lt;p&gt;- rigorous/ technical demand expected in interviews.&lt;/p&gt;\n\n&lt;p&gt;- any exciting resume projects of quintessential interview technicalities.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any thoughts! even if just a glance! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11q0m7s", "is_robot_indexable": true, "report_reasons": null, "author": "Kubrickann", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q0m7s/pyspark_interviewsdemand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q0m7s/pyspark_interviewsdemand/", "subreddit_subscribers": 92878, "created_utc": 1678683590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI'm doing a bit of data work querying data from GraphQL, extracting it, and then storing it in a big query.\n\nIs the best way to go about this just to query the data, extract it as a JSON and then upload it to BigQuery?\n\nJust want to see if my method makes sense or if it is sub-optimal.  Thanks!", "author_fullname": "t2_10sshp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GraphQL to BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pe3eh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678626300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing a bit of data work querying data from GraphQL, extracting it, and then storing it in a big query.&lt;/p&gt;\n\n&lt;p&gt;Is the best way to go about this just to query the data, extract it as a JSON and then upload it to BigQuery?&lt;/p&gt;\n\n&lt;p&gt;Just want to see if my method makes sense or if it is sub-optimal.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11pe3eh", "is_robot_indexable": true, "report_reasons": null, "author": "frankOFWGKTA", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pe3eh/graphql_to_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11pe3eh/graphql_to_bigquery/", "subreddit_subscribers": 92878, "created_utc": 1678626300.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\n\nIn **Cassandra** we have just built a complete **Marketing Mix Models Builder** that is currently **100% Free** and requires **NO** credit **card** to be used!\n\nThe only thing you\u2019ll have to worry about it **getting** **your** **dataset** ready (automated Data Pipelines are still for Paid Users Only) and then **we\u2019ll handle literally everything else**.\n\nClick on this link, check the **intro video** and then **start** right away: [Get Started for Free](https://cassandra.app/mmm-builder/)\n\nFor those who don\u2019t know what MMMs are: it\u2019s basically **your best shot** at **optimizing** your **ROI/CPO** after the Cookie Apocalypse.\n\nIn more seriousness here\u2019s a playlist on our Youtube Channel where you can **learn** **more** (in a non-technical way) about it: [Learn everything about MMM](https://www.youtube.com/watch?v=D5424PlFE3Q&amp;list=PLdaWFt7A-Gf0gVU-9ctY_SqKkfYD8Bdob&amp;index=1&amp;ab_channel=Cassandra)\n\nWe\u2019d love to **learn** all **about** **your** **experience** as well as **help you** in case you face any issue so if you want here\u2019s the **Slack Channel** dedicated to both getting **support** and sharing **feedbacks**: [Join us in Slack](https://join.slack.com/t/cassandragruppo/shared_invite/zt-1r0obcxdv-VxLn7tqkX~P3NuNGXDPUqQ)\n\nP.S. It will not always be free, we are just beta-testing it so **hurry up** until it\u2019s still available!", "author_fullname": "t2_e41xekmz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create your Marketing Mix Model (MMM) in 5 Minutes for FREE and train it in Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q3k6w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678694197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!&lt;/p&gt;\n\n&lt;p&gt;In &lt;strong&gt;Cassandra&lt;/strong&gt; we have just built a complete &lt;strong&gt;Marketing Mix Models Builder&lt;/strong&gt; that is currently &lt;strong&gt;100% Free&lt;/strong&gt; and requires &lt;strong&gt;NO&lt;/strong&gt; credit &lt;strong&gt;card&lt;/strong&gt; to be used!&lt;/p&gt;\n\n&lt;p&gt;The only thing you\u2019ll have to worry about it &lt;strong&gt;getting&lt;/strong&gt; &lt;strong&gt;your&lt;/strong&gt; &lt;strong&gt;dataset&lt;/strong&gt; ready (automated Data Pipelines are still for Paid Users Only) and then &lt;strong&gt;we\u2019ll handle literally everything else&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Click on this link, check the &lt;strong&gt;intro video&lt;/strong&gt; and then &lt;strong&gt;start&lt;/strong&gt; right away: &lt;a href=\"https://cassandra.app/mmm-builder/\"&gt;Get Started for Free&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For those who don\u2019t know what MMMs are: it\u2019s basically &lt;strong&gt;your best shot&lt;/strong&gt; at &lt;strong&gt;optimizing&lt;/strong&gt; your &lt;strong&gt;ROI/CPO&lt;/strong&gt; after the Cookie Apocalypse.&lt;/p&gt;\n\n&lt;p&gt;In more seriousness here\u2019s a playlist on our Youtube Channel where you can &lt;strong&gt;learn&lt;/strong&gt; &lt;strong&gt;more&lt;/strong&gt; (in a non-technical way) about it: &lt;a href=\"https://www.youtube.com/watch?v=D5424PlFE3Q&amp;amp;list=PLdaWFt7A-Gf0gVU-9ctY_SqKkfYD8Bdob&amp;amp;index=1&amp;amp;ab_channel=Cassandra\"&gt;Learn everything about MMM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We\u2019d love to &lt;strong&gt;learn&lt;/strong&gt; all &lt;strong&gt;about&lt;/strong&gt; &lt;strong&gt;your&lt;/strong&gt; &lt;strong&gt;experience&lt;/strong&gt; as well as &lt;strong&gt;help you&lt;/strong&gt; in case you face any issue so if you want here\u2019s the &lt;strong&gt;Slack Channel&lt;/strong&gt; dedicated to both getting &lt;strong&gt;support&lt;/strong&gt; and sharing &lt;strong&gt;feedbacks&lt;/strong&gt;: &lt;a href=\"https://join.slack.com/t/cassandragruppo/shared_invite/zt-1r0obcxdv-VxLn7tqkX%7EP3NuNGXDPUqQ\"&gt;Join us in Slack&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;P.S. It will not always be free, we are just beta-testing it so &lt;strong&gt;hurry up&lt;/strong&gt; until it\u2019s still available!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/faBbXPj_RuQZnbbf2TvPm-79muNOYEO8WGRSyga6nTY.jpg?auto=webp&amp;v=enabled&amp;s=b0acb1ab4f82ffae35da3f3ab1aa7e9b5aa2f0a4", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/faBbXPj_RuQZnbbf2TvPm-79muNOYEO8WGRSyga6nTY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbfd1024c04eac3723f5f71e0cc87d01fffd2a63", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/faBbXPj_RuQZnbbf2TvPm-79muNOYEO8WGRSyga6nTY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b024a66e89c2a3ee67a9c0206cef80cc91ec5456", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/faBbXPj_RuQZnbbf2TvPm-79muNOYEO8WGRSyga6nTY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f95013039692cec88a1c9ed216a9dcf36dcccb69", "width": 320, "height": 320}], "variants": {}, "id": "q-LMINqw2iYxbMyE58dud27QZsdoKvlbx0SoB6o1r0Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "11q3k6w", "is_robot_indexable": true, "report_reasons": null, "author": "Cristian_Nozzi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11q3k6w/create_your_marketing_mix_model_mmm_in_5_minutes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11q3k6w/create_your_marketing_mix_model_mmm_in_5_minutes/", "subreddit_subscribers": 92878, "created_utc": 1678694197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I get data for millions of records monthly from stores, and looking to map the store name to a consistent output. Ex:\n\nWalgreens Store #123  \nEast River Walgreens  \nWlgreens Store #234  \nAcme (Next to Walgreens)  \n\n\nI'd like to create a column next to it with standardized outputs\n\nWalgreens Store #123 -&gt;Walgreens  \nEast River Walgreens -&gt; Walgreens  \nWlgreens Store #234 -&gt; Walgreens  \nAcme (Next to Walgreens) -&gt;Acme  \n\n\nIn a prior company 10+ years ago we used a tool called Oracle Data Lens that would be pretty robust at identifying misspellings (you'd click on the word an associate it to the correct spelling, then would create logic to identify it (\"If Text Walgreens then Walgreens\") (\"If Text \"next to X\" then blank\").  Is there a more modern product to do this?\n\n&amp;#x200B;\n\nNote this is a simplified example, but the data would be consistent.  Using just regular expressions in a massive sp is not an ideal solution", "author_fullname": "t2_17hbdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to map text in field to a collection to create rollups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11psw9x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678662325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get data for millions of records monthly from stores, and looking to map the store name to a consistent output. Ex:&lt;/p&gt;\n\n&lt;p&gt;Walgreens Store #123&lt;br/&gt;\nEast River Walgreens&lt;br/&gt;\nWlgreens Store #234&lt;br/&gt;\nAcme (Next to Walgreens)  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to create a column next to it with standardized outputs&lt;/p&gt;\n\n&lt;p&gt;Walgreens Store #123 -&amp;gt;Walgreens&lt;br/&gt;\nEast River Walgreens -&amp;gt; Walgreens&lt;br/&gt;\nWlgreens Store #234 -&amp;gt; Walgreens&lt;br/&gt;\nAcme (Next to Walgreens) -&amp;gt;Acme  &lt;/p&gt;\n\n&lt;p&gt;In a prior company 10+ years ago we used a tool called Oracle Data Lens that would be pretty robust at identifying misspellings (you&amp;#39;d click on the word an associate it to the correct spelling, then would create logic to identify it (&amp;quot;If Text Walgreens then Walgreens&amp;quot;) (&amp;quot;If Text &amp;quot;next to X&amp;quot; then blank&amp;quot;).  Is there a more modern product to do this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note this is a simplified example, but the data would be consistent.  Using just regular expressions in a massive sp is not an ideal solution&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11psw9x", "is_robot_indexable": true, "report_reasons": null, "author": "tavada34891", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11psw9x/tool_to_map_text_in_field_to_a_collection_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11psw9x/tool_to_map_text_in_field_to_a_collection_to/", "subreddit_subscribers": 92878, "created_utc": 1678662325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi experts,\n\nI searched through the doc but couldn't find how to set timeouts for individual tasks. Any idea?\n\nThanks!", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt: How to set timeouts for Airflow tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pjqtw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678640912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi experts,&lt;/p&gt;\n\n&lt;p&gt;I searched through the doc but couldn&amp;#39;t find how to set timeouts for individual tasks. Any idea?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11pjqtw", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11pjqtw/dbt_how_to_set_timeouts_for_airflow_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11pjqtw/dbt_how_to_set_timeouts_for_airflow_tasks/", "subreddit_subscribers": 92878, "created_utc": 1678640912.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}