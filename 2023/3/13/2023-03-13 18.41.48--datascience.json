{"kind": "Listing", "data": {"after": "t3_11qa65r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all! I'm a data scientist who has shifted career from the biomedical field - now working at a tech company. It was hard to learn data science skills, to showcase them when applying to jobs and to stand out.\n\nThat's why I created [datascienceportfol.io](https://www.datascienceportfol.io/) \\- it's a platform that allows you to create your own portfolio website, to showcase your projects, education, experience, etc in an effective way (and recruiter-friendly, unlike github). Many people have registered and added projects already - you can browse them if you need some inspiration!\n\nIt's 100% free!\n\nI hope it can be useful for anyone looking for a data job - I'm still adding features every week, so any feedback or questions are \\*very\\* welcome! :)\n\nThank you!", "author_fullname": "t2_2yrisv6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a platform that lets you showcase your data projects in a beautiful portfolio website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q8v1x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 199, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 199, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678711924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! I&amp;#39;m a data scientist who has shifted career from the biomedical field - now working at a tech company. It was hard to learn data science skills, to showcase them when applying to jobs and to stand out.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why I created &lt;a href=\"https://www.datascienceportfol.io/\"&gt;datascienceportfol.io&lt;/a&gt; - it&amp;#39;s a platform that allows you to create your own portfolio website, to showcase your projects, education, experience, etc in an effective way (and recruiter-friendly, unlike github). Many people have registered and added projects already - you can browse them if you need some inspiration!&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s 100% free!&lt;/p&gt;\n\n&lt;p&gt;I hope it can be useful for anyone looking for a data job - I&amp;#39;m still adding features every week, so any feedback or questions are *very* welcome! :)&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q8v1x", "is_robot_indexable": true, "report_reasons": null, "author": "pasqpasq", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q8v1x/i_created_a_platform_that_lets_you_showcase_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q8v1x/i_created_a_platform_that_lets_you_showcase_your/", "subreddit_subscribers": 856746, "created_utc": 1678711924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It's really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.\n\nFor the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.\n\nEvery day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn't. I kept procrastinating.\n\nI was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, \"One last test,\" and that's when I accidentally deleted all my code.\n\nThe main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that's how I lost everything.\n\nI was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn't. Now, I don't even feel like coding anymore.\n\n(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, \"What could go wrong?\")", "author_fullname": "t2_a7urc8tl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost it all.... in a sec!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q1hz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678686643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.&lt;/p&gt;\n\n&lt;p&gt;For the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.&lt;/p&gt;\n\n&lt;p&gt;Every day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn&amp;#39;t. I kept procrastinating.&lt;/p&gt;\n\n&lt;p&gt;I was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, &amp;quot;One last test,&amp;quot; and that&amp;#39;s when I accidentally deleted all my code.&lt;/p&gt;\n\n&lt;p&gt;The main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that&amp;#39;s how I lost everything.&lt;/p&gt;\n\n&lt;p&gt;I was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn&amp;#39;t. Now, I don&amp;#39;t even feel like coding anymore.&lt;/p&gt;\n\n&lt;p&gt;(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, &amp;quot;What could go wrong?&amp;quot;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q1hz2", "is_robot_indexable": true, "report_reasons": null, "author": "Taylankab", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q1hz2/lost_it_all_in_a_sec/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q1hz2/lost_it_all_in_a_sec/", "subreddit_subscribers": 856746, "created_utc": 1678686643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been reading through the Reddit and see that a lot of people that are self-taught in data science have had success in getting interviews and job offers. I have a Bachelor\u2019s in Mathematics, but am self-taught in Data Science and I\u2019ve been actively applying to jobs for almost 5 months. I\u2019ve only been able to get 2 interviews and an inbox full of rejection emails. Also, most of the entry-level data science job posts I see require a Master\u2019s or PhD, which I don\u2019t have. I\u2019m constantly learning more to improve my skills and have applied my skills to a couple of projects. Although I do think that think that I could do more projects, I feel that my resume is pretty solid. So my question is what can I do to land more interviews? Any advice would be greatly appreciated.", "author_fullname": "t2_92wfg960", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science job without Masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11prj6u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678659096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been reading through the Reddit and see that a lot of people that are self-taught in data science have had success in getting interviews and job offers. I have a Bachelor\u2019s in Mathematics, but am self-taught in Data Science and I\u2019ve been actively applying to jobs for almost 5 months. I\u2019ve only been able to get 2 interviews and an inbox full of rejection emails. Also, most of the entry-level data science job posts I see require a Master\u2019s or PhD, which I don\u2019t have. I\u2019m constantly learning more to improve my skills and have applied my skills to a couple of projects. Although I do think that think that I could do more projects, I feel that my resume is pretty solid. So my question is what can I do to land more interviews? Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11prj6u", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Dog-6110", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11prj6u/data_science_job_without_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11prj6u/data_science_job_without_masters/", "subreddit_subscribers": 856746, "created_utc": 1678659096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm a data analyst with 3 years of experience who's current job description ranges from writing queries, building pipelines in python, doing analyses in notebooks, to operating in a separate analytical platform. I still am growing as a DA and perhaps if I stuck with it, eventually I wouldn't be so overwhelmed, but I'm just tired. I'm really tired. \n\nEvery day I have to learn 50 new things (so that I can filter for x in a query or consider y in a conclusion), and the best I can to learn 5-10 of them. My boss says this is normal. \n\nI make a decent salary and actually am not too dissatisfied with my work, but am absolutely miserable outside it because my brain is fried 100% of the time. \n\nAnyway, I could keep complaining but \n\nTLDR, does anyone know of slower-paced careers or industries that I could easily transition to? Don't mind making less.", "author_fullname": "t2_eyp35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simpler Alternatives to Anything Data/Tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pqutu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678657544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a data analyst with 3 years of experience who&amp;#39;s current job description ranges from writing queries, building pipelines in python, doing analyses in notebooks, to operating in a separate analytical platform. I still am growing as a DA and perhaps if I stuck with it, eventually I wouldn&amp;#39;t be so overwhelmed, but I&amp;#39;m just tired. I&amp;#39;m really tired. &lt;/p&gt;\n\n&lt;p&gt;Every day I have to learn 50 new things (so that I can filter for x in a query or consider y in a conclusion), and the best I can to learn 5-10 of them. My boss says this is normal. &lt;/p&gt;\n\n&lt;p&gt;I make a decent salary and actually am not too dissatisfied with my work, but am absolutely miserable outside it because my brain is fried 100% of the time. &lt;/p&gt;\n\n&lt;p&gt;Anyway, I could keep complaining but &lt;/p&gt;\n\n&lt;p&gt;TLDR, does anyone know of slower-paced careers or industries that I could easily transition to? Don&amp;#39;t mind making less.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11pqutu", "is_robot_indexable": true, "report_reasons": null, "author": "Vlad67", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11pqutu/simpler_alternatives_to_anything_datatech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11pqutu/simpler_alternatives_to_anything_datatech/", "subreddit_subscribers": 856746, "created_utc": 1678657544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, \n\nRecently I increasingly came across unit testing for data science projects. So far I am roughly familiar with the concept, even though we are not using it at all in the whole department. I would like to properly set up a unit testing framework for my department, especially because we have a lot of stats heavy and code light people in our team. \n\nOne thing I haven't properly understood yet, we are working with quite an amount of data which is normally a piece of garbage and we have to do a lot of preprocessing in order to make it clean. How would you set up in such an environment (very long runtimes for data preparation due to large data) a unit testing framework, since I can not run multiple parameter settings to test somethings because it will just take too long.\n\nThanks a lot in advance, this post here should not only be an question but more a discussion of unit testing in general. \n\nPaul", "author_fullname": "t2_60p6w78m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unit Testing for Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q3qa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678694815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;Recently I increasingly came across unit testing for data science projects. So far I am roughly familiar with the concept, even though we are not using it at all in the whole department. I would like to properly set up a unit testing framework for my department, especially because we have a lot of stats heavy and code light people in our team. &lt;/p&gt;\n\n&lt;p&gt;One thing I haven&amp;#39;t properly understood yet, we are working with quite an amount of data which is normally a piece of garbage and we have to do a lot of preprocessing in order to make it clean. How would you set up in such an environment (very long runtimes for data preparation due to large data) a unit testing framework, since I can not run multiple parameter settings to test somethings because it will just take too long.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance, this post here should not only be an question but more a discussion of unit testing in general. &lt;/p&gt;\n\n&lt;p&gt;Paul&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q3qa5", "is_robot_indexable": true, "report_reasons": null, "author": "Habenzu", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q3qa5/unit_testing_for_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q3qa5/unit_testing_for_big_data/", "subreddit_subscribers": 856746, "created_utc": 1678694815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing confidenceinterval, the long missing python library for computing confidence intervals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q5bps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_k8k9b", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "[https://github.com/jacobgil/confidenceinterval](https://github.com/jacobgil/confidenceinterval)\n\npip install confidenceinterval\n\ntldr: You don't have an excuse anymore to not use confidence intervals !\n\n&amp;#x200B;\n\nIn statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.\n\nFor example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range \\[0.7, 0.96\\], we can't confidently say we didn't just get lucky - we should be really careful making decisions around that result.\n\nMore formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.\n\nConfidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.\n\nHowever, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don't come from the statistics world. But I think the main reason is that there aren't easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.\n\n&amp;#x200B;\n\nThe confidenceinterval package keeps the clean and popular scikit-learn metric API,\n\ne.g roc\\_auc\\_score(y\\_true, y\\_pred), but also returns confidence intervals.\n\nIt supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2), or binary proportions like the TPR using binomial CI methods like the wilson interval).\n\nIt can be easily switched to using bootstrapping (with several supported bootstrapping methods),\n\nand also gives you a way to easily compute the confidence interval for any metric with bootstrapping.", "author_fullname": "t2_k8k9b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Introducing confidenceinterval, the long missing python library for computing confidence intervals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "four", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11orezx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678561930.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678559767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/jacobgil/confidenceinterval\"&gt;https://github.com/jacobgil/confidenceinterval&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;pip install confidenceinterval&lt;/p&gt;\n\n&lt;p&gt;tldr: You don&amp;#39;t have an excuse anymore to not use confidence intervals !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.&lt;/p&gt;\n\n&lt;p&gt;For example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range [0.7, 0.96], we can&amp;#39;t confidently say we didn&amp;#39;t just get lucky - we should be really careful making decisions around that result.&lt;/p&gt;\n\n&lt;p&gt;More formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.&lt;/p&gt;\n\n&lt;p&gt;Confidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.&lt;/p&gt;\n\n&lt;p&gt;However, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don&amp;#39;t come from the statistics world. But I think the main reason is that there aren&amp;#39;t easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The confidenceinterval package keeps the clean and popular scikit-learn metric API,&lt;/p&gt;\n\n&lt;p&gt;e.g roc_auc_score(y_true, y_pred), but also returns confidence intervals.&lt;/p&gt;\n\n&lt;p&gt;It supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from &lt;a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2\"&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2&lt;/a&gt;, or binary proportions like the TPR using binomial CI methods like the wilson interval).&lt;/p&gt;\n\n&lt;p&gt;It can be easily switched to using bootstrapping (with several supported bootstrapping methods),&lt;/p&gt;\n\n&lt;p&gt;and also gives you a way to easily compute the confidence interval for any metric with bootstrapping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?auto=webp&amp;v=enabled&amp;s=a5d2ecdd7772d8bc508c6c31bf66a3ebf6a36f9b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84265ed517381e53abccab809f4457681fe3c639", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bb99fba7a31874d7c683916fa1cefb7bc3e50b9", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17b19e9c1fe0d262fc2327c44dd600b13b7e0db4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f49c39b998f64942a836cf968ffa02593e39f60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f1484661166648bac2efcb4bb90c0fd6d50b6b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b33e1ea5932c8029ec48c2f1082eca2001226aac", "width": 1080, "height": 540}], "variants": {}, "id": "VEtVW8Q9v0zCOQrmkPZvdkf-myANUJNotk7vDz0TFtA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11orezx", "is_robot_indexable": true, "report_reasons": null, "author": "jacobgil", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "subreddit_subscribers": 2598039, "created_utc": 1678559767.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678700803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?auto=webp&amp;v=enabled&amp;s=a5d2ecdd7772d8bc508c6c31bf66a3ebf6a36f9b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84265ed517381e53abccab809f4457681fe3c639", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bb99fba7a31874d7c683916fa1cefb7bc3e50b9", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17b19e9c1fe0d262fc2327c44dd600b13b7e0db4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f49c39b998f64942a836cf968ffa02593e39f60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f1484661166648bac2efcb4bb90c0fd6d50b6b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b33e1ea5932c8029ec48c2f1082eca2001226aac", "width": 1080, "height": 540}], "variants": {}, "id": "VEtVW8Q9v0zCOQrmkPZvdkf-myANUJNotk7vDz0TFtA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q5bps", "is_robot_indexable": true, "report_reasons": null, "author": "jacobgil", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11orezx", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q5bps/introducing_confidenceinterval_the_long_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "subreddit_subscribers": 856746, "created_utc": 1678700803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " my project about predicting used car prices. \n\nI have done feature selection, and also got the model from gridsearch.\n\n[this a based feature importances](https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb)\n\n&amp;#x200B;\n\n[this is permutation importances](https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719)\n\ni've read an article that permutation importance have disadvantage. \" **If features are correlated, the permutation feature importance** **can be biased by unrealistic data instances** \". Age and mileage  have a correlation of 0.7.\n\nThank You\n\n[https://christophm.github.io/interpretable-ml-book/feature-importance.html](https://christophm.github.io/interpretable-ml-book/feature-importance.html)", "author_fullname": "t2_lzfa50u3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use permutation importance or based feature importance GradientBoostingRegressor sklearn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8n17bm2vzfna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc1d54979f78c2d7658bf5d24b2c19a2c94ea23b"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95848852cf93b9ad4ad51e5a9d39447fca36603b"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=667d02fc49961e3f71d5a13d8f0d4ce56f80f7df"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cad10371dfcdb76ced1332711086141c63a7e73"}, {"y": 677, "x": 960, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c9952cd2b5f8b6ff1493477564e0b3a5beb8b15"}], "s": {"y": 700, "x": 992, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb"}, "id": "8n17bm2vzfna1"}, "oq2chcq20gna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 104, "x": 108, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3208d44c0c3d7c9831abc86a91a255196bde0679"}, {"y": 209, "x": 216, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1ebaf0146fc9811b478c4a214ab25aaa4b521f6"}, {"y": 309, "x": 320, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ea520a8367dfdd0b1014e7636423a2237c00eb7"}, {"y": 619, "x": 640, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41077a3503dafc782e566bd81729d1e4bba235b8"}], "s": {"y": 675, "x": 697, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719"}, "id": "oq2chcq20gna1"}}, "name": "t3_11q1eaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7gNQ40M-aRjKtosn_vjyurTKB4hLCbQxmRgZigDikpk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678686269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my project about predicting used car prices. &lt;/p&gt;\n\n&lt;p&gt;I have done feature selection, and also got the model from gridsearch.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb\"&gt;this a based feature importances&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719\"&gt;this is permutation importances&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;ve read an article that permutation importance have disadvantage. &amp;quot; &lt;strong&gt;If features are correlated, the permutation feature importance&lt;/strong&gt; &lt;strong&gt;can be biased by unrealistic data instances&lt;/strong&gt; &amp;quot;. Age and mileage  have a correlation of 0.7.&lt;/p&gt;\n\n&lt;p&gt;Thank You&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://christophm.github.io/interpretable-ml-book/feature-importance.html\"&gt;https://christophm.github.io/interpretable-ml-book/feature-importance.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q1eaw", "is_robot_indexable": true, "report_reasons": null, "author": "xochaels", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q1eaw/should_i_use_permutation_importance_or_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q1eaw/should_i_use_permutation_importance_or_based/", "subreddit_subscribers": 856746, "created_utc": 1678686269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a pandas dataframe that represents a time series. My time series is segmented over the phase type that the robot is performing (i.e. I have a column with the phase type per timestamp and the phases are known). Some easy examples: if the machine is cleaning something the phase is \"cleaning\", if It is moving the phase is \"moving\".\n\nI have no domain knowledge about the phase in which I am and the constraints in the value that each signal must respect. I am searching for rules with a certain confidence.\n\nI would like to say: I am in this phase, then from the data I have seen in the past, I know that for sure signal A will be less than signal B with 90% confidence. Or again, signal C should not be negative according to what I have seen in the past with 70% confidence. I want to extract historical simple rules that I would like to validate at the end of the process with a domain expert.\n\nIs there any library or method that can handle this type of problem? I didn't find much online. It seems like association rule mining, but I am working on time series and I am looking at time periods spanning the whole phase, so a very long time period.\n\nOtherwise, if I should pass from other methods as correlation/cross-correlation analysis between time series, can you point me out the best analysis I should use? And also explain to me how should I exploit my analysis result for transforming them into more simple rules like the one I have described before.", "author_fullname": "t2_i6lyoywf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mining association rules between time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qcrhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678722322.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678721342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pandas dataframe that represents a time series. My time series is segmented over the phase type that the robot is performing (i.e. I have a column with the phase type per timestamp and the phases are known). Some easy examples: if the machine is cleaning something the phase is &amp;quot;cleaning&amp;quot;, if It is moving the phase is &amp;quot;moving&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I have no domain knowledge about the phase in which I am and the constraints in the value that each signal must respect. I am searching for rules with a certain confidence.&lt;/p&gt;\n\n&lt;p&gt;I would like to say: I am in this phase, then from the data I have seen in the past, I know that for sure signal A will be less than signal B with 90% confidence. Or again, signal C should not be negative according to what I have seen in the past with 70% confidence. I want to extract historical simple rules that I would like to validate at the end of the process with a domain expert.&lt;/p&gt;\n\n&lt;p&gt;Is there any library or method that can handle this type of problem? I didn&amp;#39;t find much online. It seems like association rule mining, but I am working on time series and I am looking at time periods spanning the whole phase, so a very long time period.&lt;/p&gt;\n\n&lt;p&gt;Otherwise, if I should pass from other methods as correlation/cross-correlation analysis between time series, can you point me out the best analysis I should use? And also explain to me how should I exploit my analysis result for transforming them into more simple rules like the one I have described before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qcrhv", "is_robot_indexable": true, "report_reasons": null, "author": "ginotherhino1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qcrhv/mining_association_rules_between_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qcrhv/mining_association_rules_between_time_series/", "subreddit_subscribers": 856746, "created_utc": 1678721342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "They say that your data analytics are only as good as the data you have to analyze.\n\nWhere do I go to find sources of data that I can do analytics on?\n\nIs there a directory for this or something?", "author_fullname": "t2_2cnlo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to Find Data Sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qaqls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They say that your data analytics are only as good as the data you have to analyze.&lt;/p&gt;\n\n&lt;p&gt;Where do I go to find sources of data that I can do analytics on?&lt;/p&gt;\n\n&lt;p&gt;Is there a directory for this or something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qaqls", "is_robot_indexable": true, "report_reasons": null, "author": "sanman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qaqls/where_to_find_data_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qaqls/where_to_find_data_sources/", "subreddit_subscribers": 856746, "created_utc": 1678716553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 13 Mar, 2023 - 20 Mar, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pzhux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678680088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11pzhux", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11pzhux/weekly_entering_transitioning_thread_13_mar_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/11pzhux/weekly_entering_transitioning_thread_13_mar_2023/", "subreddit_subscribers": 856746, "created_utc": 1678680088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! \n\nI work in a company with a two-sided marketplace. One such as doordash or Uber.\n\nComing from an engineering background with stats, I am looking for sources that can help me be better at my job.\n\nI know this might be too ad hoc, but I really think knowledge from economy can help me and make me have a better background for my position.\n\nAny help is welcome!", "author_fullname": "t2_367xvs9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Econ knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qardt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;I work in a company with a two-sided marketplace. One such as doordash or Uber.&lt;/p&gt;\n\n&lt;p&gt;Coming from an engineering background with stats, I am looking for sources that can help me be better at my job.&lt;/p&gt;\n\n&lt;p&gt;I know this might be too ad hoc, but I really think knowledge from economy can help me and make me have a better background for my position.&lt;/p&gt;\n\n&lt;p&gt;Any help is welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qardt", "is_robot_indexable": true, "report_reasons": null, "author": "Quentin-Martell", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qardt/looking_for_econ_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qardt/looking_for_econ_knowledge/", "subreddit_subscribers": 856746, "created_utc": 1678716608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/11qaizm)", "author_fullname": "t2_5njryk22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-ended questions, and do feel free to comment your opinion on the matter below. But do you think that the launch of increasingly \"Smart\" AIs will be seen in the future as akin to the beginning of the industrial revolution (AKA a turning point in history) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qaizm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11qaizm\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11qaizm", "is_robot_indexable": true, "report_reasons": null, "author": "Oldthriftmaan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679148048207, "options": [{"text": "Yes", "id": "22042341"}, {"text": "No", "id": "22042342"}, {"text": "Nuance", "id": "22042343"}, {"text": "Something else (Comment)", "id": "22042344"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 30, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qaizm/openended_questions_and_do_feel_free_to_comment/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/11qaizm/openended_questions_and_do_feel_free_to_comment/", "subreddit_subscribers": 856746, "created_utc": 1678716048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_p54xpfwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turn text into flowcharts with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 135, "top_awarded_type": null, "hide_score": false, "name": "t3_11q8c09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rP99Yi2JpBBcaiRUtJ_8MYW8VNvC3TlKby9Wiq8018k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678710496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kogrkirk2ina1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kogrkirk2ina1.png?auto=webp&amp;v=enabled&amp;s=f4a6b2d85ee45fa3354ef893206d1b1b088b2bf2", "width": 1780, "height": 1728}, "resolutions": [{"url": "https://preview.redd.it/kogrkirk2ina1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6afdfe9b7a667d5bdfff4a63943c7be52d96f02b", "width": 108, "height": 104}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ab5b1c6d61fb094ceb9101b285ae36fdb055769", "width": 216, "height": 209}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2484d4258286164e7070c6d50546927a4ab6db5e", "width": 320, "height": 310}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0504f64ff6c0874f33a8190d475e53e06e4783e5", "width": 640, "height": 621}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1991684d5772469a97270abb46b4e8a4ad3700a", "width": 960, "height": 931}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04fa203c1b43822c47e00730d2b263c35db26ff6", "width": 1080, "height": 1048}], "variants": {}, "id": "lTZ8q2byhJItaaGNdPbIbRcZCU0ORcVZWbaCfMBuWbo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q8c09", "is_robot_indexable": true, "report_reasons": null, "author": "colabDog", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q8c09/turn_text_into_flowcharts_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kogrkirk2ina1.png", "subreddit_subscribers": 856746, "created_utc": 1678710496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4ff830od", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "does anyone know data science collaboration with aerospace industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11qgq9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678730609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qgq9o", "is_robot_indexable": true, "report_reasons": null, "author": "Nethma_peiris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qgq9o/does_anyone_know_data_science_collaboration_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qgq9o/does_anyone_know_data_science_collaboration_with/", "subreddit_subscribers": 856746, "created_utc": 1678730609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an opportunity to acquire $15,000 from a grant, which will cover the cost of data science professional development activities (eg. coursework, workshops, bootcamps, conferences, etc...) There are so many things I could ask for, but I am unsure what the \"best\" use of this grant would be. I'm thinking of applying for a bootcamp like the MIT|xPRO certificate in data science and analytics.\n\nFor background, I have a BS in Computer Science with a data science minor. I am currently working in a \"data\" role that is mostly administrative and does not exercise my technical abilities. I would like to use this funding to **a)** acquire skills/experience that will help me move into a more technical data analytics/science role **b)** prevent my current skills from withering away in this job while I look for work elsewhere. I know a Master's degree would likely be the ultimate use of this funding, but I'm really looking for things I can complete within \\~6 months so I'm not tied down to my current employer for too long (only current employees qualify for reimbursement through the grant award).", "author_fullname": "t2_3kml575u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science professional development grant - learning resource recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11qghzb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678730090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an opportunity to acquire $15,000 from a grant, which will cover the cost of data science professional development activities (eg. coursework, workshops, bootcamps, conferences, etc...) There are so many things I could ask for, but I am unsure what the &amp;quot;best&amp;quot; use of this grant would be. I&amp;#39;m thinking of applying for a bootcamp like the MIT|xPRO certificate in data science and analytics.&lt;/p&gt;\n\n&lt;p&gt;For background, I have a BS in Computer Science with a data science minor. I am currently working in a &amp;quot;data&amp;quot; role that is mostly administrative and does not exercise my technical abilities. I would like to use this funding to &lt;strong&gt;a)&lt;/strong&gt; acquire skills/experience that will help me move into a more technical data analytics/science role &lt;strong&gt;b)&lt;/strong&gt; prevent my current skills from withering away in this job while I look for work elsewhere. I know a Master&amp;#39;s degree would likely be the ultimate use of this funding, but I&amp;#39;m really looking for things I can complete within ~6 months so I&amp;#39;m not tied down to my current employer for too long (only current employees qualify for reimbursement through the grant award).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qghzb", "is_robot_indexable": true, "report_reasons": null, "author": "Laurels91", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qghzb/data_science_professional_development_grant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qghzb/data_science_professional_development_grant/", "subreddit_subscribers": 856746, "created_utc": 1678730090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI had to leave my job due to some severe medical issues, and am still undergoing treatment for them and cannot currently work. I was working on Data Governance and Data Management before I had to quit, and I loved that line of work. I want to become an attorney in the field of data and information privacy, so I was set to do all sorts of trainings and have logged hours for certifications that would help me stand out as an attorney with data experience in the field.\n\nSince I am currently unemployed, I have a lot of free time and am looking to work on getting certified in things such as Data Governance, Data Management, Data Architecture, and Data Visualization. However, a lot of these certifications require logged hours, which usually would come from a job. \n\nHow can I work on these certifications without a job right now? And for any attorneys who may be in this subreddit, would these certifications even matter in the grand scheme of things?\n\nAny recommendations or advice would be greatly appreciated!\n\nEdit: Removed some personal information", "author_fullname": "t2_2a0jbore", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Becoming Certified While Unemployed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qdl0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678723714.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678723270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I had to leave my job due to some severe medical issues, and am still undergoing treatment for them and cannot currently work. I was working on Data Governance and Data Management before I had to quit, and I loved that line of work. I want to become an attorney in the field of data and information privacy, so I was set to do all sorts of trainings and have logged hours for certifications that would help me stand out as an attorney with data experience in the field.&lt;/p&gt;\n\n&lt;p&gt;Since I am currently unemployed, I have a lot of free time and am looking to work on getting certified in things such as Data Governance, Data Management, Data Architecture, and Data Visualization. However, a lot of these certifications require logged hours, which usually would come from a job. &lt;/p&gt;\n\n&lt;p&gt;How can I work on these certifications without a job right now? And for any attorneys who may be in this subreddit, would these certifications even matter in the grand scheme of things?&lt;/p&gt;\n\n&lt;p&gt;Any recommendations or advice would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Removed some personal information&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qdl0h", "is_robot_indexable": true, "report_reasons": null, "author": "cmondothefoxSWAT", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qdl0h/becoming_certified_while_unemployed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qdl0h/becoming_certified_while_unemployed/", "subreddit_subscribers": 856746, "created_utc": 1678723270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you building internal aaps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qdkts", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678723258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qdkts", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qdkts/how_are_you_building_internal_aaps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qdkts/how_are_you_building_internal_aaps/", "subreddit_subscribers": 856746, "created_utc": 1678723258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im very new to data science, I needed help regarding a project ive been working on. I want to extract number of years of experience from job description i.e 1-2 years, 2 years etc. The text is free formatted hence the need for NLP. However can anyone give a brief idea on how to go about this", "author_fullname": "t2_8drjhm8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NER to extract data from job description", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qb556", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678717504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im very new to data science, I needed help regarding a project ive been working on. I want to extract number of years of experience from job description i.e 1-2 years, 2 years etc. The text is free formatted hence the need for NLP. However can anyone give a brief idea on how to go about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qb556", "is_robot_indexable": true, "report_reasons": null, "author": "Helix-x", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qb556/ner_to_extract_data_from_job_description/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qb556/ner_to_extract_data_from_job_description/", "subreddit_subscribers": 856746, "created_utc": 1678717504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!  \nI want to work on a project to build a website that suggests Hiking Trails based on Weather Forecast.\n\nI have some experience with Data Pipelines (mostly on GCP) and basic Web Design. As a first step I want some advice on what the overall architecture should be to build a MVP.\n\nMy idea is to collect weather data from OpenWeatherMaps and cross that data with trails from most popular Trail websites, to build a score combination based on weather quality for hiking and trail reviews.\n\nLet me know if you have some suggestions as that will definitely help!", "author_fullname": "t2_7940judc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Website that suggests Hiking Trails based on Weather Forecast", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qb4j5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678717462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nI want to work on a project to build a website that suggests Hiking Trails based on Weather Forecast.&lt;/p&gt;\n\n&lt;p&gt;I have some experience with Data Pipelines (mostly on GCP) and basic Web Design. As a first step I want some advice on what the overall architecture should be to build a MVP.&lt;/p&gt;\n\n&lt;p&gt;My idea is to collect weather data from OpenWeatherMaps and cross that data with trails from most popular Trail websites, to build a score combination based on weather quality for hiking and trail reviews.&lt;/p&gt;\n\n&lt;p&gt;Let me know if you have some suggestions as that will definitely help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qb4j5", "is_robot_indexable": true, "report_reasons": null, "author": "zecerqueira", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qb4j5/website_that_suggests_hiking_trails_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qb4j5/website_that_suggests_hiking_trails_based_on/", "subreddit_subscribers": 856746, "created_utc": 1678717462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently working on data science projects for university (predoc). I have a laptop fron the CS grad (lenovo yoga 720 15\u2019), but the battery and power is not at point at all. I want a laptop for mobility (conferences, commute,\u2026). All the really heavy tasks like DL or RL will be run on servers, but I do need to play around on local for some testing (no dGPU needed). The budget is something around 1500-2000\u20ac. \nI\u2019ve seen mbp, mb air, dell xps, surface pro, \u2026 not sure which would fit better. Any recommendations?\n\nCheers.", "author_fullname": "t2_jkb1bgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qakpd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently working on data science projects for university (predoc). I have a laptop fron the CS grad (lenovo yoga 720 15\u2019), but the battery and power is not at point at all. I want a laptop for mobility (conferences, commute,\u2026). All the really heavy tasks like DL or RL will be run on servers, but I do need to play around on local for some testing (no dGPU needed). The budget is something around 1500-2000\u20ac. \nI\u2019ve seen mbp, mb air, dell xps, surface pro, \u2026 not sure which would fit better. Any recommendations?&lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qakpd", "is_robot_indexable": true, "report_reasons": null, "author": "algonbar", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qakpd/laptop_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qakpd/laptop_for_data_science/", "subreddit_subscribers": 856746, "created_utc": 1678716147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an Applied Math major with a Data Analytics internship in the summer. I am currently planning on having two minors; one in Engineering Science and one in Data Science. I am planning on graduating in the fall but due to some mistakes on both my part and an advisor, I would have to stay another semester for just one class to finish the minor. I am already going into my fifth year as I switched from engineering to math (hence the engineering minor), I would say I am a solid programmer and pretty much don't need the classes. Without the minor my last semester in the Fall would consist of 2 math classes and 2 online gen-eds, which would be an easy way to end my college experience (and save me a lot of money as my scholarship is for 4 years). \n\nShould I finish the minor or is the internship a good substitute?", "author_fullname": "t2_c2ryz920", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Science Minor Worth It", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q9s7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678714231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an Applied Math major with a Data Analytics internship in the summer. I am currently planning on having two minors; one in Engineering Science and one in Data Science. I am planning on graduating in the fall but due to some mistakes on both my part and an advisor, I would have to stay another semester for just one class to finish the minor. I am already going into my fifth year as I switched from engineering to math (hence the engineering minor), I would say I am a solid programmer and pretty much don&amp;#39;t need the classes. Without the minor my last semester in the Fall would consist of 2 math classes and 2 online gen-eds, which would be an easy way to end my college experience (and save me a lot of money as my scholarship is for 4 years). &lt;/p&gt;\n\n&lt;p&gt;Should I finish the minor or is the internship a good substitute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q9s7y", "is_robot_indexable": true, "report_reasons": null, "author": "Secure-Atmosphere-36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q9s7y/is_data_science_minor_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q9s7y/is_data_science_minor_worth_it/", "subreddit_subscribers": 856746, "created_utc": 1678714231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know cost functions is a way to better fit your model to the training data and performance measure is to see how well the model generalize but for linear regression isn\u2019t rmse used as the cost function and the performance measure, isn\u2019t it the same mathematical formula? . I\u2019m just confused", "author_fullname": "t2_9ple7b7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello guys been trying to sleep but I can\u2019t cause the I\u2019m confused by cost function and performance measures what the difference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pygyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678677066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know cost functions is a way to better fit your model to the training data and performance measure is to see how well the model generalize but for linear regression isn\u2019t rmse used as the cost function and the performance measure, isn\u2019t it the same mathematical formula? . I\u2019m just confused&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11pygyk", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Ad_7053", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11pygyk/hello_guys_been_trying_to_sleep_but_i_cant_cause/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11pygyk/hello_guys_been_trying_to_sleep_but_i_cant_cause/", "subreddit_subscribers": 856746, "created_utc": 1678677066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I was wondering if anyone has any experience with getting a data science degree? Is it worth it? A school near me, UMSL, has a bs degree called data science and analytics. You can also have a emphasis in things like economics, math, or other data science focuses with the degree. The school is very great and has almost every connection as far as internships go in the business and data world. My one thought though is will the degree truly get me a data science job even with good internships. Before hearing about this program my plan was to pursue their accelerated economics masters, allowing me to get a masters in 5 years, with a minor in comp sci, and then pursue their data analytics certificate program. Their certificate programs basically acts as way to have a second minor. So I\u2019m wondering what route will be best? I know the data science degrees are new almost everywhere so not a lot of people have experience, I also can pursue a masters in data science online if I needed to. So overall what route would be better between these two\n\u2014data science bachelors with a economics emphasis possibly a masters \n\u2014masters in economics, comp sci minor, and possibly a data analysis certificate. \n\nKeep in mind my biggest concern is entry level job market and salary.\nThank you!", "author_fullname": "t2_d0eiazz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qd6vq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678722341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was wondering if anyone has any experience with getting a data science degree? Is it worth it? A school near me, UMSL, has a bs degree called data science and analytics. You can also have a emphasis in things like economics, math, or other data science focuses with the degree. The school is very great and has almost every connection as far as internships go in the business and data world. My one thought though is will the degree truly get me a data science job even with good internships. Before hearing about this program my plan was to pursue their accelerated economics masters, allowing me to get a masters in 5 years, with a minor in comp sci, and then pursue their data analytics certificate program. Their certificate programs basically acts as way to have a second minor. So I\u2019m wondering what route will be best? I know the data science degrees are new almost everywhere so not a lot of people have experience, I also can pursue a masters in data science online if I needed to. So overall what route would be better between these two\n\u2014data science bachelors with a economics emphasis possibly a masters \n\u2014masters in economics, comp sci minor, and possibly a data analysis certificate. &lt;/p&gt;\n\n&lt;p&gt;Keep in mind my biggest concern is entry level job market and salary.\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qd6vq", "is_robot_indexable": true, "report_reasons": null, "author": "Royal-Gazelle-3214", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qd6vq/data_science_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qd6vq/data_science_degree/", "subreddit_subscribers": 856746, "created_utc": 1678722341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Package here: https://github.com/dwreeves/dbt_linreg**\n\n# Overview\n\nHey everyone! I'm sharing this here because some of you may use dbt at work to manage your data pipelines, and you might find this useful for whipping up quick analyses.\n\nI made a package that lets you run linear regression and ridge regression in any SQL engine using dbt, including Snowflake and DuckDB, which don't natively have multiple regression implementations.\n\nIn theory, this implementation supports any number of variables (in practice, adding more variables exponentially increases the computation time though with the current implementation).\n\nThe code is thoroughly tested against Statsmodels's `OLS` implementation, which you can see in the `integration_tests/` folder.\n\n# Example\n\nExample linear regression here:\n\n    {{\n      config(\n        materialized=\"table\"\n      )\n    }}\n    select * from {{\n      dbt_linreg.ols(\n        table=ref('simple_matrix')\n        endog='y',\n        exog=['xa', 'xb', 'xc'],\n        format='long'\n      )\n    }}\n\nThe above code would run a linear regression on `ref('simple_matrix')` using `y` as the y-variable, and `['xa', 'xb', 'xc']` as the X-variables. The constant term is always included and doesn't need to be specified.\n\n# Install\n\nInstallation instructions are simply to add this to your `packages.yml`:\n\n      - git: \"https://github.com/dwreeves/dbt_linreg.git\"\n        revision: \"v0.1.1\"\n\n# How it works under the hood\n\nSince this is the data science subreddit, there may be some interest in how this actually works, so I'll quote from the README on the matter:\n\nSimple univariate regression coefficients are simply `covar_pop(y, x) / var_pop(x)`.\n\nThe multiple regression implementation uses a technique described in section `3.2.3 Multiple Regression from Simple Univariate Regression` of TEoSL ([source](https://hastie.su.domains/Papers/ESLII.pdf#page=71)). Econometricians know this as the Frisch-Waugh-Lowell theorem, hence the method is referred to as `'fwl'` internally in the code base.\n\nRidge regression is implemented using the augmentation technique described in Exercise 12 of Chapter 3 of TEoSL ([source](https://hastie.su.domains/Papers/ESLII.pdf#page=115)).\n\nAll approaches were validated using Statsmodels `sm.OLS()`. Note that the ridge regression coefficients differ very slightly from Statsmodels's outputs for currently unknown reasons, but the coefficients are very close (I enforce a `&lt;0.01%` deviation from Statsmodels's ridge regression coefficients in my integration tests).", "author_fullname": "t2_h0zsodpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linear regression and ridge regression in SQL + dbt with dbt_linreg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qd0hq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678721933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Package here: &lt;a href=\"https://github.com/dwreeves/dbt_linreg\"&gt;https://github.com/dwreeves/dbt_linreg&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;h1&gt;Overview&lt;/h1&gt;\n\n&lt;p&gt;Hey everyone! I&amp;#39;m sharing this here because some of you may use dbt at work to manage your data pipelines, and you might find this useful for whipping up quick analyses.&lt;/p&gt;\n\n&lt;p&gt;I made a package that lets you run linear regression and ridge regression in any SQL engine using dbt, including Snowflake and DuckDB, which don&amp;#39;t natively have multiple regression implementations.&lt;/p&gt;\n\n&lt;p&gt;In theory, this implementation supports any number of variables (in practice, adding more variables exponentially increases the computation time though with the current implementation).&lt;/p&gt;\n\n&lt;p&gt;The code is thoroughly tested against Statsmodels&amp;#39;s &lt;code&gt;OLS&lt;/code&gt; implementation, which you can see in the &lt;code&gt;integration_tests/&lt;/code&gt; folder.&lt;/p&gt;\n\n&lt;h1&gt;Example&lt;/h1&gt;\n\n&lt;p&gt;Example linear regression here:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{{\n  config(\n    materialized=&amp;quot;table&amp;quot;\n  )\n}}\nselect * from {{\n  dbt_linreg.ols(\n    table=ref(&amp;#39;simple_matrix&amp;#39;)\n    endog=&amp;#39;y&amp;#39;,\n    exog=[&amp;#39;xa&amp;#39;, &amp;#39;xb&amp;#39;, &amp;#39;xc&amp;#39;],\n    format=&amp;#39;long&amp;#39;\n  )\n}}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The above code would run a linear regression on &lt;code&gt;ref(&amp;#39;simple_matrix&amp;#39;)&lt;/code&gt; using &lt;code&gt;y&lt;/code&gt; as the y-variable, and &lt;code&gt;[&amp;#39;xa&amp;#39;, &amp;#39;xb&amp;#39;, &amp;#39;xc&amp;#39;]&lt;/code&gt; as the X-variables. The constant term is always included and doesn&amp;#39;t need to be specified.&lt;/p&gt;\n\n&lt;h1&gt;Install&lt;/h1&gt;\n\n&lt;p&gt;Installation instructions are simply to add this to your &lt;code&gt;packages.yml&lt;/code&gt;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  - git: &amp;quot;https://github.com/dwreeves/dbt_linreg.git&amp;quot;\n    revision: &amp;quot;v0.1.1&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;How it works under the hood&lt;/h1&gt;\n\n&lt;p&gt;Since this is the data science subreddit, there may be some interest in how this actually works, so I&amp;#39;ll quote from the README on the matter:&lt;/p&gt;\n\n&lt;p&gt;Simple univariate regression coefficients are simply &lt;code&gt;covar_pop(y, x) / var_pop(x)&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;The multiple regression implementation uses a technique described in section &lt;code&gt;3.2.3 Multiple Regression from Simple Univariate Regression&lt;/code&gt; of TEoSL (&lt;a href=\"https://hastie.su.domains/Papers/ESLII.pdf#page=71\"&gt;source&lt;/a&gt;). Econometricians know this as the Frisch-Waugh-Lowell theorem, hence the method is referred to as &lt;code&gt;&amp;#39;fwl&amp;#39;&lt;/code&gt; internally in the code base.&lt;/p&gt;\n\n&lt;p&gt;Ridge regression is implemented using the augmentation technique described in Exercise 12 of Chapter 3 of TEoSL (&lt;a href=\"https://hastie.su.domains/Papers/ESLII.pdf#page=115\"&gt;source&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;All approaches were validated using Statsmodels &lt;code&gt;sm.OLS()&lt;/code&gt;. Note that the ridge regression coefficients differ very slightly from Statsmodels&amp;#39;s outputs for currently unknown reasons, but the coefficients are very close (I enforce a &lt;code&gt;&amp;lt;0.01%&lt;/code&gt; deviation from Statsmodels&amp;#39;s ridge regression coefficients in my integration tests).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?auto=webp&amp;v=enabled&amp;s=89760627f58497231c343fc84cd33b5cee42f2c5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10439ec2f6a4e74b18a5398fb471d0fc0c07f98b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb2389e3fb1cf7b3ad657684bf2d22519b1c2b8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2dad9a4b70596413b52b9e5d031114222df8fdf", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5aded51c9a4c51928ca846185d94aac43f8e334b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc3f9cd3190a0b90156f6ae7fc018482cda85553", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=647bc89ce3528f169182e0e568faef6e54a2c044", "width": 1080, "height": 540}], "variants": {}, "id": "47aZudkG3WJNkYxFgpIQmMmLZxuySLSLUFluVEhwJgo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qd0hq", "is_robot_indexable": true, "report_reasons": null, "author": "danielwreeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qd0hq/linear_regression_and_ridge_regression_in_sql_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qd0hq/linear_regression_and_ridge_regression_in_sql_dbt/", "subreddit_subscribers": 856746, "created_utc": 1678721933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What of the following options are the best to learn as an analyst trying to break into the field?\n\nMongoDB (NoSQL Database)\nAdvanced Python for Data Science and Machine Learning\nAdvanced Statistics for Data Science and Business Analysis\nPython for Financial &amp; Risk Analysis\nMicrosoft Azure Training\nTensorflow: Deep Learning and Artificial Intelligence\nGoogle BigQuery for Data Analysis\nMarketing Data Analysis\nBig Data with Apache Spark and Python\nBusiness Analytics\nHealthcare Data Analysis &amp; BioPython\nHR Analytics\nAdvanced Excel for Data Analysis\nSAS Programming", "author_fullname": "t2_11cw6lt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best out of the following options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qa65r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678715177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What of the following options are the best to learn as an analyst trying to break into the field?&lt;/p&gt;\n\n&lt;p&gt;MongoDB (NoSQL Database)\nAdvanced Python for Data Science and Machine Learning\nAdvanced Statistics for Data Science and Business Analysis\nPython for Financial &amp;amp; Risk Analysis\nMicrosoft Azure Training\nTensorflow: Deep Learning and Artificial Intelligence\nGoogle BigQuery for Data Analysis\nMarketing Data Analysis\nBig Data with Apache Spark and Python\nBusiness Analytics\nHealthcare Data Analysis &amp;amp; BioPython\nHR Analytics\nAdvanced Excel for Data Analysis\nSAS Programming&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qa65r", "is_robot_indexable": true, "report_reasons": null, "author": "daskou_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qa65r/best_out_of_the_following_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qa65r/best_out_of_the_following_options/", "subreddit_subscribers": 856746, "created_utc": 1678715177.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}