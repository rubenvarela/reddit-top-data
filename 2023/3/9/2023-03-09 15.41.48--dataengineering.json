{"kind": "Listing", "data": {"after": "t3_11mlwyw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Alright so Databricks allows for Python and PySpark programming. \n\nIf i code in only Python, does databricks distribute the computation across nodes using Spark? Or would that only occur if I use PySpark?\n\nI\u2019ve been using databricks for a month now and didn\u2019t think to program in PySpark and have been programming in Python but now I\u2019m afraid I\u2019m not getting the full benefit of Databricks.", "author_fullname": "t2_6mct0oth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks: Programming in Python vs PySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mj5cw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678337616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright so Databricks allows for Python and PySpark programming. &lt;/p&gt;\n\n&lt;p&gt;If i code in only Python, does databricks distribute the computation across nodes using Spark? Or would that only occur if I use PySpark?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been using databricks for a month now and didn\u2019t think to program in PySpark and have been programming in Python but now I\u2019m afraid I\u2019m not getting the full benefit of Databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11mj5cw", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Baseball89", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mj5cw/databricks_programming_in_python_vs_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mj5cw/databricks_programming_in_python_vs_pyspark/", "subreddit_subscribers": 92415, "created_utc": 1678337616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im an undergrad that aims to be DE and occassionally i check relevant job postings\n\n I see frequently that as a DE i should be able to write \"highly optimized\" queries. Well for starters theres the query optimizer in any DBMS, that will translate your query to an equivalent RA expression that gives better performance. So, aside from using available indexes ofc, i dont understand what this \"highly optimized query\" even means???\n\n Also i have a question regarding DWs, i see a lot of postings demanding deep knowledge of the topic and i have no issues to study hard about it. But im afraid that all this effort will be meaningless due to cloud. What do you think?", "author_fullname": "t2_fnzbiwzf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do i need to write \"highly optimized\" queries as a DE? Also, is DW knowledge becoming obsolete due to cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mq8pg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678362740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im an undergrad that aims to be DE and occassionally i check relevant job postings&lt;/p&gt;\n\n&lt;p&gt;I see frequently that as a DE i should be able to write &amp;quot;highly optimized&amp;quot; queries. Well for starters theres the query optimizer in any DBMS, that will translate your query to an equivalent RA expression that gives better performance. So, aside from using available indexes ofc, i dont understand what this &amp;quot;highly optimized query&amp;quot; even means???&lt;/p&gt;\n\n&lt;p&gt;Also i have a question regarding DWs, i see a lot of postings demanding deep knowledge of the topic and i have no issues to study hard about it. But im afraid that all this effort will be meaningless due to cloud. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11mq8pg", "is_robot_indexable": true, "report_reasons": null, "author": "Nomorechildishshit", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mq8pg/do_i_need_to_write_highly_optimized_queries_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mq8pg/do_i_need_to_write_highly_optimized_queries_as_a/", "subreddit_subscribers": 92415, "created_utc": 1678362740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been tasked with doing a preliminary market scan for tools to integrate cloud-based data sources (mostly socials) like Facebook/Meta, Google, LinkedIn, etc.  We are currently using Azure Data Factory, which works fine for on-prem databases and even some SaaS products like Salesforce.  But for most cloud-based products, Microsoft offers a generic REST-based connector and not much else.\n\nSome options I'm looking at include Fivetran, Stitch, Hevo, Supermetrics, and CData... are there others worth looking at?\n\nWhat do you use?  And why?", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for cloud-based data source?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mn1nn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678350830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been tasked with doing a preliminary market scan for tools to integrate cloud-based data sources (mostly socials) like Facebook/Meta, Google, LinkedIn, etc.  We are currently using Azure Data Factory, which works fine for on-prem databases and even some SaaS products like Salesforce.  But for most cloud-based products, Microsoft offers a generic REST-based connector and not much else.&lt;/p&gt;\n\n&lt;p&gt;Some options I&amp;#39;m looking at include Fivetran, Stitch, Hevo, Supermetrics, and CData... are there others worth looking at?&lt;/p&gt;\n\n&lt;p&gt;What do you use?  And why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11mn1nn", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mn1nn/what_do_you_use_for_cloudbased_data_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mn1nn/what_do_you_use_for_cloudbased_data_source/", "subreddit_subscribers": 92415, "created_utc": 1678350830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am starting a new job next week and I will be responsible for a lot more that I have in the past as a Power Bi Developer.  One of the requirements is to make sure that the database are in 2NF or 3NF.\n\nI understand what 1NF, 2NF and 3NF and how to change the database to be 2NF or 3NF.\n\nDoes anyone know of a good python package, SQL script or even a good check list to help identify the normalization status of a database?", "author_fullname": "t2_c25i55k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database normalization 1NF, 2NF, 3NF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mhov6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678333552.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678333323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting a new job next week and I will be responsible for a lot more that I have in the past as a Power Bi Developer.  One of the requirements is to make sure that the database are in 2NF or 3NF.&lt;/p&gt;\n\n&lt;p&gt;I understand what 1NF, 2NF and 3NF and how to change the database to be 2NF or 3NF.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a good python package, SQL script or even a good check list to help identify the normalization status of a database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11mhov6", "is_robot_indexable": true, "report_reasons": null, "author": "moltra_1", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mhov6/database_normalization_1nf_2nf_3nf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mhov6/database_normalization_1nf_2nf_3nf/", "subreddit_subscribers": 92415, "created_utc": 1678333323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just a lighter post for a change. \n\nI'll go first, I'd sell my car for an api access to the myFitnessPal data.\n\nSo many interesting findings out of it. What do people eat? Per country? Age group? How does it relate to their fitness goal? Such a gold mine.", "author_fullname": "t2_btfgm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What dataset would you pay good money to get your hands on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11mtgx0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678372796.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678371766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a lighter post for a change. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll go first, I&amp;#39;d sell my car for an api access to the myFitnessPal data.&lt;/p&gt;\n\n&lt;p&gt;So many interesting findings out of it. What do people eat? Per country? Age group? How does it relate to their fitness goal? Such a gold mine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11mtgx0", "is_robot_indexable": true, "report_reasons": null, "author": "holiquetal", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mtgx0/what_dataset_would_you_pay_good_money_to_get_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mtgx0/what_dataset_would_you_pay_good_money_to_get_your/", "subreddit_subscribers": 92415, "created_utc": 1678371766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWe are drawing from our Data Warehouse to do a report. The data is not yet large but is expected to be soon. However, the query work we are doing has become quite complex. We are coding it all up in Glue/Spark. But it begs the question: are we doing things wrong?\n\nHere's some other options:\n\n* prepare as much data manipulation into Views in the Data Warehouse\n* actually materialize some of the required data into tables via new ETLs\n* just keep programming it all in Spark\n* rely on BI tool to get the job done.\n\nHow would you achieve a report that requires many joins and filters on lots of data?\n\nBonus Question: In the context of big data, do you rely on your BI tool for such kinds of \"heavy\" reports?", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How/Where to make complex Reports?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11m9t6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678313395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are drawing from our Data Warehouse to do a report. The data is not yet large but is expected to be soon. However, the query work we are doing has become quite complex. We are coding it all up in Glue/Spark. But it begs the question: are we doing things wrong?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some other options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;prepare as much data manipulation into Views in the Data Warehouse&lt;/li&gt;\n&lt;li&gt;actually materialize some of the required data into tables via new ETLs&lt;/li&gt;\n&lt;li&gt;just keep programming it all in Spark&lt;/li&gt;\n&lt;li&gt;rely on BI tool to get the job done.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How would you achieve a report that requires many joins and filters on lots of data?&lt;/p&gt;\n\n&lt;p&gt;Bonus Question: In the context of big data, do you rely on your BI tool for such kinds of &amp;quot;heavy&amp;quot; reports?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11m9t6g", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11m9t6g/howwhere_to_make_complex_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11m9t6g/howwhere_to_make_complex_reports/", "subreddit_subscribers": 92415, "created_utc": 1678313395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9u69ulzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use JIRA as a database? (NSFL)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mkywc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1678343441.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/SoftwareEngineering/comments/11mehjg/jira_as_a_database/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "11mkywc", "is_robot_indexable": true, "report_reasons": null, "author": "tdatas", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mkywc/should_i_use_jira_as_a_database_nsfl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/SoftwareEngineering/comments/11mehjg/jira_as_a_database/", "subreddit_subscribers": 92415, "created_utc": 1678343441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context I did my bachelors and masters in electrical engineering from TMU and I took 1 course on data engineering which got me really interested. Unfortunately I was too late to take more courses on data/ML cause i finished the requirements for the MEng and just graduated last year. I only learnt basic sql/gcp and how to ingest data in hive/Hadoop and use elastic search and kibana in that course. I want to apply for data engineering roles and basically get into this field but I don\u2019t even know how to operate GitHub or have any projects. There are way too many resources online and a tonne of free courses but I want to enroll in a program which can motivate me more and actually make build projects. The ones I am interested in currently is the data science certificate at UofT and the Big data at McMaster University. I must add I have little to no work experience. I just graduated and the thought of pouring money to another useless degree is not appealing to me. But if the certificate or bootcamp actually gets me a job in data engineering I\u2019d be more than happy to invest. I honestly need help and guidance if anyone went through the same thing. Any recommendations on what I should do now is more than welcome and is greatly appreciated (pls I beg)", "author_fullname": "t2_cqcj4ctw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big data engineering certificates/courses in Toronto to start out and build portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11md525", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678321169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context I did my bachelors and masters in electrical engineering from TMU and I took 1 course on data engineering which got me really interested. Unfortunately I was too late to take more courses on data/ML cause i finished the requirements for the MEng and just graduated last year. I only learnt basic sql/gcp and how to ingest data in hive/Hadoop and use elastic search and kibana in that course. I want to apply for data engineering roles and basically get into this field but I don\u2019t even know how to operate GitHub or have any projects. There are way too many resources online and a tonne of free courses but I want to enroll in a program which can motivate me more and actually make build projects. The ones I am interested in currently is the data science certificate at UofT and the Big data at McMaster University. I must add I have little to no work experience. I just graduated and the thought of pouring money to another useless degree is not appealing to me. But if the certificate or bootcamp actually gets me a job in data engineering I\u2019d be more than happy to invest. I honestly need help and guidance if anyone went through the same thing. Any recommendations on what I should do now is more than welcome and is greatly appreciated (pls I beg)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11md525", "is_robot_indexable": true, "report_reasons": null, "author": "anonthrowaways728181", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11md525/big_data_engineering_certificatescourses_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11md525/big_data_engineering_certificatescourses_in/", "subreddit_subscribers": 92415, "created_utc": 1678321169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an American myself, but have been working in Japan for most of my data career, and I have a science degree but no formal compsci education. I wonder how seriously these things might disadvantage me as I consider returning home for much, much better pay in theory.", "author_fullname": "t2_ejt24ok7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting a DE role in the USA without a compsci degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mnuly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678353947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an American myself, but have been working in Japan for most of my data career, and I have a science degree but no formal compsci education. I wonder how seriously these things might disadvantage me as I consider returning home for much, much better pay in theory.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11mnuly", "is_robot_indexable": true, "report_reasons": null, "author": "suterebaiiiii", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mnuly/getting_a_de_role_in_the_usa_without_a_compsci/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mnuly/getting_a_de_role_in_the_usa_without_a_compsci/", "subreddit_subscribers": 92415, "created_utc": 1678353947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I wonder how many of you still do ETL with GUI tools like Oracle Data Integrator, SSIS, etc..\nI am DWH/ETL developer and for ETL we use ODI (for complicated things I write PL/SQL packages and procedures) I am worried that this way of doing ETL is dead and if I dont change job, I will have problem to find job in future. What do you guys think about it?", "author_fullname": "t2_kh4jiqla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GUI-based ETL developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mnc5w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678351975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I wonder how many of you still do ETL with GUI tools like Oracle Data Integrator, SSIS, etc..\nI am DWH/ETL developer and for ETL we use ODI (for complicated things I write PL/SQL packages and procedures) I am worried that this way of doing ETL is dead and if I dont change job, I will have problem to find job in future. What do you guys think about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11mnc5w", "is_robot_indexable": true, "report_reasons": null, "author": "No_Pause7942", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mnc5w/guibased_etl_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mnc5w/guibased_etl_developer/", "subreddit_subscribers": 92415, "created_utc": 1678351975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a conference you're looking forward to that deliver a lot of Data Engineering concepts or is centered on DE as a whole?", "author_fullname": "t2_pp8loa0k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Conferences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mbxsq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678318255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a conference you&amp;#39;re looking forward to that deliver a lot of Data Engineering concepts or is centered on DE as a whole?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11mbxsq", "is_robot_indexable": true, "report_reasons": null, "author": "de_epi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11mbxsq/de_conferences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mbxsq/de_conferences/", "subreddit_subscribers": 92415, "created_utc": 1678318255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, while researching and learning about data warehouses, I will always only find a super minimal example to demonstrate a star schema with like 5 tables total in the warehouse. Like that's cool, but what if I have hundreds of tables (50+ facts &amp; 100+ dimensions) coming from 10+ databases and APIs???? I figure this is much more what you deal with in the real world.\n\nSo to my questions are:\n\n1. How do you guys organize all of this in your warehouse? Schema per Source?\n2. Are you using a data lake before the warehouse to bring all of the sources together in a single location?\n3. How do you manage the inserts, updates, and deletes for all of these tables in the warehouse?\n4. What does your reporting layer look like on top of the warehouse tables?\n5. Are you using something like DBT to transform the raw data (normalized form) into a denormalized form?", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are your warehouses organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11m0wtv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678293216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, while researching and learning about data warehouses, I will always only find a super minimal example to demonstrate a star schema with like 5 tables total in the warehouse. Like that&amp;#39;s cool, but what if I have hundreds of tables (50+ facts &amp;amp; 100+ dimensions) coming from 10+ databases and APIs???? I figure this is much more what you deal with in the real world.&lt;/p&gt;\n\n&lt;p&gt;So to my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do you guys organize all of this in your warehouse? Schema per Source?&lt;/li&gt;\n&lt;li&gt;Are you using a data lake before the warehouse to bring all of the sources together in a single location?&lt;/li&gt;\n&lt;li&gt;How do you manage the inserts, updates, and deletes for all of these tables in the warehouse?&lt;/li&gt;\n&lt;li&gt;What does your reporting layer look like on top of the warehouse tables?&lt;/li&gt;\n&lt;li&gt;Are you using something like DBT to transform the raw data (normalized form) into a denormalized form?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11m0wtv", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11m0wtv/how_are_your_warehouses_organized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11m0wtv/how_are_your_warehouses_organized/", "subreddit_subscribers": 92415, "created_utc": 1678293216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Got a use case which requires to deploy multiple resources across multiple cloud projects with terraform.\n\nIs it better off to have one service account across all deployments or separate each with a distinct service account.\n\nI understand there are trade offs on both approaches and might not be one right solution, but is there maybe more secure to just protect one service account key instead of 50?", "author_fullname": "t2_fbkuq4f9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "one service account to rule them all, or not", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11m07eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678291595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got a use case which requires to deploy multiple resources across multiple cloud projects with terraform.&lt;/p&gt;\n\n&lt;p&gt;Is it better off to have one service account across all deployments or separate each with a distinct service account.&lt;/p&gt;\n\n&lt;p&gt;I understand there are trade offs on both approaches and might not be one right solution, but is there maybe more secure to just protect one service account key instead of 50?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11m07eb", "is_robot_indexable": true, "report_reasons": null, "author": "one_but_ninja", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11m07eb/one_service_account_to_rule_them_all_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11m07eb/one_service_account_to_rule_them_all_or_not/", "subreddit_subscribers": 92415, "created_utc": 1678291595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5pxn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Teams Survey 2023 Results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lzsrn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1678290680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jesse-anderson.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.jesse-anderson.com/2023/03/data-teams-survey-2023-results/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Mentor | Jesse Anderson", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11lzsrn", "is_robot_indexable": true, "report_reasons": null, "author": "eljefe6a", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11lzsrn/data_teams_survey_2023_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.jesse-anderson.com/2023/03/data-teams-survey-2023-results/", "subreddit_subscribers": 92415, "created_utc": 1678290680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my company currently uses dbt+snowflake in some pipelines and also databricks for others. \n\nSince snowflake is extremely expensive, will it make sense to use dbt-databricks and run all pipelines in their databricks sql clusters? Will it be any faster? I have some pipelines running half of the jobs in dbt and the other half in databricks and scheduling everything in airflow. Don\u2019t really know if I\u2019ll get anything if moving all transformations to databricks (via dbt-databricks) aside from cost/speed?", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone tested dbt-databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11moydj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678358132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my company currently uses dbt+snowflake in some pipelines and also databricks for others. &lt;/p&gt;\n\n&lt;p&gt;Since snowflake is extremely expensive, will it make sense to use dbt-databricks and run all pipelines in their databricks sql clusters? Will it be any faster? I have some pipelines running half of the jobs in dbt and the other half in databricks and scheduling everything in airflow. Don\u2019t really know if I\u2019ll get anything if moving all transformations to databricks (via dbt-databricks) aside from cost/speed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11moydj", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11moydj/has_anyone_tested_dbtdatabricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11moydj/has_anyone_tested_dbtdatabricks/", "subreddit_subscribers": 92415, "created_utc": 1678358132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a dataset with a million rows, and I'm using Pyspark for transformations to model data to meet data science needs, though Pyspark has most transformations, there are situations like I'm in now, where I need to use a third-party library function on my data which are not optimized for Pyspark  ( currently I'm tasked to find Jaro Winkler distance matrix ), running this function on about 8000 records is taking around 6 mins of time but it would take a lot of time for a million records.   \n\n\n1. How do you handle the execution of a third-party function on a huge dataset .? \n2. I'm on AWS and feel that I should use  [Python shell jobs in AWS Glue](https://docs.aws.amazon.com/glue/latest/dg/add-job-python.html) to run the Jaro Winkler function for about two days to get a matrix for the whole dataset,  am I right in this regard.?", "author_fullname": "t2_6psngyc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running a third-party-library function on a Huge dataset that is not optimized for Pyspark.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mbvwq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678318133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset with a million rows, and I&amp;#39;m using Pyspark for transformations to model data to meet data science needs, though Pyspark has most transformations, there are situations like I&amp;#39;m in now, where I need to use a third-party library function on my data which are not optimized for Pyspark  ( currently I&amp;#39;m tasked to find Jaro Winkler distance matrix ), running this function on about 8000 records is taking around 6 mins of time but it would take a lot of time for a million records.   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do you handle the execution of a third-party function on a huge dataset .? &lt;/li&gt;\n&lt;li&gt;I&amp;#39;m on AWS and feel that I should use  &lt;a href=\"https://docs.aws.amazon.com/glue/latest/dg/add-job-python.html\"&gt;Python shell jobs in AWS Glue&lt;/a&gt; to run the Jaro Winkler function for about two days to get a matrix for the whole dataset,  am I right in this regard.?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11mbvwq", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo_51799", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mbvwq/running_a_thirdpartylibrary_function_on_a_huge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mbvwq/running_a_thirdpartylibrary_function_on_a_huge/", "subreddit_subscribers": 92415, "created_utc": 1678318133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have what seems like a pretty vanilla DE project: Take an OLTP system hosted on AWS and build out a system that supports ad hoc OLAP queries by analysts (bonus points if they can continue to use Tableau or Metabase on it) and feature extraction and model training by the ML team. Data volume is currently ~500GB/500M rows with an evolving schema and projected to grow 5x-10x in the next few years. The data is largely append-only but some of it is updateable. There is a desire to pull in some higher-volume, unstructured external data for enrichment as well.\n\nMy general thinking is:\n\nData lake with something along the lines of Iceberg to help manage the raw data since it handles schema evolution, point-in-time query capabilities, and the possibility of multiple query engines if analysts and the ML team end up with different tools. \n\nStream OLTP updates to the data lake. This is an area where I have the least expertise. Something along the lines of AWS Glue seems appropriate.\n\nA horizontally-scalable query engine such as Presto that will allow analysts to do ad hoc scans over relatively large volumes of data. It looks like Tableau and Metabase plug into it as well.\n\nI've done a fair bit of work at multiple layers in setups like these, but haven't ever put one together from end-to-end and I'm looking for some sanity checks and/or gaping holes in my reasoning -- major components that are missing or tools that may be overkill for TB-scale data volumes.", "author_fullname": "t2_6p9p15m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Greenfield DE project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11m97iu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678311977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have what seems like a pretty vanilla DE project: Take an OLTP system hosted on AWS and build out a system that supports ad hoc OLAP queries by analysts (bonus points if they can continue to use Tableau or Metabase on it) and feature extraction and model training by the ML team. Data volume is currently ~500GB/500M rows with an evolving schema and projected to grow 5x-10x in the next few years. The data is largely append-only but some of it is updateable. There is a desire to pull in some higher-volume, unstructured external data for enrichment as well.&lt;/p&gt;\n\n&lt;p&gt;My general thinking is:&lt;/p&gt;\n\n&lt;p&gt;Data lake with something along the lines of Iceberg to help manage the raw data since it handles schema evolution, point-in-time query capabilities, and the possibility of multiple query engines if analysts and the ML team end up with different tools. &lt;/p&gt;\n\n&lt;p&gt;Stream OLTP updates to the data lake. This is an area where I have the least expertise. Something along the lines of AWS Glue seems appropriate.&lt;/p&gt;\n\n&lt;p&gt;A horizontally-scalable query engine such as Presto that will allow analysts to do ad hoc scans over relatively large volumes of data. It looks like Tableau and Metabase plug into it as well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a fair bit of work at multiple layers in setups like these, but haven&amp;#39;t ever put one together from end-to-end and I&amp;#39;m looking for some sanity checks and/or gaping holes in my reasoning -- major components that are missing or tools that may be overkill for TB-scale data volumes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11m97iu", "is_robot_indexable": true, "report_reasons": null, "author": "Db_Wrangler_1905", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11m97iu/greenfield_de_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11m97iu/greenfield_de_project/", "subreddit_subscribers": 92415, "created_utc": 1678311977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am located in europe and I recently joined a new company. I have 2.5 years or experience in total and almost exclusively in data eng. \n\nIn my previous job, the pressure was ok, we had separate jobs for data eng and data analytics as well as devops. People usually came at 9-930 till 5:30.\n\n\nNow at this new company, i was hired as a data eng. i am part in a 5-person team including a head of data (also our product manager), a tech lead and 3 others dev that have between 0 and 2 years of experience.\n\nI have been there for 2 weeks and the pressure is high. Every morning, someone has to check pipeline failures before 8 am, everyone usually starts at 8 am till 6:30 or more. I saw a lot of PR being made very late at night and very often by dev of my team. \n\n\nThey keep giving new tickets, i think i already have 8 tickets (some can take 2h but some days every weeks). The head of data told me yesterday that i should be the number 2 of the team very soon and be super pro-active, acting like a senior and follow our tech lead. But I don\u2019t really want to act like him, he is probably working 60-70h a week, even pushing code on week ends. He is a passionate but I don\u2019t have any equity (not sure he has either) and I just want a normal job. \n\n\nAt my previous company, my PO usually make sure before a new spring that i will be to complete all of my tickets, so the workload was ok. Now they keep giving me new tickets every day! And usually tickets are empty, just a little title such as \u00ab\u00a0fix xxx table duplicates\u00a0\u00bb .\n\nFor exemple this morning he had more than 4 different person reaching out to fix 4 different bugs, usually they pressure us a lot. \n\n\nShould i find a new job? Pay is good but i am so stressed now", "author_fullname": "t2_sdga09th", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this the norm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mrxh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678368052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678367793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am located in europe and I recently joined a new company. I have 2.5 years or experience in total and almost exclusively in data eng. &lt;/p&gt;\n\n&lt;p&gt;In my previous job, the pressure was ok, we had separate jobs for data eng and data analytics as well as devops. People usually came at 9-930 till 5:30.&lt;/p&gt;\n\n&lt;p&gt;Now at this new company, i was hired as a data eng. i am part in a 5-person team including a head of data (also our product manager), a tech lead and 3 others dev that have between 0 and 2 years of experience.&lt;/p&gt;\n\n&lt;p&gt;I have been there for 2 weeks and the pressure is high. Every morning, someone has to check pipeline failures before 8 am, everyone usually starts at 8 am till 6:30 or more. I saw a lot of PR being made very late at night and very often by dev of my team. &lt;/p&gt;\n\n&lt;p&gt;They keep giving new tickets, i think i already have 8 tickets (some can take 2h but some days every weeks). The head of data told me yesterday that i should be the number 2 of the team very soon and be super pro-active, acting like a senior and follow our tech lead. But I don\u2019t really want to act like him, he is probably working 60-70h a week, even pushing code on week ends. He is a passionate but I don\u2019t have any equity (not sure he has either) and I just want a normal job. &lt;/p&gt;\n\n&lt;p&gt;At my previous company, my PO usually make sure before a new spring that i will be to complete all of my tickets, so the workload was ok. Now they keep giving me new tickets every day! And usually tickets are empty, just a little title such as \u00ab\u00a0fix xxx table duplicates\u00a0\u00bb .&lt;/p&gt;\n\n&lt;p&gt;For exemple this morning he had more than 4 different person reaching out to fix 4 different bugs, usually they pressure us a lot. &lt;/p&gt;\n\n&lt;p&gt;Should i find a new job? Pay is good but i am so stressed now&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11mrxh9", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryWeb7537", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mrxh9/is_this_the_norm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mrxh9/is_this_the_norm/", "subreddit_subscribers": 92415, "created_utc": 1678367793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've been working as a data engineer for a bit less than a year, and I don't have anyone to ask general questions about the trade. So here I am, looking for some pointers.\n\n**Considerations**:\n\n* Small retail company, 500+ aprox.\n* Only data person in the company coming from a complete different background. Self-taught.\n* Fairly competent in Python, JS, SQL, APIs, BI tools.\n* My position was granted after I pitched the need for better reporting and the benefits of analytics to a C-suit that already left the company. He told me that he didn't understand what data analytics is, but that he trusted me because I was very good at my previous role (which was completed unrelated).\n* No one (and I mean no one) in the company has the slightest idea of what do I do or how do I do it. I am best known for my \"wizardry\" with data and delivering reports.\n* Everyone seems happy with the reports/dashboards I build.\n* The setup is simple. OnPrem PostgreSQL Data Warehouse. ELT: iPaaS for EL, SQL stored procedures orchestrated with python scripts + win task scheduler for T. Less than 50 tables, 30GB in total, all structured. BI tool pointing to the DW. Nobody queries the Data Warehouse.\n* Salary is 45K USD.\n* The conditions are challenging but at the same time have multiple benefits so I don't want to leave the company. I have free rein long as I keep costs to a minimum, and I am learning new things and gaining experience every day.\n\n**Questions**:\n\n1. What direction do you consider I should take in my learning path taking into account the existing setup and the fact that I will remain here for a while? What would you do?\n2. Is it normal to spend time maintaining the DW on a daily basis? Even with excellent setups, what minimum percentage of your day do you dedicate to maintenance (QA checks, fixing broken stuff, documentation, etc). I know that every case is different but a basic notion will suffice.\n3. No one in IT has even the most basic understanding of how to deal with data. People in development follow the same line. They struggle with moving data from A to B, and 99% of the time they do it wrong. Is this normal?\n4. The source systems administrators are incompetent with very little technical knowledge and understanding of the most basic data principles. Is this normal?\n5. I know that data analysis and data engineering complement each other, but I feel like each is a job in its own right and becomes a bit taxing. Is this a reasonable feeling, or should I be able to do both things without breaking a sweat?\n6. Is data governance a myth?\n7. Is the salary ok considering my responsibilities?\n8. What approach would you take to justify salary increase? Specially if absolutely no one (boss included) knows what a data engineer is? I can only show the impact of the data analyst side of my role, but I feel that to do that for the data engineering side is challenging.\n9. Any further advice for a greenhorn?\n\nApologies if I butcher any word, English is not my first language (though I also butcher words in my native language).", "author_fullname": "t2_83poggkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE looking for some advice/guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mp304", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678358628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a data engineer for a bit less than a year, and I don&amp;#39;t have anyone to ask general questions about the trade. So here I am, looking for some pointers.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Considerations&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Small retail company, 500+ aprox.&lt;/li&gt;\n&lt;li&gt;Only data person in the company coming from a complete different background. Self-taught.&lt;/li&gt;\n&lt;li&gt;Fairly competent in Python, JS, SQL, APIs, BI tools.&lt;/li&gt;\n&lt;li&gt;My position was granted after I pitched the need for better reporting and the benefits of analytics to a C-suit that already left the company. He told me that he didn&amp;#39;t understand what data analytics is, but that he trusted me because I was very good at my previous role (which was completed unrelated).&lt;/li&gt;\n&lt;li&gt;No one (and I mean no one) in the company has the slightest idea of what do I do or how do I do it. I am best known for my &amp;quot;wizardry&amp;quot; with data and delivering reports.&lt;/li&gt;\n&lt;li&gt;Everyone seems happy with the reports/dashboards I build.&lt;/li&gt;\n&lt;li&gt;The setup is simple. OnPrem PostgreSQL Data Warehouse. ELT: iPaaS for EL, SQL stored procedures orchestrated with python scripts + win task scheduler for T. Less than 50 tables, 30GB in total, all structured. BI tool pointing to the DW. Nobody queries the Data Warehouse.&lt;/li&gt;\n&lt;li&gt;Salary is 45K USD.&lt;/li&gt;\n&lt;li&gt;The conditions are challenging but at the same time have multiple benefits so I don&amp;#39;t want to leave the company. I have free rein long as I keep costs to a minimum, and I am learning new things and gaining experience every day.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What direction do you consider I should take in my learning path taking into account the existing setup and the fact that I will remain here for a while? What would you do?&lt;/li&gt;\n&lt;li&gt;Is it normal to spend time maintaining the DW on a daily basis? Even with excellent setups, what minimum percentage of your day do you dedicate to maintenance (QA checks, fixing broken stuff, documentation, etc). I know that every case is different but a basic notion will suffice.&lt;/li&gt;\n&lt;li&gt;No one in IT has even the most basic understanding of how to deal with data. People in development follow the same line. They struggle with moving data from A to B, and 99% of the time they do it wrong. Is this normal?&lt;/li&gt;\n&lt;li&gt;The source systems administrators are incompetent with very little technical knowledge and understanding of the most basic data principles. Is this normal?&lt;/li&gt;\n&lt;li&gt;I know that data analysis and data engineering complement each other, but I feel like each is a job in its own right and becomes a bit taxing. Is this a reasonable feeling, or should I be able to do both things without breaking a sweat?&lt;/li&gt;\n&lt;li&gt;Is data governance a myth?&lt;/li&gt;\n&lt;li&gt;Is the salary ok considering my responsibilities?&lt;/li&gt;\n&lt;li&gt;What approach would you take to justify salary increase? Specially if absolutely no one (boss included) knows what a data engineer is? I can only show the impact of the data analyst side of my role, but I feel that to do that for the data engineering side is challenging.&lt;/li&gt;\n&lt;li&gt;Any further advice for a greenhorn?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Apologies if I butcher any word, English is not my first language (though I also butcher words in my native language).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11mp304", "is_robot_indexable": true, "report_reasons": null, "author": "Ancient-Entry-6436", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mp304/de_looking_for_some_adviceguidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mp304/de_looking_for_some_adviceguidance/", "subreddit_subscribers": 92415, "created_utc": 1678358628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand the separate use cases for batch and streaming. Batch for analytical/aggregate reporting data over a set period of time. Streaming for more immediate feedback on unbounded data. My question is about the reconciliation that happens between these two layers? Why would you need to reconcile when you already have the batch data that is most accurate?  Wouldn't the batch data suffice?", "author_fullname": "t2_nmk5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about lambda architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mkle2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678342197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the separate use cases for batch and streaming. Batch for analytical/aggregate reporting data over a set period of time. Streaming for more immediate feedback on unbounded data. My question is about the reconciliation that happens between these two layers? Why would you need to reconcile when you already have the batch data that is most accurate?  Wouldn&amp;#39;t the batch data suffice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11mkle2", "is_robot_indexable": true, "report_reasons": null, "author": "getboy97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mkle2/question_about_lambda_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mkle2/question_about_lambda_architecture/", "subreddit_subscribers": 92415, "created_utc": 1678342197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic terminology and practices related to graph databases and graph modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": true, "name": "t3_11mtvay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0NyBuTvjPeHdF2zlTcWj35dnzBArL7lxVTmudJsnhgc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678372775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/docs/memgraph/tutorials/graph-modeling", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?auto=webp&amp;v=enabled&amp;s=0c12c7cf7697648578ce443559891c478718afb3", "width": 1271, "height": 753}, "resolutions": [{"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce9b74a24b9079589434bfd4611f2019117ba329", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b612795dd9da70f294873f910ce191b1ac1eff2", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b3b0aae3eb8cc9da91228e565f4e6a05f778826", "width": 320, "height": 189}, {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9578636a8b892429b11c8c938a3a32b05c6485cc", "width": 640, "height": 379}, {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=624c663a4b6acf911b63a21759c9263ccc97e636", "width": 960, "height": 568}, {"url": "https://external-preview.redd.it/vci22rOGVsZwM2Ocn4TunsfGbmDVBiBNVipfps98DdE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90d0e20fe36c4a3d4f0566a7d0adecbae5a7624e", "width": 1080, "height": 639}], "variants": {}, "id": "TnQxzN00bkfwVrypCHCgQfvGiU84UpN0z0SoGxlTEEE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11mtvay", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mtvay/basic_terminology_and_practices_related_to_graph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/docs/memgraph/tutorials/graph-modeling", "subreddit_subscribers": 92415, "created_utc": 1678372775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1rem", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Synthetic Data? The Good, the Bad, and the Ugly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11mqbmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/IxDnrSz8157WpFL-b1Aa1nQyBoJf0eHOMBnThG-Fjs8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678362999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "benthamsgaze.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.benthamsgaze.org/2023/03/01/what-is-synthetic-data-the-good-the-bad-and-the-ugly/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kXP-77mNxbIloylqArUnm4f6EzHB6u9ilkChuvTi0zU.jpg?auto=webp&amp;v=enabled&amp;s=e24858aaa91995e000913333e8b2207059868c37", "width": 954, "height": 1300}, "resolutions": [{"url": "https://external-preview.redd.it/kXP-77mNxbIloylqArUnm4f6EzHB6u9ilkChuvTi0zU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655b4da6d8cb57d985d7a832e8e96e337b931d0f", "width": 108, "height": 147}, {"url": "https://external-preview.redd.it/kXP-77mNxbIloylqArUnm4f6EzHB6u9ilkChuvTi0zU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9776616e1984c35457a0e6c607f4218e6d92bf1", "width": 216, "height": 294}, {"url": "https://external-preview.redd.it/kXP-77mNxbIloylqArUnm4f6EzHB6u9ilkChuvTi0zU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b92dbf1c60b45081ba4f9bdda109d653f0eda42c", "width": 320, "height": 436}, {"url": "https://external-preview.redd.it/kXP-77mNxbIloylqArUnm4f6EzHB6u9ilkChuvTi0zU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f94322c00edd5cdb6db436207c3bb241ecb55cac", "width": 640, "height": 872}], "variants": {}, "id": "zgDkBsV9O2ZG0GZNOTDp1DeYs_8Dp7Vut6uM2qpM3zY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11mqbmq", "is_robot_indexable": true, "report_reasons": null, "author": "sjmurdoch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mqbmq/what_is_synthetic_data_the_good_the_bad_and_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.benthamsgaze.org/2023/03/01/what-is-synthetic-data-the-good-the-bad-and-the-ugly/", "subreddit_subscribers": 92415, "created_utc": 1678362999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a1z6eog1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code with ChatGPT - SQL and Python examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_11mon3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/yuXxl5CcKBcJAnzWW9WWGe3mkOjLEHi_aX-hXpqgzy0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678356993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "makingmeaning.info", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.makingmeaning.info/post/code-with-chatgpt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?auto=webp&amp;v=enabled&amp;s=28279c0bfdbb179723bddf3b38d1243784f414cc", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7c80de2dce291a927eee08834d9628dc2b45af4", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=737c78418c73862cc4125904279bda1608495104", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=067eceaeca1149f06ccea7c877b70d8529e1da36", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a1522ad6e20ecfec774fce0059643b95d95fa42", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/7Zz4VPBCTyxiVXO07oz5eJbWpN3gY3HrTXiKYrJ6HXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec9f3f325b2f9cf2cdda0b8994e0fac59a725d58", "width": 960, "height": 640}], "variants": {}, "id": "1GjMrrZinpzZ4uWYlgMEKBUtB0rD8r88HPgB-Wgkr3o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11mon3m", "is_robot_indexable": true, "report_reasons": null, "author": "DataAnalyticsDude", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mon3m/code_with_chatgpt_sql_and_python_examples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.makingmeaning.info/post/code-with-chatgpt", "subreddit_subscribers": 92415, "created_utc": 1678356993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a large Python app that I can run with different argumentrs, e.g. `python` [`app.py`](https://app.py/) `--algorithm 1` and `python` [`app.py`](https://app.py/) `--algorithm 2`. To date, I successfully dockerized my app in a large image (\\~750MB). Next, I want to time-schedule runs of those two different algorithms. My idea was to ovveride the CMD command of the docker image and make two different runs of the same image.\n\nHowever, I'm struggling to understand if everytime I have to run a container on the cloud, e.g. with Azure Container Instances, I have to pull the image from another server and pay for the storage/internet throughput, which in my case is huge to the fact that the image is large (\\~750MB) and the time schedule is strict, e.g. every 5 minutes.\n\nAm I missing something? Could you share your ideas or review mine?", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Review needed: is a Docker container a good candidate to refactor my app architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mmy4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678350455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large Python app that I can run with different argumentrs, e.g. &lt;code&gt;python&lt;/code&gt; &lt;a href=\"https://app.py/\"&gt;&lt;code&gt;app.py&lt;/code&gt;&lt;/a&gt; &lt;code&gt;--algorithm 1&lt;/code&gt; and &lt;code&gt;python&lt;/code&gt; &lt;a href=\"https://app.py/\"&gt;&lt;code&gt;app.py&lt;/code&gt;&lt;/a&gt; &lt;code&gt;--algorithm 2&lt;/code&gt;. To date, I successfully dockerized my app in a large image (~750MB). Next, I want to time-schedule runs of those two different algorithms. My idea was to ovveride the CMD command of the docker image and make two different runs of the same image.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m struggling to understand if everytime I have to run a container on the cloud, e.g. with Azure Container Instances, I have to pull the image from another server and pay for the storage/internet throughput, which in my case is huge to the fact that the image is large (~750MB) and the time schedule is strict, e.g. every 5 minutes.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something? Could you share your ideas or review mine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11mmy4n", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mmy4n/review_needed_is_a_docker_container_a_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mmy4n/review_needed_is_a_docker_container_a_good/", "subreddit_subscribers": 92415, "created_utc": 1678350455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m curious whether anyone had played with Data Vault 2.0 DWH architecture in a real graph database such as Neo4j?\n\nGraph databases have nodes and edges. Data Vault has hubs and links. There is a certain similarity right?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault 2.0 in a graph database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mlwyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678346687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m curious whether anyone had played with Data Vault 2.0 DWH architecture in a real graph database such as Neo4j?&lt;/p&gt;\n\n&lt;p&gt;Graph databases have nodes and edges. Data Vault has hubs and links. There is a certain similarity right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11mlwyw", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11mlwyw/data_vault_20_in_a_graph_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11mlwyw/data_vault_20_in_a_graph_database/", "subreddit_subscribers": 92415, "created_utc": 1678346687.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}