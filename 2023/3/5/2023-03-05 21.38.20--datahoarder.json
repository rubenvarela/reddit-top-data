{"kind": "Listing", "data": {"after": "t3_11ils20", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11irtmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 154, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_12sq1qrv", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 154, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "yugioh", "selftext": "", "author_fullname": "t2_13syhz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [{"e": "text", "t": "News"}], "subreddit_name_prefixed": "r/yugioh", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11iiypk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 1658, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "8ef3a3ae-547f-11e2-ae80-12313d14a568", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1658, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": "dark", "author_flair_richtext": [{"e": "text", "t": "Neo Sutoumu Akusesu wa mouhitotsu kouka"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677978000.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4d296664-740b-11e3-bd5d-12313d01b5d1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Neo Sutoumu Akusesu wa mouhitotsu kouka", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2rpe6", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11iiypk", "is_robot_indexable": true, "report_reasons": null, "author": "Terraknor", "discussion_type": null, "num_comments": 283, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/yugioh/comments/11iiypk/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 372501, "created_utc": 1677978000.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678004784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11irtmi", "is_robot_indexable": true, "report_reasons": null, "author": "El-Fougere", "discussion_type": null, "num_comments": 63, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11iiypk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11irtmi/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 672148, "created_utc": 1678004784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16cmrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imaging A Hard Drive With non-ECC Memory - What Could Go Wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11itxdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1678012238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.robertelder.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.robertelder.org/importance-of-ecc-memory/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11itxdy", "is_robot_indexable": true, "report_reasons": null, "author": "rpollost", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11itxdy/imaging_a_hard_drive_with_nonecc_memory_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.robertelder.org/importance-of-ecc-memory/", "subreddit_subscribers": 672148, "created_utc": 1678012238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\nhttps://i.imgur.com/parz99n.png\n\nIs there any tool that could help me clean those and save me the manual work? Any solution to the problem?\n\n\nThank you.", "author_fullname": "t2_l59vrgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enhance bulk scanned documents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11il0xz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677983525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\n&lt;a href=\"https://i.imgur.com/parz99n.png\"&gt;https://i.imgur.com/parz99n.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any tool that could help me clean those and save me the manual work? Any solution to the problem?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?auto=webp&amp;v=enabled&amp;s=06b53542714d1dc4bd4efe10b6f10b034b3f037e", "width": 225, "height": 181}, "resolutions": [{"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4452ea09d312544507f2dd3116f9149ad6ee6ab4", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c27f34273e511a8169bbd67ff3dc5a2f7fea6e", "width": 216, "height": 173}], "variants": {}, "id": "irkNHQewcrOs-s2dNFdRyJrEoCXuTQ2-ve-aqvNTjAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11il0xz", "is_robot_indexable": true, "report_reasons": null, "author": "NotThingRs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "subreddit_subscribers": 672148, "created_utc": 1677983525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_fiawk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD My Book 8TB super concerning noise. I know they click, but this way more than clicking. This is during normal file transfer. It doesn't click as much when idle, but still does. SMART data is perfecta nd Smart self-test also passes (both short and extended)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11j2jvl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Yd_7agO7c3urM1GvEUfA2EjHE1PN-oYcP_v-psnXtUY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678036040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "streamable.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://streamable.com/9ww7bf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?auto=webp&amp;v=enabled&amp;s=33caa23b4510d4e11be74835507dd35cccc97cf0", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a99ad7a8e6e35030fdb150e00a5042a6bfc2677", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebaa2d7529993e2483f80d2e018769d21817bc80", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74f125e7a1cf5d8ad4e763a8b3b7bead0c82e29d", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e847aa03e9b9260eae21434f449b4e2e05d0a8f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=304f12e69da825159f1698afb84b348c4bbb9504", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/px-Iv0h7I8ivhtES_LLntlBzb4v4uxCMZPlkzg1rbUU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e2eb350d0e24b4e47dac8938f5face85f90c6cb", "width": 1080, "height": 607}], "variants": {}, "id": "3J94GffdK9zlXMkKocFwH5yVpxvUyWvimlc8plmEfXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11j2jvl", "is_robot_indexable": true, "report_reasons": null, "author": "Xillenn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j2jvl/wd_my_book_8tb_super_concerning_noise_i_know_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://streamable.com/9ww7bf", "subreddit_subscribers": 672148, "created_utc": 1678036040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for FLACs of some things on the site that are only available on physical media, but can only listen to the 30 second previews. Any way to download the FLAC of the full album?", "author_fullname": "t2_y0gns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive.org \"This item is available with audio samples only\"? Any way to bypass?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11j6dax", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678040393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for FLACs of some things on the site that are only available on physical media, but can only listen to the 30 second previews. Any way to download the FLAC of the full album?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j6dax", "is_robot_indexable": true, "report_reasons": null, "author": "senor_it", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j6dax/archiveorg_this_item_is_available_with_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j6dax/archiveorg_this_item_is_available_with_audio/", "subreddit_subscribers": 672148, "created_utc": 1678040393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I'd  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won't be 300 dollars?", "author_fullname": "t2_hwhmbrl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for ripping a 4K bluray?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iq54i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677998986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I&amp;#39;d  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won&amp;#39;t be 300 dollars?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iq54i", "is_robot_indexable": true, "report_reasons": null, "author": "44nifty", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "subreddit_subscribers": 672148, "created_utc": 1677998986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI've been planning moving from online media center (rclone + gdrive done via CloudBox) into a local one. Decided to go UNRAID route as it seems like the easiest one to achieve that (and it is the easiest way to add more disks in the future without worrying about disks with same sizes and still having some redundancy etc). I would like to have a Plex server there + Home Assistant (I have an another device for that purpose, but I would ditch out that and run it from single machine), backup for my personal devices, Pihole (or AdGuard), 'Arrs and some other docker containers. I am planning to encrypt all disks (in case of some theft etc.)\n\nI would like to know if my plans are okay. \n\nRight now I am planning on buying 4x16TB or 4x18TB (depends on the offer) HDD's (I am leaning towards Seagate Exos one's) which leave me with 48/56TB of usable space.\n\nSpecs:\n\nCase: Fractal Design Node 804 (I would like to have a space for future expansions)\nPSU: Corsair CX-M Modular 450W\nRAM: Some 2x16GB kit, depends which one will be the cheapest one\nSSD cache for apps/containers and write cache:\n2x Silicon Power XD80 1TB mirrored\nCPU: AMD RYZEN 5 3600 with good cooler (have it in my drawer already)\nMOBO: ASROCK B450 Pro4\nSome Bluetooth dongle for Home Assistant \n\nLater I would expand SATA slots with some LSI 9211 card.\n\nPlanning to undervolt and underclock CPU (saw a possibility to run it with +- 0.9V @ 3.1GHz) which would decrease a power consumption of this server by a lot (and don't think that full power be ever needed here).\n\nRegarding not selling Ryzen and going Intel route: I am using Plex, not paying for Plex Pass, so I cannot use a Hardware Transcoding. Anyway, all of my folks have a configuration to only allow a direct play. Secondly, I don't have a cooler bracket for Intel's socket as I do have for AM4.\n\nRight now I will need to move 30TB from cloud to this server. But I will be redownloading most of the stuff. I am not planning on having disk to spin out, as I will be hardlinking Linux ISOs in order to seed them forever from my array so they will be used 24/7. \n\nPlex along with other containers (e.g. Qbittorrent) will be configured with domain address (as it is now) behind login and password based authentication. \n\n\nBesides hardware side, I am still wondering about one thing:\n\nHow I will be able to create a backup of my devices when I will be out of my local network (I know I could do this with VPN connection, but is there any different way to achieve that? I don't want to remember to connect to VPN every time I want to save a backup to my server). Up to this day, for local backup I was using Syncthing, for remote/cloud one I was relying on my old Syncovery licence. \n\n\nWhat do you think, would you do anything differently?", "author_fullname": "t2_exbox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New build question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11j3d1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678036934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been planning moving from online media center (rclone + gdrive done via CloudBox) into a local one. Decided to go UNRAID route as it seems like the easiest one to achieve that (and it is the easiest way to add more disks in the future without worrying about disks with same sizes and still having some redundancy etc). I would like to have a Plex server there + Home Assistant (I have an another device for that purpose, but I would ditch out that and run it from single machine), backup for my personal devices, Pihole (or AdGuard), &amp;#39;Arrs and some other docker containers. I am planning to encrypt all disks (in case of some theft etc.)&lt;/p&gt;\n\n&lt;p&gt;I would like to know if my plans are okay. &lt;/p&gt;\n\n&lt;p&gt;Right now I am planning on buying 4x16TB or 4x18TB (depends on the offer) HDD&amp;#39;s (I am leaning towards Seagate Exos one&amp;#39;s) which leave me with 48/56TB of usable space.&lt;/p&gt;\n\n&lt;p&gt;Specs:&lt;/p&gt;\n\n&lt;p&gt;Case: Fractal Design Node 804 (I would like to have a space for future expansions)\nPSU: Corsair CX-M Modular 450W\nRAM: Some 2x16GB kit, depends which one will be the cheapest one\nSSD cache for apps/containers and write cache:\n2x Silicon Power XD80 1TB mirrored\nCPU: AMD RYZEN 5 3600 with good cooler (have it in my drawer already)\nMOBO: ASROCK B450 Pro4\nSome Bluetooth dongle for Home Assistant &lt;/p&gt;\n\n&lt;p&gt;Later I would expand SATA slots with some LSI 9211 card.&lt;/p&gt;\n\n&lt;p&gt;Planning to undervolt and underclock CPU (saw a possibility to run it with +- 0.9V @ 3.1GHz) which would decrease a power consumption of this server by a lot (and don&amp;#39;t think that full power be ever needed here).&lt;/p&gt;\n\n&lt;p&gt;Regarding not selling Ryzen and going Intel route: I am using Plex, not paying for Plex Pass, so I cannot use a Hardware Transcoding. Anyway, all of my folks have a configuration to only allow a direct play. Secondly, I don&amp;#39;t have a cooler bracket for Intel&amp;#39;s socket as I do have for AM4.&lt;/p&gt;\n\n&lt;p&gt;Right now I will need to move 30TB from cloud to this server. But I will be redownloading most of the stuff. I am not planning on having disk to spin out, as I will be hardlinking Linux ISOs in order to seed them forever from my array so they will be used 24/7. &lt;/p&gt;\n\n&lt;p&gt;Plex along with other containers (e.g. Qbittorrent) will be configured with domain address (as it is now) behind login and password based authentication. &lt;/p&gt;\n\n&lt;p&gt;Besides hardware side, I am still wondering about one thing:&lt;/p&gt;\n\n&lt;p&gt;How I will be able to create a backup of my devices when I will be out of my local network (I know I could do this with VPN connection, but is there any different way to achieve that? I don&amp;#39;t want to remember to connect to VPN every time I want to save a backup to my server). Up to this day, for local backup I was using Syncthing, for remote/cloud one I was relying on my old Syncovery licence. &lt;/p&gt;\n\n&lt;p&gt;What do you think, would you do anything differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j3d1m", "is_robot_indexable": true, "report_reasons": null, "author": "s1lverkin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j3d1m/new_build_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j3d1m/new_build_question/", "subreddit_subscribers": 672148, "created_utc": 1678036934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wanted to check if anyone else has had this problem.\n\nRecently purchased a 2TB PNY and noticed the drive seems to slow to a crawl during large transfers. Anywhere about 100-150 GB will be enough to take the drive from its usually 400-500Mbps write speed to 20-30. The first 100GB will transfer at full speed, then all of a sudden it will drop, sharply.\n\n&amp;#x200B;\n\nIf i cancel the transfer after the speed tanks, wait a minute or so, the drive is back to full speed again. But only to have the same problem if I try the large transfer again.\n\n&amp;#x200B;\n\nThe behavior leads me to think temperature is/was my problem. idk how reliable the tools out there measure but the PNY was coming in @ 36 deg, and only went as high as 38 during the long transfer.\n\n&amp;#x200B;\n\ni have a 500gb Samsung drive that i put through the same test's (on the same SATA cable) and i see none of the problems, my Samsung runs @ 27 deg.\n\n&amp;#x200B;\n\nMy plan was to open it up and slap some heatsinks on, but idk if the temperatures im getting is really anything to worry about.\n\n&amp;#x200B;\n\nAny other ideas?\n\n&amp;#x200B;\n\nlooks like it may be the drive itself. \n\n[https://www.amazon.com/gp/customer-reviews/R1G9GYRBGDASNB/ref=cm\\_cr\\_getr\\_d\\_rvw\\_ttl?ie=UTF8&amp;ASIN=B0722XPTL6](https://www.amazon.com/gp/customer-reviews/R1G9GYRBGDASNB/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&amp;ASIN=B0722XPTL6)", "author_fullname": "t2_w0lu9x09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2tb PNY CS900 500Mbps to 20 on transfers larger than 150gb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11j0kgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678034336.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678032213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to check if anyone else has had this problem.&lt;/p&gt;\n\n&lt;p&gt;Recently purchased a 2TB PNY and noticed the drive seems to slow to a crawl during large transfers. Anywhere about 100-150 GB will be enough to take the drive from its usually 400-500Mbps write speed to 20-30. The first 100GB will transfer at full speed, then all of a sudden it will drop, sharply.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If i cancel the transfer after the speed tanks, wait a minute or so, the drive is back to full speed again. But only to have the same problem if I try the large transfer again.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The behavior leads me to think temperature is/was my problem. idk how reliable the tools out there measure but the PNY was coming in @ 36 deg, and only went as high as 38 during the long transfer.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i have a 500gb Samsung drive that i put through the same test&amp;#39;s (on the same SATA cable) and i see none of the problems, my Samsung runs @ 27 deg.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My plan was to open it up and slap some heatsinks on, but idk if the temperatures im getting is really anything to worry about.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any other ideas?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;looks like it may be the drive itself. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/customer-reviews/R1G9GYRBGDASNB/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&amp;amp;ASIN=B0722XPTL6\"&gt;https://www.amazon.com/gp/customer-reviews/R1G9GYRBGDASNB/ref=cm_cr_getr_d_rvw_ttl?ie=UTF8&amp;amp;ASIN=B0722XPTL6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j0kgh", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Tomorrow_8225", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j0kgh/2tb_pny_cs900_500mbps_to_20_on_transfers_larger/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j0kgh/2tb_pny_cs900_500mbps_to_20_on_transfers_larger/", "subreddit_subscribers": 672148, "created_utc": 1678032213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context: I am downloading a youtube channel and have completely filled my first drive. I'm trying to pick up where I left off on a new drive.\n\nI am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.\n\nI have tried several things, but I am unable to get any of them to work.\n\nwhen running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I've tried running the following command:\n\n    yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n\nevery other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?\n\nby combinations, I mean C:\\WINDOWS\\system32&gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&gt; with the file at the root of E:, etc.", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "yt-dlp: help with --download-archive when moving a previous archive file to a new drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ird8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678003231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context: I am downloading a youtube channel and have completely filled my first drive. I&amp;#39;m trying to pick up where I left off on a new drive.&lt;/p&gt;\n\n&lt;p&gt;I am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.&lt;/p&gt;\n\n&lt;p&gt;I have tried several things, but I am unable to get any of them to work.&lt;/p&gt;\n\n&lt;p&gt;when running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I&amp;#39;ve tried running the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;every other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?&lt;/p&gt;\n\n&lt;p&gt;by combinations, I mean C:\\WINDOWS\\system32&amp;gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&amp;gt; with the file at the root of E:, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ird8w", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "subreddit_subscribers": 672148, "created_utc": 1678003231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm not able to find any information for this in Google, but I'm having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it's pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?\n\nhttps://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04", "author_fullname": "t2_d9n52ija", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to fix timestamp of old screenshots that show a weird date?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jtfpak2qnsla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 168, "x": 108, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75fc411f8e6de724402766d43219aca6715b12ad"}, {"y": 337, "x": 216, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e583c12ed8fcebc4d3ec494e4a012bf39f6171a4"}, {"y": 499, "x": 320, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec979421880362f0375f638310b8bd3fc75eed7f"}], "s": {"y": 660, "x": 423, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04"}, "id": "jtfpak2qnsla1"}}, "name": "t3_11ieiyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0x-OaPSNetEKzp54nHjD58Z9WmrHCLB5fXH0mOk3CxM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not able to find any information for this in Google, but I&amp;#39;m having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it&amp;#39;s pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04\"&gt;https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ieiyy", "is_robot_indexable": true, "report_reasons": null, "author": "SantiagoNub", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "subreddit_subscribers": 672148, "created_utc": 1677967010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to buy a 16tb hdd and have offers for **Seagate IronWolf Pro** (ST16000NE000), **WD Red Pro** (WD161KFGX) &amp; **Toshiba Performance X300** (HDWR31GUZSVA).\n\nThe Seagate has 256mb cache, the WD and Toshiba 512mb.\n\nWhich would you prefer?", "author_fullname": "t2_129wjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "16TB: Seagate IronWolf Pro, Toshiba Performance X300 or WD Red Pro?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iy6f6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678025812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to buy a 16tb hdd and have offers for &lt;strong&gt;Seagate IronWolf Pro&lt;/strong&gt; (ST16000NE000), &lt;strong&gt;WD Red Pro&lt;/strong&gt; (WD161KFGX) &amp;amp; &lt;strong&gt;Toshiba Performance X300&lt;/strong&gt; (HDWR31GUZSVA).&lt;/p&gt;\n\n&lt;p&gt;The Seagate has 256mb cache, the WD and Toshiba 512mb.&lt;/p&gt;\n\n&lt;p&gt;Which would you prefer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iy6f6", "is_robot_indexable": true, "report_reasons": null, "author": "zoomwire", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iy6f6/16tb_seagate_ironwolf_pro_toshiba_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iy6f6/16tb_seagate_ironwolf_pro_toshiba_performance/", "subreddit_subscribers": 672148, "created_utc": 1678025812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Videography individual file sizes (1MB to 100GB)\n\nProject file folder sizes (20GB to 500GB)\n\nTotal current files 18500+ 7TB \n\n&amp;#x200B;\n\nThe Situation:\n\nWhen filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.\n\n(I have two drives for different projects, one for internal department projects and one for everything elce)\n\nThis allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. \n\n&amp;#x200B;\n\nAs a backup and for long-term storage, I copy those project folders to two external hard drives.\n\nThese external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. \n\nThese drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. \n\nNow, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.\n\nBut I also want to minimise the amount of movement, so they don't get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.\n\n&amp;#x200B;\n\nHow to fix it?:\n\nSo is there a program that can be stored on one of the T5 SSD's that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?\n\n(I don't know if I have explained it that well)\n\nBasically, 2 HDD's on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what's on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.\n\n&amp;#x200B;\n\nOr is there another way?\n\nAny help would be much appreciated.", "author_fullname": "t2_jcrm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote syncing of external drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iwinm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678020988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Videography individual file sizes (1MB to 100GB)&lt;/p&gt;\n\n&lt;p&gt;Project file folder sizes (20GB to 500GB)&lt;/p&gt;\n\n&lt;p&gt;Total current files 18500+ 7TB &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Situation:&lt;/p&gt;\n\n&lt;p&gt;When filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.&lt;/p&gt;\n\n&lt;p&gt;(I have two drives for different projects, one for internal department projects and one for everything elce)&lt;/p&gt;\n\n&lt;p&gt;This allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a backup and for long-term storage, I copy those project folders to two external hard drives.&lt;/p&gt;\n\n&lt;p&gt;These external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. &lt;/p&gt;\n\n&lt;p&gt;These drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. &lt;/p&gt;\n\n&lt;p&gt;Now, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.&lt;/p&gt;\n\n&lt;p&gt;But I also want to minimise the amount of movement, so they don&amp;#39;t get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How to fix it?:&lt;/p&gt;\n\n&lt;p&gt;So is there a program that can be stored on one of the T5 SSD&amp;#39;s that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?&lt;/p&gt;\n\n&lt;p&gt;(I don&amp;#39;t know if I have explained it that well)&lt;/p&gt;\n\n&lt;p&gt;Basically, 2 HDD&amp;#39;s on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what&amp;#39;s on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or is there another way?&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iwinm", "is_robot_indexable": true, "report_reasons": null, "author": "Tappitss", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "subreddit_subscribers": 672148, "created_utc": 1678020988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys,\n\nI'm thinking about upgrading my current homeserver and I would like some advice. I'm running into storage limits on my current setup. \n\nMy current setup is: \n\n\\- ASRock J5005-ITX (Pentium Silver, passively cooled)\n\n\\- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)\n\n\\- Samsung 850 EVO 500GB\n\n\\- 3x WD White label 12TB\n\n\\- 1x HGST 4TB HDD\n\n\\- 1x WB Green 4TB HDD\n\n\\- be quiet! System Power B9 300W\n\n\\- Fractal Design Node 304 \n\nThe Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I'm hoarding isn't super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. \n\nMy current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.   \nThe problem I'm running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. \n\nSo my questions are:\n\n1. Which HDD's do you recommend? I'm eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. \n2. Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)\n3. PSU and case recommendations are very welcome!", "author_fullname": "t2_jcfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading my 44TB homeserver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iw4en", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678019731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about upgrading my current homeserver and I would like some advice. I&amp;#39;m running into storage limits on my current setup. &lt;/p&gt;\n\n&lt;p&gt;My current setup is: &lt;/p&gt;\n\n&lt;p&gt;- ASRock J5005-ITX (Pentium Silver, passively cooled)&lt;/p&gt;\n\n&lt;p&gt;- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)&lt;/p&gt;\n\n&lt;p&gt;- Samsung 850 EVO 500GB&lt;/p&gt;\n\n&lt;p&gt;- 3x WD White label 12TB&lt;/p&gt;\n\n&lt;p&gt;- 1x HGST 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- 1x WB Green 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- be quiet! System Power B9 300W&lt;/p&gt;\n\n&lt;p&gt;- Fractal Design Node 304 &lt;/p&gt;\n\n&lt;p&gt;The Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I&amp;#39;m hoarding isn&amp;#39;t super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. &lt;/p&gt;\n\n&lt;p&gt;My current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.&lt;br/&gt;\nThe problem I&amp;#39;m running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. &lt;/p&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which HDD&amp;#39;s do you recommend? I&amp;#39;m eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. &lt;/li&gt;\n&lt;li&gt;Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)&lt;/li&gt;\n&lt;li&gt;PSU and case recommendations are very welcome!&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iw4en", "is_robot_indexable": true, "report_reasons": null, "author": "roogie15", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "subreddit_subscribers": 672148, "created_utc": 1678019731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.\n\nAs far as I've researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.\n\n&amp;#x200B;\n\nOption One: Seagate Exos 16 TB (ST16000NM001G) [Datasheet)](https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf) Price: $223 on Newegg.\n\nOption Two: WD Gold 8 TB (WD8004FRYZ)  [Datasheet](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf) Price: $225 on Newegg.\n\n(Maybe there is an option three: Toshiba 8 TB MG08ADA800E [Datasheet](https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf) Price: $194 on Newegg.\n\nToday I only need 8TB's of space but who says no to extra space? :)\n\nAfter reading the specs, I've  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.\n\nAs you seasoned data hoarders, which one would you choose?", "author_fullname": "t2_ov6uu2h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos vs WD Gold", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ipp69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677998195.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677997506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.&lt;/p&gt;\n\n&lt;p&gt;As far as I&amp;#39;ve researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option One: Seagate Exos 16 TB (ST16000NM001G) &lt;a href=\"https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf\"&gt;Datasheet)&lt;/a&gt; Price: $223 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Option Two: WD Gold 8 TB (WD8004FRYZ)  &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf\"&gt;Datasheet&lt;/a&gt; Price: $225 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;(Maybe there is an option three: Toshiba 8 TB MG08ADA800E &lt;a href=\"https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf\"&gt;Datasheet&lt;/a&gt; Price: $194 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Today I only need 8TB&amp;#39;s of space but who says no to extra space? :)&lt;/p&gt;\n\n&lt;p&gt;After reading the specs, I&amp;#39;ve  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.&lt;/p&gt;\n\n&lt;p&gt;As you seasoned data hoarders, which one would you choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ipp69", "is_robot_indexable": true, "report_reasons": null, "author": "Gammeloni", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "subreddit_subscribers": 672148, "created_utc": 1677997506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm trying to download large folders (Mega) but they're just too big and time out before completion. I've tried it with Jdownloader but without any luck. They're about 14GB and 11GB.\n\nDoes anyone know how this can be done or can access the individual files to make them available on their own?\n\nAny help would be appreciated.", "author_fullname": "t2_tk9orzbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help needed accessing files in large Mega folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ikp7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677982643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m trying to download large folders (Mega) but they&amp;#39;re just too big and time out before completion. I&amp;#39;ve tried it with Jdownloader but without any luck. They&amp;#39;re about 14GB and 11GB.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how this can be done or can access the individual files to make them available on their own?&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ikp7d", "is_robot_indexable": true, "report_reasons": null, "author": "cdnrtrt", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "subreddit_subscribers": 672148, "created_utc": 1677982643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?", "author_fullname": "t2_jdihuowm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get a list of every game on Steam through SteamDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11igw9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677972735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11igw9m", "is_robot_indexable": true, "report_reasons": null, "author": "dunkeyboi77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "subreddit_subscribers": 672148, "created_utc": 1677972735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?", "author_fullname": "t2_4don0ngl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automatic torrents for new content releases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifvlf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677970249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifvlf", "is_robot_indexable": true, "report_reasons": null, "author": "LionSuneater", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "subreddit_subscribers": 672148, "created_utc": 1677970249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 40TB of Movies and TV spread over 8 harddrives in a Drivepool. I'd like to place all the 4K Remux files on some drives.  \n\n\nThe directory structure is: M:/Films/Filmname (year)/Filmname (year) - Remux-2160p.mkv  \n\n\nIs there a way I can search for all files with \"Remux-2160p\" in thier name, but instead of bulk selecting the files... bulk select the folders containing those files?", "author_fullname": "t2_ksyqqly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Select Folders Based on Filenames in Folders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifhl6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677969299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 40TB of Movies and TV spread over 8 harddrives in a Drivepool. I&amp;#39;d like to place all the 4K Remux files on some drives.  &lt;/p&gt;\n\n&lt;p&gt;The directory structure is: M:/Films/Filmname (year)/Filmname (year) - Remux-2160p.mkv  &lt;/p&gt;\n\n&lt;p&gt;Is there a way I can search for all files with &amp;quot;Remux-2160p&amp;quot; in thier name, but instead of bulk selecting the files... bulk select the folders containing those files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifhl6", "is_robot_indexable": true, "report_reasons": null, "author": "Explorer200", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifhl6/select_folders_based_on_filenames_in_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifhl6/select_folders_based_on_filenames_in_folders/", "subreddit_subscribers": 672148, "created_utc": 1677969299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, someone knows a SSD TBW comparison table ?", "author_fullname": "t2_cl76ghrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD TBW Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iexuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, someone knows a SSD TBW comparison table ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iexuc", "is_robot_indexable": true, "report_reasons": null, "author": "BTC_Informer", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "subreddit_subscribers": 672148, "created_utc": 1677967983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\nI use HP Ultrium 1760 SAS LTO4 Tape drives to back up my data hoard(s) and it\u2019s been going well. I got the drive 2nd hand for \u00a330 and it has 93% head life, 99% load/unload life and has been read/writing with great margin ever since.\n\nJust to be safe I bought another one for \u00a330 (to speed up backups as well as have a spare just in case), but when it arrived this one was making a nasty scraping noise reading a tape, with Tape Tools showing the head life was at 76% and failed read/write test with bad margins. Otherwise the drive reported good health.\n\nI am currently have about 8TB backed up, with a total of about 50TB to back up in the end (and that number growing gradually every month).\n\nWhat I\u2019m trying to work out is whether to send it in for service/repair or just buy another second hand? Has anyone had their drives repaired, and can give a rough estimate on what I would expect to pay for repairs? I\u2019m not looking for expedited service, just the basic standard service/repair.\n\nThanks!", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO4 Tape Drive repair estimate costs UK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11j47t7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678037883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI use HP Ultrium 1760 SAS LTO4 Tape drives to back up my data hoard(s) and it\u2019s been going well. I got the drive 2nd hand for \u00a330 and it has 93% head life, 99% load/unload life and has been read/writing with great margin ever since.&lt;/p&gt;\n\n&lt;p&gt;Just to be safe I bought another one for \u00a330 (to speed up backups as well as have a spare just in case), but when it arrived this one was making a nasty scraping noise reading a tape, with Tape Tools showing the head life was at 76% and failed read/write test with bad margins. Otherwise the drive reported good health.&lt;/p&gt;\n\n&lt;p&gt;I am currently have about 8TB backed up, with a total of about 50TB to back up in the end (and that number growing gradually every month).&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m trying to work out is whether to send it in for service/repair or just buy another second hand? Has anyone had their drives repaired, and can give a rough estimate on what I would expect to pay for repairs? I\u2019m not looking for expedited service, just the basic standard service/repair.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j47t7", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j47t7/lto4_tape_drive_repair_estimate_costs_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j47t7/lto4_tape_drive_repair_estimate_costs_uk/", "subreddit_subscribers": 672148, "created_utc": 1678037883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The exact enclosure is [this](https://www.amazon.com/dp/B08J5SLTJX/ref=dp_iou_view_item?ie=UTF8&amp;psc=1) guy. I\u2019m probably missing something, but shouldn\u2019t that work? If not, can anyone please point me in the direction of a more suitable power supply or enclosure?\n\nThank you", "author_fullname": "t2_793w4kvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi all, I got a Seagate Exos X16 14TB and plugged it into my external enclosure that I had a 3TB in. It sounds like it\u2019s beeping. Does it need more power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11j1x20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678035253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The exact enclosure is &lt;a href=\"https://www.amazon.com/dp/B08J5SLTJX/ref=dp_iou_view_item?ie=UTF8&amp;amp;psc=1\"&gt;this&lt;/a&gt; guy. I\u2019m probably missing something, but shouldn\u2019t that work? If not, can anyone please point me in the direction of a more suitable power supply or enclosure?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j1x20", "is_robot_indexable": true, "report_reasons": null, "author": "platynom", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j1x20/hi_all_i_got_a_seagate_exos_x16_14tb_and_plugged/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j1x20/hi_all_i_got_a_seagate_exos_x16_14tb_and_plugged/", "subreddit_subscribers": 672148, "created_utc": 1678035253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am getting this error on my external WD HDD.\n\nIs this a critical error? Should I replace it?   \nDoes the warranty cover these errors?  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd", "author_fullname": "t2_5ggngnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Pending Sector Count", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9zjjoxp11wla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 101, "x": 108, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e52ab88086b1c38c48d71c48265ba96b45d5e796"}, {"y": 203, "x": 216, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfd8378d6b8f24edf53e12e1e3666cb1e6419b82"}, {"y": 301, "x": 320, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b60c326563cb9f0bdb1075cd3700c0c07078a4"}, {"y": 603, "x": 640, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dea3e791a759aa40c17e794a8518c009930853ce"}], "s": {"y": 859, "x": 911, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd"}, "id": "9zjjoxp11wla1"}}, "name": "t3_11isnjw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6DWvmsyJJ5t2OKUTJCdg8G8PYFQ4bajX8NF2CxBuSdM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678007798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting this error on my external WD HDD.&lt;/p&gt;\n\n&lt;p&gt;Is this a critical error? Should I replace it?&lt;br/&gt;\nDoes the warranty cover these errors?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd\"&gt;https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11isnjw", "is_robot_indexable": true, "report_reasons": null, "author": "meshurcanli", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "subreddit_subscribers": 672148, "created_utc": 1678007798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i'm doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don't know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i'm aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one", "author_fullname": "t2_k06v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "unraid like alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iqt4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678001272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;m doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don&amp;#39;t know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i&amp;#39;m aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "69.1TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iqt4s", "is_robot_indexable": true, "report_reasons": null, "author": "duelistjp", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "subreddit_subscribers": 672148, "created_utc": 1678001272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, does it automatically format the destination disk to GPT if it is MBR? And also, what is this:https://ibb.co/JmGj7Dc    What is the backup definition file? Is it large?", "author_fullname": "t2_r0oxj8cl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello fellow hoarders! I want to clone my smaller Win 10 boot ssd to a larger one, using Macrium Reflect free, and have some questions, having never done it before.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ip6d4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677995780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, does it automatically format the destination disk to GPT if it is MBR? And also, what is this:&lt;a href=\"https://ibb.co/JmGj7Dc\"&gt;https://ibb.co/JmGj7Dc&lt;/a&gt;    What is the backup definition file? Is it large?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vzfsZ1KPMJ3cfy6-D52wq8Iym8kzuZ2ueVw8q7ytGKc.jpg?auto=webp&amp;v=enabled&amp;s=6c3d8aad33275bdc3c598d35359c9217fc3c1572", "width": 372, "height": 312}, "resolutions": [{"url": "https://external-preview.redd.it/vzfsZ1KPMJ3cfy6-D52wq8Iym8kzuZ2ueVw8q7ytGKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfefba23dfb905ce4e8645f16cde82479285fac9", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/vzfsZ1KPMJ3cfy6-D52wq8Iym8kzuZ2ueVw8q7ytGKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=731ac949aefcf3f498c9faa2a25375c01eb2648b", "width": 216, "height": 181}, {"url": "https://external-preview.redd.it/vzfsZ1KPMJ3cfy6-D52wq8Iym8kzuZ2ueVw8q7ytGKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=473c2e68d311ec719e91f28f66a0808e15fab501", "width": 320, "height": 268}], "variants": {}, "id": "t2IMnE-bSRqsvB8HkhKpRUWyOipSJD9sqJwEOO4Xfok"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ip6d4", "is_robot_indexable": true, "report_reasons": null, "author": "ggRavingGamer", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ip6d4/hello_fellow_hoarders_i_want_to_clone_my_smaller/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ip6d4/hello_fellow_hoarders_i_want_to_clone_my_smaller/", "subreddit_subscribers": 672148, "created_utc": 1677995780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a WD My book duo 24 TB set to JBOD and no encryption from the beginning and now it's full of data.\n\nI would like to know if I want to take the harddisks inside out and plug it into another HDD docking without formatting, will there be data loss or not?\n\n&amp;#x200B;\n\nAny suggestions are welcome. Thanks", "author_fullname": "t2_134zzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will the data on my HDD be lost if I do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ils20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677985642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a WD My book duo 24 TB set to JBOD and no encryption from the beginning and now it&amp;#39;s full of data.&lt;/p&gt;\n\n&lt;p&gt;I would like to know if I want to take the harddisks inside out and plug it into another HDD docking without formatting, will there be data loss or not?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions are welcome. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ils20", "is_robot_indexable": true, "report_reasons": null, "author": "xxredees", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ils20/will_the_data_on_my_hdd_be_lost_if_i_do_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ils20/will_the_data_on_my_hdd_be_lost_if_i_do_this/", "subreddit_subscribers": 672148, "created_utc": 1677985642.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}