{"kind": "Listing", "data": {"after": "t3_11iqt4s", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_lruux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Memory capacity of a human brain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_11iczr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 1184, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1184, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sVD5BEHjedlo1CkD27-9MJQat2kx_fjH5U3Ya244C-c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677963398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/7ocy7teoutla1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?auto=webp&amp;v=enabled&amp;s=c47f58268dafdf94d25c09f7cb9e1a9b78efd9a5", "width": 828, "height": 371}, "resolutions": [{"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68b368715046c579c62e589588249cc852b124f5", "width": 108, "height": 48}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00751edf67ef092979d0df6af0e9de8fe362e1c5", "width": 216, "height": 96}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69a1ebf1ae37b527a287efee8621afddf90096c4", "width": 320, "height": 143}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61fb9df1d5a973752c9c2602cd648773c1c47db1", "width": 640, "height": 286}], "variants": {}, "id": "FI2rHUm1Xt7_AOoXaBel1HJCQWA0psqnNVBuU8D7T-M"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11iczr7", "is_robot_indexable": true, "report_reasons": null, "author": "Kushtrim11", "discussion_type": null, "num_comments": 212, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iczr7/memory_capacity_of_a_human_brain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/7ocy7teoutla1.jpg", "subreddit_subscribers": 672133, "created_utc": 1677963398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you've been using the \"Get cookies.txt\" Chrome extension, it's tracking you now.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iat1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 119, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_920k5", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 119, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "youtubedl", "selftext": "**[Update from 2023-03-04: The situation is now even worse; the extension is [now also sending all your cookies to the developer, too](https://old.reddit.com/r/youtubedl/comments/11i5vyq/psa_the_get_cookiestxt_extension_is_now_actively/).]**\n\nThe \"Get cookies.txt\" extension updated to version 1.5.0 yesterday and the new update is sending details of **every** page you visit (not just video sites, but every page) back to its developer at the domain \"ck.getcookiestxt.com\". Specifically, for every page you visit, it sends:\n\n* The page address,\n* A unique ID for your browser installation,\n* Your browser's user-agent string (which shows what OS you're using and the browser version number),\n* Your language setting,\n* The platform you're on,\n* The current date/time and your current timezone.\n\nI'd highly recommend moving away from this extension ASAP.\n\nNow for the good news: If you're using `yt-dlp`, you don't need to use this extension! It has a `--cookies-from-browser` switch which allows you to say, for example, `--cookies-from-browser firefox` and it'll get the cookies directly from your browser. There are also advanced usages that allow you to specify decryption keyrings, profile paths, and (for Firefox) container names - see the `yt-dlp --help` output for details.\n\nPlease be careful out there!", "author_fullname": "t2_4rnqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you've been using the \"Get cookies.txt\" Chrome extension, it's tracking you now.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/youtubedl", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ar7o7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 168, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 168, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677949694.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673605585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.youtubedl", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;[Update from 2023-03-04: The situation is now even worse; the extension is &lt;a href=\"https://old.reddit.com/r/youtubedl/comments/11i5vyq/psa_the_get_cookiestxt_extension_is_now_actively/\"&gt;now also sending all your cookies to the developer, too&lt;/a&gt;.]&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;Get cookies.txt&amp;quot; extension updated to version 1.5.0 yesterday and the new update is sending details of &lt;strong&gt;every&lt;/strong&gt; page you visit (not just video sites, but every page) back to its developer at the domain &amp;quot;ck.getcookiestxt.com&amp;quot;. Specifically, for every page you visit, it sends:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The page address,&lt;/li&gt;\n&lt;li&gt;A unique ID for your browser installation,&lt;/li&gt;\n&lt;li&gt;Your browser&amp;#39;s user-agent string (which shows what OS you&amp;#39;re using and the browser version number),&lt;/li&gt;\n&lt;li&gt;Your language setting,&lt;/li&gt;\n&lt;li&gt;The platform you&amp;#39;re on,&lt;/li&gt;\n&lt;li&gt;The current date/time and your current timezone.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d highly recommend moving away from this extension ASAP.&lt;/p&gt;\n\n&lt;p&gt;Now for the good news: If you&amp;#39;re using &lt;code&gt;yt-dlp&lt;/code&gt;, you don&amp;#39;t need to use this extension! It has a &lt;code&gt;--cookies-from-browser&lt;/code&gt; switch which allows you to say, for example, &lt;code&gt;--cookies-from-browser firefox&lt;/code&gt; and it&amp;#39;ll get the cookies directly from your browser. There are also advanced usages that allow you to specify decryption keyrings, profile paths, and (for Firefox) container names - see the &lt;code&gt;yt-dlp --help&lt;/code&gt; output for details.&lt;/p&gt;\n\n&lt;p&gt;Please be careful out there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3fv7b", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ar7o7", "is_robot_indexable": true, "report_reasons": null, "author": "Sophira", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "subreddit_subscribers": 19274, "created_utc": 1673605585.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1677958312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.youtubedl", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "32TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iat1f", "is_robot_indexable": true, "report_reasons": null, "author": "jacroe", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10ar7o7", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11iat1f/if_youve_been_using_the_get_cookiestxt_chrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "subreddit_subscribers": 672133, "created_utc": 1677958312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11irtmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_12sq1qrv", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "yugioh", "selftext": "", "author_fullname": "t2_13syhz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [{"e": "text", "t": "News"}], "subreddit_name_prefixed": "r/yugioh", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11iiypk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1509, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "8ef3a3ae-547f-11e2-ae80-12313d14a568", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1509, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": "dark", "author_flair_richtext": [{"e": "text", "t": "Neo Sutoumu Akusesu wa mouhitotsu kouka"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677978000.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4d296664-740b-11e3-bd5d-12313d01b5d1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Neo Sutoumu Akusesu wa mouhitotsu kouka", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2rpe6", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11iiypk", "is_robot_indexable": true, "report_reasons": null, "author": "Terraknor", "discussion_type": null, "num_comments": 275, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/yugioh/comments/11iiypk/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 372465, "created_utc": 1677978000.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678004784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11irtmi", "is_robot_indexable": true, "report_reasons": null, "author": "El-Fougere", "discussion_type": null, "num_comments": 37, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11iiypk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11irtmi/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 672133, "created_utc": 1678004784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16cmrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imaging A Hard Drive With non-ECC Memory - What Could Go Wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11itxdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1678012238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.robertelder.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.robertelder.org/importance-of-ecc-memory/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11itxdy", "is_robot_indexable": true, "report_reasons": null, "author": "rpollost", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11itxdy/imaging_a_hard_drive_with_nonecc_memory_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.robertelder.org/importance-of-ecc-memory/", "subreddit_subscribers": 672133, "created_utc": 1678012238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\nhttps://i.imgur.com/parz99n.png\n\nIs there any tool that could help me clean those and save me the manual work? Any solution to the problem?\n\n\nThank you.", "author_fullname": "t2_l59vrgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enhance bulk scanned documents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11il0xz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677983525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\n&lt;a href=\"https://i.imgur.com/parz99n.png\"&gt;https://i.imgur.com/parz99n.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any tool that could help me clean those and save me the manual work? Any solution to the problem?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?auto=webp&amp;v=enabled&amp;s=06b53542714d1dc4bd4efe10b6f10b034b3f037e", "width": 225, "height": 181}, "resolutions": [{"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4452ea09d312544507f2dd3116f9149ad6ee6ab4", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c27f34273e511a8169bbd67ff3dc5a2f7fea6e", "width": 216, "height": 173}], "variants": {}, "id": "irkNHQewcrOs-s2dNFdRyJrEoCXuTQ2-ve-aqvNTjAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11il0xz", "is_robot_indexable": true, "report_reasons": null, "author": "NotThingRs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "subreddit_subscribers": 672133, "created_utc": 1677983525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI've been planning moving from online media center (rclone + gdrive done via CloudBox) into a local one. Decided to go UNRAID route as it seems like the easiest one to achieve that (and it is the easiest way to add more disks in the future without worrying about disks with same sizes and still having some redundancy etc). I would like to have a Plex server there + Home Assistant (I have an another device for that purpose, but I would ditch out that and run it from single machine), backup for my personal devices, Pihole (or AdGuard), 'Arrs and some other docker containers. I am planning to encrypt all disks (in case of some theft etc.)\n\nI would like to know if my plans are okay. \n\nRight now I am planning on buying 4x16TB or 4x18TB (depends on the offer) HDD's (I am leaning towards Seagate Exos one's) which leave me with 48/56TB of usable space.\n\nSpecs:\n\nCase: Fractal Design Node 804 (I would like to have a space for future expansions)\nPSU: Corsair CX-M Modular 450W\nRAM: Some 2x16GB kit, depends which one will be the cheapest one\nSSD cache for apps/containers and write cache:\n2x Silicon Power XD80 1TB mirrored\nCPU: AMD RYZEN 5 3600 with good cooler (have it in my drawer already)\nMOBO: ASROCK B450 Pro4\nSome Bluetooth dongle for Home Assistant \n\nLater I would expand SATA slots with some LSI 9211 card.\n\nPlanning to undervolt and underclock CPU (saw a possibility to run it with +- 0.9V @ 3.1GHz) which would decrease a power consumption of this server by a lot (and don't think that full power be ever needed here).\n\nRegarding not selling Ryzen and going Intel route: I am using Plex, not paying for Plex Pass, so I cannot use a Hardware Transcoding. Anyway, all of my folks have a configuration to only allow a direct play. Secondly, I don't have a cooler bracket for Intel's socket as I do have for AM4.\n\nRight now I will need to move 30TB from cloud to this server. But I will be redownloading most of the stuff. I am not planning on having disk to spin out, as I will be hardlinking Linux ISOs in order to seed them forever from my array so they will be used 24/7. \n\nPlex along with other containers (e.g. Qbittorrent) will be configured with domain address (as it is now) behind login and password based authentication. \n\n\nBesides hardware side, I am still wondering about one thing:\n\nHow I will be able to create a backup of my devices when I will be out of my local network (I know I could do this with VPN connection, but is there any different way to achieve that? I don't want to remember to connect to VPN every time I want to save a backup to my server). Up to this day, for local backup I was using Syncthing, for remote/cloud one I was relying on my old Syncovery licence. \n\n\nWhat do you think, would you do anything differently?", "author_fullname": "t2_exbox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New build question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11j3d1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678036934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been planning moving from online media center (rclone + gdrive done via CloudBox) into a local one. Decided to go UNRAID route as it seems like the easiest one to achieve that (and it is the easiest way to add more disks in the future without worrying about disks with same sizes and still having some redundancy etc). I would like to have a Plex server there + Home Assistant (I have an another device for that purpose, but I would ditch out that and run it from single machine), backup for my personal devices, Pihole (or AdGuard), &amp;#39;Arrs and some other docker containers. I am planning to encrypt all disks (in case of some theft etc.)&lt;/p&gt;\n\n&lt;p&gt;I would like to know if my plans are okay. &lt;/p&gt;\n\n&lt;p&gt;Right now I am planning on buying 4x16TB or 4x18TB (depends on the offer) HDD&amp;#39;s (I am leaning towards Seagate Exos one&amp;#39;s) which leave me with 48/56TB of usable space.&lt;/p&gt;\n\n&lt;p&gt;Specs:&lt;/p&gt;\n\n&lt;p&gt;Case: Fractal Design Node 804 (I would like to have a space for future expansions)\nPSU: Corsair CX-M Modular 450W\nRAM: Some 2x16GB kit, depends which one will be the cheapest one\nSSD cache for apps/containers and write cache:\n2x Silicon Power XD80 1TB mirrored\nCPU: AMD RYZEN 5 3600 with good cooler (have it in my drawer already)\nMOBO: ASROCK B450 Pro4\nSome Bluetooth dongle for Home Assistant &lt;/p&gt;\n\n&lt;p&gt;Later I would expand SATA slots with some LSI 9211 card.&lt;/p&gt;\n\n&lt;p&gt;Planning to undervolt and underclock CPU (saw a possibility to run it with +- 0.9V @ 3.1GHz) which would decrease a power consumption of this server by a lot (and don&amp;#39;t think that full power be ever needed here).&lt;/p&gt;\n\n&lt;p&gt;Regarding not selling Ryzen and going Intel route: I am using Plex, not paying for Plex Pass, so I cannot use a Hardware Transcoding. Anyway, all of my folks have a configuration to only allow a direct play. Secondly, I don&amp;#39;t have a cooler bracket for Intel&amp;#39;s socket as I do have for AM4.&lt;/p&gt;\n\n&lt;p&gt;Right now I will need to move 30TB from cloud to this server. But I will be redownloading most of the stuff. I am not planning on having disk to spin out, as I will be hardlinking Linux ISOs in order to seed them forever from my array so they will be used 24/7. &lt;/p&gt;\n\n&lt;p&gt;Plex along with other containers (e.g. Qbittorrent) will be configured with domain address (as it is now) behind login and password based authentication. &lt;/p&gt;\n\n&lt;p&gt;Besides hardware side, I am still wondering about one thing:&lt;/p&gt;\n\n&lt;p&gt;How I will be able to create a backup of my devices when I will be out of my local network (I know I could do this with VPN connection, but is there any different way to achieve that? I don&amp;#39;t want to remember to connect to VPN every time I want to save a backup to my server). Up to this day, for local backup I was using Syncthing, for remote/cloud one I was relying on my old Syncovery licence. &lt;/p&gt;\n\n&lt;p&gt;What do you think, would you do anything differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j3d1m", "is_robot_indexable": true, "report_reasons": null, "author": "s1lverkin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j3d1m/new_build_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j3d1m/new_build_question/", "subreddit_subscribers": 672133, "created_utc": 1678036934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\nI use HP Ultrium 1760 SAS LTO4 Tape drives to back up my data hoard(s) and it\u2019s been going well. I got the drive 2nd hand for \u00a330 and it has 93% head life, 99% load/unload life and has been read/writing with great margin ever since.\n\nJust to be safe I bought another one for \u00a330 (to speed up backups as well as have a spare just in case), but when it arrived this one was making a nasty scraping noise reading a tape, with Tape Tools showing the head life was at 76% and failed read/write test with bad margins. Otherwise the drive reported good health.\n\nI am currently have about 8TB backed up, with a total of about 50TB to back up in the end (and that number growing gradually every month).\n\nWhat I\u2019m trying to work out is whether to send it in for service/repair or just buy another second hand? Has anyone had their drives repaired, and can give a rough estimate on what I would expect to pay for repairs? I\u2019m not looking for expedited service, just the basic standard service/repair.\n\nThanks!", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO4 Tape Drive repair estimate costs UK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11j47t7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678037883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI use HP Ultrium 1760 SAS LTO4 Tape drives to back up my data hoard(s) and it\u2019s been going well. I got the drive 2nd hand for \u00a330 and it has 93% head life, 99% load/unload life and has been read/writing with great margin ever since.&lt;/p&gt;\n\n&lt;p&gt;Just to be safe I bought another one for \u00a330 (to speed up backups as well as have a spare just in case), but when it arrived this one was making a nasty scraping noise reading a tape, with Tape Tools showing the head life was at 76% and failed read/write test with bad margins. Otherwise the drive reported good health.&lt;/p&gt;\n\n&lt;p&gt;I am currently have about 8TB backed up, with a total of about 50TB to back up in the end (and that number growing gradually every month).&lt;/p&gt;\n\n&lt;p&gt;What I\u2019m trying to work out is whether to send it in for service/repair or just buy another second hand? Has anyone had their drives repaired, and can give a rough estimate on what I would expect to pay for repairs? I\u2019m not looking for expedited service, just the basic standard service/repair.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j47t7", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j47t7/lto4_tape_drive_repair_estimate_costs_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j47t7/lto4_tape_drive_repair_estimate_costs_uk/", "subreddit_subscribers": 672133, "created_utc": 1678037883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I'd  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won't be 300 dollars?", "author_fullname": "t2_hwhmbrl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for ripping a 4K bluray?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iq54i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677998986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I&amp;#39;d  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won&amp;#39;t be 300 dollars?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iq54i", "is_robot_indexable": true, "report_reasons": null, "author": "44nifty", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "subreddit_subscribers": 672133, "created_utc": 1677998986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm not able to find any information for this in Google, but I'm having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it's pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?\n\nhttps://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04", "author_fullname": "t2_d9n52ija", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to fix timestamp of old screenshots that show a weird date?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jtfpak2qnsla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 168, "x": 108, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75fc411f8e6de724402766d43219aca6715b12ad"}, {"y": 337, "x": 216, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e583c12ed8fcebc4d3ec494e4a012bf39f6171a4"}, {"y": 499, "x": 320, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec979421880362f0375f638310b8bd3fc75eed7f"}], "s": {"y": 660, "x": 423, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04"}, "id": "jtfpak2qnsla1"}}, "name": "t3_11ieiyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0x-OaPSNetEKzp54nHjD58Z9WmrHCLB5fXH0mOk3CxM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not able to find any information for this in Google, but I&amp;#39;m having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it&amp;#39;s pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04\"&gt;https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ieiyy", "is_robot_indexable": true, "report_reasons": null, "author": "SantiagoNub", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "subreddit_subscribers": 672133, "created_utc": 1677967010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently in the process of downloading an entire youtube channel and it looks like I'm going to run out of space on the drive I'm using. How would you go about picking up a script on a new drive without having it start all over again? \n\nI've searched around and haven't found anything that seems like it would work. I've already downloaded several hundred videos and while I can get a new drive that could hold everything, I would rather not have to transfer the 1.8TB of videos over until I'm done with the whole project.", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new to yt-dlp - needing some help continuing a project onto a new hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ibdhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677959622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the process of downloading an entire youtube channel and it looks like I&amp;#39;m going to run out of space on the drive I&amp;#39;m using. How would you go about picking up a script on a new drive without having it start all over again? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched around and haven&amp;#39;t found anything that seems like it would work. I&amp;#39;ve already downloaded several hundred videos and while I can get a new drive that could hold everything, I would rather not have to transfer the 1.8TB of videos over until I&amp;#39;m done with the whole project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ibdhl", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ibdhl/new_to_ytdlp_needing_some_help_continuing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ibdhl/new_to_ytdlp_needing_some_help_continuing_a/", "subreddit_subscribers": 672133, "created_utc": 1677959622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Videography individual file sizes (1MB to 100GB)\n\nProject file folder sizes (20GB to 500GB)\n\nTotal current files 18500+ 7TB \n\n&amp;#x200B;\n\nThe Situation:\n\nWhen filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.\n\n(I have two drives for different projects, one for internal department projects and one for everything elce)\n\nThis allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. \n\n&amp;#x200B;\n\nAs a backup and for long-term storage, I copy those project folders to two external hard drives.\n\nThese external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. \n\nThese drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. \n\nNow, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.\n\nBut I also want to minimise the amount of movement, so they don't get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.\n\n&amp;#x200B;\n\nHow to fix it?:\n\nSo is there a program that can be stored on one of the T5 SSD's that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?\n\n(I don't know if I have explained it that well)\n\nBasically, 2 HDD's on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what's on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.\n\n&amp;#x200B;\n\nOr is there another way?\n\nAny help would be much appreciated.", "author_fullname": "t2_jcrm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote syncing of external drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iwinm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678020988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Videography individual file sizes (1MB to 100GB)&lt;/p&gt;\n\n&lt;p&gt;Project file folder sizes (20GB to 500GB)&lt;/p&gt;\n\n&lt;p&gt;Total current files 18500+ 7TB &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Situation:&lt;/p&gt;\n\n&lt;p&gt;When filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.&lt;/p&gt;\n\n&lt;p&gt;(I have two drives for different projects, one for internal department projects and one for everything elce)&lt;/p&gt;\n\n&lt;p&gt;This allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a backup and for long-term storage, I copy those project folders to two external hard drives.&lt;/p&gt;\n\n&lt;p&gt;These external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. &lt;/p&gt;\n\n&lt;p&gt;These drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. &lt;/p&gt;\n\n&lt;p&gt;Now, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.&lt;/p&gt;\n\n&lt;p&gt;But I also want to minimise the amount of movement, so they don&amp;#39;t get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How to fix it?:&lt;/p&gt;\n\n&lt;p&gt;So is there a program that can be stored on one of the T5 SSD&amp;#39;s that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?&lt;/p&gt;\n\n&lt;p&gt;(I don&amp;#39;t know if I have explained it that well)&lt;/p&gt;\n\n&lt;p&gt;Basically, 2 HDD&amp;#39;s on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what&amp;#39;s on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or is there another way?&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iwinm", "is_robot_indexable": true, "report_reasons": null, "author": "Tappitss", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "subreddit_subscribers": 672133, "created_utc": 1678020988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys,\n\nI'm thinking about upgrading my current homeserver and I would like some advice. I'm running into storage limits on my current setup. \n\nMy current setup is: \n\n\\- ASRock J5005-ITX (Pentium Silver, passively cooled)\n\n\\- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)\n\n\\- Samsung 850 EVO 500GB\n\n\\- 3x WD White label 12TB\n\n\\- 1x HGST 4TB HDD\n\n\\- 1x WB Green 4TB HDD\n\n\\- be quiet! System Power B9 300W\n\n\\- Fractal Design Node 304 \n\nThe Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I'm hoarding isn't super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. \n\nMy current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.   \nThe problem I'm running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. \n\nSo my questions are:\n\n1. Which HDD's do you recommend? I'm eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. \n2. Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)\n3. PSU and case recommendations are very welcome!", "author_fullname": "t2_jcfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading my 44TB homeserver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iw4en", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678019731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about upgrading my current homeserver and I would like some advice. I&amp;#39;m running into storage limits on my current setup. &lt;/p&gt;\n\n&lt;p&gt;My current setup is: &lt;/p&gt;\n\n&lt;p&gt;- ASRock J5005-ITX (Pentium Silver, passively cooled)&lt;/p&gt;\n\n&lt;p&gt;- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)&lt;/p&gt;\n\n&lt;p&gt;- Samsung 850 EVO 500GB&lt;/p&gt;\n\n&lt;p&gt;- 3x WD White label 12TB&lt;/p&gt;\n\n&lt;p&gt;- 1x HGST 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- 1x WB Green 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- be quiet! System Power B9 300W&lt;/p&gt;\n\n&lt;p&gt;- Fractal Design Node 304 &lt;/p&gt;\n\n&lt;p&gt;The Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I&amp;#39;m hoarding isn&amp;#39;t super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. &lt;/p&gt;\n\n&lt;p&gt;My current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.&lt;br/&gt;\nThe problem I&amp;#39;m running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. &lt;/p&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which HDD&amp;#39;s do you recommend? I&amp;#39;m eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. &lt;/li&gt;\n&lt;li&gt;Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)&lt;/li&gt;\n&lt;li&gt;PSU and case recommendations are very welcome!&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iw4en", "is_robot_indexable": true, "report_reasons": null, "author": "roogie15", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "subreddit_subscribers": 672133, "created_utc": 1678019731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "my warranty is expired, but I want to try to get a repair anyway, cus I have alot of important Minecraft worlds, like alot of the important ones\n\nis there a data recovery service or some kind of insurance I could get to repair it for a reasonable price?", "author_fullname": "t2_8l6uwpdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropped my seagate external hard drive 2tb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifnlm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677969711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my warranty is expired, but I want to try to get a repair anyway, cus I have alot of important Minecraft worlds, like alot of the important ones&lt;/p&gt;\n\n&lt;p&gt;is there a data recovery service or some kind of insurance I could get to repair it for a reasonable price?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifnlm", "is_robot_indexable": true, "report_reasons": null, "author": "Pokemasterkendrew06", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifnlm/dropped_my_seagate_external_hard_drive_2tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifnlm/dropped_my_seagate_external_hard_drive_2tb/", "subreddit_subscribers": 672133, "created_utc": 1677969711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, someone knows a SSD TBW comparison table ?", "author_fullname": "t2_cl76ghrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD TBW Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iexuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, someone knows a SSD TBW comparison table ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iexuc", "is_robot_indexable": true, "report_reasons": null, "author": "BTC_Informer", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "subreddit_subscribers": 672133, "created_utc": 1677967983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The exact enclosure is [this](https://www.amazon.com/dp/B08J5SLTJX/ref=dp_iou_view_item?ie=UTF8&amp;psc=1) guy. I\u2019m probably missing something, but shouldn\u2019t that work? If not, can anyone please point me in the direction of a more suitable power supply or enclosure?\n\nThank you", "author_fullname": "t2_793w4kvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi all, I got a Seagate Exos X16 14TB and plugged it into my external enclosure that I had a 3TB in. It sounds like it\u2019s beeping. Does it need more power?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11j1x20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678035253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The exact enclosure is &lt;a href=\"https://www.amazon.com/dp/B08J5SLTJX/ref=dp_iou_view_item?ie=UTF8&amp;amp;psc=1\"&gt;this&lt;/a&gt; guy. I\u2019m probably missing something, but shouldn\u2019t that work? If not, can anyone please point me in the direction of a more suitable power supply or enclosure?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11j1x20", "is_robot_indexable": true, "report_reasons": null, "author": "platynom", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11j1x20/hi_all_i_got_a_seagate_exos_x16_14tb_and_plugged/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11j1x20/hi_all_i_got_a_seagate_exos_x16_14tb_and_plugged/", "subreddit_subscribers": 672133, "created_utc": 1678035253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to buy a 16tb hdd and have offers for **Seagate IronWolf Pro** (ST16000NE000), **WD Red Pro** (WD161KFGX) &amp; **Toshiba Performance X300** (HDWR31GUZSVA).\n\nThe Seagate has 256mb cache, the WD and Toshiba 512mb.\n\nWhich would you prefer?", "author_fullname": "t2_129wjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "16TB: Seagate IronWolf Pro, Toshiba Performance X300 or WD Red Pro?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iy6f6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678025812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to buy a 16tb hdd and have offers for &lt;strong&gt;Seagate IronWolf Pro&lt;/strong&gt; (ST16000NE000), &lt;strong&gt;WD Red Pro&lt;/strong&gt; (WD161KFGX) &amp;amp; &lt;strong&gt;Toshiba Performance X300&lt;/strong&gt; (HDWR31GUZSVA).&lt;/p&gt;\n\n&lt;p&gt;The Seagate has 256mb cache, the WD and Toshiba 512mb.&lt;/p&gt;\n\n&lt;p&gt;Which would you prefer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iy6f6", "is_robot_indexable": true, "report_reasons": null, "author": "zoomwire", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iy6f6/16tb_seagate_ironwolf_pro_toshiba_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iy6f6/16tb_seagate_ironwolf_pro_toshiba_performance/", "subreddit_subscribers": 672133, "created_utc": 1678025812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context: I am downloading a youtube channel and have completely filled my first drive. I'm trying to pick up where I left off on a new drive.\n\nI am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.\n\nI have tried several things, but I am unable to get any of them to work.\n\nwhen running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I've tried running the following command:\n\n    yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n\nevery other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?\n\nby combinations, I mean C:\\WINDOWS\\system32&gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&gt; with the file at the root of E:, etc.", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "yt-dlp: help with --download-archive when moving a previous archive file to a new drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ird8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678003231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context: I am downloading a youtube channel and have completely filled my first drive. I&amp;#39;m trying to pick up where I left off on a new drive.&lt;/p&gt;\n\n&lt;p&gt;I am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.&lt;/p&gt;\n\n&lt;p&gt;I have tried several things, but I am unable to get any of them to work.&lt;/p&gt;\n\n&lt;p&gt;when running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I&amp;#39;ve tried running the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;every other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?&lt;/p&gt;\n\n&lt;p&gt;by combinations, I mean C:\\WINDOWS\\system32&amp;gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&amp;gt; with the file at the root of E:, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ird8w", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "subreddit_subscribers": 672133, "created_utc": 1678003231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.\n\nAs far as I've researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.\n\n&amp;#x200B;\n\nOption One: Seagate Exos 16 TB (ST16000NM001G) [Datasheet)](https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf) Price: $223 on Newegg.\n\nOption Two: WD Gold 8 TB (WD8004FRYZ)  [Datasheet](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf) Price: $225 on Newegg.\n\n(Maybe there is an option three: Toshiba 8 TB MG08ADA800E [Datasheet](https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf) Price: $194 on Newegg.\n\nToday I only need 8TB's of space but who says no to extra space? :)\n\nAfter reading the specs, I've  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.\n\nAs you seasoned data hoarders, which one would you choose?", "author_fullname": "t2_ov6uu2h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos vs WD Gold", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ipp69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677998195.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677997506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.&lt;/p&gt;\n\n&lt;p&gt;As far as I&amp;#39;ve researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option One: Seagate Exos 16 TB (ST16000NM001G) &lt;a href=\"https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf\"&gt;Datasheet)&lt;/a&gt; Price: $223 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Option Two: WD Gold 8 TB (WD8004FRYZ)  &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf\"&gt;Datasheet&lt;/a&gt; Price: $225 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;(Maybe there is an option three: Toshiba 8 TB MG08ADA800E &lt;a href=\"https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf\"&gt;Datasheet&lt;/a&gt; Price: $194 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Today I only need 8TB&amp;#39;s of space but who says no to extra space? :)&lt;/p&gt;\n\n&lt;p&gt;After reading the specs, I&amp;#39;ve  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.&lt;/p&gt;\n\n&lt;p&gt;As you seasoned data hoarders, which one would you choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ipp69", "is_robot_indexable": true, "report_reasons": null, "author": "Gammeloni", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "subreddit_subscribers": 672133, "created_utc": 1677997506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm trying to download large folders (Mega) but they're just too big and time out before completion. I've tried it with Jdownloader but without any luck. They're about 14GB and 11GB.\n\nDoes anyone know how this can be done or can access the individual files to make them available on their own?\n\nAny help would be appreciated.", "author_fullname": "t2_tk9orzbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help needed accessing files in large Mega folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ikp7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677982643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m trying to download large folders (Mega) but they&amp;#39;re just too big and time out before completion. I&amp;#39;ve tried it with Jdownloader but without any luck. They&amp;#39;re about 14GB and 11GB.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how this can be done or can access the individual files to make them available on their own?&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ikp7d", "is_robot_indexable": true, "report_reasons": null, "author": "cdnrtrt", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "subreddit_subscribers": 672133, "created_utc": 1677982643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a sister post to one I made on data recovery, but the short story is that my 4tb HDD (Seagate barracuda laptop sized) failed. I'm working to get that back (see my data recovery post for more on that). I am looking to replace it with a more redundant setup\n\nMy idea is to have 4 drives: my SSD i use now for windows (it is almost full),  2 8tb WD blues in raid 1 for working on. And 1 separate 8tb WD blue fro storing games (they can fail, steam backs up saves) as well as periodic copies of my data.\n\nThen for my personal projects I plan on using a private GitHub.", "author_fullname": "t2_15bclw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for advice to replace hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ijzyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677980743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a sister post to one I made on data recovery, but the short story is that my 4tb HDD (Seagate barracuda laptop sized) failed. I&amp;#39;m working to get that back (see my data recovery post for more on that). I am looking to replace it with a more redundant setup&lt;/p&gt;\n\n&lt;p&gt;My idea is to have 4 drives: my SSD i use now for windows (it is almost full),  2 8tb WD blues in raid 1 for working on. And 1 separate 8tb WD blue fro storing games (they can fail, steam backs up saves) as well as periodic copies of my data.&lt;/p&gt;\n\n&lt;p&gt;Then for my personal projects I plan on using a private GitHub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ijzyw", "is_robot_indexable": true, "report_reasons": null, "author": "Sligee", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ijzyw/looking_for_advice_to_replace_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ijzyw/looking_for_advice_to_replace_hard_drive/", "subreddit_subscribers": 672133, "created_utc": 1677980743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?", "author_fullname": "t2_jdihuowm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get a list of every game on Steam through SteamDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11igw9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677972735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11igw9m", "is_robot_indexable": true, "report_reasons": null, "author": "dunkeyboi77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "subreddit_subscribers": 672133, "created_utc": 1677972735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?", "author_fullname": "t2_4don0ngl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automatic torrents for new content releases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifvlf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677970249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifvlf", "is_robot_indexable": true, "report_reasons": null, "author": "LionSuneater", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "subreddit_subscribers": 672133, "created_utc": 1677970249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 40TB of Movies and TV spread over 8 harddrives in a Drivepool. I'd like to place all the 4K Remux files on some drives.  \n\n\nThe directory structure is: M:/Films/Filmname (year)/Filmname (year) - Remux-2160p.mkv  \n\n\nIs there a way I can search for all files with \"Remux-2160p\" in thier name, but instead of bulk selecting the files... bulk select the folders containing those files?", "author_fullname": "t2_ksyqqly", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Select Folders Based on Filenames in Folders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifhl6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677969299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 40TB of Movies and TV spread over 8 harddrives in a Drivepool. I&amp;#39;d like to place all the 4K Remux files on some drives.  &lt;/p&gt;\n\n&lt;p&gt;The directory structure is: M:/Films/Filmname (year)/Filmname (year) - Remux-2160p.mkv  &lt;/p&gt;\n\n&lt;p&gt;Is there a way I can search for all files with &amp;quot;Remux-2160p&amp;quot; in thier name, but instead of bulk selecting the files... bulk select the folders containing those files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifhl6", "is_robot_indexable": true, "report_reasons": null, "author": "Explorer200", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifhl6/select_folders_based_on_filenames_in_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifhl6/select_folders_based_on_filenames_in_folders/", "subreddit_subscribers": 672133, "created_utc": 1677969299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am getting this error on my external WD HDD.\n\nIs this a critical error? Should I replace it?   \nDoes the warranty cover these errors?  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd", "author_fullname": "t2_5ggngnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Pending Sector Count", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9zjjoxp11wla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 101, "x": 108, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e52ab88086b1c38c48d71c48265ba96b45d5e796"}, {"y": 203, "x": 216, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfd8378d6b8f24edf53e12e1e3666cb1e6419b82"}, {"y": 301, "x": 320, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b60c326563cb9f0bdb1075cd3700c0c07078a4"}, {"y": 603, "x": 640, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dea3e791a759aa40c17e794a8518c009930853ce"}], "s": {"y": 859, "x": 911, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd"}, "id": "9zjjoxp11wla1"}}, "name": "t3_11isnjw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6DWvmsyJJ5t2OKUTJCdg8G8PYFQ4bajX8NF2CxBuSdM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678007798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting this error on my external WD HDD.&lt;/p&gt;\n\n&lt;p&gt;Is this a critical error? Should I replace it?&lt;br/&gt;\nDoes the warranty cover these errors?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd\"&gt;https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11isnjw", "is_robot_indexable": true, "report_reasons": null, "author": "meshurcanli", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "subreddit_subscribers": 672133, "created_utc": 1678007798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i'm doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don't know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i'm aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one", "author_fullname": "t2_k06v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "unraid like alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iqt4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678001272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;m doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don&amp;#39;t know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i&amp;#39;m aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "69.1TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iqt4s", "is_robot_indexable": true, "report_reasons": null, "author": "duelistjp", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "subreddit_subscribers": 672133, "created_utc": 1678001272.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}