{"kind": "Listing", "data": {"after": "t3_11isnjw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_lruux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Memory capacity of a human brain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_11iczr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 948, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 948, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sVD5BEHjedlo1CkD27-9MJQat2kx_fjH5U3Ya244C-c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677963398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/7ocy7teoutla1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?auto=webp&amp;v=enabled&amp;s=c47f58268dafdf94d25c09f7cb9e1a9b78efd9a5", "width": 828, "height": 371}, "resolutions": [{"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68b368715046c579c62e589588249cc852b124f5", "width": 108, "height": 48}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00751edf67ef092979d0df6af0e9de8fe362e1c5", "width": 216, "height": 96}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69a1ebf1ae37b527a287efee8621afddf90096c4", "width": 320, "height": 143}, {"url": "https://preview.redd.it/7ocy7teoutla1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61fb9df1d5a973752c9c2602cd648773c1c47db1", "width": 640, "height": 286}], "variants": {}, "id": "FI2rHUm1Xt7_AOoXaBel1HJCQWA0psqnNVBuU8D7T-M"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11iczr7", "is_robot_indexable": true, "report_reasons": null, "author": "Kushtrim11", "discussion_type": null, "num_comments": 182, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iczr7/memory_capacity_of_a_human_brain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/7ocy7teoutla1.jpg", "subreddit_subscribers": 672111, "created_utc": 1677963398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you've been using the \"Get cookies.txt\" Chrome extension, it's tracking you now.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iat1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_920k5", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "youtubedl", "selftext": "**[Update from 2023-03-04: The situation is now even worse; the extension is [now also sending all your cookies to the developer, too](https://old.reddit.com/r/youtubedl/comments/11i5vyq/psa_the_get_cookiestxt_extension_is_now_actively/).]**\n\nThe \"Get cookies.txt\" extension updated to version 1.5.0 yesterday and the new update is sending details of **every** page you visit (not just video sites, but every page) back to its developer at the domain \"ck.getcookiestxt.com\". Specifically, for every page you visit, it sends:\n\n* The page address,\n* A unique ID for your browser installation,\n* Your browser's user-agent string (which shows what OS you're using and the browser version number),\n* Your language setting,\n* The platform you're on,\n* The current date/time and your current timezone.\n\nI'd highly recommend moving away from this extension ASAP.\n\nNow for the good news: If you're using `yt-dlp`, you don't need to use this extension! It has a `--cookies-from-browser` switch which allows you to say, for example, `--cookies-from-browser firefox` and it'll get the cookies directly from your browser. There are also advanced usages that allow you to specify decryption keyrings, profile paths, and (for Firefox) container names - see the `yt-dlp --help` output for details.\n\nPlease be careful out there!", "author_fullname": "t2_4rnqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you've been using the \"Get cookies.txt\" Chrome extension, it's tracking you now.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/youtubedl", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ar7o7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 164, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 164, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677949694.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673605585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.youtubedl", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;[Update from 2023-03-04: The situation is now even worse; the extension is &lt;a href=\"https://old.reddit.com/r/youtubedl/comments/11i5vyq/psa_the_get_cookiestxt_extension_is_now_actively/\"&gt;now also sending all your cookies to the developer, too&lt;/a&gt;.]&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;Get cookies.txt&amp;quot; extension updated to version 1.5.0 yesterday and the new update is sending details of &lt;strong&gt;every&lt;/strong&gt; page you visit (not just video sites, but every page) back to its developer at the domain &amp;quot;ck.getcookiestxt.com&amp;quot;. Specifically, for every page you visit, it sends:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The page address,&lt;/li&gt;\n&lt;li&gt;A unique ID for your browser installation,&lt;/li&gt;\n&lt;li&gt;Your browser&amp;#39;s user-agent string (which shows what OS you&amp;#39;re using and the browser version number),&lt;/li&gt;\n&lt;li&gt;Your language setting,&lt;/li&gt;\n&lt;li&gt;The platform you&amp;#39;re on,&lt;/li&gt;\n&lt;li&gt;The current date/time and your current timezone.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d highly recommend moving away from this extension ASAP.&lt;/p&gt;\n\n&lt;p&gt;Now for the good news: If you&amp;#39;re using &lt;code&gt;yt-dlp&lt;/code&gt;, you don&amp;#39;t need to use this extension! It has a &lt;code&gt;--cookies-from-browser&lt;/code&gt; switch which allows you to say, for example, &lt;code&gt;--cookies-from-browser firefox&lt;/code&gt; and it&amp;#39;ll get the cookies directly from your browser. There are also advanced usages that allow you to specify decryption keyrings, profile paths, and (for Firefox) container names - see the &lt;code&gt;yt-dlp --help&lt;/code&gt; output for details.&lt;/p&gt;\n\n&lt;p&gt;Please be careful out there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3fv7b", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ar7o7", "is_robot_indexable": true, "report_reasons": null, "author": "Sophira", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "subreddit_subscribers": 19266, "created_utc": 1673605585.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1677958312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.youtubedl", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "32TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iat1f", "is_robot_indexable": true, "report_reasons": null, "author": "jacroe", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10ar7o7", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11iat1f/if_youve_been_using_the_get_cookiestxt_chrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/youtubedl/comments/10ar7o7/if_youve_been_using_the_get_cookiestxt_chrome/", "subreddit_subscribers": 672111, "created_utc": 1677958312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16cmrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imaging A Hard Drive With non-ECC Memory - What Could Go Wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11itxdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1678012238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.robertelder.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.robertelder.org/importance-of-ecc-memory/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11itxdy", "is_robot_indexable": true, "report_reasons": null, "author": "rpollost", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11itxdy/imaging_a_hard_drive_with_nonecc_memory_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.robertelder.org/importance-of-ecc-memory/", "subreddit_subscribers": 672111, "created_utc": 1678012238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\nhttps://i.imgur.com/parz99n.png\n\nIs there any tool that could help me clean those and save me the manual work? Any solution to the problem?\n\n\nThank you.", "author_fullname": "t2_l59vrgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Enhance bulk scanned documents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11il0xz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677983525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so I have around 600 documents that needs to be cleaned and enhanced and put into a book, the wrost of them look look like this:\n&lt;a href=\"https://i.imgur.com/parz99n.png\"&gt;https://i.imgur.com/parz99n.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there any tool that could help me clean those and save me the manual work? Any solution to the problem?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?auto=webp&amp;v=enabled&amp;s=06b53542714d1dc4bd4efe10b6f10b034b3f037e", "width": 225, "height": 181}, "resolutions": [{"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4452ea09d312544507f2dd3116f9149ad6ee6ab4", "width": 108, "height": 86}, {"url": "https://external-preview.redd.it/ZLlDnGJAbWwPuPBRRnDdzyGp5kKa1Qul8Nv5iGbFW1k.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0c27f34273e511a8169bbd67ff3dc5a2f7fea6e", "width": 216, "height": 173}], "variants": {}, "id": "irkNHQewcrOs-s2dNFdRyJrEoCXuTQ2-ve-aqvNTjAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11il0xz", "is_robot_indexable": true, "report_reasons": null, "author": "NotThingRs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11il0xz/enhance_bulk_scanned_documents/", "subreddit_subscribers": 672111, "created_utc": 1677983525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11irtmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_12sq1qrv", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "yugioh", "selftext": "", "author_fullname": "t2_13syhz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dan Parker has accidentally deleted Yugipedia without recent backup", "link_flair_richtext": [{"e": "text", "t": "News"}], "subreddit_name_prefixed": "r/yugioh", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 45, "top_awarded_type": null, "hide_score": false, "name": "t3_11iiypk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1272, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "8ef3a3ae-547f-11e2-ae80-12313d14a568", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1272, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fLU469q7bBSQLOYzW0ZpvaQxh4g1Usl4BbFC6gJ9VFI.jpg", "edited": false, "author_flair_css_class": "dark", "author_flair_richtext": [{"e": "text", "t": "Neo Sutoumu Akusesu wa mouhitotsu kouka"}], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677978000.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "richtext", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4d296664-740b-11e3-bd5d-12313d01b5d1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Neo Sutoumu Akusesu wa mouhitotsu kouka", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2rpe6", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11iiypk", "is_robot_indexable": true, "report_reasons": null, "author": "Terraknor", "discussion_type": null, "num_comments": 248, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/yugioh/comments/11iiypk/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 372435, "created_utc": 1677978000.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678004784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/q7ikvaehktla1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/q7ikvaehktla1.png?auto=webp&amp;v=enabled&amp;s=d52290939461b0aa097cbb739b9ec24199c4e0fe", "width": 1296, "height": 424}, "resolutions": [{"url": "https://preview.redd.it/q7ikvaehktla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3e4cc37742a646be92a58572e5de8aa8347eac", "width": 108, "height": 35}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ce130718a909e9603fd26fbd1a73472e45d96c5", "width": 216, "height": 70}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86dfc94b989e0d12a2adde4950fed2feda412eb0", "width": 320, "height": 104}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d530ef1c5a4ba259804cde65c3342961a6d2d40b", "width": 640, "height": 209}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eda05b3d84a26f225b936c06f4e52cfa8ba49f4", "width": 960, "height": 314}, {"url": "https://preview.redd.it/q7ikvaehktla1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d8b014b6ec351332c46d64f0d0f06c58c3a37d5", "width": 1080, "height": 353}], "variants": {}, "id": "9v6qEbVDSMkjigx8T-g2X-LsbiW_Hr0dQyYCTHu15zY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11irtmi", "is_robot_indexable": true, "report_reasons": null, "author": "El-Fougere", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11iiypk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11irtmi/dan_parker_has_accidentally_deleted_yugipedia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/q7ikvaehktla1.png", "subreddit_subscribers": 672111, "created_utc": 1678004784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "my warranty is expired, but I want to try to get a repair anyway, cus I have alot of important Minecraft worlds, like alot of the important ones\n\nis there a data recovery service or some kind of insurance I could get to repair it for a reasonable price?", "author_fullname": "t2_8l6uwpdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropped my seagate external hard drive 2tb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifnlm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677969711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my warranty is expired, but I want to try to get a repair anyway, cus I have alot of important Minecraft worlds, like alot of the important ones&lt;/p&gt;\n\n&lt;p&gt;is there a data recovery service or some kind of insurance I could get to repair it for a reasonable price?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifnlm", "is_robot_indexable": true, "report_reasons": null, "author": "Pokemasterkendrew06", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifnlm/dropped_my_seagate_external_hard_drive_2tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifnlm/dropped_my_seagate_external_hard_drive_2tb/", "subreddit_subscribers": 672111, "created_utc": 1677969711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I work in movie art departments and I have a ton of blurays of movies that I really enjoy the production design of and often go back to watch the special features and look through the concept art. \n\nIf I like a movie a lot, I usually buy the most expansive, highest quality edition available just for the special features and production diaries.\n\nThe googleable, popular methods of archiving movies seem to just be focussed on grabbing the feature alone without the ability to use the menus or other stuff, but I would like to have access to the full disk image on my NAS.\n\nDoes anyone know of any way I can have a library of ISOs available on my TV from my NAS? I see that Plex doesn't support ISOs anymore which is a shame.\n\nIts a niche use case but it would be very useful for space saving in my apartment!", "author_fullname": "t2_eq196", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to stream .iso to my TV from a NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11ix46t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678023231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678022804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in movie art departments and I have a ton of blurays of movies that I really enjoy the production design of and often go back to watch the special features and look through the concept art. &lt;/p&gt;\n\n&lt;p&gt;If I like a movie a lot, I usually buy the most expansive, highest quality edition available just for the special features and production diaries.&lt;/p&gt;\n\n&lt;p&gt;The googleable, popular methods of archiving movies seem to just be focussed on grabbing the feature alone without the ability to use the menus or other stuff, but I would like to have access to the full disk image on my NAS.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of any way I can have a library of ISOs available on my TV from my NAS? I see that Plex doesn&amp;#39;t support ISOs anymore which is a shame.&lt;/p&gt;\n\n&lt;p&gt;Its a niche use case but it would be very useful for space saving in my apartment!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ix46t", "is_robot_indexable": true, "report_reasons": null, "author": "jpjapers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ix46t/any_way_to_stream_iso_to_my_tv_from_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ix46t/any_way_to_stream_iso_to_my_tv_from_a_nas/", "subreddit_subscribers": 672111, "created_utc": 1678022804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Videography individual file sizes (1MB to 100GB)\n\nProject file folder sizes (20GB to 500GB)\n\nTotal current files 18500+ 7TB \n\n&amp;#x200B;\n\nThe Situation:\n\nWhen filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.\n\n(I have two drives for different projects, one for internal department projects and one for everything elce)\n\nThis allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. \n\n&amp;#x200B;\n\nAs a backup and for long-term storage, I copy those project folders to two external hard drives.\n\nThese external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. \n\nThese drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. \n\nNow, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.\n\nBut I also want to minimise the amount of movement, so they don't get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.\n\n&amp;#x200B;\n\nHow to fix it?:\n\nSo is there a program that can be stored on one of the T5 SSD's that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?\n\n(I don't know if I have explained it that well)\n\nBasically, 2 HDD's on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what's on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.\n\n&amp;#x200B;\n\nOr is there another way?\n\nAny help would be much appreciated.", "author_fullname": "t2_jcrm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remote syncing of external drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11iwinm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678020988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Videography individual file sizes (1MB to 100GB)&lt;/p&gt;\n\n&lt;p&gt;Project file folder sizes (20GB to 500GB)&lt;/p&gt;\n\n&lt;p&gt;Total current files 18500+ 7TB &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Situation:&lt;/p&gt;\n\n&lt;p&gt;When filming, I usually pull the files from the cameras and put them onto one of my two 1TB Samsung t5 drives that I edit off.&lt;/p&gt;\n\n&lt;p&gt;(I have two drives for different projects, one for internal department projects and one for everything elce)&lt;/p&gt;\n\n&lt;p&gt;This allows me to work on projects from home, and then I just sync them to long-term storage when I get back to the office. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As a backup and for long-term storage, I copy those project folders to two external hard drives.&lt;/p&gt;\n\n&lt;p&gt;These external drives are generally plugged into my workstation in the office, but from time to time, I have to take them home when I need to do stuff on older projects or other tasks. &lt;/p&gt;\n\n&lt;p&gt;These drives have a copy of all video footage that has been taken in the last four years, and some of the projects are not released yet, so they are basically the masters. &lt;/p&gt;\n\n&lt;p&gt;Now, these drives are getting to capacity, and I will need to buy two more for projects 2023 and onwards, but I still need access to the older stuff, so I will need the older drives plugged in as well.&lt;/p&gt;\n\n&lt;p&gt;But I also want to minimise the amount of movement, so they don&amp;#39;t get damaged. But It would be nice to have the drives split in two locations (offsite backup), but I need to keep them both synced somehow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How to fix it?:&lt;/p&gt;\n\n&lt;p&gt;So is there a program that can be stored on one of the T5 SSD&amp;#39;s that reads the project folders in, say the office, but when plugged into the home PC, can see the changes and temporarily stores the needed files on the SSD and then copies them when plugged into the workstation in the office?&lt;/p&gt;\n\n&lt;p&gt;(I don&amp;#39;t know if I have explained it that well)&lt;/p&gt;\n\n&lt;p&gt;Basically, 2 HDD&amp;#39;s on two separate computers that are basically air-gapped but will use an external SSD that can be moved between the locations that will keep a list of what&amp;#39;s on each and copy the needed files/updated files onto the SSD for it to then copy into the other location and vice versa.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or is there another way?&lt;/p&gt;\n\n&lt;p&gt;Any help would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iwinm", "is_robot_indexable": true, "report_reasons": null, "author": "Tappitss", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iwinm/remote_syncing_of_external_drives/", "subreddit_subscribers": 672111, "created_utc": 1678020988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys,\n\nI'm thinking about upgrading my current homeserver and I would like some advice. I'm running into storage limits on my current setup. \n\nMy current setup is: \n\n\\- ASRock J5005-ITX (Pentium Silver, passively cooled)\n\n\\- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)\n\n\\- Samsung 850 EVO 500GB\n\n\\- 3x WD White label 12TB\n\n\\- 1x HGST 4TB HDD\n\n\\- 1x WB Green 4TB HDD\n\n\\- be quiet! System Power B9 300W\n\n\\- Fractal Design Node 304 \n\nThe Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I'm hoarding isn't super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. \n\nMy current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.   \nThe problem I'm running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. \n\nSo my questions are:\n\n1. Which HDD's do you recommend? I'm eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. \n2. Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)\n3. PSU and case recommendations are very welcome!", "author_fullname": "t2_jcfky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading my 44TB homeserver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iw4en", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678019731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about upgrading my current homeserver and I would like some advice. I&amp;#39;m running into storage limits on my current setup. &lt;/p&gt;\n\n&lt;p&gt;My current setup is: &lt;/p&gt;\n\n&lt;p&gt;- ASRock J5005-ITX (Pentium Silver, passively cooled)&lt;/p&gt;\n\n&lt;p&gt;- G.Skill Ripjaws F4-2666C18D-8GRS (2x4GB)&lt;/p&gt;\n\n&lt;p&gt;- Samsung 850 EVO 500GB&lt;/p&gt;\n\n&lt;p&gt;- 3x WD White label 12TB&lt;/p&gt;\n\n&lt;p&gt;- 1x HGST 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- 1x WB Green 4TB HDD&lt;/p&gt;\n\n&lt;p&gt;- be quiet! System Power B9 300W&lt;/p&gt;\n\n&lt;p&gt;- Fractal Design Node 304 &lt;/p&gt;\n\n&lt;p&gt;The Samsung EVO is my system disk running OMV with a bunch of dockers. The other disks are all running in JBOD. The data I&amp;#39;m hoarding isn&amp;#39;t super important, I just like hoarding movies, tv shows, porn etc. I addition I would like to set up some CCTV around my apartment. &lt;/p&gt;\n\n&lt;p&gt;My current plans are to remove the 2x4TB disks (containing media) and replace them with 2x 18 TB disks, the Toshiba M09 for example. However this wont let me upgrade further in the future.&lt;br/&gt;\nThe problem I&amp;#39;m running into is that my case can only hold 6 disks and my current PSU only has 6 connectors for SATA devices, which is also maxed out currently. &lt;/p&gt;\n\n&lt;p&gt;So my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Which HDD&amp;#39;s do you recommend? I&amp;#39;m eyeing 18TB drives atm as they appear to be the best price/TB in The Netherlands and neighbouring countries. &lt;/li&gt;\n&lt;li&gt;Would you recommend waiting for a bit as rumours are bigger disks are being released this year? (Perhaps making the 20-22TB disks more attractive?)&lt;/li&gt;\n&lt;li&gt;PSU and case recommendations are very welcome!&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iw4en", "is_robot_indexable": true, "report_reasons": null, "author": "roogie15", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iw4en/upgrading_my_44tb_homeserver/", "subreddit_subscribers": 672111, "created_utc": 1678019731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was just wondering a few things like, is there actually access to old articles? Can you download old articles or is it more like a web reader thing with drm in it? If so, what format are they in? PDF? Also, is there a limit you have found? I'd like to get a subscription and download some stuff. I don't know if I would be doing anything serious like w-get, etc. But in case I decided to do that, I'm just wondering what these digital perks look like in reality. Thank you", "author_fullname": "t2_sn9i9n2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody in here have subscriptions like The Atlantic, New York Times, New Yorker? Is it true you can download old articles from these places?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11isfnr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678007285.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678006986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just wondering a few things like, is there actually access to old articles? Can you download old articles or is it more like a web reader thing with drm in it? If so, what format are they in? PDF? Also, is there a limit you have found? I&amp;#39;d like to get a subscription and download some stuff. I don&amp;#39;t know if I would be doing anything serious like w-get, etc. But in case I decided to do that, I&amp;#39;m just wondering what these digital perks look like in reality. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11isfnr", "is_robot_indexable": true, "report_reasons": null, "author": "Peruvian_Poo_Pickler", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11isfnr/anybody_in_here_have_subscriptions_like_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11isfnr/anybody_in_here_have_subscriptions_like_the/", "subreddit_subscribers": 672111, "created_utc": 1678006986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm not able to find any information for this in Google, but I'm having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it's pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?\n\nhttps://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04", "author_fullname": "t2_d9n52ija", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to fix timestamp of old screenshots that show a weird date?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jtfpak2qnsla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 168, "x": 108, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75fc411f8e6de724402766d43219aca6715b12ad"}, {"y": 337, "x": 216, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e583c12ed8fcebc4d3ec494e4a012bf39f6171a4"}, {"y": 499, "x": 320, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec979421880362f0375f638310b8bd3fc75eed7f"}], "s": {"y": 660, "x": 423, "u": "https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04"}, "id": "jtfpak2qnsla1"}}, "name": "t3_11ieiyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0x-OaPSNetEKzp54nHjD58Z9WmrHCLB5fXH0mOk3CxM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not able to find any information for this in Google, but I&amp;#39;m having problems with my old screenshots because they show random dates (maybe they are from some moving between devices but idk), and the thing is that it&amp;#39;s pretty obvious by the name and date of them. I would only need a program that uses the filename and changes the timestamp, does it exist tho?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04\"&gt;https://preview.redd.it/jtfpak2qnsla1.png?width=423&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4652e2c587a6c861d34227cbd5c9d4787af48a04&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ieiyy", "is_robot_indexable": true, "report_reasons": null, "author": "SantiagoNub", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ieiyy/how_to_fix_timestamp_of_old_screenshots_that_show/", "subreddit_subscribers": 672111, "created_utc": 1677967010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently in the process of downloading an entire youtube channel and it looks like I'm going to run out of space on the drive I'm using. How would you go about picking up a script on a new drive without having it start all over again? \n\nI've searched around and haven't found anything that seems like it would work. I've already downloaded several hundred videos and while I can get a new drive that could hold everything, I would rather not have to transfer the 1.8TB of videos over until I'm done with the whole project.", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new to yt-dlp - needing some help continuing a project onto a new hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ibdhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677959622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the process of downloading an entire youtube channel and it looks like I&amp;#39;m going to run out of space on the drive I&amp;#39;m using. How would you go about picking up a script on a new drive without having it start all over again? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched around and haven&amp;#39;t found anything that seems like it would work. I&amp;#39;ve already downloaded several hundred videos and while I can get a new drive that could hold everything, I would rather not have to transfer the 1.8TB of videos over until I&amp;#39;m done with the whole project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ibdhl", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ibdhl/new_to_ytdlp_needing_some_help_continuing_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ibdhl/new_to_ytdlp_needing_some_help_continuing_a/", "subreddit_subscribers": 672111, "created_utc": 1677959622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Found this evangelion dvd collection [https://archive.org/details/neon-genesis-evangelion-adv-dvd-iso/NEON+GENESIS+EVANGELION+PERFECT+COLLECTION+2002+ADV/Disc+02/NGE+Disc+02.ISO](https://archive.org/details/neon-genesis-evangelion-adv-dvd-iso/NEON+GENESIS+EVANGELION+PERFECT+COLLECTION+2002+ADV/Disc+02/NGE+Disc+02.ISO). However, when I try to download it via savefrom.net , it only downloads from the first video/disc. Even when I copy the link of the second video/disc, it still only recognizes the first one. Any advice?", "author_fullname": "t2_75dhr4rp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download collections from internet archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i1vb3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677943677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found this evangelion dvd collection &lt;a href=\"https://archive.org/details/neon-genesis-evangelion-adv-dvd-iso/NEON+GENESIS+EVANGELION+PERFECT+COLLECTION+2002+ADV/Disc+02/NGE+Disc+02.ISO\"&gt;https://archive.org/details/neon-genesis-evangelion-adv-dvd-iso/NEON+GENESIS+EVANGELION+PERFECT+COLLECTION+2002+ADV/Disc+02/NGE+Disc+02.ISO&lt;/a&gt;. However, when I try to download it via savefrom.net , it only downloads from the first video/disc. Even when I copy the link of the second video/disc, it still only recognizes the first one. Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MlbI28TzMqpYEXY6EsvRbpVbD5rtxHck9EWwq8WTQZ0.jpg?auto=webp&amp;v=enabled&amp;s=797c00c2eaec24cc14f389ca6e6d89719b118654", "width": 640, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/MlbI28TzMqpYEXY6EsvRbpVbD5rtxHck9EWwq8WTQZ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=decd51e61f3f6d952856d875b0b0f27513126379", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/MlbI28TzMqpYEXY6EsvRbpVbD5rtxHck9EWwq8WTQZ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cd54dd76de226233e6ab17d48f999bcdec0a546", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/MlbI28TzMqpYEXY6EsvRbpVbD5rtxHck9EWwq8WTQZ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=197d68410cd6683badfc911e30f925c3b11e3b72", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/MlbI28TzMqpYEXY6EsvRbpVbD5rtxHck9EWwq8WTQZ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba2a99f0d1b99b0f62c9433293c4c65c1194c3f2", "width": 640, "height": 480}], "variants": {}, "id": "tsAFuW68N8ir63lSwi-U2KV7VjtU0hnr4RVfZV-wIJE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11i1vb3", "is_robot_indexable": true, "report_reasons": null, "author": "theSquaReh", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11i1vb3/how_to_download_collections_from_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11i1vb3/how_to_download_collections_from_internet_archive/", "subreddit_subscribers": 672111, "created_utc": 1677943677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am running **Windows 10** on a **laptop**. It has a 250GB SSD that runs the OS, and a 1TB **attached** HDD (which also resides **within** the laptop) that holds the **data**. \n\n&amp;#x200B;\n\nTo backup my data **locally**, I am thinking of getting 2 external HDDs and doing backup/syncing between my laptop and the external HDDs. I would like the backup HDDs to always be connected to my laptop, and the data backup/syncing to happen automatically and in real time. \n\n&amp;#x200B;\n\nIs this solution sensible/feasible? How will I implement it - a USB hub into which both the external HDDs will be plugged in always? Should I be using HDDs or SSDs? Which back up and syncing **software** should I use?  .... Looking for something **simple** though, since I have no expertise whatsoever in this area.\n\n&amp;#x200B;\n\nNot to be too greedy, but can I backup the whole system also somehow (say to a 3rd HDD/SSD) so in case my laptop dies, I can simply restore onto a new system from this backup?\n\n&amp;#x200B;\n\nThanks in advance.", "author_fullname": "t2_stxr3x9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local data backup solution for a personal laptop", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i1ij9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677942803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running &lt;strong&gt;Windows 10&lt;/strong&gt; on a &lt;strong&gt;laptop&lt;/strong&gt;. It has a 250GB SSD that runs the OS, and a 1TB &lt;strong&gt;attached&lt;/strong&gt; HDD (which also resides &lt;strong&gt;within&lt;/strong&gt; the laptop) that holds the &lt;strong&gt;data&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To backup my data &lt;strong&gt;locally&lt;/strong&gt;, I am thinking of getting 2 external HDDs and doing backup/syncing between my laptop and the external HDDs. I would like the backup HDDs to always be connected to my laptop, and the data backup/syncing to happen automatically and in real time. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this solution sensible/feasible? How will I implement it - a USB hub into which both the external HDDs will be plugged in always? Should I be using HDDs or SSDs? Which back up and syncing &lt;strong&gt;software&lt;/strong&gt; should I use?  .... Looking for something &lt;strong&gt;simple&lt;/strong&gt; though, since I have no expertise whatsoever in this area.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not to be too greedy, but can I backup the whole system also somehow (say to a 3rd HDD/SSD) so in case my laptop dies, I can simply restore onto a new system from this backup?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11i1ij9", "is_robot_indexable": true, "report_reasons": null, "author": "lenovo_andy", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11i1ij9/local_data_backup_solution_for_a_personal_laptop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11i1ij9/local_data_backup_solution_for_a_personal_laptop/", "subreddit_subscribers": 672111, "created_utc": 1677942803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context: I am downloading a youtube channel and have completely filled my first drive. I'm trying to pick up where I left off on a new drive.\n\nI am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.\n\nI have tried several things, but I am unable to get any of them to work.\n\nwhen running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I've tried running the following command:\n\n    yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n\nevery other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?\n\nby combinations, I mean C:\\WINDOWS\\system32&gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&gt; with the file at the root of E:, etc.", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "yt-dlp: help with --download-archive when moving a previous archive file to a new drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ird8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678003231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context: I am downloading a youtube channel and have completely filled my first drive. I&amp;#39;m trying to pick up where I left off on a new drive.&lt;/p&gt;\n\n&lt;p&gt;I am having trouble getting --download-archive to pick up my archive.log file from a previous run and skip to the latest video.&lt;/p&gt;\n\n&lt;p&gt;I have tried several things, but I am unable to get any of them to work.&lt;/p&gt;\n\n&lt;p&gt;when running powershell as admin, my directory is C:\\WINDOWS\\system32 by default. My target drive is E:. I&amp;#39;ve tried running the following command:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;yt-dlp -P E:\\pikamee\\streams --download-archive archive.log -N 8 --write-info-json https://www.youtube.com/@Pikamee/streams\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;every other component of this command works perfectly, but not --download-archive. It will always start at the first video. I have tried all kinds of combinations of changing my active directory and changing the path for the archive.log file (with the file in the appropriate place each time), but no luck. Am I missing something obvious here?&lt;/p&gt;\n\n&lt;p&gt;by combinations, I mean C:\\WINDOWS\\system32&amp;gt; ....... --download-archive archive.log, with the file placed in \\system32, then the same, but in E:&amp;gt; with the file at the root of E:, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ird8w", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ird8w/ytdlp_help_with_downloadarchive_when_moving_a/", "subreddit_subscribers": 672111, "created_utc": 1678003231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i'm doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don't know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i'm aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one", "author_fullname": "t2_k06v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "unraid like alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iqt4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678001272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;m doing a server upgrade.  moving from lubuntu with mergerfs and snapraid.  i am wanting to move off of snapraid as i prefer a real time parity but it is important to me that disks can be any size without wasting extra space and i can add disks as i go along without issue and that even with drive failures beyond my parity level only the drives that failed lose data.  so far this is looking to me like unraid (with btrfs or xfs with plugins for checking data for silent corruption) is going to be my best bet but i don&amp;#39;t know how much i like going closed source or locking myself to usb booting which has proven unreliable for me in the past.  is there an alternative way to get something like unraid set up on lubuntu. i keep hearing zfs with truenas but as far as i&amp;#39;m aware mixing disk sizes and adding new drives one at a time is not really supported with zfs yet although there has been some work done on it.    the last hardware for the new build will be here by wednesday and right now it is looking like unraid will be my choice but am hoping someone can suggest a better one&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "69.1TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iqt4s", "is_robot_indexable": true, "report_reasons": null, "author": "duelistjp", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iqt4s/unraid_like_alternatives/", "subreddit_subscribers": 672111, "created_utc": 1678001272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I'd  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won't be 300 dollars?", "author_fullname": "t2_hwhmbrl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for ripping a 4K bluray?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iq54i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677998986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just placed  an order  for the 4k bluray of Weird: The Al Yankovic Story and I&amp;#39;d  like to make a digital copy on my PC. Does anyone have any advice for external drives, ideally ones  that won&amp;#39;t be 300 dollars?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iq54i", "is_robot_indexable": true, "report_reasons": null, "author": "44nifty", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iq54i/advice_for_ripping_a_4k_bluray/", "subreddit_subscribers": 672111, "created_utc": 1677998986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.\n\nAs far as I've researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.\n\n&amp;#x200B;\n\nOption One: Seagate Exos 16 TB (ST16000NM001G) [Datasheet)](https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf) Price: $223 on Newegg.\n\nOption Two: WD Gold 8 TB (WD8004FRYZ)  [Datasheet](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf) Price: $225 on Newegg.\n\n(Maybe there is an option three: Toshiba 8 TB MG08ADA800E [Datasheet](https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf) Price: $194 on Newegg.\n\nToday I only need 8TB's of space but who says no to extra space? :)\n\nAfter reading the specs, I've  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.\n\nAs you seasoned data hoarders, which one would you choose?", "author_fullname": "t2_ov6uu2h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos vs WD Gold", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ipp69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677998195.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677997506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I need a USB external HDD for storage. My usage scenario is to write my whole data to the disk once and read GBs of them daily. Actually, I am a music producer and those data are my sound files. So, reliability and sustained read rates and shock resistance (since it will be external) are key factors for me to choose.&lt;/p&gt;\n\n&lt;p&gt;As far as I&amp;#39;ve researched, enterprise class disks are what should I look for. So I came across to a point of choosing between Seagate Exos and WD Gold.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option One: Seagate Exos 16 TB (ST16000NM001G) &lt;a href=\"https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x16-DS2011-1-1904US-en_US.pdf\"&gt;Datasheet)&lt;/a&gt; Price: $223 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Option Two: WD Gold 8 TB (WD8004FRYZ)  &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-gold/product-brief-wd-gold-hdd.pdf\"&gt;Datasheet&lt;/a&gt; Price: $225 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;(Maybe there is an option three: Toshiba 8 TB MG08ADA800E &lt;a href=\"https://storage.toshiba.com/docs/enterprise-hdd-documents/ehdd-mg08-d_product-manual_r0.pdf\"&gt;Datasheet&lt;/a&gt; Price: $194 on Newegg.&lt;/p&gt;\n\n&lt;p&gt;Today I only need 8TB&amp;#39;s of space but who says no to extra space? :)&lt;/p&gt;\n\n&lt;p&gt;After reading the specs, I&amp;#39;ve  seen two differences. First is shock resistance on operating state. Exos has a resistance of 50G and WD Gold has 70G. Exos has 2,5M hours of MTBF and WD Gold has 2M hours of MTBF.&lt;/p&gt;\n\n&lt;p&gt;As you seasoned data hoarders, which one would you choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ipp69", "is_robot_indexable": true, "report_reasons": null, "author": "Gammeloni", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ipp69/seagate_exos_vs_wd_gold/", "subreddit_subscribers": 672111, "created_utc": 1677997506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I'm trying to download large folders (Mega) but they're just too big and time out before completion. I've tried it with Jdownloader but without any luck. They're about 14GB and 11GB.\n\nDoes anyone know how this can be done or can access the individual files to make them available on their own?\n\nAny help would be appreciated.", "author_fullname": "t2_tk9orzbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help needed accessing files in large Mega folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ikp7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677982643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m trying to download large folders (Mega) but they&amp;#39;re just too big and time out before completion. I&amp;#39;ve tried it with Jdownloader but without any luck. They&amp;#39;re about 14GB and 11GB.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know how this can be done or can access the individual files to make them available on their own?&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ikp7d", "is_robot_indexable": true, "report_reasons": null, "author": "cdnrtrt", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ikp7d/help_needed_accessing_files_in_large_mega_folders/", "subreddit_subscribers": 672111, "created_utc": 1677982643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a sister post to one I made on data recovery, but the short story is that my 4tb HDD (Seagate barracuda laptop sized) failed. I'm working to get that back (see my data recovery post for more on that). I am looking to replace it with a more redundant setup\n\nMy idea is to have 4 drives: my SSD i use now for windows (it is almost full),  2 8tb WD blues in raid 1 for working on. And 1 separate 8tb WD blue fro storing games (they can fail, steam backs up saves) as well as periodic copies of my data.\n\nThen for my personal projects I plan on using a private GitHub.", "author_fullname": "t2_15bclw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for advice to replace hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ijzyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677980743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a sister post to one I made on data recovery, but the short story is that my 4tb HDD (Seagate barracuda laptop sized) failed. I&amp;#39;m working to get that back (see my data recovery post for more on that). I am looking to replace it with a more redundant setup&lt;/p&gt;\n\n&lt;p&gt;My idea is to have 4 drives: my SSD i use now for windows (it is almost full),  2 8tb WD blues in raid 1 for working on. And 1 separate 8tb WD blue fro storing games (they can fail, steam backs up saves) as well as periodic copies of my data.&lt;/p&gt;\n\n&lt;p&gt;Then for my personal projects I plan on using a private GitHub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ijzyw", "is_robot_indexable": true, "report_reasons": null, "author": "Sligee", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ijzyw/looking_for_advice_to_replace_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ijzyw/looking_for_advice_to_replace_hard_drive/", "subreddit_subscribers": 672111, "created_utc": 1677980743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?", "author_fullname": "t2_jdihuowm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to get a list of every game on Steam through SteamDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11igw9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677972735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gogdb has an index file you can grab that shows you every product on GoG. Does SteamDB have something similar? If not, how can one obtain such a list?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11igw9m", "is_robot_indexable": true, "report_reasons": null, "author": "dunkeyboi77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11igw9m/is_it_possible_to_get_a_list_of_every_game_on/", "subreddit_subscribers": 672111, "created_utc": 1677972735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?", "author_fullname": "t2_4don0ngl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automatic torrents for new content releases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ifvlf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677970249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I want the monthly archlinux iso and wikipedia_en_all_maxi. Is there an established method for updating my torrent links to the new release?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ifvlf", "is_robot_indexable": true, "report_reasons": null, "author": "LionSuneater", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ifvlf/how_to_automatic_torrents_for_new_content_releases/", "subreddit_subscribers": 672111, "created_utc": 1677970249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, someone knows a SSD TBW comparison table ?", "author_fullname": "t2_cl76ghrt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD TBW Comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iexuc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, someone knows a SSD TBW comparison table ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11iexuc", "is_robot_indexable": true, "report_reasons": null, "author": "BTC_Informer", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11iexuc/ssd_tbw_comparison/", "subreddit_subscribers": 672111, "created_utc": 1677967983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_w2xvb6zx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about uploading this folder to the Internet Archive? More info in comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11i3pww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/sAEE0fSYMKPdlTE7dx6eGzfhQXB5wCeETfPqa2Kfko0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677946487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/uz4tbefiwqla1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/uz4tbefiwqla1.png?auto=webp&amp;v=enabled&amp;s=967e1bbd175eb24a94912020b653c0b367916206", "width": 354, "height": 354}, "resolutions": [{"url": "https://preview.redd.it/uz4tbefiwqla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d17dc47e63e29b892bbccd49accb8b0c5db87769", "width": 108, "height": 108}, {"url": "https://preview.redd.it/uz4tbefiwqla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7011b8dc67e1f36e4117d584ce0c344004c27324", "width": 216, "height": 216}, {"url": "https://preview.redd.it/uz4tbefiwqla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dcdc3d7b4d9dec6820c347ce88fbebc033c6c36c", "width": 320, "height": 320}], "variants": {}, "id": "-MAfreotc-c-y0Ix5y9s65LEvmo7hCYH9ysjGlrZ4Kw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11i3pww", "is_robot_indexable": true, "report_reasons": null, "author": "Starmapo3352", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11i3pww/how_would_i_go_about_uploading_this_folder_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/uz4tbefiwqla1.png", "subreddit_subscribers": 672111, "created_utc": 1677946487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am getting this error on my external WD HDD.\n\nIs this a critical error? Should I replace it?   \nDoes the warranty cover these errors?  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd", "author_fullname": "t2_5ggngnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Pending Sector Count", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 132, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9zjjoxp11wla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 101, "x": 108, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e52ab88086b1c38c48d71c48265ba96b45d5e796"}, {"y": 203, "x": 216, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfd8378d6b8f24edf53e12e1e3666cb1e6419b82"}, {"y": 301, "x": 320, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1b60c326563cb9f0bdb1075cd3700c0c07078a4"}, {"y": 603, "x": 640, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dea3e791a759aa40c17e794a8518c009930853ce"}], "s": {"y": 859, "x": 911, "u": "https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd"}, "id": "9zjjoxp11wla1"}}, "name": "t3_11isnjw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6DWvmsyJJ5t2OKUTJCdg8G8PYFQ4bajX8NF2CxBuSdM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678007798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am getting this error on my external WD HDD.&lt;/p&gt;\n\n&lt;p&gt;Is this a critical error? Should I replace it?&lt;br/&gt;\nDoes the warranty cover these errors?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd\"&gt;https://preview.redd.it/9zjjoxp11wla1.png?width=911&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1823aeb0fcbca7aa5c8f136f24a40cefbcc844bd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11isnjw", "is_robot_indexable": true, "report_reasons": null, "author": "meshurcanli", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11isnjw/current_pending_sector_count/", "subreddit_subscribers": 672111, "created_utc": 1678007798.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}