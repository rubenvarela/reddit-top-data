{"kind": "Listing", "data": {"after": "t3_11i3ddr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I'm due to do a talk at a DS event in May. I've been trying to think of a topic for it for about 3 weeks and drawn a blank. Until now. \n\nI'd like to do a talk on tools that are really really cool / good / useful but for whatever reason haven't got the traction they perhaps deserve. I have a few in mind, but if life has taught me anything it's that there is wisdom in crowds.\n\nSo DS of reddit... I ask you... What's your secret weapon? And why?\n\nIt can be anything - a package, a plugin, a webapp, a framework etc. etc. but it ideally should be free and accessible.", "author_fullname": "t2_xkz43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your secret weapon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i7eq9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677950825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m due to do a talk at a DS event in May. I&amp;#39;ve been trying to think of a topic for it for about 3 weeks and drawn a blank. Until now. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to do a talk on tools that are really really cool / good / useful but for whatever reason haven&amp;#39;t got the traction they perhaps deserve. I have a few in mind, but if life has taught me anything it&amp;#39;s that there is wisdom in crowds.&lt;/p&gt;\n\n&lt;p&gt;So DS of reddit... I ask you... What&amp;#39;s your secret weapon? And why?&lt;/p&gt;\n\n&lt;p&gt;It can be anything - a package, a plugin, a webapp, a framework etc. etc. but it ideally should be free and accessible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i7eq9", "is_robot_indexable": true, "report_reasons": null, "author": "Tommo565", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i7eq9/whats_your_secret_weapon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i7eq9/whats_your_secret_weapon/", "subreddit_subscribers": 853886, "created_utc": 1677950825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello fellow data lovers,\n\nI'm about to inherit a testing and analytic business process that needs to move from an inherently manual extraction, transformation and analysis model into something that's more sustainable and reproducible.\n\n**Current process**\n\n&gt;SQL queries into EDW produce Excel/CSV files. The business processes produce similar, but definitely not exactly the same data in the respective applications. I.e., there are many types of products, some with similar features, normally all having time series data (open, maintenance, close, etc), interest rates, balances, customer information. There are also some business processes that produce records that have nothing to do with customers. These tests usually only occur 1x a year but there are situations where it needs to happen more frequently. But not often.  \n&gt;  \n&gt;  \n&gt;  \n&gt;Those files are then read into a third party app that is very expensive and black-boxy. It forces continued use to reproduce vs. something like R that is fully reproducible and auditable. The data is then transformed and anomalous records are identified for further exploration. Reports are written on the outcomes of the data analysis as it informs conformity to the related business process that produces the records.\n\nEach of these applications/processes may produce anywhere from a few hundred records to thousands but likely never millions. E.g., one application may only generate 1,000 new records in a year.\n\n**Target Model**\n\n&gt;Continuous monthly data loads of the structured files from the EDW or other source databases flow into the data mart. The data continues to 'stack' but can be differentiated by a record\\_load\\_date\\_num so we have 'history'. I.e., Q1-2023 results vs Q2-2023 results but also, if I Just want to do current month.  \n&gt;  \n&gt;The automation from above affords us the time to write solid, reproducible R scripts to bring the data into an R environment (at this time most likely desktop but in the future server hosted possibly). We use the R environment to cleanse the data and produce tidy data sets that can speed up analysis and anomaly detection.  \n&gt;  \n&gt;The data in the R environment could somehow be used to create dashboards for testers to in an ad hoc manner, change the parameters of the R scripts to see different results across time (e.g., single month vs quarter over quarter).  \n\nEventually, it would be nice to identify anomalous records based on the outcomes of the testing so we have closer to \u2018real time\u2019 detection. If a test identifies and validates a pattern and we can create rules that match this pattern, then we can detect these anomalies and fix them before they start to create more and more bad records.\n&gt;  \n&gt;\\*\\*As I'm typing this I'm realizing perhaps this could all be done in PowerBI but I'm not certain about the 'audit-ability' of PowerBI vs R. I.e., R I can fully comment and mark down my script to describe every transformation. I'm also only familiar with using PowerBI at a high level: reading in one or two tables of data, no joins across those tables, creating visualizations using the current fields with some measures and DAX calculations. But open to learning if it can work as fast and reproducible as R.\n\n**Where I Am Now**\n\nI am in the stage of developing the concept but not sure what the best 'data mart', data process and visual analytic solution would be. It seems to me like trying to standardize the 100+ data sets into a traditional data model (RDBMS) would be cumbersome. Maybe that's a faulty assumption since my knowledge base is limited.\n\nWould a NoSQL environment possibly solve this situation? Each data source can continuously be loaded into a 'table' or whatever space NoSQL uses and then I can query a specific data source in the data mart for a specific test OR if there are relations between two data sources I can join those together to produce results similar to an RDBMS?\n\nAppreciate your time and thoughts on this topic.", "author_fullname": "t2_viztxm6i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data mart strategy question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hyz9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677937581.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677936003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data lovers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to inherit a testing and analytic business process that needs to move from an inherently manual extraction, transformation and analysis model into something that&amp;#39;s more sustainable and reproducible.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Current process&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;SQL queries into EDW produce Excel/CSV files. The business processes produce similar, but definitely not exactly the same data in the respective applications. I.e., there are many types of products, some with similar features, normally all having time series data (open, maintenance, close, etc), interest rates, balances, customer information. There are also some business processes that produce records that have nothing to do with customers. These tests usually only occur 1x a year but there are situations where it needs to happen more frequently. But not often.  &lt;/p&gt;\n\n&lt;p&gt;Those files are then read into a third party app that is very expensive and black-boxy. It forces continued use to reproduce vs. something like R that is fully reproducible and auditable. The data is then transformed and anomalous records are identified for further exploration. Reports are written on the outcomes of the data analysis as it informs conformity to the related business process that produces the records.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Each of these applications/processes may produce anywhere from a few hundred records to thousands but likely never millions. E.g., one application may only generate 1,000 new records in a year.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Target Model&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Continuous monthly data loads of the structured files from the EDW or other source databases flow into the data mart. The data continues to &amp;#39;stack&amp;#39; but can be differentiated by a record_load_date_num so we have &amp;#39;history&amp;#39;. I.e., Q1-2023 results vs Q2-2023 results but also, if I Just want to do current month.  &lt;/p&gt;\n\n&lt;p&gt;The automation from above affords us the time to write solid, reproducible R scripts to bring the data into an R environment (at this time most likely desktop but in the future server hosted possibly). We use the R environment to cleanse the data and produce tidy data sets that can speed up analysis and anomaly detection.  &lt;/p&gt;\n\n&lt;p&gt;The data in the R environment could somehow be used to create dashboards for testers to in an ad hoc manner, change the parameters of the R scripts to see different results across time (e.g., single month vs quarter over quarter).  &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Eventually, it would be nice to identify anomalous records based on the outcomes of the testing so we have closer to \u2018real time\u2019 detection. If a test identifies and validates a pattern and we can create rules that match this pattern, then we can detect these anomalies and fix them before they start to create more and more bad records.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;**As I&amp;#39;m typing this I&amp;#39;m realizing perhaps this could all be done in PowerBI but I&amp;#39;m not certain about the &amp;#39;audit-ability&amp;#39; of PowerBI vs R. I.e., R I can fully comment and mark down my script to describe every transformation. I&amp;#39;m also only familiar with using PowerBI at a high level: reading in one or two tables of data, no joins across those tables, creating visualizations using the current fields with some measures and DAX calculations. But open to learning if it can work as fast and reproducible as R.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;Where I Am Now&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I am in the stage of developing the concept but not sure what the best &amp;#39;data mart&amp;#39;, data process and visual analytic solution would be. It seems to me like trying to standardize the 100+ data sets into a traditional data model (RDBMS) would be cumbersome. Maybe that&amp;#39;s a faulty assumption since my knowledge base is limited.&lt;/p&gt;\n\n&lt;p&gt;Would a NoSQL environment possibly solve this situation? Each data source can continuously be loaded into a &amp;#39;table&amp;#39; or whatever space NoSQL uses and then I can query a specific data source in the data mart for a specific test OR if there are relations between two data sources I can join those together to produce results similar to an RDBMS?&lt;/p&gt;\n\n&lt;p&gt;Appreciate your time and thoughts on this topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hyz9n", "is_robot_indexable": true, "report_reasons": null, "author": "rationally_speaking", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hyz9n/data_mart_strategy_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hyz9n/data_mart_strategy_question/", "subreddit_subscribers": 853886, "created_utc": 1677936003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_coz8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody else here in a DS and adjacent team in a Cold Civil War with sales just dumping requests on you because their \"job is to bring money in\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i8j8r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677953025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i8j8r", "is_robot_indexable": true, "report_reasons": null, "author": "honeyplease", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i8j8r/anybody_else_here_in_a_ds_and_adjacent_team_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i8j8r/anybody_else_here_in_a_ds_and_adjacent_team_in_a/", "subreddit_subscribers": 853886, "created_utc": 1677953025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I don't consider myself as an introvert. I think I can talk to anyone about anything and make it interesting, but when it comes to presentations I just freeze when I forget the next sentence. \n\nThis happened at my internships as well as other school presentations. Now my thesis advisor wants me to present a paper at a reading group that I'm not that comfortable presenting because I only started reading papers 2 weeks ago (only read like 4 papers) so I've barely started learning about the field.\n\nDo you have any tips when it comes to presenting scientific papers/experiments/findings?\n\nI'm asking in this sub because I imagine you do a lot of scientific presentations.", "author_fullname": "t2_h916gqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with an upcoming presentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hzrmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677938347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t consider myself as an introvert. I think I can talk to anyone about anything and make it interesting, but when it comes to presentations I just freeze when I forget the next sentence. &lt;/p&gt;\n\n&lt;p&gt;This happened at my internships as well as other school presentations. Now my thesis advisor wants me to present a paper at a reading group that I&amp;#39;m not that comfortable presenting because I only started reading papers 2 weeks ago (only read like 4 papers) so I&amp;#39;ve barely started learning about the field.&lt;/p&gt;\n\n&lt;p&gt;Do you have any tips when it comes to presenting scientific papers/experiments/findings?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking in this sub because I imagine you do a lot of scientific presentations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hzrmn", "is_robot_indexable": true, "report_reasons": null, "author": "AdministrativeRub484", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hzrmn/need_help_with_an_upcoming_presentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hzrmn/need_help_with_an_upcoming_presentation/", "subreddit_subscribers": 853886, "created_utc": 1677938347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking to bring my stats knowledge up to par to understand texts like Deep Learning- Goodfellow, ESL, PRML, ML A Probabilistic Perspective, etc. \n\nMy background is civil engineering and in undergrad took Calc 1-3, Diff Eq, Linear Algebra and a non-calc based stats 101 type class. When I got my masters in Civil-Transportation I took some stats modeling classes that covered regression (linear, logistic, poisson, negative binomial, etc) pretty heavily using R+NLOGIT.\n\nAt this point my stats knowledge is pretty disjointed and feel like I dont have a solid understanding of the fundamentals. From what I can tell with some research the most popular recommendations I've seen are:\n\n1. Statistical Inference- at first glance this book feels way above my level, like I can probably work out some things with effort, but I'll probably need another book to fill in the gaps.\n2. All of Statistics- Looks solid as a reference for someone who's taken way more stats than I have, super concise but super dry read.\n3. Mathematical Statistics with Applications(Wackerly)- This is one that feels like could be a possibility\n4. Introduction to Probability(Blitz)- This feels like the other contender\n\nSo far books 3 and 4 seem like best options, is there anything else I'm missing or votes one way or another?\n\n\nThanks!\n\n[View Poll](https://www.reddit.com/poll/11hqlmq)", "author_fullname": "t2_7s03mmwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Text Recommendations for Stats Refresher?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hqlmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677907528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to bring my stats knowledge up to par to understand texts like Deep Learning- Goodfellow, ESL, PRML, ML A Probabilistic Perspective, etc. &lt;/p&gt;\n\n&lt;p&gt;My background is civil engineering and in undergrad took Calc 1-3, Diff Eq, Linear Algebra and a non-calc based stats 101 type class. When I got my masters in Civil-Transportation I took some stats modeling classes that covered regression (linear, logistic, poisson, negative binomial, etc) pretty heavily using R+NLOGIT.&lt;/p&gt;\n\n&lt;p&gt;At this point my stats knowledge is pretty disjointed and feel like I dont have a solid understanding of the fundamentals. From what I can tell with some research the most popular recommendations I&amp;#39;ve seen are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Statistical Inference- at first glance this book feels way above my level, like I can probably work out some things with effort, but I&amp;#39;ll probably need another book to fill in the gaps.&lt;/li&gt;\n&lt;li&gt;All of Statistics- Looks solid as a reference for someone who&amp;#39;s taken way more stats than I have, super concise but super dry read.&lt;/li&gt;\n&lt;li&gt;Mathematical Statistics with Applications(Wackerly)- This is one that feels like could be a possibility&lt;/li&gt;\n&lt;li&gt;Introduction to Probability(Blitz)- This feels like the other contender&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So far books 3 and 4 seem like best options, is there anything else I&amp;#39;m missing or votes one way or another?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11hqlmq\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11hqlmq", "is_robot_indexable": true, "report_reasons": null, "author": "425trafficeng", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1678166728307, "options": [{"text": "Statistical Inference- Casella Berger", "id": "21890594"}, {"text": "All of Statistics-Wasserman", "id": "21890595"}, {"text": "Mathematical Statistics-Wackerly", "id": "21890596"}, {"text": "Introduction to Probability-Blitzstein", "id": "21890597"}, {"text": "Other- see comments", "id": "21890598"}, {"text": "\ud83c\udf7f\ud83c\udf7f\ud83c\udf7f", "id": "21890599"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 452, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hqlmq/text_recommendations_for_stats_refresher/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/11hqlmq/text_recommendations_for_stats_refresher/", "subreddit_subscribers": 853886, "created_utc": 1677907528.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Situation 1:\n\nI\u2019m experimenting with two distinct features, A and B, which I would like to compare to a Control group. However, I\u2019d like to use the same control for both variants and assume the one with the greater difference is the best\n\nSituation 2:\nI have a standard AB test with one treatment and one control. If I designed the sample size to achieve sufficient power in two metrics using an alpha of 0.05, does it fall in a multi comparison problem and I should adjust the alpha? \n\nSituation 3:\nFinally, if I have conducted the same AB test of Situation 2 and I want to dig deeper into finding some heterogeneous effect. If I segment the data using 5 different features, does it mean I have multiple comparisons as well?\n\nAlso, does anyone know a good reference to understand this concept?\n\nThanks!", "author_fullname": "t2_fxo8qvko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these situations categorised as Multi Comparison problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11igruk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677972432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Situation 1:&lt;/p&gt;\n\n&lt;p&gt;I\u2019m experimenting with two distinct features, A and B, which I would like to compare to a Control group. However, I\u2019d like to use the same control for both variants and assume the one with the greater difference is the best&lt;/p&gt;\n\n&lt;p&gt;Situation 2:\nI have a standard AB test with one treatment and one control. If I designed the sample size to achieve sufficient power in two metrics using an alpha of 0.05, does it fall in a multi comparison problem and I should adjust the alpha? &lt;/p&gt;\n\n&lt;p&gt;Situation 3:\nFinally, if I have conducted the same AB test of Situation 2 and I want to dig deeper into finding some heterogeneous effect. If I segment the data using 5 different features, does it mean I have multiple comparisons as well?&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone know a good reference to understand this concept?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11igruk", "is_robot_indexable": true, "report_reasons": null, "author": "LogisticDepression", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11igruk/are_these_situations_categorised_as_multi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11igruk/are_these_situations_categorised_as_multi/", "subreddit_subscribers": 853886, "created_utc": 1677972432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Two job offers: service company w/ projects but pay same as old job OR jewelry manufacturer pays double but unsure if data science skills useful. Help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ib7m1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677959252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ib7m1", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ib7m1/two_job_offers_service_company_w_projects_but_pay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ib7m1/two_job_offers_service_company_w_projects_but_pay/", "subreddit_subscribers": 853886, "created_utc": 1677959252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_of2vk8g8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "commodity prices per country dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i610p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677949105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i610p", "is_robot_indexable": true, "report_reasons": null, "author": "TomatoSignificant365", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i610p/commodity_prices_per_country_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i610p/commodity_prices_per_country_dataset/", "subreddit_subscribers": 853886, "created_utc": 1677949105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So this is my first job where I am workin for a market research company and one of our projects is mapping salons in a certain country. My boss suggested using google places api to get all the places categorized as salons in that country, along with their additional attributes.\n\n But I am having some trouble getting started as ideally they would like a generalized script to input the type of business and the location radius we are searching in and it spits out the list of those places.    \nDoes anyone have any experience doing something like this and can give me some tips/ alternative options to do the same?", "author_fullname": "t2_u7viyqwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Google Places API to find businesses in a certain location", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hy2z6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677932971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this is my first job where I am workin for a market research company and one of our projects is mapping salons in a certain country. My boss suggested using google places api to get all the places categorized as salons in that country, along with their additional attributes.&lt;/p&gt;\n\n&lt;p&gt;But I am having some trouble getting started as ideally they would like a generalized script to input the type of business and the location radius we are searching in and it spits out the list of those places.&lt;br/&gt;\nDoes anyone have any experience doing something like this and can give me some tips/ alternative options to do the same?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hy2z6", "is_robot_indexable": true, "report_reasons": null, "author": "ShoddyEggnog", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hy2z6/using_google_places_api_to_find_businesses_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hy2z6/using_google_places_api_to_find_businesses_in_a/", "subreddit_subscribers": 853886, "created_utc": 1677932971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a beginner with ANN, I tried searching online but couldn't get a clear answer. I am training a model and have split the validation to 20%, as the model is training the validation accuracy is at a constant 0. However, when evaluating the model with a separate test set, I am able to get an accuracy of 0.8. The training set is a bit small &lt;100 records and 20 inputs. Any idea why this is happening?", "author_fullname": "t2_1439zt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model.fit vs model.evaluate accuracy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iencl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677967285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a beginner with ANN, I tried searching online but couldn&amp;#39;t get a clear answer. I am training a model and have split the validation to 20%, as the model is training the validation accuracy is at a constant 0. However, when evaluating the model with a separate test set, I am able to get an accuracy of 0.8. The training set is a bit small &amp;lt;100 records and 20 inputs. Any idea why this is happening?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11iencl", "is_robot_indexable": true, "report_reasons": null, "author": "Alipizzaman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11iencl/modelfit_vs_modelevaluate_accuracy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11iencl/modelfit_vs_modelevaluate_accuracy/", "subreddit_subscribers": 853886, "created_utc": 1677967285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pzr91bdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11icepb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4EFe0snM7WA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4EFe0snM7WA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/4EFe0snM7WA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4EFe0snM7WA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11icepb", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7MhO_SDLWbTTF2brMWDB1wotThRsdvckL0BUmZ1bw4s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677962031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=4EFe0snM7WA", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WTCaCb0LBg4l95X8BRoZ0dpNnPrpl87-cdm_9vuQj3c.jpg?auto=webp&amp;v=enabled&amp;s=69cc0b8757f3117b9837272f7972316317b31f22", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/WTCaCb0LBg4l95X8BRoZ0dpNnPrpl87-cdm_9vuQj3c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e01669d2029c0e3a237e396b01aa11dabea5e3c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/WTCaCb0LBg4l95X8BRoZ0dpNnPrpl87-cdm_9vuQj3c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a476a8ca851fc2bf1763f9e723aa05a5d5cf4146", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/WTCaCb0LBg4l95X8BRoZ0dpNnPrpl87-cdm_9vuQj3c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8e338d64f0487a6c6621bcb66cf63180449960f", "width": 320, "height": 240}], "variants": {}, "id": "73LJlCay0mcWBhy-OtRdFoqdxwy7XJK8rZO4IU3mL7U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11icepb", "is_robot_indexable": true, "report_reasons": null, "author": "oridnary_artist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11icepb/transform_videos_into_gifs_with_python_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=4EFe0snM7WA", "subreddit_subscribers": 853886, "created_utc": 1677962031.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4EFe0snM7WA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Transform Videos into Gifs with Python and Streamlit | Step-by-Step Tutorial\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/4EFe0snM7WA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Please suggest some quick methods / evaluation metrics to detect anomalous behavior in time series data.", "author_fullname": "t2_8cvbnc48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anomaly detection in time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i3a3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677945986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please suggest some quick methods / evaluation metrics to detect anomalous behavior in time series data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i3a3h", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious_Two_810", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i3a3h/anomaly_detection_in_time_series_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i3a3h/anomaly_detection_in_time_series_data/", "subreddit_subscribers": 853886, "created_utc": 1677945986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have tweets and the task is to perform text classification. I already have learned token embeddings for those tokens present in each of the tweets through some Graph based NN model. Now that I want to use those token embeddings to represent the tweet but the issue is every tweet will have different size embeddings if I just do concatenation. Is there any way, where I can input variable length embeddings to pre-trained BioBERT (if not, any other BERT) model and still be able to perform classification task?", "author_fullname": "t2_kijernbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[R] Variable size input to pre-trained BERT model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hq9iw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677906534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tweets and the task is to perform text classification. I already have learned token embeddings for those tokens present in each of the tweets through some Graph based NN model. Now that I want to use those token embeddings to represent the tweet but the issue is every tweet will have different size embeddings if I just do concatenation. Is there any way, where I can input variable length embeddings to pre-trained BioBERT (if not, any other BERT) model and still be able to perform classification task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hq9iw", "is_robot_indexable": true, "report_reasons": null, "author": "inFamous_16", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hq9iw/r_variable_size_input_to_pretrained_bert_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hq9iw/r_variable_size_input_to_pretrained_bert_model/", "subreddit_subscribers": 853886, "created_utc": 1677906534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What stats courses/ topics/ fundamentals should I take or cover in uni if I want a job in Data Science and potentially ML?", "author_fullname": "t2_t6i1musl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uni stats courses for Data Science / ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hodvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677901100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What stats courses/ topics/ fundamentals should I take or cover in uni if I want a job in Data Science and potentially ML?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hodvo", "is_robot_indexable": true, "report_reasons": null, "author": "Capital-Duty-744", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hodvo/uni_stats_courses_for_data_science_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hodvo/uni_stats_courses_for_data_science_ml/", "subreddit_subscribers": 853886, "created_utc": 1677901100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "E.g. I\u2019m a many-hats data person at my org. Analysis, engineering, visualization, stakeholder convos, etc. I don\u2019t have time to be tweaking data science models till kingdom come when my biggest use case is feature importance for things like churn analysis and not actually deploying a model into production. So the no code sites work really well! \n\nLast night I tried the site Obviously AI. Was super easy to get started, load my training data in, and get some binary classification predictions within an hour. Optimized using multiple algorithms and did all the parameter tweaking for me. And all free for what I need!\n\nWhat are y\u2019all\u2019s thoughts on these types of platforms? Am I missing something big by not getting really into the weeds myself? Have you tried out any of these no code platforms?", "author_fullname": "t2_53o3zuz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No code data science platforms. As far as I can tell, they work really well!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ibzbi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677969412.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677961028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g. I\u2019m a many-hats data person at my org. Analysis, engineering, visualization, stakeholder convos, etc. I don\u2019t have time to be tweaking data science models till kingdom come when my biggest use case is feature importance for things like churn analysis and not actually deploying a model into production. So the no code sites work really well! &lt;/p&gt;\n\n&lt;p&gt;Last night I tried the site Obviously AI. Was super easy to get started, load my training data in, and get some binary classification predictions within an hour. Optimized using multiple algorithms and did all the parameter tweaking for me. And all free for what I need!&lt;/p&gt;\n\n&lt;p&gt;What are y\u2019all\u2019s thoughts on these types of platforms? Am I missing something big by not getting really into the weeds myself? Have you tried out any of these no code platforms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ibzbi", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Tooth_501", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ibzbi/no_code_data_science_platforms_as_far_as_i_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ibzbi/no_code_data_science_platforms_as_far_as_i_can/", "subreddit_subscribers": 853886, "created_utc": 1677961028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m an avid reader. One of my heroes General Mattis wrote \u201cThanks to my reading, I have never been caught flat-footed by any situation, never at a loss for how any problem has been addressed before. It doesn\u2019t give me all the answers, but it lights what is often a dark path ahead.\u201d I\u2019m looking to apply this to data science. What would you all recommend?", "author_fullname": "t2_dnpu8jre", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for reading recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i1qsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677943363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an avid reader. One of my heroes General Mattis wrote \u201cThanks to my reading, I have never been caught flat-footed by any situation, never at a loss for how any problem has been addressed before. It doesn\u2019t give me all the answers, but it lights what is often a dark path ahead.\u201d I\u2019m looking to apply this to data science. What would you all recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i1qsc", "is_robot_indexable": true, "report_reasons": null, "author": "itsbigdambe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i1qsc/looking_for_reading_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i1qsc/looking_for_reading_recommendations/", "subreddit_subscribers": 853886, "created_utc": 1677943363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_571g5zy1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Courses or materials for switching to Product DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ibo47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677960287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ibo47", "is_robot_indexable": true, "report_reasons": null, "author": "Hieronymus_T-Rex", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ibo47/courses_or_materials_for_switching_to_product_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ibo47/courses_or_materials_for_switching_to_product_ds/", "subreddit_subscribers": 853886, "created_utc": 1677960287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we implement data science in jewellery manufacturing company ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11iaz5a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677958710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11iaz5a", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11iaz5a/how_can_we_implement_data_science_in_jewellery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11iaz5a/how_can_we_implement_data_science_in_jewellery/", "subreddit_subscribers": 853886, "created_utc": 1677958710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi a little background I have a BS in math and I have data analysis experience but no DS experience other than research .I am interviewing for a data scientist position. \n\nthe third interview is a take home multi class classification problem.\n\nI solved the problem but can only seem to get a maximum accuracy of around 71%. \n\nThere is only 15 features in the data set , 1 target of 5 labels to predict and it is real world data.\n\n I am supposed to present my results in an interview next week. \n\nI feel like I shpuld be getting a higher accuracy but i cant . Is it like a trick question where the max you can achieve is 70% and they just want to see how you present?\n\nIf so how shpuld I go about presenting my results? \n\nThank you for your help.", "author_fullname": "t2_2bgvubv6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS take home interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i5ha0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677948473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi a little background I have a BS in math and I have data analysis experience but no DS experience other than research .I am interviewing for a data scientist position. &lt;/p&gt;\n\n&lt;p&gt;the third interview is a take home multi class classification problem.&lt;/p&gt;\n\n&lt;p&gt;I solved the problem but can only seem to get a maximum accuracy of around 71%. &lt;/p&gt;\n\n&lt;p&gt;There is only 15 features in the data set , 1 target of 5 labels to predict and it is real world data.&lt;/p&gt;\n\n&lt;p&gt;I am supposed to present my results in an interview next week. &lt;/p&gt;\n\n&lt;p&gt;I feel like I shpuld be getting a higher accuracy but i cant . Is it like a trick question where the max you can achieve is 70% and they just want to see how you present?&lt;/p&gt;\n\n&lt;p&gt;If so how shpuld I go about presenting my results? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i5ha0", "is_robot_indexable": true, "report_reasons": null, "author": "xsmore24", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i5ha0/ds_take_home_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i5ha0/ds_take_home_interview/", "subreddit_subscribers": 853886, "created_utc": 1677948473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi\n\nWhere can i found a dataset that helps me to build a business development dashboard :\n Sales revenue \nNet profit margin \nSales growth \nEmployee happiness \nRetention rate\nCustomer life time \n\u2026etc \n\nThank u", "author_fullname": "t2_e0ekagm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business development dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i0ive", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677940301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Where can i found a dataset that helps me to build a business development dashboard :\n Sales revenue \nNet profit margin \nSales growth \nEmployee happiness \nRetention rate\nCustomer life time \n\u2026etc &lt;/p&gt;\n\n&lt;p&gt;Thank u&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i0ive", "is_robot_indexable": true, "report_reasons": null, "author": "ash_engyam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i0ive/business_development_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i0ive/business_development_dashboard/", "subreddit_subscribers": 853886, "created_utc": 1677940301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\nI am from India. I did my graduation from tier 2 college in electrical engineering.\nI have been working with a consulting firm as a decision analytics consultant and mostly working in data science domain. I have a total of 2 years of experience.\nI would like to know how can i get a job switch in countries like Dubai or any other middle east countries?", "author_fullname": "t2_agqjjp6t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get job in Dubai or middle east in data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hwnht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677927618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am from India. I did my graduation from tier 2 college in electrical engineering.\nI have been working with a consulting firm as a decision analytics consultant and mostly working in data science domain. I have a total of 2 years of experience.\nI would like to know how can i get a job switch in countries like Dubai or any other middle east countries?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11hwnht", "is_robot_indexable": true, "report_reasons": null, "author": "CounterWonderful3298", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11hwnht/how_to_get_job_in_dubai_or_middle_east_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11hwnht/how_to_get_job_in_dubai_or_middle_east_in_data/", "subreddit_subscribers": 853886, "created_utc": 1677927618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "just started uni and i want a good laptop for that major at a good price", "author_fullname": "t2_5gco868r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "laptop for ai &amp; data science major", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i8ri6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677953540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;just started uni and i want a good laptop for that major at a good price&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i8ri6", "is_robot_indexable": true, "report_reasons": null, "author": "yolipoo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i8ri6/laptop_for_ai_data_science_major/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i8ri6/laptop_for_ai_data_science_major/", "subreddit_subscribers": 853886, "created_utc": 1677953540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jdv2e0lh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does the one create interesting visualizations with the dataset? Are there AI tools that help with this process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i73ko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677950373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i73ko", "is_robot_indexable": true, "report_reasons": null, "author": "sami-tech", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i73ko/how_does_the_one_create_interesting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11i73ko/how_does_the_one_create_interesting/", "subreddit_subscribers": 853886, "created_utc": 1677950373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soo True! Lol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i7gcj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.14, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_a1tvdh0y", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "DataScienceMemes", "selftext": "Kya faayda XGboost aur Random forest ka ;(\n\n#datascience #machinelerning #artificialintelligence #xgboost #mlmodel\n\nhttps://www.instagram.com/reel/CpXLbvUAbMo/?igshid=MDJmNzVkMjY=", "author_fullname": "t2_a1tvdh0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Soo True! Lol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataScienceMemes", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11i7fj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.1, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677950863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataScienceMemes", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kya faayda XGboost aur Random forest ka ;(&lt;/p&gt;\n\n&lt;h1&gt;datascience #machinelerning #artificialintelligence #xgboost #mlmodel&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.instagram.com/reel/CpXLbvUAbMo/?igshid=MDJmNzVkMjY=\"&gt;https://www.instagram.com/reel/CpXLbvUAbMo/?igshid=MDJmNzVkMjY=&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?auto=webp&amp;v=enabled&amp;s=d219419fab9392a9728cf804b5b1c6fe5d3b9f29", "width": 468, "height": 263}, "resolutions": [{"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4643e6f746960dc4a41969c9b4073da1109801a1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a5cbddf5ace873351f22aa80dddbe632ab1adef", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=724dfd418049bd4ea20b6c6b8b60dac86f6e7f3f", "width": 320, "height": 179}], "variants": {}, "id": "IWZHJREc6LyZ6Zoqr_bNgmmlSrfaYMuu4jxAUGW2YWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_r6ed7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i7fj7", "is_robot_indexable": true, "report_reasons": null, "author": "Confident-Parsnip804", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataScienceMemes/comments/11i7fj7/soo_true_lol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataScienceMemes/comments/11i7fj7/soo_true_lol/", "subreddit_subscribers": 3387, "created_utc": 1677950863.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1677950899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataScienceMemes", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/DataScienceMemes/comments/11i7fj7/soo_true_lol/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?auto=webp&amp;v=enabled&amp;s=d219419fab9392a9728cf804b5b1c6fe5d3b9f29", "width": 468, "height": 263}, "resolutions": [{"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4643e6f746960dc4a41969c9b4073da1109801a1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a5cbddf5ace873351f22aa80dddbe632ab1adef", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/2IpUyLJG4s_7jI7-vmHeds-n_KEhUdJYmCIx9KFO1fI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=724dfd418049bd4ea20b6c6b8b60dac86f6e7f3f", "width": 320, "height": 179}], "variants": {}, "id": "IWZHJREc6LyZ6Zoqr_bNgmmlSrfaYMuu4jxAUGW2YWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i7gcj", "is_robot_indexable": true, "report_reasons": null, "author": "Confident-Parsnip804", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11i7fj7", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i7gcj/soo_true_lol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/DataScienceMemes/comments/11i7fj7/soo_true_lol/", "subreddit_subscribers": 853886, "created_utc": 1677950899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_93usyrbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MUST DO!!!! to improve your data visualization!!! use seaborn to beautify you visualizations ( for beginners - intermediate )", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11i3ddr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PUqBo3X4bFrBjjrodlvE74DYv2x1h5f0fDUs0L3H_4c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677946092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lokeshwarlakhi.hashnode.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://lokeshwarlakhi.hashnode.dev/eda-101-explore-discover-analyze-part-5", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?auto=webp&amp;v=enabled&amp;s=55925f95f38ee4bd3d8ca9994d4ab92f0f9e1cf9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4ba065cdcbc61c537d974d584c0b501d9e0c56e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8760a4c9b5afcfd6fe02a69cb665ad1fa14c2781", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2cf62d7b52479ae3094fab3758da27f74ccd30a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc6b8d5c368c085749ab8da97c7fb704266c5237", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a58bcc7875a0b18abeefb0fb1efb2e93e241d7b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PsgxIiU0vhQ-qpd-8PHHJkt7x75IjtTMTQENG1Jvg40.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a57bc31f351d895ad7d9c3e9c7736a9e1b0764db", "width": 1080, "height": 567}], "variants": {}, "id": "3bnapKMOZLdTVJxrR6snr6i9pHAC4yEhDyLKcGgZ7F4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11i3ddr", "is_robot_indexable": true, "report_reasons": null, "author": "lokeshwarlakhi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11i3ddr/must_do_to_improve_your_data_visualization_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lokeshwarlakhi.hashnode.dev/eda-101-explore-discover-analyze-part-5", "subreddit_subscribers": 853886, "created_utc": 1677946092.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}