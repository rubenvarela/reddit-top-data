{"kind": "Listing", "data": {"after": "t3_11xqjlx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know we all work in different tech stacks. But what is the hottest tech stack at the moment (also have good future perspective) for any data engineers to pursue? Thank you.", "author_fullname": "t2_q6tghhmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the hottest tech stack in Data Engineering world now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x4u47", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679367377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know we all work in different tech stacks. But what is the hottest tech stack at the moment (also have good future perspective) for any data engineers to pursue? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11x4u47", "is_robot_indexable": true, "report_reasons": null, "author": "jimmy3579", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x4u47/what_is_the_hottest_tech_stack_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x4u47/what_is_the_hottest_tech_stack_in_data/", "subreddit_subscribers": 93819, "created_utc": 1679367377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand it's an in process OLAP database. Ok, fine, that's what everyone have been saying since its inception.  I understand it's great and everyone loves it.\n\nI also have no ducking clue what I'm supposed to do with it. Is it supposed to be a drop in replacement for pandas? Or spark?\n\nOr am I supposed to ship it alongside an analytics app to make fast calculations, like Hex does?\n\nOr maybe run it in a pod and use that to perform the T in ETL? Or all of the above?\n\n\\---\n\nCan you ELI5 it to me?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't understand DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xcy2g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679394460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand it&amp;#39;s an in process OLAP database. Ok, fine, that&amp;#39;s what everyone have been saying since its inception.  I understand it&amp;#39;s great and everyone loves it.&lt;/p&gt;\n\n&lt;p&gt;I also have no ducking clue what I&amp;#39;m supposed to do with it. Is it supposed to be a drop in replacement for pandas? Or spark?&lt;/p&gt;\n\n&lt;p&gt;Or am I supposed to ship it alongside an analytics app to make fast calculations, like Hex does?&lt;/p&gt;\n\n&lt;p&gt;Or maybe run it in a pod and use that to perform the T in ETL? Or all of the above?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Can you ELI5 it to me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xcy2g", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xcy2g/i_dont_understand_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xcy2g/i_dont_understand_duckdb/", "subreddit_subscribers": 93819, "created_utc": 1679394460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I posted this on another thread but felt like more data engineers should be aware of these issues with Fivetran and other ELT tools:\n\nFivetran is terrible for these reasons:\n\n- slow to fix issues or problems when they are discovered\n- they alter field names and change data structure thereby making it very difficult to migrate to other options if the need arises.\n- for some data sources they force you to ingest all objects thereby increasing your costs - great for them as it makes them more money\n- they constantly have issues - we would get emails very regularly identifying problems with their system\n- within 6 months of us cancelling we identified an issue where Fivetran was incorrectly identifying primary keys with the Pendo trackevents object.  We raised this with the support team and they denied there was an issue.  Maybe 4 weeks later they sent out an email admitting they had an issue and refused to credit us for the reprocessing of data we incurred trying to fix it.  Their fix also took about 2 months to implement.  We later learned we had dropped over 1 billion rows of data due to this issue.\n- lack of transparency with all the transformations and adjustments they make (yes I know they have schema charts but the transparency goes beyond this)\n- enormous expenses for loading data - we were getting charged around 30k to reload Pendo data when we were able to do it ourselves for about 3k.\n- SLAs are non existent.  They have a 12 hour buffer.  Most integrations get flagged as \u201cdelayed\u201d and there are no clear answers why.\n- They pick and chose what data on each object they pull in.  Don\u2019t assume they bring in all fields that are available on all endpoints.\n\nWe used fivetran for a few years and got off it last November.  \n\nIf you have the skill set to develop and support your own integration framework (Python in our case) I highly recommend it. It is much cheaper, you have full visibility into your data, you don\u2019t get locked into anyone\u2019s architecture, you can troubleshoot issues very quickly, and you can validate the accuracy of the data you are receiving.\n\nFor reference we are supporting over 700 objects with only one headcount.  If you build out a strong well thought out foundation you don\u2019t need a ton of people.", "author_fullname": "t2_fer0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beware of Fivetran and other ELT tools.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xbpjy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679423038.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679390010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I posted this on another thread but felt like more data engineers should be aware of these issues with Fivetran and other ELT tools:&lt;/p&gt;\n\n&lt;p&gt;Fivetran is terrible for these reasons:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;slow to fix issues or problems when they are discovered&lt;/li&gt;\n&lt;li&gt;they alter field names and change data structure thereby making it very difficult to migrate to other options if the need arises.&lt;/li&gt;\n&lt;li&gt;for some data sources they force you to ingest all objects thereby increasing your costs - great for them as it makes them more money&lt;/li&gt;\n&lt;li&gt;they constantly have issues - we would get emails very regularly identifying problems with their system&lt;/li&gt;\n&lt;li&gt;within 6 months of us cancelling we identified an issue where Fivetran was incorrectly identifying primary keys with the Pendo trackevents object.  We raised this with the support team and they denied there was an issue.  Maybe 4 weeks later they sent out an email admitting they had an issue and refused to credit us for the reprocessing of data we incurred trying to fix it.  Their fix also took about 2 months to implement.  We later learned we had dropped over 1 billion rows of data due to this issue.&lt;/li&gt;\n&lt;li&gt;lack of transparency with all the transformations and adjustments they make (yes I know they have schema charts but the transparency goes beyond this)&lt;/li&gt;\n&lt;li&gt;enormous expenses for loading data - we were getting charged around 30k to reload Pendo data when we were able to do it ourselves for about 3k.&lt;/li&gt;\n&lt;li&gt;SLAs are non existent.  They have a 12 hour buffer.  Most integrations get flagged as \u201cdelayed\u201d and there are no clear answers why.&lt;/li&gt;\n&lt;li&gt;They pick and chose what data on each object they pull in.  Don\u2019t assume they bring in all fields that are available on all endpoints.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We used fivetran for a few years and got off it last November.  &lt;/p&gt;\n\n&lt;p&gt;If you have the skill set to develop and support your own integration framework (Python in our case) I highly recommend it. It is much cheaper, you have full visibility into your data, you don\u2019t get locked into anyone\u2019s architecture, you can troubleshoot issues very quickly, and you can validate the accuracy of the data you are receiving.&lt;/p&gt;\n\n&lt;p&gt;For reference we are supporting over 700 objects with only one headcount.  If you build out a strong well thought out foundation you don\u2019t need a ton of people.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xbpjy", "is_robot_indexable": true, "report_reasons": null, "author": "TheCauthon", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xbpjy/beware_of_fivetran_and_other_elt_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xbpjy/beware_of_fivetran_and_other_elt_tools/", "subreddit_subscribers": 93819, "created_utc": 1679390010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I I have experience building pipelines (mainly batch) data modeling (dbt, data vault ect ) and lightly managing infra (terraform for snowflake or AWS/gcp, docker) and setting up ci/cd (GitHub , circleci ). It just seems all the online course go heavier on python / sql etl dev that won\u2019t get you a job as a swe-data platform or data ops engine or ml ops ; like no clear path or structure to those roles and a decent amount of gate keeping where like I have so many adjacent skills/ experiences.\n\nAnyone have a good class or mentor to help me get to one of those roles that\u2019s not just recommending general related topics", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I see a lot of courses on data engineering that also incorporate what some call analytics engineering. I don\u2019t see many software engineer-data platform / data infrastructure/ data ops courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x4g6x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679366350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I I have experience building pipelines (mainly batch) data modeling (dbt, data vault ect ) and lightly managing infra (terraform for snowflake or AWS/gcp, docker) and setting up ci/cd (GitHub , circleci ). It just seems all the online course go heavier on python / sql etl dev that won\u2019t get you a job as a swe-data platform or data ops engine or ml ops ; like no clear path or structure to those roles and a decent amount of gate keeping where like I have so many adjacent skills/ experiences.&lt;/p&gt;\n\n&lt;p&gt;Anyone have a good class or mentor to help me get to one of those roles that\u2019s not just recommending general related topics&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11x4g6x", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x4g6x/i_see_a_lot_of_courses_on_data_engineering_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x4g6x/i_see_a_lot_of_courses_on_data_engineering_that/", "subreddit_subscribers": 93819, "created_utc": 1679366350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm not a Snowflake user so currently don't have access to the dbt semantic layer. I'm curious if it brought value to anybody? \n\nSome of my colleagues are excited to try it, but I feel I may not understand it fully. Is there a difference between the semantic layer, and the mart layers in a dbt project? Can we not create a common table which contains the correct definition for some business KPI, and let that be used throughout the end points like dashboards and notebooks. Could somebody shed some light on the difference between the semantic layer in dbt vs the mart layer in dbt? Thanks!", "author_fullname": "t2_2gzsok4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt semantic layer - did it bring value to you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wzaz1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679358074.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679353600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a Snowflake user so currently don&amp;#39;t have access to the dbt semantic layer. I&amp;#39;m curious if it brought value to anybody? &lt;/p&gt;\n\n&lt;p&gt;Some of my colleagues are excited to try it, but I feel I may not understand it fully. Is there a difference between the semantic layer, and the mart layers in a dbt project? Can we not create a common table which contains the correct definition for some business KPI, and let that be used throughout the end points like dashboards and notebooks. Could somebody shed some light on the difference between the semantic layer in dbt vs the mart layer in dbt? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11wzaz1", "is_robot_indexable": true, "report_reasons": null, "author": "ciarandeceol1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11wzaz1/dbt_semantic_layer_did_it_bring_value_to_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11wzaz1/dbt_semantic_layer_did_it_bring_value_to_you/", "subreddit_subscribers": 93819, "created_utc": 1679353600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Suppose, you want to hire someone with 2+ years of Data Engineering experience. What are some Data Engineering Project ideas that they made on their own, that would make you hire them even though the projects they did in their previous job are not related to Data Engineering? Or what's something you'd look for in someone's resume even if the projects they did in their previous job are not related to Data Engineering?", "author_fullname": "t2_mu0etwaj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Projects to get hired", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjkoy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679411183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose, you want to hire someone with 2+ years of Data Engineering experience. What are some Data Engineering Project ideas that they made on their own, that would make you hire them even though the projects they did in their previous job are not related to Data Engineering? Or what&amp;#39;s something you&amp;#39;d look for in someone&amp;#39;s resume even if the projects they did in their previous job are not related to Data Engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11xjkoy", "is_robot_indexable": true, "report_reasons": null, "author": "Chance_Ad_3105", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjkoy/data_engineering_projects_to_get_hired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjkoy/data_engineering_projects_to_get_hired/", "subreddit_subscribers": 93819, "created_utc": 1679411183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I\u2019m one of the founders at EqualTo. \n\nWe\u2019re currently building a \u2018spreadsheets as a service\u2019 to help developers integrate spreadsheets. I\u2019d love to hear your thoughts on the concept, and whether you\u2019ve ever experienced any issues with integrating or embedding spreadsheets into apps or websites in the past? \n\nWe\u2019ve just launched our [open beta](https://sheets.equalto.com/#/license/request) if you\u2019d like to check it out!", "author_fullname": "t2_553i0uk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A dev-friendly spreadsheet product - yay or nay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xhuu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679407483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I\u2019m one of the founders at EqualTo. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re currently building a \u2018spreadsheets as a service\u2019 to help developers integrate spreadsheets. I\u2019d love to hear your thoughts on the concept, and whether you\u2019ve ever experienced any issues with integrating or embedding spreadsheets into apps or websites in the past? &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve just launched our &lt;a href=\"https://sheets.equalto.com/#/license/request\"&gt;open beta&lt;/a&gt; if you\u2019d like to check it out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xhuu4", "is_robot_indexable": true, "report_reasons": null, "author": "PinksFunnyFarm", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xhuu4/a_devfriendly_spreadsheet_product_yay_or_nay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xhuu4/a_devfriendly_spreadsheet_product_yay_or_nay/", "subreddit_subscribers": 93819, "created_utc": 1679407483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_11093gvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"No Code\" data tools and approaches are the placebo for unwanted complexity, not the medicine.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xh7we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1679406040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ucovi-data.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "http://www.ucovi-data.com/BlogLatest", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xh7we", "is_robot_indexable": true, "report_reasons": null, "author": "UCOVINed", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xh7we/no_code_data_tools_and_approaches_are_the_placebo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://www.ucovi-data.com/BlogLatest", "subreddit_subscribers": 93819, "created_utc": 1679406040.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI\u2019ve been an avid reader of /r/dataengineering since I discovered this role and pitched it to my previous employer, I switched and from a Business Analyst I became a Data Engineer - but that\u2019s ages ago now\u2026 \n\nLast year I moved abroad after accepting a Data Analyst role for a startup and that role expanded to the point where I began managing our teams data mart (Marketing related data), also, that was my foray into Cloud environment (last employer had everything on-prem).\n\nFast forward to today, my team leader decided to leave and I always jokingly said that when she leaves so will I - and so I do! Shortly after her telling us she\u2019s leaving I had a scheduled job interview which went great and I got an offer - so from May I\u2019ll be a ETL Developer helping a huge telecom company migrate to GCP (my first cloud env I ever worked in). It was all the bells and whistles I like - Spark, Airflow, GCP, huge datasets!\n\nBut what\u2019s the point of this post? \n\nWell, I was always struggling with impostor syndrome, every job opportunity I had I thought they\u2019re doing me a favour employing me, but this time it\u2019s different - the hiring manager called me 30min after the interview offering me money I thought I\u2019d be making in 2 years time, I was confident during that interview and we had a genuine awesome chat about data, airflow etc. So it turns out I know my stuff and they valued my expertise!\n\nSo, guys, fellow analysts, engineers - don\u2019t give up, your skills are worth more than you know - pursue your ambitions!\n\nAlso, huge kudos to this community, you\u2019ve helped so much throughout these years - all of you are amazing!", "author_fullname": "t2_cm6l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst (with a little bit of DE) to an ETL Developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x9oqm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679383221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been an avid reader of &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt; since I discovered this role and pitched it to my previous employer, I switched and from a Business Analyst I became a Data Engineer - but that\u2019s ages ago now\u2026 &lt;/p&gt;\n\n&lt;p&gt;Last year I moved abroad after accepting a Data Analyst role for a startup and that role expanded to the point where I began managing our teams data mart (Marketing related data), also, that was my foray into Cloud environment (last employer had everything on-prem).&lt;/p&gt;\n\n&lt;p&gt;Fast forward to today, my team leader decided to leave and I always jokingly said that when she leaves so will I - and so I do! Shortly after her telling us she\u2019s leaving I had a scheduled job interview which went great and I got an offer - so from May I\u2019ll be a ETL Developer helping a huge telecom company migrate to GCP (my first cloud env I ever worked in). It was all the bells and whistles I like - Spark, Airflow, GCP, huge datasets!&lt;/p&gt;\n\n&lt;p&gt;But what\u2019s the point of this post? &lt;/p&gt;\n\n&lt;p&gt;Well, I was always struggling with impostor syndrome, every job opportunity I had I thought they\u2019re doing me a favour employing me, but this time it\u2019s different - the hiring manager called me 30min after the interview offering me money I thought I\u2019d be making in 2 years time, I was confident during that interview and we had a genuine awesome chat about data, airflow etc. So it turns out I know my stuff and they valued my expertise!&lt;/p&gt;\n\n&lt;p&gt;So, guys, fellow analysts, engineers - don\u2019t give up, your skills are worth more than you know - pursue your ambitions!&lt;/p&gt;\n\n&lt;p&gt;Also, huge kudos to this community, you\u2019ve helped so much throughout these years - all of you are amazing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11x9oqm", "is_robot_indexable": true, "report_reasons": null, "author": "mjkisgod", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11x9oqm/data_analyst_with_a_little_bit_of_de_to_an_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x9oqm/data_analyst_with_a_little_bit_of_de_to_an_etl/", "subreddit_subscribers": 93819, "created_utc": 1679383221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve read similar threads, worked with both models. I\u2019m still confused where the threshold between OBT and Star Schema choice is. This question is about looking for right questions to ask given use case, rather than comparing pros &amp; cons of two data models. Please, amend my ways.\n\n**Question**: would you choose OBT or Star Schema for my use case? If it depends, how decision tree looks like in your opinion?\n\n**Use case**: you were asked to implement a new \u201cfeature\u201d (=reports) at medium-big product company, where data engineering is split into dozen of domain-specific teams. These reports are going to be consumed by a few internal business teams (i.e. marketing, sales, etc.), they should also be able to do ad-hoc data exploration. At the moment there is no explicit requirement to combine/conform your reports with any other reports, but as a newcomer you can\u2019t estimate the future trajectory precisely. Billions of rows at report tables, dozens-hundreds of TBs of historical data at ETL layer. Batch ETL - S3/Spark, data exploration \u2013 Athena/Trino, DWH (if needed) \u2013 Snowflake.\n\n**P.S. (terminology)**: despite OBT can be used over star schema, here by OBT I mean absense of division into facts and dimensions.\n\n\\--------------------------------------------------------------------------------------------------------------------------\n\n**^(Optional to read)**^(: my current undestanding, which doesn't cover current use case because it's somewhere in the middle)\n\n^(One side of the spectrum -) **^(use only OBT)**^(:)\n\n* ^(Cost-performance over query-model flexibility-extensibility (i.e. B2C dashboards for thousands of external web customers, where it isn\u2019t possible to give them full freedom of querying under reasonable cost))\n* ^(Implementation speed and simplicity over query-model flexibility-extensibility (i.e. DS/ML use case, where data model is very use case specific, people work in experimentation manner and prefer quick preparation over super universal models))\n\n^(Another side of the spectrum -) **^(use only Star Schema)**^(:)\n\n* ^(Query-model flexibility over initial implementation speed(i.e. BI with dozens++ of reports/business-users, complex ETL with hundreds/thousands of tables. Star Schema benefits overweight modeling effort: it gives more flexibility and optimization room for BI reports developers, narrow/de-composed tables usually give more straightforward data flow and better reporting performance, regular schema upgrades or ad-hoc dimension updates become easier, historical results become queriable by end users))\n* ^(Drill-across multiple business processes is required(OBTs won\u2019t scale here, need Star Schema and conformed dimensions))", "author_fullname": "t2_26jx1rij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you choose between star schema vs one big table (OBT) data models for big data reporting without explicit enterprise data warehouse requirements?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjsyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679411664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve read similar threads, worked with both models. I\u2019m still confused where the threshold between OBT and Star Schema choice is. This question is about looking for right questions to ask given use case, rather than comparing pros &amp;amp; cons of two data models. Please, amend my ways.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: would you choose OBT or Star Schema for my use case? If it depends, how decision tree looks like in your opinion?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: you were asked to implement a new \u201cfeature\u201d (=reports) at medium-big product company, where data engineering is split into dozen of domain-specific teams. These reports are going to be consumed by a few internal business teams (i.e. marketing, sales, etc.), they should also be able to do ad-hoc data exploration. At the moment there is no explicit requirement to combine/conform your reports with any other reports, but as a newcomer you can\u2019t estimate the future trajectory precisely. Billions of rows at report tables, dozens-hundreds of TBs of historical data at ETL layer. Batch ETL - S3/Spark, data exploration \u2013 Athena/Trino, DWH (if needed) \u2013 Snowflake.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. (terminology)&lt;/strong&gt;: despite OBT can be used over star schema, here by OBT I mean absense of division into facts and dimensions.&lt;/p&gt;\n\n&lt;p&gt;--------------------------------------------------------------------------------------------------------------------------&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;sup&gt;Optional to read&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;: my current undestanding, which doesn&amp;#39;t cover current use case because it&amp;#39;s somewhere in the middle&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;One side of the spectrum -&lt;/sup&gt; &lt;strong&gt;&lt;sup&gt;use only OBT&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;:&lt;/sup&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;sup&gt;Cost-performance over query-model flexibility-extensibility (i.e. B2C dashboards for thousands of external web customers, where it isn\u2019t possible to give them full freedom of querying under reasonable cost&lt;/sup&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;sup&gt;Implementation speed and simplicity over query-model flexibility-extensibility (i.e. DS/ML use case, where data model is very use case specific, people work in experimentation manner and prefer quick preparation over super universal models&lt;/sup&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;sup&gt;Another side of the spectrum -&lt;/sup&gt; &lt;strong&gt;&lt;sup&gt;use only Star Schema&lt;/sup&gt;&lt;/strong&gt;&lt;sup&gt;:&lt;/sup&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;sup&gt;Query-model flexibility over initial implementation speed(i.e. BI with dozens++ of reports/business-users, complex ETL with hundreds/thousands of tables. Star Schema benefits overweight modeling effort: it gives more flexibility and optimization room for BI reports developers, narrow/de-composed tables usually give more straightforward data flow and better reporting performance, regular schema upgrades or ad-hoc dimension updates become easier, historical results become queriable by end users&lt;/sup&gt;)&lt;/li&gt;\n&lt;li&gt;&lt;sup&gt;Drill-across multiple business processes is required(OBTs won\u2019t scale here, need Star Schema and conformed dimensions&lt;/sup&gt;)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xjsyl", "is_robot_indexable": true, "report_reasons": null, "author": "Volody_", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjsyl/how_would_you_choose_between_star_schema_vs_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjsyl/how_would_you_choose_between_star_schema_vs_one/", "subreddit_subscribers": 93819, "created_utc": 1679411664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Including how to format ctes, variables etc.?", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a standard whitespace format for SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xjgjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679410943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Including how to format ctes, variables etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xjgjn", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xjgjn/is_there_a_standard_whitespace_format_for_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xjgjn/is_there_a_standard_whitespace_format_for_sql/", "subreddit_subscribers": 93819, "created_utc": 1679410943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't wait to do a KT session on this.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_11xpphg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/N6s58Z_wGH9_M0Zv5Itr5dZ_beQUoEq5TMOEdPba-jI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679423320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u5qr6r58y4pa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?auto=webp&amp;v=enabled&amp;s=bdf68ed9a33beab092a344bd127dd12645b32e07", "width": 1423, "height": 958}, "resolutions": [{"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28d015d4784521000a2ae0ed0d307569ff8a58ae", "width": 108, "height": 72}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0509656cdac75f04603924cabdd99085c0d89500", "width": 216, "height": 145}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c47edc67369d19c714037bd69eb1300247b5408", "width": 320, "height": 215}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dbb0a991dce5cb875beb540e76f83402ffc8f1e", "width": 640, "height": 430}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb1230597cfccd5a8080d87dbf983960ff76721e", "width": 960, "height": 646}, {"url": "https://preview.redd.it/u5qr6r58y4pa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed1ad18dd5dfb6d4532871f08532a575ff527202", "width": 1080, "height": 727}], "variants": {}, "id": "mZ7Q8_k2hf4U-_KFlay9qPpRO4P8KGuMYa6D6g-viKA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "11xpphg", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xpphg/cant_wait_to_do_a_kt_session_on_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u5qr6r58y4pa1.jpg", "subreddit_subscribers": 93819, "created_utc": 1679423320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI've inherited a number of Dagster Repositories (I will migrate them to Definitions whenever possible). \n\nRight now their deployment is one \"main\" \"server\" and several other servers connected via gRPC. They all share the same local storage and database (for run information storage, etc..).\n\nAs I'm new to Dagster, I'm wondering if this is the best approach. The current UI is extremely slow, sometimes unresponsive when loading runs (and loading stuff in general), for example.\n\nI'm thinking about proposing a migration to a different deployment system. One Dagit Instance per repository/definition, each one with its own local storage and DB. Each one would be deployed in a Docker container.\n\nI'm also wondering what's the best way of deleting old runs. Right now there is a job that uses the DagsterInstance object to load and delete runs older than a certain age. Is this the best approach?\n\nFinally, I'm all hears (or eyes, in this case) for tips on how to manage and scale Dagster. Any source of information/documentation/examples on this would be highly appreciated.\n\nThanks in advance!", "author_fullname": "t2_hezlmqqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xb0c7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679387381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve inherited a number of Dagster Repositories (I will migrate them to Definitions whenever possible). &lt;/p&gt;\n\n&lt;p&gt;Right now their deployment is one &amp;quot;main&amp;quot; &amp;quot;server&amp;quot; and several other servers connected via gRPC. They all share the same local storage and database (for run information storage, etc..).&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m new to Dagster, I&amp;#39;m wondering if this is the best approach. The current UI is extremely slow, sometimes unresponsive when loading runs (and loading stuff in general), for example.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about proposing a migration to a different deployment system. One Dagit Instance per repository/definition, each one with its own local storage and DB. Each one would be deployed in a Docker container.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also wondering what&amp;#39;s the best way of deleting old runs. Right now there is a job that uses the DagsterInstance object to load and delete runs older than a certain age. Is this the best approach?&lt;/p&gt;\n\n&lt;p&gt;Finally, I&amp;#39;m all hears (or eyes, in this case) for tips on how to manage and scale Dagster. Any source of information/documentation/examples on this would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xb0c7", "is_robot_indexable": true, "report_reasons": null, "author": "doppeldenken", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xb0c7/scaling_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xb0c7/scaling_dagster/", "subreddit_subscribers": 93819, "created_utc": 1679387381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is currently utilizing Matillion to move data from source systems into our data warehouse. Source systems include a lot of databases, SaaS tools, API, files. \nSome of our struggles that we have with Matillion is the git integration and lack of flexibility. \n\nWe are evaluating our tech stack and I was going to take a look at Azure Data Factory. Does anyone have any reviews of ADF vs Matillion?\n\nI am going to do some demo pipelines to compare but wanted to get some other opinions.", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating Data Factory vs Matillion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x793j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679374597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is currently utilizing Matillion to move data from source systems into our data warehouse. Source systems include a lot of databases, SaaS tools, API, files. \nSome of our struggles that we have with Matillion is the git integration and lack of flexibility. &lt;/p&gt;\n\n&lt;p&gt;We are evaluating our tech stack and I was going to take a look at Azure Data Factory. Does anyone have any reviews of ADF vs Matillion?&lt;/p&gt;\n\n&lt;p&gt;I am going to do some demo pipelines to compare but wanted to get some other opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11x793j", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x793j/evaluating_data_factory_vs_matillion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x793j/evaluating_data_factory_vs_matillion/", "subreddit_subscribers": 93819, "created_utc": 1679374597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI am looking for best practices to consume files arriving at high frequency in S3 , we are using a native  integration tool that is using S3 as queue/dump rather than a landing zone controlling the dumps, sending files every sub-second/2-seconds, files are dumped in `daily` partitions containing these live dumps, but not less than daily ( eg hourly  ). I want a way to control picking up these files, and transforming them,  then loading it into a DWH.\n\nRight now we are running an ETL as  a D-1, and is kinda stable , but I want to achieve more frequent updates, we target an Hourly run.\n\nWhat would be your best practice architecture suggestions here.\n\nThanks !", "author_fullname": "t2_ce0xxymx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices : High frequency dumps in S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xodtv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679420731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am looking for best practices to consume files arriving at high frequency in S3 , we are using a native  integration tool that is using S3 as queue/dump rather than a landing zone controlling the dumps, sending files every sub-second/2-seconds, files are dumped in &lt;code&gt;daily&lt;/code&gt; partitions containing these live dumps, but not less than daily ( eg hourly  ). I want a way to control picking up these files, and transforming them,  then loading it into a DWH.&lt;/p&gt;\n\n&lt;p&gt;Right now we are running an ETL as  a D-1, and is kinda stable , but I want to achieve more frequent updates, we target an Hourly run.&lt;/p&gt;\n\n&lt;p&gt;What would be your best practice architecture suggestions here.&lt;/p&gt;\n\n&lt;p&gt;Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xodtv", "is_robot_indexable": true, "report_reasons": null, "author": "Wingsofpeace7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xodtv/best_practices_high_frequency_dumps_in_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xodtv/best_practices_high_frequency_dumps_in_s3/", "subreddit_subscribers": 93819, "created_utc": 1679420731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried and tested Codon yet ,\n\n[https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314](https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314)\n\n&amp;#x200B;\n\nBrain Storming to see how the code and future in house or OS implementations would be implemented with Codon,\n\nif anyone has any industry news on future roadmaps of other python frameworks being refactored with its use  please share ?", "author_fullname": "t2_kqhkj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Codon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xei7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679399434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried and tested Codon yet ,&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314\"&gt;https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Brain Storming to see how the code and future in house or OS implementations would be implemented with Codon,&lt;/p&gt;\n\n&lt;p&gt;if anyone has any industry news on future roadmaps of other python frameworks being refactored with its use  please share ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?auto=webp&amp;v=enabled&amp;s=20358f89bb763869cda6461b01461cf4a811bb10", "width": 1500, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8299e4f06021e65c937356ab6c9730c0bc194771", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b222338636277f5f2d62d528c7102aa40f4b77f5", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=868cbe581e483597e18765e592a40d06204f64f7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c81813067a6724ef8e7b2e88a33ed3742bfe4933", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbfbd11b20a1602c1e1971eaa75b555abff08a1e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/dLZdvDob7R_NZfxFKvgxzSrU-pv4XhX-GNJskSqbOaw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc1bb809dc94e16946345af82e9d5d530ec8292a", "width": 1080, "height": 720}], "variants": {}, "id": "q8mXD_72YdtfxqBVGJrRf6ZHbP-LoRsgm1Vj9MJySu0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xei7c", "is_robot_indexable": true, "report_reasons": null, "author": "audyoga", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xei7c/python_codon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xei7c/python_codon/", "subreddit_subscribers": 93819, "created_utc": 1679399434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I am coming with an MS degree in Analytics and 2+ YOE as a data analyst. I was offered and accepted a Sr. Data Engineer position 6 months ago, which is more Analytics Engineer role.  \n\n\nMy main work is ETL development with Snowflake, basic pipeline management, and dashboards with Looker. I am somewhat comfortable with these aspects, however, I am thinking about how to grow to become a \"real\" data engineer with the right skill set.   \n\n\nI was thinking the next logical tool is learning dbt, but also was thinking that some AWS experience will be needed.\n\nThank You", "author_fullname": "t2_cobpexag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tools/skills should I learn next as a starting data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x8fq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679378547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I am coming with an MS degree in Analytics and 2+ YOE as a data analyst. I was offered and accepted a Sr. Data Engineer position 6 months ago, which is more Analytics Engineer role.  &lt;/p&gt;\n\n&lt;p&gt;My main work is ETL development with Snowflake, basic pipeline management, and dashboards with Looker. I am somewhat comfortable with these aspects, however, I am thinking about how to grow to become a &amp;quot;real&amp;quot; data engineer with the right skill set.   &lt;/p&gt;\n\n&lt;p&gt;I was thinking the next logical tool is learning dbt, but also was thinking that some AWS experience will be needed.&lt;/p&gt;\n\n&lt;p&gt;Thank You&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11x8fq0", "is_robot_indexable": true, "report_reasons": null, "author": "NewTrouble6245", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x8fq0/which_toolsskills_should_i_learn_next_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x8fq0/which_toolsskills_should_i_learn_next_as_a/", "subreddit_subscribers": 93819, "created_utc": 1679378547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To all the people who are familiar with Graph databases, I need help in assessing the performance and accessibility of ArangoDB, Neo4J and D-Graph. I would just like to know your opinion on these and maybe let me know why do you think so.\nI'm just a beginner and i have minimal knowledge about databases in general, so i hope someone can maybe help me out with this", "author_fullname": "t2_pm1p6xmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Graph Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x8d3j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679378323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all the people who are familiar with Graph databases, I need help in assessing the performance and accessibility of ArangoDB, Neo4J and D-Graph. I would just like to know your opinion on these and maybe let me know why do you think so.\nI&amp;#39;m just a beginner and i have minimal knowledge about databases in general, so i hope someone can maybe help me out with this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11x8d3j", "is_robot_indexable": true, "report_reasons": null, "author": "screenshot07", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x8d3j/graph_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x8d3j/graph_databases/", "subreddit_subscribers": 93819, "created_utc": 1679378323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer: I'm totally new to DE; this is my first DE job, and I don't have full understanding of DE concepts and technologies yet.\n\nDoes Databricks provide a sandbox environment to practise the Lab exercises from the Databricks Customer Academy? Am I missing something? Am I expected to practise on my company's workspace? In that case, they don't have a learning environment yet... How can I practise?\n\nThanks in advance.", "author_fullname": "t2_14zmwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workspace to practise Lab \u2014 Databricks Customer Academy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xlus1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679420048.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679415741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I&amp;#39;m totally new to DE; this is my first DE job, and I don&amp;#39;t have full understanding of DE concepts and technologies yet.&lt;/p&gt;\n\n&lt;p&gt;Does Databricks provide a sandbox environment to practise the Lab exercises from the Databricks Customer Academy? Am I missing something? Am I expected to practise on my company&amp;#39;s workspace? In that case, they don&amp;#39;t have a learning environment yet... How can I practise?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xlus1", "is_robot_indexable": true, "report_reasons": null, "author": "silcap", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xlus1/workspace_to_practise_lab_databricks_customer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xlus1/workspace_to_practise_lab_databricks_customer/", "subreddit_subscribers": 93819, "created_utc": 1679415741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! We have a supplier who have a REST API with the form &lt;host&gt;/&lt;entity type&gt;/&lt;id&gt;.  \nI wish to fetch about a million of these entities, and unfortunately they dont have a bulk endpoint. \n\nOne solution is a Cloud Function that fetches and stores each call, fed from a pub/sub queue holding the unfetched ids (in Google Cloud), but I dont see how I would rate limit the Cloud Function, as to not cause their DDOS protection to kick in.\n\nHow would you have done this? Is there any SAAS that does this that I am not aware of?", "author_fullname": "t2_82s0a64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fetch a million entities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xk6l4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679412462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! We have a supplier who have a REST API with the form &amp;lt;host&amp;gt;/&amp;lt;entity type&amp;gt;/&amp;lt;id&amp;gt;.&lt;br/&gt;\nI wish to fetch about a million of these entities, and unfortunately they dont have a bulk endpoint. &lt;/p&gt;\n\n&lt;p&gt;One solution is a Cloud Function that fetches and stores each call, fed from a pub/sub queue holding the unfetched ids (in Google Cloud), but I dont see how I would rate limit the Cloud Function, as to not cause their DDOS protection to kick in.&lt;/p&gt;\n\n&lt;p&gt;How would you have done this? Is there any SAAS that does this that I am not aware of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xk6l4", "is_robot_indexable": true, "report_reasons": null, "author": "Ootoootooo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xk6l4/fetch_a_million_entities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xk6l4/fetch_a_million_entities/", "subreddit_subscribers": 93819, "created_utc": 1679412462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any sort of workaround to enable the use of type hints for PySpark SQL dataframes. I know that Pandas API on PySpark dataframes support type hints.\n\nCurrently, I struggle to infer the columns available on a dataframe as in my project, we do multiple joins and add different columns in various places. Having a static typing will help me in those cases.\n\nExample:\n```\ndef add_age_col(df: DataFrame[\"id\": int, \"name\": str) -&gt; DataFrame[\"id\": int, \"name\": str, \"age\": int]:\n    ...\n```\n\nWhen I run this, I get an error saying that DataFrame is not subscriptable, which means it doesn't support type hints.\n\nDoes anybody know if it's coming to PySpark anytime soon?", "author_fullname": "t2_179cg5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Static type hints for PySpark SQL dataframes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xefye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679399258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any sort of workaround to enable the use of type hints for PySpark SQL dataframes. I know that Pandas API on PySpark dataframes support type hints.&lt;/p&gt;\n\n&lt;p&gt;Currently, I struggle to infer the columns available on a dataframe as in my project, we do multiple joins and add different columns in various places. Having a static typing will help me in those cases.&lt;/p&gt;\n\n&lt;p&gt;Example:\n&lt;code&gt;\ndef add_age_col(df: DataFrame[&amp;quot;id&amp;quot;: int, &amp;quot;name&amp;quot;: str) -&amp;gt; DataFrame[&amp;quot;id&amp;quot;: int, &amp;quot;name&amp;quot;: str, &amp;quot;age&amp;quot;: int]:\n    ...\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;When I run this, I get an error saying that DataFrame is not subscriptable, which means it doesn&amp;#39;t support type hints.&lt;/p&gt;\n\n&lt;p&gt;Does anybody know if it&amp;#39;s coming to PySpark anytime soon?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xefye", "is_robot_indexable": true, "report_reasons": null, "author": "pavi2410", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xefye/static_type_hints_for_pyspark_sql_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xefye/static_type_hints_for_pyspark_sql_dataframes/", "subreddit_subscribers": 93819, "created_utc": 1679399258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could someone please explain to me how to automate an ETL pipeline using Python/SQL? I\u2019m a beginner data engineer and I\u2019m trying to find a simple answer (or guideline) for automating ETL. I\u2019ve looked this topic up on several platforms and I keep seeing references to Apache Airflow, Luigi, and cron in Python as well as numerous other frameworks. I\u2019m confused as to where to start. What would be the best practice in my case?", "author_fullname": "t2_d5gbt9n1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xd6qa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679395270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could someone please explain to me how to automate an ETL pipeline using Python/SQL? I\u2019m a beginner data engineer and I\u2019m trying to find a simple answer (or guideline) for automating ETL. I\u2019ve looked this topic up on several platforms and I keep seeing references to Apache Airflow, Luigi, and cron in Python as well as numerous other frameworks. I\u2019m confused as to where to start. What would be the best practice in my case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11xd6qa", "is_robot_indexable": true, "report_reasons": null, "author": "romitriozera", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xd6qa/automating_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xd6qa/automating_etl/", "subreddit_subscribers": 93819, "created_utc": 1679395270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3sl4dlyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To Clean Data with Python Pandas \u2014 Vehicles registered in Poland", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11xc5yz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XUxA24hwMfVo6Gb1Fit2WZ7OznW5w78nhhA06XPnVzM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679391716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "maciejszymczyk.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://maciejszymczyk.medium.com/how-to-clean-data-with-python-pandas-vehicles-registered-in-poland-f78b896045fd?sk=c91a8a11c558ee5b8fd12a5b9425b29a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?auto=webp&amp;v=enabled&amp;s=8583b9e7fdb2eb742190dacc3df724783934ba0c", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fe4027e16b346ca0b3e07f95c8c49bbbd331c93", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b20752a183e6e4040d311ba5706ddf88ad628bf4", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc9442805b675106519553a4b4e59a8654a6a9c3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93a1eb73ad3c6c146eae1880c0a2710625a69614", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f776f9a6fec4323c7afe3f2a936ce9c2b638b60", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/-hhBokBEwwBUQDfRF9NCnNVqoxUnWHZNVI3Enlq9KuA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0f83e8cf96dae1773e09e25a202ac183849a0aa", "width": 1080, "height": 607}], "variants": {}, "id": "G8OymSFZUcurYz2bc9ycqYT7w3kEemogo6S4qSYzS_M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11xc5yz", "is_robot_indexable": true, "report_reasons": null, "author": "mszymczyk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xc5yz/how_to_clean_data_with_python_pandas_vehicles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://maciejszymczyk.medium.com/how-to-clean-data-with-python-pandas-vehicles-registered-in-poland-f78b896045fd?sk=c91a8a11c558ee5b8fd12a5b9425b29a", "subreddit_subscribers": 93819, "created_utc": 1679391716.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a recent graduate(from SF area) and I\u2019ve decided to become a data engineer. \n\nDue to the recent hiring freeze and recession, I\u2019ve decided to work as a DE in the insurance industry where I only got offer from even though I have a great passion to work in the tech industry. \n\nI am very grateful that I was able to start my career as a DE right after college. However, I am not sure the company that I work for could be thought as a right place for me to grow. The technologies that I have been using are outdated and not sure if there is going to a new opportunity where I can use/learn technologies.\n\nMy plan is to stay here maybe about one more year until the whole hiring freeze and economic uncertainties to cool down and move to a tech company.\n\nI really want to be ready by the time I start looking for a new job in the tech industry and use my time wisely to develop myself. Please let me know about things that I can do in my situation and I really really appreciate your advices.", "author_fullname": "t2_ij7y2ya5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advices needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11x2xg2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679362373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a recent graduate(from SF area) and I\u2019ve decided to become a data engineer. &lt;/p&gt;\n\n&lt;p&gt;Due to the recent hiring freeze and recession, I\u2019ve decided to work as a DE in the insurance industry where I only got offer from even though I have a great passion to work in the tech industry. &lt;/p&gt;\n\n&lt;p&gt;I am very grateful that I was able to start my career as a DE right after college. However, I am not sure the company that I work for could be thought as a right place for me to grow. The technologies that I have been using are outdated and not sure if there is going to a new opportunity where I can use/learn technologies.&lt;/p&gt;\n\n&lt;p&gt;My plan is to stay here maybe about one more year until the whole hiring freeze and economic uncertainties to cool down and move to a tech company.&lt;/p&gt;\n\n&lt;p&gt;I really want to be ready by the time I start looking for a new job in the tech industry and use my time wisely to develop myself. Please let me know about things that I can do in my situation and I really really appreciate your advices.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11x2xg2", "is_robot_indexable": true, "report_reasons": null, "author": "StatusWasabi9235", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11x2xg2/advices_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11x2xg2/advices_needed/", "subreddit_subscribers": 93819, "created_utc": 1679362373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've joined a new team and the ingestion pipeline they have in place looks clumsy to me. It's very, very slow (it takes 1 min to ingest 2MB of data!!!) and just doesn't look like a best practice approach.\n\n- one script checks if files have been ingested before - it checks logs in a Redshift table, stores data in lists, iterates over lists... This can be optimised, but it makes sense to only load data that hasn't been loaded before \n- we have metadata stored in JSON files such as expected file size, file type, columns and data types for each parquet file\n- parquet files are ingested from another AWS account and read with Pyarrow to compare columns with the expected metadata in JSON files. These checks take quite some time and include file size and file type checks. The tech lead decided against using Glue so we can't use PySpark to read schemas, but to be fair we also don't have a lot of data. \n- all parquet are copied into our bucket once all metadata checks have passed successfully - if some checks have failed they are copied from the landing zone into a rejected folder. This means that files are loaded when they contain additional columns, but these columns won't be added to Redshift. If columns are missing or data types are inconsistent, the entire table is rejected for the specific day\n- if files are rejected, the data producer needs to fix them manually and we have to re-run our pipeline which can be done by adjusting a cron job in prod (the pipeline runs once a day and doesn't have a retry mechanism -&gt; these are all custom Python script running in containers) \n\nIs any of this best practice? Wouldn't it make more sense to copy new data first into a landing zone and then run checks? The comparison with a JSON file also seems odd to me. Isn't this something I would do with a data catalogue?", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this ingestion pipeline make sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11xqjlx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679425043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve joined a new team and the ingestion pipeline they have in place looks clumsy to me. It&amp;#39;s very, very slow (it takes 1 min to ingest 2MB of data!!!) and just doesn&amp;#39;t look like a best practice approach.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;one script checks if files have been ingested before - it checks logs in a Redshift table, stores data in lists, iterates over lists... This can be optimised, but it makes sense to only load data that hasn&amp;#39;t been loaded before &lt;/li&gt;\n&lt;li&gt;we have metadata stored in JSON files such as expected file size, file type, columns and data types for each parquet file&lt;/li&gt;\n&lt;li&gt;parquet files are ingested from another AWS account and read with Pyarrow to compare columns with the expected metadata in JSON files. These checks take quite some time and include file size and file type checks. The tech lead decided against using Glue so we can&amp;#39;t use PySpark to read schemas, but to be fair we also don&amp;#39;t have a lot of data. &lt;/li&gt;\n&lt;li&gt;all parquet are copied into our bucket once all metadata checks have passed successfully - if some checks have failed they are copied from the landing zone into a rejected folder. This means that files are loaded when they contain additional columns, but these columns won&amp;#39;t be added to Redshift. If columns are missing or data types are inconsistent, the entire table is rejected for the specific day&lt;/li&gt;\n&lt;li&gt;if files are rejected, the data producer needs to fix them manually and we have to re-run our pipeline which can be done by adjusting a cron job in prod (the pipeline runs once a day and doesn&amp;#39;t have a retry mechanism -&amp;gt; these are all custom Python script running in containers) &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is any of this best practice? Wouldn&amp;#39;t it make more sense to copy new data first into a landing zone and then run checks? The comparison with a JSON file also seems odd to me. Isn&amp;#39;t this something I would do with a data catalogue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11xqjlx", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11xqjlx/does_this_ingestion_pipeline_make_sense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11xqjlx/does_this_ingestion_pipeline_make_sense/", "subreddit_subscribers": 93819, "created_utc": 1679425043.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}