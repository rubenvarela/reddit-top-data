{"kind": "Listing", "data": {"after": "t3_11stxmf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1hn4plaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning NLP today feels like trying to tinker with super complicated systems to produce electricity at home while we have access to nuclear power for a few dollars per month", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sattj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 367, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 367, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678917765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sattj", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonPilgrim", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sattj/learning_nlp_today_feels_like_trying_to_tinker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sattj/learning_nlp_today_feels_like_trying_to_tinker/", "subreddit_subscribers": 857854, "created_utc": 1678917765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all, I am from academia in the US at one of the Ivy league colleges. I am not a faculty and on soft money. I feel constant threat of loosing my funds every few years. I am sure there are people here who might have gone through the same and switched to data scientist in industry. Do you feel more job security or less or the same? Thanks", "author_fullname": "t2_8ph5mvj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People from academia in data science, do you feel more job security in this sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sgbjc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678930770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I am from academia in the US at one of the Ivy league colleges. I am not a faculty and on soft money. I feel constant threat of loosing my funds every few years. I am sure there are people here who might have gone through the same and switched to data scientist in industry. Do you feel more job security or less or the same? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sgbjc", "is_robot_indexable": true, "report_reasons": null, "author": "mmmhhefjwj", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sgbjc/people_from_academia_in_data_science_do_you_feel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sgbjc/people_from_academia_in_data_science_do_you_feel/", "subreddit_subscribers": 857854, "created_utc": 1678930770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been trying to get a deeper grasp on these types of problems and would love to get some book recommendations here. Additional resources (videos, texts, lectures) are welcome as well. Thanks in advance!", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for books on working with time series/forecasting problems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s9jm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678914956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to get a deeper grasp on these types of problems and would love to get some book recommendations here. Additional resources (videos, texts, lectures) are welcome as well. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11s9jm0", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11s9jm0/recommendations_for_books_on_working_with_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11s9jm0/recommendations_for_books_on_working_with_time/", "subreddit_subscribers": 857854, "created_utc": 1678914956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Heard about this being used in marketing. Is there an increase in usage of Bayesian methods in data science? I feel like these methods would be able to glean more intuitive insights into many things data scientists do already (AB testing).", "author_fullname": "t2_uy28jztl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often are Bayesian methods used in practice? If so where?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11siza8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678937594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heard about this being used in marketing. Is there an increase in usage of Bayesian methods in data science? I feel like these methods would be able to glean more intuitive insights into many things data scientists do already (AB testing).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11siza8", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Touch469", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11siza8/how_often_are_bayesian_methods_used_in_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11siza8/how_often_are_bayesian_methods_used_in_practice/", "subreddit_subscribers": 857854, "created_utc": 1678937594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t171s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_47sfqfo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "who's applying and what are you planning to build???  [https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge](https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge)", "author_fullname": "t2_47sfqfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "two", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8yk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678913695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;who&amp;#39;s applying and what are you planning to build???  &lt;a href=\"https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge\"&gt;https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11s8yk2", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 2600295, "created_utc": 1678913695.0, "num_crossposts": 8, "media": null, "is_video": false}], "created": 1678989165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t171s", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11s8yk2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t171s/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 857854, "created_utc": 1678989165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Today at work, I heard one guy say something along the lines of \"Yea we can move the data to trix and then slurpy it to plex\" and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha", "author_fullname": "t2_d8yn6ekd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science terminology can be wild", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3t3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678995071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today at work, I heard one guy say something along the lines of &amp;quot;Yea we can move the data to trix and then slurpy it to plex&amp;quot; and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t3t3v", "is_robot_indexable": true, "report_reasons": null, "author": "No_Boysenberry_7138", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "subreddit_subscribers": 857854, "created_utc": 1678995071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There is only a handful of videos on Youtube that covers on ML Pipelines. But from what I can see, the use case or definition changes..?  \n\n\nI'm seeing ML pipelines that are directly embedded into a system that takes in data a data source, processes it, then sends it to a data storage. I don't remember the exact details, but I think it was something like this \n\nMySQL ==&gt; Python ==&gt; Postgres  \n\n\nOn top of that, I'm also seeing a few tutorials using scikit learn pipeline. From what I can understand, we can create functions, combine them all together and use scikit learn module to bundle them up into a single pipeline. In which, we can just use it by supplying some data and get the desired result. \n\nWhat I can think of is, by using scikitlearn pipeline, I can export it and embed it into a backend framework like Django REST Framework or even FastAPI. \n\nNot sure if this still counts as a ML pipeline or not. \n\n&amp;#x200B;\n\nAside from that, I'm seeing that, these pipelines can have functions that cleans the data, remove here and there, rescales it, etc, and even feed it into a predictive model.  \n\n\nAlongside scikit learn pipeline, I've seen a few pipelines created using PySpark. Although it looks a bit more daunting but looks possible. \n\n&amp;#x200B;\n\n Final question, how does industry normally build ML pipelines and where does it get stored?\n\n&amp;#x200B;\n\nSorry for the long rant. Many thanks.", "author_fullname": "t2_46qj3zfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exactly is a Machine Learning Pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sbvgi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678920082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is only a handful of videos on Youtube that covers on ML Pipelines. But from what I can see, the use case or definition changes..?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeing ML pipelines that are directly embedded into a system that takes in data a data source, processes it, then sends it to a data storage. I don&amp;#39;t remember the exact details, but I think it was something like this &lt;/p&gt;\n\n&lt;p&gt;MySQL ==&amp;gt; Python ==&amp;gt; Postgres  &lt;/p&gt;\n\n&lt;p&gt;On top of that, I&amp;#39;m also seeing a few tutorials using scikit learn pipeline. From what I can understand, we can create functions, combine them all together and use scikit learn module to bundle them up into a single pipeline. In which, we can just use it by supplying some data and get the desired result. &lt;/p&gt;\n\n&lt;p&gt;What I can think of is, by using scikitlearn pipeline, I can export it and embed it into a backend framework like Django REST Framework or even FastAPI. &lt;/p&gt;\n\n&lt;p&gt;Not sure if this still counts as a ML pipeline or not. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Aside from that, I&amp;#39;m seeing that, these pipelines can have functions that cleans the data, remove here and there, rescales it, etc, and even feed it into a predictive model.  &lt;/p&gt;\n\n&lt;p&gt;Alongside scikit learn pipeline, I&amp;#39;ve seen a few pipelines created using PySpark. Although it looks a bit more daunting but looks possible. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Final question, how does industry normally build ML pipelines and where does it get stored?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sorry for the long rant. Many thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sbvgi", "is_robot_indexable": true, "report_reasons": null, "author": "FlyingRaijinEX", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sbvgi/what_exactly_is_a_machine_learning_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sbvgi/what_exactly_is_a_machine_learning_pipeline/", "subreddit_subscribers": 857854, "created_utc": 1678920082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to this and so I've been wanting to know what other people have been using to make their work feel as smooth as butter. Since I've been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. **The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!**\n\nIDE: **VSCode with the Jupyter Notebook Extension**. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that **Jupyter Lab** has something like this, so if anyone has used both VSCode's notebooks and used Lab, your input would be appreciated. I hear good things about **PyCharm and Spyder**. Some people also use **Google Collab, DataSpell, and DeepNote** but I don't know enough about it. I did play around with DeepNote, and it was very cool but I didn't feel compelled to switch (and you have to pay for it!). \n\nTools:\n\n* A code helper: A few months back I was googling everything and I would've listed **Stackoverflow**. I might actually use that occasionally, but these days I use **ChatGPT** and **Bing AI**. For more current info or news-based I'll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it's great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I'm talking about and can provide a better explanation as to which is better for what purpose.\n* Software: **Excel** is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don't need with Ctrl+click to select, it's easier and quicker than copy + pasting or typing out each of the string column names I want to \"df.drop()\". Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as **Alteryx, KNIME, and Orange**. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a \"lite\" version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven't found a huge use case for them since I've been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.\n* Version Control: This is where I'm primarily lacking, but I know that **Github** is the go-to. I don't use this but I know that a ton of people do. I don't even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I'm also not too aware of what other innovative tools for version control exist.\n* Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I've recently found out about this library called **Polars**. It's basically a Rust version of Pandas, and it's super powerful. Some operations that I've run, that would've taken hours with Pandas, took me minutes. But I've been hearing that **Pandas 2.0** which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is **DuckDB** but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I'll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.\n\nAnyway, that's just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.\n\nhttps://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a", "author_fullname": "t2_gk7up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your digital workspace, tools, setup, etc. for ETL, research, production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qj2cywt1r4oa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6026f61ce2eac4655501946e87ff28b630eafef"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=465f2b0ba6e556d68c2e38da6a0cbf88d55bdae0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78622791ecd096a9586bd2fa375924ecfa71e40c"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa7f19b7612f47b30d08371d8a6aa7c45868cab6"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df91ed30b6053048ed5f1619bcfa1bc9ca731ee0"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eaf1df085449f3113dea76a3a8a86913761bf9c"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a"}, "id": "qj2cywt1r4oa1"}}, "name": "t3_11szca1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OuxRKRDebneIMbv8ljpRG_Aszt8idVQ8R-QV3AksOJQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678985129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to this and so I&amp;#39;ve been wanting to know what other people have been using to make their work feel as smooth as butter. Since I&amp;#39;ve been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. &lt;strong&gt;The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;IDE: &lt;strong&gt;VSCode with the Jupyter Notebook Extension&lt;/strong&gt;. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that &lt;strong&gt;Jupyter Lab&lt;/strong&gt; has something like this, so if anyone has used both VSCode&amp;#39;s notebooks and used Lab, your input would be appreciated. I hear good things about &lt;strong&gt;PyCharm and Spyder&lt;/strong&gt;. Some people also use &lt;strong&gt;Google Collab, DataSpell, and DeepNote&lt;/strong&gt; but I don&amp;#39;t know enough about it. I did play around with DeepNote, and it was very cool but I didn&amp;#39;t feel compelled to switch (and you have to pay for it!). &lt;/p&gt;\n\n&lt;p&gt;Tools:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A code helper: A few months back I was googling everything and I would&amp;#39;ve listed &lt;strong&gt;Stackoverflow&lt;/strong&gt;. I might actually use that occasionally, but these days I use &lt;strong&gt;ChatGPT&lt;/strong&gt; and &lt;strong&gt;Bing AI&lt;/strong&gt;. For more current info or news-based I&amp;#39;ll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it&amp;#39;s great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I&amp;#39;m talking about and can provide a better explanation as to which is better for what purpose.&lt;/li&gt;\n&lt;li&gt;Software: &lt;strong&gt;Excel&lt;/strong&gt; is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don&amp;#39;t need with Ctrl+click to select, it&amp;#39;s easier and quicker than copy + pasting or typing out each of the string column names I want to &amp;quot;df.drop()&amp;quot;. Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as &lt;strong&gt;Alteryx, KNIME, and Orange&lt;/strong&gt;. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a &amp;quot;lite&amp;quot; version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven&amp;#39;t found a huge use case for them since I&amp;#39;ve been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.&lt;/li&gt;\n&lt;li&gt;Version Control: This is where I&amp;#39;m primarily lacking, but I know that &lt;strong&gt;Github&lt;/strong&gt; is the go-to. I don&amp;#39;t use this but I know that a ton of people do. I don&amp;#39;t even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I&amp;#39;m also not too aware of what other innovative tools for version control exist.&lt;/li&gt;\n&lt;li&gt;Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I&amp;#39;ve recently found out about this library called &lt;strong&gt;Polars&lt;/strong&gt;. It&amp;#39;s basically a Rust version of Pandas, and it&amp;#39;s super powerful. Some operations that I&amp;#39;ve run, that would&amp;#39;ve taken hours with Pandas, took me minutes. But I&amp;#39;ve been hearing that &lt;strong&gt;Pandas 2.0&lt;/strong&gt; which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is &lt;strong&gt;DuckDB&lt;/strong&gt; but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I&amp;#39;ll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyway, that&amp;#39;s just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a\"&gt;https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11szca1", "is_robot_indexable": true, "report_reasons": null, "author": "BreathAether", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "subreddit_subscribers": 857854, "created_utc": 1678985129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A comprehensive library of features from various industries, complete with methodologies and ideas, that will significantly enhance the efficiency of ML/AI projects.\n\nWe are still in the early stages of development, and we would love to collaborate with experienced professionals in data science, ML/AI, and related fields. \n\n[https://github.com/FeatureHub-AI/FeatureHub](https://github.com/FeatureHub-AI/FeatureHub)", "author_fullname": "t2_73c7xq817", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The library of features for various AI/ML projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sskaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678969257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A comprehensive library of features from various industries, complete with methodologies and ideas, that will significantly enhance the efficiency of ML/AI projects.&lt;/p&gt;\n\n&lt;p&gt;We are still in the early stages of development, and we would love to collaborate with experienced professionals in data science, ML/AI, and related fields. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FeatureHub-AI/FeatureHub\"&gt;https://github.com/FeatureHub-AI/FeatureHub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sskaq", "is_robot_indexable": true, "report_reasons": null, "author": "irynagrv", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sskaq/the_library_of_features_for_various_aiml_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sskaq/the_library_of_features_for_various_aiml_projects/", "subreddit_subscribers": 857854, "created_utc": 1678969257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey !\n\nI'm kind of a beginner and i've tasked with my first misson in my internship and i'm  not sure how to handle it .\n\nFor some context , we have multiple sentences (tasks) and each one has its own price tag .   \nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .\n\nMy mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .   \nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .\n\nI also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity \n\nAny help or advice  would be welcome !", "author_fullname": "t2_rn9s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeding embedded sentences to another model for price prediction ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sw4os", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678977870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey !&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of a beginner and i&amp;#39;ve tasked with my first misson in my internship and i&amp;#39;m  not sure how to handle it .&lt;/p&gt;\n\n&lt;p&gt;For some context , we have multiple sentences (tasks) and each one has its own price tag .&lt;br/&gt;\nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .&lt;/p&gt;\n\n&lt;p&gt;My mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .&lt;br/&gt;\nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .&lt;/p&gt;\n\n&lt;p&gt;I also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity &lt;/p&gt;\n\n&lt;p&gt;Any help or advice  would be welcome !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sw4os", "is_robot_indexable": true, "report_reasons": null, "author": "Avencher", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "subreddit_subscribers": 857854, "created_utc": 1678977870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6k4lezou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Biases to Data-Driven: A Businessman's Journey towards Better Decision Making", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_11t67c9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MerzKaRZJPw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"From Biases to Data-Driven: A Businessman&amp;#39;s Journey towards Better Decision-Making\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "From Biases to Data-Driven: A Businessman's Journey towards Better Decision-Making", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MerzKaRZJPw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"From Biases to Data-Driven: A Businessman&amp;#39;s Journey towards Better Decision-Making\"&gt;&lt;/iframe&gt;", "author_name": "Sukhen's AI Studio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/MerzKaRZJPw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Sukhenw"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MerzKaRZJPw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"From Biases to Data-Driven: A Businessman&amp;#39;s Journey towards Better Decision-Making\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11t67c9", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cyx2v-dFMqtTnqY0by2gawIafPmwrEwQ6vKPWSU0Fmc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679000600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtube.com/watch?v=MerzKaRZJPw&amp;feature=share", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4LL5Moib4c-LLOtrH9uOUAgqbp5ubRezUbBRQcbwTRY.jpg?auto=webp&amp;v=enabled&amp;s=4089e860186be8d2e5421a12579171e9d181484a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/4LL5Moib4c-LLOtrH9uOUAgqbp5ubRezUbBRQcbwTRY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d2c5ec2d1dcea5a9ef793912189b6a211db23ae", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/4LL5Moib4c-LLOtrH9uOUAgqbp5ubRezUbBRQcbwTRY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2b23a1931f83735b9eab12fcd0c84799facdec9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/4LL5Moib4c-LLOtrH9uOUAgqbp5ubRezUbBRQcbwTRY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=601c27c3eba886193e0ebc6099b80f0e68d43151", "width": 320, "height": 240}], "variants": {}, "id": "wmVWaBvUrYjBJLl7XWZ8R3XpnpfK3C2KGY4RbU2tZkM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t67c9", "is_robot_indexable": true, "report_reasons": null, "author": "Sukhen_Waghmare", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t67c9/from_biases_to_datadriven_a_businessmans_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtube.com/watch?v=MerzKaRZJPw&amp;feature=share", "subreddit_subscribers": 857854, "created_utc": 1679000600.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "From Biases to Data-Driven: A Businessman's Journey towards Better Decision-Making", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/MerzKaRZJPw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"From Biases to Data-Driven: A Businessman&amp;#39;s Journey towards Better Decision-Making\"&gt;&lt;/iframe&gt;", "author_name": "Sukhen's AI Studio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/MerzKaRZJPw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Sukhenw"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any help please?", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Science masters in paris ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t644y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any help please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t644y", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "subreddit_subscribers": 857854, "created_utc": 1679000406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?", "author_fullname": "t2_rugmcqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the McKinsey of Data Science Consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t60oq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t60oq", "is_robot_indexable": true, "report_reasons": null, "author": "Whathefish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "subreddit_subscribers": 857854, "created_utc": 1679000181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I'm having second thoughts and I would loved if anyone have any info on the school, it seems shady but I'm not sure, if not what other schools you might advise me ? thank you !", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ScienceTech Institute (Paris)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t5ovw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I&amp;#39;m having second thoughts and I would loved if anyone have any info on the school, it seems shady but I&amp;#39;m not sure, if not what other schools you might advise me ? thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t5ovw", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "subreddit_subscribers": 857854, "created_utc": 1678999427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, can you help me finding a PC? Im an economics studente and i Will start learning some R and phyton. After the bachelor i will go for a masters in statistica and i think i would like to get into data science after it. My budget Is 1500 but i evacuate every best deal\nAnother question: you think a MacBook Air would be fine?", "author_fullname": "t2_qynyfdtk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best pc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t4qkx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678997230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, can you help me finding a PC? Im an economics studente and i Will start learning some R and phyton. After the bachelor i will go for a masters in statistica and i think i would like to get into data science after it. My budget Is 1500 but i evacuate every best deal\nAnother question: you think a MacBook Air would be fine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t4qkx", "is_robot_indexable": true, "report_reasons": null, "author": "AcanthaceaeTiny2348", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t4qkx/best_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t4qkx/best_pc/", "subreddit_subscribers": 857854, "created_utc": 1678997230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. \n\nFor example, say you want to predict whether a customer churns in the next month\n\nI assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?\n\nWhat about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?\n\nThank you!", "author_fullname": "t2_w9lhl6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best timeline to pull data for classification if predicting whether something happens within a month?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t49ti", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678996402.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678996167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. &lt;/p&gt;\n\n&lt;p&gt;For example, say you want to predict whether a customer churns in the next month&lt;/p&gt;\n\n&lt;p&gt;I assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?&lt;/p&gt;\n\n&lt;p&gt;What about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t49ti", "is_robot_indexable": true, "report_reasons": null, "author": "BlaseRaptor544", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "subreddit_subscribers": 857854, "created_utc": 1678996167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have tables stored in a datalake that are being treated via pyspark. They are upwards to 10million rows for each month, some pilling up to hundreds of millions.\nThe total values  counted last week, regarding data from February chenged when  counted again today.\n\nThe date of reference is the date that the row was processed, so there is not new data being added, since it would be counted as being processed in march if it was inputed this week.\n\nThe only process that is running that changes the total is a deduplication process that follows the logic of Last position of the client if they had a positive decision or the last negative decision, nothing else.\n\nI can't for the love of god discover why this happens, and there seems to be no connection to the table size since some really small tables(some hundred thousands rows) are behaving the same way.", "author_fullname": "t2_axhjl6nf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can cause changes in a data lake table total observations???", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sshqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678969078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tables stored in a datalake that are being treated via pyspark. They are upwards to 10million rows for each month, some pilling up to hundreds of millions.\nThe total values  counted last week, regarding data from February chenged when  counted again today.&lt;/p&gt;\n\n&lt;p&gt;The date of reference is the date that the row was processed, so there is not new data being added, since it would be counted as being processed in march if it was inputed this week.&lt;/p&gt;\n\n&lt;p&gt;The only process that is running that changes the total is a deduplication process that follows the logic of Last position of the client if they had a positive decision or the last negative decision, nothing else.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t for the love of god discover why this happens, and there seems to be no connection to the table size since some really small tables(some hundred thousands rows) are behaving the same way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sshqn", "is_robot_indexable": true, "report_reasons": null, "author": "One_Kaleidoscope_271", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sshqn/what_can_cause_changes_in_a_data_lake_table_total/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sshqn/what_can_cause_changes_in_a_data_lake_table_total/", "subreddit_subscribers": 857854, "created_utc": 1678969078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)", "author_fullname": "t2_7dah3w1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smarty-GPT: library of prompts/contexts (connected with Awesome Prompts Chat GPT)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sp0yn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678958500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a &lt;strong&gt;TRANSPARENT&lt;/strong&gt; way to end users.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/citiususc/Smarty-GPT\"&gt;https://github.com/citiususc/Smarty-GPT&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?auto=webp&amp;v=enabled&amp;s=4c4e24f34f2d2048c36c709970f8b0a1f554763b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08317e2847b960e563e3760767f8996f74ffec91", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5ffa97632b3db9cdbcadea2e79c7397fcee942a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=150c1fc2bcb8f1988d5c51893f9f39430a052aeb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1161943b7223878b97b477932eab962225efd7d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6a7c3f67eda6e09b4e1c5da80509311d705e723", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=965bf12a639553a1544471b20965e8ffffb1020e", "width": 1080, "height": 540}], "variants": {}, "id": "-sE09W2NVnKrkkxWVPCHfeOdIP9QoKJRenZt2uMdLIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sp0yn", "is_robot_indexable": true, "report_reasons": null, "author": "usc-ur", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sp0yn/smartygpt_library_of_promptscontexts_connected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sp0yn/smartygpt_library_of_promptscontexts_connected/", "subreddit_subscribers": 857854, "created_utc": 1678958500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, hope you\u2019re doing well.\n\nAs part of one of the requests, we\u2019re analysing the data of lost sales opportunities for a particular customer of ours. I wanted to know if there\u2019s any insight that we could generate from this data, other than the usual (Account owner wise wins, Sales cycle time etc).\n\nThanks in advance!", "author_fullname": "t2_7l62js01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insights for lost sales opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11so12z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678954869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, hope you\u2019re doing well.&lt;/p&gt;\n\n&lt;p&gt;As part of one of the requests, we\u2019re analysing the data of lost sales opportunities for a particular customer of ours. I wanted to know if there\u2019s any insight that we could generate from this data, other than the usual (Account owner wise wins, Sales cycle time etc).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11so12z", "is_robot_indexable": true, "report_reasons": null, "author": "MuayThaiandMolly", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11so12z/insights_for_lost_sales_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11so12z/insights_for_lost_sales_opportunities/", "subreddit_subscribers": 857854, "created_utc": 1678954869.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is the stack-overflow of 2023 and beyond, and will only get better.\n\nWould you penalize a candidate for using a resource like ChatGPT?  Specifically if it made them more efficient, and were able to solve more problems in the same amount of time as someone who used more traditional resources (stack-overflow, google, etc.)\n\nEDIT: to clarify, I want to emphasize my point above where in this case, the candidate needs to be able to describe what they are doing, why it works, pros and cons vs other approaches, etc.  I\u2019m also assuming if they have gotten to the point of an in-person coding technical interview, they have already passed prior interview steps where they have demonstrated foundational knowledge of the field.\n\nAdditionally, if you are in the role of hiring and you haven\u2019t deeply probed the capacity of ChatGPT to write effective code given an appropriate prompt, I\u2019d say that is step 1.", "author_fullname": "t2_6ldwsyzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When hiring, how would you react if a candidate data scientist used ChatGPT heavily throughout a technical interview/coding session, but did a great job communicating what they were doing and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11skvpf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678982226.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678943441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is the stack-overflow of 2023 and beyond, and will only get better.&lt;/p&gt;\n\n&lt;p&gt;Would you penalize a candidate for using a resource like ChatGPT?  Specifically if it made them more efficient, and were able to solve more problems in the same amount of time as someone who used more traditional resources (stack-overflow, google, etc.)&lt;/p&gt;\n\n&lt;p&gt;EDIT: to clarify, I want to emphasize my point above where in this case, the candidate needs to be able to describe what they are doing, why it works, pros and cons vs other approaches, etc.  I\u2019m also assuming if they have gotten to the point of an in-person coding technical interview, they have already passed prior interview steps where they have demonstrated foundational knowledge of the field.&lt;/p&gt;\n\n&lt;p&gt;Additionally, if you are in the role of hiring and you haven\u2019t deeply probed the capacity of ChatGPT to write effective code given an appropriate prompt, I\u2019d say that is step 1.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11skvpf", "is_robot_indexable": true, "report_reasons": null, "author": "MyNotWittyHandle", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11skvpf/when_hiring_how_would_you_react_if_a_candidate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11skvpf/when_hiring_how_would_you_react_if_a_candidate/", "subreddit_subscribers": 857854, "created_utc": 1678943441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I am building my firsts deep-learning based projects and i just noticed that pytorch 2.0 is officially available. I started to learn tensorflow a while ago, but i have heard that pytorch is one of the most popular DL frameworks out there besides tf. Which one you guys prefer and why?\n\n[View Poll](https://www.reddit.com/poll/11t4dlm)", "author_fullname": "t2_cl9x61e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choose wisely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11t4dlm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678996409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I am building my firsts deep-learning based projects and i just noticed that pytorch 2.0 is officially available. I started to learn tensorflow a while ago, but i have heard that pytorch is one of the most popular DL frameworks out there besides tf. Which one you guys prefer and why?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11t4dlm\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11t4dlm", "is_robot_indexable": true, "report_reasons": null, "author": "nickpngc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679255609122, "options": [{"text": "Tensorflow 2.0", "id": "22095470"}, {"text": "Pytorch 2.0", "id": "22095471"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 44, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t4dlm/choose_wisely/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/11t4dlm/choose_wisely/", "subreddit_subscribers": 857854, "created_utc": 1678996409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i am a beginner but have some theoretical knowledge about data science as an undergrad student.\n\ni travel by public transportation all the time and the frequency is supposed to be 15 mins but it goes up to an hour sometimes.  i want to find out what factors affect the time and how it can be solved!", "author_fullname": "t2_uz1t4ape", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for some guidance on personal data science project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t0j0a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678987695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i am a beginner but have some theoretical knowledge about data science as an undergrad student.&lt;/p&gt;\n\n&lt;p&gt;i travel by public transportation all the time and the frequency is supposed to be 15 mins but it goes up to an hour sometimes.  i want to find out what factors affect the time and how it can be solved!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t0j0a", "is_robot_indexable": true, "report_reasons": null, "author": "mani-maau", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t0j0a/looking_for_some_guidance_on_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t0j0a/looking_for_some_guidance_on_personal_data/", "subreddit_subscribers": 857854, "created_utc": 1678987695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/citiususc/pyplexity](https://github.com/citiususc/pyplexity)", "author_fullname": "t2_7dah3w1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyplexity: cleaning scraped text (better than BS4!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sp1iu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678958557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/citiususc/pyplexity\"&gt;https://github.com/citiususc/pyplexity&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sp1iu", "is_robot_indexable": true, "report_reasons": null, "author": "usc-ur", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sp1iu/pyplexity_cleaning_scraped_text_better_than_bs4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sp1iu/pyplexity_cleaning_scraped_text_better_than_bs4/", "subreddit_subscribers": 857854, "created_utc": 1678958557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Some of the Big Tech layoffs were from companies that were major contributors to Open Source development. What's your opinion on how this might be affected by the reduction in tech staff levels?", "author_fullname": "t2_lf5bem0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Tech layoffs and Open Source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11smu44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678950308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some of the Big Tech layoffs were from companies that were major contributors to Open Source development. What&amp;#39;s your opinion on how this might be affected by the reduction in tech staff levels?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11smu44", "is_robot_indexable": true, "report_reasons": null, "author": "Ariadne_Soul", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11smu44/big_tech_layoffs_and_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11smu44/big_tech_layoffs_and_open_source/", "subreddit_subscribers": 857854, "created_utc": 1678950308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've a dataset , sample columns\n\nBrand     Model         Fuel       Year        Price \n\nSuzuki    Mehran      CNG       2020      77777\nToyota    Corola       Petrol     2018      77729\netc......\n\n\nIs there model in which i can fit string column? iam basically using Logical regression, and i dont know how to convert these xolumns to integer. i tried pd...astype(int), didnt worked.", "author_fullname": "t2_qegyv1n1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "String column conversion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11stxmf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": 1678973349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678972699.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve a dataset , sample columns&lt;/p&gt;\n\n&lt;p&gt;Brand     Model         Fuel       Year        Price &lt;/p&gt;\n\n&lt;p&gt;Suzuki    Mehran      CNG       2020      77777\nToyota    Corola       Petrol     2018      77729\netc......&lt;/p&gt;\n\n&lt;p&gt;Is there model in which i can fit string column? iam basically using Logical regression, and i dont know how to convert these xolumns to integer. i tried pd...astype(int), didnt worked.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11stxmf", "is_robot_indexable": true, "report_reasons": null, "author": "Calm_Motor4162", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11stxmf/string_column_conversion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11stxmf/string_column_conversion/", "subreddit_subscribers": 857854, "created_utc": 1678972699.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}