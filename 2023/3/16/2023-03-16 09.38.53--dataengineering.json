{"kind": "Listing", "data": {"after": "t3_11rr5s4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got the below synopsis of dbt...\n\n \n\n1. Modularity and Reusability: DBT allows for the creation of reusable and modular data models, which can be easily shared across different projects and teams. This makes it easier to maintain consistency across the organization and reduces the duplication of effort.\n2. Version Control: DBT integrates with version control systems like Git, allowing data engineers to track changes to the data pipeline over time. This feature is crucial for maintaining data integrity and auditability.\n3. Testing and Validation: DBT includes built-in testing and validation features, which enable data engineers to test data pipelines and ensure that the output is accurate and consistent with the input data.\n4. Collaboration: DBT's collaborative features allow multiple team members to work on the same project simultaneously, which increases productivity and reduces the likelihood of errors.\n\n&amp;#x200B;\n\n...but I still don't get what the point of it is. What am I missing?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm not getting it...what's the point of DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8x0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678913595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got the below synopsis of dbt...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Modularity and Reusability: DBT allows for the creation of reusable and modular data models, which can be easily shared across different projects and teams. This makes it easier to maintain consistency across the organization and reduces the duplication of effort.&lt;/li&gt;\n&lt;li&gt;Version Control: DBT integrates with version control systems like Git, allowing data engineers to track changes to the data pipeline over time. This feature is crucial for maintaining data integrity and auditability.&lt;/li&gt;\n&lt;li&gt;Testing and Validation: DBT includes built-in testing and validation features, which enable data engineers to test data pipelines and ensure that the output is accurate and consistent with the input data.&lt;/li&gt;\n&lt;li&gt;Collaboration: DBT&amp;#39;s collaborative features allow multiple team members to work on the same project simultaneously, which increases productivity and reduces the likelihood of errors.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;...but I still don&amp;#39;t get what the point of it is. What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11s8x0q", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s8x0q/im_not_getting_itwhats_the_point_of_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s8x0q/im_not_getting_itwhats_the_point_of_dbt/", "subreddit_subscribers": 93215, "created_utc": 1678913595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should you use CTEs in Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_11rxy7l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JdWDI6f7iRhcYxYKl46_gqjRD6kclhCAfizOuPyEGEk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678890313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/should-you-use-ctes-in-snowflake", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?auto=webp&amp;v=enabled&amp;s=20a2551088f898639b6ec955d6d7871290427e5d", "width": 1029, "height": 559}, "resolutions": [{"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9235a9a2aca20741b9538b78ac05c3d243d85d", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cf7a2ab4633ef2929cbc1f238a4df5a7cccfba2", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9d07948fda7ff64ae817d5f9f16f1bd1000134f", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a44d58bd9253bb8b054057145639377e0ec7607", "width": 640, "height": 347}, {"url": "https://external-preview.redd.it/jIJPusbe0LFh_rWg-9MjW0hn2dkJhB-QnPXWMZVG4cE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=512d3b8c927e17c67413fb48c0bacea0308b7fc1", "width": 960, "height": 521}], "variants": {}, "id": "OslPu481G_OgkFvb61EI1AZa8gHcC9QARwcbWDbA6q0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11rxy7l", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rxy7l/should_you_use_ctes_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/should-you-use-ctes-in-snowflake", "subreddit_subscribers": 93215, "created_utc": 1678890313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I love using dbt, I'm not going to stop using it any time soon.  I can easily explain where it lives in the Modern Data Stack / ELT style of doing data engineering AND I can explain the features and benefits.\n\nBUT, in a meeting earlier today I was asked what are the alternatives to dbt? \n\n&amp;#x200B;\n\nAs in ... for E &amp; L you can use FiveTran or Hevo or Stitch, for database you can use AWS RedShift or GBQ or Snowflake, but for T ..... I can only think of dbt - is there any alternative?   (and to define that a bit better - any software that can transform data in SQL, cloud-based)", "author_fullname": "t2_353ucr1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt - what are the alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sintx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678936710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love using dbt, I&amp;#39;m not going to stop using it any time soon.  I can easily explain where it lives in the Modern Data Stack / ELT style of doing data engineering AND I can explain the features and benefits.&lt;/p&gt;\n\n&lt;p&gt;BUT, in a meeting earlier today I was asked what are the alternatives to dbt? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As in ... for E &amp;amp; L you can use FiveTran or Hevo or Stitch, for database you can use AWS RedShift or GBQ or Snowflake, but for T ..... I can only think of dbt - is there any alternative?   (and to define that a bit better - any software that can transform data in SQL, cloud-based)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11sintx", "is_robot_indexable": true, "report_reasons": null, "author": "cmcau", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11sintx/dbt_what_are_the_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11sintx/dbt_what_are_the_alternatives/", "subreddit_subscribers": 93215, "created_utc": 1678936710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The programming language that we'd use is Python, and I have worked with Python and SQL but never with async structures.", "author_fullname": "t2_q0hjyvx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently joined a DE team and I've been asked to study async, multiprocessing, queuing, and Kafka. Can anybody tell me how to proceed and also share resources that I can use.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s4t6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678904866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The programming language that we&amp;#39;d use is Python, and I have worked with Python and SQL but never with async structures.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11s4t6s", "is_robot_indexable": true, "report_reasons": null, "author": "Ready--Aim--Fire", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s4t6s/recently_joined_a_de_team_and_ive_been_asked_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s4t6s/recently_joined_a_de_team_and_ive_been_asked_to/", "subreddit_subscribers": 93215, "created_utc": 1678904866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I watched a video on breaking into big tech as a data engineer and in the video they mention a few things you should know. One thing you should know is how to build \"high quality pipelines\", but that's very vague. So, what are the characteristics of a high quality data pipeline?", "author_fullname": "t2_yabvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Quality Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8iqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678912734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I watched a video on breaking into big tech as a data engineer and in the video they mention a few things you should know. One thing you should know is how to build &amp;quot;high quality pipelines&amp;quot;, but that&amp;#39;s very vague. So, what are the characteristics of a high quality data pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11s8iqn", "is_robot_indexable": true, "report_reasons": null, "author": "phantomxxone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s8iqn/high_quality_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s8iqn/high_quality_pipelines/", "subreddit_subscribers": 93215, "created_utc": 1678912734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My coworker and I are tasked with building out our data platform at our company. Our company has never had a data warehouse - just reporting directly against production database. It was decided not by us that we will be using Azure tools since we are already mostly a Microsoft shop. So we are using ADF, Azure Data Lake, Azure SQL servers/databases for the Data Warehouse, etc. We are not data engineers or even data analysts per se, but do work in these areas and are increasingly doing more.\n\nThe idea is to use ADF as simply an orchestrator as much as possible. Any transformations will be done on the SQL server side via stored procedures (it was clear after browsing this and other forums/sites that ADF can be a pain for transformations). We have a very small team which is very comfortable in SQL, so we are thinking this will play to our strengths.\n\nOur company does not deal with the amount of data where we need robust heavily-engineered processes. We don't even know what those even look like anyway.\n\nHere is how we are approaching the design at a high level. All steps are orchestrated via ADF.\n\n1. **Extract** from source and **Load** to Data Lake as CSV files\n2. **Extract** from Data Lake and **Load** to SQL staging table\n3. Call a stored procedure in SQL to do the following: \n   1. **Extract**/select data from staging table\n   2. **Transform** the data as needed\n   3. **Load**/insert the data into production table in the Warehouse\n\nTo be honest, my coworker and I are not really sure we will even realize the benefit of using the Data Lake given our use case, but again it was decided not by us that we will use the Data Lake.\n\nAny and all feedback, advice, tips, etc. is welcome and greatly appreciated. If this is a garbage approach, please tell me it is, but then also provide suggestions on what you would do instead.\n\nThank you in advance!", "author_fullname": "t2_dycud4bp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT Design - Request for Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s9h3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678914809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My coworker and I are tasked with building out our data platform at our company. Our company has never had a data warehouse - just reporting directly against production database. It was decided not by us that we will be using Azure tools since we are already mostly a Microsoft shop. So we are using ADF, Azure Data Lake, Azure SQL servers/databases for the Data Warehouse, etc. We are not data engineers or even data analysts per se, but do work in these areas and are increasingly doing more.&lt;/p&gt;\n\n&lt;p&gt;The idea is to use ADF as simply an orchestrator as much as possible. Any transformations will be done on the SQL server side via stored procedures (it was clear after browsing this and other forums/sites that ADF can be a pain for transformations). We have a very small team which is very comfortable in SQL, so we are thinking this will play to our strengths.&lt;/p&gt;\n\n&lt;p&gt;Our company does not deal with the amount of data where we need robust heavily-engineered processes. We don&amp;#39;t even know what those even look like anyway.&lt;/p&gt;\n\n&lt;p&gt;Here is how we are approaching the design at a high level. All steps are orchestrated via ADF.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Extract&lt;/strong&gt; from source and &lt;strong&gt;Load&lt;/strong&gt; to Data Lake as CSV files&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Extract&lt;/strong&gt; from Data Lake and &lt;strong&gt;Load&lt;/strong&gt; to SQL staging table&lt;/li&gt;\n&lt;li&gt;Call a stored procedure in SQL to do the following: \n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Extract&lt;/strong&gt;/select data from staging table&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Transform&lt;/strong&gt; the data as needed&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Load&lt;/strong&gt;/insert the data into production table in the Warehouse&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To be honest, my coworker and I are not really sure we will even realize the benefit of using the Data Lake given our use case, but again it was decided not by us that we will use the Data Lake.&lt;/p&gt;\n\n&lt;p&gt;Any and all feedback, advice, tips, etc. is welcome and greatly appreciated. If this is a garbage approach, please tell me it is, but then also provide suggestions on what you would do instead.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11s9h3v", "is_robot_indexable": true, "report_reasons": null, "author": "armurphy1907", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s9h3v/elt_design_request_for_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s9h3v/elt_design_request_for_feedback/", "subreddit_subscribers": 93215, "created_utc": 1678914809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Every now and then I find myself writing practically the same data connector that does the same exhaustive traversing:\n\nfor example, maybe something like:\n\n    GET /orgs\n    GET /orgs/1/users\n    GET /orgs/1/users/100\n    GET /orgs/1/users/100/events\n    GET /orgs/1/users/100/events?page=2\n    GET /orgs/1/users/100/events?page=3\n    GET /orgs/1/users/200/events\n    GET /orgs/1/users/200/events?page=2\n\nI've always written dirty one-offs to get where I need to go quickly, but with the feeling I'm reinventing the wheel each time. Does anyone know of any mature python libraries that abstract away the minutia of exhaustively iterating rest endpoints? Something where you might pass something like an endpoints definition dict and it runs with it?", "author_fullname": "t2_udio63vp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Library for Iterating over REST endpoints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s6zyu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678909437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Every now and then I find myself writing practically the same data connector that does the same exhaustive traversing:&lt;/p&gt;\n\n&lt;p&gt;for example, maybe something like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;GET /orgs\nGET /orgs/1/users\nGET /orgs/1/users/100\nGET /orgs/1/users/100/events\nGET /orgs/1/users/100/events?page=2\nGET /orgs/1/users/100/events?page=3\nGET /orgs/1/users/200/events\nGET /orgs/1/users/200/events?page=2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve always written dirty one-offs to get where I need to go quickly, but with the feeling I&amp;#39;m reinventing the wheel each time. Does anyone know of any mature python libraries that abstract away the minutia of exhaustively iterating rest endpoints? Something where you might pass something like an endpoints definition dict and it runs with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11s6zyu", "is_robot_indexable": true, "report_reasons": null, "author": "unsupported-subquery", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s6zyu/python_library_for_iterating_over_rest_endpoints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s6zyu/python_library_for_iterating_over_rest_endpoints/", "subreddit_subscribers": 93215, "created_utc": 1678909437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. \n\nI've read the rules and know job posts aren't allowed, but I'm hoping this might be OK.\n\n I'm a VP at a mid to large size nonprofit organization in the SF Bay Area. Our current data structure is all over the map with crucial information in databases, google sheets, spreadsheets, etc., but very little consistency between sources. I'm leading an effort to improve this situation and have been able to convince the CEO that we need a centralized data warehouse/data lake. A lot of our current internal reporting happens in Tableau (which I oversee), but it's becoming a real burden to maintain all the data flows. I feel like we've been building a fairly nice house (dashboards etc.) but on rather unfinished foundations. Ironically, though, it's the reports we've built that have made the CEO understand the value of the work and have contributed to being given the green light to expand our scope.\n\nI know a little bit but not enough to get this done, and I don't have the time for it anyway. So I'm looking at either contracting with an external consultant to get the initial blueprint for a data warehouse set up and then hiring someone full time for maintenance etc., or just hiring someone who can build and then maintain.\n\nWhat are your thoughts on those two options, from the perspective of the desirability of the job? My thought would be that it's nice to work on something and somewhat 'own' it, but it does require a fair degree of maturity in terms of being able to work in what will initially be a rather unstructured environment (and creating the structure for it). And I'm not sure if the skillset for building is the same as that for maintaining/managing.\n\nI've browsed through the salary thread, but I'm also wondering what your thoughts are on salary for a position like this. Since we're a nonprofit we are not able to compete with FAANG type compensation packages, but in contrast we do offer very stable employment (we have long-standing government contracts), a very friendly work environment and the opportunity to work in a mission-driven environment, which may provide value for some. We're also very family and work-life balance friendly. The only minus is that you get me as a boss (JK).\n\nI'm currently drawing up the job description, preparing my salary ask to the CFO , etc. So any input would be great!", "author_fullname": "t2_9zj6ggu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Light in the darkness- data engineering for a nonprofit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s1z6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678898877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read the rules and know job posts aren&amp;#39;t allowed, but I&amp;#39;m hoping this might be OK.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a VP at a mid to large size nonprofit organization in the SF Bay Area. Our current data structure is all over the map with crucial information in databases, google sheets, spreadsheets, etc., but very little consistency between sources. I&amp;#39;m leading an effort to improve this situation and have been able to convince the CEO that we need a centralized data warehouse/data lake. A lot of our current internal reporting happens in Tableau (which I oversee), but it&amp;#39;s becoming a real burden to maintain all the data flows. I feel like we&amp;#39;ve been building a fairly nice house (dashboards etc.) but on rather unfinished foundations. Ironically, though, it&amp;#39;s the reports we&amp;#39;ve built that have made the CEO understand the value of the work and have contributed to being given the green light to expand our scope.&lt;/p&gt;\n\n&lt;p&gt;I know a little bit but not enough to get this done, and I don&amp;#39;t have the time for it anyway. So I&amp;#39;m looking at either contracting with an external consultant to get the initial blueprint for a data warehouse set up and then hiring someone full time for maintenance etc., or just hiring someone who can build and then maintain.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on those two options, from the perspective of the desirability of the job? My thought would be that it&amp;#39;s nice to work on something and somewhat &amp;#39;own&amp;#39; it, but it does require a fair degree of maturity in terms of being able to work in what will initially be a rather unstructured environment (and creating the structure for it). And I&amp;#39;m not sure if the skillset for building is the same as that for maintaining/managing.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve browsed through the salary thread, but I&amp;#39;m also wondering what your thoughts are on salary for a position like this. Since we&amp;#39;re a nonprofit we are not able to compete with FAANG type compensation packages, but in contrast we do offer very stable employment (we have long-standing government contracts), a very friendly work environment and the opportunity to work in a mission-driven environment, which may provide value for some. We&amp;#39;re also very family and work-life balance friendly. The only minus is that you get me as a boss (JK).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently drawing up the job description, preparing my salary ask to the CFO , etc. So any input would be great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11s1z6a", "is_robot_indexable": true, "report_reasons": null, "author": "drpepinos", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s1z6a/light_in_the_darkness_data_engineering_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s1z6a/light_in_the_darkness_data_engineering_for_a/", "subreddit_subscribers": 93215, "created_utc": 1678898877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For reference, here is the JD they used (same for normal and intern roles lol) https://boards.greenhouse.io/icapitalnetwork/jobs/6628661002\n\nI\u2019m very excited to have been accepted because I haven\u2019t worked with a lot of industry stuff before like AWS, Snowflake, etc\n\nFinding housing in NYC is so difficult and expensive lol\n\nAny advice on how to make the most of my internship? I already know python and sql very well for reference", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I make the most of my internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s7x46", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678911423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For reference, here is the JD they used (same for normal and intern roles lol) &lt;a href=\"https://boards.greenhouse.io/icapitalnetwork/jobs/6628661002\"&gt;https://boards.greenhouse.io/icapitalnetwork/jobs/6628661002&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m very excited to have been accepted because I haven\u2019t worked with a lot of industry stuff before like AWS, Snowflake, etc&lt;/p&gt;\n\n&lt;p&gt;Finding housing in NYC is so difficult and expensive lol&lt;/p&gt;\n\n&lt;p&gt;Any advice on how to make the most of my internship? I already know python and sql very well for reference&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3UEUo51yjDeVtTnn4soxeRZQ1WuOG8NL6fhMG_X5lXo.jpg?auto=webp&amp;v=enabled&amp;s=a54f2cd3057f25902a68be3bd4e4cc8c3e6187ad", "width": 430, "height": 102}, "resolutions": [{"url": "https://external-preview.redd.it/3UEUo51yjDeVtTnn4soxeRZQ1WuOG8NL6fhMG_X5lXo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f4cfee524f77741a3d0575d2800665d0fd906d5", "width": 108, "height": 25}, {"url": "https://external-preview.redd.it/3UEUo51yjDeVtTnn4soxeRZQ1WuOG8NL6fhMG_X5lXo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb81672a91f70f0c786ba9549cdc7e59bcd40d90", "width": 216, "height": 51}, {"url": "https://external-preview.redd.it/3UEUo51yjDeVtTnn4soxeRZQ1WuOG8NL6fhMG_X5lXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8205db9ffaba6dde27c79aac470593c67b3e4241", "width": 320, "height": 75}], "variants": {}, "id": "4H1lO3enS-406D_brUYyFcz09gQJmJ3-OV8Q6vyIyF8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11s7x46", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s7x46/how_can_i_make_the_most_of_my_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s7x46/how_can_i_make_the_most_of_my_internship/", "subreddit_subscribers": 93215, "created_utc": 1678911423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'll quote the announcement that I just got:\n\n\"In our first featured community call, [Memgraph](https://www.linkedin.com/company/memgraph/)'s valued Discord member [S\u00f6ren Klein](https://www.linkedin.com/in/ACoAACs86OYB8i3eB1IJswJ0dvzgUOChhPyanzM) will educate us about the history of graph databases and share some interesting information about Cypher!\n\nJoin us today, March 15th, at 18:00 CET at [https://discord.com/events/842007348272169002/1083363853276041216](https://discord.com/events/842007348272169002/1083363853276041216)\"\n\nHope to see all of you there :)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/0r3z1de9vwna1.png?width=3200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0cfa0118fbec96276f8cecef1b6c9fdc2f794e65", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Memgraph's featured community call - history of graph databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0r3z1de9vwna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52c49bb7f77b15487264cbef95effc94d914ccf9"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712acf51f48479a65406a60d4cf92bd6729748df"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e91bf903115775d5b4cc1259351aba19843febc0"}, {"y": 256, "x": 640, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81100d0888ce93cbc60422c65afb2b66240f09e"}, {"y": 384, "x": 960, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6b0c9a73f78e767282288af40408da8c75ccd53"}, {"y": 432, "x": 1080, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=807e5c7b76c5aef9560157d5e091b0d0f2a95fad"}], "s": {"y": 1280, "x": 3200, "u": "https://preview.redd.it/0r3z1de9vwna1.png?width=3200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0cfa0118fbec96276f8cecef1b6c9fdc2f794e65"}, "id": "0r3z1de9vwna1"}}, "name": "t3_11rxmtv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5NbbfsYz7Ds7871DUTZJw_-HNCco8XwrCqMm0RY0EQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678889624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll quote the announcement that I just got:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;In our first featured community call, &lt;a href=\"https://www.linkedin.com/company/memgraph/\"&gt;Memgraph&lt;/a&gt;&amp;#39;s valued Discord member &lt;a href=\"https://www.linkedin.com/in/ACoAACs86OYB8i3eB1IJswJ0dvzgUOChhPyanzM\"&gt;S\u00f6ren Klein&lt;/a&gt; will educate us about the history of graph databases and share some interesting information about Cypher!&lt;/p&gt;\n\n&lt;p&gt;Join us today, March 15th, at 18:00 CET at &lt;a href=\"https://discord.com/events/842007348272169002/1083363853276041216\"&gt;https://discord.com/events/842007348272169002/1083363853276041216&lt;/a&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Hope to see all of you there :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0r3z1de9vwna1.png?width=3200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0cfa0118fbec96276f8cecef1b6c9fdc2f794e65\"&gt;https://preview.redd.it/0r3z1de9vwna1.png?width=3200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0cfa0118fbec96276f8cecef1b6c9fdc2f794e65&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11rxmtv", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rxmtv/memgraphs_featured_community_call_history_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rxmtv/memgraphs_featured_community_call_history_of/", "subreddit_subscribers": 93215, "created_utc": 1678889624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There's a shortage of good data engineering roles in my area, so I have been considering SWE and devops.  How hard would it be to make that switch, after spending my entire career in data.  My resume looks like this:\n\n\n\n1) Data analyst (1 year): I worked at two separate companies over the course of a year as a data analyst.  I used python and SQL, but the jobs were definitely more analytics focused than engineering.\n\n\n2) Data scientist (2 years): I did data platform work mostly, lots of python, SQL, and various AWS tools.  I should note that I never did the typical data science work, like predictive models and data exploration.\n\n\n\n\n\n\n3) Data engineer (2 years): I currently work as a data engineer.  I use Python, SQL, airflow, and do plenty of cloud platform work.  I'm not sure if it makes a difference, but this is my first job at a well known tech company.\n\n\n\n\nI have been using Python and SQL my entire career, so I feel like that might make it hard to switch to SWE.", "author_fullname": "t2_bc6dzgi9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard would it be for a data engineer to get a SWE role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ruz5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678883902.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678883440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a shortage of good data engineering roles in my area, so I have been considering SWE and devops.  How hard would it be to make that switch, after spending my entire career in data.  My resume looks like this:&lt;/p&gt;\n\n&lt;p&gt;1) Data analyst (1 year): I worked at two separate companies over the course of a year as a data analyst.  I used python and SQL, but the jobs were definitely more analytics focused than engineering.&lt;/p&gt;\n\n&lt;p&gt;2) Data scientist (2 years): I did data platform work mostly, lots of python, SQL, and various AWS tools.  I should note that I never did the typical data science work, like predictive models and data exploration.&lt;/p&gt;\n\n&lt;p&gt;3) Data engineer (2 years): I currently work as a data engineer.  I use Python, SQL, airflow, and do plenty of cloud platform work.  I&amp;#39;m not sure if it makes a difference, but this is my first job at a well known tech company.&lt;/p&gt;\n\n&lt;p&gt;I have been using Python and SQL my entire career, so I feel like that might make it hard to switch to SWE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ruz5h", "is_robot_indexable": true, "report_reasons": null, "author": "wfh_forever1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11ruz5h/how_hard_would_it_be_for_a_data_engineer_to_get_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ruz5h/how_hard_would_it_be_for_a_data_engineer_to_get_a/", "subreddit_subscribers": 93215, "created_utc": 1678883440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.decube.io/post/beginner-guide-for-building-data-pipeline-with-rust](https://www.decube.io/post/beginner-guide-for-building-data-pipeline-with-rust)", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginners guide using Rust for Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11smj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678949187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.decube.io/post/beginner-guide-for-building-data-pipeline-with-rust\"&gt;https://www.decube.io/post/beginner-guide-for-building-data-pipeline-with-rust&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MWh4J7rPO0d7pGkT8MtPVe_cIpfBfS730lvI8RIMbwg.jpg?auto=webp&amp;v=enabled&amp;s=aaa24e560b3b51a696e41d80c42e9a56211f7b72", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/MWh4J7rPO0d7pGkT8MtPVe_cIpfBfS730lvI8RIMbwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4efe0fd3bdfa1f2fc5d7054b89cbfadc8d89a89c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MWh4J7rPO0d7pGkT8MtPVe_cIpfBfS730lvI8RIMbwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19cf4a43e716e109039b895c418eb9ab3a1e38df", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/MWh4J7rPO0d7pGkT8MtPVe_cIpfBfS730lvI8RIMbwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a55bb720b124e0d1e2cf71bd6ed5c6c85968728", "width": 320, "height": 320}], "variants": {}, "id": "VcfOJWcP-OMqTp4ZgPcxtH81ZuMdmK2ePF8ZW97FeoM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11smj3u", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11smj3u/beginners_guide_using_rust_for_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11smj3u/beginners_guide_using_rust_for_data_pipeline/", "subreddit_subscribers": 93215, "created_utc": 1678949187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I tried posting a question about documenting and version controlling DE projects because I need to start doing that, the question was removed on grounds that I can't find on the wiki but I can't find that at all. Please help", "author_fullname": "t2_ozdnflqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't find some resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ru1f6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678880921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried posting a question about documenting and version controlling DE projects because I need to start doing that, the question was removed on grounds that I can&amp;#39;t find on the wiki but I can&amp;#39;t find that at all. Please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ru1f6", "is_robot_indexable": true, "report_reasons": null, "author": "Various_Bandicoot977", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ru1f6/cant_find_some_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ru1f6/cant_find_some_resources/", "subreddit_subscribers": 93215, "created_utc": 1678880921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've stumbled upon a European job site for data jobs and I've gone through some job ads for the DACH region, mainly for Big 4 companies.\n\nIs this salary really typical for managers with 5+ years of experience? Or is this one of these job ads from companies that hope to employ cheap immigrants?\n\nEven assuming that it's the bottom amount (\"from\"), I find the salary shockingly low. (I know the realities of the countries, including the cost of living, quite well, just haven't worked there in the area of data).\n\n&amp;#x200B;\n\nhttps://preview.redd.it/s78wh3vezyna1.png?width=672&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=011409db5c60b76f9c7d3a45c79db136bdbfae55", "author_fullname": "t2_ti6b0o4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data jobs in Germany, Austria, Switzerland (DACH region)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s78wh3vezyna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/s78wh3vezyna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8269605643affc833877e97a5e6680904292c2a1"}, {"y": 109, "x": 216, "u": "https://preview.redd.it/s78wh3vezyna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=149c06be929caba3d0e2e544ca76db0b8edb3207"}, {"y": 162, "x": 320, "u": "https://preview.redd.it/s78wh3vezyna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1208ab937277c4af9c0677fb080733f3c12ccd5f"}, {"y": 325, "x": 640, "u": "https://preview.redd.it/s78wh3vezyna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adc31a5bf4bb8528cd23c3b27bbbe163118fd554"}], "s": {"y": 342, "x": 672, "u": "https://preview.redd.it/s78wh3vezyna1.png?width=672&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=011409db5c60b76f9c7d3a45c79db136bdbfae55"}, "id": "s78wh3vezyna1"}}, "name": "t3_11s9shm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/j0E9DAKCQiuBUsnL3ljT41f8MIiVmml_6deVYKLSDwc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678915500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve stumbled upon a European job site for data jobs and I&amp;#39;ve gone through some job ads for the DACH region, mainly for Big 4 companies.&lt;/p&gt;\n\n&lt;p&gt;Is this salary really typical for managers with 5+ years of experience? Or is this one of these job ads from companies that hope to employ cheap immigrants?&lt;/p&gt;\n\n&lt;p&gt;Even assuming that it&amp;#39;s the bottom amount (&amp;quot;from&amp;quot;), I find the salary shockingly low. (I know the realities of the countries, including the cost of living, quite well, just haven&amp;#39;t worked there in the area of data).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s78wh3vezyna1.png?width=672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=011409db5c60b76f9c7d3a45c79db136bdbfae55\"&gt;https://preview.redd.it/s78wh3vezyna1.png?width=672&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=011409db5c60b76f9c7d3a45c79db136bdbfae55&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11s9shm", "is_robot_indexable": true, "report_reasons": null, "author": "user2401372", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s9shm/data_jobs_in_germany_austria_switzerland_dach/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s9shm/data_jobs_in_germany_austria_switzerland_dach/", "subreddit_subscribers": 93215, "created_utc": 1678915500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, university student who is new to DE here!\n\nAre hackathons/datathons a good way of boosting up my resume or would working on individual projects be better? It seems somewhat hard to build good data pipelines in such a short amount of time and for the hackathon I've actually been to, everybody was focused on building a frontend such that it barely functioned, but both reasons could just be my lack of experience. What are your thoughts?", "author_fullname": "t2_9adyx088", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hackathons/datathons appropriate for building DE projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s3xbw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678903056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, university student who is new to DE here!&lt;/p&gt;\n\n&lt;p&gt;Are hackathons/datathons a good way of boosting up my resume or would working on individual projects be better? It seems somewhat hard to build good data pipelines in such a short amount of time and for the hackathon I&amp;#39;ve actually been to, everybody was focused on building a frontend such that it barely functioned, but both reasons could just be my lack of experience. What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11s3xbw", "is_robot_indexable": true, "report_reasons": null, "author": "Secular123", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s3xbw/hackathonsdatathons_appropriate_for_building_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s3xbw/hackathonsdatathons_appropriate_for_building_de/", "subreddit_subscribers": 93215, "created_utc": 1678903056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The opinions on DS/DE online are almost split between to camps, the online bootcamp/ tech blogs camp who wants to convince me that taking 2 courses would prepare me for a senior level position where I would get paid a million dollar for being gEnEiOuS ArRifiCal daTa eNginEEr, and the other camp says that most DE jobs either require a Masters degree or couple years of experience so I seriously don't know what to do.\n\nI am a 4th year CS student right now, and I got interested in data engineering after researching about it but I am not sure if I should focus my free time on studying it, OR work mostly on something like backend engineering with some studying of DE (something like a 80/20 split) in the hope of starting as a Backend engineer then transferring to DE when I gain experience.\n\n\nMost of you work in the field so I am interested in your opinions.\n\nThanks!", "author_fullname": "t2_78b3uzmv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a career that I could logicly study for while at uni with the hope of getting a job after I graduate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rt2ih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678878073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The opinions on DS/DE online are almost split between to camps, the online bootcamp/ tech blogs camp who wants to convince me that taking 2 courses would prepare me for a senior level position where I would get paid a million dollar for being gEnEiOuS ArRifiCal daTa eNginEEr, and the other camp says that most DE jobs either require a Masters degree or couple years of experience so I seriously don&amp;#39;t know what to do.&lt;/p&gt;\n\n&lt;p&gt;I am a 4th year CS student right now, and I got interested in data engineering after researching about it but I am not sure if I should focus my free time on studying it, OR work mostly on something like backend engineering with some studying of DE (something like a 80/20 split) in the hope of starting as a Backend engineer then transferring to DE when I gain experience.&lt;/p&gt;\n\n&lt;p&gt;Most of you work in the field so I am interested in your opinions.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11rt2ih", "is_robot_indexable": true, "report_reasons": null, "author": "CyperFlicker", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rt2ih/is_this_a_career_that_i_could_logicly_study_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rt2ih/is_this_a_career_that_i_could_logicly_study_for/", "subreddit_subscribers": 93215, "created_utc": 1678878073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nFirst of all, sorry if that post sounds like it has been treated already multiple time, but I would like extra thoughts.\n\nAs a software developer with 12 y experience, I want to switch to a data engineer role. I don't have a degree nor a certification.\n\nWith the data tech ecosystem having grown so fast, I think I need to learn other things to get into DE area but I cannot manage to see what is the most relevant for me, and the list of possibilities is quite big. \n\nLet say that the main goal is be more attractive to companies for that role and to have some good theorical + some basic hands on experience on some of the new cool tools used by data engineers. \n\nFor a more practical experience I m thinking of building pet projects on my own, or contributing to open source projects. \n\n**I see 3 categories ( maybe there are more ) for the learning aspect, and I would like thoughts about the most relevant one.**\n\n1. **Msc online** are very expensives, I can afford them, but would the return of investement be worth ?\n2. **courses/ learning path** giving certification on [https://www.coursera.org/](https://www.coursera.org/), [https://www.dataquest.io/](https://www.dataquest.io/) and others.\n3. **data boot camps** they seem to be in the middle between the first two options.\n\n&amp;#x200B;\n\nmy background is, I guess, a factor that plays a role in the decision, so I leave it here as well.\n\nI have a quite strong experience in the java ecosystem plus some good sql / nosql db experience. \n\nWith some experience in python ( not in big data field ), scala, elasticsearch, kafka, hadoop, aws cli/sdk for s3, elasticbeanstalk, lambdas and dynamodb. \n\nNon professional experience in kafka-stream, reactive programming. \n\nI m also confortable building CI/CD pipeline with github actions and aws cli.\n\n&amp;#x200B;\n\nThanks for the ones who reach that part of the post without missing a line ;)", "author_fullname": "t2_nj7sjynk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career switch advice , choosing the right learning form", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8xbk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678913616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;First of all, sorry if that post sounds like it has been treated already multiple time, but I would like extra thoughts.&lt;/p&gt;\n\n&lt;p&gt;As a software developer with 12 y experience, I want to switch to a data engineer role. I don&amp;#39;t have a degree nor a certification.&lt;/p&gt;\n\n&lt;p&gt;With the data tech ecosystem having grown so fast, I think I need to learn other things to get into DE area but I cannot manage to see what is the most relevant for me, and the list of possibilities is quite big. &lt;/p&gt;\n\n&lt;p&gt;Let say that the main goal is be more attractive to companies for that role and to have some good theorical + some basic hands on experience on some of the new cool tools used by data engineers. &lt;/p&gt;\n\n&lt;p&gt;For a more practical experience I m thinking of building pet projects on my own, or contributing to open source projects. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I see 3 categories ( maybe there are more ) for the learning aspect, and I would like thoughts about the most relevant one.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Msc online&lt;/strong&gt; are very expensives, I can afford them, but would the return of investement be worth ?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;courses/ learning path&lt;/strong&gt; giving certification on &lt;a href=\"https://www.coursera.org/\"&gt;https://www.coursera.org/&lt;/a&gt;, &lt;a href=\"https://www.dataquest.io/\"&gt;https://www.dataquest.io/&lt;/a&gt; and others.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;data boot camps&lt;/strong&gt; they seem to be in the middle between the first two options.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;my background is, I guess, a factor that plays a role in the decision, so I leave it here as well.&lt;/p&gt;\n\n&lt;p&gt;I have a quite strong experience in the java ecosystem plus some good sql / nosql db experience. &lt;/p&gt;\n\n&lt;p&gt;With some experience in python ( not in big data field ), scala, elasticsearch, kafka, hadoop, aws cli/sdk for s3, elasticbeanstalk, lambdas and dynamodb. &lt;/p&gt;\n\n&lt;p&gt;Non professional experience in kafka-stream, reactive programming. &lt;/p&gt;\n\n&lt;p&gt;I m also confortable building CI/CD pipeline with github actions and aws cli.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for the ones who reach that part of the post without missing a line ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?auto=webp&amp;v=enabled&amp;s=27d1fbfa41af08ab445125a5830ec1430f088fbe", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b3ed072c56ec3ae0f01b63b31f88e9dcfedd755", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aac48616e1f390d96fa9ec298d73476bb0c10a0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d3c1980b3aaf1c175d31609ebfcb55b32519959", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9b5b8270e6b546ed7251d47ac6e5acf7403cd1f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07b9aa4e8ce45c44a350f4ee3e281f47dbc30394", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/pLSR0Rpmlm0YOrI_U2sKzEeF87LsInGWnlb54-hObD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=642d9f69a16a0baabc5c6d9c77a1a7de26ad4e49", "width": 1080, "height": 565}], "variants": {}, "id": "nnmvZitIdtl3UJSov7ZcIqMwnFG7OvGcVvkNPR4Vsrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11s8xbk", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Feed5480", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s8xbk/career_switch_advice_choosing_the_right_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s8xbk/career_switch_advice_choosing_the_right_learning/", "subreddit_subscribers": 93215, "created_utc": 1678913616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any experience with qwak? and can shed light on the pros cons, and how it stands vs other platforms?  \nThe background is that I'm a DS trying to improve the data engineering infrastructure in my company, the data is time series and audio from &gt; 100K sensors. We are looking to improve our infrastructure, and someone suggested this platform.  The desired infra would allow the DSs to create new features seamlessly, there is no need for real-time processing, and daily jobs are good enough. Hope this made some sense :)  \n\n\nI don't have much experience with the engineering side, and any suggestions would be appreciated.", "author_fullname": "t2_1ioyllpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience with qwak?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s6sj3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678908979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any experience with qwak? and can shed light on the pros cons, and how it stands vs other platforms?&lt;br/&gt;\nThe background is that I&amp;#39;m a DS trying to improve the data engineering infrastructure in my company, the data is time series and audio from &amp;gt; 100K sensors. We are looking to improve our infrastructure, and someone suggested this platform.  The desired infra would allow the DSs to create new features seamlessly, there is no need for real-time processing, and daily jobs are good enough. Hope this made some sense :)  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much experience with the engineering side, and any suggestions would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11s6sj3", "is_robot_indexable": true, "report_reasons": null, "author": "zoshka", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s6sj3/any_experience_with_qwak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s6sj3/any_experience_with_qwak/", "subreddit_subscribers": 93215, "created_utc": 1678908979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been working as a Data analyst at this small-ish healthcare company.  The EMR is...... Not the greatest for my function.  Reporting is all done via premade data exports in the EMR.  Meaning the EMR company has to build the reports for us and then we can run them (sometimes a report will take a whole day to run) and then we can export the data into a .csv or .txt file.  One good thing is that we can set them up to automatically run overnight on schedules.  I think they are in the process of setting up automatic exporting of the data to an SFTP server for future development, but I have no clue tbh.\n\nI've begun working with our accounting team a lot and have been automating a lot of their reporting.  Unfortunately all the automation is done through VBA.  But we use historical data in these reports, so essentially for each report I've been working on, I'm keeping a directory structure of each year, then each month and then the data reports I download from our EMR.  Which could be 1-3 different .txt files with data that gets joined together, or manipulated in some way.\n\nIn an ideal world, we could get these reports dumped into an SFTP server automatically and then I could write some scripts to pull that data and load it into a database and then my reporting scripts could run off the database.\n\nSo I'm just looking for opinions?  At what point did any of you make the switch from storing data in txt/csv files to storing it in a database?", "author_fullname": "t2_vlxp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I be using a database in this situation | Healthcare Industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s1k8y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678897983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working as a Data analyst at this small-ish healthcare company.  The EMR is...... Not the greatest for my function.  Reporting is all done via premade data exports in the EMR.  Meaning the EMR company has to build the reports for us and then we can run them (sometimes a report will take a whole day to run) and then we can export the data into a .csv or .txt file.  One good thing is that we can set them up to automatically run overnight on schedules.  I think they are in the process of setting up automatic exporting of the data to an SFTP server for future development, but I have no clue tbh.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve begun working with our accounting team a lot and have been automating a lot of their reporting.  Unfortunately all the automation is done through VBA.  But we use historical data in these reports, so essentially for each report I&amp;#39;ve been working on, I&amp;#39;m keeping a directory structure of each year, then each month and then the data reports I download from our EMR.  Which could be 1-3 different .txt files with data that gets joined together, or manipulated in some way.&lt;/p&gt;\n\n&lt;p&gt;In an ideal world, we could get these reports dumped into an SFTP server automatically and then I could write some scripts to pull that data and load it into a database and then my reporting scripts could run off the database.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m just looking for opinions?  At what point did any of you make the switch from storing data in txt/csv files to storing it in a database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11s1k8y", "is_robot_indexable": true, "report_reasons": null, "author": "CaptSprinkls", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s1k8y/should_i_be_using_a_database_in_this_situation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s1k8y/should_i_be_using_a_database_in_this_situation/", "subreddit_subscribers": 93215, "created_utc": 1678897983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aqvee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Data Engineering can drive Data Governance by Design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "name": "t3_11rs83w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pcudav56SBKVO6hNuX0C41j_90SkXjAicfX9Vv4Ga1I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678875443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@willemkoenders/intelligent-data-governance-by-design-a-practical-example-30f2bbf1bf91", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?auto=webp&amp;v=enabled&amp;s=440a38d71b9365f5e78de9584368154c985b466b", "width": 1200, "height": 560}, "resolutions": [{"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc41a0dbae7ad11e81179ede286878e1101e67ae", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=073e7846c5d3f55bbdb8810bbe226f0eecc58642", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f5cdd5c6c76387379c2aa49d4826e208149322b", "width": 320, "height": 149}, {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=441e7e12d0ed2cd57ec085af487295e560665aab", "width": 640, "height": 298}, {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=781ef81ac1970f42133315d5e60350676b435145", "width": 960, "height": 448}, {"url": "https://external-preview.redd.it/oNrWm7VEMC20raxkmvy7aXCqeZIMsuTg0DAXB3Xaaf8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8911edcceb97daa566b41cc91b86136a485120b7", "width": 1080, "height": 504}], "variants": {}, "id": "Elg06ssVg6p7fFB2tSPYfO2KRzeTv2w5SYbGLOttetk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11rs83w", "is_robot_indexable": true, "report_reasons": null, "author": "willemkoenders", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rs83w/how_data_engineering_can_drive_data_governance_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@willemkoenders/intelligent-data-governance-by-design-a-practical-example-30f2bbf1bf91", "subreddit_subscribers": 93215, "created_utc": 1678875443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are on-premises RTU'S which are currently using the medina protocol and Palo Alto gateway. I would like to build a data pipeline to transfer the data from on-premises to AWS cloud through VPN. \n\nAdditional info, there is a postgres database running in an ec2 instance in which the data is being stored currently. \n\nWhat can I do to achieve this?", "author_fullname": "t2_6wgyvyl5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DATA pipeline from on premise RTU's to AWS Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11smn5v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678953699.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678949594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are on-premises RTU&amp;#39;S which are currently using the medina protocol and Palo Alto gateway. I would like to build a data pipeline to transfer the data from on-premises to AWS cloud through VPN. &lt;/p&gt;\n\n&lt;p&gt;Additional info, there is a postgres database running in an ec2 instance in which the data is being stored currently. &lt;/p&gt;\n\n&lt;p&gt;What can I do to achieve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11smn5v", "is_robot_indexable": true, "report_reasons": null, "author": "aimonster7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11smn5v/data_pipeline_from_on_premise_rtus_to_aws_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11smn5v/data_pipeline_from_on_premise_rtus_to_aws_cloud/", "subreddit_subscribers": 93215, "created_utc": 1678949594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. Me and some colleagues are working on various script files (mainly written in R and Python) whose goal is to perform some ELT tasks and generate some data analysis. \n\nI was wondering how do u manage your documentation for these types of scripts:\n\n- We have code documentation (comments) inside the script to describe exactly what tasks are performed by the code\n\n- We have a more \u00ab\u00a0business \u00bb documentation, which consists in one Readme file per script\n\n- everything is well versionned using Git. \n\nAll of the things I described work well, but I would need A more \u00abhigh level\u00bb documentation, which could be a sort of user friendly documentation website with the list of all scripts, the business description (sourcing from readmes), and links to github scripts \u00b4 codes. \n\nDo tools like confluence allow us to do these tasks or do you have any orges recommandations ?\n\nThank u :)", "author_fullname": "t2_ce3go0rt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scripts documentation ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sbho0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678919214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. Me and some colleagues are working on various script files (mainly written in R and Python) whose goal is to perform some ELT tasks and generate some data analysis. &lt;/p&gt;\n\n&lt;p&gt;I was wondering how do u manage your documentation for these types of scripts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;We have code documentation (comments) inside the script to describe exactly what tasks are performed by the code&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;We have a more \u00ab\u00a0business \u00bb documentation, which consists in one Readme file per script&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything is well versionned using Git. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All of the things I described work well, but I would need A more \u00abhigh level\u00bb documentation, which could be a sort of user friendly documentation website with the list of all scripts, the business description (sourcing from readmes), and links to github scripts \u00b4 codes. &lt;/p&gt;\n\n&lt;p&gt;Do tools like confluence allow us to do these tasks or do you have any orges recommandations ?&lt;/p&gt;\n\n&lt;p&gt;Thank u :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11sbho0", "is_robot_indexable": true, "report_reasons": null, "author": "nad_pub", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11sbho0/scripts_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11sbho0/scripts_documentation/", "subreddit_subscribers": 93215, "created_utc": 1678919214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we are looking to hire an experienced data engineer / mlops , I know it's not the same, but the company is not big enough to separate the positions.   \nWhat are some good practices in designing an interview process?  \nAre home assignments a thing in those fields?  \nI'm in the DS team, and don't have much experience with DE, and I feel the interview processes are different for DS than a DE", "author_fullname": "t2_1ioyllpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the common practices for a data engineer, mlops interview process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s6vi6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678909172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we are looking to hire an experienced data engineer / mlops , I know it&amp;#39;s not the same, but the company is not big enough to separate the positions.&lt;br/&gt;\nWhat are some good practices in designing an interview process?&lt;br/&gt;\nAre home assignments a thing in those fields?&lt;br/&gt;\nI&amp;#39;m in the DS team, and don&amp;#39;t have much experience with DE, and I feel the interview processes are different for DS than a DE&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11s6vi6", "is_robot_indexable": true, "report_reasons": null, "author": "zoshka", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11s6vi6/what_are_the_common_practices_for_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11s6vi6/what_are_the_common_practices_for_a_data_engineer/", "subreddit_subscribers": 93215, "created_utc": 1678909172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to learn the use case and should we opt for open-source or closed loop.\n\nOpen Source List:  \n1. Datahub  \n2. Open Meta Data  \n3. Amundsen  \n\n\nClosed Loop:  \n1. Atlan  \n2. Alation  \n3. Decube  \n\n\nHappy to get views and way forward.", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats DE's view on Data Catalog tools and governance? Does it impact DE anyway?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rxgqh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678889259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to learn the use case and should we opt for open-source or closed loop.&lt;/p&gt;\n\n&lt;p&gt;Open Source List:&lt;br/&gt;\n1. Datahub&lt;br/&gt;\n2. Open Meta Data&lt;br/&gt;\n3. Amundsen  &lt;/p&gt;\n\n&lt;p&gt;Closed Loop:&lt;br/&gt;\n1. Atlan&lt;br/&gt;\n2. Alation&lt;br/&gt;\n3. Decube  &lt;/p&gt;\n\n&lt;p&gt;Happy to get views and way forward.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11rxgqh", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rxgqh/whats_des_view_on_data_catalog_tools_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rxgqh/whats_des_view_on_data_catalog_tools_and/", "subreddit_subscribers": 93215, "created_utc": 1678889259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nThis may be a broad question, but any opinions would be helpful.\n\nAs a data engineer or data engineering consultant, when a client asks you about doing a project they usually have a vision in mind, e.g. integrate two data sources or enable a data science use case, what they usually don't have is an explanation of the organization's 'data maturity'.\n\nI'm posting about this because I've often found myself start solving the initial problem only to come up with multiple other underlying problems - e.g. I want to integrate the organization's customer data into a single data source, but they have no data quality standards in place, so the project scope widens and I'm stuck in limbo when trying to achieve the original goal.\n\nDo you have any frameworks or typical assessments you do to check the viability of a data engineering project? My rough thinking is to assess individual aspects like:  \n\n\n1. Data governance - how do folks access data and who monitors this.\n2. Data quality - what frameworks do you have in place to check the data?\n3. Data security - how do you protect data - what are your standards for this?\n4. Infrastructure - do you have a tech stack in place capable of serving your needs?\n5. Advanced analytics - how do you surface data insights, do your analysts have a CI/CD framework like MLFlow etc.\n\nI think that assessments like these may help uncover a more 'root problem' before you go ahead and do what the client asks for in the beginning.\n\nI hope this makes sense. Please let me know if you have any ideas or opinions.", "author_fullname": "t2_4wsp8k38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Framework for an organization's 'data readiness'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11rr5s4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678871860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;This may be a broad question, but any opinions would be helpful.&lt;/p&gt;\n\n&lt;p&gt;As a data engineer or data engineering consultant, when a client asks you about doing a project they usually have a vision in mind, e.g. integrate two data sources or enable a data science use case, what they usually don&amp;#39;t have is an explanation of the organization&amp;#39;s &amp;#39;data maturity&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m posting about this because I&amp;#39;ve often found myself start solving the initial problem only to come up with multiple other underlying problems - e.g. I want to integrate the organization&amp;#39;s customer data into a single data source, but they have no data quality standards in place, so the project scope widens and I&amp;#39;m stuck in limbo when trying to achieve the original goal.&lt;/p&gt;\n\n&lt;p&gt;Do you have any frameworks or typical assessments you do to check the viability of a data engineering project? My rough thinking is to assess individual aspects like:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data governance - how do folks access data and who monitors this.&lt;/li&gt;\n&lt;li&gt;Data quality - what frameworks do you have in place to check the data?&lt;/li&gt;\n&lt;li&gt;Data security - how do you protect data - what are your standards for this?&lt;/li&gt;\n&lt;li&gt;Infrastructure - do you have a tech stack in place capable of serving your needs?&lt;/li&gt;\n&lt;li&gt;Advanced analytics - how do you surface data insights, do your analysts have a CI/CD framework like MLFlow etc.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I think that assessments like these may help uncover a more &amp;#39;root problem&amp;#39; before you go ahead and do what the client asks for in the beginning.&lt;/p&gt;\n\n&lt;p&gt;I hope this makes sense. Please let me know if you have any ideas or opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11rr5s4", "is_robot_indexable": true, "report_reasons": null, "author": "trendy_parker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11rr5s4/framework_for_an_organizations_data_readiness/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11rr5s4/framework_for_an_organizations_data_readiness/", "subreddit_subscribers": 93215, "created_utc": 1678871860.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}