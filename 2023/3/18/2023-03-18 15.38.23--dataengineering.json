{"kind": "Listing", "data": {"after": "t3_11unx46", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nThere are a lot of ways to pass credentials to boto3 for aws.  I'm curious what's the most secure one to use? What do you guys use in production?\n\nThanks!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to pass credentials to boto3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tuflm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679067129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;There are a lot of ways to pass credentials to boto3 for aws.  I&amp;#39;m curious what&amp;#39;s the most secure one to use? What do you guys use in production?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11tuflm", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tuflm/best_way_to_pass_credentials_to_boto3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11tuflm/best_way_to_pass_credentials_to_boto3/", "subreddit_subscribers": 93451, "created_utc": 1679067129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggest I\u2019d love to know what books you felt made you become a better data / software engineer. Ones that helped you either advance your career or changed the way you thought about data / programming in general.", "author_fullname": "t2_8jkeh00n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books that made you become a better engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uiemx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679128038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggest I\u2019d love to know what books you felt made you become a better data / software engineer. Ones that helped you either advance your career or changed the way you thought about data / programming in general.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11uiemx", "is_robot_indexable": true, "report_reasons": null, "author": "GC_invests", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11uiemx/books_that_made_you_become_a_better_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11uiemx/books_that_made_you_become_a_better_engineer/", "subreddit_subscribers": 93451, "created_utc": 1679128038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In hive it is preferred that\n\n    SELECT * FROM smaller_table  s  JOIN bigger_table b ON  s.id = b.id  \n\nas it is much faster. Is this the same for SparkSQL?", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does order of table matter in Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11udgmw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679111034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In hive it is preferred that&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT * FROM smaller_table  s  JOIN bigger_table b ON  s.id = b.id  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;as it is much faster. Is this the same for SparkSQL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11udgmw", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11udgmw/does_order_of_table_matter_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11udgmw/does_order_of_table_matter_in_spark/", "subreddit_subscribers": 93451, "created_utc": 1679111034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many data warehouse architectures are there, and is there one that stands out with a good balance between auditability, performance, ease of use, with a preference for designs that can be built over time in an agile team?\n\nBy architecture, I should clarify I\u2019m not referring to medallion architecture or similar, but rather the design of tables and their relationships.\n\nExamples:\n- Inmon DWH\n- Kimball Star Schema\n- Linstead Data Vault (and Data Vault 2.0)\n- Ensemble Modelling\n- Anchor Modelling \n- OBT\n\nWhat others are there out there, and how do they rate?\n\nWe have our own approach, but it\u2019s showing issues, so want to survey the landscape and workout what direction we should head.\n\nEdit: so others don\u2019t go down the same path as us, this is our process:\n\n1. We land data into raw databases in Snowflake, then immediately snapshot them with dbt. This gives us static history. \n2. We bring through to our base schema a 1:1 table relationship to the raw table, with PII redacted and field names changed to \u2018business naming convention\u2019. \n3. We then build \u2018object\u2019 tables. These are source agnostic, include joins between sources, business rules etc. and importantly handle the time element, aligning multiple snapshots based on their valid to/valid from to get the full history of the \u2018object\u2019, be that a customer table, an application table, a team member table. This gives us a business view that ai would describe as an independent of source \u2018transactional table\u2019 with full type 2 history. If two systems that have been blended into one table have the same field, we coalesce the data with preference to what we believe should be the source system that is the primary source for that data.\n4. We build fact and dimension tables on top of our objects.\n\nThe problems are:\n- we probably shouldn\u2019t have changed field names to business names so eagerly, but rather left it until later in the process.\n- the object tables take time to calculate and build. We do a full rebuild each night because the different systems data updates at differing frequencies, and it\u2019s easier to truncate and reload than to do incremental.\n- the data is tightly coupled, so a failure in one upstream dataset can lead to a catastrophic failure of the whole load. Example: lead table in source fails to refresh, and it\u2019s joined to our customer object, which then gets skipped by dbt, which is used in our dim_customer, which is skipped, which basically links to every fact table, which then also get skipped. Not ideal!", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uhfv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679127226.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679124393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many data warehouse architectures are there, and is there one that stands out with a good balance between auditability, performance, ease of use, with a preference for designs that can be built over time in an agile team?&lt;/p&gt;\n\n&lt;p&gt;By architecture, I should clarify I\u2019m not referring to medallion architecture or similar, but rather the design of tables and their relationships.&lt;/p&gt;\n\n&lt;p&gt;Examples:\n- Inmon DWH\n- Kimball Star Schema\n- Linstead Data Vault (and Data Vault 2.0)\n- Ensemble Modelling\n- Anchor Modelling \n- OBT&lt;/p&gt;\n\n&lt;p&gt;What others are there out there, and how do they rate?&lt;/p&gt;\n\n&lt;p&gt;We have our own approach, but it\u2019s showing issues, so want to survey the landscape and workout what direction we should head.&lt;/p&gt;\n\n&lt;p&gt;Edit: so others don\u2019t go down the same path as us, this is our process:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We land data into raw databases in Snowflake, then immediately snapshot them with dbt. This gives us static history. &lt;/li&gt;\n&lt;li&gt;We bring through to our base schema a 1:1 table relationship to the raw table, with PII redacted and field names changed to \u2018business naming convention\u2019. &lt;/li&gt;\n&lt;li&gt;We then build \u2018object\u2019 tables. These are source agnostic, include joins between sources, business rules etc. and importantly handle the time element, aligning multiple snapshots based on their valid to/valid from to get the full history of the \u2018object\u2019, be that a customer table, an application table, a team member table. This gives us a business view that ai would describe as an independent of source \u2018transactional table\u2019 with full type 2 history. If two systems that have been blended into one table have the same field, we coalesce the data with preference to what we believe should be the source system that is the primary source for that data.&lt;/li&gt;\n&lt;li&gt;We build fact and dimension tables on top of our objects.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problems are:\n- we probably shouldn\u2019t have changed field names to business names so eagerly, but rather left it until later in the process.\n- the object tables take time to calculate and build. We do a full rebuild each night because the different systems data updates at differing frequencies, and it\u2019s easier to truncate and reload than to do incremental.\n- the data is tightly coupled, so a failure in one upstream dataset can lead to a catastrophic failure of the whole load. Example: lead table in source fails to refresh, and it\u2019s joined to our customer object, which then gets skipped by dbt, which is used in our dim_customer, which is skipped, which basically links to every fact table, which then also get skipped. Not ideal!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11uhfv8", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11uhfv8/data_warehouse_architectures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11uhfv8/data_warehouse_architectures/", "subreddit_subscribers": 93451, "created_utc": 1679124393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently, I am working as a DE in Canada, utilizing ADF, snowflake, python and Databricks.\n\nI have heard that many DEs in Canada work remotely for US companies, and I am keen to join their ranks. \nHowever, I am having a hard time finding a way to get there since I don\u2019t have the proper visa.\n\nWhile I understand that the job market may be a slow now, I\u2019m eager to prepare myself for future opportunities .\n\nHence, I would be grateful if you could share your journey to be able to work remotely in the US as a  DE from a different country.\n\nThank you!", "author_fullname": "t2_9fzxlzm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am very interested in learning about your experiences.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11u0l82", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679080193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I am working as a DE in Canada, utilizing ADF, snowflake, python and Databricks.&lt;/p&gt;\n\n&lt;p&gt;I have heard that many DEs in Canada work remotely for US companies, and I am keen to join their ranks. \nHowever, I am having a hard time finding a way to get there since I don\u2019t have the proper visa.&lt;/p&gt;\n\n&lt;p&gt;While I understand that the job market may be a slow now, I\u2019m eager to prepare myself for future opportunities .&lt;/p&gt;\n\n&lt;p&gt;Hence, I would be grateful if you could share your journey to be able to work remotely in the US as a  DE from a different country.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11u0l82", "is_robot_indexable": true, "report_reasons": null, "author": "kitkatsareyummy15", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11u0l82/i_am_very_interested_in_learning_about_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11u0l82/i_am_very_interested_in_learning_about_your/", "subreddit_subscribers": 93451, "created_utc": 1679080193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interviewing at a company that still uses SSIS and OLAP cubes. Everything is still done in SQL, no python nowhere. Opinion?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSIS &amp; OLAP Cubes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uijzg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679128623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interviewing at a company that still uses SSIS and OLAP cubes. Everything is still done in SQL, no python nowhere. Opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11uijzg", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11uijzg/ssis_olap_cubes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11uijzg/ssis_olap_cubes/", "subreddit_subscribers": 93451, "created_utc": 1679128623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone running Starburst over their data lake (Delta lake file format generally) as the general query engine? If yes, just wanted a general idea of whether it's a good idea to do so? Is the performance is upto par? Is the cost is manageable?", "author_fullname": "t2_7fd7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake + Starburst patterns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uezcw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679115819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone running Starburst over their data lake (Delta lake file format generally) as the general query engine? If yes, just wanted a general idea of whether it&amp;#39;s a good idea to do so? Is the performance is upto par? Is the cost is manageable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11uezcw", "is_robot_indexable": true, "report_reasons": null, "author": "counterstruck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11uezcw/delta_lake_starburst_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11uezcw/delta_lake_starburst_patterns/", "subreddit_subscribers": 93451, "created_utc": 1679115819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On average, what type of work consumes most of your time in your job as an engineer? Feel free to note if you feel you spend too much/too little on any given category.\n\n[View Poll](https://www.reddit.com/poll/11ubqwc)", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you spend the majority of your time doing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ubqwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679105970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On average, what type of work consumes most of your time in your job as an engineer? Feel free to note if you feel you spend too much/too little on any given category.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11ubqwc\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ubqwc", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679710770176, "options": [{"text": "ETL Development", "id": "22117207"}, {"text": "Infrastructure as Code Development", "id": "22117208"}, {"text": "Testing/bug fixes", "id": "22117209"}, {"text": "Designing/implementing Data Models or Database/Warehouse/Lake/Mart/Vault/etc", "id": "22117210"}, {"text": "Requirements Gathering/Stakeholder meetings", "id": "22117211"}, {"text": "Other (Add in Comments)", "id": "22117212"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 525, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ubqwc/what_do_you_spend_the_majority_of_your_time_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11ubqwc/what_do_you_spend_the_majority_of_your_time_doing/", "subreddit_subscribers": 93451, "created_utc": 1679105970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that this might be better suited in some other subreddits, but since data engineers usually are close to the infrastructure, I was curious if anyone is running Nomad or has moved to it?", "author_fullname": "t2_73sd7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Nomad over Kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11u54m2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679090142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that this might be better suited in some other subreddits, but since data engineers usually are close to the infrastructure, I was curious if anyone is running Nomad or has moved to it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11u54m2", "is_robot_indexable": true, "report_reasons": null, "author": "intellidumb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11u54m2/anyone_using_nomad_over_kubernetes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11u54m2/anyone_using_nomad_over_kubernetes/", "subreddit_subscribers": 93451, "created_utc": 1679090142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Since learning Python I've been using environment variables locally to store credentials and sensitive information such as API Keys and credentials for databases.\n\nHow is this information stored in a live production server and kept safe? Are they stored in something like Azure Keyvault / AWS KMS? If so how are the credentials accessed?", "author_fullname": "t2_12iasj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are credentials and secrets stored and used in Production with Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11upvix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679149528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since learning Python I&amp;#39;ve been using environment variables locally to store credentials and sensitive information such as API Keys and credentials for databases.&lt;/p&gt;\n\n&lt;p&gt;How is this information stored in a live production server and kept safe? Are they stored in something like Azure Keyvault / AWS KMS? If so how are the credentials accessed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11upvix", "is_robot_indexable": true, "report_reasons": null, "author": "KingofBoo", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11upvix/how_are_credentials_and_secrets_stored_and_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11upvix/how_are_credentials_and_secrets_stored_and_used/", "subreddit_subscribers": 93451, "created_utc": 1679149528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently I joined a company and among all the services we are using AWS Redshift. All the permissions, table creations etc. are done manually and then copyed to github repo dedicated for keeping the changes.\n\nMy question is how do you track all the changes and all the states, are there any apps/services for such use cases or you as well have GH repo and some CI/CD on top of that?\n\nHow do you keep consistent state between staging and production database? How do you prevent users manually adding objects and permissions?\n\nAny guidance will be much appreciated!", "author_fullname": "t2_yu7cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you keep track of your database schemas, tables, users and permissions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11up8pt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679147970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently I joined a company and among all the services we are using AWS Redshift. All the permissions, table creations etc. are done manually and then copyed to github repo dedicated for keeping the changes.&lt;/p&gt;\n\n&lt;p&gt;My question is how do you track all the changes and all the states, are there any apps/services for such use cases or you as well have GH repo and some CI/CD on top of that?&lt;/p&gt;\n\n&lt;p&gt;How do you keep consistent state between staging and production database? How do you prevent users manually adding objects and permissions?&lt;/p&gt;\n\n&lt;p&gt;Any guidance will be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11up8pt", "is_robot_indexable": true, "report_reasons": null, "author": "UserPobro", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11up8pt/how_do_you_keep_track_of_your_database_schemas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11up8pt/how_do_you_keep_track_of_your_database_schemas/", "subreddit_subscribers": 93451, "created_utc": 1679147970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of us work on company laptops, but I'm sure most of us also have personal machines.  I am in the market for a new machine and wondering: what machine do you use for personal use?  Do you like it?  Why?  Would you recommend I buy one too?", "author_fullname": "t2_h2e0l0gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal machines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uml60", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679140951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of us work on company laptops, but I&amp;#39;m sure most of us also have personal machines.  I am in the market for a new machine and wondering: what machine do you use for personal use?  Do you like it?  Why?  Would you recommend I buy one too?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11uml60", "is_robot_indexable": true, "report_reasons": null, "author": "curiosickly", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11uml60/personal_machines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11uml60/personal_machines/", "subreddit_subscribers": 93451, "created_utc": 1679140951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an IoT device that feeds data into a MySQL table. The most relevant columns in this table are:\n\n- The `value` column, which is a float column that just stores the quantitative measurement of interest.\n- The `datetime_created` column, which is a datetime field that stores the datetime this record was generated.\n\nWe have an application that queries this table, passing in the following 2 parameters, `date_start` and `date_end`.\n\nBoth of these parameters are dates. We then filter our table, and run aggregations on the filtered dataset including:\n\n1. Aggregating by hour, \n2. Running some statistical computation to calculate min/max/median within each hour, \n3. And after the above, we return the data to our frontend layer.\n\nLately, as this table has grown, we've found that queries take upwards of 30-40 seconds when the date range selected is huge.\n\nAre there ways we could be optimizing this at either the database layer or the application layer? Is our chosen method of storing this in a MySQL db just not optimized for our case?", "author_fullname": "t2_k01zajj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving query times from a MySQL table with a datetime column that stores a time stream of occurrences about 2-3 minutes apart.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ue8ci", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679113429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an IoT device that feeds data into a MySQL table. The most relevant columns in this table are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The &lt;code&gt;value&lt;/code&gt; column, which is a float column that just stores the quantitative measurement of interest.&lt;/li&gt;\n&lt;li&gt;The &lt;code&gt;datetime_created&lt;/code&gt; column, which is a datetime field that stores the datetime this record was generated.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We have an application that queries this table, passing in the following 2 parameters, &lt;code&gt;date_start&lt;/code&gt; and &lt;code&gt;date_end&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Both of these parameters are dates. We then filter our table, and run aggregations on the filtered dataset including:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Aggregating by hour, &lt;/li&gt;\n&lt;li&gt;Running some statistical computation to calculate min/max/median within each hour, &lt;/li&gt;\n&lt;li&gt;And after the above, we return the data to our frontend layer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Lately, as this table has grown, we&amp;#39;ve found that queries take upwards of 30-40 seconds when the date range selected is huge.&lt;/p&gt;\n\n&lt;p&gt;Are there ways we could be optimizing this at either the database layer or the application layer? Is our chosen method of storing this in a MySQL db just not optimized for our case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ue8ci", "is_robot_indexable": true, "report_reasons": null, "author": "Lostwhispers05", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ue8ci/improving_query_times_from_a_mysql_table_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ue8ci/improving_query_times_from_a_mysql_table_with_a/", "subreddit_subscribers": 93451, "created_utc": 1679113429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m using Matillion ETL and snowflake. I have various data sources ljke DBs and APIs and files owned by other teams within the business.\n\nI have a raw data layer in snowflake where all the source data lands from matillion, then layers on top of that (cleansed, modelled, presentation layer).\n\nCurrent strategy is to merge/upsert incoming data into the raw layer so it only holds the latest version of each record when source data gets updated.\n\nIs that a typical pattern? Would it be better to store each version of every record in raw, then filter them out downstream to only select the latest record? And how and when do you apply that filter?", "author_fullname": "t2_4y2g3lh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "History in the Raw Data Layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tws9j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679072220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m using Matillion ETL and snowflake. I have various data sources ljke DBs and APIs and files owned by other teams within the business.&lt;/p&gt;\n\n&lt;p&gt;I have a raw data layer in snowflake where all the source data lands from matillion, then layers on top of that (cleansed, modelled, presentation layer).&lt;/p&gt;\n\n&lt;p&gt;Current strategy is to merge/upsert incoming data into the raw layer so it only holds the latest version of each record when source data gets updated.&lt;/p&gt;\n\n&lt;p&gt;Is that a typical pattern? Would it be better to store each version of every record in raw, then filter them out downstream to only select the latest record? And how and when do you apply that filter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11tws9j", "is_robot_indexable": true, "report_reasons": null, "author": "Right-Requirement895", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tws9j/history_in_the_raw_data_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11tws9j/history_in_the_raw_data_layer/", "subreddit_subscribers": 93451, "created_utc": 1679072220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am reading messages from Kafka and processing it in pyspark.\n\n In some of the messages, there are some keys corresponding to which there are 0's and 1's. \n\nNow I want to convert these 0's and 1's to False and True. The challenge here I should only convert those columns for whose the datatype in the schema in boolean. There is no way of knowing which columns may have the datatype as BooleanType since this is streaming job and new columns are added everyday.\n\nThe main challenge here is, I need to do the conversion even before parsing the Kafka Message because as soon as I parse those messages using a schema, then column values become NULL (bcoz the columns have 0's and 1's and when parsed using BooleanType, they become NULL)\n\nCan anyone help me or point me in the right direction?", "author_fullname": "t2_188qz428", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convert some specific columns that have 0 and 1 values in Kafka messages to False and True in PySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tvzd9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679070506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am reading messages from Kafka and processing it in pyspark.&lt;/p&gt;\n\n&lt;p&gt;In some of the messages, there are some keys corresponding to which there are 0&amp;#39;s and 1&amp;#39;s. &lt;/p&gt;\n\n&lt;p&gt;Now I want to convert these 0&amp;#39;s and 1&amp;#39;s to False and True. The challenge here I should only convert those columns for whose the datatype in the schema in boolean. There is no way of knowing which columns may have the datatype as BooleanType since this is streaming job and new columns are added everyday.&lt;/p&gt;\n\n&lt;p&gt;The main challenge here is, I need to do the conversion even before parsing the Kafka Message because as soon as I parse those messages using a schema, then column values become NULL (bcoz the columns have 0&amp;#39;s and 1&amp;#39;s and when parsed using BooleanType, they become NULL)&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me or point me in the right direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11tvzd9", "is_robot_indexable": true, "report_reasons": null, "author": "swarup_i_am", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tvzd9/convert_some_specific_columns_that_have_0_and_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11tvzd9/convert_some_specific_columns_that_have_0_and_1/", "subreddit_subscribers": 93451, "created_utc": 1679070506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rx4wrtdi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "6 Effective Tips to Hire Data Engineers Remotely: Best Practices for Data Engineer Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "name": "t3_11ttur3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M8YcMpTR9W5derfEZRy8cozpAg3f7L-jtUvckudcy1A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679065859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "borderlessmind.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.borderlessmind.com/blog/6-effective-tips-hire-data-engineers-remotely-best-practices-data-engineer-interviews/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?auto=webp&amp;v=enabled&amp;s=e9c11445bf920365a113c07a7b54a4b61a939578", "width": 1200, "height": 763}, "resolutions": [{"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f30bae4bd9fbedbca0ea052606d035953b9439f", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13f976c64d9d547309a154e83b1d436cdcfb564e", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ce10e60a910542e594f58788d9e51245ba5784d", "width": 320, "height": 203}, {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49374afb293b8d303f1e9fcc3c7dae8482eff380", "width": 640, "height": 406}, {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8359c4e75539d929fe4a84ab029f5760e414830d", "width": 960, "height": 610}, {"url": "https://external-preview.redd.it/ZZeRFpQyjSqO1tzjkCQ9AVFWVuvdJqDoWh5bcO1lbn4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae0113b3ed683420a8485c1dee38b267fb825cf5", "width": 1080, "height": 686}], "variants": {}, "id": "1q-X_hWaphUhvnt06YINXEhG2ASNieB0KxNR6hHCl6c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11ttur3", "is_robot_indexable": true, "report_reasons": null, "author": "AccomplishedRice2031", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ttur3/6_effective_tips_to_hire_data_engineers_remotely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.borderlessmind.com/blog/6-effective-tips-hire-data-engineers-remotely-best-practices-data-engineer-interviews/", "subreddit_subscribers": 93451, "created_utc": 1679065859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked at several small, several medium, and a few large companies. It may just be my experience, but none of them had really figured out how to efficiently and effectively manage operational change. \n\nIn various roles, I've tried implementing things like shared documentation, regular meetings to discuss operational changes with leadership responsible for upstream tools, and monitoring. Of the things I've tried, automated monitoring has been the most helpful because it puts our expectations in code. Meetings have been the least helpful because there is no real way to meet frequently enough to not delay upstream teams from doing their jobs, which isn't really realistic either. \n\nThe main problem I have with monitoring source data for assumptions is that is still pretty reactive. It's too frequent that we wind up with stuff broken -- sometimes due to assumptions that weren't fully documented on our end. One concern is that having too much monitoring in place makes every tiny change super noisy and useless as well. \n\nWhat have you seen actually work to solve this problem?", "author_fullname": "t2_2rgmgp57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your successful best-practices for *proactively* managing upstream operational change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11upq7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679149152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked at several small, several medium, and a few large companies. It may just be my experience, but none of them had really figured out how to efficiently and effectively manage operational change. &lt;/p&gt;\n\n&lt;p&gt;In various roles, I&amp;#39;ve tried implementing things like shared documentation, regular meetings to discuss operational changes with leadership responsible for upstream tools, and monitoring. Of the things I&amp;#39;ve tried, automated monitoring has been the most helpful because it puts our expectations in code. Meetings have been the least helpful because there is no real way to meet frequently enough to not delay upstream teams from doing their jobs, which isn&amp;#39;t really realistic either. &lt;/p&gt;\n\n&lt;p&gt;The main problem I have with monitoring source data for assumptions is that is still pretty reactive. It&amp;#39;s too frequent that we wind up with stuff broken -- sometimes due to assumptions that weren&amp;#39;t fully documented on our end. One concern is that having too much monitoring in place makes every tiny change super noisy and useless as well. &lt;/p&gt;\n\n&lt;p&gt;What have you seen actually work to solve this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11upq7j", "is_robot_indexable": true, "report_reasons": null, "author": "ADataDude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11upq7j/what_are_your_successful_bestpractices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11upq7j/what_are_your_successful_bestpractices_for/", "subreddit_subscribers": 93451, "created_utc": 1679149152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenLineage with Streaming Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_11up708", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Toe7bhqGXhkK5mjs_LuQVxmbRsw1nnkfuCMK6fsheJE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679147848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/openlineage-with-streaming-data?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4FI9DNx78lzYBxfhMnIQFFSQEZqBnHKyQj6LY26xiP0.jpg?auto=webp&amp;v=enabled&amp;s=b2ba68fbf5364c0865579a7072a1722b34d4bc32", "width": 720, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/4FI9DNx78lzYBxfhMnIQFFSQEZqBnHKyQj6LY26xiP0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d28056f4ef982132f18f377876aaa93b36ab2dd4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4FI9DNx78lzYBxfhMnIQFFSQEZqBnHKyQj6LY26xiP0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d8f5071b78098d126bc3181884331833d5511f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4FI9DNx78lzYBxfhMnIQFFSQEZqBnHKyQj6LY26xiP0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70ec0dddf614297bb474bc5582292a0d4e2e5a88", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4FI9DNx78lzYBxfhMnIQFFSQEZqBnHKyQj6LY26xiP0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0dd7fad23fa81afd026d720aa9bfe4d49d1a9eb4", "width": 640, "height": 320}], "variants": {}, "id": "dIfh2wdpXlvdMIrCXBCLN83pnf-QDltpj50lNd3nvMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11up708", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11up708/openlineage_with_streaming_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/openlineage-with-streaming-data?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 93451, "created_utc": 1679147848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've done very well on the MeasureUp practice exams (though they're generally known to be more difficult than the actual exam) but when I took the MS Practice Assessment some questions appeared there on topics that weren't covered in MeasureUp. Has anyone else noticed that? I'm wondering now if I should postpone my exam scheduled for Monday as now I feel I didn't prepare enough.", "author_fullname": "t2_oq215ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP-203 Exam: MS Practice Assessment vs MeasureUp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11umcdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679140259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve done very well on the MeasureUp practice exams (though they&amp;#39;re generally known to be more difficult than the actual exam) but when I took the MS Practice Assessment some questions appeared there on topics that weren&amp;#39;t covered in MeasureUp. Has anyone else noticed that? I&amp;#39;m wondering now if I should postpone my exam scheduled for Monday as now I feel I didn&amp;#39;t prepare enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11umcdj", "is_robot_indexable": true, "report_reasons": null, "author": "truffelmayo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11umcdj/dp203_exam_ms_practice_assessment_vs_measureup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11umcdj/dp203_exam_ms_practice_assessment_vs_measureup/", "subreddit_subscribers": 93451, "created_utc": 1679140259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a small size start up and this has been my by far biggest challenge that still remains unsolved:\n\nWe have a legacy Java application still running that uses Cassandra hosted on EC2. The tables are mostly hundreds of millions of rows. \n\nAlmost none of the tables contain a modified_at or created_at column and they aren\u2019t partitioned/clustered in a manner where they can be read out incrementally.\n\nI need these tables synced to Snowflake daily preferably hourly. Currently having a Python Fargate task running really weird queries to read the rows out incrementally without having to use ALLOW FILTERING in the Cassandra queries, but many rows seem to not make it into Snowflake. I think this is because large query results returned from Cassandra are unstable.\n\nOnly one person is left at the company that knows Java so editing the legacy application is not an option. I see Matillion has a Cassandra Conector I\u2019m going to try, but I\u2019m guessing it will run into the same issues as my custom Python service I made to do this. \n\nAny suggestions?", "author_fullname": "t2_56wplwbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cassandra to Snowflake Headache", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11udak6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679110518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a small size start up and this has been my by far biggest challenge that still remains unsolved:&lt;/p&gt;\n\n&lt;p&gt;We have a legacy Java application still running that uses Cassandra hosted on EC2. The tables are mostly hundreds of millions of rows. &lt;/p&gt;\n\n&lt;p&gt;Almost none of the tables contain a modified_at or created_at column and they aren\u2019t partitioned/clustered in a manner where they can be read out incrementally.&lt;/p&gt;\n\n&lt;p&gt;I need these tables synced to Snowflake daily preferably hourly. Currently having a Python Fargate task running really weird queries to read the rows out incrementally without having to use ALLOW FILTERING in the Cassandra queries, but many rows seem to not make it into Snowflake. I think this is because large query results returned from Cassandra are unstable.&lt;/p&gt;\n\n&lt;p&gt;Only one person is left at the company that knows Java so editing the legacy application is not an option. I see Matillion has a Cassandra Conector I\u2019m going to try, but I\u2019m guessing it will run into the same issues as my custom Python service I made to do this. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11udak6", "is_robot_indexable": true, "report_reasons": null, "author": "dmage5000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11udak6/cassandra_to_snowflake_headache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11udak6/cassandra_to_snowflake_headache/", "subreddit_subscribers": 93451, "created_utc": 1679110518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's talk metadata management. Some folks say it's the unsung hero of data engineering, while others think it's a waste of time. So, what's the deal?\n\n1. **Finding data:** Metadata makes it a breeze to find the right stuff.\n2. **Teamwork:** Helps peeps from different teams understand each other's data.\n3. **Tracking data's journey:** Know where your data's been and what's happened to it.\n4. **Keeping data on point:** Makes sure your data's reliable and accurate.\n5. **Ready for the future:** Helps you stay flexible and adapt to new tech.\n\nBut hey, there's another side to the story. Some say metadata management just adds headaches, takes time, and makes us rely on specific tools. They think we should focus on building a solid data architecture instead.\n\nSo, let's get real: is metadata management a game changer or just another hype train we should skip? Drop your thoughts and experiences below, and let's hash it out", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metadata Management: Key to Data Engineering Success or Overhyped Trend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11u5fhx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679090799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s talk metadata management. Some folks say it&amp;#39;s the unsung hero of data engineering, while others think it&amp;#39;s a waste of time. So, what&amp;#39;s the deal?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Finding data:&lt;/strong&gt; Metadata makes it a breeze to find the right stuff.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Teamwork:&lt;/strong&gt; Helps peeps from different teams understand each other&amp;#39;s data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Tracking data&amp;#39;s journey:&lt;/strong&gt; Know where your data&amp;#39;s been and what&amp;#39;s happened to it.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Keeping data on point:&lt;/strong&gt; Makes sure your data&amp;#39;s reliable and accurate.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ready for the future:&lt;/strong&gt; Helps you stay flexible and adapt to new tech.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;But hey, there&amp;#39;s another side to the story. Some say metadata management just adds headaches, takes time, and makes us rely on specific tools. They think we should focus on building a solid data architecture instead.&lt;/p&gt;\n\n&lt;p&gt;So, let&amp;#39;s get real: is metadata management a game changer or just another hype train we should skip? Drop your thoughts and experiences below, and let&amp;#39;s hash it out&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11u5fhx", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11u5fhx/metadata_management_key_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11u5fhx/metadata_management_key_to_data_engineering/", "subreddit_subscribers": 93451, "created_utc": 1679090799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't know Shell/Bash can i replace it only with powershell?", "author_fullname": "t2_voqzneej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Knowing only powershell is enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tz3ik", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679077063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know Shell/Bash can i replace it only with powershell?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11tz3ik", "is_robot_indexable": true, "report_reasons": null, "author": "Aesop7K", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tz3ik/knowing_only_powershell_is_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11tz3ik/knowing_only_powershell_is_enough/", "subreddit_subscribers": 93451, "created_utc": 1679077063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can a data engineer become quant engineer?", "author_fullname": "t2_7yh1jlaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer to quant engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tupt6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679067771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can a data engineer become quant engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11tupt6", "is_robot_indexable": true, "report_reasons": null, "author": "Foot_Straight", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tupt6/data_engineer_to_quant_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11tupt6/data_engineer_to_quant_engineer/", "subreddit_subscribers": 93451, "created_utc": 1679067771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DSA For The Rest Of Us - Into to Linked Lists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_11tttqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rKlkVJkBs0cBD-Q7iMYOQ73dQ7s2D3AcpqWxhp854Xs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679065801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/dsa-for-the-rest-of-us-part-1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7yugdQ_-MklYqSk8s_SoQKrHaIl7C_wkVlNJQ36r2Vg.jpg?auto=webp&amp;v=enabled&amp;s=e37daeab152f8b973578fcfb39a74cbb21592eff", "width": 900, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7yugdQ_-MklYqSk8s_SoQKrHaIl7C_wkVlNJQ36r2Vg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35c8e44e454dd93a169ddbcb302921eb3c80f73f", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/7yugdQ_-MklYqSk8s_SoQKrHaIl7C_wkVlNJQ36r2Vg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b6c40e34bb1c5a915927fa4b2c395cb43705721", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/7yugdQ_-MklYqSk8s_SoQKrHaIl7C_wkVlNJQ36r2Vg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bee06a0484b34f5b0d87ff60c4ae1b076e0d93c", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7yugdQ_-MklYqSk8s_SoQKrHaIl7C_wkVlNJQ36r2Vg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf688c6b7a02561694a2eb32ecc739614cda10b2", "width": 640, "height": 426}], "variants": {}, "id": "cKBOkB2CV-NZpjD3ua5g11XaHAPE1Zvk14BH-IOqxZI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11tttqg", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11tttqg/dsa_for_the_rest_of_us_into_to_linked_lists/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/dsa-for-the-rest-of-us-part-1", "subreddit_subscribers": 93451, "created_utc": 1679065801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys, need feedback on my situation.\n\nI'm trying for a switch and I'm  not getting interview calls from big tech companies.\n\nI'm currently working as a data engineer with 1.9 years of experience where my role mostly revolves around -\n\n1.writing snowflake procedure for transformation \n2.Adding few lines in a spring boot application that's used for snowflake ingestion.\n3. Python scripts to monitor some stats from snowflake.\n4. Building automation using python.\n\n\n I like working on development projects rather than writing sql queries.\n\nSo, I get calls from serviced bassed companies and most of them don't setup interview as they think they can't match the expected salary. \n\nSo should I start learning spark since I don't see data engineers with snowflake as primary skill getting hired in faang or big tech companies.\n\nDisclaimer: I'm trying to switch because my current role looks like a support kind of work and I want to work development projects.", "author_fullname": "t2_h194hggr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I switch my role from snowflake developer to spark developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11unx46", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679147173.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679144518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, need feedback on my situation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying for a switch and I&amp;#39;m  not getting interview calls from big tech companies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a data engineer with 1.9 years of experience where my role mostly revolves around -&lt;/p&gt;\n\n&lt;p&gt;1.writing snowflake procedure for transformation \n2.Adding few lines in a spring boot application that&amp;#39;s used for snowflake ingestion.\n3. Python scripts to monitor some stats from snowflake.\n4. Building automation using python.&lt;/p&gt;\n\n&lt;p&gt;I like working on development projects rather than writing sql queries.&lt;/p&gt;\n\n&lt;p&gt;So, I get calls from serviced bassed companies and most of them don&amp;#39;t setup interview as they think they can&amp;#39;t match the expected salary. &lt;/p&gt;\n\n&lt;p&gt;So should I start learning spark since I don&amp;#39;t see data engineers with snowflake as primary skill getting hired in faang or big tech companies.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I&amp;#39;m trying to switch because my current role looks like a support kind of work and I want to work development projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11unx46", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological_Pen933", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11unx46/should_i_switch_my_role_from_snowflake_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11unx46/should_i_switch_my_role_from_snowflake_developer/", "subreddit_subscribers": 93451, "created_utc": 1679144518.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}