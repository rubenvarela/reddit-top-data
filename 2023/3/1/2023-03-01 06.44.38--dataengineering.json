{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w2y7e99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Brace yourselves... \"professional\" Data Mesh developer job ads incoming!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11eezyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 97, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 97, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7Fg-OCdcmezq19GoguvtGJK4781V_M-QvPVyOOof7-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677606641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u0xw0g77wyka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?auto=webp&amp;v=enabled&amp;s=99eb928deaafeb0b6d3e137e8dc78d94286e08ed", "width": 1300, "height": 1583}, "resolutions": [{"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64c0f173fca9655222e716d0e23c56aa440e8a97", "width": 108, "height": 131}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec87f23838b5919a0744c3062abfa641a13b1f7", "width": 216, "height": 263}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c566574e632b461ca970f1e9fee8c7fa8cf7b314", "width": 320, "height": 389}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff9e57499592a22b228e11acce182fbde04bb1c0", "width": 640, "height": 779}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b2aa657a7b5a3b068cc69499f312ae26e285c94", "width": 960, "height": 1168}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=694a1ba988e661acc0d902399b7decce6e4fb234", "width": 1080, "height": 1315}], "variants": {}, "id": "qwTGK3kHziyl0N7qLQfANNJvHWA3yaYv--CIWLyF-_g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11eezyq", "is_robot_indexable": true, "report_reasons": null, "author": "whichalps", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eezyq/brace_yourselves_professional_data_mesh_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u0xw0g77wyka1.jpg", "subreddit_subscribers": 91468, "created_utc": 1677606641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples](https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples)\n\nHi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it's for example to write data back into Snowflake or to visualize a map data. \n\nHope you enjoy and had as much fun reading as I had writing this.   \n\n\nhttps://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Streamlit and Data applications on Snowflake with Winter Sports examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sgnvh0116xka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aba633b89ce8a4ad4b6ad478e398b87b98701892"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7168ad79cf7bc0e89f737d02fd9a5da08b2685d0"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=250dd2fc5d66dbfa5d6541df378d5147b21972a0"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7318e143a74a678c35b71e4407a6c9cf62567db"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3b41d90f5e2d93b3cbc91ff19c3544c59d6fc2a"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b6f7e1c23ca1a7cb5902486f4bb8b88f334e3da"}], "s": {"y": 875, "x": 1920, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5"}, "id": "sgnvh0116xka1"}}, "name": "t3_11e4bv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WNUlYBzmq5_xjOvDF9FNroXOFVBeHFjCtdrFBVGl18g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677585694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples\"&gt;https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it&amp;#39;s for example to write data back into Snowflake or to visualize a map data. &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy and had as much fun reading as I had writing this.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5\"&gt;https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11e4bv4", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "subreddit_subscribers": 91468, "created_utc": 1677585694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone.  \n\n\nI make a lot of diagrams to help visualize data pipelines, software architecture, and more.\n\nMy way-to-go tool in the past year and a half is [Whimiscal](https://whimsical.com/). It is by far one of the best tools I've used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn't. The tool just helped me. Big win! :)   \n\n\nHowever, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   \n\n\nI am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.  \n1. [Draw.io](https://Draw.io) \\-  It's forever free, but it is not pretty. My diagrams won't be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else's and won't stand out in the crowd.\n\n2. [https://miro.com/](https://miro.com/) \\- Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn't really understand what it is. Maybe someone has used it and can throw some light.\n\n3. [https://www.taskade.com/](https://www.taskade.com/) \\- They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn't hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   \n\n\n4. Other alternatives?  \n\n\nThank you all. :)\n\n&amp;#x200B;\n\nSide note: Just to give an example, that's a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren't that far from it. Isn't it beautiful? \n\n \n\nhttps://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best free diagram tool alternative in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 99, "top_awarded_type": null, "hide_score": false, "media_metadata": {"21q1xw9gxyka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c1d4410700e9800eceb539e795806fdbc885705"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fec057f9e1bef58cab753de0a440fe4b093d11d"}, {"y": 227, "x": 320, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9277b0e953f020ec4be8ccd27df9b7125ea8c475"}, {"y": 455, "x": 640, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90eef4c9806596308eec1ef7e701721d80e996af"}, {"y": 683, "x": 960, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1be8e7f9ac22e597a2f3630321100972c82ac90a"}, {"y": 768, "x": 1080, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e725ee97909069fcef083679d7f78e4b397a693d"}], "s": {"y": 1154, "x": 1622, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41"}, "id": "21q1xw9gxyka1"}}, "name": "t3_11ef7lk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9qqFweX1KyxDHUvJqEgNJvexAHar6Vut1z4OlW5Kep4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677607178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone.  &lt;/p&gt;\n\n&lt;p&gt;I make a lot of diagrams to help visualize data pipelines, software architecture, and more.&lt;/p&gt;\n\n&lt;p&gt;My way-to-go tool in the past year and a half is &lt;a href=\"https://whimsical.com/\"&gt;Whimiscal&lt;/a&gt;. It is by far one of the best tools I&amp;#39;ve used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn&amp;#39;t. The tool just helped me. Big win! :)   &lt;/p&gt;\n\n&lt;p&gt;However, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   &lt;/p&gt;\n\n&lt;p&gt;I am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.&lt;br/&gt;\n1. &lt;a href=\"https://Draw.io\"&gt;Draw.io&lt;/a&gt; -  It&amp;#39;s forever free, but it is not pretty. My diagrams won&amp;#39;t be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else&amp;#39;s and won&amp;#39;t stand out in the crowd.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://miro.com/\"&gt;https://miro.com/&lt;/a&gt; - Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn&amp;#39;t really understand what it is. Maybe someone has used it and can throw some light.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://www.taskade.com/\"&gt;https://www.taskade.com/&lt;/a&gt; - They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn&amp;#39;t hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other alternatives?  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you all. :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Side note: Just to give an example, that&amp;#39;s a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren&amp;#39;t that far from it. Isn&amp;#39;t it beautiful? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41\"&gt;https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?auto=webp&amp;v=enabled&amp;s=a9f6dad99adbc9a7fb64ea6f090216c19a9215b8", "width": 1744, "height": 912}, "resolutions": [{"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5489caee9a35f72de0c4f2e0775f6eb01afb065", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8529c221c0d7aa4845c78526a5fc7357a5afa044", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ab9417914f9d18499d85c65b7753c564ce2fbaa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=917d95a02dd55147c6aff31f43b8bf8ed053ba78", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b218d1bb6fc94247a758630de5617148d71300d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70aba50d6cb83c288b36dc32148531496695af79", "width": 1080, "height": 564}], "variants": {}, "id": "k3XoPhRiwTJWBB72DdNhIHIqhF-cNikHtNW8qfA63mc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ef7lk", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "subreddit_subscribers": 91468, "created_utc": 1677607178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "## Or how to build a light weight data platform for a small organization from scratch? \n\nWe are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.\n\nHowever, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.\n\nWe do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.\n\n\n### Update\nI try to draw out a potential solution based on the discussion and knowledge we have.\n\n| Domain | Solution | Comment |\n|-|-|-|\n| Data Warehouse | Clickhouse | Lakehouse is overkill |\n| BI / Data App | SuperSet and Dash |  |\n| ETL | AirByte |  |", "author_fullname": "t2_m0cc1w3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to deploy a lakehouse solution on a bare metal server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ea84j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677632775.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677596960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Or how to build a light weight data platform for a small organization from scratch?&lt;/h2&gt;\n\n&lt;p&gt;We are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.&lt;/p&gt;\n\n&lt;p&gt;However, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.&lt;/p&gt;\n\n&lt;p&gt;We do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.&lt;/p&gt;\n\n&lt;h3&gt;Update&lt;/h3&gt;\n\n&lt;p&gt;I try to draw out a potential solution based on the discussion and knowledge we have.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Domain&lt;/th&gt;\n&lt;th&gt;Solution&lt;/th&gt;\n&lt;th&gt;Comment&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Data Warehouse&lt;/td&gt;\n&lt;td&gt;Clickhouse&lt;/td&gt;\n&lt;td&gt;Lakehouse is overkill&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;BI / Data App&lt;/td&gt;\n&lt;td&gt;SuperSet and Dash&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ETL&lt;/td&gt;\n&lt;td&gt;AirByte&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ea84j", "is_robot_indexable": true, "report_reasons": null, "author": "_link89_", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "subreddit_subscribers": 91468, "created_utc": 1677596960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.\n\n1. If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?\n2. Purpose of dbfs if they say not to put data in it?\n3. Do you just mount your external cloud storage anyways?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice with storage and databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ec67v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?&lt;/li&gt;\n&lt;li&gt;Purpose of dbfs if they say not to put data in it?&lt;/li&gt;\n&lt;li&gt;Do you just mount your external cloud storage anyways?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ec67v", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "subreddit_subscribers": 91468, "created_utc": 1677599940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?", "author_fullname": "t2_qjqclauw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I crazy, making a newbie mistake or do I need to adjust my expectation of the cost of running a simple ETL in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eh8sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677612031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eh8sf", "is_robot_indexable": true, "report_reasons": null, "author": "EconomistNeither2472", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "subreddit_subscribers": 91468, "created_utc": 1677612031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.", "author_fullname": "t2_55onda91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone taken the updated version of DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edx4t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677604040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11edx4t", "is_robot_indexable": true, "report_reasons": null, "author": "bingbongpeepee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "subreddit_subscribers": 91468, "created_utc": 1677604040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prod data in dev environments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eqzva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677635939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eqzva", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "subreddit_subscribers": 91468, "created_utc": 1677635939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Art and Science of Measuring Data Teams Value", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_11eijno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yAoHcL7bQ0GuSIgzY2nBbWEsxMFTSwlZu_No21jJVKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677615073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/measuring-data-teams-value", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?auto=webp&amp;v=enabled&amp;s=c7b775b6cb5f26e40ac1b947136898809d2bc2d2", "width": 1800, "height": 1174}, "resolutions": [{"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc55254d0cf507f50cd11eb8d253129dabb86d7b", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a175f0d0cb404bbfcaff33306343cf02fc06a3b2", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=054084df2f57e8e047ff55b9e9a776a2bb51ea46", "width": 320, "height": 208}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e0484976ac50b957ca3d7f03f01696d007ca4c", "width": 640, "height": 417}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=129f1d2e8bb0a3ae417679b5eee5db085516563e", "width": 960, "height": 626}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1d7020733b3dd9bbd778dc62c83b1abeba10c54", "width": 1080, "height": 704}], "variants": {}, "id": "OCdXOfuYus0uN13ED4cARCiy_YL8zxwm7gjdvP0vJ0g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eijno", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eijno/the_art_and_science_of_measuring_data_teams_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/measuring-data-teams-value", "subreddit_subscribers": 91468, "created_utc": 1677615073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don't know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edtlt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don&amp;#39;t know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11edtlt", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edtlt/interview_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edtlt/interview_test/", "subreddit_subscribers": 91468, "created_utc": 1677603806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can somebody explain these two terms in as simple words as possible. New to the field", "author_fullname": "t2_66513e19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is an enterprise data platform and enterprise data catalogue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eonaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677629679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody explain these two terms in as simple words as possible. New to the field&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eonaj", "is_robot_indexable": true, "report_reasons": null, "author": "nikiii_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "subreddit_subscribers": 91468, "created_utc": 1677629679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're moving away from Snowflake. We'd like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.\n\nI have several questions and I'd appreciate any help on any of them.\n\n1. Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, `{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/` for IoT device data, which is similar to our use case. Right?\n\n2. Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it's columnar/compression properties. Right?\n\n3. What options do we have for getting historical data currently in SF into this format and moving it over efficiently?\n\n4. Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? \n\n5. Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We've never used it. \n\n6. Should we use Synapse, do you \"load\" all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. \n\nAgain, thanks for any help.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on our migration to a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11emsf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677625075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re moving away from Snowflake. We&amp;#39;d like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.&lt;/p&gt;\n\n&lt;p&gt;I have several questions and I&amp;#39;d appreciate any help on any of them.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, &lt;code&gt;{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/&lt;/code&gt; for IoT device data, which is similar to our use case. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it&amp;#39;s columnar/compression properties. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What options do we have for getting historical data currently in SF into this format and moving it over efficiently?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We&amp;#39;ve never used it. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should we use Synapse, do you &amp;quot;load&amp;quot; all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Again, thanks for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11emsf6", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "subreddit_subscribers": 91468, "created_utc": 1677625075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?", "author_fullname": "t2_2vnue5gp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a realtime firebase data and want each collection as a separate table in BigQuery for analysis, what is the best way to do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eiclj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677614622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eiclj", "is_robot_indexable": true, "report_reasons": null, "author": "blackfrwhite", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "subreddit_subscribers": 91468, "created_utc": 1677614622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference [https://www.datacouncil.ai/austin](https://www.datacouncil.ai/austin). I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.", "author_fullname": "t2_1u2bikk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edhmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference &lt;a href=\"https://www.datacouncil.ai/austin\"&gt;https://www.datacouncil.ai/austin&lt;/a&gt;. I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?auto=webp&amp;v=enabled&amp;s=54e72a190e3a4e0e3e7412697d111a1d4164245f", "width": 1434, "height": 1434}, "resolutions": [{"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712b54f3ba3432e501cc4ba9fba72776b722543a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eeb54f2d3f0388636f0b6c30d23acaaf892ab9d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4724ad2f2c8c22bcf6f3d29edf73f5975a527d96", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e46045182cf4ea2bd1725215182a69ceafaf3ba7", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=652c5d744d177eabea48e38193f0a9985d19e198", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18c77681ac295cf1d6523ab0a3856cb09db838ca", "width": 1080, "height": 1080}], "variants": {}, "id": "Fc1fxjSKNc0AhT9MqwkoW1xP4i7uEi4B67sxKyjzJl8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11edhmg", "is_robot_indexable": true, "report_reasons": null, "author": "ks4701", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edhmg/data_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edhmg/data_conference/", "subreddit_subscribers": 91468, "created_utc": 1677603024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I would very appreciate your help here, an important question about architecture modification.  \nWe use the ETL process to fetch data from external services (for example, Github).\n\n1. Extract the data (e.g. issues and PRs) and create raw\\_data objects\n2. Transform the data to our unique objects - let's call them assets.\n3. Load the assets as JSONs (jsonb field) to postgres DB (general assets table).\n\nWe have a few problems with this approach and now we are considering to change our pipeline.\n\n* **Bidirectional asset connection:** our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)\n* **Very slow analysis:** we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, 'find all issues that are related to the pull request', in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.\n\nWhat would you recommend in this case?Suggestions:\n\n1. Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.\n2. Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?\n3. GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.\n\nWhat do you think guys? What would you do in this case?", "author_fullname": "t2_64lh2w2sq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline modification - JSONs and graphs driven", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ebv7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I would very appreciate your help here, an important question about architecture modification.&lt;br/&gt;\nWe use the ETL process to fetch data from external services (for example, Github).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Extract the data (e.g. issues and PRs) and create raw_data objects&lt;/li&gt;\n&lt;li&gt;Transform the data to our unique objects - let&amp;#39;s call them assets.&lt;/li&gt;\n&lt;li&gt;Load the assets as JSONs (jsonb field) to postgres DB (general assets table).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have a few problems with this approach and now we are considering to change our pipeline.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Bidirectional asset connection:&lt;/strong&gt; our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Very slow analysis:&lt;/strong&gt; we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, &amp;#39;find all issues that are related to the pull request&amp;#39;, in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What would you recommend in this case?Suggestions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.&lt;/li&gt;\n&lt;li&gt;Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?&lt;/li&gt;\n&lt;li&gt;GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What do you think guys? What would you do in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ebv7v", "is_robot_indexable": true, "report_reasons": null, "author": "ewenField", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "subreddit_subscribers": 91468, "created_utc": 1677599291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interested in becoming certified in data bricks and am looking for feedback on the best resources to learn and obtain certification.", "author_fullname": "t2_25hcisu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best data bricks certification to begin with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11euy09", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677647285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in becoming certified in data bricks and am looking for feedback on the best resources to learn and obtain certification.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11euy09", "is_robot_indexable": true, "report_reasons": null, "author": "vrajp98", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11euy09/which_is_the_best_data_bricks_certification_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11euy09/which_is_the_best_data_bricks_certification_to/", "subreddit_subscribers": 91468, "created_utc": 1677647285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.\n\nBelow are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! \n\nBig 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? \n\nConsulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work \n\nBig tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great", "author_fullname": "t2_3g1nc2rv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Australia - best industry for data engineering grad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11esjgj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677640473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677640185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.&lt;/p&gt;\n\n&lt;p&gt;Below are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! &lt;/p&gt;\n\n&lt;p&gt;Big 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? &lt;/p&gt;\n\n&lt;p&gt;Consulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work &lt;/p&gt;\n\n&lt;p&gt;Big tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11esjgj", "is_robot_indexable": true, "report_reasons": null, "author": "taybayx", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "subreddit_subscribers": 91468, "created_utc": 1677640185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?\n\nWe load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.\n\nIf we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?\n\nI know dbt is the popular solution here but management has dictated only official AWS products may be used.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue for ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ellex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677622213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?&lt;/p&gt;\n\n&lt;p&gt;We load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.&lt;/p&gt;\n\n&lt;p&gt;If we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?&lt;/p&gt;\n\n&lt;p&gt;I know dbt is the popular solution here but management has dictated only official AWS products may be used.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ellex", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ellex/glue_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ellex/glue_for_elt/", "subreddit_subscribers": 91468, "created_utc": 1677622213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_66icy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast: Real-Time Data Transformation and Analytics with dbtLabs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11eem3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Real-Time Data Transformation and Analytics with dbt Labs", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "author_name": "Confluent", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jmFBCQFkX7o/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Confluent"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11eem3t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WEHqDA4HP8d9TenEunduLXKz_pUso-fPBlbv-iM52JM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677605699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/jmFBCQFkX7o", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?auto=webp&amp;v=enabled&amp;s=8b994133c91036f595dc275a79fe2920619b786d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a696499e3d86e245a43ce3c9e77e430a81d8280", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a4babf2628c86e06215080ac78036c0c90d8339", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe583da01bdd051d7423d43822c4cc29f443fa02", "width": 320, "height": 240}], "variants": {}, "id": "-3kHx9E4aGvBSvGbdC7kc0J8XoJMcL-eVH8emK8RsWs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eem3t", "is_robot_indexable": true, "report_reasons": null, "author": "krisajenkins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eem3t/podcast_realtime_data_transformation_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/jmFBCQFkX7o", "subreddit_subscribers": 91468, "created_utc": 1677605699.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Real-Time Data Transformation and Analytics with dbt Labs", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "author_name": "Confluent", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jmFBCQFkX7o/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Confluent"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling delta files in data lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11e3wgn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677584262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11e3wgn", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "subreddit_subscribers": 91468, "created_utc": 1677584262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating dbt Cloud features vs dbt Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11eemdf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UttijFwPZ1u1g62F5EWUoF-Orec7p60mkwvkxfwi3hQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677605717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-cloud", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?auto=webp&amp;v=enabled&amp;s=b59b8e8aa8edaf7fadc5fe1db0607dd6d67ec577", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a79fb773196462b6916386c7a151e69abeb90303", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b02290a513a8edf0bdc9df0ac3c21f0e8cb111c", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bada74c988b2d861be6e0fd2400f5912e7441398", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3702aaf99eb824c0065b4aff34a71f2547209299", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=080da950935f79bbc84fa9edb6f083ef22c84951", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f59d1d35204b73984a1c663ac477c9bf84423df", "width": 1080, "height": 607}], "variants": {}, "id": "KmumNgjtFU6jMZRKV2HhNcHPL2ZZ2wK8w-aZVdTRkaQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eemdf", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eemdf/evaluating_dbt_cloud_features_vs_dbt_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-cloud", "subreddit_subscribers": 91468, "created_utc": 1677605717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) are two different approaches for data integration in data warehousing.\n\nIn ETL, data is extracted from various sources, transformed to fit the target schema, and then loaded into the data warehouse. In contrast, ELT loads the raw data into the data warehouse and then applies transformations as needed.\n\nThe main advantage of ETL is that it can handle complex transformations and can be more efficient when dealing with large datasets. ELT, on the other hand, allows for faster loading of data and greater flexibility in performing transformations.\n\nUltimately, the choice between ETL and ELT will depend on the specific requirements and constraints of each data integration project.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/tm49toucpwka1.png?width=1466&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267", "author_fullname": "t2_jtca4f0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL vs ELT: Check out the major differences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tm49toucpwka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/tm49toucpwka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cf11bffa252465348ae77cc9d8c374833cb0c6b"}, {"y": 159, "x": 216, "u": "https://preview.redd.it/tm49toucpwka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be57ca76fbb1ce14ca71284a043e314bbebcce90"}, {"y": 236, "x": 320, "u": "https://preview.redd.it/tm49toucpwka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd79d4fcd69c61adcec4d0967f6d76d5ae712075"}, {"y": 473, "x": 640, "u": "https://preview.redd.it/tm49toucpwka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f92c26b5ced72a5faa9f41bc174c393160780ea8"}, {"y": 709, "x": 960, "u": "https://preview.redd.it/tm49toucpwka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f76e46536971112ff37adc4ca668a3b58d8a4cf"}, {"y": 798, "x": 1080, "u": "https://preview.redd.it/tm49toucpwka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49c565df9a45a5d2662b67bb8c6b11e7e87733c4"}], "s": {"y": 1084, "x": 1466, "u": "https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267"}, "id": "tm49toucpwka1"}}, "name": "t3_11e2rqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VmyF4Cx_rlvpJp8Ola9mFsLJW0SprwZA1cVkc6gHQgk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677580103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) are two different approaches for data integration in data warehousing.&lt;/p&gt;\n\n&lt;p&gt;In ETL, data is extracted from various sources, transformed to fit the target schema, and then loaded into the data warehouse. In contrast, ELT loads the raw data into the data warehouse and then applies transformations as needed.&lt;/p&gt;\n\n&lt;p&gt;The main advantage of ETL is that it can handle complex transformations and can be more efficient when dealing with large datasets. ELT, on the other hand, allows for faster loading of data and greater flexibility in performing transformations.&lt;/p&gt;\n\n&lt;p&gt;Ultimately, the choice between ETL and ELT will depend on the specific requirements and constraints of each data integration project.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267\"&gt;https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11e2rqj", "is_robot_indexable": true, "report_reasons": null, "author": "hardik-s", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11e2rqj/etl_vs_elt_check_out_the_major_differences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e2rqj/etl_vs_elt_check_out_the_major_differences/", "subreddit_subscribers": 91468, "created_utc": 1677580103.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}