{"kind": "Listing", "data": {"after": "t3_11emsf6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w2y7e99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Brace yourselves... \"professional\" Data Mesh developer job ads incoming!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11eezyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 119, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 119, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7Fg-OCdcmezq19GoguvtGJK4781V_M-QvPVyOOof7-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677606641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u0xw0g77wyka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?auto=webp&amp;v=enabled&amp;s=99eb928deaafeb0b6d3e137e8dc78d94286e08ed", "width": 1300, "height": 1583}, "resolutions": [{"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64c0f173fca9655222e716d0e23c56aa440e8a97", "width": 108, "height": 131}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec87f23838b5919a0744c3062abfa641a13b1f7", "width": 216, "height": 263}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c566574e632b461ca970f1e9fee8c7fa8cf7b314", "width": 320, "height": 389}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff9e57499592a22b228e11acce182fbde04bb1c0", "width": 640, "height": 779}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b2aa657a7b5a3b068cc69499f312ae26e285c94", "width": 960, "height": 1168}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=694a1ba988e661acc0d902399b7decce6e4fb234", "width": 1080, "height": 1315}], "variants": {}, "id": "qwTGK3kHziyl0N7qLQfANNJvHWA3yaYv--CIWLyF-_g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11eezyq", "is_robot_indexable": true, "report_reasons": null, "author": "whichalps", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eezyq/brace_yourselves_professional_data_mesh_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u0xw0g77wyka1.jpg", "subreddit_subscribers": 91494, "created_utc": 1677606641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples](https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples)\n\nHi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it's for example to write data back into Snowflake or to visualize a map data. \n\nHope you enjoy and had as much fun reading as I had writing this.   \n\n\nhttps://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Streamlit and Data applications on Snowflake with Winter Sports examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sgnvh0116xka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aba633b89ce8a4ad4b6ad478e398b87b98701892"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7168ad79cf7bc0e89f737d02fd9a5da08b2685d0"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=250dd2fc5d66dbfa5d6541df378d5147b21972a0"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7318e143a74a678c35b71e4407a6c9cf62567db"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3b41d90f5e2d93b3cbc91ff19c3544c59d6fc2a"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b6f7e1c23ca1a7cb5902486f4bb8b88f334e3da"}], "s": {"y": 875, "x": 1920, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5"}, "id": "sgnvh0116xka1"}}, "name": "t3_11e4bv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WNUlYBzmq5_xjOvDF9FNroXOFVBeHFjCtdrFBVGl18g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677585694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples\"&gt;https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it&amp;#39;s for example to write data back into Snowflake or to visualize a map data. &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy and had as much fun reading as I had writing this.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5\"&gt;https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11e4bv4", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "subreddit_subscribers": 91494, "created_utc": 1677585694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone.  \n\n\nI make a lot of diagrams to help visualize data pipelines, software architecture, and more.\n\nMy way-to-go tool in the past year and a half is [Whimiscal](https://whimsical.com/). It is by far one of the best tools I've used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn't. The tool just helped me. Big win! :)   \n\n\nHowever, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   \n\n\nI am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.  \n1. [Draw.io](https://Draw.io) \\-  It's forever free, but it is not pretty. My diagrams won't be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else's and won't stand out in the crowd.\n\n2. [https://miro.com/](https://miro.com/) \\- Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn't really understand what it is. Maybe someone has used it and can throw some light.\n\n3. [https://www.taskade.com/](https://www.taskade.com/) \\- They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn't hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   \n\n\n4. Other alternatives?  \n\n\nThank you all. :)\n\n&amp;#x200B;\n\nSide note: Just to give an example, that's a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren't that far from it. Isn't it beautiful? \n\n \n\nhttps://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best free diagram tool alternative in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 99, "top_awarded_type": null, "hide_score": false, "media_metadata": {"21q1xw9gxyka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c1d4410700e9800eceb539e795806fdbc885705"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fec057f9e1bef58cab753de0a440fe4b093d11d"}, {"y": 227, "x": 320, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9277b0e953f020ec4be8ccd27df9b7125ea8c475"}, {"y": 455, "x": 640, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90eef4c9806596308eec1ef7e701721d80e996af"}, {"y": 683, "x": 960, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1be8e7f9ac22e597a2f3630321100972c82ac90a"}, {"y": 768, "x": 1080, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e725ee97909069fcef083679d7f78e4b397a693d"}], "s": {"y": 1154, "x": 1622, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41"}, "id": "21q1xw9gxyka1"}}, "name": "t3_11ef7lk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9qqFweX1KyxDHUvJqEgNJvexAHar6Vut1z4OlW5Kep4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677607178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone.  &lt;/p&gt;\n\n&lt;p&gt;I make a lot of diagrams to help visualize data pipelines, software architecture, and more.&lt;/p&gt;\n\n&lt;p&gt;My way-to-go tool in the past year and a half is &lt;a href=\"https://whimsical.com/\"&gt;Whimiscal&lt;/a&gt;. It is by far one of the best tools I&amp;#39;ve used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn&amp;#39;t. The tool just helped me. Big win! :)   &lt;/p&gt;\n\n&lt;p&gt;However, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   &lt;/p&gt;\n\n&lt;p&gt;I am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.&lt;br/&gt;\n1. &lt;a href=\"https://Draw.io\"&gt;Draw.io&lt;/a&gt; -  It&amp;#39;s forever free, but it is not pretty. My diagrams won&amp;#39;t be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else&amp;#39;s and won&amp;#39;t stand out in the crowd.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://miro.com/\"&gt;https://miro.com/&lt;/a&gt; - Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn&amp;#39;t really understand what it is. Maybe someone has used it and can throw some light.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://www.taskade.com/\"&gt;https://www.taskade.com/&lt;/a&gt; - They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn&amp;#39;t hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other alternatives?  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you all. :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Side note: Just to give an example, that&amp;#39;s a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren&amp;#39;t that far from it. Isn&amp;#39;t it beautiful? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41\"&gt;https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?auto=webp&amp;v=enabled&amp;s=a9f6dad99adbc9a7fb64ea6f090216c19a9215b8", "width": 1744, "height": 912}, "resolutions": [{"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5489caee9a35f72de0c4f2e0775f6eb01afb065", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8529c221c0d7aa4845c78526a5fc7357a5afa044", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ab9417914f9d18499d85c65b7753c564ce2fbaa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=917d95a02dd55147c6aff31f43b8bf8ed053ba78", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b218d1bb6fc94247a758630de5617148d71300d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70aba50d6cb83c288b36dc32148531496695af79", "width": 1080, "height": 564}], "variants": {}, "id": "k3XoPhRiwTJWBB72DdNhIHIqhF-cNikHtNW8qfA63mc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ef7lk", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "subreddit_subscribers": 91494, "created_utc": 1677607178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prod data in dev environments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eqzva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677635939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eqzva", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "subreddit_subscribers": 91494, "created_utc": 1677635939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "## Or how to build a light weight data platform for a small organization from scratch? \n\nWe are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.\n\nHowever, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.\n\nWe do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.\n\n\n### Update\nI try to draw out a potential solution based on the discussion and knowledge we have.\n\n| Domain | Solution | Comment |\n|-|-|-|\n| Data Warehouse | Clickhouse | Lakehouse is overkill |\n| BI / Data App | SuperSet and Dash |  |\n| ETL | AirByte |  |", "author_fullname": "t2_m0cc1w3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to deploy a lakehouse solution on a bare metal server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ea84j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677632775.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677596960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Or how to build a light weight data platform for a small organization from scratch?&lt;/h2&gt;\n\n&lt;p&gt;We are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.&lt;/p&gt;\n\n&lt;p&gt;However, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.&lt;/p&gt;\n\n&lt;p&gt;We do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.&lt;/p&gt;\n\n&lt;h3&gt;Update&lt;/h3&gt;\n\n&lt;p&gt;I try to draw out a potential solution based on the discussion and knowledge we have.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Domain&lt;/th&gt;\n&lt;th&gt;Solution&lt;/th&gt;\n&lt;th&gt;Comment&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Data Warehouse&lt;/td&gt;\n&lt;td&gt;Clickhouse&lt;/td&gt;\n&lt;td&gt;Lakehouse is overkill&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;BI / Data App&lt;/td&gt;\n&lt;td&gt;SuperSet and Dash&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ETL&lt;/td&gt;\n&lt;td&gt;AirByte&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ea84j", "is_robot_indexable": true, "report_reasons": null, "author": "_link89_", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "subreddit_subscribers": 91494, "created_utc": 1677596960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.\n\n1. If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?\n2. Purpose of dbfs if they say not to put data in it?\n3. Do you just mount your external cloud storage anyways?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice with storage and databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ec67v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?&lt;/li&gt;\n&lt;li&gt;Purpose of dbfs if they say not to put data in it?&lt;/li&gt;\n&lt;li&gt;Do you just mount your external cloud storage anyways?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ec67v", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "subreddit_subscribers": 91494, "created_utc": 1677599940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.\n\nBelow are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! \n\nBig 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? \n\nConsulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work \n\nBig tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great", "author_fullname": "t2_3g1nc2rv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Australia - best industry for data engineering grad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11esjgj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677640473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677640185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.&lt;/p&gt;\n\n&lt;p&gt;Below are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! &lt;/p&gt;\n\n&lt;p&gt;Big 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? &lt;/p&gt;\n\n&lt;p&gt;Consulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work &lt;/p&gt;\n\n&lt;p&gt;Big tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11esjgj", "is_robot_indexable": true, "report_reasons": null, "author": "taybayx", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "subreddit_subscribers": 91494, "created_utc": 1677640185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?", "author_fullname": "t2_qjqclauw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I crazy, making a newbie mistake or do I need to adjust my expectation of the cost of running a simple ETL in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eh8sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677612031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eh8sf", "is_robot_indexable": true, "report_reasons": null, "author": "EconomistNeither2472", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "subreddit_subscribers": 91494, "created_utc": 1677612031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.", "author_fullname": "t2_55onda91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone taken the updated version of DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edx4t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677604040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11edx4t", "is_robot_indexable": true, "report_reasons": null, "author": "bingbongpeepee", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "subreddit_subscribers": 91494, "created_utc": 1677604040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Art and Science of Measuring Data Teams Value", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_11eijno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yAoHcL7bQ0GuSIgzY2nBbWEsxMFTSwlZu_No21jJVKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677615073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/measuring-data-teams-value", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?auto=webp&amp;v=enabled&amp;s=c7b775b6cb5f26e40ac1b947136898809d2bc2d2", "width": 1800, "height": 1174}, "resolutions": [{"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc55254d0cf507f50cd11eb8d253129dabb86d7b", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a175f0d0cb404bbfcaff33306343cf02fc06a3b2", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=054084df2f57e8e047ff55b9e9a776a2bb51ea46", "width": 320, "height": 208}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e0484976ac50b957ca3d7f03f01696d007ca4c", "width": 640, "height": 417}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=129f1d2e8bb0a3ae417679b5eee5db085516563e", "width": 960, "height": 626}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1d7020733b3dd9bbd778dc62c83b1abeba10c54", "width": 1080, "height": 704}], "variants": {}, "id": "OCdXOfuYus0uN13ED4cARCiy_YL8zxwm7gjdvP0vJ0g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eijno", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eijno/the_art_and_science_of_measuring_data_teams_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/measuring-data-teams-value", "subreddit_subscribers": 91494, "created_utc": 1677615073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don't know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edtlt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don&amp;#39;t know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11edtlt", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edtlt/interview_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edtlt/interview_test/", "subreddit_subscribers": 91494, "created_utc": 1677603806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can somebody explain these two terms in as simple words as possible. New to the field", "author_fullname": "t2_66513e19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is an enterprise data platform and enterprise data catalogue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eonaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677629679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody explain these two terms in as simple words as possible. New to the field&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eonaj", "is_robot_indexable": true, "report_reasons": null, "author": "nikiii_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "subreddit_subscribers": 91494, "created_utc": 1677629679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title basically. I am trying to upskill myself and Kubernetes is in my list to learn. Before I dive in I need to first understand how k8s is used in data engg. \nCan you share how you are using k8s in your etl pipeline? Anything is appreciated. Thanks!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the role of Kubernetes in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11f0ckj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title basically. I am trying to upskill myself and Kubernetes is in my list to learn. Before I dive in I need to first understand how k8s is used in data engg. \nCan you share how you are using k8s in your etl pipeline? Anything is appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f0ckj", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0ckj/what_is_the_role_of_kubernetes_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0ckj/what_is_the_role_of_kubernetes_in_data_engineering/", "subreddit_subscribers": 91494, "created_utc": 1677666477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I want to write some Medium articles around Data Engineering, talking about Architecture concepts and technologies. What do you think would be relevant topics for beginners as well as mid level DE?\n\nThanks in advance", "author_fullname": "t2_9amrsuus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE articles for beginners and mid-level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11f0a8b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I want to write some Medium articles around Data Engineering, talking about Architecture concepts and technologies. What do you think would be relevant topics for beginners as well as mid level DE?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f0a8b", "is_robot_indexable": true, "report_reasons": null, "author": "dmborges", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0a8b/de_articles_for_beginners_and_midlevel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0a8b/de_articles_for_beginners_and_midlevel/", "subreddit_subscribers": 91494, "created_utc": 1677666230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a scenario where we manage 2 separate DBs, one on Europe and one in the US.\nThose DBs are then replicated and transformed using ELT practices.\n\nCurrently they use a set of transformations that makes them SEPARATELY analysis ready. If we want to check something across both regions, we have to perform unions of tables before.\n\nIs there a good practice as to how to manage those? Unioning every time feels kind of counter productive.\n\nI thought perhaps we can create a dataset for unioned data as views or even as tables that will update once in a while, and whenever we need both origins, query those. Is that relevant?\n\nI'd appreciate any tips for that!", "author_fullname": "t2_7tujv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly manage multiple regions of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ewdgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677651871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a scenario where we manage 2 separate DBs, one on Europe and one in the US.\nThose DBs are then replicated and transformed using ELT practices.&lt;/p&gt;\n\n&lt;p&gt;Currently they use a set of transformations that makes them SEPARATELY analysis ready. If we want to check something across both regions, we have to perform unions of tables before.&lt;/p&gt;\n\n&lt;p&gt;Is there a good practice as to how to manage those? Unioning every time feels kind of counter productive.&lt;/p&gt;\n\n&lt;p&gt;I thought perhaps we can create a dataset for unioned data as views or even as tables that will update once in a while, and whenever we need both origins, query those. Is that relevant?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any tips for that!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ewdgo", "is_robot_indexable": true, "report_reasons": null, "author": "qrixten", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ewdgo/how_to_properly_manage_multiple_regions_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ewdgo/how_to_properly_manage_multiple_regions_of_data/", "subreddit_subscribers": 91494, "created_utc": 1677651871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?\n\nWe load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.\n\nIf we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?\n\nI know dbt is the popular solution here but management has dictated only official AWS products may be used.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue for ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ellex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677622213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?&lt;/p&gt;\n\n&lt;p&gt;We load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.&lt;/p&gt;\n\n&lt;p&gt;If we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?&lt;/p&gt;\n\n&lt;p&gt;I know dbt is the popular solution here but management has dictated only official AWS products may be used.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ellex", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ellex/glue_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ellex/glue_for_elt/", "subreddit_subscribers": 91494, "created_utc": 1677622213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?", "author_fullname": "t2_2vnue5gp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a realtime firebase data and want each collection as a separate table in BigQuery for analysis, what is the best way to do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eiclj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677614622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eiclj", "is_robot_indexable": true, "report_reasons": null, "author": "blackfrwhite", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "subreddit_subscribers": 91494, "created_utc": 1677614622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference [https://www.datacouncil.ai/austin](https://www.datacouncil.ai/austin). I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.", "author_fullname": "t2_1u2bikk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edhmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference &lt;a href=\"https://www.datacouncil.ai/austin\"&gt;https://www.datacouncil.ai/austin&lt;/a&gt;. I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?auto=webp&amp;v=enabled&amp;s=54e72a190e3a4e0e3e7412697d111a1d4164245f", "width": 1434, "height": 1434}, "resolutions": [{"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712b54f3ba3432e501cc4ba9fba72776b722543a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eeb54f2d3f0388636f0b6c30d23acaaf892ab9d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4724ad2f2c8c22bcf6f3d29edf73f5975a527d96", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e46045182cf4ea2bd1725215182a69ceafaf3ba7", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=652c5d744d177eabea48e38193f0a9985d19e198", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18c77681ac295cf1d6523ab0a3856cb09db838ca", "width": 1080, "height": 1080}], "variants": {}, "id": "Fc1fxjSKNc0AhT9MqwkoW1xP4i7uEi4B67sxKyjzJl8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11edhmg", "is_robot_indexable": true, "report_reasons": null, "author": "ks4701", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edhmg/data_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edhmg/data_conference/", "subreddit_subscribers": 91494, "created_utc": 1677603024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I would very appreciate your help here, an important question about architecture modification.We use the ETL process to fetch data from external services (for example, Github).\n\n1. Extract the data (e.g. issues and PRs) and create raw\\_data objects\n2. Transform the data to our unique objects - let's call them assets.\n3. Load the assets as JSONs (jsonb field) to postgres DB (general assets table).\n\nWe have a few problems with this approach and now we are considering to change our pipeline.\n\n* **Bidirectional asset connection:** our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)\n* **Very slow analysis:** we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, 'find all issues that are related to the pull request', in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.\n\nWhat would you recommend in this case?\n\nSuggestions:\n\n1. Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.\n2. Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?\n3. GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.\n\nWhat do you think guys? What would you do in this case?", "author_fullname": "t2_64lh2w2sq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline modification - JSONs and graphs driven", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ebv7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677656426.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I would very appreciate your help here, an important question about architecture modification.We use the ETL process to fetch data from external services (for example, Github).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Extract the data (e.g. issues and PRs) and create raw_data objects&lt;/li&gt;\n&lt;li&gt;Transform the data to our unique objects - let&amp;#39;s call them assets.&lt;/li&gt;\n&lt;li&gt;Load the assets as JSONs (jsonb field) to postgres DB (general assets table).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have a few problems with this approach and now we are considering to change our pipeline.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Bidirectional asset connection:&lt;/strong&gt; our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Very slow analysis:&lt;/strong&gt; we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, &amp;#39;find all issues that are related to the pull request&amp;#39;, in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What would you recommend in this case?&lt;/p&gt;\n\n&lt;p&gt;Suggestions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.&lt;/li&gt;\n&lt;li&gt;Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?&lt;/li&gt;\n&lt;li&gt;GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What do you think guys? What would you do in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ebv7v", "is_robot_indexable": true, "report_reasons": null, "author": "ewenField", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "subreddit_subscribers": 91494, "created_utc": 1677599291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling delta files in data lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11e3wgn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677584262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11e3wgn", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "subreddit_subscribers": 91494, "created_utc": 1677584262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a junior data scientist working on predictive modelling for a small international company, I come to notice that my company has no data management or wtsoever. Everything is stored in Excel with different formats and the worst part is that they are now rolling out products of real-time monitoring with no insights or intention to manage the data. And then they are expecting me to work on the modeling in this shitty situation and ends up most of my work time is spent on cleaning and combining the data. And from what I heard, this happens to almost all departments around the company.\n\nIt is a good opportunity for me to pitch an idea for proper data management/warehousing to the management team. Not only will this make me more experienced in data engineering, it can gain me more bargaining power for asking higher position (e.g. management role)/salary.\n\nHowever, I have no practical experience in setting up data management system/warehouse. I wonder if you guys had any suggestions/resource to recommend? \n\nAs a small company of 500ppl, I also wonder if just a SQL system would already work?", "author_fullname": "t2_tdxm4fbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resources to learn/ Suggestions to set up the data management system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11f0ex9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a junior data scientist working on predictive modelling for a small international company, I come to notice that my company has no data management or wtsoever. Everything is stored in Excel with different formats and the worst part is that they are now rolling out products of real-time monitoring with no insights or intention to manage the data. And then they are expecting me to work on the modeling in this shitty situation and ends up most of my work time is spent on cleaning and combining the data. And from what I heard, this happens to almost all departments around the company.&lt;/p&gt;\n\n&lt;p&gt;It is a good opportunity for me to pitch an idea for proper data management/warehousing to the management team. Not only will this make me more experienced in data engineering, it can gain me more bargaining power for asking higher position (e.g. management role)/salary.&lt;/p&gt;\n\n&lt;p&gt;However, I have no practical experience in setting up data management system/warehouse. I wonder if you guys had any suggestions/resource to recommend? &lt;/p&gt;\n\n&lt;p&gt;As a small company of 500ppl, I also wonder if just a SQL system would already work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f0ex9", "is_robot_indexable": true, "report_reasons": null, "author": "Delay_no_more_1999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0ex9/any_good_resources_to_learn_suggestions_to_set_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0ex9/any_good_resources_to_learn_suggestions_to_set_up/", "subreddit_subscribers": 91494, "created_utc": 1677666715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have large amounts of data on postgres dbs that we would like to aggregate and show to customers on the website (with some dimensions splits and filters). The aggregations can be heavy queries. \n\nWhat are the best technologies that are used these days to provide this? Do data engineers use cloud data tools for these kind of \"production\" calculations?   \nWe already have a modern data stack for internal analytics, so I'm wondering if we can leverage that in our production pipeline as well, or if that's regarded bad practice.\n\nTIA", "author_fullname": "t2_7hc6xuzu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which technologies are best to show data aggregations to customers in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11f0dmn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have large amounts of data on postgres dbs that we would like to aggregate and show to customers on the website (with some dimensions splits and filters). The aggregations can be heavy queries. &lt;/p&gt;\n\n&lt;p&gt;What are the best technologies that are used these days to provide this? Do data engineers use cloud data tools for these kind of &amp;quot;production&amp;quot; calculations?&lt;br/&gt;\nWe already have a modern data stack for internal analytics, so I&amp;#39;m wondering if we can leverage that in our production pipeline as well, or if that&amp;#39;s regarded bad practice.&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11f0dmn", "is_robot_indexable": true, "report_reasons": null, "author": "Environmental_Hat911", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0dmn/which_technologies_are_best_to_show_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0dmn/which_technologies_are_best_to_show_data/", "subreddit_subscribers": 91494, "created_utc": 1677666594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Deequ is library for data [quality](https://github.com/awslabs/deequ)\n\nIn my org we are looking at using Deequ for data quality and I\u2019m looking for feedback from people that used it in production. I\u2019m basically interested in the limitations that you had with the framework and your use cases.\n\nBelow are some example of limitations we found:\n\n**1) Metrics modelization:**\n\nThe kind of metrics that can be extracted by Deequ is limited. There are only[ three](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/metrics/Metric.scala#L39):\n\n1. DoubleMetric\n2. HistorgramMetric\n3. KLLMetric\n\nWhich makes it difficult to have the min/max for non numerical columns. Hence this[ issue](https://github.com/awslabs/deequ/issues/47)\n\n**2) Inability to add custom Analyzers**\n\nThere is a finite set of[ Analyzers](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L228-L354) and there is no possibility for users to extend and create their own. If you try you will trigger an exception[ here](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L353). Did you ever want to extend and create your own analyzer ? Or did you always manage to express your use case using the set of existing ones ?\n\n**Runner:**\n\nDeequ uses Spark as a backend to compute the metrics but did you try to use another runner ? By using I mean re-implementing Deequ but this time with Snowflake as a runner for example ?\n\nIf not, how were you computing data quality that existed in some data stores like: Snowflake, BigQuery ? Was it efficient with Spark (since you were relying on the spark connector of the data store)\n\nAnd more generally what are the features that you missed ? For which use case ?\n\nThank you", "author_fullname": "t2_to6i6cdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Data Quality] Deequ Feedback request", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11ezqft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677664203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deequ is library for data &lt;a href=\"https://github.com/awslabs/deequ\"&gt;quality&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In my org we are looking at using Deequ for data quality and I\u2019m looking for feedback from people that used it in production. I\u2019m basically interested in the limitations that you had with the framework and your use cases.&lt;/p&gt;\n\n&lt;p&gt;Below are some example of limitations we found:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1) Metrics modelization:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The kind of metrics that can be extracted by Deequ is limited. There are only&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/metrics/Metric.scala#L39\"&gt; three&lt;/a&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;DoubleMetric&lt;/li&gt;\n&lt;li&gt;HistorgramMetric&lt;/li&gt;\n&lt;li&gt;KLLMetric&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which makes it difficult to have the min/max for non numerical columns. Hence this&lt;a href=\"https://github.com/awslabs/deequ/issues/47\"&gt; issue&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2) Inability to add custom Analyzers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There is a finite set of&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L228-L354\"&gt; Analyzers&lt;/a&gt; and there is no possibility for users to extend and create their own. If you try you will trigger an exception&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L353\"&gt; here&lt;/a&gt;. Did you ever want to extend and create your own analyzer ? Or did you always manage to express your use case using the set of existing ones ?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Runner:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Deequ uses Spark as a backend to compute the metrics but did you try to use another runner ? By using I mean re-implementing Deequ but this time with Snowflake as a runner for example ?&lt;/p&gt;\n\n&lt;p&gt;If not, how were you computing data quality that existed in some data stores like: Snowflake, BigQuery ? Was it efficient with Spark (since you were relying on the spark connector of the data store)&lt;/p&gt;\n\n&lt;p&gt;And more generally what are the features that you missed ? For which use case ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?auto=webp&amp;v=enabled&amp;s=39f1d29001f32fb2860ebdd3067d9b217115eec0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f16968a00aefa288a8ccc2b2d16157fa238e229", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7835fff6e02f544a2e31e78fb0a4d010b307ceeb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc546f714b1b4accc49831c7e7911c2ccb834ac5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7714f0e33cf2f6db8d862b772e4166b71568e508", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1b95e87f60f2f1dbd3b670497244527a9575cf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=615451807407c9c22197cc8107c8c44908831297", "width": 1080, "height": 540}], "variants": {}, "id": "45pC0WwUfD77oMIqZiiY0GY1lKDHLoN48Ti27hzjT2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ezqft", "is_robot_indexable": true, "report_reasons": null, "author": "LabAway8794", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ezqft/data_quality_deequ_feedback_request/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ezqft/data_quality_deequ_feedback_request/", "subreddit_subscribers": 91494, "created_utc": 1677664203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you live in Europe, please help with a vote. I'm genuinely interested in where you search for Data Engineering jobs. Is there a difference between employment and freelancing regarding where you search? \n\n[View Poll](https://www.reddit.com/poll/11ez5ic)", "author_fullname": "t2_4g5nylle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you search for Data Engineering jobs in Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ez5ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677661996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you live in Europe, please help with a vote. I&amp;#39;m genuinely interested in where you search for Data Engineering jobs. Is there a difference between employment and freelancing regarding where you search? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11ez5ic\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11ez5ic", "is_robot_indexable": true, "report_reasons": null, "author": "trendydots", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1677921196393, "options": [{"text": "Social networks (Linkeding, Xing, etc.)", "id": "21841261"}, {"text": "Dedicated job boards (Websites with only data jobs in EU)", "id": "21841262"}, {"text": "Reverse jobs search (Companies that search jobs for you)", "id": "21841263"}, {"text": "Show results", "id": "21841264"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 34, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ez5ic/where_do_you_search_for_data_engineering_jobs_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11ez5ic/where_do_you_search_for_data_engineering_jobs_in/", "subreddit_subscribers": 91494, "created_utc": 1677661996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're moving away from Snowflake. We'd like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.\n\nI have several questions and I'd appreciate any help on any of them.\n\n1. Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, `{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/` for IoT device data, which is similar to our use case. Right?\n\n2. Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it's columnar/compression properties. Right?\n\n3. What options do we have for getting historical data currently in SF into this format and moving it over efficiently?\n\n4. Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? \n\n5. Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We've never used it. \n\n6. Should we use Synapse, do you \"load\" all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. \n\nAgain, thanks for any help.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on our migration to a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11emsf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677625075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re moving away from Snowflake. We&amp;#39;d like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.&lt;/p&gt;\n\n&lt;p&gt;I have several questions and I&amp;#39;d appreciate any help on any of them.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, &lt;code&gt;{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/&lt;/code&gt; for IoT device data, which is similar to our use case. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it&amp;#39;s columnar/compression properties. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What options do we have for getting historical data currently in SF into this format and moving it over efficiently?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We&amp;#39;ve never used it. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should we use Synapse, do you &amp;quot;load&amp;quot; all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Again, thanks for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11emsf6", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "subreddit_subscribers": 91494, "created_utc": 1677625075.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}