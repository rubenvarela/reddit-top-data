{"kind": "Listing", "data": {"after": "t3_11emsf6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title basically. I am trying to upskill myself and Kubernetes is in my list to learn. Before I dive in I need to first understand how k8s is used in data engg. \nCan you share how you are using k8s in your etl pipeline? Anything is appreciated. Thanks!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the role of Kubernetes in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f0ckj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title basically. I am trying to upskill myself and Kubernetes is in my list to learn. Before I dive in I need to first understand how k8s is used in data engg. \nCan you share how you are using k8s in your etl pipeline? Anything is appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f0ckj", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0ckj/what_is_the_role_of_kubernetes_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0ckj/what_is_the_role_of_kubernetes_in_data_engineering/", "subreddit_subscribers": 91535, "created_utc": 1677666477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prod data in dev environments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eqzva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677635939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle sensitive data within dev or staging? Is it normal to have prod data in dev environments? I am not sure how I can do accurate testing if I don\u2019t have prod data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eqzva", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eqzva/prod_data_in_dev_environments/", "subreddit_subscribers": 91535, "created_utc": 1677635939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.\n\nBelow are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! \n\nBig 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? \n\nConsulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work \n\nBig tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great", "author_fullname": "t2_3g1nc2rv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Australia - best industry for data engineering grad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11esjgj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677640473.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677640185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am graduating from my bachelor\u2019s this year and interesting in working in data engineering. Since data engineering is in demand in most industries, I\u2019m having trouble deciding which industry to go into to best start my career.&lt;/p&gt;\n\n&lt;p&gt;Below are the options I am considering and my thoughts. Would love anyone\u2019s perspective on these or any others! &lt;/p&gt;\n\n&lt;p&gt;Big 4 bank (eg CBA, Westpac)\n- I\u2019ve heard that the majority of data engineers in Australia work for a bank, hence I assume there would be good opportunities to learn from others\n- Pay is good\n- Worried about things moving slowly at banks and lots of regulatory hurdles\n- Worried about career progression - will I reach a point where I have learnt everything there is to learn about data engineering at a bank? Then where would I go next? &lt;/p&gt;\n\n&lt;p&gt;Consulting (eg BCG, McKinsey, Accenture, Deloitte)\n- Fast moving so I believe I would learn fast\n- Opportunity to interact with clients and work on communication skills\n- Opportunities to work with variety of clients and tech stacks\n- Not sure how much deep data engineering work would be required on consulting projects - worried I might only be assembling datasets and pass onto the business analysts to do most of the work &lt;/p&gt;\n\n&lt;p&gt;Big tech (eg Canva, Atlassian)\n- Don\u2019t know too much about data engineering at big tech in Australia, but the culture seems pretty great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11esjgj", "is_robot_indexable": true, "report_reasons": null, "author": "taybayx", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11esjgj/australia_best_industry_for_data_engineering_grad/", "subreddit_subscribers": 91535, "created_utc": 1677640185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?", "author_fullname": "t2_qjqclauw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I crazy, making a newbie mistake or do I need to adjust my expectation of the cost of running a simple ETL in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eh8sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677612031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m new to Azure Data Factory.  My first ETL has been set up to move data from a small excel file to an on prim SQL Server database.  The only transformation work that is done is the addition of a column with th current datetime.  One simple ETL is costing me $2.50.  It seems that a cluster needs to be spun up just to add the datetime.  The ETL runs in seconds so the $2.50 for that single run seems excessive to me.  Would anyone have any advise for where I might be going wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eh8sf", "is_robot_indexable": true, "report_reasons": null, "author": "EconomistNeither2472", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eh8sf/am_i_crazy_making_a_newbie_mistake_or_do_i_need/", "subreddit_subscribers": 91535, "created_utc": 1677612031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:\n\n1. Current title\n\n2. Years of experience (YOE)\n\n3. Location\n\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n\n5. Bonuses/Equity (optional)\n\n6. Industry (optional)\n\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1677690034.814, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8yxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Current title&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Years of experience (YOE)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Location&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Bonuses/Equity (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Industry (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tech stack (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f8yxo", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8yxo/quarterly_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/11f8yxo/quarterly_salary_discussion/", "subreddit_subscribers": 91535, "created_utc": 1677690034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Getting into Data Engineering and more!\n\nHey fellow Devs,\n\nI recently posted in this sub for some advice about a job switch,  but got a lot of queries and DMs about how I got into Data Engineering, how to get better and go from entry level to senior position or from Data Analyst to Data Engineer (DE)\n\nI'm working as a Senior Data Engineer in a Unicorn Startup in India. \n\nTrying to give back to the community from my experience in Data Engineering since 2019. Still surprised that not many are aware about what actually are the roles, the expectations from Data Engineers are. Most of the stuff is available online, videos from many youtubers, still posted it for people who might not be aware! :)\n\nWill answer FAQs about Data Engineering. Feel free to correct or improvise. \n\n**Warning: This is going to be a long post.**\n\n&gt; DE means Data Engineering\n\n\nI. As a fresher, I'm interested in Data Engineering, but how to get a job in this domain?\n\nA. Getting a job directly as a full-time DE is pretty tough. Try to apply for DE internships and maybe it will get converted to full-time or with that experience try to apply for Associate / Junior DE positions. Build a network on Linkedin with many Data Engineers and connect with them about their experience. \n\n\n\n2.  What are the required skill-sets to become a DE?\n\nA. From my experience companies expect you to be good at any one language\n\n* Python, Java or Scala\n* Strong SQL skills\n* Data warehousing\n* Spark\n* Cloud experience - AWS/Azure/GCP \\[good to atleast have an idea on how to spin up a cluster in any cloud vendor, setting up Network rules, firewall, etc.\\]\n\n\n\n3. Is DE in demand, is it better than Data Science?\n\nA. Even though all the hype on the internet is for Data Scientists, the role of Data Engineer is equally crucial and critical for companies to enable Data Scientists. \n\n* Even the pay is lucrative! \n   * Salaries may vary, but mostly ranges look like this in India\n   * Entry level DE - 4 to 10 LPA\n   * 2 - 4 years - 12 to 30 LPA\n   * 4 - 7 years - 25 - 60+ LPA\n\n4. How do the roles differ, Data Engineer vs Data Scientist vs Data Analyst\n\nA. My understanding - In the Data ecosystem\n\n1. Data Engineer - Process starts here, collecting, cleaning and transforming, ingesting data into Data warehouses or datalakes.\n\n2. Data Scientist - With the collected data in DW/DL, understand business logic and build useful data science techniques / ML models to identify key patterns, insights that can drive revenue.\n\n   3. Data Analyst - Final part in process, Visualize the insights from Data Scientists using BI tools like Tableau, Looker, etc. \n\n\n\n3. How to prepare for DE interviews, Most commonly asked interview questions?\n\n\n\n* **NOTE: In most companies, even Data Engineers are expected to be strong in DSA, since first rounds can be OA tests like Hackerrank and F2F Coding rounds before you can enter technical rounds about topics mentioned below. So, still need to Grind Leetcode to some extent!**\n* **That being said, there are still companies that focus mostly on SQL, Spark for interviews and pay lesser attention to coding skills.**\n\n\n\nAfter attending close to 40 interviews in last 4 years, the most asked interview questions for 0-3 years of experience were mostly on the following.\n\n**Must have knowledge on these concepts to crack any DE interview:**\n\nI. SQL\n\n* Aggregate functions - AVG, MIN, MAX, etc.\n* Joins - **important!** types of joins and their output.\n* Window functions - Ranking functions, LAG, LEAD\n* what is &lt;**following**\\&gt; how do they **work**, how to **create** this and why is it used, **pros** and **cons** for the **following:**\n   * CTEs\n   * Views, Materialized views\n   * Index - also types of indexes, index behind the scenes.\n   * Partitioning - types of partitioning\n* Normalization / Denormalization - rarely asked but important\n\n\n\n2. Data Warehousing (DW) and ETL\n\n* Star vs Snowflake Schema\n* DB vs DW vs Data lake, when to use appropriately\n* Choosing Columnar vs row oriented Databases\n* Facts, Dimensions - understanding, examples\n* Steps to implement a Data warehouse (for example in Bigquery)\n* Best practices for DW, reporting\n* Slowly changing dimensions\n* Handling duplicate records, inconsistencies in data.\n* Understanding ETL vs ELT process, data cleaning, ingestion techniques. \n\n\n\n3. Spark\n\n* Understading Architecture\n* YARN basics\n* Sparkcontext, session, worker, task, job, stage, etc\n* Spark dataframes, actions, transformations, reading and writing data, specifying schema options\n* Repartioning vs Coalesce\n* Partioning\n* Handling OOM error in spark\n* Broadcast variables, broadcast joins\n* Best practices of Spark, best tuning practices\n* Different persisting strategies in spark\n\n\nCloud experience\n\n* Not much questions but it is vital to have an idea on different big data tools and services available in any one Cloud platform and their use cases.\n* Most commonly used services in Cloud for Data systems\n   * AWS - S3, Redshift, Glue, RDS\n   * GCP - Cloud Storage, Bigquery, CloudSQL, Dataflow \\[for streaming\\]\n\n**Linux skills - I think this is also a very important skill and a basic requirement**\n\n \n\nOther skills to learn to become a better a niche Data Engineer,  if have the above mentioned topics covered, check these out:\n\n1. Orchestration tool - Airflow \\[slowly becoming a must have skill\\]\n2. Streaming data - Spark Streaming / Flink\n3. Pubsub systems like Kafka\n4. NoSQL databases - MongoDB, Elasticsearch, Cassandra, etc.\n5. System Design for Big Data\n\n\n\nResources: \n\n**Datacamp** is one of my most favorite platforms. It has skill tracks for Data Engineering, Python, SQL, Shell, Spark, etc.\n\nhttps://www.datacamp.com/tracks/data-engineer-with-python](https://www.datacamp.com/tracks/data-engineer-with-python\n\nhttps://www.datacamp.com/tracks/big-data-with-pyspark](https://www.datacamp.com/tracks/big-data-with-pyspark\n\n\n**I would highly recommend this but this is a paid platform though :(\n\nFeel free to explore Youtube, Coursera, Udemy for specific concepts / courses based on the topics mentioned! \n\nif you are a student, use your college ID and activate Github Student developer program, get free access to datacamp for 3 months!\n\n**Other resources I used to prep:**\n\nhttps://dataengineering.wiki/](https://dataengineering.wiki/\n\n\n\n1. **Orielly books -** for any topic, check reviews, most of them are available as PDFs in github.\n2. SQL - [pgexercises.com](https://pgexercises.com), data Lemur, Ankit Bansal on Youtube, hackerrank, Leetcode\n3. Spark - Spark by examples, Datacamp, ChatGPT recently :P,  to understand concepts with amazing analogies. \n4. DWH - Ralph Kimball book\n\nNotable YT channels: Ankit Bansal for SQL\n\nBig data folks on Linkedin : Shashank Mishra, Seattle Data Guy, Zach Wilson\n\n\nData Engineering is gaining more importance everyday. Upskill yourselves and join the ride!\n\nFeel free to correct / add on, ping me for any queries. \n\nCheers!", "author_fullname": "t2_dd74avna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting into Data Engineering and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f95x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Getting into Data Engineering and more!&lt;/p&gt;\n\n&lt;p&gt;Hey fellow Devs,&lt;/p&gt;\n\n&lt;p&gt;I recently posted in this sub for some advice about a job switch,  but got a lot of queries and DMs about how I got into Data Engineering, how to get better and go from entry level to senior position or from Data Analyst to Data Engineer (DE)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working as a Senior Data Engineer in a Unicorn Startup in India. &lt;/p&gt;\n\n&lt;p&gt;Trying to give back to the community from my experience in Data Engineering since 2019. Still surprised that not many are aware about what actually are the roles, the expectations from Data Engineers are. Most of the stuff is available online, videos from many youtubers, still posted it for people who might not be aware! :)&lt;/p&gt;\n\n&lt;p&gt;Will answer FAQs about Data Engineering. Feel free to correct or improvise. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Warning: This is going to be a long post.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;DE means Data Engineering&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I. As a fresher, I&amp;#39;m interested in Data Engineering, but how to get a job in this domain?&lt;/p&gt;\n\n&lt;p&gt;A. Getting a job directly as a full-time DE is pretty tough. Try to apply for DE internships and maybe it will get converted to full-time or with that experience try to apply for Associate / Junior DE positions. Build a network on Linkedin with many Data Engineers and connect with them about their experience. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; What are the required skill-sets to become a DE?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. From my experience companies expect you to be good at any one language&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python, Java or Scala&lt;/li&gt;\n&lt;li&gt;Strong SQL skills&lt;/li&gt;\n&lt;li&gt;Data warehousing&lt;/li&gt;\n&lt;li&gt;Spark&lt;/li&gt;\n&lt;li&gt;Cloud experience - AWS/Azure/GCP [good to atleast have an idea on how to spin up a cluster in any cloud vendor, setting up Network rules, firewall, etc.]&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is DE in demand, is it better than Data Science?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. Even though all the hype on the internet is for Data Scientists, the role of Data Engineer is equally crucial and critical for companies to enable Data Scientists. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Even the pay is lucrative! \n\n&lt;ul&gt;\n&lt;li&gt;Salaries may vary, but mostly ranges look like this in India&lt;/li&gt;\n&lt;li&gt;Entry level DE - 4 to 10 LPA&lt;/li&gt;\n&lt;li&gt;2 - 4 years - 12 to 30 LPA&lt;/li&gt;\n&lt;li&gt;4 - 7 years - 25 - 60+ LPA&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do the roles differ, Data Engineer vs Data Scientist vs Data Analyst&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. My understanding - In the Data ecosystem&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data Engineer - Process starts here, collecting, cleaning and transforming, ingesting data into Data warehouses or datalakes.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Scientist - With the collected data in DW/DL, understand business logic and build useful data science techniques / ML models to identify key patterns, insights that can drive revenue.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Analyst - Final part in process, Visualize the insights from Data Scientists using BI tools like Tableau, Looker, etc. &lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How to prepare for DE interviews, Most commonly asked interview questions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;NOTE: In most companies, even Data Engineers are expected to be strong in DSA, since first rounds can be OA tests like Hackerrank and F2F Coding rounds before you can enter technical rounds about topics mentioned below. So, still need to Grind Leetcode to some extent!&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;That being said, there are still companies that focus mostly on SQL, Spark for interviews and pay lesser attention to coding skills.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;After attending close to 40 interviews in last 4 years, the most asked interview questions for 0-3 years of experience were mostly on the following.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Must have knowledge on these concepts to crack any DE interview:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I. SQL&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Aggregate functions - AVG, MIN, MAX, etc.&lt;/li&gt;\n&lt;li&gt;Joins - &lt;strong&gt;important!&lt;/strong&gt; types of joins and their output.&lt;/li&gt;\n&lt;li&gt;Window functions - Ranking functions, LAG, LEAD&lt;/li&gt;\n&lt;li&gt;what is &amp;lt;&lt;strong&gt;following&lt;/strong&gt;&amp;gt; how do they &lt;strong&gt;work&lt;/strong&gt;, how to &lt;strong&gt;create&lt;/strong&gt; this and why is it used, &lt;strong&gt;pros&lt;/strong&gt; and &lt;strong&gt;cons&lt;/strong&gt; for the &lt;strong&gt;following:&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CTEs&lt;/li&gt;\n&lt;li&gt;Views, Materialized views&lt;/li&gt;\n&lt;li&gt;Index - also types of indexes, index behind the scenes.&lt;/li&gt;\n&lt;li&gt;Partitioning - types of partitioning&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Normalization / Denormalization - rarely asked but important&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Warehousing (DW) and ETL&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Star vs Snowflake Schema&lt;/li&gt;\n&lt;li&gt;DB vs DW vs Data lake, when to use appropriately&lt;/li&gt;\n&lt;li&gt;Choosing Columnar vs row oriented Databases&lt;/li&gt;\n&lt;li&gt;Facts, Dimensions - understanding, examples&lt;/li&gt;\n&lt;li&gt;Steps to implement a Data warehouse (for example in Bigquery)&lt;/li&gt;\n&lt;li&gt;Best practices for DW, reporting&lt;/li&gt;\n&lt;li&gt;Slowly changing dimensions&lt;/li&gt;\n&lt;li&gt;Handling duplicate records, inconsistencies in data.&lt;/li&gt;\n&lt;li&gt;Understanding ETL vs ELT process, data cleaning, ingestion techniques. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Spark&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Understading Architecture&lt;/li&gt;\n&lt;li&gt;YARN basics&lt;/li&gt;\n&lt;li&gt;Sparkcontext, session, worker, task, job, stage, etc&lt;/li&gt;\n&lt;li&gt;Spark dataframes, actions, transformations, reading and writing data, specifying schema options&lt;/li&gt;\n&lt;li&gt;Repartioning vs Coalesce&lt;/li&gt;\n&lt;li&gt;Partioning&lt;/li&gt;\n&lt;li&gt;Handling OOM error in spark&lt;/li&gt;\n&lt;li&gt;Broadcast variables, broadcast joins&lt;/li&gt;\n&lt;li&gt;Best practices of Spark, best tuning practices&lt;/li&gt;\n&lt;li&gt;Different persisting strategies in spark&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Cloud experience&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Not much questions but it is vital to have an idea on different big data tools and services available in any one Cloud platform and their use cases.&lt;/li&gt;\n&lt;li&gt;Most commonly used services in Cloud for Data systems\n\n&lt;ul&gt;\n&lt;li&gt;AWS - S3, Redshift, Glue, RDS&lt;/li&gt;\n&lt;li&gt;GCP - Cloud Storage, Bigquery, CloudSQL, Dataflow [for streaming]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Linux skills - I think this is also a very important skill and a basic requirement&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Other skills to learn to become a better a niche Data Engineer,  if have the above mentioned topics covered, check these out:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Orchestration tool - Airflow [slowly becoming a must have skill]&lt;/li&gt;\n&lt;li&gt;Streaming data - Spark Streaming / Flink&lt;/li&gt;\n&lt;li&gt;Pubsub systems like Kafka&lt;/li&gt;\n&lt;li&gt;NoSQL databases - MongoDB, Elasticsearch, Cassandra, etc.&lt;/li&gt;\n&lt;li&gt;System Design for Big Data&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Resources: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Datacamp&lt;/strong&gt; is one of my most favorite platforms. It has skill tracks for Data Engineering, Python, SQL, Shell, Spark, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/tracks/data-engineer-with-python%5D(https://www.datacamp.com/tracks/data-engineer-with-python\"&gt;https://www.datacamp.com/tracks/data-engineer-with-python](https://www.datacamp.com/tracks/data-engineer-with-python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/tracks/big-data-with-pyspark%5D(https://www.datacamp.com/tracks/big-data-with-pyspark\"&gt;https://www.datacamp.com/tracks/big-data-with-pyspark](https://www.datacamp.com/tracks/big-data-with-pyspark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;**I would highly recommend this but this is a paid platform though :(&lt;/p&gt;\n\n&lt;p&gt;Feel free to explore Youtube, Coursera, Udemy for specific concepts / courses based on the topics mentioned! &lt;/p&gt;\n\n&lt;p&gt;if you are a student, use your college ID and activate Github Student developer program, get free access to datacamp for 3 months!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Other resources I used to prep:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dataengineering.wiki/%5D(https://dataengineering.wiki/\"&gt;https://dataengineering.wiki/](https://dataengineering.wiki/&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Orielly books -&lt;/strong&gt; for any topic, check reviews, most of them are available as PDFs in github.&lt;/li&gt;\n&lt;li&gt;SQL - &lt;a href=\"https://pgexercises.com\"&gt;pgexercises.com&lt;/a&gt;, data Lemur, Ankit Bansal on Youtube, hackerrank, Leetcode&lt;/li&gt;\n&lt;li&gt;Spark - Spark by examples, Datacamp, ChatGPT recently :P,  to understand concepts with amazing analogies. &lt;/li&gt;\n&lt;li&gt;DWH - Ralph Kimball book&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Notable YT channels: Ankit Bansal for SQL&lt;/p&gt;\n\n&lt;p&gt;Big data folks on Linkedin : Shashank Mishra, Seattle Data Guy, Zach Wilson&lt;/p&gt;\n\n&lt;p&gt;Data Engineering is gaining more importance everyday. Upskill yourselves and join the ride!&lt;/p&gt;\n\n&lt;p&gt;Feel free to correct / add on, ping me for any queries. &lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f95x7", "is_robot_indexable": true, "report_reasons": null, "author": "Simple_Bunch8526", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f95x7/getting_into_data_engineering_and_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f95x7/getting_into_data_engineering_and_more/", "subreddit_subscribers": 91535, "created_utc": 1677690468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849](https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing the Top 3 Schema Management Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f3agn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677675922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849\"&gt;https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?auto=webp&amp;v=enabled&amp;s=d5a315406c4b243e16dd97652a66097e6dfe99d8", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40f464226f4706e9d84d5b0dd10a47a43f773281", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83efe3747c9101a68c36469b87cd471901acbc16", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=920d05bcdaa6446581df8bc5e9869331308f6096", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3e23528c6cc1032b31d31060b48cc8bd3c94ce5", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3654b4712847ba4aac1a8eafd7c4d557ad70c47", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2473afe5676df4bd1292081c5f19ac7d7f68ada5", "width": 1080, "height": 607}], "variants": {}, "id": "kvmx4jjWHaJLdHWOmLYo5GeokUifMuiaOh-3__iBVyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f3agn", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f3agn/comparing_the_top_3_schema_management_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f3agn/comparing_the_top_3_schema_management_tools/", "subreddit_subscribers": 91535, "created_utc": 1677675922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Art and Science of Measuring Data Teams Value", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_11eijno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yAoHcL7bQ0GuSIgzY2nBbWEsxMFTSwlZu_No21jJVKg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677615073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/measuring-data-teams-value", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?auto=webp&amp;v=enabled&amp;s=c7b775b6cb5f26e40ac1b947136898809d2bc2d2", "width": 1800, "height": 1174}, "resolutions": [{"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc55254d0cf507f50cd11eb8d253129dabb86d7b", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a175f0d0cb404bbfcaff33306343cf02fc06a3b2", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=054084df2f57e8e047ff55b9e9a776a2bb51ea46", "width": 320, "height": 208}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06e0484976ac50b957ca3d7f03f01696d007ca4c", "width": 640, "height": 417}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=129f1d2e8bb0a3ae417679b5eee5db085516563e", "width": 960, "height": 626}, {"url": "https://external-preview.redd.it/_bt9sTGqzuMKOXVhIzUooI1mn4HEyIkYja8KWpDSmys.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1d7020733b3dd9bbd778dc62c83b1abeba10c54", "width": 1080, "height": 704}], "variants": {}, "id": "OCdXOfuYus0uN13ED4cARCiy_YL8zxwm7gjdvP0vJ0g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eijno", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eijno/the_art_and_science_of_measuring_data_teams_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/measuring-data-teams-value", "subreddit_subscribers": 91535, "created_utc": 1677615073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am loading a large table from Snowflake into Power BI using \"import mode\"\n\nThe table is around 20 million rows and 25 columns and it take around 15 mins to be totally loaded into Power BI\n\nThe query finished executing on Snowflake in less that 2 mins and the remaining time was spent on transferring the data to Power BI\n\nWe tried loading the same table from SQL Server it was ~7x faster\n\nis there anything I can do to decrease the transfer time of the data from Snowflake to Power Bi and still use the \"import mode\"\n\nI am using the latest Snowflake ODBC Driver, version 2.25.9 on Windows", "author_fullname": "t2_a3lkw6g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake is slow with Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f6na7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677684544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am loading a large table from Snowflake into Power BI using &amp;quot;import mode&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The table is around 20 million rows and 25 columns and it take around 15 mins to be totally loaded into Power BI&lt;/p&gt;\n\n&lt;p&gt;The query finished executing on Snowflake in less that 2 mins and the remaining time was spent on transferring the data to Power BI&lt;/p&gt;\n\n&lt;p&gt;We tried loading the same table from SQL Server it was ~7x faster&lt;/p&gt;\n\n&lt;p&gt;is there anything I can do to decrease the transfer time of the data from Snowflake to Power Bi and still use the &amp;quot;import mode&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I am using the latest Snowflake ODBC Driver, version 2.25.9 on Windows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11f6na7", "is_robot_indexable": true, "report_reasons": null, "author": "nobel-001", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f6na7/snowflake_is_slow_with_power_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f6na7/snowflake_is_slow_with_power_bi/", "subreddit_subscribers": 91535, "created_utc": 1677684544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1677690047.203, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8z5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f8z5h", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8z5h/monthly_general_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/11f8z5h/monthly_general_discussion/", "subreddit_subscribers": 91535, "created_utc": 1677690046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I went from actuarial consultant pushing Excel dashboards and munging data in R, to a Data Science consultant that played whatever roles that got me billable hours, mostly advanced analytics/dashboard building, and data engineering as it was always in demand. I worked a lot of hours and have been pretty good at keeping up with the cutting edge technology due to my 10 years of consulting experience.  Actuaries are praised for their statistical domain knowledge and (in prior years) their ability to process and analyze data. Insurance industry is huge and Actuaries are the best Excel Monkies you can find.\n\nThough my title has changed over the years, my day to day hasn't changed: someone has a problem and I have to solve it. The tools I use are bound to the stakeholder I'm working with and the timeline is yesterday. Reinforcements are unlikely on the way until I improve the bottom line. It's all about finding the bottlenecks in processes and either fixing it or proving it's not repairable and finding a path forward. It all comes down to money. Save us $200k a year and you can have a developer. If not, work more or sell more.\n\nData industry is constantly changes and best practices have gone out the window. Warehouse is not best practice and now Lakehouse architecture is best. Maybe custom isn't best and we need a platform. Project Managers have entered the industry and SCRUM and Story Grooming are trigger words for veterans. Titles on LinkedIn hardly make sense anymore and you can tell it doesn't make sense to whoever crafted the JD (ChatGPT prolly). \n\nThere's also a lot of merging data engineering with DevOps and companies that do not have a proper analytics practice may have Data Engineers working under Software Engineering. So there's been a lot more demand for people that have breadth instead of depth. How long will it take this new hire to get up to speed until we're not sinking more costs and stressing more people out by having an additional person to explain things to. It's less about the title and more about the person you're hiring. The unicorns are the ones that can adapt to new problems quickly and have enough experience to figure it out on their own with a properly scoped project.\n\nHas anyone else seen similar trends? If we had to recategorize data roles similar to software engineering, what would those titles be?\n\nFor instance, I now work as a Solution Architect which is a sexy ass title for someone in data, but meaningless outside of the industry cause there's no definition to what it means. I think it's very similar to a Software Arcitecht, if not a direct subset specific to data oriented field. Knowing all of the current best practices and technologies and knowing which parts are worth salvaging vs recreating and providing diagraming/documentation of the \"why\". I don't know Java and took a course on CS when a 125MB Flash drive that cost $60 and the school didn't have Wifi lol. But knowing whether we should use Python vs R vs Java vs Scala vs SQL and how much it's going to cost us per month to run all of these reports for a given periodicity is more valuable to a business than being able to create an algorithm that can create a palindrome.", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you consider a full stack data developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8txm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677689709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I went from actuarial consultant pushing Excel dashboards and munging data in R, to a Data Science consultant that played whatever roles that got me billable hours, mostly advanced analytics/dashboard building, and data engineering as it was always in demand. I worked a lot of hours and have been pretty good at keeping up with the cutting edge technology due to my 10 years of consulting experience.  Actuaries are praised for their statistical domain knowledge and (in prior years) their ability to process and analyze data. Insurance industry is huge and Actuaries are the best Excel Monkies you can find.&lt;/p&gt;\n\n&lt;p&gt;Though my title has changed over the years, my day to day hasn&amp;#39;t changed: someone has a problem and I have to solve it. The tools I use are bound to the stakeholder I&amp;#39;m working with and the timeline is yesterday. Reinforcements are unlikely on the way until I improve the bottom line. It&amp;#39;s all about finding the bottlenecks in processes and either fixing it or proving it&amp;#39;s not repairable and finding a path forward. It all comes down to money. Save us $200k a year and you can have a developer. If not, work more or sell more.&lt;/p&gt;\n\n&lt;p&gt;Data industry is constantly changes and best practices have gone out the window. Warehouse is not best practice and now Lakehouse architecture is best. Maybe custom isn&amp;#39;t best and we need a platform. Project Managers have entered the industry and SCRUM and Story Grooming are trigger words for veterans. Titles on LinkedIn hardly make sense anymore and you can tell it doesn&amp;#39;t make sense to whoever crafted the JD (ChatGPT prolly). &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also a lot of merging data engineering with DevOps and companies that do not have a proper analytics practice may have Data Engineers working under Software Engineering. So there&amp;#39;s been a lot more demand for people that have breadth instead of depth. How long will it take this new hire to get up to speed until we&amp;#39;re not sinking more costs and stressing more people out by having an additional person to explain things to. It&amp;#39;s less about the title and more about the person you&amp;#39;re hiring. The unicorns are the ones that can adapt to new problems quickly and have enough experience to figure it out on their own with a properly scoped project.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else seen similar trends? If we had to recategorize data roles similar to software engineering, what would those titles be?&lt;/p&gt;\n\n&lt;p&gt;For instance, I now work as a Solution Architect which is a sexy ass title for someone in data, but meaningless outside of the industry cause there&amp;#39;s no definition to what it means. I think it&amp;#39;s very similar to a Software Arcitecht, if not a direct subset specific to data oriented field. Knowing all of the current best practices and technologies and knowing which parts are worth salvaging vs recreating and providing diagraming/documentation of the &amp;quot;why&amp;quot;. I don&amp;#39;t know Java and took a course on CS when a 125MB Flash drive that cost $60 and the school didn&amp;#39;t have Wifi lol. But knowing whether we should use Python vs R vs Java vs Scala vs SQL and how much it&amp;#39;s going to cost us per month to run all of these reports for a given periodicity is more valuable to a business than being able to create an algorithm that can create a palindrome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f8txm", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8txm/what_do_you_consider_a_full_stack_data_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f8txm/what_do_you_consider_a_full_stack_data_developer/", "subreddit_subscribers": 91535, "created_utc": 1677689709.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I want to write some Medium articles around Data Engineering, talking about Architecture concepts and technologies. What do you think would be relevant topics for beginners as well as mid level DE?\n\nThanks in advance", "author_fullname": "t2_9amrsuus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE articles for beginners and mid-level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f0a8b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I want to write some Medium articles around Data Engineering, talking about Architecture concepts and technologies. What do you think would be relevant topics for beginners as well as mid level DE?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f0a8b", "is_robot_indexable": true, "report_reasons": null, "author": "dmborges", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0a8b/de_articles_for_beginners_and_midlevel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0a8b/de_articles_for_beginners_and_midlevel/", "subreddit_subscribers": 91535, "created_utc": 1677666230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw there is \u201chive\u201d partitions format that is like \u201cyear=2023/month=3/day=1\u201d but also \u201c2023/3/1\u201d. What are the benefits/which one is the most common and preferred? I guess the Hive one as Hive metastore is often used for tools like Databricks delta lake, Trino etc.?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lake partitions format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f3hpt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677676492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw there is \u201chive\u201d partitions format that is like \u201cyear=2023/month=3/day=1\u201d but also \u201c2023/3/1\u201d. What are the benefits/which one is the most common and preferred? I guess the Hive one as Hive metastore is often used for tools like Databricks delta lake, Trino etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f3hpt", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f3hpt/data_lake_partitions_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f3hpt/data_lake_partitions_format/", "subreddit_subscribers": 91535, "created_utc": 1677676492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can somebody explain these two terms in as simple words as possible. New to the field", "author_fullname": "t2_66513e19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is an enterprise data platform and enterprise data catalogue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eonaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677629679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody explain these two terms in as simple words as possible. New to the field&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11eonaj", "is_robot_indexable": true, "report_reasons": null, "author": "nikiii_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eonaj/what_is_an_enterprise_data_platform_and/", "subreddit_subscribers": 91535, "created_utc": 1677629679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a junior data scientist working on predictive modelling for a small international company, I come to notice that my company has no data management or wtsoever. Everything is stored in Excel with different formats and the worst part is that they are now rolling out products of real-time monitoring with no insights or intention to manage the data. And then they are expecting me to work on the modeling in this shitty situation and ends up most of my work time is spent on cleaning and combining the data. And from what I heard, this happens to almost all departments around the company.\n\nIt is a good opportunity for me to pitch an idea for proper data management/warehousing to the management team. Not only will this make me more experienced in data engineering, it can gain me more bargaining power for asking higher position (e.g. management role)/salary.\n\nHowever, I have no practical experience in setting up data management system/warehouse. I wonder if you guys had any suggestions/resource to recommend? \n\nAs a small company of 500ppl, I also wonder if just a SQL system would already work?", "author_fullname": "t2_tdxm4fbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resources to learn/ Suggestions to set up the data management system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f0ex9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a junior data scientist working on predictive modelling for a small international company, I come to notice that my company has no data management or wtsoever. Everything is stored in Excel with different formats and the worst part is that they are now rolling out products of real-time monitoring with no insights or intention to manage the data. And then they are expecting me to work on the modeling in this shitty situation and ends up most of my work time is spent on cleaning and combining the data. And from what I heard, this happens to almost all departments around the company.&lt;/p&gt;\n\n&lt;p&gt;It is a good opportunity for me to pitch an idea for proper data management/warehousing to the management team. Not only will this make me more experienced in data engineering, it can gain me more bargaining power for asking higher position (e.g. management role)/salary.&lt;/p&gt;\n\n&lt;p&gt;However, I have no practical experience in setting up data management system/warehouse. I wonder if you guys had any suggestions/resource to recommend? &lt;/p&gt;\n\n&lt;p&gt;As a small company of 500ppl, I also wonder if just a SQL system would already work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f0ex9", "is_robot_indexable": true, "report_reasons": null, "author": "Delay_no_more_1999", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0ex9/any_good_resources_to_learn_suggestions_to_set_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0ex9/any_good_resources_to_learn_suggestions_to_set_up/", "subreddit_subscribers": 91535, "created_utc": 1677666715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Deequ is library for data [quality](https://github.com/awslabs/deequ)\n\nIn my org we are looking at using Deequ for data quality and I\u2019m looking for feedback from people that used it in production. I\u2019m basically interested in the limitations that you had with the framework and your use cases.\n\nBelow are some example of limitations we found:\n\n**1) Metrics modelization:**\n\nThe kind of metrics that can be extracted by Deequ is limited. There are only[ three](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/metrics/Metric.scala#L39):\n\n1. DoubleMetric\n2. HistorgramMetric\n3. KLLMetric\n\nWhich makes it difficult to have the min/max for non numerical columns. Hence this[ issue](https://github.com/awslabs/deequ/issues/47)\n\n**2) Inability to add custom Analyzers**\n\nThere is a finite set of[ Analyzers](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L228-L354) and there is no possibility for users to extend and create their own. If you try you will trigger an exception[ here](https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L353). Did you ever want to extend and create your own analyzer ? Or did you always manage to express your use case using the set of existing ones ?\n\n**Runner:**\n\nDeequ uses Spark as a backend to compute the metrics but did you try to use another runner ? By using I mean re-implementing Deequ but this time with Snowflake as a runner for example ?\n\nIf not, how were you computing data quality that existed in some data stores like: Snowflake, BigQuery ? Was it efficient with Spark (since you were relying on the spark connector of the data store)\n\nAnd more generally what are the features that you missed ? For which use case ?\n\nThank you", "author_fullname": "t2_to6i6cdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Data Quality] Deequ Feedback request", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ezqft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677664203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deequ is library for data &lt;a href=\"https://github.com/awslabs/deequ\"&gt;quality&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In my org we are looking at using Deequ for data quality and I\u2019m looking for feedback from people that used it in production. I\u2019m basically interested in the limitations that you had with the framework and your use cases.&lt;/p&gt;\n\n&lt;p&gt;Below are some example of limitations we found:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1) Metrics modelization:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The kind of metrics that can be extracted by Deequ is limited. There are only&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/metrics/Metric.scala#L39\"&gt; three&lt;/a&gt;:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;DoubleMetric&lt;/li&gt;\n&lt;li&gt;HistorgramMetric&lt;/li&gt;\n&lt;li&gt;KLLMetric&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which makes it difficult to have the min/max for non numerical columns. Hence this&lt;a href=\"https://github.com/awslabs/deequ/issues/47\"&gt; issue&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2) Inability to add custom Analyzers&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There is a finite set of&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L228-L354\"&gt; Analyzers&lt;/a&gt; and there is no possibility for users to extend and create their own. If you try you will trigger an exception&lt;a href=\"https://github.com/awslabs/deequ/blob/310f40056c3787f2ff05e73533e79446b1eefa44/src/main/scala/com/amazon/deequ/repository/AnalysisResultSerde.scala#L353\"&gt; here&lt;/a&gt;. Did you ever want to extend and create your own analyzer ? Or did you always manage to express your use case using the set of existing ones ?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Runner:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Deequ uses Spark as a backend to compute the metrics but did you try to use another runner ? By using I mean re-implementing Deequ but this time with Snowflake as a runner for example ?&lt;/p&gt;\n\n&lt;p&gt;If not, how were you computing data quality that existed in some data stores like: Snowflake, BigQuery ? Was it efficient with Spark (since you were relying on the spark connector of the data store)&lt;/p&gt;\n\n&lt;p&gt;And more generally what are the features that you missed ? For which use case ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?auto=webp&amp;v=enabled&amp;s=39f1d29001f32fb2860ebdd3067d9b217115eec0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f16968a00aefa288a8ccc2b2d16157fa238e229", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7835fff6e02f544a2e31e78fb0a4d010b307ceeb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc546f714b1b4accc49831c7e7911c2ccb834ac5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7714f0e33cf2f6db8d862b772e4166b71568e508", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1b95e87f60f2f1dbd3b670497244527a9575cf", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1TNzwU-svesGK99ylSh36sDl3oVbT4VJpjxBAaLLbsg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=615451807407c9c22197cc8107c8c44908831297", "width": 1080, "height": 540}], "variants": {}, "id": "45pC0WwUfD77oMIqZiiY0GY1lKDHLoN48Ti27hzjT2Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ezqft", "is_robot_indexable": true, "report_reasons": null, "author": "LabAway8794", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ezqft/data_quality_deequ_feedback_request/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ezqft/data_quality_deequ_feedback_request/", "subreddit_subscribers": 91535, "created_utc": 1677664203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you live in Europe, please help with a vote. I'm genuinely interested in where you search for Data Engineering jobs. Is there a difference between employment and freelancing regarding where you search? \n\n[View Poll](https://www.reddit.com/poll/11ez5ic)", "author_fullname": "t2_4g5nylle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you search for Data Engineering jobs in Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ez5ic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677661996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you live in Europe, please help with a vote. I&amp;#39;m genuinely interested in where you search for Data Engineering jobs. Is there a difference between employment and freelancing regarding where you search? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11ez5ic\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11ez5ic", "is_robot_indexable": true, "report_reasons": null, "author": "trendydots", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1677921196393, "options": [{"text": "Social networks (Linkeding, Xing, etc.)", "id": "21841261"}, {"text": "Dedicated job boards (Websites with only data jobs in EU)", "id": "21841262"}, {"text": "Reverse jobs search (Companies that search jobs for you)", "id": "21841263"}, {"text": "Show results", "id": "21841264"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 68, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ez5ic/where_do_you_search_for_data_engineering_jobs_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11ez5ic/where_do_you_search_for_data_engineering_jobs_in/", "subreddit_subscribers": 91535, "created_utc": 1677661996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a scenario where we manage 2 separate DBs, one on Europe and one in the US.\nThose DBs are then replicated and transformed using ELT practices.\n\nCurrently they use a set of transformations that makes them SEPARATELY analysis ready. If we want to check something across both regions, we have to perform unions of tables before.\n\nIs there a good practice as to how to manage those? Unioning every time feels kind of counter productive.\n\nI thought perhaps we can create a dataset for unioned data as views or even as tables that will update once in a while, and whenever we need both origins, query those. Is that relevant?\n\nI'd appreciate any tips for that!", "author_fullname": "t2_7tujv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to properly manage multiple regions of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ewdgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677651871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a scenario where we manage 2 separate DBs, one on Europe and one in the US.\nThose DBs are then replicated and transformed using ELT practices.&lt;/p&gt;\n\n&lt;p&gt;Currently they use a set of transformations that makes them SEPARATELY analysis ready. If we want to check something across both regions, we have to perform unions of tables before.&lt;/p&gt;\n\n&lt;p&gt;Is there a good practice as to how to manage those? Unioning every time feels kind of counter productive.&lt;/p&gt;\n\n&lt;p&gt;I thought perhaps we can create a dataset for unioned data as views or even as tables that will update once in a while, and whenever we need both origins, query those. Is that relevant?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any tips for that!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ewdgo", "is_robot_indexable": true, "report_reasons": null, "author": "qrixten", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ewdgo/how_to_properly_manage_multiple_regions_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ewdgo/how_to_properly_manage_multiple_regions_of_data/", "subreddit_subscribers": 91535, "created_utc": 1677651871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?\n\nWe load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.\n\nIf we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?\n\nI know dbt is the popular solution here but management has dictated only official AWS products may be used.", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glue for ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ellex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677622213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something I can\u2019t get a clear answer on\u2026 is Spark/Glue suitable for ELT work? Or just ETL?&lt;/p&gt;\n\n&lt;p&gt;We load our source data into Redshift and are now looking to build datamarts in the same Redshift cluster. All easy SQL work, no external APIs or complex transforms needed.&lt;/p&gt;\n\n&lt;p&gt;If we built the staging to datamart ETL in Glue, would it shuffle the data out of Redshift (incurring additional overhead) or will it recognize that source and target are the same cluster and orchestrate the movement with Redshift?&lt;/p&gt;\n\n&lt;p&gt;I know dbt is the popular solution here but management has dictated only official AWS products may be used.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ellex", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ellex/glue_for_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ellex/glue_for_elt/", "subreddit_subscribers": 91535, "created_utc": 1677622213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?", "author_fullname": "t2_2vnue5gp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a realtime firebase data and want each collection as a separate table in BigQuery for analysis, what is the best way to do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11eiclj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677614622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One way I can think of doing this is exporting the database to Google Cloud Storage as a JSON and write the collections in this JSON as separate tables to BigQuery. However, does anyone have experience with doing this same process or achieving the goal in a different way (maybe without writing any code)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11eiclj", "is_robot_indexable": true, "report_reasons": null, "author": "blackfrwhite", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11eiclj/i_have_a_realtime_firebase_data_and_want_each/", "subreddit_subscribers": 91535, "created_utc": 1677614622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a project to make sure that our database is always in sync across the 3 environments (DEV, QA, PROD) and I was wondering, if you use snowflake, how do you keep your database in sync across the 3 environments? \n\nDo you just copy all the files from the S3 Bucket for PROD to the S3 buckets for DEV &amp; QA and run your ETL/ELT for each environment every day?", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep DEV, QA, &amp; PROD environments in Sync in Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11fa0gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677692425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a project to make sure that our database is always in sync across the 3 environments (DEV, QA, PROD) and I was wondering, if you use snowflake, how do you keep your database in sync across the 3 environments? &lt;/p&gt;\n\n&lt;p&gt;Do you just copy all the files from the S3 Bucket for PROD to the S3 buckets for DEV &amp;amp; QA and run your ETL/ELT for each environment every day?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fa0gx", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fa0gx/how_to_keep_dev_qa_prod_environments_in_sync_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fa0gx/how_to_keep_dev_qa_prod_environments_in_sync_in/", "subreddit_subscribers": 91535, "created_utc": 1677692425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a developer, you're no stranger to the challenges of creating a cohesive API from multiple microservices. Here is our approach: [https://getdozer.io/blog/microservices-unified-apis](https://getdozer.io/blog/microservices-unified-apis)", "author_fullname": "t2_5efs1s7d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking down microservices silos: Building real-time cohesive APIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f6sxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677684903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a developer, you&amp;#39;re no stranger to the challenges of creating a cohesive API from multiple microservices. Here is our approach: &lt;a href=\"https://getdozer.io/blog/microservices-unified-apis\"&gt;https://getdozer.io/blog/microservices-unified-apis&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?auto=webp&amp;v=enabled&amp;s=8058360680a2eaf0a9a8e66f6f4b9c8cf7aacf21", "width": 1713, "height": 860}, "resolutions": [{"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6359f908e37c8cd7ad413220e96447540bef93a1", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1496d50902b71e2a78e845c084696b71bc472e49", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ece404d471906106d51094d57c684bc38118af9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=948ecd923bd96b752017189cc7b6e1b76c605724", "width": 640, "height": 321}, {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7014a2e13cda5e9d2506babd19d410fbdd43c031", "width": 960, "height": 481}, {"url": "https://external-preview.redd.it/_4rg0b-T_DogQevtSbPi24hXrApQZGUkWJ84TSgPK2U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8169b64e981b47135bbfbed882324d8d1f90058", "width": 1080, "height": 542}], "variants": {}, "id": "dwFeGpOqNXM5F5FZr1zlZYnK40Qt1KpA7_2cBWqHgTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f6sxk", "is_robot_indexable": true, "report_reasons": null, "author": "matteopelati76", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f6sxk/breaking_down_microservices_silos_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f6sxk/breaking_down_microservices_silos_building/", "subreddit_subscribers": 91535, "created_utc": 1677684903.0, "num_crossposts": 6, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11f44qq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VC04oAHnrxPHHD_ivI1peKUMpIzZoshL2eq2zeMRRn4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677678272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?auto=webp&amp;v=enabled&amp;s=6763ef0071a893ed732b2a289485d0bdf0e98618", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=506669e8aba350ec60db312a299d11d854854ce0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a68bb5121d235cf07cbe7a8cf9bbd4eec717f061", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c7b2aef8c79fed9b52ddfa1562b3c869e97076", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a26d98a4fc7fa34d512862b1611b96d81a02dd61", "width": 640, "height": 336}], "variants": {}, "id": "JGhC9b9qhHNJ4eh7-qMHVcYJNdZfz1K-5VoSz-ZvhQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f44qq", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f44qq/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 91535, "created_utc": 1677678272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have large amounts of data on postgres dbs that we would like to aggregate and show to customers on the website (with some dimensions splits and filters). The aggregations can be heavy queries. \n\nWhat are the best technologies that are used these days to provide this? Do data engineers use cloud data tools for these kind of \"production\" calculations?   \nWe already have a modern data stack for internal analytics, so I'm wondering if we can leverage that in our production pipeline as well, or if that's regarded bad practice.\n\nTIA", "author_fullname": "t2_7hc6xuzu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which technologies are best to show data aggregations to customers in production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f0dmn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677666594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have large amounts of data on postgres dbs that we would like to aggregate and show to customers on the website (with some dimensions splits and filters). The aggregations can be heavy queries. &lt;/p&gt;\n\n&lt;p&gt;What are the best technologies that are used these days to provide this? Do data engineers use cloud data tools for these kind of &amp;quot;production&amp;quot; calculations?&lt;br/&gt;\nWe already have a modern data stack for internal analytics, so I&amp;#39;m wondering if we can leverage that in our production pipeline as well, or if that&amp;#39;s regarded bad practice.&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11f0dmn", "is_robot_indexable": true, "report_reasons": null, "author": "Environmental_Hat911", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f0dmn/which_technologies_are_best_to_show_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f0dmn/which_technologies_are_best_to_show_data/", "subreddit_subscribers": 91535, "created_utc": 1677666594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're moving away from Snowflake. We'd like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.\n\nI have several questions and I'd appreciate any help on any of them.\n\n1. Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, `{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/` for IoT device data, which is similar to our use case. Right?\n\n2. Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it's columnar/compression properties. Right?\n\n3. What options do we have for getting historical data currently in SF into this format and moving it over efficiently?\n\n4. Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? \n\n5. Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We've never used it. \n\n6. Should we use Synapse, do you \"load\" all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. \n\nAgain, thanks for any help.", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on our migration to a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11emsf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677625075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re moving away from Snowflake. We&amp;#39;d like to use a data lake paradigm and will be using Azure. The Snowflake instance was not in Azure before.&lt;/p&gt;\n\n&lt;p&gt;I have several questions and I&amp;#39;d appreciate any help on any of them.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded into the lake ought to conform to a directory structure from the very beginning. MS recommends something like, &lt;code&gt;{Region}/{SubjectMatter(s)}/{yyyy}/{mm}/{dd}/{hh}/&lt;/code&gt; for IoT device data, which is similar to our use case. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any data loaded should be in a columnar format like parquet or avro for its meta-data properties and it&amp;#39;s columnar/compression properties. Right?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What options do we have for getting historical data currently in SF into this format and moving it over efficiently?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Our source data is in a MongoDB instance. A Python workflow reads from it, does some basic parsing/formatting, writes a csv to S3, which then triggers Snowpipe for load. A rewrite of this should allow the same process but would write parquet to the data lake instead. Is there a better option? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Recommendations for the query engine on top of the data lake? Seems like Synapse is the default. But We&amp;#39;ve never used it. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should we use Synapse, do you &amp;quot;load&amp;quot; all data lake data into it and then model to your marts? Or do you need to use some other tool to create bronze, silver, gold in the data lake and load those? Im not sure if this question even makes sense since idk how Synapse reads from data lake but my point is that this step is murky. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Again, thanks for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11emsf6", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11emsf6/feedback_on_our_migration_to_a_data_lake/", "subreddit_subscribers": 91535, "created_utc": 1677625075.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}