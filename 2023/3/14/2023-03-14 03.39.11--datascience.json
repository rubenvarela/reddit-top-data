{"kind": "Listing", "data": {"after": "t3_11q9s7y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It's really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.\n\nFor the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.\n\nEvery day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn't. I kept procrastinating.\n\nI was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, \"One last test,\" and that's when I accidentally deleted all my code.\n\nThe main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that's how I lost everything.\n\nI was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn't. Now, I don't even feel like coding anymore.\n\n(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, \"What could go wrong?\")", "author_fullname": "t2_a7urc8tl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost it all.... in a sec!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q1hz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 144, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 144, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678686643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s really sad and frustrating to lose so much hard work and a possible opportunity due to a stupid mistake.&lt;/p&gt;\n\n&lt;p&gt;For the past six days, I have been working day and night on developing an entire data streaming system using Docker (from streaming APIs and Kafka consumers/producers to the MLspark model). This was a task for a company I am interviewing with for a big data engineering position.&lt;/p&gt;\n\n&lt;p&gt;Every day, I told myself I needed to start a repository or back up the code somewhere, but for an unknown reason, I didn&amp;#39;t. I kept procrastinating.&lt;/p&gt;\n\n&lt;p&gt;I was so excited to finish the project and share it with the interviewer on GitHub as soon as possible. But I told myself, &amp;quot;One last test,&amp;quot; and that&amp;#39;s when I accidentally deleted all my code.&lt;/p&gt;\n\n&lt;p&gt;The main project directory was mounted by the Docker Spark container, which would write the output to the folder provided. However, it needed to remove or empty everything in the provided directory before writing. And that&amp;#39;s how I lost everything.&lt;/p&gt;\n\n&lt;p&gt;I was so pissed off and spent three hours trying different methods to retrieve my work, but I couldn&amp;#39;t. Now, I don&amp;#39;t even feel like coding anymore.&lt;/p&gt;\n\n&lt;p&gt;(Note: I know I should have versioned the code with Git, which I usually do. But this time, I thought, &amp;quot;What could go wrong?&amp;quot;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q1hz2", "is_robot_indexable": true, "report_reasons": null, "author": "Taylankab", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q1hz2/lost_it_all_in_a_sec/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q1hz2/lost_it_all_in_a_sec/", "subreddit_subscribers": 856883, "created_utc": 1678686643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been in the Accounting/Business Operations field for my entire adult life, since graduating with a BBA from Texas A&amp;M. My Accounting Degree emphasis was in Business Analysis, so I learned Fortran and COBOL, and now want to pivot to Data Science. \n\nHaving just started learning Python, I am curious what job/career opportunities I might have once I have completed the certification process. While many individuals at my age may have or be considering retirement, I do not plan to retire anytime soon as I want to keep learning and applying those skills as long as I am able to do so. \n\nMy plan is to work in a remote position in the Data Science/Data Analysis field.\n\nI am looking for feedback as to if my goals and aspirations are realistic.   \nThanks in advance for your input.", "author_fullname": "t2_6sij3e6oe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Changing career at age 62\u2026 is it even possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qrs41", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678755205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been in the Accounting/Business Operations field for my entire adult life, since graduating with a BBA from Texas A&amp;amp;M. My Accounting Degree emphasis was in Business Analysis, so I learned Fortran and COBOL, and now want to pivot to Data Science. &lt;/p&gt;\n\n&lt;p&gt;Having just started learning Python, I am curious what job/career opportunities I might have once I have completed the certification process. While many individuals at my age may have or be considering retirement, I do not plan to retire anytime soon as I want to keep learning and applying those skills as long as I am able to do so. &lt;/p&gt;\n\n&lt;p&gt;My plan is to work in a remote position in the Data Science/Data Analysis field.&lt;/p&gt;\n\n&lt;p&gt;I am looking for feedback as to if my goals and aspirations are realistic.&lt;br/&gt;\nThanks in advance for your input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qrs41", "is_robot_indexable": true, "report_reasons": null, "author": "DjAggie90", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qrs41/changing_career_at_age_62_is_it_even_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qrs41/changing_career_at_age_62_is_it_even_possible/", "subreddit_subscribers": 856883, "created_utc": 1678755205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, \n\nRecently I increasingly came across unit testing for data science projects. So far I am roughly familiar with the concept, even though we are not using it at all in the whole department. I would like to properly set up a unit testing framework for my department, especially because we have a lot of stats heavy and code light people in our team. \n\nOne thing I haven't properly understood yet, we are working with quite an amount of data which is normally a piece of garbage and we have to do a lot of preprocessing in order to make it clean. How would you set up in such an environment (very long runtimes for data preparation due to large data) a unit testing framework, since I can not run multiple parameter settings to test somethings because it will just take too long.\n\nThanks a lot in advance, this post here should not only be an question but more a discussion of unit testing in general. \n\nPaul", "author_fullname": "t2_60p6w78m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unit Testing for Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q3qa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678694815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;Recently I increasingly came across unit testing for data science projects. So far I am roughly familiar with the concept, even though we are not using it at all in the whole department. I would like to properly set up a unit testing framework for my department, especially because we have a lot of stats heavy and code light people in our team. &lt;/p&gt;\n\n&lt;p&gt;One thing I haven&amp;#39;t properly understood yet, we are working with quite an amount of data which is normally a piece of garbage and we have to do a lot of preprocessing in order to make it clean. How would you set up in such an environment (very long runtimes for data preparation due to large data) a unit testing framework, since I can not run multiple parameter settings to test somethings because it will just take too long.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance, this post here should not only be an question but more a discussion of unit testing in general. &lt;/p&gt;\n\n&lt;p&gt;Paul&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q3qa5", "is_robot_indexable": true, "report_reasons": null, "author": "Habenzu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q3qa5/unit_testing_for_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q3qa5/unit_testing_for_big_data/", "subreddit_subscribers": 856883, "created_utc": 1678694815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing confidenceinterval, the long missing python library for computing confidence intervals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q5bps", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_k8k9b", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "[https://github.com/jacobgil/confidenceinterval](https://github.com/jacobgil/confidenceinterval)\n\npip install confidenceinterval\n\ntldr: You don't have an excuse anymore to not use confidence intervals !\n\n&amp;#x200B;\n\nIn statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.\n\nFor example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range \\[0.7, 0.96\\], we can't confidently say we didn't just get lucky - we should be really careful making decisions around that result.\n\nMore formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.\n\nConfidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.\n\nHowever, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don't come from the statistics world. But I think the main reason is that there aren't easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.\n\n&amp;#x200B;\n\nThe confidenceinterval package keeps the clean and popular scikit-learn metric API,\n\ne.g roc\\_auc\\_score(y\\_true, y\\_pred), but also returns confidence intervals.\n\nIt supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2), or binary proportions like the TPR using binomial CI methods like the wilson interval).\n\nIt can be easily switched to using bootstrapping (with several supported bootstrapping methods),\n\nand also gives you a way to easily compute the confidence interval for any metric with bootstrapping.", "author_fullname": "t2_k8k9b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Introducing confidenceinterval, the long missing python library for computing confidence intervals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "four", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11orezx", "quarantine": false, "link_flair_text_color": null, "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 114, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 114, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678561930.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678559767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/jacobgil/confidenceinterval\"&gt;https://github.com/jacobgil/confidenceinterval&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;pip install confidenceinterval&lt;/p&gt;\n\n&lt;p&gt;tldr: You don&amp;#39;t have an excuse anymore to not use confidence intervals !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.&lt;/p&gt;\n\n&lt;p&gt;For example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range [0.7, 0.96], we can&amp;#39;t confidently say we didn&amp;#39;t just get lucky - we should be really careful making decisions around that result.&lt;/p&gt;\n\n&lt;p&gt;More formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.&lt;/p&gt;\n\n&lt;p&gt;Confidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.&lt;/p&gt;\n\n&lt;p&gt;However, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don&amp;#39;t come from the statistics world. But I think the main reason is that there aren&amp;#39;t easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The confidenceinterval package keeps the clean and popular scikit-learn metric API,&lt;/p&gt;\n\n&lt;p&gt;e.g roc_auc_score(y_true, y_pred), but also returns confidence intervals.&lt;/p&gt;\n\n&lt;p&gt;It supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from &lt;a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2\"&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2&lt;/a&gt;, or binary proportions like the TPR using binomial CI methods like the wilson interval).&lt;/p&gt;\n\n&lt;p&gt;It can be easily switched to using bootstrapping (with several supported bootstrapping methods),&lt;/p&gt;\n\n&lt;p&gt;and also gives you a way to easily compute the confidence interval for any metric with bootstrapping.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?auto=webp&amp;v=enabled&amp;s=a5d2ecdd7772d8bc508c6c31bf66a3ebf6a36f9b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84265ed517381e53abccab809f4457681fe3c639", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bb99fba7a31874d7c683916fa1cefb7bc3e50b9", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17b19e9c1fe0d262fc2327c44dd600b13b7e0db4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f49c39b998f64942a836cf968ffa02593e39f60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f1484661166648bac2efcb4bb90c0fd6d50b6b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b33e1ea5932c8029ec48c2f1082eca2001226aac", "width": 1080, "height": 540}], "variants": {}, "id": "VEtVW8Q9v0zCOQrmkPZvdkf-myANUJNotk7vDz0TFtA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11orezx", "is_robot_indexable": true, "report_reasons": null, "author": "jacobgil", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "subreddit_subscribers": 2598220, "created_utc": 1678559767.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678700803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?auto=webp&amp;v=enabled&amp;s=a5d2ecdd7772d8bc508c6c31bf66a3ebf6a36f9b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84265ed517381e53abccab809f4457681fe3c639", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bb99fba7a31874d7c683916fa1cefb7bc3e50b9", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17b19e9c1fe0d262fc2327c44dd600b13b7e0db4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f49c39b998f64942a836cf968ffa02593e39f60", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12f1484661166648bac2efcb4bb90c0fd6d50b6b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/CROI3aTcH3zmr0jZ1tMPkj12KS9h-bmcBzIW_MdSL6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b33e1ea5932c8029ec48c2f1082eca2001226aac", "width": 1080, "height": 540}], "variants": {}, "id": "VEtVW8Q9v0zCOQrmkPZvdkf-myANUJNotk7vDz0TFtA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q5bps", "is_robot_indexable": true, "report_reasons": null, "author": "jacobgil", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11orezx", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q5bps/introducing_confidenceinterval_the_long_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/", "subreddit_subscribers": 856883, "created_utc": 1678700803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_p54xpfwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Turn text into flowcharts with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 135, "top_awarded_type": null, "hide_score": false, "name": "t3_11q8c09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rP99Yi2JpBBcaiRUtJ_8MYW8VNvC3TlKby9Wiq8018k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678710496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kogrkirk2ina1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kogrkirk2ina1.png?auto=webp&amp;v=enabled&amp;s=f4a6b2d85ee45fa3354ef893206d1b1b088b2bf2", "width": 1780, "height": 1728}, "resolutions": [{"url": "https://preview.redd.it/kogrkirk2ina1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6afdfe9b7a667d5bdfff4a63943c7be52d96f02b", "width": 108, "height": 104}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ab5b1c6d61fb094ceb9101b285ae36fdb055769", "width": 216, "height": 209}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2484d4258286164e7070c6d50546927a4ab6db5e", "width": 320, "height": 310}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0504f64ff6c0874f33a8190d475e53e06e4783e5", "width": 640, "height": 621}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1991684d5772469a97270abb46b4e8a4ad3700a", "width": 960, "height": 931}, {"url": "https://preview.redd.it/kogrkirk2ina1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04fa203c1b43822c47e00730d2b263c35db26ff6", "width": 1080, "height": 1048}], "variants": {}, "id": "lTZ8q2byhJItaaGNdPbIbRcZCU0ORcVZWbaCfMBuWbo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q8c09", "is_robot_indexable": true, "report_reasons": null, "author": "colabDog", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q8c09/turn_text_into_flowcharts_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kogrkirk2ina1.png", "subreddit_subscribers": 856883, "created_utc": 1678710496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there, I\u2019m in a very fortunate position; I\u2019ve been accepted into two different Masters programs for the upcoming 2023 school year. \n\nThe first, [UBC-Okanagan Master of Data Science](https://masterdatascience.ubc.ca/programs/okanagan)\n\nThe second, [Queen\u2019s Master of Biomedical Informatics](https://www.cs.queensu.ca/graduate/bmif/)\n\nI recently completed my undergrad in Honours Life Sci. I\u2019ve also developed modest coding knowledge with Google Coursera and DataCamp, mainly focusing on Python (pandas, matplotlib, numpy), but some focus on SQL and R. \n\nI love bio \u2014 it\u2019s been a dream to use science to help people since I can remember having career aspirations. The field of Bioinformatics feels like a great fit for me. However, I\u2019m concerned that a CS-focused Masters in Data Science will functionally open many more doors for me, with my undergrad in bio providing enough evidence that I\u2019m capable of a Bioinformatics role. \n\nI\u2019ve been wrestling with this decision, listed pros/cons, and spoken to friends and family. The two programs are similar in content, length and most other metrics. \n\nThank you very much for your time, and I\u2019d be happy to provide any additional context. Have a great day!", "author_fullname": "t2_mp632", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ms. Data Science vs Ms. Biomedical Informatics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qplyn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678749986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I\u2019m in a very fortunate position; I\u2019ve been accepted into two different Masters programs for the upcoming 2023 school year. &lt;/p&gt;\n\n&lt;p&gt;The first, &lt;a href=\"https://masterdatascience.ubc.ca/programs/okanagan\"&gt;UBC-Okanagan Master of Data Science&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The second, &lt;a href=\"https://www.cs.queensu.ca/graduate/bmif/\"&gt;Queen\u2019s Master of Biomedical Informatics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I recently completed my undergrad in Honours Life Sci. I\u2019ve also developed modest coding knowledge with Google Coursera and DataCamp, mainly focusing on Python (pandas, matplotlib, numpy), but some focus on SQL and R. &lt;/p&gt;\n\n&lt;p&gt;I love bio \u2014 it\u2019s been a dream to use science to help people since I can remember having career aspirations. The field of Bioinformatics feels like a great fit for me. However, I\u2019m concerned that a CS-focused Masters in Data Science will functionally open many more doors for me, with my undergrad in bio providing enough evidence that I\u2019m capable of a Bioinformatics role. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been wrestling with this decision, listed pros/cons, and spoken to friends and family. The two programs are similar in content, length and most other metrics. &lt;/p&gt;\n\n&lt;p&gt;Thank you very much for your time, and I\u2019d be happy to provide any additional context. Have a great day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qplyn", "is_robot_indexable": true, "report_reasons": null, "author": "Nemesis104", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qplyn/ms_data_science_vs_ms_biomedical_informatics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qplyn/ms_data_science_vs_ms_biomedical_informatics/", "subreddit_subscribers": 856883, "created_utc": 1678749986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " my project about predicting used car prices. \n\nI have done feature selection, and also got the model from gridsearch.\n\n[this a based feature importances](https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb)\n\n&amp;#x200B;\n\n[this is permutation importances](https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719)\n\ni've read an article that permutation importance have disadvantage. \" **If features are correlated, the permutation feature importance** **can be biased by unrealistic data instances** \". Age and mileage  have a correlation of 0.7.\n\nThank You\n\n[https://christophm.github.io/interpretable-ml-book/feature-importance.html](https://christophm.github.io/interpretable-ml-book/feature-importance.html)", "author_fullname": "t2_lzfa50u3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use permutation importance or based feature importance GradientBoostingRegressor sklearn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8n17bm2vzfna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc1d54979f78c2d7658bf5d24b2c19a2c94ea23b"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95848852cf93b9ad4ad51e5a9d39447fca36603b"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=667d02fc49961e3f71d5a13d8f0d4ce56f80f7df"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cad10371dfcdb76ced1332711086141c63a7e73"}, {"y": 677, "x": 960, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c9952cd2b5f8b6ff1493477564e0b3a5beb8b15"}], "s": {"y": 700, "x": 992, "u": "https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb"}, "id": "8n17bm2vzfna1"}, "oq2chcq20gna1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 104, "x": 108, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3208d44c0c3d7c9831abc86a91a255196bde0679"}, {"y": 209, "x": 216, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1ebaf0146fc9811b478c4a214ab25aaa4b521f6"}, {"y": 309, "x": 320, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ea520a8367dfdd0b1014e7636423a2237c00eb7"}, {"y": 619, "x": 640, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41077a3503dafc782e566bd81729d1e4bba235b8"}], "s": {"y": 675, "x": 697, "u": "https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719"}, "id": "oq2chcq20gna1"}}, "name": "t3_11q1eaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7gNQ40M-aRjKtosn_vjyurTKB4hLCbQxmRgZigDikpk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678686269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my project about predicting used car prices. &lt;/p&gt;\n\n&lt;p&gt;I have done feature selection, and also got the model from gridsearch.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8n17bm2vzfna1.png?width=992&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c148dfe05a6e6909b6c26d46d739f9c103f142fb\"&gt;this a based feature importances&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oq2chcq20gna1.png?width=697&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6fde29ed1393b0bc0360982888ea6229b96ce719\"&gt;this is permutation importances&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;ve read an article that permutation importance have disadvantage. &amp;quot; &lt;strong&gt;If features are correlated, the permutation feature importance&lt;/strong&gt; &lt;strong&gt;can be biased by unrealistic data instances&lt;/strong&gt; &amp;quot;. Age and mileage  have a correlation of 0.7.&lt;/p&gt;\n\n&lt;p&gt;Thank You&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://christophm.github.io/interpretable-ml-book/feature-importance.html\"&gt;https://christophm.github.io/interpretable-ml-book/feature-importance.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q1eaw", "is_robot_indexable": true, "report_reasons": null, "author": "xochaels", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q1eaw/should_i_use_permutation_importance_or_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q1eaw/should_i_use_permutation_importance_or_based/", "subreddit_subscribers": 856883, "created_utc": 1678686269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a pandas dataframe that represents a time series. My time series is segmented over the phase type that the robot is performing (i.e. I have a column with the phase type per timestamp and the phases are known). Some easy examples: if the machine is cleaning something the phase is \"cleaning\", if It is moving the phase is \"moving\".\n\nI have no domain knowledge about the phase in which I am and the constraints in the value that each signal must respect. I am searching for rules with a certain confidence.\n\nI would like to say: I am in this phase, then from the data I have seen in the past, I know that for sure signal A will be less than signal B with 90% confidence. Or again, signal C should not be negative according to what I have seen in the past with 70% confidence. I want to extract historical simple rules that I would like to validate at the end of the process with a domain expert.\n\nIs there any library or method that can handle this type of problem? I didn't find much online. It seems like association rule mining, but I am working on time series and I am looking at time periods spanning the whole phase, so a very long time period.\n\nOtherwise, if I should pass from other methods as correlation/cross-correlation analysis between time series, can you point me out the best analysis I should use? And also explain to me how should I exploit my analysis result for transforming them into more simple rules like the one I have described before.", "author_fullname": "t2_i6lyoywf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mining association rules between time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qcrhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678722322.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678721342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pandas dataframe that represents a time series. My time series is segmented over the phase type that the robot is performing (i.e. I have a column with the phase type per timestamp and the phases are known). Some easy examples: if the machine is cleaning something the phase is &amp;quot;cleaning&amp;quot;, if It is moving the phase is &amp;quot;moving&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I have no domain knowledge about the phase in which I am and the constraints in the value that each signal must respect. I am searching for rules with a certain confidence.&lt;/p&gt;\n\n&lt;p&gt;I would like to say: I am in this phase, then from the data I have seen in the past, I know that for sure signal A will be less than signal B with 90% confidence. Or again, signal C should not be negative according to what I have seen in the past with 70% confidence. I want to extract historical simple rules that I would like to validate at the end of the process with a domain expert.&lt;/p&gt;\n\n&lt;p&gt;Is there any library or method that can handle this type of problem? I didn&amp;#39;t find much online. It seems like association rule mining, but I am working on time series and I am looking at time periods spanning the whole phase, so a very long time period.&lt;/p&gt;\n\n&lt;p&gt;Otherwise, if I should pass from other methods as correlation/cross-correlation analysis between time series, can you point me out the best analysis I should use? And also explain to me how should I exploit my analysis result for transforming them into more simple rules like the one I have described before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qcrhv", "is_robot_indexable": true, "report_reasons": null, "author": "ginotherhino1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qcrhv/mining_association_rules_between_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qcrhv/mining_association_rules_between_time_series/", "subreddit_subscribers": 856883, "created_utc": 1678721342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 13 Mar, 2023 - 20 Mar, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pzhux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678680088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11pzhux", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 27, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11pzhux/weekly_entering_transitioning_thread_13_mar_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/11pzhux/weekly_entering_transitioning_thread_13_mar_2023/", "subreddit_subscribers": 856883, "created_utc": 1678680088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know cost functions is a way to better fit your model to the training data and performance measure is to see how well the model generalize but for linear regression isn\u2019t rmse used as the cost function and the performance measure, isn\u2019t it the same mathematical formula? . I\u2019m just confused", "author_fullname": "t2_9ple7b7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello guys been trying to sleep but I can\u2019t cause the I\u2019m confused by cost function and performance measures what the difference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11pygyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678677066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know cost functions is a way to better fit your model to the training data and performance measure is to see how well the model generalize but for linear regression isn\u2019t rmse used as the cost function and the performance measure, isn\u2019t it the same mathematical formula? . I\u2019m just confused&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11pygyk", "is_robot_indexable": true, "report_reasons": null, "author": "Longjumping_Ad_7053", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11pygyk/hello_guys_been_trying_to_sleep_but_i_cant_cause/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11pygyk/hello_guys_been_trying_to_sleep_but_i_cant_cause/", "subreddit_subscribers": 856883, "created_utc": 1678677066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI or visualization in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11qtyh2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678760694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qtyh2", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qtyh2/power_bi_or_visualization_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qtyh2/power_bi_or_visualization_in_python/", "subreddit_subscribers": 856883, "created_utc": 1678760694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI had to leave my job due to some severe medical issues, and am still undergoing treatment for them and cannot currently work. I was working on Data Governance and Data Management before I had to quit, and I loved that line of work. I want to become an attorney in the field of data and information privacy, so I was set to do all sorts of trainings and have logged hours for certifications that would help me stand out as an attorney with data experience in the field.\n\nSince I am currently unemployed, I have a lot of free time and am looking to work on getting certified in things such as Data Governance, Data Management, Data Architecture, and Data Visualization. However, a lot of these certifications require logged hours, which usually would come from a job. \n\nHow can I work on these certifications without a job right now? And for any attorneys who may be in this subreddit, would these certifications even matter in the grand scheme of things?\n\nAny recommendations or advice would be greatly appreciated!\n\nEdit: Removed some personal information", "author_fullname": "t2_2a0jbore", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Becoming Certified While Unemployed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qdl0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678723714.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678723270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I had to leave my job due to some severe medical issues, and am still undergoing treatment for them and cannot currently work. I was working on Data Governance and Data Management before I had to quit, and I loved that line of work. I want to become an attorney in the field of data and information privacy, so I was set to do all sorts of trainings and have logged hours for certifications that would help me stand out as an attorney with data experience in the field.&lt;/p&gt;\n\n&lt;p&gt;Since I am currently unemployed, I have a lot of free time and am looking to work on getting certified in things such as Data Governance, Data Management, Data Architecture, and Data Visualization. However, a lot of these certifications require logged hours, which usually would come from a job. &lt;/p&gt;\n\n&lt;p&gt;How can I work on these certifications without a job right now? And for any attorneys who may be in this subreddit, would these certifications even matter in the grand scheme of things?&lt;/p&gt;\n\n&lt;p&gt;Any recommendations or advice would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Edit: Removed some personal information&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qdl0h", "is_robot_indexable": true, "report_reasons": null, "author": "cmondothefoxSWAT", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qdl0h/becoming_certified_while_unemployed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qdl0h/becoming_certified_while_unemployed/", "subreddit_subscribers": 856883, "created_utc": 1678723270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! \n\nI work in a company with a two-sided marketplace. One such as doordash or Uber.\n\nComing from an engineering background with stats, I am looking for sources that can help me be better at my job.\n\nI know this might be too ad hoc, but I really think knowledge from economy can help me and make me have a better background for my position.\n\nAny help is welcome!", "author_fullname": "t2_367xvs9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Econ knowledge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qardt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;I work in a company with a two-sided marketplace. One such as doordash or Uber.&lt;/p&gt;\n\n&lt;p&gt;Coming from an engineering background with stats, I am looking for sources that can help me be better at my job.&lt;/p&gt;\n\n&lt;p&gt;I know this might be too ad hoc, but I really think knowledge from economy can help me and make me have a better background for my position.&lt;/p&gt;\n\n&lt;p&gt;Any help is welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qardt", "is_robot_indexable": true, "report_reasons": null, "author": "Quentin-Martell", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qardt/looking_for_econ_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qardt/looking_for_econ_knowledge/", "subreddit_subscribers": 856883, "created_utc": 1678716608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/11qaizm)", "author_fullname": "t2_5njryk22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open-ended questions, and do feel free to comment your opinion on the matter below. But do you think that the launch of increasingly \"Smart\" AIs will be seen in the future as akin to the beginning of the industrial revolution (AKA a turning point in history) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qaizm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678716048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11qaizm\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11qaizm", "is_robot_indexable": true, "report_reasons": null, "author": "Oldthriftmaan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679148048207, "options": [{"text": "Yes", "id": "22042341"}, {"text": "No", "id": "22042342"}, {"text": "Nuance", "id": "22042343"}, {"text": "Something else (Comment)", "id": "22042344"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 83, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qaizm/openended_questions_and_do_feel_free_to_comment/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/11qaizm/openended_questions_and_do_feel_free_to_comment/", "subreddit_subscribers": 856883, "created_utc": 1678716048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Folks, \n\nI operate data science/data eng at a YC backed tech firm.  I've developed a good skillset in the past decade and want to start consulting/contracting for product analytics.   \nCurious to know how any freelancer/agency owners here started their journey, built clients etc.   \n\n\nCurrently trying to understand where to find clients open for outsourcing product analytics work. How do you go about it?", "author_fullname": "t2_4g2p0coqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting an analytics firm. Where to find clients?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11qul5w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678762419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Folks, &lt;/p&gt;\n\n&lt;p&gt;I operate data science/data eng at a YC backed tech firm.  I&amp;#39;ve developed a good skillset in the past decade and want to start consulting/contracting for product analytics.&lt;br/&gt;\nCurious to know how any freelancer/agency owners here started their journey, built clients etc.   &lt;/p&gt;\n\n&lt;p&gt;Currently trying to understand where to find clients open for outsourcing product analytics work. How do you go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qul5w", "is_robot_indexable": true, "report_reasons": null, "author": "jack_newman25", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qul5w/starting_an_analytics_firm_where_to_find_clients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qul5w/starting_an_analytics_firm_where_to_find_clients/", "subreddit_subscribers": 856883, "created_utc": 1678762419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Folks,  \nI am researching the challenges of engineering data products to develop a deeper understanding of the problems and challenges faced by the teams building data products.\n\nI used to be a data engineer between 2009 and 2014. In 2014, I got into product management and I am currently in a product lead role. I have always worked products which included a large amount of analytics, insights, predictive models, machine learning in software companies serving healthcare, surveillance, automotive, and ecommerce.\n\nIn my experience over the past 14 years, the data tooling ecosystem has expanded a lot.  \nHowever, I am still in a scenario where the cost of data infrastructure and tooling is expensive.\n\n* Projects are complex and long drawn.\n* It is super hard to solve basic issues of data quality even reactively.\n* Maintaining trust in the data assets is really hard.\n* Data literacy of decision makers is not up to the mark in a lot of cases.\n* Stakeholders expect miracles and stuff to just work.\n* Very few people can explain the attributes, the calculations, the metrics, the insights, and the implications.\n* Everyone is just promising stuff and punting the inevitable reality of face the hard problem and solve it properly.\n\nI am just trying to research and gather inputs from the community on the nagging challenges of building products now to inform my product development and to inform a course that I am building to develop data product managers (because it is really difficult to find candidates to hire)\n\nMy question for you is:\n\n* What are your top 3 challenges in engineering data flows and pipelines?  \n\n   * Is it the data inventory, quality, governance, accessibility, etc.?\n   * Is the infrastructure, the complexity of building, deploying, administering the systems?\n   * Is it the challenge of organizational structure, talent, capacity, leadership?\n   * Is it communication, silos, lack of alignment?\n   * Is it cost, performance, complexity of infrastructure?\n* What is preventing you from building valuable data products?\n\nFor me, infrastructure cost, performance of existing tools, spaghetti code, lack of data expertise among leadership stakeholders has been the biggest headwinds to progress.\n\nLast year, at one point, our AWS costs were $1.6 for every $1 a customer paid us. After working on a year and reducing substantial tech debt, we got to AWS cost of $0.6 for every $1 revenue. Still, there is no recognition, leadership is reluctant to fix data quality issues.\n\nAs a product lead, I have been able to influence some, but it's a lot of compounding challenges.\n\nDoes this resonate with folks?\n\nWhat are the top challenges you are facing?\n\nWhat are some solutions or workaround that have worked for you?\n\nLooking forward to your responses.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the sticky problems in your data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11quk66", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678762340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks,&lt;br/&gt;\nI am researching the challenges of engineering data products to develop a deeper understanding of the problems and challenges faced by the teams building data products.&lt;/p&gt;\n\n&lt;p&gt;I used to be a data engineer between 2009 and 2014. In 2014, I got into product management and I am currently in a product lead role. I have always worked products which included a large amount of analytics, insights, predictive models, machine learning in software companies serving healthcare, surveillance, automotive, and ecommerce.&lt;/p&gt;\n\n&lt;p&gt;In my experience over the past 14 years, the data tooling ecosystem has expanded a lot.&lt;br/&gt;\nHowever, I am still in a scenario where the cost of data infrastructure and tooling is expensive.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Projects are complex and long drawn.&lt;/li&gt;\n&lt;li&gt;It is super hard to solve basic issues of data quality even reactively.&lt;/li&gt;\n&lt;li&gt;Maintaining trust in the data assets is really hard.&lt;/li&gt;\n&lt;li&gt;Data literacy of decision makers is not up to the mark in a lot of cases.&lt;/li&gt;\n&lt;li&gt;Stakeholders expect miracles and stuff to just work.&lt;/li&gt;\n&lt;li&gt;Very few people can explain the attributes, the calculations, the metrics, the insights, and the implications.&lt;/li&gt;\n&lt;li&gt;Everyone is just promising stuff and punting the inevitable reality of face the hard problem and solve it properly.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am just trying to research and gather inputs from the community on the nagging challenges of building products now to inform my product development and to inform a course that I am building to develop data product managers (because it is really difficult to find candidates to hire)&lt;/p&gt;\n\n&lt;p&gt;My question for you is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;What are your top 3 challenges in engineering data flows and pipelines?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is it the data inventory, quality, governance, accessibility, etc.?&lt;/li&gt;\n&lt;li&gt;Is the infrastructure, the complexity of building, deploying, administering the systems?&lt;/li&gt;\n&lt;li&gt;Is it the challenge of organizational structure, talent, capacity, leadership?&lt;/li&gt;\n&lt;li&gt;Is it communication, silos, lack of alignment?&lt;/li&gt;\n&lt;li&gt;Is it cost, performance, complexity of infrastructure?&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What is preventing you from building valuable data products?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For me, infrastructure cost, performance of existing tools, spaghetti code, lack of data expertise among leadership stakeholders has been the biggest headwinds to progress.&lt;/p&gt;\n\n&lt;p&gt;Last year, at one point, our AWS costs were $1.6 for every $1 a customer paid us. After working on a year and reducing substantial tech debt, we got to AWS cost of $0.6 for every $1 revenue. Still, there is no recognition, leadership is reluctant to fix data quality issues.&lt;/p&gt;\n\n&lt;p&gt;As a product lead, I have been able to influence some, but it&amp;#39;s a lot of compounding challenges.&lt;/p&gt;\n\n&lt;p&gt;Does this resonate with folks?&lt;/p&gt;\n\n&lt;p&gt;What are the top challenges you are facing?&lt;/p&gt;\n\n&lt;p&gt;What are some solutions or workaround that have worked for you?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11quk66", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11quk66/what_are_some_of_the_sticky_problems_in_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11quk66/what_are_some_of_the_sticky_problems_in_your_data/", "subreddit_subscribers": 856883, "created_utc": 1678762340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does this sub have a list of major DS employers organized by career stage and type of work primarily done at the company? r/quantfinance has a very good post that lists the major quant firms organized by the type of quant they hire and I think this sub would benefit from a similar post", "author_fullname": "t2_2w9f1i99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List of Major DS Employers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11qtjmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678759615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does this sub have a list of major DS employers organized by career stage and type of work primarily done at the company? &lt;a href=\"/r/quantfinance\"&gt;r/quantfinance&lt;/a&gt; has a very good post that lists the major quant firms organized by the type of quant they hire and I think this sub would benefit from a similar post&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qtjmx", "is_robot_indexable": true, "report_reasons": null, "author": "saucy_corvette", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qtjmx/list_of_major_ds_employers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qtjmx/list_of_major_ds_employers/", "subreddit_subscribers": 856883, "created_utc": 1678759615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is an Amazon L5 data scientist equivalent to an L5 software engineer in the corporate heirarchy? \nJust curious about your opinion.", "author_fullname": "t2_663ey8v7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding the corporate heirarchy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qrixn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678754564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is an Amazon L5 data scientist equivalent to an L5 software engineer in the corporate heirarchy? \nJust curious about your opinion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qrixn", "is_robot_indexable": true, "report_reasons": null, "author": "King_2000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qrixn/understanding_the_corporate_heirarchy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qrixn/understanding_the_corporate_heirarchy/", "subreddit_subscribers": 856883, "created_utc": 1678754564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\nI am an Senior EM. But I want to learn and practise about DataScience. I know some theory and some python. Can you guys give me advice from which material i can start and go through and learn my way up on the Implementation stuffs. Because there are so many materials online and everybody has their biased responses. Looking for advices and guidelines.", "author_fullname": "t2_18m10vei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Materials for Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qhzbi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678733443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am an Senior EM. But I want to learn and practise about DataScience. I know some theory and some python. Can you guys give me advice from which material i can start and go through and learn my way up on the Implementation stuffs. Because there are so many materials online and everybody has their biased responses. Looking for advices and guidelines.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qhzbi", "is_robot_indexable": true, "report_reasons": null, "author": "mahabubakram", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qhzbi/materials_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qhzbi/materials_for_data_science/", "subreddit_subscribers": 856883, "created_utc": 1678733443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im very new to data science, I needed help regarding a project ive been working on. I want to extract number of years of experience from job description i.e 1-2 years, 2 years etc. The text is free formatted hence the need for NLP. However can anyone give a brief idea on how to go about this", "author_fullname": "t2_8drjhm8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NER to extract data from job description", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qb556", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678717504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im very new to data science, I needed help regarding a project ive been working on. I want to extract number of years of experience from job description i.e 1-2 years, 2 years etc. The text is free formatted hence the need for NLP. However can anyone give a brief idea on how to go about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qb556", "is_robot_indexable": true, "report_reasons": null, "author": "Helix-x", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qb556/ner_to_extract_data_from_job_description/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qb556/ner_to_extract_data_from_job_description/", "subreddit_subscribers": 856883, "created_utc": 1678717504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!  \nI want to work on a project to build a website that suggests Hiking Trails based on Weather Forecast.\n\nI have some experience with Data Pipelines (mostly on GCP) and basic Web Design. As a first step I want some advice on what the overall architecture should be to build a MVP.\n\nMy idea is to collect weather data from OpenWeatherMaps and cross that data with trails from most popular Trail websites, to build a score combination based on weather quality for hiking and trail reviews.\n\nLet me know if you have some suggestions as that will definitely help!", "author_fullname": "t2_7940judc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Website that suggests Hiking Trails based on Weather Forecast", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qb4j5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678717462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nI want to work on a project to build a website that suggests Hiking Trails based on Weather Forecast.&lt;/p&gt;\n\n&lt;p&gt;I have some experience with Data Pipelines (mostly on GCP) and basic Web Design. As a first step I want some advice on what the overall architecture should be to build a MVP.&lt;/p&gt;\n\n&lt;p&gt;My idea is to collect weather data from OpenWeatherMaps and cross that data with trails from most popular Trail websites, to build a score combination based on weather quality for hiking and trail reviews.&lt;/p&gt;\n\n&lt;p&gt;Let me know if you have some suggestions as that will definitely help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qb4j5", "is_robot_indexable": true, "report_reasons": null, "author": "zecerqueira", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qb4j5/website_that_suggests_hiking_trails_based_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qb4j5/website_that_suggests_hiking_trails_based_on/", "subreddit_subscribers": 856883, "created_utc": 1678717462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Simple question really, but I cant find anything on it. \n\nIs there a method in the Pandas Profiling report to export graphs in any way?", "author_fullname": "t2_1um7ls9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Pandas Profiling] - Can generated graphs be exported?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qrgdx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678754393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Simple question really, but I cant find anything on it. &lt;/p&gt;\n\n&lt;p&gt;Is there a method in the Pandas Profiling report to export graphs in any way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qrgdx", "is_robot_indexable": true, "report_reasons": null, "author": "JimmySuicidex", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qrgdx/pandas_profiling_can_generated_graphs_be_exported/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qrgdx/pandas_profiling_can_generated_graphs_be_exported/", "subreddit_subscribers": 856883, "created_utc": 1678754393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you building internal aaps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qdkts", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678723258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qdkts", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qdkts/how_are_you_building_internal_aaps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qdkts/how_are_you_building_internal_aaps/", "subreddit_subscribers": 856883, "created_utc": 1678723258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Package here: https://github.com/dwreeves/dbt_linreg**\n\n# Overview\n\nHey everyone! I'm sharing this here because some of you may use dbt at work to manage your data pipelines, and you might find this useful for whipping up quick analyses.\n\nI made a package that lets you run linear regression and ridge regression in any SQL engine using dbt, including Snowflake and DuckDB, which don't natively have multiple regression implementations.\n\nIn theory, this implementation supports any number of variables (in practice, adding more variables exponentially increases the computation time though with the current implementation).\n\nThe code is thoroughly tested against Statsmodels's `OLS` implementation, which you can see in the `integration_tests/` folder.\n\n# Example\n\nExample linear regression here:\n\n    {{\n      config(\n        materialized=\"table\"\n      )\n    }}\n    select * from {{\n      dbt_linreg.ols(\n        table=ref('simple_matrix')\n        endog='y',\n        exog=['xa', 'xb', 'xc'],\n        format='long'\n      )\n    }}\n\nThe above code would run a linear regression on `ref('simple_matrix')` using `y` as the y-variable, and `['xa', 'xb', 'xc']` as the X-variables. The constant term is always included and doesn't need to be specified.\n\n# Install\n\nInstallation instructions are simply to add this to your `packages.yml`:\n\n      - git: \"https://github.com/dwreeves/dbt_linreg.git\"\n        revision: \"v0.1.1\"\n\n# How it works under the hood\n\nSince this is the data science subreddit, there may be some interest in how this actually works, so I'll quote from the README on the matter:\n\nSimple univariate regression coefficients are simply `covar_pop(y, x) / var_pop(x)`.\n\nThe multiple regression implementation uses a technique described in section `3.2.3 Multiple Regression from Simple Univariate Regression` of TEoSL ([source](https://hastie.su.domains/Papers/ESLII.pdf#page=71)). Econometricians know this as the Frisch-Waugh-Lowell theorem, hence the method is referred to as `'fwl'` internally in the code base.\n\nRidge regression is implemented using the augmentation technique described in Exercise 12 of Chapter 3 of TEoSL ([source](https://hastie.su.domains/Papers/ESLII.pdf#page=115)).\n\nAll approaches were validated using Statsmodels `sm.OLS()`. Note that the ridge regression coefficients differ very slightly from Statsmodels's outputs for currently unknown reasons, but the coefficients are very close (I enforce a `&lt;0.01%` deviation from Statsmodels's ridge regression coefficients in my integration tests).", "author_fullname": "t2_h0zsodpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linear regression and ridge regression in SQL + dbt with dbt_linreg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11qd0hq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678721933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Package here: &lt;a href=\"https://github.com/dwreeves/dbt_linreg\"&gt;https://github.com/dwreeves/dbt_linreg&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;h1&gt;Overview&lt;/h1&gt;\n\n&lt;p&gt;Hey everyone! I&amp;#39;m sharing this here because some of you may use dbt at work to manage your data pipelines, and you might find this useful for whipping up quick analyses.&lt;/p&gt;\n\n&lt;p&gt;I made a package that lets you run linear regression and ridge regression in any SQL engine using dbt, including Snowflake and DuckDB, which don&amp;#39;t natively have multiple regression implementations.&lt;/p&gt;\n\n&lt;p&gt;In theory, this implementation supports any number of variables (in practice, adding more variables exponentially increases the computation time though with the current implementation).&lt;/p&gt;\n\n&lt;p&gt;The code is thoroughly tested against Statsmodels&amp;#39;s &lt;code&gt;OLS&lt;/code&gt; implementation, which you can see in the &lt;code&gt;integration_tests/&lt;/code&gt; folder.&lt;/p&gt;\n\n&lt;h1&gt;Example&lt;/h1&gt;\n\n&lt;p&gt;Example linear regression here:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{{\n  config(\n    materialized=&amp;quot;table&amp;quot;\n  )\n}}\nselect * from {{\n  dbt_linreg.ols(\n    table=ref(&amp;#39;simple_matrix&amp;#39;)\n    endog=&amp;#39;y&amp;#39;,\n    exog=[&amp;#39;xa&amp;#39;, &amp;#39;xb&amp;#39;, &amp;#39;xc&amp;#39;],\n    format=&amp;#39;long&amp;#39;\n  )\n}}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The above code would run a linear regression on &lt;code&gt;ref(&amp;#39;simple_matrix&amp;#39;)&lt;/code&gt; using &lt;code&gt;y&lt;/code&gt; as the y-variable, and &lt;code&gt;[&amp;#39;xa&amp;#39;, &amp;#39;xb&amp;#39;, &amp;#39;xc&amp;#39;]&lt;/code&gt; as the X-variables. The constant term is always included and doesn&amp;#39;t need to be specified.&lt;/p&gt;\n\n&lt;h1&gt;Install&lt;/h1&gt;\n\n&lt;p&gt;Installation instructions are simply to add this to your &lt;code&gt;packages.yml&lt;/code&gt;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  - git: &amp;quot;https://github.com/dwreeves/dbt_linreg.git&amp;quot;\n    revision: &amp;quot;v0.1.1&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;How it works under the hood&lt;/h1&gt;\n\n&lt;p&gt;Since this is the data science subreddit, there may be some interest in how this actually works, so I&amp;#39;ll quote from the README on the matter:&lt;/p&gt;\n\n&lt;p&gt;Simple univariate regression coefficients are simply &lt;code&gt;covar_pop(y, x) / var_pop(x)&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;The multiple regression implementation uses a technique described in section &lt;code&gt;3.2.3 Multiple Regression from Simple Univariate Regression&lt;/code&gt; of TEoSL (&lt;a href=\"https://hastie.su.domains/Papers/ESLII.pdf#page=71\"&gt;source&lt;/a&gt;). Econometricians know this as the Frisch-Waugh-Lowell theorem, hence the method is referred to as &lt;code&gt;&amp;#39;fwl&amp;#39;&lt;/code&gt; internally in the code base.&lt;/p&gt;\n\n&lt;p&gt;Ridge regression is implemented using the augmentation technique described in Exercise 12 of Chapter 3 of TEoSL (&lt;a href=\"https://hastie.su.domains/Papers/ESLII.pdf#page=115\"&gt;source&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;All approaches were validated using Statsmodels &lt;code&gt;sm.OLS()&lt;/code&gt;. Note that the ridge regression coefficients differ very slightly from Statsmodels&amp;#39;s outputs for currently unknown reasons, but the coefficients are very close (I enforce a &lt;code&gt;&amp;lt;0.01%&lt;/code&gt; deviation from Statsmodels&amp;#39;s ridge regression coefficients in my integration tests).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?auto=webp&amp;v=enabled&amp;s=89760627f58497231c343fc84cd33b5cee42f2c5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10439ec2f6a4e74b18a5398fb471d0fc0c07f98b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb2389e3fb1cf7b3ad657684bf2d22519b1c2b8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2dad9a4b70596413b52b9e5d031114222df8fdf", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5aded51c9a4c51928ca846185d94aac43f8e334b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc3f9cd3190a0b90156f6ae7fc018482cda85553", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/aafOh_i1nqewUphpG_wAR8390qZF6S4mNEDEIw1soqA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=647bc89ce3528f169182e0e568faef6e54a2c044", "width": 1080, "height": 540}], "variants": {}, "id": "47aZudkG3WJNkYxFgpIQmMmLZxuySLSLUFluVEhwJgo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11qd0hq", "is_robot_indexable": true, "report_reasons": null, "author": "danielwreeves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11qd0hq/linear_regression_and_ridge_regression_in_sql_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11qd0hq/linear_regression_and_ridge_regression_in_sql_dbt/", "subreddit_subscribers": 856883, "created_utc": 1678721933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an Applied Math major with a Data Analytics internship in the summer. I am currently planning on having two minors; one in Engineering Science and one in Data Science. I am planning on graduating in the fall but due to some mistakes on both my part and an advisor, I would have to stay another semester for just one class to finish the minor. I am already going into my fifth year as I switched from engineering to math (hence the engineering minor), I would say I am a solid programmer and pretty much don't need the classes. Without the minor my last semester in the Fall would consist of 2 math classes and 2 online gen-eds, which would be an easy way to end my college experience (and save me a lot of money as my scholarship is for 4 years). \n\nShould I finish the minor or is the internship a good substitute?", "author_fullname": "t2_c2ryz920", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Science Minor Worth It", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11q9s7y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678714231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an Applied Math major with a Data Analytics internship in the summer. I am currently planning on having two minors; one in Engineering Science and one in Data Science. I am planning on graduating in the fall but due to some mistakes on both my part and an advisor, I would have to stay another semester for just one class to finish the minor. I am already going into my fifth year as I switched from engineering to math (hence the engineering minor), I would say I am a solid programmer and pretty much don&amp;#39;t need the classes. Without the minor my last semester in the Fall would consist of 2 math classes and 2 online gen-eds, which would be an easy way to end my college experience (and save me a lot of money as my scholarship is for 4 years). &lt;/p&gt;\n\n&lt;p&gt;Should I finish the minor or is the internship a good substitute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11q9s7y", "is_robot_indexable": true, "report_reasons": null, "author": "Secure-Atmosphere-36", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11q9s7y/is_data_science_minor_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11q9s7y/is_data_science_minor_worth_it/", "subreddit_subscribers": 856883, "created_utc": 1678714231.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}