{"kind": "Listing", "data": {"after": "t3_11kebvy", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas 2.0 and its Ecosystem (Arrow, Polars, DuckDB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzbx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WfBLcHtYpbobHIPQcl9yw8-EzWiHI6KOWUeZXci3dgU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678110254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/pandas-2-0-ecosystem-arrow-polars-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?auto=webp&amp;v=enabled&amp;s=c99fe49fad376054047ca7a1e39b3e95b13d15b2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b6278e769713db18bf213a52f241ba7e6fd287", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52908720030dc2cdf14443982af90f39110acec5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83e96d87d7056881fc72a713eff848e605ca128b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c34b1793c4e556185d7436ed33ad33a9cd1813f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5676b7eefa2904c952e8479bc0ce518c9541179c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa6ad5241da76bb55da21a4d74d8ba115038db4c", "width": 1080, "height": 567}], "variants": {}, "id": "NboYMU5MfVrPm_M685v01j18yegh_p4z5qgcI3RL6J8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11jzbx6", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11jzbx6/pandas_20_and_its_ecosystem_arrow_polars_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/pandas-2-0-ecosystem-arrow-polars-duckdb/", "subreddit_subscribers": 92141, "created_utc": 1678110254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets say I have a python app that every day performs some data transformations and then loads the data into the warehouse (postgres). It loads parquet files using pyarrow and then using polars/pandas do some stuff and then it needs to save it to the db. \n\nWhat would be the best way to insert the data into the DB?\n\na. use pandas to_sql method\n\nb. iterate over each dataframe row and send an insert statement\n\nc. convert dataframe to e.g. list of dicts and send an insert statements (i suppose worse than b.)\n\nd. asyncronously iterate over dataframe rows and send an insert statements\n\ne. save dataframe to CSV and ?somehow import it into the DB\n\nf. some better alternative?\n\nAlso - is it common to send the insert statements directly to the DB or should I use Kafka/RabbitMQ, send the data to the messaging system, create a consumer app that would take the data from queue and insert into the db?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insert data into DB best practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kdvkr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678137570.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678136504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a python app that every day performs some data transformations and then loads the data into the warehouse (postgres). It loads parquet files using pyarrow and then using polars/pandas do some stuff and then it needs to save it to the db. &lt;/p&gt;\n\n&lt;p&gt;What would be the best way to insert the data into the DB?&lt;/p&gt;\n\n&lt;p&gt;a. use pandas to_sql method&lt;/p&gt;\n\n&lt;p&gt;b. iterate over each dataframe row and send an insert statement&lt;/p&gt;\n\n&lt;p&gt;c. convert dataframe to e.g. list of dicts and send an insert statements (i suppose worse than b.)&lt;/p&gt;\n\n&lt;p&gt;d. asyncronously iterate over dataframe rows and send an insert statements&lt;/p&gt;\n\n&lt;p&gt;e. save dataframe to CSV and ?somehow import it into the DB&lt;/p&gt;\n\n&lt;p&gt;f. some better alternative?&lt;/p&gt;\n\n&lt;p&gt;Also - is it common to send the insert statements directly to the DB or should I use Kafka/RabbitMQ, send the data to the messaging system, create a consumer app that would take the data from queue and insert into the db?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kdvkr", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kdvkr/insert_data_into_db_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kdvkr/insert_data_into_db_best_practice/", "subreddit_subscribers": 92141, "created_utc": 1678136504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "E.g: database systems, workflow engines, ETL/ELT tools, analytical tools, cloud services, etc., basically anything that you feel is a convenient tool set to get data from source(s) to destination in the desired form.", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your favorite end-to-end tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzppg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678111228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g: database systems, workflow engines, ETL/ELT tools, analytical tools, cloud services, etc., basically anything that you feel is a convenient tool set to get data from source(s) to destination in the desired form.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11jzppg", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jzppg/whats_your_favorite_endtoend_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jzppg/whats_your_favorite_endtoend_tech_stack/", "subreddit_subscribers": 92141, "created_utc": 1678111228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nTaking a look back to my prev projects, there are always different approaches to deal with any kind of sensitive data.\n\nView layer without sensetive, restricted columns etc.\n\n&amp;#x200B;\n\nAnd every time ppls try to invent new mechanics and approaches.\n\n&amp;#x200B;\n\nWhat's your best cases of developing dhw/lake, containing personal data and role-based access model?", "author_fullname": "t2_89j762yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you deal with personal/sensetive information in dwh? Also cool stories welcome.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jxx1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678106685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Taking a look back to my prev projects, there are always different approaches to deal with any kind of sensitive data.&lt;/p&gt;\n\n&lt;p&gt;View layer without sensetive, restricted columns etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And every time ppls try to invent new mechanics and approaches.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your best cases of developing dhw/lake, containing personal data and role-based access model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11jxx1t", "is_robot_indexable": true, "report_reasons": null, "author": "tehdima", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jxx1t/how_you_deal_with_personalsensetive_information/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jxx1t/how_you_deal_with_personalsensetive_information/", "subreddit_subscribers": 92141, "created_utc": 1678106685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I already passively listen to music or old audiobooks while in the gym.  I'm wondering if there are any relevant data engineering related podcasts or audiobooks that could work for this. Do people here have any suggestions? \n\nI'm specifically looking for high quality DE related material, not just two marketing juniors flaunting buzz words.", "author_fullname": "t2_i45gnyoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good professional podcasts to listen to while working out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k47s4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678121745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already passively listen to music or old audiobooks while in the gym.  I&amp;#39;m wondering if there are any relevant data engineering related podcasts or audiobooks that could work for this. Do people here have any suggestions? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m specifically looking for high quality DE related material, not just two marketing juniors flaunting buzz words.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k47s4", "is_robot_indexable": true, "report_reasons": null, "author": "StartledBlackCat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k47s4/any_good_professional_podcasts_to_listen_to_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k47s4/any_good_professional_podcasts_to_listen_to_while/", "subreddit_subscribers": 92141, "created_utc": 1678121745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could you recommend some free data modeling (ER diagrams) tool?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free data modeling tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k2hwn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678117941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could you recommend some free data modeling (ER diagrams) tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k2hwn", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k2hwn/free_data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k2hwn/free_data_modeling_tool/", "subreddit_subscribers": 92141, "created_utc": 1678117941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I moved from a Python + SQL heavy role into one where the bulk of the coding is left to more junior members. Meanwhile, I build infrastructure and set up the bigger components. It\u2019s still technical work but I hardly get to write code. It\u2019s mostly configuration through YAML or terraform, or system diagramming. The code that I do write is Ops heavy. I\u2019ll be an expert in k8s, terraform, CICD soon enough\u2026. (Not really, this shit\u2019s complicated).\n\nI\u2019m not sure I enjoy it as much as writing Python, Go, or even SQL. \n\nDo y\u2019all enjoy setting up off-the-shelf tools, writing config files in YAML or toml or terraform/infra when you have to? What do you enjoy about it? Has your system design sense improved? \n\nI\u2019m just tossing around the idea of making a transition towards more traditional SWE. Thanks", "author_fullname": "t2_q03sptgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ever feel like a professional YAMLer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kckqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678133795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I moved from a Python + SQL heavy role into one where the bulk of the coding is left to more junior members. Meanwhile, I build infrastructure and set up the bigger components. It\u2019s still technical work but I hardly get to write code. It\u2019s mostly configuration through YAML or terraform, or system diagramming. The code that I do write is Ops heavy. I\u2019ll be an expert in k8s, terraform, CICD soon enough\u2026. (Not really, this shit\u2019s complicated).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure I enjoy it as much as writing Python, Go, or even SQL. &lt;/p&gt;\n\n&lt;p&gt;Do y\u2019all enjoy setting up off-the-shelf tools, writing config files in YAML or toml or terraform/infra when you have to? What do you enjoy about it? Has your system design sense improved? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just tossing around the idea of making a transition towards more traditional SWE. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kckqy", "is_robot_indexable": true, "report_reasons": null, "author": "bingbangbio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kckqy/ever_feel_like_a_professional_yamler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kckqy/ever_feel_like_a_professional_yamler/", "subreddit_subscribers": 92141, "created_utc": 1678133795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello, I need to build some crawlers where I must automate clicking on buttons and filling out forms. By client requirement, I need to build these crawlers within the Synapse Analytics environment.\n\nI had thought of solving this problem using Selenium to do all the automation part, but I don't know if it's possible to integrate Selenium with Synapse.\n\nHas anyone faced a similar problem?", "author_fullname": "t2_goecqk3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building crawlers using Azure Synapse Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jy680", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678107338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I need to build some crawlers where I must automate clicking on buttons and filling out forms. By client requirement, I need to build these crawlers within the Synapse Analytics environment.&lt;/p&gt;\n\n&lt;p&gt;I had thought of solving this problem using Selenium to do all the automation part, but I don&amp;#39;t know if it&amp;#39;s possible to integrate Selenium with Synapse.&lt;/p&gt;\n\n&lt;p&gt;Has anyone faced a similar problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11jy680", "is_robot_indexable": true, "report_reasons": null, "author": "Folkrar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jy680/building_crawlers_using_azure_synapse_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jy680/building_crawlers_using_azure_synapse_analytics/", "subreddit_subscribers": 92141, "created_utc": 1678107338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_t01yxrq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check out the awesome stuff in Apache Airflow 2.5! \ud83e\udd29", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11k1a73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.5?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aji3S_H_-Fo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11k1a73", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0DAVeiubl0P4UOcpno1joaoJ9Zz3dLiEgxPBs3LNhAY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678115191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/aji3S_H_-Fo", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?auto=webp&amp;v=enabled&amp;s=8c912308dc1f42e1643a185c72896332eff2bdd1", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5058efbc719fb6752c5574771c720d013a3edd0a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfa7f21fd404af60f27ee538e4596b35a0d71f22", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb0aca22f154adcdde5e159dfc1f2e59a80a520e", "width": 320, "height": 240}], "variants": {}, "id": "U7_XfScaeDo5P-CnwYfNqrHGduPTxK37lLZfshZfWKE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11k1a73", "is_robot_indexable": true, "report_reasons": null, "author": "Yahentamitsi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k1a73/check_out_the_awesome_stuff_in_apache_airflow_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/aji3S_H_-Fo", "subreddit_subscribers": 92141, "created_utc": 1678115191.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.5?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aji3S_H_-Fo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! Been looking into Fivetran + dbt for a while but would like to understand better what's limiting or if that is basically the holy grail already?  \n\n\nFeel like it's nice to start out but don't want to end up buying tool after tool on top of that to manage things, add governance, etc.  \n\n\nHow do you feel about having to manage so many tools? Would it make sense to instead use something that stitches those together? Would it be worth it to pay more for that?", "author_fullname": "t2_beueng4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran + dbt users experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k64f7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678123982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! Been looking into Fivetran + dbt for a while but would like to understand better what&amp;#39;s limiting or if that is basically the holy grail already?  &lt;/p&gt;\n\n&lt;p&gt;Feel like it&amp;#39;s nice to start out but don&amp;#39;t want to end up buying tool after tool on top of that to manage things, add governance, etc.  &lt;/p&gt;\n\n&lt;p&gt;How do you feel about having to manage so many tools? Would it make sense to instead use something that stitches those together? Would it be worth it to pay more for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k64f7", "is_robot_indexable": true, "report_reasons": null, "author": "Thybrat", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k64f7/fivetran_dbt_users_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k64f7/fivetran_dbt_users_experience/", "subreddit_subscribers": 92141, "created_utc": 1678123982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to load json files to Databricks tables, and was wondering what tools/methods are easiest for this (i'm currently trying with python). This seems like it would be a common task for data engineers, but I was running into a few issues. 1) My json has nested lists of jsons, which i would like to extract the values to a row for each element in the list. I have list nested lists inside those as well, so there will need to be 2 levels of exploding/looping to generate these rows. 2) If an element does not exist, I want this defaulted to 'null', but that situation causes an error when using python. I've read a few solutions on this but none of them seem simple or easy and I'm trying to avoid complexity in this code. Thanks!", "author_fullname": "t2_50i9ola", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Json to SQL Tables, specifically Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k333m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678119251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to load json files to Databricks tables, and was wondering what tools/methods are easiest for this (i&amp;#39;m currently trying with python). This seems like it would be a common task for data engineers, but I was running into a few issues. 1) My json has nested lists of jsons, which i would like to extract the values to a row for each element in the list. I have list nested lists inside those as well, so there will need to be 2 levels of exploding/looping to generate these rows. 2) If an element does not exist, I want this defaulted to &amp;#39;null&amp;#39;, but that situation causes an error when using python. I&amp;#39;ve read a few solutions on this but none of them seem simple or easy and I&amp;#39;m trying to avoid complexity in this code. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k333m", "is_robot_indexable": true, "report_reasons": null, "author": "D-2-The-Ave", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k333m/json_to_sql_tables_specifically_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k333m/json_to_sql_tables_specifically_databricks/", "subreddit_subscribers": 92141, "created_utc": 1678119251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am new here and looking to get some input from people that have more experience in the industry.\n\nI worked in a digital advertising industry before, but very early on realised moving to a data role would suit me. So over 3 years I spent a lot of time learning R and Python, mostly to interact with APIs and automate reporting.\n\nA year ago I finally landed a role of a data analyst for a DTC ecomm company.\n\nThe only problem is I don't really spend a lot of time analysing data. \n\nSo far I have implemented Airbyte for data extraction, suplemented with Airflow orchestrated python scripts for stuff that Airbyte does not support, I wrote all of our DBT models and on top I am creating tableau dashboards for end users.\n\nOur stack currently is Airbyte, Airflow, DBT, BigQuery.\n\nAlso I am the only person in the company that does anything to do with data. So I had to figure out everything on my own.\n\nI have a feeling I have learned a ton past year, but I am also starting to realise that some of the stuff I did is very subpar (no dimensional modeling, non incrimental models in dbt, busines logic scattered all over the place etc.).\n\nMy contract is expiring end of this year and I am looking to you guys for some advice.\n\nFirst of all I want to know if this kind of work I have described is typicall for a data engineer? \n\nI work remotely and have not had a lot of opportunities to talk to people who actually are employed as data engineers.\n\nSecond, is it enough to ge me into a junior data engineer position, or should I aim to learn some new skills?\n\nI am pretty good at python, sql, R, Airflow, i know how to work with VMs and have experience with GCP. I am learning about dimensional modeling now.\n\n\nThirdly, should I stay at current position?\n\nI am currently making $100k a year. But I am not really seing my company hiring anyone more experienced then me, if anything they might hire people under me.\n\nI would really like an opportunity to work with a team and learn from more experienced people. Kinda sick of having to figure out everything on my own, but otherwise I like the type of work I have been doing this past year.\n\nThank you for a long read and thanks in advance for sharing your thoughts.", "author_fullname": "t2_9rpn5ks6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a data analyst or a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kim2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678146940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am new here and looking to get some input from people that have more experience in the industry.&lt;/p&gt;\n\n&lt;p&gt;I worked in a digital advertising industry before, but very early on realised moving to a data role would suit me. So over 3 years I spent a lot of time learning R and Python, mostly to interact with APIs and automate reporting.&lt;/p&gt;\n\n&lt;p&gt;A year ago I finally landed a role of a data analyst for a DTC ecomm company.&lt;/p&gt;\n\n&lt;p&gt;The only problem is I don&amp;#39;t really spend a lot of time analysing data. &lt;/p&gt;\n\n&lt;p&gt;So far I have implemented Airbyte for data extraction, suplemented with Airflow orchestrated python scripts for stuff that Airbyte does not support, I wrote all of our DBT models and on top I am creating tableau dashboards for end users.&lt;/p&gt;\n\n&lt;p&gt;Our stack currently is Airbyte, Airflow, DBT, BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Also I am the only person in the company that does anything to do with data. So I had to figure out everything on my own.&lt;/p&gt;\n\n&lt;p&gt;I have a feeling I have learned a ton past year, but I am also starting to realise that some of the stuff I did is very subpar (no dimensional modeling, non incrimental models in dbt, busines logic scattered all over the place etc.).&lt;/p&gt;\n\n&lt;p&gt;My contract is expiring end of this year and I am looking to you guys for some advice.&lt;/p&gt;\n\n&lt;p&gt;First of all I want to know if this kind of work I have described is typicall for a data engineer? &lt;/p&gt;\n\n&lt;p&gt;I work remotely and have not had a lot of opportunities to talk to people who actually are employed as data engineers.&lt;/p&gt;\n\n&lt;p&gt;Second, is it enough to ge me into a junior data engineer position, or should I aim to learn some new skills?&lt;/p&gt;\n\n&lt;p&gt;I am pretty good at python, sql, R, Airflow, i know how to work with VMs and have experience with GCP. I am learning about dimensional modeling now.&lt;/p&gt;\n\n&lt;p&gt;Thirdly, should I stay at current position?&lt;/p&gt;\n\n&lt;p&gt;I am currently making $100k a year. But I am not really seing my company hiring anyone more experienced then me, if anything they might hire people under me.&lt;/p&gt;\n\n&lt;p&gt;I would really like an opportunity to work with a team and learn from more experienced people. Kinda sick of having to figure out everything on my own, but otherwise I like the type of work I have been doing this past year.&lt;/p&gt;\n\n&lt;p&gt;Thank you for a long read and thanks in advance for sharing your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kim2m", "is_robot_indexable": true, "report_reasons": null, "author": "CryptographerMain698", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kim2m/am_i_a_data_analyst_or_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kim2m/am_i_a_data_analyst_or_a_data_engineer/", "subreddit_subscribers": 92141, "created_utc": 1678146940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI'm working with a dataframe with 30 million lines, using the AWS Glue docker image, but I'm having a very slow time to perform operations, like select, count and group by, when I read the files directly from s3.\n\nI noticed that if I download the parquets from s3 and read them locally, this problem of slowness is solved and the operations work very quickly.\n\nI tried to use cache() and persist() after reading the files from s3 but the performance was still very slow.\n\nDo you know any way to optimize the performance without downloading the parquet files and reading them locally?\n\n&amp;#x200B;\n\nRegards", "author_fullname": "t2_4i184twi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[PySpark] Read S3 x Read Local", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzx6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678111747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with a dataframe with 30 million lines, using the AWS Glue docker image, but I&amp;#39;m having a very slow time to perform operations, like select, count and group by, when I read the files directly from s3.&lt;/p&gt;\n\n&lt;p&gt;I noticed that if I download the parquets from s3 and read them locally, this problem of slowness is solved and the operations work very quickly.&lt;/p&gt;\n\n&lt;p&gt;I tried to use cache() and persist() after reading the files from s3 but the performance was still very slow.&lt;/p&gt;\n\n&lt;p&gt;Do you know any way to optimize the performance without downloading the parquet files and reading them locally?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Regards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11jzx6r", "is_robot_indexable": true, "report_reasons": null, "author": "M4ksB", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jzx6r/pyspark_read_s3_x_read_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jzx6r/pyspark_read_s3_x_read_local/", "subreddit_subscribers": 92141, "created_utc": 1678111747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm asking for some career advice for a relative.\n\nShe did her MSc thesis in Data Science with Natural Language Processing (NLP) and Machine Learning (ML) in a company. Therefore, she also learned quite a bit of practical know-how and engineering skills. Through this MSc thesis, she got very excited about NLP and would like to work on NLP projects from prototype to deployment and maintaining (MLOps). Her goal is to work at a (big) tech company where there is enough data available to work on interesting projects, free choice of Mac or Linux (and not being force to use Windows), a good salary and additional perks.\n\nCurrently, she is working as a Data Engineer at a consulting company with the intention to improve skills and know-how she can't learn on her own because of the used infrastructure, e.g., building data pipelines. The current project she is assigned to is quite boring. She is working on a web-based platform to design data flows with very little coding involved. There are also no senior people on the project from whom she could learn. To me, it looks like a bunch of not so skilled people have to work many hours overtime to get the job done, because they lack the necessary skills and don't have seniors guiding them. Maybe this is standard in technical consulting. I don't know.\n\nShe started her Data Engineer job a year ago. During her BSc and MSc studies she always worked (part-time) but mostly on project assignments which lasted half a year. This makes her CV a bit scattered, and she would prefer to have a longer term entry in her CV. It is also quite difficult (practically impossible) to work part-time next to this job due to the company's policy. Therefore, she would like to improve her skills and know-how next to the job in her free time.\n\nNow to the actual question, what do you recommend to up-skill in the free time next to a day job. A few options that came to my mind are:\n\n* Improving programming skills on HackerRank\n\n* Coursera courses like [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) and [MLOps](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops) she started both of them when she was applying for jobs\n\n* Development of own projects on GitHub\n\n* Contribution to OpenSource: Which projects can you recommend in the NLP space?\n\n* Implementing Algorithms from research papers\n\nThese are just a few options that came to my mind. What do you recommend and in which order? Since people in the consulting world also need to attend networking events (semi-optional) next to long working hours, time is a scarce good.", "author_fullname": "t2_bxji82xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get from technical consulting to big tech?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jst2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678090712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m asking for some career advice for a relative.&lt;/p&gt;\n\n&lt;p&gt;She did her MSc thesis in Data Science with Natural Language Processing (NLP) and Machine Learning (ML) in a company. Therefore, she also learned quite a bit of practical know-how and engineering skills. Through this MSc thesis, she got very excited about NLP and would like to work on NLP projects from prototype to deployment and maintaining (MLOps). Her goal is to work at a (big) tech company where there is enough data available to work on interesting projects, free choice of Mac or Linux (and not being force to use Windows), a good salary and additional perks.&lt;/p&gt;\n\n&lt;p&gt;Currently, she is working as a Data Engineer at a consulting company with the intention to improve skills and know-how she can&amp;#39;t learn on her own because of the used infrastructure, e.g., building data pipelines. The current project she is assigned to is quite boring. She is working on a web-based platform to design data flows with very little coding involved. There are also no senior people on the project from whom she could learn. To me, it looks like a bunch of not so skilled people have to work many hours overtime to get the job done, because they lack the necessary skills and don&amp;#39;t have seniors guiding them. Maybe this is standard in technical consulting. I don&amp;#39;t know.&lt;/p&gt;\n\n&lt;p&gt;She started her Data Engineer job a year ago. During her BSc and MSc studies she always worked (part-time) but mostly on project assignments which lasted half a year. This makes her CV a bit scattered, and she would prefer to have a longer term entry in her CV. It is also quite difficult (practically impossible) to work part-time next to this job due to the company&amp;#39;s policy. Therefore, she would like to improve her skills and know-how next to the job in her free time.&lt;/p&gt;\n\n&lt;p&gt;Now to the actual question, what do you recommend to up-skill in the free time next to a day job. A few options that came to my mind are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Improving programming skills on HackerRank&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Coursera courses like &lt;a href=\"https://www.coursera.org/specializations/deep-learning\"&gt;Deep Learning Specialization&lt;/a&gt; and &lt;a href=\"https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops\"&gt;MLOps&lt;/a&gt; she started both of them when she was applying for jobs&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Development of own projects on GitHub&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Contribution to OpenSource: Which projects can you recommend in the NLP space?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Implementing Algorithms from research papers&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These are just a few options that came to my mind. What do you recommend and in which order? Since people in the consulting world also need to attend networking events (semi-optional) next to long working hours, time is a scarce good.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?auto=webp&amp;v=enabled&amp;s=1cd6dde85a3b19a0920cff488dc675c2f25f906e", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68fdb081afb26275ee0b9993a80453ba4dfc2951", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4afec28ee66b1983c3b4008f298854e0565688e9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dca4ec9da0136b2aa0412ed1c2cc05bd7fb47f6e", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac55817fe587aea13fa7a7efc710bee751350b58", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb6297e691f860d583a02565cd635f332ef10462", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/SRe7R3ejhe5bPdRXzzVLzR_vuNuCSbarN40d32LQ8BU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=875bee4d8062e26a9cb48e5c0e1e2f44e5dd07ff", "width": 1080, "height": 565}], "variants": {}, "id": "mrN4dHSa_JybT9iNbdDvFQTCtBX-YXlzlIOpsypDL6w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11jst2h", "is_robot_indexable": true, "report_reasons": null, "author": "AndreasZiegler", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jst2h/how_to_get_from_technical_consulting_to_big_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jst2h/how_to_get_from_technical_consulting_to_big_tech/", "subreddit_subscribers": 92141, "created_utc": 1678090712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, i created the following code as a test to perform an ETL using pandas in chunks. The idea was so use a for loop to get a chunk of data into a dataframe, load that chunk into a database and then truncate the dataframe so that memory consumption is low and then move onto the next chunk. This is the code:\n\n&amp;#x200B;\n\n    import pandas as pd\n    from sqlalchemy import create_engine\n    \n    query = \"SELECT * FROM table\"\n    \n    def ETL():\n        engine = create_engine('connection details', fast_executemany=True)\n        engine2 = create_engine('connection details', fast_executemany=True)\n        conn = engine.connect().execution_options(stream_results=True)\n        \n        for chunk in pd.read_sql(query, conn, chunksize=1000):\n            print(f\"Got dataframe w/{len(chunk)} rows\")\n            chunk.to_sql(\"table2\", engine2, if_exists='append', index=False, chunksize=1000)\n            \n        engine.dispose()\n        engine2.dispose()\n\nthe code works but i think im doing something wrong, the first 30k rows uploaded quickly but it started slowing down, thats when i realized the dataframe might not be truncating after every loop, its holding all of the data.\n\n&amp;#x200B;\n\nHow would i truncate the dataframe in this case to increase speed and reduce memory usage?\n\nthanks yall", "author_fullname": "t2_pcb7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does truncating pandas dataframe reduce memory usage? confused about chunking code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k8l78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678126791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i created the following code as a test to perform an ETL using pandas in chunks. The idea was so use a for loop to get a chunk of data into a dataframe, load that chunk into a database and then truncate the dataframe so that memory consumption is low and then move onto the next chunk. This is the code:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nfrom sqlalchemy import create_engine\n\nquery = &amp;quot;SELECT * FROM table&amp;quot;\n\ndef ETL():\n    engine = create_engine(&amp;#39;connection details&amp;#39;, fast_executemany=True)\n    engine2 = create_engine(&amp;#39;connection details&amp;#39;, fast_executemany=True)\n    conn = engine.connect().execution_options(stream_results=True)\n\n    for chunk in pd.read_sql(query, conn, chunksize=1000):\n        print(f&amp;quot;Got dataframe w/{len(chunk)} rows&amp;quot;)\n        chunk.to_sql(&amp;quot;table2&amp;quot;, engine2, if_exists=&amp;#39;append&amp;#39;, index=False, chunksize=1000)\n\n    engine.dispose()\n    engine2.dispose()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;the code works but i think im doing something wrong, the first 30k rows uploaded quickly but it started slowing down, thats when i realized the dataframe might not be truncating after every loop, its holding all of the data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How would i truncate the dataframe in this case to increase speed and reduce memory usage?&lt;/p&gt;\n\n&lt;p&gt;thanks yall&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11k8l78", "is_robot_indexable": true, "report_reasons": null, "author": "IceStallion", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k8l78/does_truncating_pandas_dataframe_reduce_memory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k8l78/does_truncating_pandas_dataframe_reduce_memory/", "subreddit_subscribers": 92141, "created_utc": 1678126791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm currently employed as (semi) Solution Architect where I work mostly with a specific product suite. The work mostly consist of analyzing, troubleshooting, maintaining, implementing, upgrading and migrating customer environments with some customer support as well for simpler tasks.\n\n&amp;nbsp;\n\nIn my current team, things are moving slow and we are not adapting to new technologies (such as proper infrastructure orchestration, docker, workflow pipelines or monitoring and so on). I've tried multiple times but some of the seniors like to have it \"as it has always been\" and I can't seem to get things to change since they have strong voices in the company. It saddens me since I believe that working within IT you kinda need to be aware of \"new\" technologies and it's good to be at least curious about it. What I do like about my current job is doing the backend stuff (fixing broken things, for eg application config files or apache/nginx problems, sorting out DB problems, optimization and so on).\n\n&amp;nbsp;\n\nI recently got 'head hunted' to an interview as a Data Engineer. But I'm unsure if it will be a good fit. Reading up on the career it looks to be quite different pending on where you work. Some are deeming the role as a slave by GUI (spark?) to help customers get out data, while others talk more about pipelines, fixing broken pipelines, setting up models and making sure customers get what they need by supporting the backend. \n\n&amp;nbsp;\n\nI find that I have become more interested in infrastructure as code and automation with Docker &amp; Kubernetes. Going the data engineering route, will that take me further away from that? How much are you able to use code in your daily work (ie Python or something equivalent).\n\n&amp;nbsp;\n\nWhat possible routes is it after going down the Data Engineering route if I find in a few years that it isn't for me? \n\n&amp;nbsp;\n\n**TL:DR**\n&amp;nbsp;\n\nI want to do backend stuff and solve problems, interested in infrastructure as code, automation and Python in general. Is Data Engineering a good career choice and what paths comes down the road from this role?", "author_fullname": "t2_3ju3hemx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Potentially switching to Data Engineer, please advice :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jskte", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678090137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678089946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently employed as (semi) Solution Architect where I work mostly with a specific product suite. The work mostly consist of analyzing, troubleshooting, maintaining, implementing, upgrading and migrating customer environments with some customer support as well for simpler tasks.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;In my current team, things are moving slow and we are not adapting to new technologies (such as proper infrastructure orchestration, docker, workflow pipelines or monitoring and so on). I&amp;#39;ve tried multiple times but some of the seniors like to have it &amp;quot;as it has always been&amp;quot; and I can&amp;#39;t seem to get things to change since they have strong voices in the company. It saddens me since I believe that working within IT you kinda need to be aware of &amp;quot;new&amp;quot; technologies and it&amp;#39;s good to be at least curious about it. What I do like about my current job is doing the backend stuff (fixing broken things, for eg application config files or apache/nginx problems, sorting out DB problems, optimization and so on).&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I recently got &amp;#39;head hunted&amp;#39; to an interview as a Data Engineer. But I&amp;#39;m unsure if it will be a good fit. Reading up on the career it looks to be quite different pending on where you work. Some are deeming the role as a slave by GUI (spark?) to help customers get out data, while others talk more about pipelines, fixing broken pipelines, setting up models and making sure customers get what they need by supporting the backend. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I find that I have become more interested in infrastructure as code and automation with Docker &amp;amp; Kubernetes. Going the data engineering route, will that take me further away from that? How much are you able to use code in your daily work (ie Python or something equivalent).&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;What possible routes is it after going down the Data Engineering route if I find in a few years that it isn&amp;#39;t for me? &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL:DR&lt;/strong&gt;\n&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I want to do backend stuff and solve problems, interested in infrastructure as code, automation and Python in general. Is Data Engineering a good career choice and what paths comes down the road from this role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11jskte", "is_robot_indexable": true, "report_reasons": null, "author": "modanogaming", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jskte/potentially_switching_to_data_engineer_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jskte/potentially_switching_to_data_engineer_please/", "subreddit_subscribers": 92141, "created_utc": 1678089946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m torn whether I should pursue a Master\u2019s degree in Data science or instead just focus on sought-after IT certifications like Cloud certifications and data warehouse like Snowflake Snowpro, and perfect my craft during those 2 years that could have been in the University studying. I\u2019m 24 and if do decide to take a Master\u2019s degree, my mom says that the best time to do it is before the age of 30. My goal is to become a Data Architect in the next 5 years, and thankfully I was previously deployed to challenging projects at Accenture that deals mostly with end-to-end pipelines so I\u2019m getting there. Also, I live in the Philippines and would want to work overseas for a better opportunity. Now begs the question, what is the better route to achieve my goals as fast as possible?", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice whether to take Master\u2019s degree in Data Science or instead just take IT certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jp0rl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678078901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m torn whether I should pursue a Master\u2019s degree in Data science or instead just focus on sought-after IT certifications like Cloud certifications and data warehouse like Snowflake Snowpro, and perfect my craft during those 2 years that could have been in the University studying. I\u2019m 24 and if do decide to take a Master\u2019s degree, my mom says that the best time to do it is before the age of 30. My goal is to become a Data Architect in the next 5 years, and thankfully I was previously deployed to challenging projects at Accenture that deals mostly with end-to-end pipelines so I\u2019m getting there. Also, I live in the Philippines and would want to work overseas for a better opportunity. Now begs the question, what is the better route to achieve my goals as fast as possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11jp0rl", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jp0rl/need_advice_whether_to_take_masters_degree_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jp0rl/need_advice_whether_to_take_masters_degree_in/", "subreddit_subscribers": 92141, "created_utc": 1678078901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all - my front end team wants to get the github actions metrics to monitor the build performance over time and benchmark builds across repos + monitoring fails. \n\nOutside paid vendor solution, is there a way to extract this data to Snowflake easily?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extract Github actions metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kmtdt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678157184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - my front end team wants to get the github actions metrics to monitor the build performance over time and benchmark builds across repos + monitoring fails. &lt;/p&gt;\n\n&lt;p&gt;Outside paid vendor solution, is there a way to extract this data to Snowflake easily?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kmtdt", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kmtdt/extract_github_actions_metrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kmtdt/extract_github_actions_metrics/", "subreddit_subscribers": 92141, "created_utc": 1678157184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! I have accepted an offer at a big bank for when I graduate as a software engineer. I can decide between two different roles. What they have available is big data engineer or ios/android app dev. I do want to end up in a more traditional SWE role like fullstack or web dev. But who knows I may like whatever I get into. Which of the two roles would a better start to my career? I personally feel like iOS/android dev is a bit too niche and I could transfer big data skills to other jobs. But I\u2019m not 100% which is why I\u2019m asking here. Any advice is appreciated!", "author_fullname": "t2_3y8aolho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding between two positions unrelated to what I want to do\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kmoho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678156839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! I have accepted an offer at a big bank for when I graduate as a software engineer. I can decide between two different roles. What they have available is big data engineer or ios/android app dev. I do want to end up in a more traditional SWE role like fullstack or web dev. But who knows I may like whatever I get into. Which of the two roles would a better start to my career? I personally feel like iOS/android dev is a bit too niche and I could transfer big data skills to other jobs. But I\u2019m not 100% which is why I\u2019m asking here. Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kmoho", "is_robot_indexable": true, "report_reasons": null, "author": "OOFBOSS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kmoho/deciding_between_two_positions_unrelated_to_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kmoho/deciding_between_two_positions_unrelated_to_what/", "subreddit_subscribers": 92141, "created_utc": 1678156839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to run a simple pipeline in Azure with whatever service is easiest to stand up. Have a few python files pulling from a web api, they are helper modules that execute in main python file. Need to run them once a week. And store output in some kind of storage\u2026 sql pool or dedicated, blob. Doesn\u2019t matter. Any suggestions helpful. Mainly looking for an easy orchestration or trigger for the weekly batch load. Thanks again", "author_fullname": "t2_vmi9ivlo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline in azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kmmqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678156718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to run a simple pipeline in Azure with whatever service is easiest to stand up. Have a few python files pulling from a web api, they are helper modules that execute in main python file. Need to run them once a week. And store output in some kind of storage\u2026 sql pool or dedicated, blob. Doesn\u2019t matter. Any suggestions helpful. Mainly looking for an easy orchestration or trigger for the weekly batch load. Thanks again&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kmmqx", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable-Watch-79", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kmmqx/pipeline_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kmmqx/pipeline_in_azure/", "subreddit_subscribers": 92141, "created_utc": 1678156718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 150 TB data in 15k parquet files containing intensities and few other columns. At max. 1000 users/day (mostly in US) might enter 5 arrays containing their test intensities. The batch processing system must find the cosine similarity between each of the test intensity and all the hundreds of millions of intensities in the 150 TB files and return the top 10 intensities with the highest score (cosine similarity). What batch prcessing system like MapReduce, Spark etc. should I use?                                 \n\nOvertime (in 1 month or so), the top-1000 parquet files (15TB) that contain the most number of highest scores returned to the users must be cached for faster performance. The replication factor for all the files except for the cached ones is 1. I don't want high availablity of all the data due to the cost factor but there must be no soingle point of failure and lesser network overhead. What file storage system like Cassandra, Ceph, Gluster etc. must I use?", "author_fullname": "t2_j17djqm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self hosted file storage and batch processing system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kiwum", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678147608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 150 TB data in 15k parquet files containing intensities and few other columns. At max. 1000 users/day (mostly in US) might enter 5 arrays containing their test intensities. The batch processing system must find the cosine similarity between each of the test intensity and all the hundreds of millions of intensities in the 150 TB files and return the top 10 intensities with the highest score (cosine similarity). What batch prcessing system like MapReduce, Spark etc. should I use?                                 &lt;/p&gt;\n\n&lt;p&gt;Overtime (in 1 month or so), the top-1000 parquet files (15TB) that contain the most number of highest scores returned to the users must be cached for faster performance. The replication factor for all the files except for the cached ones is 1. I don&amp;#39;t want high availablity of all the data due to the cost factor but there must be no soingle point of failure and lesser network overhead. What file storage system like Cassandra, Ceph, Gluster etc. must I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kiwum", "is_robot_indexable": true, "report_reasons": null, "author": "loyangab", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kiwum/self_hosted_file_storage_and_batch_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kiwum/self_hosted_file_storage_and_batch_processing/", "subreddit_subscribers": 92141, "created_utc": 1678147608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to grow my skills in ci/cd &amp; right now our dbt cli / dbt core operation is relatively basic. We have a docker image to support local dev thru production, use circleci but have little testing. \n\nAnyone have any really optimized method for cicd with dbt / docker (full stack includes gcp/snowflake / terraform / GitHub)\n\nMaybe some low hanging fruit so I could get a quick win. I was thinking doing https://www.vantage-ai.com/blog/how-to-use-slim-ci-with-dbt-core but need some more hand holding on setting up. \n\nAny good articles or packages you\u2019d recommend?\n\nAlso any ideas on data infrastructure would be taken. We use terraform for role granting in snowflake and infra  but open to ideas on how to improve so I can be less of just a DE and more of an infra/ops skillet also", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "While this may be a better post for dbt slack, I have trouble getting traction there at times.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kiog0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678148665.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678147092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to grow my skills in ci/cd &amp;amp; right now our dbt cli / dbt core operation is relatively basic. We have a docker image to support local dev thru production, use circleci but have little testing. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any really optimized method for cicd with dbt / docker (full stack includes gcp/snowflake / terraform / GitHub)&lt;/p&gt;\n\n&lt;p&gt;Maybe some low hanging fruit so I could get a quick win. I was thinking doing &lt;a href=\"https://www.vantage-ai.com/blog/how-to-use-slim-ci-with-dbt-core\"&gt;https://www.vantage-ai.com/blog/how-to-use-slim-ci-with-dbt-core&lt;/a&gt; but need some more hand holding on setting up. &lt;/p&gt;\n\n&lt;p&gt;Any good articles or packages you\u2019d recommend?&lt;/p&gt;\n\n&lt;p&gt;Also any ideas on data infrastructure would be taken. We use terraform for role granting in snowflake and infra  but open to ideas on how to improve so I can be less of just a DE and more of an infra/ops skillet also&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?auto=webp&amp;v=enabled&amp;s=da46bd8f9fbd68286c6a284ee9be398535009009", "width": 1000, "height": 672}, "resolutions": [{"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88aea10a7e68604c1463a51f9eefd4e3bb75fc91", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9396cac5e006fee47b2b10fe972c8594e95a7765", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41d375adf004ce0a1857b99ccde873aa8c71c36f", "width": 320, "height": 215}, {"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2ca14c71a5df61def8e89677728ab56c2b5c496", "width": 640, "height": 430}, {"url": "https://external-preview.redd.it/Pic9fHTrBnpihc8yG7z8QEOyeYiWQ4OnRaa1TJzo_MQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=607dfc1483ba7bacdc72dff65ef2dc8efb351797", "width": 960, "height": 645}], "variants": {}, "id": "kRjFJ-AHbv87rCsgC-CvtXVOA5FqfofXkBw_eDm9_HY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kiog0", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kiog0/while_this_may_be_a_better_post_for_dbt_slack_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kiog0/while_this_may_be_a_better_post_for_dbt_slack_i/", "subreddit_subscribers": 92141, "created_utc": 1678147092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The project I'm currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.\n\nWe are going to be expanding our data size by something like 4x-20x in the next year or two. \n\nWe want to find examples of companies doing similar data work to us, and seeing how they managed their data.\n\nOur main setup is:  \n\n\n1. Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.\n2. Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.\n3. Post processing Feature values. We have a database of post processing features so we don't need to process the raw data each time we do a model training run.\n\nThe setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.\n\nAre there any good resources on how more established companies manage this setup?", "author_fullname": "t2_80ont", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog posts detailing ML companies data infrastructure / DB schema?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kh6a0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678143676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The project I&amp;#39;m currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.&lt;/p&gt;\n\n&lt;p&gt;We are going to be expanding our data size by something like 4x-20x in the next year or two. &lt;/p&gt;\n\n&lt;p&gt;We want to find examples of companies doing similar data work to us, and seeing how they managed their data.&lt;/p&gt;\n\n&lt;p&gt;Our main setup is:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.&lt;/li&gt;\n&lt;li&gt;Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.&lt;/li&gt;\n&lt;li&gt;Post processing Feature values. We have a database of post processing features so we don&amp;#39;t need to process the raw data each time we do a model training run.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources on how more established companies manage this setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kh6a0", "is_robot_indexable": true, "report_reasons": null, "author": "Cwlrs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kh6a0/blog_posts_detailing_ml_companies_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kh6a0/blog_posts_detailing_ml_companies_data/", "subreddit_subscribers": 92141, "created_utc": 1678143676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Looking to implement - call it version 0.001 of a data catalog on top of our AWS-backed data lake.\n\nI can attempt to roll my own on using tools native to AWS.\n\nI can start with an open source tool such as Amundsen.\n\nI may be able to start with an inexpensive SaaS Data Catalog, but I will not have budget for Data Catalog until I'm able to show exactly what I mean by Data Catalog, and I'd love to provide the team something tangible to seed the conversation with our community of data consumers.\n\nDoes anyone use Amundsen?  Is it still a good option in 2023, or is it a dormant project?\n\nIf you are using a data catalog to enable discoverability and self-service analytics, what are you using, and is it working for you?  \n\nDon't know whether to call this a request for help or for discussion; went with \"discussion\" but maybe that's a data quality issue :)\n\nTruly appreciate any information, observations, thoughts, ideas.\n\nBest!", "author_fullname": "t2_w9nubpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog, Data Discovery, Active Metadata Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kfaeu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678139495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Looking to implement - call it version 0.001 of a data catalog on top of our AWS-backed data lake.&lt;/p&gt;\n\n&lt;p&gt;I can attempt to roll my own on using tools native to AWS.&lt;/p&gt;\n\n&lt;p&gt;I can start with an open source tool such as Amundsen.&lt;/p&gt;\n\n&lt;p&gt;I may be able to start with an inexpensive SaaS Data Catalog, but I will not have budget for Data Catalog until I&amp;#39;m able to show exactly what I mean by Data Catalog, and I&amp;#39;d love to provide the team something tangible to seed the conversation with our community of data consumers.&lt;/p&gt;\n\n&lt;p&gt;Does anyone use Amundsen?  Is it still a good option in 2023, or is it a dormant project?&lt;/p&gt;\n\n&lt;p&gt;If you are using a data catalog to enable discoverability and self-service analytics, what are you using, and is it working for you?  &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t know whether to call this a request for help or for discussion; went with &amp;quot;discussion&amp;quot; but maybe that&amp;#39;s a data quality issue :)&lt;/p&gt;\n\n&lt;p&gt;Truly appreciate any information, observations, thoughts, ideas.&lt;/p&gt;\n\n&lt;p&gt;Best!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kfaeu", "is_robot_indexable": true, "report_reasons": null, "author": "realrussgreen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kfaeu/data_catalog_data_discovery_active_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kfaeu/data_catalog_data_discovery_active_metadata/", "subreddit_subscribers": 92141, "created_utc": 1678139495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone know of a tool or has anyone ever built a tool that could parse through load scripts (python or KSH) and map out data lineage?\n\n&amp;#x200B;\n\nFor example, script A loads to X table, but joins to Y and Z table and would be diagramed as such? Ultimately the goal would be to parse through 500+ scrips and map out the lineage of all loads using a visualization tool.", "author_fullname": "t2_qbicj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Load Diagram", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kebvy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678137462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a tool or has anyone ever built a tool that could parse through load scripts (python or KSH) and map out data lineage?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example, script A loads to X table, but joins to Y and Z table and would be diagramed as such? Ultimately the goal would be to parse through 500+ scrips and map out the lineage of all loads using a visualization tool.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kebvy", "is_robot_indexable": true, "report_reasons": null, "author": "cbtrack692", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kebvy/data_load_diagram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kebvy/data_load_diagram/", "subreddit_subscribers": 92141, "created_utc": 1678137462.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}