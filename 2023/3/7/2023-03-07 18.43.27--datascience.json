{"kind": "Listing", "data": {"after": "t3_11kw86x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ud467w6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tech layoffs since January 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11k84qx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 452, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 452, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tJiDjDQ5qPP65Hch7jkscXAhFJNYGHfIMVbawKG8xOM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678126268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4q5yqa3za7ma1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?auto=webp&amp;v=enabled&amp;s=f823dfede95ba2732295d99e9da216515497deb0", "width": 1080, "height": 1080}, "resolutions": [{"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aae4626cd11d13548ed3fd6590278cc8574177bb", "width": 108, "height": 108}, {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7eda7169cc5e99b4cf114df7b841d12cd47051b3", "width": 216, "height": 216}, {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2274b710f1a71d674c33facaf2b0e496495db78c", "width": 320, "height": 320}, {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3181180c0c2133ca5f14bbbf9abeacce5f016370", "width": 640, "height": 640}, {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5691d9c4673c150d61b3d90e3e82fe08da079af", "width": 960, "height": 960}, {"url": "https://preview.redd.it/4q5yqa3za7ma1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6f151b816441cee7f164e998d3417fdb03a89a9", "width": 1080, "height": 1080}], "variants": {}, "id": "n7UGQGq2QeT230tYZg0hTg6Zb-IZUUK_Kb80Zp6eMkE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11k84qx", "is_robot_indexable": true, "report_reasons": null, "author": "b0zgor", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11k84qx/tech_layoffs_since_january_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4q5yqa3za7ma1.jpg", "subreddit_subscribers": 854743, "created_utc": 1678126268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_479zgx6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rich Jupyter Notebook Diffs on GitHub... Finally.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_11l2ojh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/PvkJonCBrm55xEa1hSeNqwyOUAcm0SG1VzQFV17rHVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678203789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kvhebtuu7cma1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kvhebtuu7cma1.png?auto=webp&amp;v=enabled&amp;s=6c9567daa41908136cc898b0d1f1ee53c7727251", "width": 1222, "height": 805}, "resolutions": [{"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb23c929b73c2c109150b9b96faa2adbf2c28153", "width": 108, "height": 71}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=557a9586b2872506a27041bc5e5fd42c49d6fa5b", "width": 216, "height": 142}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7697cd5d5cc43d61881c88fe934174912082669", "width": 320, "height": 210}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df8b0f73a34fd987a2543626f8eee0cea16b768b", "width": 640, "height": 421}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93f05243bd0498494b82534038f49a42e4ba37ad", "width": 960, "height": 632}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed60a93aef191fde96aaa484504a2e11182b3384", "width": 1080, "height": 711}], "variants": {}, "id": "CS5aUJvi1pTuFwS4VGyg2ZqyibSL9XYgRap8O5u4-nY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l2ojh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomForests92", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l2ojh/rich_jupyter_notebook_diffs_on_github_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kvhebtuu7cma1.png", "subreddit_subscribers": 854743, "created_utc": 1678203789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!\n\nI dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.\n\nI know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.\n\nI think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)", "author_fullname": "t2_4lqbue6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AMA: Broke into DS without masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ks4c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678172417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!&lt;/p&gt;\n\n&lt;p&gt;I dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.&lt;/p&gt;\n\n&lt;p&gt;I know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.&lt;/p&gt;\n\n&lt;p&gt;I think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ks4c2", "is_robot_indexable": true, "report_reasons": null, "author": "beecheee", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "subreddit_subscribers": 854743, "created_utc": 1678172417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. \n\n&amp;#x200B;\n\nIs this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should working in DS be this boring?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kzfdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678196070.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678195889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kzfdo", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "subreddit_subscribers": 854743, "created_utc": 1678195889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This might be a dumb question, but i am a phd student who has been working with data for the past 4-5 years. I honestly suck at organizing my work. I am now switching to a macbook and would like to hear about any tips to stay more organized, both file and code wise (mac related shortcuts are also appreciated). I mainly us R but slowly transitioning to python on VScode.", "author_fullname": "t2_mzpvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow tips (particularly mac)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11khwf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678145299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a dumb question, but i am a phd student who has been working with data for the past 4-5 years. I honestly suck at organizing my work. I am now switching to a macbook and would like to hear about any tips to stay more organized, both file and code wise (mac related shortcuts are also appreciated). I mainly us R but slowly transitioning to python on VScode.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11khwf2", "is_robot_indexable": true, "report_reasons": null, "author": "supertitiz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11khwf2/workflow_tips_particularly_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11khwf2/workflow_tips_particularly_mac/", "subreddit_subscribers": 854743, "created_utc": 1678145299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I've been told I won't be kept on past that. I have 6 years experience in the field, so I'm quite surprised. I have had to upskill a lot, but the systems were messy and I've struggled to know how to approach finding data since whenever I've asked I've been drawn into a call with my supervisor who has then picked apart whatever I've been working on which isn't usually finished instead of just directing me to the correct database so I can figure it out. I'm a bit lost since I've been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn't have enough attention to detail (but I would argue most of the tasks I submit haven't been finished since they end up getting reviewed the moment I ask a question). \n\nAny advice on next steps? I've never failed probation before, so I'm a bit lost.", "author_fullname": "t2_9ku7bdlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been told I won't be kept on past probation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ky71w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678192527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I&amp;#39;ve been told I won&amp;#39;t be kept on past that. I have 6 years experience in the field, so I&amp;#39;m quite surprised. I have had to upskill a lot, but the systems were messy and I&amp;#39;ve struggled to know how to approach finding data since whenever I&amp;#39;ve asked I&amp;#39;ve been drawn into a call with my supervisor who has then picked apart whatever I&amp;#39;ve been working on which isn&amp;#39;t usually finished instead of just directing me to the correct database so I can figure it out. I&amp;#39;m a bit lost since I&amp;#39;ve been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn&amp;#39;t have enough attention to detail (but I would argue most of the tasks I submit haven&amp;#39;t been finished since they end up getting reviewed the moment I ask a question). &lt;/p&gt;\n\n&lt;p&gt;Any advice on next steps? I&amp;#39;ve never failed probation before, so I&amp;#39;m a bit lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ky71w", "is_robot_indexable": true, "report_reasons": null, "author": "LazyTowels", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "subreddit_subscribers": 854743, "created_utc": 1678192527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_36ft48fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Runtime completion for complied data science libraries like NumPy or PyTorch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o0oda9i8gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=8ef57fdec22a638cd31c7e8c0b52267ee13e8048"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f28dd96be1ef957c2ce03353670d2e787df5e0cd"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=c5271df2a69516467f17c606c8189ece511fc55b"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=b5af76536900f11ce6e47935ffe48df6ac530f92"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6ca36cf6e5215add16f858f86ce7fbb155e79256"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6f463d7949ce6a9d51ba375b1b38f1345053a114"}], "s": {"y": 464, "gif": "https://i.redd.it/o0oda9i8gama1.gif", "mp4": "https://preview.redd.it/o0oda9i8gama1.gif?format=mp4&amp;v=enabled&amp;s=36d5d4b24086cde32f50838f35cc72ab556c0316", "x": 1286}, "id": "o0oda9i8gama1"}, "lnjuf7f9gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d31f1010917b9b11e9aad2869d1d7e1628147600"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6375bb64784d52479828bf317a7cb224397bdc1b"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=310ea65799c162162401f50ff7fdc5b9f51ac2e9"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=badbe2de57d5e6af756a27fdfbaca015e1d2e1e8"}], "s": {"y": 464, "gif": "https://i.redd.it/lnjuf7f9gama1.gif", "mp4": "https://preview.redd.it/lnjuf7f9gama1.gif?format=mp4&amp;v=enabled&amp;s=0d640473048426611a3d361a183a2adebb690972", "x": 643}, "id": "lnjuf7f9gama1"}, "xbqpr029gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3cee312028b9a8a19f6fd001e3534091441878dd"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d62de689ec524f319a18b7f7bd3cee61e80370cb"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=2534628b83e1d50b656191828cf03ee87f255928"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9dbcedb45167fda56e88d929a61599bb71e3b838"}], "s": {"y": 464, "gif": "https://i.redd.it/xbqpr029gama1.gif", "mp4": "https://preview.redd.it/xbqpr029gama1.gif?format=mp4&amp;v=enabled&amp;s=6ea8eaabc78a9d8ca17c0dbff282d71e3ed54e26", "x": 643}, "id": "xbqpr029gama1"}}, "name": "t3_11kuyu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 11, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Left hand side - during debugging with reloadium, right hand side, without debugging", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "o0oda9i8gama1", "id": 248228601}, {"caption": "Runtime completion with reloadium", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "xbqpr029gama1", "id": 248228602}, {"media_id": "lnjuf7f9gama1", "id": 248228603}]}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4Rwp5v78I_1uAbgPoQvdJI5LnpISGrOAxpfi4NNBVWI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678182816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/11kuyu6", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "11kuyu6", "is_robot_indexable": true, "report_reasons": null, "author": "kwazar90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kuyu6/runtime_completion_for_complied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/reloadware/reloadium", "subreddit_subscribers": 854743, "created_utc": 1678182816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area\n\nI make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.\n\nMy analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019\n\nI\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? \n\nThis might be too high level so happy to provide more detail.\n\nEdit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay", "author_fullname": "t2_ekymh22j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overpaid and don\u2019t see the point", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11l5mg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678212638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area&lt;/p&gt;\n\n&lt;p&gt;I make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.&lt;/p&gt;\n\n&lt;p&gt;My analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? &lt;/p&gt;\n\n&lt;p&gt;This might be too high level so happy to provide more detail.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5mg2", "is_robot_indexable": true, "report_reasons": null, "author": "leaver_believer", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "subreddit_subscribers": 854743, "created_utc": 1678210462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://www.reddit.com/r/StreamlitOfficial/comments/11kahfk/streamlit\\_appathon\\_contest/?utm\\_source=share&amp;utm\\_medium=web2x&amp;context=3](https://www.reddit.com/r/StreamlitOfficial/comments/11kahfk/streamlit_appathon_contest/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/4j3ijw66x6ma1.png?width=1200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c8604581e4f3c4138091749f49be3a9937778589", "author_fullname": "t2_uas4ojzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streamlit App-A-Thon Contest \ud83c\udfc6", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4j3ijw66x6ma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8c94c79493b8c133d465cc7f257375a81bf643d"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdaa26e2dd51e742fc49d49238f5926db9500590"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c91edf0b23d54e49ae03f6364fd35ae6199001a1"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c28be37157bbcd88ec8ccd8d070c14665c0070e"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6789ee931df37e560a8b6f041d9d9a92b828adad"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ff1865ccfd5f9722384d113aafea2f0265bc3d7"}], "s": {"y": 1200, "x": 1200, "u": "https://preview.redd.it/4j3ijw66x6ma1.png?width=1200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c8604581e4f3c4138091749f49be3a9937778589"}, "id": "4j3ijw66x6ma1"}}, "name": "t3_11kfcv9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8vbTtcxEZY_mya1CIo14pQ7r6hjPGZv1yrksRj4997c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678139644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/StreamlitOfficial/comments/11kahfk/streamlit_appathon_contest/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;https://www.reddit.com/r/StreamlitOfficial/comments/11kahfk/streamlit_appathon_contest/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4j3ijw66x6ma1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c8604581e4f3c4138091749f49be3a9937778589\"&gt;https://preview.redd.it/4j3ijw66x6ma1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c8604581e4f3c4138091749f49be3a9937778589&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kfcv9", "is_robot_indexable": true, "report_reasons": null, "author": "tonykipkemboi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kfcv9/streamlit_appathon_contest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kfcv9/streamlit_appathon_contest/", "subreddit_subscribers": 854743, "created_utc": 1678139644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working with sales data for products where they are on promotion and also not. My issue is that there are alot fewer examples of items not on promotion. I am aware of under/oversampling but has anyone worked on something similar? What techniques did you use?", "author_fullname": "t2_4j2f02c2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imbalance of examples for Regression Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kboxy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678131916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with sales data for products where they are on promotion and also not. My issue is that there are alot fewer examples of items not on promotion. I am aware of under/oversampling but has anyone worked on something similar? What techniques did you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kboxy", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativePut202", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kboxy/imbalance_of_examples_for_regression_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kboxy/imbalance_of_examples_for_regression_model/", "subreddit_subscribers": 854743, "created_utc": 1678131916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im a data scientist at a start-up where the team is quite young and you end up working on lots of different parts of the data science pipeline (e.g. analytics, data engineering, model building/deployment, etc) and whilst its a great experience as you learn alot, its also quite chaotic and as everyone may be relatively new to something, lots of mistakes and bad practices occur. \n\nIm curious to know how this sort of experience is viewed in larger companies where your job is perhaps more structured and focussed but with less breadth. Is it favoured or disliked? Is this good experience or a hinderance for when moving on?", "author_fullname": "t2_so4x4i94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do larger corporations feel about DS on start-ups?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kezia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678138845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a data scientist at a start-up where the team is quite young and you end up working on lots of different parts of the data science pipeline (e.g. analytics, data engineering, model building/deployment, etc) and whilst its a great experience as you learn alot, its also quite chaotic and as everyone may be relatively new to something, lots of mistakes and bad practices occur. &lt;/p&gt;\n\n&lt;p&gt;Im curious to know how this sort of experience is viewed in larger companies where your job is perhaps more structured and focussed but with less breadth. Is it favoured or disliked? Is this good experience or a hinderance for when moving on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kezia", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Touch_9863", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kezia/how_do_larger_corporations_feel_about_ds_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kezia/how_do_larger_corporations_feel_about_ds_on/", "subreddit_subscribers": 854743, "created_utc": 1678138845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say we need to use features such as \"day of the week\" or \"week of the year\" or \"month of the year\" in a DL model for predicting sales of a product (there are a bunch of other variables present as well). I would naturally incline towards using OHE (Yes, I'm aware that it increases dimensionality). I've had someone suggest that we can apply Target Encoding so that it won't increase the dimensions. My first thought was that it'll lead to target leakage (I've looked it up as well. It indeed happens and there seems to be some work around). I would immensely appreciate it if you can help me pick one of the above approaches with good rigorous argument supporting it. Or if you have another approach apart from the above two.", "author_fullname": "t2_7pfh6trc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Target Encoding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kaw3l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678130186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we need to use features such as &amp;quot;day of the week&amp;quot; or &amp;quot;week of the year&amp;quot; or &amp;quot;month of the year&amp;quot; in a DL model for predicting sales of a product (there are a bunch of other variables present as well). I would naturally incline towards using OHE (Yes, I&amp;#39;m aware that it increases dimensionality). I&amp;#39;ve had someone suggest that we can apply Target Encoding so that it won&amp;#39;t increase the dimensions. My first thought was that it&amp;#39;ll lead to target leakage (I&amp;#39;ve looked it up as well. It indeed happens and there seems to be some work around). I would immensely appreciate it if you can help me pick one of the above approaches with good rigorous argument supporting it. Or if you have another approach apart from the above two.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kaw3l", "is_robot_indexable": true, "report_reasons": null, "author": "eternalmathstudent", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kaw3l/target_encoding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kaw3l/target_encoding/", "subreddit_subscribers": 854743, "created_utc": 1678130186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. My team at work has been considering changes to our infrastructure, and it seems like management wants to switch over to a managed platform. We currently use an airflow/mlflow approach to creating and deploying models, with AWS mostly as a data store with other resources built into the infrastructure. Through the back and forth of how to move forward I began wondering what teams are actually using and have found success with. We\u2019ve looked at AWS Sagemaker and another third party platform but neither seems to really solve enough of our problems to make the transition worth it. Our models are not all traditional machine learning and are often custom classes with a \u201cpredict\u201d function to act like an ML model so we need some kind of flexibility in what we consider a \u201cmodel\u201d. Are other teams using some kind of platform? Are there any lesser known platforms that have been flexible and powerful for ML development? Reddit felt like the best place to get some good real feedback on experiences with these tools and this kind of transition. Thanks for any help!", "author_fullname": "t2_a465dchu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managed Platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ka5lt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678128849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. My team at work has been considering changes to our infrastructure, and it seems like management wants to switch over to a managed platform. We currently use an airflow/mlflow approach to creating and deploying models, with AWS mostly as a data store with other resources built into the infrastructure. Through the back and forth of how to move forward I began wondering what teams are actually using and have found success with. We\u2019ve looked at AWS Sagemaker and another third party platform but neither seems to really solve enough of our problems to make the transition worth it. Our models are not all traditional machine learning and are often custom classes with a \u201cpredict\u201d function to act like an ML model so we need some kind of flexibility in what we consider a \u201cmodel\u201d. Are other teams using some kind of platform? Are there any lesser known platforms that have been flexible and powerful for ML development? Reddit felt like the best place to get some good real feedback on experiences with these tools and this kind of transition. Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ka5lt", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Ingenuity4068", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ka5lt/managed_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ka5lt/managed_platforms/", "subreddit_subscribers": 854743, "created_utc": 1678128849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Working with big economics datasets e.g. 10-50 gb. \n\nOnce I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift \n\nProblem is anytime I try to debug to see if it's working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. \n\nAssuming I've used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. \n\nWhat other things can I add to my code:\n\n1. To not have to read my data in every time I run the code while developing n debugging \n\n2. Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints \n\nOther economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it's in use", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for a way of reading big data files into python without having to read the same file everything I run ti debug", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11l6eff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with big economics datasets e.g. 10-50 gb. &lt;/p&gt;\n\n&lt;p&gt;Once I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift &lt;/p&gt;\n\n&lt;p&gt;Problem is anytime I try to debug to see if it&amp;#39;s working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. &lt;/p&gt;\n\n&lt;p&gt;Assuming I&amp;#39;ve used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. &lt;/p&gt;\n\n&lt;p&gt;What other things can I add to my code:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;To not have to read my data in every time I run the code while developing n debugging &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it&amp;#39;s in use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6eff", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "subreddit_subscribers": 854743, "created_utc": 1678212199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello mate,\n\nI hope you're having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\n\n&amp;#x200B;\n\nIf you're interested, please let me know.\n\nRegards.", "author_fullname": "t2_pz75y30d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-study group in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": true, "media_metadata": {"9sx9e4zctcma1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=994986d8b07a3e4f8ad291f5cbe978300520f574"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24a5f495456d645d38b0cb1af8fc31685927777f"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb0f287367e4ce6dac59921d8f82cb146c0ae4c2"}, {"y": 299, "x": 640, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55d615d054af3a149f11175552cfece01c9dcc8d"}, {"y": 449, "x": 960, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da595e5a003258ee901af025cda872299c0f3106"}, {"y": 505, "x": 1080, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa3e1d39e0691ee5645dcfe855f2d7d3708d900"}], "s": {"y": 702, "x": 1500, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1"}, "id": "9sx9e4zctcma1"}}, "name": "t3_11l5v5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bwQQ0CPIFuVZOnxe3c1dP-4zbPvkO10SHhrXNu_vIDg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678211021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello mate,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\"&gt;https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, please let me know.&lt;/p&gt;\n\n&lt;p&gt;Regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5v5t", "is_robot_indexable": true, "report_reasons": null, "author": "Sam-Oden", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "subreddit_subscribers": 854743, "created_utc": 1678211021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says, I\u2019ve made a pandas profiler .html report and it is missing several columns from interactions and correlations. \n\nIs there an upper limit to the number of columns it can handle for these functions? \n\nI\u2019m totally stumped.", "author_fullname": "t2_1um7ls9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas profiler is missing columns from interactions and correlations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11l5ohz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I\u2019ve made a pandas profiler .html report and it is missing several columns from interactions and correlations. &lt;/p&gt;\n\n&lt;p&gt;Is there an upper limit to the number of columns it can handle for these functions? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m totally stumped.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5ohz", "is_robot_indexable": true, "report_reasons": null, "author": "JimmySuicidex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5ohz/pandas_profiler_is_missing_columns_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5ohz/pandas_profiler_is_missing_columns_from/", "subreddit_subscribers": 854743, "created_utc": 1678210598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley](https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=914258685272006e0115ba6ff5a391f39c415a67)\n\nHave you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nYou can see the full map [here](https://1712n.github.io/yachay-public/maps/chatbots/).\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.", "author_fullname": "t2_tn9uzy0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fnhre7h3fcma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81e556060f4ec2dddd354d6819a0d966e40829fd"}, {"y": 186, "x": 216, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=586e6bf96b2d16a4aaf3100fb3cb3aa01c460809"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fecc492aaf9d6c4b92b1bb2cea5a4d0cfb077c1"}, {"y": 551, "x": 640, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfedc9fcea8c8fc96947499e2e7fc7a4f3cc0535"}, {"y": 827, "x": 960, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2bab308ce9818b7cade6b19763f564bf171adb8"}, {"y": 930, "x": 1080, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ed104e7c230be02e3b2c653b28d3523887b4da3"}], "s": {"y": 1108, "x": 1286, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=914258685272006e0115ba6ff5a391f39c415a67"}, "id": "fnhre7h3fcma1"}}, "name": "t3_11l3r81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CJCMJVr9abxpqryIU-zEJwZ2oy9gj-IBPZGpiGcqSME.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678206234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=914258685272006e0115ba6ff5a391f39c415a67\"&gt;Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Have you been following the news on the conversational AI race? We used social media data and &lt;a href=\"https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model\"&gt;geolocation models&lt;/a&gt; to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.&lt;/p&gt;\n\n&lt;p&gt;First, we filtered social media data with the keywords &amp;quot;openai,&amp;quot; &amp;quot;bing,&amp;quot; &amp;quot;bard,&amp;quot; and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.&lt;/p&gt;\n\n&lt;p&gt;We analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.&lt;/p&gt;\n\n&lt;p&gt;You can see the full map &lt;a href=\"https://1712n.github.io/yachay-public/maps/chatbots/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;OpenAI may be winning the AI race at the moment, but it&amp;#39;s not the end yet. Let us know what other AI projects you&amp;#39;re following, and we&amp;#39;ll check them out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l3r81", "is_robot_indexable": true, "report_reasons": null, "author": "yachay_ai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l3r81/we_tracked_mentions_of_openai_bing_and_bard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l3r81/we_tracked_mentions_of_openai_bing_and_bard/", "subreddit_subscribers": 854743, "created_utc": 1678206234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Check out the full list of training workshops:  https:\\/\\/events.enterprisedb.com\\/YwNBgy?RefId=reddit ](https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb)", "author_fullname": "t2_p9pkrcde", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join the Postgres community at EDB Postgres Vision for hands-on exercises to learn how to effectively diagnose and resolve Postgres issues, including replication errors, data corruption and disk space: https://events.enterprisedb.com/YwNBgy?RefId=reddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5jb1o5dpacma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=821babf80729a0b9e1807bd614096620c72e944a"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96df6fea4ea82cb8e794933b0ecf60df2c21a192"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f7db2f32b6c1d4b0dc18d9e170e248d44d4041"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38159f95151b8f26922d32642ae57fef25e33bab"}], "s": {"y": 358, "x": 685, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb"}, "id": "5jb1o5dpacma1"}}, "name": "t3_11l33hu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/11BOss35JLgaopbjYmkopsMr7_QKnTQgnXBfejpB6SE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1678204752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb\"&gt;Check out the full list of training workshops:  https://events.enterprisedb.com/YwNBgy?RefId=reddit &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?auto=webp&amp;v=enabled&amp;s=c746b3a5688a5c96b443ef8f57bb1c0829cf9f87", "width": 1201, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b72bc2d81a2a4153f233d3914e995bcd3e4b1705", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a310d1294a4d6540dadb181e2de96ba11de3fab3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=455611e34a4a84d9b84756bef255f78dadb9b305", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d488c22e507af2075dcbce4917848eb9c10f293c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0127a0a51accfe45c1127d9f5aebb2611dec5e6d", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=721df1d80bac953db3186386820dbdc30ac8618a", "width": 1080, "height": 563}], "variants": {}, "id": "I1gdlw9y8oANehkt8YYaXY9RU4JUZo72bT3BVsadCos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l33hu", "is_robot_indexable": true, "report_reasons": null, "author": "EDB_Postgres", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l33hu/join_the_postgres_community_at_edb_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l33hu/join_the_postgres_community_at_edb_postgres/", "subreddit_subscribers": 854743, "created_utc": 1678204752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We've seen recently that the ChatGPT team can prevent certain topics, or quickly shut down racist or unfriendly AI responses.  They seem to resolve these issues really quickly.\n\nI'm curious how this can be done without retraining the model every time they need to make changes?  Does it have some intermediate layer that filters questions or responses, bypassing the AI completely?", "author_fullname": "t2_645hhw9y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can ChatGPT be updated to ignore topics or update responses without retraining?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kkf4l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678151232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve seen recently that the ChatGPT team can prevent certain topics, or quickly shut down racist or unfriendly AI responses.  They seem to resolve these issues really quickly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how this can be done without retraining the model every time they need to make changes?  Does it have some intermediate layer that filters questions or responses, bypassing the AI completely?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kkf4l", "is_robot_indexable": true, "report_reasons": null, "author": "CozyNorth9", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kkf4l/how_can_chatgpt_be_updated_to_ignore_topics_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kkf4l/how_can_chatgpt_be_updated_to_ignore_topics_or/", "subreddit_subscribers": 854743, "created_utc": 1678151232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_n9wlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote an article about the cool things you can do with Pandas Extension types with an example of how to create your own. Thought it might be useful here!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 131, "top_awarded_type": null, "hide_score": false, "name": "t3_11kbf0p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P7AKbnaL51vOGAbt5ZkrcMj_DK3OhfAyNQMmGB4EAZo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678131326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@finndersen/guide-to-pandas-extension-types-and-how-to-create-your-own-3b213d689c86", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kX1MAOzbqlL46Ox6bmllmR6APjApoE3RGmAh9ufwKhY.jpg?auto=webp&amp;v=enabled&amp;s=c7d6a101e6de8263b6973a102b028931b7ee16ab", "width": 718, "height": 676}, "resolutions": [{"url": "https://external-preview.redd.it/kX1MAOzbqlL46Ox6bmllmR6APjApoE3RGmAh9ufwKhY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de1819b46b293e928344015e658b93efeb8f1f8a", "width": 108, "height": 101}, {"url": "https://external-preview.redd.it/kX1MAOzbqlL46Ox6bmllmR6APjApoE3RGmAh9ufwKhY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a788293390ca461fb7238f3e23b7f4525522ceed", "width": 216, "height": 203}, {"url": "https://external-preview.redd.it/kX1MAOzbqlL46Ox6bmllmR6APjApoE3RGmAh9ufwKhY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a719b45fea44db5e22d677b942b6d12b3f7751d7", "width": 320, "height": 301}, {"url": "https://external-preview.redd.it/kX1MAOzbqlL46Ox6bmllmR6APjApoE3RGmAh9ufwKhY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c8d1f602a0f99f0a4e83634412b7e3b30629362", "width": 640, "height": 602}], "variants": {}, "id": "5O3uhT-4FOxpfRhdPy7gf6PRcwKv0B-zIQTFJdMx4t8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kbf0p", "is_robot_indexable": true, "report_reasons": null, "author": "Finndersen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kbf0p/i_wrote_an_article_about_the_cool_things_you_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@finndersen/guide-to-pandas-extension-types-and-how-to-create-your-own-3b213d689c86", "subreddit_subscribers": 854743, "created_utc": 1678131326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.\n\nI started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.\n\nTo fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it's saved with encryption). Then, all you have to do is write what you need in plain English, Ex. \"Users who have been online over 5 days this week\", and it writes the SQL query for you.\n\nI showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.\n\nWhat do you think? Would love to get your feedback. It's 100% free, you couldn't pay me even if you wanted to.", "author_fullname": "t2_11bl5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My AI tool to writes SQL queries for me now, so I don't have to. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11l5jqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.&lt;/p&gt;\n\n&lt;p&gt;I started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.&lt;/p&gt;\n\n&lt;p&gt;To fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it&amp;#39;s saved with encryption). Then, all you have to do is write what you need in plain English, Ex. &amp;quot;Users who have been online over 5 days this week&amp;quot;, and it writes the SQL query for you.&lt;/p&gt;\n\n&lt;p&gt;I showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Would love to get your feedback. It&amp;#39;s 100% free, you couldn&amp;#39;t pay me even if you wanted to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5jqm", "is_robot_indexable": true, "report_reasons": null, "author": "slingshoota", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "subreddit_subscribers": 854743, "created_utc": 1678210291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey,\nI'm here to request some help. Recently I made a credit score model (for credit line updates), the model runs daily and I've noticed that the score for each client changes significantly over time, due to some variables such as full payment, payments, days past due, and others. However, to take a decision I have to define the best point to take the score. I don't how to do it, I was thinking to do an average moving window, but if you have other ideas I'll appreciate it.", "author_fullname": "t2_lwe6pvfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the instability of the output model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l2193", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678202313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,\nI&amp;#39;m here to request some help. Recently I made a credit score model (for credit line updates), the model runs daily and I&amp;#39;ve noticed that the score for each client changes significantly over time, due to some variables such as full payment, payments, days past due, and others. However, to take a decision I have to define the best point to take the score. I don&amp;#39;t how to do it, I was thinking to do an average moving window, but if you have other ideas I&amp;#39;ll appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l2193", "is_robot_indexable": true, "report_reasons": null, "author": "Natalia_Moon", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l2193/question_about_the_instability_of_the_output_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l2193/question_about_the_instability_of_the_output_model/", "subreddit_subscribers": 854743, "created_utc": 1678202313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If anyone has come across any interesting finance or economics related projects, can you link to them here?\n\nI need to use machine learning in that domain for a final project.", "author_fullname": "t2_8fm83pcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Economics/ Finance Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kzxzj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678197224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone has come across any interesting finance or economics related projects, can you link to them here?&lt;/p&gt;\n\n&lt;p&gt;I need to use machine learning in that domain for a final project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kzxzj", "is_robot_indexable": true, "report_reasons": null, "author": "_CynicalCyanide", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kzxzj/data_science_economics_finance_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kzxzj/data_science_economics_finance_projects/", "subreddit_subscribers": 854743, "created_utc": 1678197224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an Indian student doing his undergraduate in B.Tech CSE . DS ( Bachelors of technology in Computer Science Engineering in Data Science) , I\u2019m still a first year student and I\u2019d say I\u2019m pretty good at programming, I wanted to ask here for advice for students who want to get into data science field , what are courses I\u2019ll have to do , what all do I have to learn to get a nice paying job , where are good options to do my masters , I have very little clue as to how this industry works and I wanted some guidance from people working in this industry. \nThank You!!", "author_fullname": "t2_9746vo39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Student and need help knowing what to do in career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kyrsm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678194104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an Indian student doing his undergraduate in B.Tech CSE . DS ( Bachelors of technology in Computer Science Engineering in Data Science) , I\u2019m still a first year student and I\u2019d say I\u2019m pretty good at programming, I wanted to ask here for advice for students who want to get into data science field , what are courses I\u2019ll have to do , what all do I have to learn to get a nice paying job , where are good options to do my masters , I have very little clue as to how this industry works and I wanted some guidance from people working in this industry. \nThank You!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kyrsm", "is_robot_indexable": true, "report_reasons": null, "author": "sumith19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kyrsm/student_and_need_help_knowing_what_to_do_in_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kyrsm/student_and_need_help_knowing_what_to_do_in_career/", "subreddit_subscribers": 854743, "created_utc": 1678194104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nI just wanted to reach out on the off chance that someone has a suggestion. \n\nI have a dataframe that I need to view changes for in a time series, which is simple enough. \n\nThe problem is the number of rows (there are around 200) so generating line and bar plots is messy and difficult to read, and I also need to compare 2 or three columns at a time which further complicates things. \n\nDoes anyone have any tips on visualisation methods to help with this? I had considered plotly and an interactive diagram, however I am including the data in a written paper, so I need static graphs to show the changes/differences between categories without it getting too messy. \n\nIf there are any libraries/approaches that I'm missing do let me know, I'm working with Python and Pandas, and currently matplotlib.", "author_fullname": "t2_1um7ls9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Method for visualising dataframe with many entries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kw86x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678186866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I just wanted to reach out on the off chance that someone has a suggestion. &lt;/p&gt;\n\n&lt;p&gt;I have a dataframe that I need to view changes for in a time series, which is simple enough. &lt;/p&gt;\n\n&lt;p&gt;The problem is the number of rows (there are around 200) so generating line and bar plots is messy and difficult to read, and I also need to compare 2 or three columns at a time which further complicates things. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any tips on visualisation methods to help with this? I had considered plotly and an interactive diagram, however I am including the data in a written paper, so I need static graphs to show the changes/differences between categories without it getting too messy. &lt;/p&gt;\n\n&lt;p&gt;If there are any libraries/approaches that I&amp;#39;m missing do let me know, I&amp;#39;m working with Python and Pandas, and currently matplotlib.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kw86x", "is_robot_indexable": true, "report_reasons": null, "author": "JimmySuicidex", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kw86x/best_method_for_visualising_dataframe_with_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kw86x/best_method_for_visualising_dataframe_with_many/", "subreddit_subscribers": 854743, "created_utc": 1678186866.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}