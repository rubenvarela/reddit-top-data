{"kind": "Listing", "data": {"after": "t3_11l33hu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_479zgx6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rich Jupyter Notebook Diffs on GitHub... Finally.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_11l2ojh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 212, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 212, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/PvkJonCBrm55xEa1hSeNqwyOUAcm0SG1VzQFV17rHVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678203789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kvhebtuu7cma1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kvhebtuu7cma1.png?auto=webp&amp;v=enabled&amp;s=6c9567daa41908136cc898b0d1f1ee53c7727251", "width": 1222, "height": 805}, "resolutions": [{"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb23c929b73c2c109150b9b96faa2adbf2c28153", "width": 108, "height": 71}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=557a9586b2872506a27041bc5e5fd42c49d6fa5b", "width": 216, "height": 142}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7697cd5d5cc43d61881c88fe934174912082669", "width": 320, "height": 210}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df8b0f73a34fd987a2543626f8eee0cea16b768b", "width": 640, "height": 421}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93f05243bd0498494b82534038f49a42e4ba37ad", "width": 960, "height": 632}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed60a93aef191fde96aaa484504a2e11182b3384", "width": 1080, "height": 711}], "variants": {}, "id": "CS5aUJvi1pTuFwS4VGyg2ZqyibSL9XYgRap8O5u4-nY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l2ojh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomForests92", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l2ojh/rich_jupyter_notebook_diffs_on_github_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kvhebtuu7cma1.png", "subreddit_subscribers": 854786, "created_utc": 1678203789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area\n\nI make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.\n\nMy analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019\n\nI\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? \n\nThis might be too high level so happy to provide more detail.\n\nEdit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay", "author_fullname": "t2_ekymh22j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overpaid and don\u2019t see the point", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l5mg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 128, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 128, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678212638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area&lt;/p&gt;\n\n&lt;p&gt;I make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.&lt;/p&gt;\n\n&lt;p&gt;My analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? &lt;/p&gt;\n\n&lt;p&gt;This might be too high level so happy to provide more detail.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5mg2", "is_robot_indexable": true, "report_reasons": null, "author": "leaver_believer", "discussion_type": null, "num_comments": 111, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "subreddit_subscribers": 854786, "created_utc": 1678210462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. \n\n&amp;#x200B;\n\nIs this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should working in DS be this boring?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kzfdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678196070.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678195889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kzfdo", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "subreddit_subscribers": 854786, "created_utc": 1678195889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!\n\nI dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.\n\nI know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.\n\nI think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)", "author_fullname": "t2_4lqbue6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AMA: Broke into DS without masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ks4c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678172417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!&lt;/p&gt;\n\n&lt;p&gt;I dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.&lt;/p&gt;\n\n&lt;p&gt;I know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.&lt;/p&gt;\n\n&lt;p&gt;I think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ks4c2", "is_robot_indexable": true, "report_reasons": null, "author": "beecheee", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "subreddit_subscribers": 854786, "created_utc": 1678172417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_d45r1", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Using an AI plugin I made to guess gender from email, do sentiment analysis, and perform a simple segmentation analysis (link in comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6mx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 22, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gl7qbixaycma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gl7qbixaycma1/DASH_96.mp4", "dash_url": "https://v.redd.it/gl7qbixaycma1/DASHPlaylist.mpd?a=1680820816%2CNGZhNzhlMDViZWQyNDBkNzYzMTNmM2EzYTYxMGI1NzYzZTI0MTg2Y2QyMzY3NjgxMWM0ZDY3NjUxYTQ4N2E4Nw%3D%3D&amp;v=1&amp;f=sd", "duration": 59, "hls_url": "https://v.redd.it/gl7qbixaycma1/HLSPlaylist.m3u8?a=1680820816%2CNTEwM2ZmNDgzNDI2ZTQ5N2I4ZWUzZDJlYmMxOTcyNWZlZDczMzdjMzA0YzQ3ZThjZWQ0ZWI0YzYxNmNhZGNmMw%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/n-kPPvWPj4MR9Q4LnV3nLDI0Ekf3ozNAqsj0vNaHp2M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678212732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/gl7qbixaycma1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=208b7756ddbcf6ddd289954408b6bfa17399b8fc", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c03433464c2d0fd616fd531fbce1a4d95b253574", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=48b0fe7a9b1f2a8a7ce37de03856ad356bb50350", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c555c144f46f0f4afdab95de55bfac9b6f72a444", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=23ed97680da41e8c2f2f9bb2b8d2d914bd68e25e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8681d0bf1822ad9e100b1cb8ceb39f986a82566b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d1307ec178800150011d9636b3929d9ef2cdf9ab", "width": 1080, "height": 607}], "variants": {}, "id": "uNAtrEjago7y_yM6VbHNDvEaHE2BvZVv0bvUxOr6VVg"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6mx3", "is_robot_indexable": true, "report_reasons": null, "author": "rtwalz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6mx3/using_an_ai_plugin_i_made_to_guess_gender_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/gl7qbixaycma1", "subreddit_subscribers": 854786, "created_utc": 1678212732.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gl7qbixaycma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gl7qbixaycma1/DASH_96.mp4", "dash_url": "https://v.redd.it/gl7qbixaycma1/DASHPlaylist.mpd?a=1680820816%2CNGZhNzhlMDViZWQyNDBkNzYzMTNmM2EzYTYxMGI1NzYzZTI0MTg2Y2QyMzY3NjgxMWM0ZDY3NjUxYTQ4N2E4Nw%3D%3D&amp;v=1&amp;f=sd", "duration": 59, "hls_url": "https://v.redd.it/gl7qbixaycma1/HLSPlaylist.m3u8?a=1680820816%2CNTEwM2ZmNDgzNDI2ZTQ5N2I4ZWUzZDJlYmMxOTcyNWZlZDczMzdjMzA0YzQ3ZThjZWQ0ZWI0YzYxNmNhZGNmMw%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I've been told I won't be kept on past that. I have 6 years experience in the field, so I'm quite surprised. I have had to upskill a lot, but the systems were messy and I've struggled to know how to approach finding data since whenever I've asked I've been drawn into a call with my supervisor who has then picked apart whatever I've been working on which isn't usually finished instead of just directing me to the correct database so I can figure it out. I'm a bit lost since I've been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn't have enough attention to detail (but I would argue most of the tasks I submit haven't been finished since they end up getting reviewed the moment I ask a question). \n\nAny advice on next steps? I've never failed probation before, so I'm a bit lost.", "author_fullname": "t2_9ku7bdlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been told I won't be kept on past probation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ky71w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678192527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I&amp;#39;ve been told I won&amp;#39;t be kept on past that. I have 6 years experience in the field, so I&amp;#39;m quite surprised. I have had to upskill a lot, but the systems were messy and I&amp;#39;ve struggled to know how to approach finding data since whenever I&amp;#39;ve asked I&amp;#39;ve been drawn into a call with my supervisor who has then picked apart whatever I&amp;#39;ve been working on which isn&amp;#39;t usually finished instead of just directing me to the correct database so I can figure it out. I&amp;#39;m a bit lost since I&amp;#39;ve been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn&amp;#39;t have enough attention to detail (but I would argue most of the tasks I submit haven&amp;#39;t been finished since they end up getting reviewed the moment I ask a question). &lt;/p&gt;\n\n&lt;p&gt;Any advice on next steps? I&amp;#39;ve never failed probation before, so I&amp;#39;m a bit lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ky71w", "is_robot_indexable": true, "report_reasons": null, "author": "LazyTowels", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "subreddit_subscribers": 854786, "created_utc": 1678192527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This might be a dumb question, but i am a phd student who has been working with data for the past 4-5 years. I honestly suck at organizing my work. I am now switching to a macbook and would like to hear about any tips to stay more organized, both file and code wise (mac related shortcuts are also appreciated). I mainly us R but slowly transitioning to python on VScode.", "author_fullname": "t2_mzpvx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow tips (particularly mac)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11khwf2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678145299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a dumb question, but i am a phd student who has been working with data for the past 4-5 years. I honestly suck at organizing my work. I am now switching to a macbook and would like to hear about any tips to stay more organized, both file and code wise (mac related shortcuts are also appreciated). I mainly us R but slowly transitioning to python on VScode.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11khwf2", "is_robot_indexable": true, "report_reasons": null, "author": "supertitiz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11khwf2/workflow_tips_particularly_mac/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11khwf2/workflow_tips_particularly_mac/", "subreddit_subscribers": 854786, "created_utc": 1678145299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_36ft48fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Runtime completion for complied data science libraries like NumPy or PyTorch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o0oda9i8gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=8ef57fdec22a638cd31c7e8c0b52267ee13e8048"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f28dd96be1ef957c2ce03353670d2e787df5e0cd"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=c5271df2a69516467f17c606c8189ece511fc55b"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=b5af76536900f11ce6e47935ffe48df6ac530f92"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6ca36cf6e5215add16f858f86ce7fbb155e79256"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6f463d7949ce6a9d51ba375b1b38f1345053a114"}], "s": {"y": 464, "gif": "https://i.redd.it/o0oda9i8gama1.gif", "mp4": "https://preview.redd.it/o0oda9i8gama1.gif?format=mp4&amp;v=enabled&amp;s=36d5d4b24086cde32f50838f35cc72ab556c0316", "x": 1286}, "id": "o0oda9i8gama1"}, "lnjuf7f9gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d31f1010917b9b11e9aad2869d1d7e1628147600"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6375bb64784d52479828bf317a7cb224397bdc1b"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=310ea65799c162162401f50ff7fdc5b9f51ac2e9"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=badbe2de57d5e6af756a27fdfbaca015e1d2e1e8"}], "s": {"y": 464, "gif": "https://i.redd.it/lnjuf7f9gama1.gif", "mp4": "https://preview.redd.it/lnjuf7f9gama1.gif?format=mp4&amp;v=enabled&amp;s=0d640473048426611a3d361a183a2adebb690972", "x": 643}, "id": "lnjuf7f9gama1"}, "xbqpr029gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3cee312028b9a8a19f6fd001e3534091441878dd"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d62de689ec524f319a18b7f7bd3cee61e80370cb"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=2534628b83e1d50b656191828cf03ee87f255928"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9dbcedb45167fda56e88d929a61599bb71e3b838"}], "s": {"y": 464, "gif": "https://i.redd.it/xbqpr029gama1.gif", "mp4": "https://preview.redd.it/xbqpr029gama1.gif?format=mp4&amp;v=enabled&amp;s=6ea8eaabc78a9d8ca17c0dbff282d71e3ed54e26", "x": 643}, "id": "xbqpr029gama1"}}, "name": "t3_11kuyu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 10, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Left hand side - during debugging with reloadium, right hand side, without debugging", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "o0oda9i8gama1", "id": 248228601}, {"caption": "Runtime completion with reloadium", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "xbqpr029gama1", "id": 248228602}, {"media_id": "lnjuf7f9gama1", "id": 248228603}]}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4Rwp5v78I_1uAbgPoQvdJI5LnpISGrOAxpfi4NNBVWI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678182816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/11kuyu6", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "11kuyu6", "is_robot_indexable": true, "report_reasons": null, "author": "kwazar90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kuyu6/runtime_completion_for_complied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/reloadware/reloadium", "subreddit_subscribers": 854786, "created_utc": 1678182816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.\n\nI started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.\n\nTo fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it's saved with encryption). Then, all you have to do is write what you need in plain English, Ex. \"Users who have been online over 5 days this week\", and it writes the SQL query for you.\n\nI showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.\n\nWhat do you think? Would love to get your feedback. It's 100% free, you couldn't pay me even if you wanted to.", "author_fullname": "t2_11bl5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My AI tool to writes SQL queries for me now, so I don't have to. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l5jqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.&lt;/p&gt;\n\n&lt;p&gt;I started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.&lt;/p&gt;\n\n&lt;p&gt;To fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it&amp;#39;s saved with encryption). Then, all you have to do is write what you need in plain English, Ex. &amp;quot;Users who have been online over 5 days this week&amp;quot;, and it writes the SQL query for you.&lt;/p&gt;\n\n&lt;p&gt;I showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Would love to get your feedback. It&amp;#39;s 100% free, you couldn&amp;#39;t pay me even if you wanted to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5jqm", "is_robot_indexable": true, "report_reasons": null, "author": "slingshoota", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "subreddit_subscribers": 854786, "created_utc": 1678210291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was asked by leadership to create a massive pdf that contains bunch of line graphs with week vs week data with all possible way that we can break out. Example: sales by country, sales by state, sales by market and so on.  The goal is the catch if something isn\u2019t right and\n99% of reports in the business are line graphs.\n\nIn my mind that is waste of time because no one will ever look at 500 pages PDF so I was thinking of suggesting algorithm that would highlight every week the biggest problem or drop based on historical performance. \n\n\nI was hoping to get some inspiration, or tools suggestions to help me get started.", "author_fullname": "t2_c24qzfnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anomaly detection Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11lc2v9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678224783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked by leadership to create a massive pdf that contains bunch of line graphs with week vs week data with all possible way that we can break out. Example: sales by country, sales by state, sales by market and so on.  The goal is the catch if something isn\u2019t right and\n99% of reports in the business are line graphs.&lt;/p&gt;\n\n&lt;p&gt;In my mind that is waste of time because no one will ever look at 500 pages PDF so I was thinking of suggesting algorithm that would highlight every week the biggest problem or drop based on historical performance. &lt;/p&gt;\n\n&lt;p&gt;I was hoping to get some inspiration, or tools suggestions to help me get started.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lc2v9", "is_robot_indexable": true, "report_reasons": null, "author": "Grapeflavor_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lc2v9/anomaly_detection_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lc2v9/anomaly_detection_algorithms/", "subreddit_subscribers": 854786, "created_utc": 1678224783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anybody know a website besides Linkedin Jobs to find/filter DS/MLE jobs at startups (Series A/B/C/D/E)? \n\nIt is so hard to filter on Linkedin and it kind of pisses me off to see 6+ YOE DS jobs with \"Entry level\" tags on Linkedin.", "author_fullname": "t2_6gpihliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find DS jobs at funded Startups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l8h6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678216827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know a website besides Linkedin Jobs to find/filter DS/MLE jobs at startups (Series A/B/C/D/E)? &lt;/p&gt;\n\n&lt;p&gt;It is so hard to filter on Linkedin and it kind of pisses me off to see 6+ YOE DS jobs with &amp;quot;Entry level&amp;quot; tags on Linkedin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l8h6t", "is_robot_indexable": true, "report_reasons": null, "author": "wardrobe_creator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l8h6t/how_to_find_ds_jobs_at_funded_startups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l8h6t/how_to_find_ds_jobs_at_funded_startups/", "subreddit_subscribers": 854786, "created_utc": 1678216827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Working with big economics datasets e.g. 10-50 gb. \n\nOnce I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift \n\nProblem is anytime I try to debug to see if it's working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. \n\nAssuming I've used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. \n\nWhat other things can I add to my code:\n\n1. To not have to read my data in every time I run the code while developing n debugging \n\n2. Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints \n\nOther economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it's in use", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for a way of reading big data files into python without having to read the same file everything I run ti debug", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6eff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with big economics datasets e.g. 10-50 gb. &lt;/p&gt;\n\n&lt;p&gt;Once I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift &lt;/p&gt;\n\n&lt;p&gt;Problem is anytime I try to debug to see if it&amp;#39;s working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. &lt;/p&gt;\n\n&lt;p&gt;Assuming I&amp;#39;ve used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. &lt;/p&gt;\n\n&lt;p&gt;What other things can I add to my code:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;To not have to read my data in every time I run the code while developing n debugging &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it&amp;#39;s in use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6eff", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "subreddit_subscribers": 854786, "created_utc": 1678212199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR; graduating with a Masters in Mathematics this May, seeking some guidance/advice for breaking into data science (or getting any sort of non-teaching job, really).\n\nI've been applying to both full-time jobs in data science/analytics and internships for 4-5 months and have received one final round interview so far for an internship. Lots of rejections. I know the market sucks in general right now, but I can't help think there's something I'm doing wrong or something I could improve on to help my chances. I've been a high achiever my entire life, but I just feel pretty down about choosing a math degree when what I want to do for a career is data science. People say math is a great choice, and I know I would make a wonderful employee, there is **great** value in having a math education, but I don't think tech recruiters are seeing that? I would love to hear some insight from folks who transitioned into data science from a non-CS degree (math in particular, or otherwise). Any tips, connections, or general empathy is super appreciated.\n\nAcademic Background: I have a BS in Pure Math from a small private liberal arts university, finishing up my MS in Mathematics this may from a mid-tier public state school. Graduated with a 4.0 from undergrad with Honors and I won my department's award for high achievement in mathematics. I currently have a 3.8 in grad school, and have been a graduate assistant for the past two years. The past year I have been instructor-of-record for a business calculus class. Courses from grad school include: 4 semesters of real analysis, Applied Probability, Dynamical Systems, Ordinary Differential Equations, Data Structures and Algorithms (CS course), Numerical Linear Algebra, and Numerical Linear Algebra II for Data Science. In the latter course we essentially learned the math behind a bunch of machine learning algorithms, as well as how to implement them from scratch in Python and using Scikit learn.\n\nSkills: Python (3 years), SQL (pretty much beginner level), Java, C++, MATLAB, packages in Python: numpy, pandas, scikit-learn, tensorflow, matplotlib.\n\nOther background: I'm a female, on the East Coast of the US, I was a collegiate athlete (swimming) and team captain, sorority member and served on the exec board, president of the math club in undergrad, and am currently secretary for the Math graduate student association at my university. I have no related work experience or internships (I've applied every summer for the past 2 years, no luck, I received one interview total)\n\nI have 2 data science projects listed on my resume. One is an image recognition program using CNN, and one is a clustering project. I also feel confident in my ability to do well in a technical interview, but I have not been given the chance yet.\n\nI will say, I don't as of right now have a github profile, and am not posting my work online. I understand why this would be quite important, but a math degree and teaching is time consuming and I haven't had the free time to put out work that I am proud of.\n\nThis leads me to a second question: I don't know exactly what the standard is for posting my work, how do I know if a certain project is good, has enough work done on it, isn't redundant from what others have done, etc? I guess I would say I know how to implement a bunch of machine learning algorithms including neural networks, and I know why they work and when to use which one, but in terms of putting together a nice example project, I'm unconfident.  What advice/resources/guidance can you give me on this specifically, and do you think this is the main reason I'm not getting interviews?\n\nThat felt a little all over the place, but hearing back from anyone with some encouragement and help would be appreciated. Thank you!", "author_fullname": "t2_5sy262lv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Math Masters graduate trying to get a job in DS, advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l80yy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678215814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; graduating with a Masters in Mathematics this May, seeking some guidance/advice for breaking into data science (or getting any sort of non-teaching job, really).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying to both full-time jobs in data science/analytics and internships for 4-5 months and have received one final round interview so far for an internship. Lots of rejections. I know the market sucks in general right now, but I can&amp;#39;t help think there&amp;#39;s something I&amp;#39;m doing wrong or something I could improve on to help my chances. I&amp;#39;ve been a high achiever my entire life, but I just feel pretty down about choosing a math degree when what I want to do for a career is data science. People say math is a great choice, and I know I would make a wonderful employee, there is &lt;strong&gt;great&lt;/strong&gt; value in having a math education, but I don&amp;#39;t think tech recruiters are seeing that? I would love to hear some insight from folks who transitioned into data science from a non-CS degree (math in particular, or otherwise). Any tips, connections, or general empathy is super appreciated.&lt;/p&gt;\n\n&lt;p&gt;Academic Background: I have a BS in Pure Math from a small private liberal arts university, finishing up my MS in Mathematics this may from a mid-tier public state school. Graduated with a 4.0 from undergrad with Honors and I won my department&amp;#39;s award for high achievement in mathematics. I currently have a 3.8 in grad school, and have been a graduate assistant for the past two years. The past year I have been instructor-of-record for a business calculus class. Courses from grad school include: 4 semesters of real analysis, Applied Probability, Dynamical Systems, Ordinary Differential Equations, Data Structures and Algorithms (CS course), Numerical Linear Algebra, and Numerical Linear Algebra II for Data Science. In the latter course we essentially learned the math behind a bunch of machine learning algorithms, as well as how to implement them from scratch in Python and using Scikit learn.&lt;/p&gt;\n\n&lt;p&gt;Skills: Python (3 years), SQL (pretty much beginner level), Java, C++, MATLAB, packages in Python: numpy, pandas, scikit-learn, tensorflow, matplotlib.&lt;/p&gt;\n\n&lt;p&gt;Other background: I&amp;#39;m a female, on the East Coast of the US, I was a collegiate athlete (swimming) and team captain, sorority member and served on the exec board, president of the math club in undergrad, and am currently secretary for the Math graduate student association at my university. I have no related work experience or internships (I&amp;#39;ve applied every summer for the past 2 years, no luck, I received one interview total)&lt;/p&gt;\n\n&lt;p&gt;I have 2 data science projects listed on my resume. One is an image recognition program using CNN, and one is a clustering project. I also feel confident in my ability to do well in a technical interview, but I have not been given the chance yet.&lt;/p&gt;\n\n&lt;p&gt;I will say, I don&amp;#39;t as of right now have a github profile, and am not posting my work online. I understand why this would be quite important, but a math degree and teaching is time consuming and I haven&amp;#39;t had the free time to put out work that I am proud of.&lt;/p&gt;\n\n&lt;p&gt;This leads me to a second question: I don&amp;#39;t know exactly what the standard is for posting my work, how do I know if a certain project is good, has enough work done on it, isn&amp;#39;t redundant from what others have done, etc? I guess I would say I know how to implement a bunch of machine learning algorithms including neural networks, and I know why they work and when to use which one, but in terms of putting together a nice example project, I&amp;#39;m unconfident.  What advice/resources/guidance can you give me on this specifically, and do you think this is the main reason I&amp;#39;m not getting interviews?&lt;/p&gt;\n\n&lt;p&gt;That felt a little all over the place, but hearing back from anyone with some encouragement and help would be appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l80yy", "is_robot_indexable": true, "report_reasons": null, "author": "tim-shel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l80yy/math_masters_graduate_trying_to_get_a_job_in_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l80yy/math_masters_graduate_trying_to_get_a_job_in_ds/", "subreddit_subscribers": 854786, "created_utc": 1678215814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone\n\nI'm currently using key words to detect certain events in textual data. However, I'm wondering whether there is a more advanced tool I can use to help me in this application.\n\nSay I have two sentences:\n1- \"I woke up today and it was raining\"\n2- \"I woke up today and it was not raining\"\n\nI would like to add a \"rain\" tag to the first sentence and not the second sentence.\n\nI'm currently using regex but the patterns are getting too long and complex. Is there a better tool that could help me with this application?", "author_fullname": "t2_l1lf6s9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool for Event Detection in Textual Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6r3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using key words to detect certain events in textual data. However, I&amp;#39;m wondering whether there is a more advanced tool I can use to help me in this application.&lt;/p&gt;\n\n&lt;p&gt;Say I have two sentences:\n1- &amp;quot;I woke up today and it was raining&amp;quot;\n2- &amp;quot;I woke up today and it was not raining&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I would like to add a &amp;quot;rain&amp;quot; tag to the first sentence and not the second sentence.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using regex but the patterns are getting too long and complex. Is there a better tool that could help me with this application?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6r3h", "is_robot_indexable": true, "report_reasons": null, "author": "Unlikely_Silver_1650", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6r3h/tool_for_event_detection_in_textual_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6r3h/tool_for_event_detection_in_textual_data/", "subreddit_subscribers": 854786, "created_utc": 1678212993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, just wondering if someone with more experience in the field could answer this question.\n\nI got my first data job about 6 months ago at a market research company, I mainly use SPSS excel and to a lesser extent R in my work.\n\nSome of the work is super interesting and statistics heavy but I fear that as I am not getting hands on experience with more modern tools (SQL, powerBI, Tableau, Azure etc) I worry I will find it hard to get a job outside of my company.\n\nSo the question is, is it worth staying for a couple years (I enjoy the company) or should I leave early due to not learning marketable skills.", "author_fullname": "t2_vym43h1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long should I stay in this role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11lbr32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678225438.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678224038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wondering if someone with more experience in the field could answer this question.&lt;/p&gt;\n\n&lt;p&gt;I got my first data job about 6 months ago at a market research company, I mainly use SPSS excel and to a lesser extent R in my work.&lt;/p&gt;\n\n&lt;p&gt;Some of the work is super interesting and statistics heavy but I fear that as I am not getting hands on experience with more modern tools (SQL, powerBI, Tableau, Azure etc) I worry I will find it hard to get a job outside of my company.&lt;/p&gt;\n\n&lt;p&gt;So the question is, is it worth staying for a couple years (I enjoy the company) or should I leave early due to not learning marketable skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lbr32", "is_robot_indexable": true, "report_reasons": null, "author": "Blue__Agave", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lbr32/how_long_should_i_stay_in_this_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lbr32/how_long_should_i_stay_in_this_role/", "subreddit_subscribers": 854786, "created_utc": 1678224038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI've been working on a problem which I can't seem to get my head round at the moment. I have a dataset lets say is like the following:\n\n&amp;#x200B;\n\n|user\\_id|discount\\_offered|price\\_pre\\_discount|price\\_after\\_discount|actual\\_discount|profit|\n|:-|:-|:-|:-|:-|:-|\n|3720917|10|1000|900|100|450|\n|9283908|10|1000|950|50|475|\n|3488334|0|1000|1000|0|500|\n\nso we can see that even with discount offered the actual discount may only have a weaker than expected correlation. This can be because the discount may only apply to certain items or shipping may not be included in certain deals etc. \n\n&amp;#x200B;\n\nBasically what I want to do is to optimise the discount offered to maximise profit, in this particular fake data i made further up the post, 10% discount would be optimal because although the profit was lower, it pushed more sales. \n\n&amp;#x200B;\n\nIt seems to me like this should be possible to solve via some sort of optimisation problem but I'm not sure how to do it or if it is even possible? Like some type of gradient descent maybe? But then how can I extract the optimal value of discount? \n\n&amp;#x200B;\n\nI also looked into using the pulp package but it seems its more just theoretical if I input the algebraic formula for revenue and then solve for discount, with a constraint it can't be negative discount, but then that doesn't take into affect the volume of sales and I can't figure out how to incorporate it?\n\n&amp;#x200B;\n\nAny tips or nudges in the right direction would be awesome and I'm happy to answer questions as best as I can... I'm not so sure I fully understand the problem myself so might not have explained it great!", "author_fullname": "t2_g4nqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "optimising sales from discount offered", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11laztr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678222413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a problem which I can&amp;#39;t seem to get my head round at the moment. I have a dataset lets say is like the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;user_id&lt;/th&gt;\n&lt;th align=\"left\"&gt;discount_offered&lt;/th&gt;\n&lt;th align=\"left\"&gt;price_pre_discount&lt;/th&gt;\n&lt;th align=\"left\"&gt;price_after_discount&lt;/th&gt;\n&lt;th align=\"left\"&gt;actual_discount&lt;/th&gt;\n&lt;th align=\"left\"&gt;profit&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3720917&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;900&lt;/td&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;450&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;9283908&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;950&lt;/td&gt;\n&lt;td align=\"left\"&gt;50&lt;/td&gt;\n&lt;td align=\"left\"&gt;475&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3488334&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;500&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;so we can see that even with discount offered the actual discount may only have a weaker than expected correlation. This can be because the discount may only apply to certain items or shipping may not be included in certain deals etc. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically what I want to do is to optimise the discount offered to maximise profit, in this particular fake data i made further up the post, 10% discount would be optimal because although the profit was lower, it pushed more sales. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It seems to me like this should be possible to solve via some sort of optimisation problem but I&amp;#39;m not sure how to do it or if it is even possible? Like some type of gradient descent maybe? But then how can I extract the optimal value of discount? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also looked into using the pulp package but it seems its more just theoretical if I input the algebraic formula for revenue and then solve for discount, with a constraint it can&amp;#39;t be negative discount, but then that doesn&amp;#39;t take into affect the volume of sales and I can&amp;#39;t figure out how to incorporate it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any tips or nudges in the right direction would be awesome and I&amp;#39;m happy to answer questions as best as I can... I&amp;#39;m not so sure I fully understand the problem myself so might not have explained it great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11laztr", "is_robot_indexable": true, "report_reasons": null, "author": "god_dammit_karl", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11laztr/optimising_sales_from_discount_offered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11laztr/optimising_sales_from_discount_offered/", "subreddit_subscribers": 854786, "created_utc": 1678222413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " **TL;DR: My friends and I have a stupid hobby that's getting out of control and I need your help spiraling it further. Please help me create a fair power rankings system (using the attached spreadsheet for reference) for the Beerio Kart tournaments we host.**\n\n[**https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc\\_jHWbTZ\\_khS/edit?usp=sharing&amp;ouid=114408781303577995971&amp;rtpof=true&amp;sd=true**](https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;ouid=114408781303577995971&amp;rtpof=true&amp;sd=true)\n\nDear members of the Data Science community,\n\nI call humbly upon the mario kart champions, statisticians, mathematicians, programming aficionados, excel experts, sports analysts, and power rankings enthusiasts of this great community to assist me with a vital task -- creating a fair and representative power ranking formula for the International Beerio Kart Championships of the World.\n\nA little background: my buddies and I were trapped at home Thanksgiving of '21 for a fourteen day COVID quarantine. We were saddened by a missed opportunity to see our families, but with competitive spirit running through our veins and a surplus of leftover PBR from a party we threw (which was undoubtedly what gave us COVID), we found solace in roughly two weeks straight of fierce competition in the best drinking/video game pair to ever exist: Beerio Kart. For the uninitiated: Beerio Kart is Mario Kart, however, you need to finish your beer before the end of each race, and you can't drink and drive (i.e. chug and control your character simultaneously). Our version of the game has many extra rules and sub-rules, however, that's the basic premise of the game.\n\nAfter two weeks of this, we needed an outlet to determine who was truly the best of us, and thusly the International Beerio Kart Championships of the World were born. It started with a modest eight competitors, but interest has increased steadily over the past three years and in recent events we've had as many as 58 competitors fighting to compete in a 32 person bracket (surplus competitors play in Play-in Prix's for entry into the main bracket). We've now had 75 people play in official brackets and obtain power rankings, and close to 100 participate in the events overall. For a little context into how the tournaments are run, four competitors participate in each Grand Prix, and the top two competitors advance from each round until the championship. In the preliminary rounds, players must drink a beer on races two and four of each Grand Prix, and in the finals all four races are drinking rounds, thusly the final four competitors must drink a minimum of 10 beers to win the tournament.\n\nAs tournaments got larger and more intricate (and people started complaining that they were seeded unfairly), we realized we needed an objective ranking system to seed players so that the Prix's leading up to the championship were fair and quantitative. This background brings me to the hallowed undertaking I beseech your help with: **please help me figure out how to do this.**\n\nWe've tried a few formulas, but we are but amateur statisticians and none have felt like they effectively capture a player's skill level.\n\nFirst we tried the following formula: ibkc power ranking = 0.33t/60n + 0.33z/60 + 0.33y/60, where:\n\n1. 60 = the maximum number of possible points scored in any given grand prix\n2. t = total points accrued over all past tournaments attended\n3. n = total number of grand prix\u2019 held in all official tournaments\n4. z = average points scored per prix, per tournament, in all tournaments attended\n5. y = average points scored per prix, per tournament, in all tournaments attended this calendar year\n\nIt was a good start, but it unfairly biased players who had played in more tournaments, and wasn't an accurate reflection of *current* skill level. It would be like baseball power rankings putting the Yankees are at the top because they're an ancient ball club and have won 27 World Series', even though the last time they won was 2009, or the Astros low down on the power rankings because they didn't win their first Series until 2017, even though they've won twice in the past 5 years.\n\nWe then created a formula based on Pythagorean expectation, where a players skill level is calculated by averaging their (points accrued in a prix)/(points accrued in a prix + total number of possible points in a prix). Each round of a tournament was weighted heavier than the last, and tournaments with four rounds carry more weight than tournaments with three rounds. The player's Pythagorean expectation was then averaged over all tournaments they've participated in, averaged over the last four tournaments held, and averaged over the last two tournaments held. Their power score was then calculated by averaging these three numbers together with the intention that more recent tournaments would be weighted heavier than older ones. **This is the formula that the attached spreadsheet uses.**\n\nThis new formula was better than the first but has an inverse problem -- it weighs recent tournaments too heavily and doesn't account for any rank decay from missing tournaments. For example, you can see that BAT has won 6 of 8 tournaments, but after a huge upset in the semi's, BAT did not make the finals of the last tournament, and was booted from first place overall to third. All the while, Squirt4Boyz advanced from second place overall to first, even though Squirt4Boyz didn't even participate in the last tournament.\n\nThere's all sorts of hidden columns and rows and whatnot in this spreadsheet so please dm me with any questions you might have, but please, I beg of you fine and glorious proprietors of the world's most stressful game, help me create a ranking system that makes sense. **Ultimately we need a system that reflects how many points a player is expected to score, considers that player's tournament wins, podium finishes and finals appearances, accounts for rank decay, and like in global tennis or golf rankings, has some bias for recent events.**\n\nThank you, friends.\n\nYour servant,\n\nThe International Beerio Kart Championships of the World League Commissioner", "author_fullname": "t2_7kap8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "International Beerio Kart Championships of the World: Data Scientists, please help me!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11la0m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678220225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR: My friends and I have a stupid hobby that&amp;#39;s getting out of control and I need your help spiraling it further. Please help me create a fair power rankings system (using the attached spreadsheet for reference) for the Beerio Kart tournaments we host.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;amp;ouid=114408781303577995971&amp;amp;rtpof=true&amp;amp;sd=true\"&gt;&lt;strong&gt;https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;amp;ouid=114408781303577995971&amp;amp;rtpof=true&amp;amp;sd=true&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Dear members of the Data Science community,&lt;/p&gt;\n\n&lt;p&gt;I call humbly upon the mario kart champions, statisticians, mathematicians, programming aficionados, excel experts, sports analysts, and power rankings enthusiasts of this great community to assist me with a vital task -- creating a fair and representative power ranking formula for the International Beerio Kart Championships of the World.&lt;/p&gt;\n\n&lt;p&gt;A little background: my buddies and I were trapped at home Thanksgiving of &amp;#39;21 for a fourteen day COVID quarantine. We were saddened by a missed opportunity to see our families, but with competitive spirit running through our veins and a surplus of leftover PBR from a party we threw (which was undoubtedly what gave us COVID), we found solace in roughly two weeks straight of fierce competition in the best drinking/video game pair to ever exist: Beerio Kart. For the uninitiated: Beerio Kart is Mario Kart, however, you need to finish your beer before the end of each race, and you can&amp;#39;t drink and drive (i.e. chug and control your character simultaneously). Our version of the game has many extra rules and sub-rules, however, that&amp;#39;s the basic premise of the game.&lt;/p&gt;\n\n&lt;p&gt;After two weeks of this, we needed an outlet to determine who was truly the best of us, and thusly the International Beerio Kart Championships of the World were born. It started with a modest eight competitors, but interest has increased steadily over the past three years and in recent events we&amp;#39;ve had as many as 58 competitors fighting to compete in a 32 person bracket (surplus competitors play in Play-in Prix&amp;#39;s for entry into the main bracket). We&amp;#39;ve now had 75 people play in official brackets and obtain power rankings, and close to 100 participate in the events overall. For a little context into how the tournaments are run, four competitors participate in each Grand Prix, and the top two competitors advance from each round until the championship. In the preliminary rounds, players must drink a beer on races two and four of each Grand Prix, and in the finals all four races are drinking rounds, thusly the final four competitors must drink a minimum of 10 beers to win the tournament.&lt;/p&gt;\n\n&lt;p&gt;As tournaments got larger and more intricate (and people started complaining that they were seeded unfairly), we realized we needed an objective ranking system to seed players so that the Prix&amp;#39;s leading up to the championship were fair and quantitative. This background brings me to the hallowed undertaking I beseech your help with: &lt;strong&gt;please help me figure out how to do this.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve tried a few formulas, but we are but amateur statisticians and none have felt like they effectively capture a player&amp;#39;s skill level.&lt;/p&gt;\n\n&lt;p&gt;First we tried the following formula: ibkc power ranking = 0.33t/60n + 0.33z/60 + 0.33y/60, where:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;60 = the maximum number of possible points scored in any given grand prix&lt;/li&gt;\n&lt;li&gt;t = total points accrued over all past tournaments attended&lt;/li&gt;\n&lt;li&gt;n = total number of grand prix\u2019 held in all official tournaments&lt;/li&gt;\n&lt;li&gt;z = average points scored per prix, per tournament, in all tournaments attended&lt;/li&gt;\n&lt;li&gt;y = average points scored per prix, per tournament, in all tournaments attended this calendar year&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It was a good start, but it unfairly biased players who had played in more tournaments, and wasn&amp;#39;t an accurate reflection of &lt;em&gt;current&lt;/em&gt; skill level. It would be like baseball power rankings putting the Yankees are at the top because they&amp;#39;re an ancient ball club and have won 27 World Series&amp;#39;, even though the last time they won was 2009, or the Astros low down on the power rankings because they didn&amp;#39;t win their first Series until 2017, even though they&amp;#39;ve won twice in the past 5 years.&lt;/p&gt;\n\n&lt;p&gt;We then created a formula based on Pythagorean expectation, where a players skill level is calculated by averaging their (points accrued in a prix)/(points accrued in a prix + total number of possible points in a prix). Each round of a tournament was weighted heavier than the last, and tournaments with four rounds carry more weight than tournaments with three rounds. The player&amp;#39;s Pythagorean expectation was then averaged over all tournaments they&amp;#39;ve participated in, averaged over the last four tournaments held, and averaged over the last two tournaments held. Their power score was then calculated by averaging these three numbers together with the intention that more recent tournaments would be weighted heavier than older ones. &lt;strong&gt;This is the formula that the attached spreadsheet uses.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This new formula was better than the first but has an inverse problem -- it weighs recent tournaments too heavily and doesn&amp;#39;t account for any rank decay from missing tournaments. For example, you can see that BAT has won 6 of 8 tournaments, but after a huge upset in the semi&amp;#39;s, BAT did not make the finals of the last tournament, and was booted from first place overall to third. All the while, Squirt4Boyz advanced from second place overall to first, even though Squirt4Boyz didn&amp;#39;t even participate in the last tournament.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s all sorts of hidden columns and rows and whatnot in this spreadsheet so please dm me with any questions you might have, but please, I beg of you fine and glorious proprietors of the world&amp;#39;s most stressful game, help me create a ranking system that makes sense. &lt;strong&gt;Ultimately we need a system that reflects how many points a player is expected to score, considers that player&amp;#39;s tournament wins, podium finishes and finals appearances, accounts for rank decay, and like in global tennis or golf rankings, has some bias for recent events.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you, friends.&lt;/p&gt;\n\n&lt;p&gt;Your servant,&lt;/p&gt;\n\n&lt;p&gt;The International Beerio Kart Championships of the World League Commissioner&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?auto=webp&amp;v=enabled&amp;s=ac1c84de7cd76a29b4042b046e17d9acc84e1550", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31a7f4c0970e53d8d0aa95f02d1a52d7bc1490e0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=346452f887e8ffd2acede0d45fa23db46ec874a6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=474adbb31de38cc3f64760877eb1ca96078c9e82", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49c12274105ddcb9e0084a2bdcd71f5f62953f78", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f29217fcf51a0aed6fe7aedb9422b247442b60", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78cc3c0091728d93e1d59045723d18144c83903c", "width": 1080, "height": 567}], "variants": {}, "id": "CZ1IT9UepvRZrTOmYYuoRJc5P5HRmKDk0Zc3vgIOFZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11la0m3", "is_robot_indexable": true, "report_reasons": null, "author": "zakarm22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11la0m3/international_beerio_kart_championships_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11la0m3/international_beerio_kart_championships_of_the/", "subreddit_subscribers": 854786, "created_utc": 1678220225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting Scikit-Learn Library Algorithms to C", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l9pla", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jspkwono", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MLQuestions", "selftext": "Hey everyone,\n\nI've been working on an embedded machine learning project that involves image classification, and our team has been using the Histogram of Oriented Gradients (HOG) algorithm from the scikit-learn library to extract features from our images. We were able to manually port the Python code for HOG to C, but I'm wondering if there are any tools or scripts that can automatically convert other scikit-learn algorithms to C?\n\nscikit hog library: [https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/\\_hog.py#L302](https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hog.py#L302) , [https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/\\_hoghistogram.pyx](https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hoghistogram.pyx)", "author_fullname": "t2_jspkwono", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting Scikit-Learn Library Algorithms to C", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MLQuestions", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l9ox4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678219506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MLQuestions", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on an embedded machine learning project that involves image classification, and our team has been using the Histogram of Oriented Gradients (HOG) algorithm from the scikit-learn library to extract features from our images. We were able to manually port the Python code for HOG to C, but I&amp;#39;m wondering if there are any tools or scripts that can automatically convert other scikit-learn algorithms to C?&lt;/p&gt;\n\n&lt;p&gt;scikit hog library: &lt;a href=\"https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hog.py#L302\"&gt;https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hog.py#L302&lt;/a&gt; , &lt;a href=\"https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hoghistogram.pyx\"&gt;https://github.com/scikit-image/scikit-image/blob/main/skimage/feature/_hoghistogram.pyx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?auto=webp&amp;v=enabled&amp;s=d75205b3e8bc94c71198aed3777c8da5578bf937", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ffe476acb1cdbd9a3961707b5db13f44cc6308c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e9713dcd0392e557c6743c849b1d38b80454da4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48e8ff2ac2e1019afd4809c8f2668d3ca1fb845d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeb491cfae9bd7b7b23299ac351d5798179a8796", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28b2d1b8c2a0580224c3b7a1a14774008a4f2640", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72ea2ca765635c388e5db407b7fe5daa551dcc90", "width": 1080, "height": 540}], "variants": {}, "id": "fIjwgCUcqteqsROFzTIPlJm-7dGvhV2fvYY_rmHd_2o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_30rel", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l9ox4", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Ant-5281", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MLQuestions/comments/11l9ox4/converting_scikitlearn_library_algorithms_to_c/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MLQuestions/comments/11l9ox4/converting_scikitlearn_library_algorithms_to_c/", "subreddit_subscribers": 39017, "created_utc": 1678219506.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1678219545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MLQuestions", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MLQuestions/comments/11l9ox4/converting_scikitlearn_library_algorithms_to_c/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?auto=webp&amp;v=enabled&amp;s=d75205b3e8bc94c71198aed3777c8da5578bf937", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ffe476acb1cdbd9a3961707b5db13f44cc6308c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e9713dcd0392e557c6743c849b1d38b80454da4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48e8ff2ac2e1019afd4809c8f2668d3ca1fb845d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeb491cfae9bd7b7b23299ac351d5798179a8796", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28b2d1b8c2a0580224c3b7a1a14774008a4f2640", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yf7sAb6njNTp3WKxvwLBre_uO4kBZlgJzSBZHKe7Sz8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72ea2ca765635c388e5db407b7fe5daa551dcc90", "width": 1080, "height": 540}], "variants": {}, "id": "fIjwgCUcqteqsROFzTIPlJm-7dGvhV2fvYY_rmHd_2o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l9pla", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Ant-5281", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11l9ox4", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l9pla/converting_scikitlearn_library_algorithms_to_c/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MLQuestions/comments/11l9ox4/converting_scikitlearn_library_algorithms_to_c/", "subreddit_subscribers": 854786, "created_utc": 1678219545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Naturally, Data Science is a spectrum and different tasks will have different hardware needs. But since I don't actively work on all DS areas I  need the community's input on what would be the Macbook of best fit for DS.\n\nCross-checking different library support for all the  Apple silicon chips in combination with RAM/GPU core count has been pretty complicated.\n\nWhich Macbook would you recommend as best overall for DS?", "author_fullname": "t2_13hucc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best overall Data Science Macbook on the market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l9o6n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678219463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Naturally, Data Science is a spectrum and different tasks will have different hardware needs. But since I don&amp;#39;t actively work on all DS areas I  need the community&amp;#39;s input on what would be the Macbook of best fit for DS.&lt;/p&gt;\n\n&lt;p&gt;Cross-checking different library support for all the  Apple silicon chips in combination with RAM/GPU core count has been pretty complicated.&lt;/p&gt;\n\n&lt;p&gt;Which Macbook would you recommend as best overall for DS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l9o6n", "is_robot_indexable": true, "report_reasons": null, "author": "every_other_freackle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l9o6n/whats_the_best_overall_data_science_macbook_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l9o6n/whats_the_best_overall_data_science_macbook_on/", "subreddit_subscribers": 854786, "created_utc": 1678219463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to find the link to a story I read about a newly hired data science manager who gets hired at a startup and the data scientists do research on cool ML models that don't go anywhere and needs to turn the department into SQL monkeys to do basic analytics (and has to get them to really understand and work with the business). \n\nAnyone know what I'm talking about?", "author_fullname": "t2_7ar5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tip of my Tongue: Story about a data science manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l7t8r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678215353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to find the link to a story I read about a newly hired data science manager who gets hired at a startup and the data scientists do research on cool ML models that don&amp;#39;t go anywhere and needs to turn the department into SQL monkeys to do basic analytics (and has to get them to really understand and work with the business). &lt;/p&gt;\n\n&lt;p&gt;Anyone know what I&amp;#39;m talking about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l7t8r", "is_robot_indexable": true, "report_reasons": null, "author": "lastchancexi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l7t8r/tip_of_my_tongue_story_about_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l7t8r/tip_of_my_tongue_story_about_a_data_science/", "subreddit_subscribers": 854786, "created_utc": 1678215353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My professor strongly recommended UNCC dsba for my future Master in DS. It seems pretty good, but it would cost almost 4 times than going to Gatch omsa. \nAs on campus, I might get more involved with faculty and more opportunities, but I wonder that would be worth that much money. \n\nAs I am leaning toward Gatech, not only due to reputation but also cost and it being online, I also think UNCC is a great option as I could graduate a little earlier as a full time student with more possible opportunities through faculty and on campus benefits.\n\nCurriculum-wise, I think Gatech would be more centered with CS courses with various options, whereas UNCC is relatively slightly more business focused.\n\nI would appreciate anyone's advice!", "author_fullname": "t2_j8t5xiv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gatech Omsa vs UNC Charlotte dsba", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6vx9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678213284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My professor strongly recommended UNCC dsba for my future Master in DS. It seems pretty good, but it would cost almost 4 times than going to Gatch omsa. \nAs on campus, I might get more involved with faculty and more opportunities, but I wonder that would be worth that much money. &lt;/p&gt;\n\n&lt;p&gt;As I am leaning toward Gatech, not only due to reputation but also cost and it being online, I also think UNCC is a great option as I could graduate a little earlier as a full time student with more possible opportunities through faculty and on campus benefits.&lt;/p&gt;\n\n&lt;p&gt;Curriculum-wise, I think Gatech would be more centered with CS courses with various options, whereas UNCC is relatively slightly more business focused.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate anyone&amp;#39;s advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6vx9", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Tip-5097", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6vx9/gatech_omsa_vs_unc_charlotte_dsba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6vx9/gatech_omsa_vs_unc_charlotte_dsba/", "subreddit_subscribers": 854786, "created_utc": 1678213284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In genetics PCA is used to represent distances and relationships between populations, however, it only does *relative* distances. What i mean by that is e.g. we know European population is only a small subset appendage of African populations, but in all PCAs it's reversed - Africa is shown as a small blob due to relatively small number of people represented. Statistically i need the PCA-like method that will better represent variance within a cluster and visually show that one cluster has orders of magnitude larger variance and i suspect understanding math better would allow me to do it. Could you give some suggestions?", "author_fullname": "t2_ehomo9o8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a PCA-type method that displays **real** distances?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6pkp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In genetics PCA is used to represent distances and relationships between populations, however, it only does &lt;em&gt;relative&lt;/em&gt; distances. What i mean by that is e.g. we know European population is only a small subset appendage of African populations, but in all PCAs it&amp;#39;s reversed - Africa is shown as a small blob due to relatively small number of people represented. Statistically i need the PCA-like method that will better represent variance within a cluster and visually show that one cluster has orders of magnitude larger variance and i suspect understanding math better would allow me to do it. Could you give some suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6pkp", "is_robot_indexable": true, "report_reasons": null, "author": "nevermindever42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6pkp/is_there_a_pcatype_method_that_displays_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6pkp/is_there_a_pcatype_method_that_displays_real/", "subreddit_subscribers": 854786, "created_utc": 1678212896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello mate,\n\nI hope you're having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\n\n&amp;#x200B;\n\nIf you're interested, please let me know.\n\nRegards.", "author_fullname": "t2_pz75y30d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-study group in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9sx9e4zctcma1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=994986d8b07a3e4f8ad291f5cbe978300520f574"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24a5f495456d645d38b0cb1af8fc31685927777f"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb0f287367e4ce6dac59921d8f82cb146c0ae4c2"}, {"y": 299, "x": 640, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55d615d054af3a149f11175552cfece01c9dcc8d"}, {"y": 449, "x": 960, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da595e5a003258ee901af025cda872299c0f3106"}, {"y": 505, "x": 1080, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa3e1d39e0691ee5645dcfe855f2d7d3708d900"}], "s": {"y": 702, "x": 1500, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1"}, "id": "9sx9e4zctcma1"}}, "name": "t3_11l5v5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bwQQ0CPIFuVZOnxe3c1dP-4zbPvkO10SHhrXNu_vIDg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678211021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello mate,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\"&gt;https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, please let me know.&lt;/p&gt;\n\n&lt;p&gt;Regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5v5t", "is_robot_indexable": true, "report_reasons": null, "author": "Sam-Oden", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "subreddit_subscribers": 854786, "created_utc": 1678211021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley](https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=914258685272006e0115ba6ff5a391f39c415a67)\n\nHave you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nYou can see the full map [here](https://1712n.github.io/yachay-public/maps/chatbots/).\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.", "author_fullname": "t2_tn9uzy0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fnhre7h3fcma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81e556060f4ec2dddd354d6819a0d966e40829fd"}, {"y": 186, "x": 216, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=586e6bf96b2d16a4aaf3100fb3cb3aa01c460809"}, {"y": 275, "x": 320, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fecc492aaf9d6c4b92b1bb2cea5a4d0cfb077c1"}, {"y": 551, "x": 640, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfedc9fcea8c8fc96947499e2e7fc7a4f3cc0535"}, {"y": 827, "x": 960, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2bab308ce9818b7cade6b19763f564bf171adb8"}, {"y": 930, "x": 1080, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ed104e7c230be02e3b2c653b28d3523887b4da3"}], "s": {"y": 1108, "x": 1286, "u": "https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=914258685272006e0115ba6ff5a391f39c415a67"}, "id": "fnhre7h3fcma1"}}, "name": "t3_11l3r81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CJCMJVr9abxpqryIU-zEJwZ2oy9gj-IBPZGpiGcqSME.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678206234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/fnhre7h3fcma1.png?width=1286&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=914258685272006e0115ba6ff5a391f39c415a67\"&gt;Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Have you been following the news on the conversational AI race? We used social media data and &lt;a href=\"https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model\"&gt;geolocation models&lt;/a&gt; to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.&lt;/p&gt;\n\n&lt;p&gt;First, we filtered social media data with the keywords &amp;quot;openai,&amp;quot; &amp;quot;bing,&amp;quot; &amp;quot;bard,&amp;quot; and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.&lt;/p&gt;\n\n&lt;p&gt;We analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.&lt;/p&gt;\n\n&lt;p&gt;You can see the full map &lt;a href=\"https://1712n.github.io/yachay-public/maps/chatbots/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;OpenAI may be winning the AI race at the moment, but it&amp;#39;s not the end yet. Let us know what other AI projects you&amp;#39;re following, and we&amp;#39;ll check them out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l3r81", "is_robot_indexable": true, "report_reasons": null, "author": "yachay_ai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l3r81/we_tracked_mentions_of_openai_bing_and_bard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l3r81/we_tracked_mentions_of_openai_bing_and_bard/", "subreddit_subscribers": 854786, "created_utc": 1678206234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Check out the full list of training workshops:  https:\\/\\/events.enterprisedb.com\\/YwNBgy?RefId=reddit ](https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb)", "author_fullname": "t2_p9pkrcde", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Join the Postgres community at EDB Postgres Vision for hands-on exercises to learn how to effectively diagnose and resolve Postgres issues, including replication errors, data corruption and disk space: https://events.enterprisedb.com/YwNBgy?RefId=reddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5jb1o5dpacma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=821babf80729a0b9e1807bd614096620c72e944a"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96df6fea4ea82cb8e794933b0ecf60df2c21a192"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53f7db2f32b6c1d4b0dc18d9e170e248d44d4041"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38159f95151b8f26922d32642ae57fef25e33bab"}], "s": {"y": 358, "x": 685, "u": "https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb"}, "id": "5jb1o5dpacma1"}}, "name": "t3_11l33hu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/11BOss35JLgaopbjYmkopsMr7_QKnTQgnXBfejpB6SE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1678204752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5jb1o5dpacma1.png?width=685&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f8f3543015951fc035f007c8f607dd7c49cbf3fb\"&gt;Check out the full list of training workshops:  https://events.enterprisedb.com/YwNBgy?RefId=reddit &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?auto=webp&amp;v=enabled&amp;s=c746b3a5688a5c96b443ef8f57bb1c0829cf9f87", "width": 1201, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b72bc2d81a2a4153f233d3914e995bcd3e4b1705", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a310d1294a4d6540dadb181e2de96ba11de3fab3", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=455611e34a4a84d9b84756bef255f78dadb9b305", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d488c22e507af2075dcbce4917848eb9c10f293c", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0127a0a51accfe45c1127d9f5aebb2611dec5e6d", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/6IJY24lIJvQM_Kvc-2SVJ-sNDiSPQUGF6a7JQDvjT9M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=721df1d80bac953db3186386820dbdc30ac8618a", "width": 1080, "height": 563}], "variants": {}, "id": "I1gdlw9y8oANehkt8YYaXY9RU4JUZo72bT3BVsadCos"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l33hu", "is_robot_indexable": true, "report_reasons": null, "author": "EDB_Postgres", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l33hu/join_the_postgres_community_at_edb_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l33hu/join_the_postgres_community_at_edb_postgres/", "subreddit_subscribers": 854786, "created_utc": 1678204752.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}