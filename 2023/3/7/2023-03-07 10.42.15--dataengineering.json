{"kind": "Listing", "data": {"after": "t3_11kmoho", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas 2.0 and its Ecosystem (Arrow, Polars, DuckDB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzbx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WfBLcHtYpbobHIPQcl9yw8-EzWiHI6KOWUeZXci3dgU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678110254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/pandas-2-0-ecosystem-arrow-polars-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?auto=webp&amp;v=enabled&amp;s=c99fe49fad376054047ca7a1e39b3e95b13d15b2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b6278e769713db18bf213a52f241ba7e6fd287", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52908720030dc2cdf14443982af90f39110acec5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83e96d87d7056881fc72a713eff848e605ca128b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c34b1793c4e556185d7436ed33ad33a9cd1813f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5676b7eefa2904c952e8479bc0ce518c9541179c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/u5Ki7ZPb84MAwTpKSt3heCylwrOS1Wp3mHEvjPvFyGA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa6ad5241da76bb55da21a4d74d8ba115038db4c", "width": 1080, "height": 567}], "variants": {}, "id": "NboYMU5MfVrPm_M685v01j18yegh_p4z5qgcI3RL6J8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11jzbx6", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11jzbx6/pandas_20_and_its_ecosystem_arrow_polars_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/pandas-2-0-ecosystem-arrow-polars-duckdb/", "subreddit_subscribers": 92161, "created_utc": 1678110254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets say I have a python app that every day performs some data transformations and then loads the data into the warehouse (postgres). It loads parquet files using pyarrow and then using polars/pandas do some stuff and then it needs to save it to the db. \n\nWhat would be the best way to insert the data into the DB?\n\na. use pandas to_sql method\n\nb. iterate over each dataframe row and send an insert statement\n\nc. convert dataframe to e.g. list of dicts and send an insert statements (i suppose worse than b.)\n\nd. asyncronously iterate over dataframe rows and send an insert statements\n\ne. save dataframe to CSV and ?somehow import it into the DB\n\nf. some better alternative?\n\nAlso - is it common to send the insert statements directly to the DB or should I use Kafka/RabbitMQ, send the data to the messaging system, create a consumer app that would take the data from queue and insert into the db?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insert data into DB best practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kdvkr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678137570.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678136504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a python app that every day performs some data transformations and then loads the data into the warehouse (postgres). It loads parquet files using pyarrow and then using polars/pandas do some stuff and then it needs to save it to the db. &lt;/p&gt;\n\n&lt;p&gt;What would be the best way to insert the data into the DB?&lt;/p&gt;\n\n&lt;p&gt;a. use pandas to_sql method&lt;/p&gt;\n\n&lt;p&gt;b. iterate over each dataframe row and send an insert statement&lt;/p&gt;\n\n&lt;p&gt;c. convert dataframe to e.g. list of dicts and send an insert statements (i suppose worse than b.)&lt;/p&gt;\n\n&lt;p&gt;d. asyncronously iterate over dataframe rows and send an insert statements&lt;/p&gt;\n\n&lt;p&gt;e. save dataframe to CSV and ?somehow import it into the DB&lt;/p&gt;\n\n&lt;p&gt;f. some better alternative?&lt;/p&gt;\n\n&lt;p&gt;Also - is it common to send the insert statements directly to the DB or should I use Kafka/RabbitMQ, send the data to the messaging system, create a consumer app that would take the data from queue and insert into the db?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kdvkr", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kdvkr/insert_data_into_db_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kdvkr/insert_data_into_db_best_practice/", "subreddit_subscribers": 92161, "created_utc": 1678136504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "E.g: database systems, workflow engines, ETL/ELT tools, analytical tools, cloud services, etc., basically anything that you feel is a convenient tool set to get data from source(s) to destination in the desired form.", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your favorite end-to-end tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzppg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678111228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g: database systems, workflow engines, ETL/ELT tools, analytical tools, cloud services, etc., basically anything that you feel is a convenient tool set to get data from source(s) to destination in the desired form.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11jzppg", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jzppg/whats_your_favorite_endtoend_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jzppg/whats_your_favorite_endtoend_tech_stack/", "subreddit_subscribers": 92161, "created_utc": 1678111228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I already passively listen to music or old audiobooks while in the gym.  I'm wondering if there are any relevant data engineering related podcasts or audiobooks that could work for this. Do people here have any suggestions? \n\nI'm specifically looking for high quality DE related material, not just two marketing juniors flaunting buzz words.", "author_fullname": "t2_i45gnyoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good professional podcasts to listen to while working out?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k47s4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678121745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already passively listen to music or old audiobooks while in the gym.  I&amp;#39;m wondering if there are any relevant data engineering related podcasts or audiobooks that could work for this. Do people here have any suggestions? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m specifically looking for high quality DE related material, not just two marketing juniors flaunting buzz words.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k47s4", "is_robot_indexable": true, "report_reasons": null, "author": "StartledBlackCat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k47s4/any_good_professional_podcasts_to_listen_to_while/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k47s4/any_good_professional_podcasts_to_listen_to_while/", "subreddit_subscribers": 92161, "created_utc": 1678121745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could you recommend some free data modeling (ER diagrams) tool?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free data modeling tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k2hwn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678117941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could you recommend some free data modeling (ER diagrams) tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k2hwn", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k2hwn/free_data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k2hwn/free_data_modeling_tool/", "subreddit_subscribers": 92161, "created_utc": 1678117941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to see more substantial content in this Reddit.  Lately the depth and quality of recent posts have not really added anything to the community.\n\nAre there any thoughts on how to lift and improve it?", "author_fullname": "t2_fer0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting tired of \u201cHow do I break into DE posts\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kth8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678177294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to see more substantial content in this Reddit.  Lately the depth and quality of recent posts have not really added anything to the community.&lt;/p&gt;\n\n&lt;p&gt;Are there any thoughts on how to lift and improve it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kth8p", "is_robot_indexable": true, "report_reasons": null, "author": "TheCauthon", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kth8p/getting_tired_of_how_do_i_break_into_de_posts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kth8p/getting_tired_of_how_do_i_break_into_de_posts/", "subreddit_subscribers": 92161, "created_utc": 1678177294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nTaking a look back to my prev projects, there are always different approaches to deal with any kind of sensitive data.\n\nView layer without sensetive, restricted columns etc.\n\n&amp;#x200B;\n\nAnd every time ppls try to invent new mechanics and approaches.\n\n&amp;#x200B;\n\nWhat's your best cases of developing dhw/lake, containing personal data and role-based access model?", "author_fullname": "t2_89j762yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you deal with personal/sensetive information in dwh? Also cool stories welcome.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jxx1t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678106685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Taking a look back to my prev projects, there are always different approaches to deal with any kind of sensitive data.&lt;/p&gt;\n\n&lt;p&gt;View layer without sensetive, restricted columns etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;And every time ppls try to invent new mechanics and approaches.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your best cases of developing dhw/lake, containing personal data and role-based access model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11jxx1t", "is_robot_indexable": true, "report_reasons": null, "author": "tehdima", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jxx1t/how_you_deal_with_personalsensetive_information/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jxx1t/how_you_deal_with_personalsensetive_information/", "subreddit_subscribers": 92161, "created_utc": 1678106685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I moved from a Python + SQL heavy role into one where the bulk of the coding is left to more junior members. Meanwhile, I build infrastructure and set up the bigger components. It\u2019s still technical work but I hardly get to write code. It\u2019s mostly configuration through YAML or terraform, or system diagramming. The code that I do write is Ops heavy. I\u2019ll be an expert in k8s, terraform, CICD soon enough\u2026. (Not really, this shit\u2019s complicated).\n\nI\u2019m not sure I enjoy it as much as writing Python, Go, or even SQL. \n\nDo y\u2019all enjoy setting up off-the-shelf tools, writing config files in YAML or toml or terraform/infra when you have to? What do you enjoy about it? Has your system design sense improved? \n\nI\u2019m just tossing around the idea of making a transition towards more traditional SWE. Thanks", "author_fullname": "t2_q03sptgw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ever feel like a professional YAMLer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kckqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678133795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I moved from a Python + SQL heavy role into one where the bulk of the coding is left to more junior members. Meanwhile, I build infrastructure and set up the bigger components. It\u2019s still technical work but I hardly get to write code. It\u2019s mostly configuration through YAML or terraform, or system diagramming. The code that I do write is Ops heavy. I\u2019ll be an expert in k8s, terraform, CICD soon enough\u2026. (Not really, this shit\u2019s complicated).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure I enjoy it as much as writing Python, Go, or even SQL. &lt;/p&gt;\n\n&lt;p&gt;Do y\u2019all enjoy setting up off-the-shelf tools, writing config files in YAML or toml or terraform/infra when you have to? What do you enjoy about it? Has your system design sense improved? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just tossing around the idea of making a transition towards more traditional SWE. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kckqy", "is_robot_indexable": true, "report_reasons": null, "author": "bingbangbio", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kckqy/ever_feel_like_a_professional_yamler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kckqy/ever_feel_like_a_professional_yamler/", "subreddit_subscribers": 92161, "created_utc": 1678133795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am new here and looking to get some input from people that have more experience in the industry.\n\nI worked in a digital advertising industry before, but very early on realised moving to a data role would suit me. So over 3 years I spent a lot of time learning R and Python, mostly to interact with APIs and automate reporting.\n\nA year ago I finally landed a role of a data analyst for a DTC ecomm company.\n\nThe only problem is I don't really spend a lot of time analysing data. \n\nSo far I have implemented Airbyte for data extraction, suplemented with Airflow orchestrated python scripts for stuff that Airbyte does not support, I wrote all of our DBT models and on top I am creating tableau dashboards for end users.\n\nOur stack currently is Airbyte, Airflow, DBT, BigQuery.\n\nAlso I am the only person in the company that does anything to do with data. So I had to figure out everything on my own.\n\nI have a feeling I have learned a ton past year, but I am also starting to realise that some of the stuff I did is very subpar (no dimensional modeling, non incrimental models in dbt, busines logic scattered all over the place etc.).\n\nMy contract is expiring end of this year and I am looking to you guys for some advice.\n\nFirst of all I want to know if this kind of work I have described is typicall for a data engineer? \n\nI work remotely and have not had a lot of opportunities to talk to people who actually are employed as data engineers.\n\nSecond, is it enough to ge me into a junior data engineer position, or should I aim to learn some new skills?\n\nI am pretty good at python, sql, R, Airflow, i know how to work with VMs and have experience with GCP. I am learning about dimensional modeling now.\n\n\nThirdly, should I stay at current position?\n\nI am currently making $100k a year. But I am not really seing my company hiring anyone more experienced then me, if anything they might hire people under me.\n\nI would really like an opportunity to work with a team and learn from more experienced people. Kinda sick of having to figure out everything on my own, but otherwise I like the type of work I have been doing this past year.\n\nThank you for a long read and thanks in advance for sharing your thoughts.", "author_fullname": "t2_9rpn5ks6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a data analyst or a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kim2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678146940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am new here and looking to get some input from people that have more experience in the industry.&lt;/p&gt;\n\n&lt;p&gt;I worked in a digital advertising industry before, but very early on realised moving to a data role would suit me. So over 3 years I spent a lot of time learning R and Python, mostly to interact with APIs and automate reporting.&lt;/p&gt;\n\n&lt;p&gt;A year ago I finally landed a role of a data analyst for a DTC ecomm company.&lt;/p&gt;\n\n&lt;p&gt;The only problem is I don&amp;#39;t really spend a lot of time analysing data. &lt;/p&gt;\n\n&lt;p&gt;So far I have implemented Airbyte for data extraction, suplemented with Airflow orchestrated python scripts for stuff that Airbyte does not support, I wrote all of our DBT models and on top I am creating tableau dashboards for end users.&lt;/p&gt;\n\n&lt;p&gt;Our stack currently is Airbyte, Airflow, DBT, BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Also I am the only person in the company that does anything to do with data. So I had to figure out everything on my own.&lt;/p&gt;\n\n&lt;p&gt;I have a feeling I have learned a ton past year, but I am also starting to realise that some of the stuff I did is very subpar (no dimensional modeling, non incrimental models in dbt, busines logic scattered all over the place etc.).&lt;/p&gt;\n\n&lt;p&gt;My contract is expiring end of this year and I am looking to you guys for some advice.&lt;/p&gt;\n\n&lt;p&gt;First of all I want to know if this kind of work I have described is typicall for a data engineer? &lt;/p&gt;\n\n&lt;p&gt;I work remotely and have not had a lot of opportunities to talk to people who actually are employed as data engineers.&lt;/p&gt;\n\n&lt;p&gt;Second, is it enough to ge me into a junior data engineer position, or should I aim to learn some new skills?&lt;/p&gt;\n\n&lt;p&gt;I am pretty good at python, sql, R, Airflow, i know how to work with VMs and have experience with GCP. I am learning about dimensional modeling now.&lt;/p&gt;\n\n&lt;p&gt;Thirdly, should I stay at current position?&lt;/p&gt;\n\n&lt;p&gt;I am currently making $100k a year. But I am not really seing my company hiring anyone more experienced then me, if anything they might hire people under me.&lt;/p&gt;\n\n&lt;p&gt;I would really like an opportunity to work with a team and learn from more experienced people. Kinda sick of having to figure out everything on my own, but otherwise I like the type of work I have been doing this past year.&lt;/p&gt;\n\n&lt;p&gt;Thank you for a long read and thanks in advance for sharing your thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kim2m", "is_robot_indexable": true, "report_reasons": null, "author": "CryptographerMain698", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kim2m/am_i_a_data_analyst_or_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kim2m/am_i_a_data_analyst_or_a_data_engineer/", "subreddit_subscribers": 92161, "created_utc": 1678146940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! Been looking into Fivetran + dbt for a while but would like to understand better what's limiting or if that is basically the holy grail already?  \n\n\nFeel like it's nice to start out but don't want to end up buying tool after tool on top of that to manage things, add governance, etc.  \n\n\nHow do you feel about having to manage so many tools? Would it make sense to instead use something that stitches those together? Would it be worth it to pay more for that?", "author_fullname": "t2_beueng4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran + dbt users experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k64f7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678123982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! Been looking into Fivetran + dbt for a while but would like to understand better what&amp;#39;s limiting or if that is basically the holy grail already?  &lt;/p&gt;\n\n&lt;p&gt;Feel like it&amp;#39;s nice to start out but don&amp;#39;t want to end up buying tool after tool on top of that to manage things, add governance, etc.  &lt;/p&gt;\n\n&lt;p&gt;How do you feel about having to manage so many tools? Would it make sense to instead use something that stitches those together? Would it be worth it to pay more for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k64f7", "is_robot_indexable": true, "report_reasons": null, "author": "Thybrat", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k64f7/fivetran_dbt_users_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k64f7/fivetran_dbt_users_experience/", "subreddit_subscribers": 92161, "created_utc": 1678123982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHello, I need to build some crawlers where I must automate clicking on buttons and filling out forms. By client requirement, I need to build these crawlers within the Synapse Analytics environment.\n\nI had thought of solving this problem using Selenium to do all the automation part, but I don't know if it's possible to integrate Selenium with Synapse.\n\nHas anyone faced a similar problem?", "author_fullname": "t2_goecqk3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building crawlers using Azure Synapse Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jy680", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678107338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I need to build some crawlers where I must automate clicking on buttons and filling out forms. By client requirement, I need to build these crawlers within the Synapse Analytics environment.&lt;/p&gt;\n\n&lt;p&gt;I had thought of solving this problem using Selenium to do all the automation part, but I don&amp;#39;t know if it&amp;#39;s possible to integrate Selenium with Synapse.&lt;/p&gt;\n\n&lt;p&gt;Has anyone faced a similar problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11jy680", "is_robot_indexable": true, "report_reasons": null, "author": "Folkrar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jy680/building_crawlers_using_azure_synapse_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jy680/building_crawlers_using_azure_synapse_analytics/", "subreddit_subscribers": 92161, "created_utc": 1678107338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! Anyone recently cleared a Tesla data engineer 30 min Python coding interview? Would love some pointers as to what to prepare. Would love some advice please. Thanks a lot!", "author_fullname": "t2_8pd9nebp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tesla data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kpw2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678166197.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678165595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! Anyone recently cleared a Tesla data engineer 30 min Python coding interview? Would love some pointers as to what to prepare. Would love some advice please. Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11kpw2w", "is_robot_indexable": true, "report_reasons": null, "author": "Existing_Comment_919", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kpw2w/tesla_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kpw2w/tesla_data_engineer/", "subreddit_subscribers": 92161, "created_utc": 1678165595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to load json files to Databricks tables, and was wondering what tools/methods are easiest for this (i'm currently trying with python). This seems like it would be a common task for data engineers, but I was running into a few issues. 1) My json has nested lists of jsons, which i would like to extract the values to a row for each element in the list. I have list nested lists inside those as well, so there will need to be 2 levels of exploding/looping to generate these rows. 2) If an element does not exist, I want this defaulted to 'null', but that situation causes an error when using python. I've read a few solutions on this but none of them seem simple or easy and I'm trying to avoid complexity in this code. Thanks!", "author_fullname": "t2_50i9ola", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Json to SQL Tables, specifically Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k333m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678119251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to load json files to Databricks tables, and was wondering what tools/methods are easiest for this (i&amp;#39;m currently trying with python). This seems like it would be a common task for data engineers, but I was running into a few issues. 1) My json has nested lists of jsons, which i would like to extract the values to a row for each element in the list. I have list nested lists inside those as well, so there will need to be 2 levels of exploding/looping to generate these rows. 2) If an element does not exist, I want this defaulted to &amp;#39;null&amp;#39;, but that situation causes an error when using python. I&amp;#39;ve read a few solutions on this but none of them seem simple or easy and I&amp;#39;m trying to avoid complexity in this code. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11k333m", "is_robot_indexable": true, "report_reasons": null, "author": "D-2-The-Ave", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k333m/json_to_sql_tables_specifically_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k333m/json_to_sql_tables_specifically_databricks/", "subreddit_subscribers": 92161, "created_utc": 1678119251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_t01yxrq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Check out the awesome stuff in Apache Airflow 2.5! \ud83e\udd29", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11k1a73", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.5?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aji3S_H_-Fo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11k1a73", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0DAVeiubl0P4UOcpno1joaoJ9Zz3dLiEgxPBs3LNhAY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678115191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/aji3S_H_-Fo", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?auto=webp&amp;v=enabled&amp;s=8c912308dc1f42e1643a185c72896332eff2bdd1", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5058efbc719fb6752c5574771c720d013a3edd0a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfa7f21fd404af60f27ee538e4596b35a0d71f22", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/FVtamQ9cPePR__-FOFJpqhOHedylTjxfSUMFsC25GT4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb0aca22f154adcdde5e159dfc1f2e59a80a520e", "width": 320, "height": 240}], "variants": {}, "id": "U7_XfScaeDo5P-CnwYfNqrHGduPTxK37lLZfshZfWKE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11k1a73", "is_robot_indexable": true, "report_reasons": null, "author": "Yahentamitsi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k1a73/check_out_the_awesome_stuff_in_apache_airflow_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/aji3S_H_-Fo", "subreddit_subscribers": 92161, "created_utc": 1678115191.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "What's new in Apache Airflow 2.5?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/aji3S_H_-Fo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"What&amp;#39;s new in Apache Airflow 2.5?\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/aji3S_H_-Fo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data engineer who has been working with data pipelines in Airflow with Scala and Apache Spark, I am now tasked with building a data quality check framework that requires planning, high level design, low level design, unit testing, integration testing, and overall software development lifecycle.\nI am looking for resources to help me understand how to deliver an end-to-end project like this, with a focus on proper design for building data quality frameworks.\n\nCan anyone recommend any books, blogs, courses, or other resources that could help me with this? Any advice or guidance would be greatly appreciated. Thank you!", "author_fullname": "t2_2bfywe95", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Request] Tips on building a data quality check framework with proper design in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kuh6c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678181001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data engineer who has been working with data pipelines in Airflow with Scala and Apache Spark, I am now tasked with building a data quality check framework that requires planning, high level design, low level design, unit testing, integration testing, and overall software development lifecycle.\nI am looking for resources to help me understand how to deliver an end-to-end project like this, with a focus on proper design for building data quality frameworks.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend any books, blogs, courses, or other resources that could help me with this? Any advice or guidance would be greatly appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kuh6c", "is_robot_indexable": true, "report_reasons": null, "author": "A-n-d-y-R-e-d", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kuh6c/request_tips_on_building_a_data_quality_check/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kuh6c/request_tips_on_building_a_data_quality_check/", "subreddit_subscribers": 92161, "created_utc": 1678181001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I learned that Snowflake is quite limited, when it comes to its data modeling capabilitiea. For example it does not enforce unique values for Primary Keys. How am I supposed to set up a data model without possibly breaking those constraints?\n\nThanks in advance for sharing your experiences.", "author_fullname": "t2_ug93cwsp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to data model in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ksc63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678173145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I learned that Snowflake is quite limited, when it comes to its data modeling capabilitiea. For example it does not enforce unique values for Primary Keys. How am I supposed to set up a data model without possibly breaking those constraints?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for sharing your experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ksc63", "is_robot_indexable": true, "report_reasons": null, "author": "RoleSuspicious6537", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ksc63/how_to_data_model_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ksc63/how_to_data_model_in_snowflake/", "subreddit_subscribers": 92161, "created_utc": 1678173145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to create data warehouse where i am getting data from current DBs (postgres RDS instances) and some other apps. The architecture i could come up with is\n\nOption 1:\n- Using DMS to store my rds postgres to S3 bucket.\n- Using appflow to store apps data in S3.\n- Using crawler to catalog data.\n- Then in the end use command in redshift to get that data. \u201cCopy from data catalog\u2026.\u201d\nIssue here: Tables where CDC is activated, it creates multiple csv in S3 bucket. And when i am reading this using athena, such table data is not created and empty.\n\nOption 2: \n- Using appflow to store apps data in S3.\n- Using crawler to catalog postgres db.\n- Then in the end use command in redshift to get that data. \u201cCopy from data catalog\u2026.\u201d\n\nIssue here: crawler crawls the schema and tables of postgres but when i query in redshift i am getting this error  \u201cCan not deserialize table. InputFormat, outputFormat, serializationLibrary required\u201d. The crawler is supposed to get these information. It fills all other properties correctly such as classification of data as postgres.\n\nIf above all makes sense, can someone guide me especially for Option2. Thank you so much \ud83d\ude4f", "author_fullname": "t2_8jfrjnc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws redshift serverless", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11koo5j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678162202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create data warehouse where i am getting data from current DBs (postgres RDS instances) and some other apps. The architecture i could come up with is&lt;/p&gt;\n\n&lt;p&gt;Option 1:\n- Using DMS to store my rds postgres to S3 bucket.\n- Using appflow to store apps data in S3.\n- Using crawler to catalog data.\n- Then in the end use command in redshift to get that data. \u201cCopy from data catalog\u2026.\u201d\nIssue here: Tables where CDC is activated, it creates multiple csv in S3 bucket. And when i am reading this using athena, such table data is not created and empty.&lt;/p&gt;\n\n&lt;p&gt;Option 2: \n- Using appflow to store apps data in S3.\n- Using crawler to catalog postgres db.\n- Then in the end use command in redshift to get that data. \u201cCopy from data catalog\u2026.\u201d&lt;/p&gt;\n\n&lt;p&gt;Issue here: crawler crawls the schema and tables of postgres but when i query in redshift i am getting this error  \u201cCan not deserialize table. InputFormat, outputFormat, serializationLibrary required\u201d. The crawler is supposed to get these information. It fills all other properties correctly such as classification of data as postgres.&lt;/p&gt;\n\n&lt;p&gt;If above all makes sense, can someone guide me especially for Option2. Thank you so much \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11koo5j", "is_robot_indexable": true, "report_reasons": null, "author": "lost_soul1995", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11koo5j/aws_redshift_serverless/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11koo5j/aws_redshift_serverless/", "subreddit_subscribers": 92161, "created_utc": 1678162202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to run a simple pipeline in Azure with whatever service is easiest to stand up. Have a few python files pulling from a web api, they are helper modules that execute in main python file. Need to run them once a week. And store output in some kind of storage\u2026 sql pool or dedicated, blob. Doesn\u2019t matter. Any suggestions helpful. Mainly looking for an easy orchestration or trigger for the weekly batch load. Thanks again", "author_fullname": "t2_vmi9ivlo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline in azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kmmqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678156718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to run a simple pipeline in Azure with whatever service is easiest to stand up. Have a few python files pulling from a web api, they are helper modules that execute in main python file. Need to run them once a week. And store output in some kind of storage\u2026 sql pool or dedicated, blob. Doesn\u2019t matter. Any suggestions helpful. Mainly looking for an easy orchestration or trigger for the weekly batch load. Thanks again&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kmmqx", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable-Watch-79", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kmmqx/pipeline_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kmmqx/pipeline_in_azure/", "subreddit_subscribers": 92161, "created_utc": 1678156718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Looking to implement - call it version 0.001 of a data catalog on top of our AWS-backed data lake.\n\nI can attempt to roll my own on using tools native to AWS.\n\nI can start with an open source tool such as Amundsen.\n\nI may be able to start with an inexpensive SaaS Data Catalog, but I will not have budget for Data Catalog until I'm able to show exactly what I mean by Data Catalog, and I'd love to provide the team something tangible to seed the conversation with our community of data consumers.\n\nDoes anyone use Amundsen?  Is it still a good option in 2023, or is it a dormant project?\n\nIf you are using a data catalog to enable discoverability and self-service analytics, what are you using, and is it working for you?  \n\nDon't know whether to call this a request for help or for discussion; went with \"discussion\" but maybe that's a data quality issue :)\n\nTruly appreciate any information, observations, thoughts, ideas.\n\nBest!", "author_fullname": "t2_w9nubpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog, Data Discovery, Active Metadata Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kfaeu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678139495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Looking to implement - call it version 0.001 of a data catalog on top of our AWS-backed data lake.&lt;/p&gt;\n\n&lt;p&gt;I can attempt to roll my own on using tools native to AWS.&lt;/p&gt;\n\n&lt;p&gt;I can start with an open source tool such as Amundsen.&lt;/p&gt;\n\n&lt;p&gt;I may be able to start with an inexpensive SaaS Data Catalog, but I will not have budget for Data Catalog until I&amp;#39;m able to show exactly what I mean by Data Catalog, and I&amp;#39;d love to provide the team something tangible to seed the conversation with our community of data consumers.&lt;/p&gt;\n\n&lt;p&gt;Does anyone use Amundsen?  Is it still a good option in 2023, or is it a dormant project?&lt;/p&gt;\n\n&lt;p&gt;If you are using a data catalog to enable discoverability and self-service analytics, what are you using, and is it working for you?  &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t know whether to call this a request for help or for discussion; went with &amp;quot;discussion&amp;quot; but maybe that&amp;#39;s a data quality issue :)&lt;/p&gt;\n\n&lt;p&gt;Truly appreciate any information, observations, thoughts, ideas.&lt;/p&gt;\n\n&lt;p&gt;Best!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kfaeu", "is_robot_indexable": true, "report_reasons": null, "author": "realrussgreen", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kfaeu/data_catalog_data_discovery_active_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kfaeu/data_catalog_data_discovery_active_metadata/", "subreddit_subscribers": 92161, "created_utc": 1678139495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, i created the following code as a test to perform an ETL using pandas in chunks. The idea was so use a for loop to get a chunk of data into a dataframe, load that chunk into a database and then truncate the dataframe so that memory consumption is low and then move onto the next chunk. This is the code:\n\n&amp;#x200B;\n\n    import pandas as pd\n    from sqlalchemy import create_engine\n    \n    query = \"SELECT * FROM table\"\n    \n    def ETL():\n        engine = create_engine('connection details', fast_executemany=True)\n        engine2 = create_engine('connection details', fast_executemany=True)\n        conn = engine.connect().execution_options(stream_results=True)\n        \n        for chunk in pd.read_sql(query, conn, chunksize=1000):\n            print(f\"Got dataframe w/{len(chunk)} rows\")\n            chunk.to_sql(\"table2\", engine2, if_exists='append', index=False, chunksize=1000)\n            \n        engine.dispose()\n        engine2.dispose()\n\nthe code works but i think im doing something wrong, the first 30k rows uploaded quickly but it started slowing down, thats when i realized the dataframe might not be truncating after every loop, its holding all of the data.\n\n&amp;#x200B;\n\nHow would i truncate the dataframe in this case to increase speed and reduce memory usage?\n\nthanks yall", "author_fullname": "t2_pcb7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does truncating pandas dataframe reduce memory usage? confused about chunking code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11k8l78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678126791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i created the following code as a test to perform an ETL using pandas in chunks. The idea was so use a for loop to get a chunk of data into a dataframe, load that chunk into a database and then truncate the dataframe so that memory consumption is low and then move onto the next chunk. This is the code:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nfrom sqlalchemy import create_engine\n\nquery = &amp;quot;SELECT * FROM table&amp;quot;\n\ndef ETL():\n    engine = create_engine(&amp;#39;connection details&amp;#39;, fast_executemany=True)\n    engine2 = create_engine(&amp;#39;connection details&amp;#39;, fast_executemany=True)\n    conn = engine.connect().execution_options(stream_results=True)\n\n    for chunk in pd.read_sql(query, conn, chunksize=1000):\n        print(f&amp;quot;Got dataframe w/{len(chunk)} rows&amp;quot;)\n        chunk.to_sql(&amp;quot;table2&amp;quot;, engine2, if_exists=&amp;#39;append&amp;#39;, index=False, chunksize=1000)\n\n    engine.dispose()\n    engine2.dispose()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;the code works but i think im doing something wrong, the first 30k rows uploaded quickly but it started slowing down, thats when i realized the dataframe might not be truncating after every loop, its holding all of the data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How would i truncate the dataframe in this case to increase speed and reduce memory usage?&lt;/p&gt;\n\n&lt;p&gt;thanks yall&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11k8l78", "is_robot_indexable": true, "report_reasons": null, "author": "IceStallion", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11k8l78/does_truncating_pandas_dataframe_reduce_memory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11k8l78/does_truncating_pandas_dataframe_reduce_memory/", "subreddit_subscribers": 92161, "created_utc": 1678126791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI'm working with a dataframe with 30 million lines, using the AWS Glue docker image, but I'm having a very slow time to perform operations, like select, count and group by, when I read the files directly from s3.\n\nI noticed that if I download the parquets from s3 and read them locally, this problem of slowness is solved and the operations work very quickly.\n\nI tried to use cache() and persist() after reading the files from s3 but the performance was still very slow.\n\nDo you know any way to optimize the performance without downloading the parquet files and reading them locally?\n\n&amp;#x200B;\n\nRegards", "author_fullname": "t2_4i184twi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[PySpark] Read S3 x Read Local", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11jzx6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678111747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with a dataframe with 30 million lines, using the AWS Glue docker image, but I&amp;#39;m having a very slow time to perform operations, like select, count and group by, when I read the files directly from s3.&lt;/p&gt;\n\n&lt;p&gt;I noticed that if I download the parquets from s3 and read them locally, this problem of slowness is solved and the operations work very quickly.&lt;/p&gt;\n\n&lt;p&gt;I tried to use cache() and persist() after reading the files from s3 but the performance was still very slow.&lt;/p&gt;\n\n&lt;p&gt;Do you know any way to optimize the performance without downloading the parquet files and reading them locally?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Regards&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11jzx6r", "is_robot_indexable": true, "report_reasons": null, "author": "M4ksB", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11jzx6r/pyspark_read_s3_x_read_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11jzx6r/pyspark_read_s3_x_read_local/", "subreddit_subscribers": 92161, "created_utc": 1678111747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need a recommendation from fellow DEs regarding flexible hierarchies, as often encountered in logistics (bill of material):\n\n \nBUSINES ANALYSIS\n\na PRODUCT basically composed of individual MATERIALS, but those are organized and presented in MATERIAL SUBGROUPS.\n\nI t looks like:\n\nPRODUCT_A\n\n-- SUBGROUP_S1\n\n---- SUBGROUP_S1.1\n\n------ ...\n\n-------- SUBGROUP_S1.N\n\n------------ MATERIAL 1\n\n------------ MATERIAL 2\n\n-- MATERIAL n\n\n---- SUBGROUP_S1\n\n------ SUBGROUP_S2.1\n\n-------- MATERIAL 10\n\n-------- MATERIAL m\n\n\nThe hierarchy is unbalanced and flexible, the deepest level might be 20 subgroups today, but tomorrow it could be 22 subgroups because of engineering changes.\n\nOf course the data warehouse would be the very last system to get notified of this, so it should ideally handle such flexible hierarchies without problem.\n\nThe hierarchie is delivered by flat file in a normal PARENT-CHILD relation, and then present as a table (with varying length, as the products add/remove materials and subgroups).\n\n \n\nDATA MART\n\nSo far the data marts would be modelled as normal star schemas with a fact table on the lowest granularity, including the MATERIAL. Something like:\n\nDIM_MATERIAL DIM_CLIENT DIM_TRANSACTION DIM_xxx KF1 KF2 ...\n\n---------------------- -------------------- ------------------------------ --------------- ----- ------\n\nMATERIAL 1 ........ client_x ......... transaction y ............. z ................ 5 ...... 10\n\n \n\n \n\nAnd the BOM table is so far completely separate in PARENT_CHILD format and could be joined via the FACTS.DIM_MATERIAL = BOM.CHILD.\n\nHowever:\n\nNow the data should be presented as the Bill Of Material in the analytics tool, and my main 2 challenges are:\n\n \n\n(1) Since the hierarchie is flexible, the number of necessary joins to traverse parent-child table is dynamic.\n\nAny approach with flattening the hierarchie is also not optimal, as the number of fields would be dynamic (and BI anyltics tools dont like dynamically changing result sets).\n\n \n\n(2) Even more bitter: the BI Analytics tool is PowerBI, and that seems to be completely unable to work with anything in PARENT-CHILD format, seems like flattening would be preferred (but not possible due to flexible depths of the hierarchie).\n\n \n\nI understand that SAP BW is actually working with such a data model (relational star schema and external hierarchie in PARENT-CHILD format, thus extremely flexible).\n\nBut i dont understand how they handle this, especially since the number of (self-)joins is dynamic...\n\nI cannot be the only one from logistics - how do you people do things with hierarchies?", "author_fullname": "t2_m0qyu51x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling flexible hierarchies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kuvmc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678182508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need a recommendation from fellow DEs regarding flexible hierarchies, as often encountered in logistics (bill of material):&lt;/p&gt;\n\n&lt;p&gt;BUSINES ANALYSIS&lt;/p&gt;\n\n&lt;p&gt;a PRODUCT basically composed of individual MATERIALS, but those are organized and presented in MATERIAL SUBGROUPS.&lt;/p&gt;\n\n&lt;p&gt;I t looks like:&lt;/p&gt;\n\n&lt;p&gt;PRODUCT_A&lt;/p&gt;\n\n&lt;p&gt;-- SUBGROUP_S1&lt;/p&gt;\n\n&lt;p&gt;---- SUBGROUP_S1.1&lt;/p&gt;\n\n&lt;p&gt;------ ...&lt;/p&gt;\n\n&lt;p&gt;-------- SUBGROUP_S1.N&lt;/p&gt;\n\n&lt;p&gt;------------ MATERIAL 1&lt;/p&gt;\n\n&lt;p&gt;------------ MATERIAL 2&lt;/p&gt;\n\n&lt;p&gt;-- MATERIAL n&lt;/p&gt;\n\n&lt;p&gt;---- SUBGROUP_S1&lt;/p&gt;\n\n&lt;p&gt;------ SUBGROUP_S2.1&lt;/p&gt;\n\n&lt;p&gt;-------- MATERIAL 10&lt;/p&gt;\n\n&lt;p&gt;-------- MATERIAL m&lt;/p&gt;\n\n&lt;p&gt;The hierarchy is unbalanced and flexible, the deepest level might be 20 subgroups today, but tomorrow it could be 22 subgroups because of engineering changes.&lt;/p&gt;\n\n&lt;p&gt;Of course the data warehouse would be the very last system to get notified of this, so it should ideally handle such flexible hierarchies without problem.&lt;/p&gt;\n\n&lt;p&gt;The hierarchie is delivered by flat file in a normal PARENT-CHILD relation, and then present as a table (with varying length, as the products add/remove materials and subgroups).&lt;/p&gt;\n\n&lt;p&gt;DATA MART&lt;/p&gt;\n\n&lt;p&gt;So far the data marts would be modelled as normal star schemas with a fact table on the lowest granularity, including the MATERIAL. Something like:&lt;/p&gt;\n\n&lt;p&gt;DIM_MATERIAL DIM_CLIENT DIM_TRANSACTION DIM_xxx KF1 KF2 ...&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;MATERIAL 1 ........ client_x ......... transaction y ............. z ................ 5 ...... 10&lt;/p&gt;\n\n&lt;p&gt;And the BOM table is so far completely separate in PARENT_CHILD format and could be joined via the FACTS.DIM_MATERIAL = BOM.CHILD.&lt;/p&gt;\n\n&lt;p&gt;However:&lt;/p&gt;\n\n&lt;p&gt;Now the data should be presented as the Bill Of Material in the analytics tool, and my main 2 challenges are:&lt;/p&gt;\n\n&lt;p&gt;(1) Since the hierarchie is flexible, the number of necessary joins to traverse parent-child table is dynamic.&lt;/p&gt;\n\n&lt;p&gt;Any approach with flattening the hierarchie is also not optimal, as the number of fields would be dynamic (and BI anyltics tools dont like dynamically changing result sets).&lt;/p&gt;\n\n&lt;p&gt;(2) Even more bitter: the BI Analytics tool is PowerBI, and that seems to be completely unable to work with anything in PARENT-CHILD format, seems like flattening would be preferred (but not possible due to flexible depths of the hierarchie).&lt;/p&gt;\n\n&lt;p&gt;I understand that SAP BW is actually working with such a data model (relational star schema and external hierarchie in PARENT-CHILD format, thus extremely flexible).&lt;/p&gt;\n\n&lt;p&gt;But i dont understand how they handle this, especially since the number of (self-)joins is dynamic...&lt;/p&gt;\n\n&lt;p&gt;I cannot be the only one from logistics - how do you people do things with hierarchies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11kuvmc", "is_robot_indexable": true, "report_reasons": null, "author": "Wedeldog", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kuvmc/modelling_flexible_hierarchies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kuvmc/modelling_flexible_hierarchies/", "subreddit_subscribers": 92161, "created_utc": 1678182508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys I am looking for help in designing our ETL/ ELT process. We have 10+ partners all of them are sending us data in different formats; CSV, JSON etc. The data is somehow related but each partner uses different names for datasets (eg different column names). We have this data in S3 and it is loaded here daily. This part is working and we have no way of changing this right now.\n\nNow we would like to transform this data in S3 into a consolidated Postgres. We have a final DB schema design ready. Now I would like to ask for your opinion on how to create an ETL/ ELT pipeline with minimum changes to the code base for each partner? If possible it will be fantastic to use JSON/ YAML configs to reduce changes to the base source code.\n\nMore context. \n\n- We are planning to build a pipeline for each partner however we hope to reuse some common functionality.\n- We are flexible in reaching the end product.\n- We are flexible in tooling as well but we prefer open source and we are Python heavy team.\n- Its possible to use staging schema for transformations.\n- We have AWS Athena which we are using to query the data in S3.\n- Each partner has a dedicated folder in S3 with the data they share with us.", "author_fullname": "t2_les6mk56", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help! How to create an ETL/ ELT from multiple source data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11kuux0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678182436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys I am looking for help in designing our ETL/ ELT process. We have 10+ partners all of them are sending us data in different formats; CSV, JSON etc. The data is somehow related but each partner uses different names for datasets (eg different column names). We have this data in S3 and it is loaded here daily. This part is working and we have no way of changing this right now.&lt;/p&gt;\n\n&lt;p&gt;Now we would like to transform this data in S3 into a consolidated Postgres. We have a final DB schema design ready. Now I would like to ask for your opinion on how to create an ETL/ ELT pipeline with minimum changes to the code base for each partner? If possible it will be fantastic to use JSON/ YAML configs to reduce changes to the base source code.&lt;/p&gt;\n\n&lt;p&gt;More context. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We are planning to build a pipeline for each partner however we hope to reuse some common functionality.&lt;/li&gt;\n&lt;li&gt;We are flexible in reaching the end product.&lt;/li&gt;\n&lt;li&gt;We are flexible in tooling as well but we prefer open source and we are Python heavy team.&lt;/li&gt;\n&lt;li&gt;Its possible to use staging schema for transformations.&lt;/li&gt;\n&lt;li&gt;We have AWS Athena which we are using to query the data in S3.&lt;/li&gt;\n&lt;li&gt;Each partner has a dedicated folder in S3 with the data they share with us.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11kuux0", "is_robot_indexable": true, "report_reasons": null, "author": "zimbodev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kuux0/help_how_to_create_an_etl_elt_from_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kuux0/help_how_to_create_an_etl_elt_from_multiple/", "subreddit_subscribers": 92161, "created_utc": 1678182436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Introduction, I'm a sophomore(Bachelor) in College who wants to be a Data Engineer. I'm currently in the process of learning Python Frameworks and SQL.\n\nFrom what I've seen in this subreddit and Job listings is that DE jobs are more suited to people who switch from Data Science/ Data Analysis and the crowd is mostly based on that niche. Now, from what I've heard switching from core Data Science has the advantage of having learned Machine Learning and hardcore Data Science. Moreover, a lot of job listings that I've seen actually specify that the Data Engineer has to implement Data Science and Machine Learning. I guess this is required so that DEs have better communication with Data Scientists, who are the end user.\n\nNow, the major problem I have, related to this, is that the Data Engineering Roadmaps and Bootcamps don't ask you to learn Data Science or Machine Learning. Also, my college degree doesn't let me access the Linear Algebra course(they replaced it with ODE/PDE), also I don't quite like Math. The Thing is that learning DE tools(Like Spark and Hadoop) alongside Data Science(which is more mathematical in nature) would be quite hectic for me as I aspire to crack a Remote Paid Internship within an Year. For now, this is my primary goal. I am willing to learn another stack if need be.\n\nPlease advice me on what my course of action should be. Should I change domain? Or should I learn Data Science?", "author_fullname": "t2_zdxnz5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting a career in tech with Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ksnif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678174276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Introduction, I&amp;#39;m a sophomore(Bachelor) in College who wants to be a Data Engineer. I&amp;#39;m currently in the process of learning Python Frameworks and SQL.&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve seen in this subreddit and Job listings is that DE jobs are more suited to people who switch from Data Science/ Data Analysis and the crowd is mostly based on that niche. Now, from what I&amp;#39;ve heard switching from core Data Science has the advantage of having learned Machine Learning and hardcore Data Science. Moreover, a lot of job listings that I&amp;#39;ve seen actually specify that the Data Engineer has to implement Data Science and Machine Learning. I guess this is required so that DEs have better communication with Data Scientists, who are the end user.&lt;/p&gt;\n\n&lt;p&gt;Now, the major problem I have, related to this, is that the Data Engineering Roadmaps and Bootcamps don&amp;#39;t ask you to learn Data Science or Machine Learning. Also, my college degree doesn&amp;#39;t let me access the Linear Algebra course(they replaced it with ODE/PDE), also I don&amp;#39;t quite like Math. The Thing is that learning DE tools(Like Spark and Hadoop) alongside Data Science(which is more mathematical in nature) would be quite hectic for me as I aspire to crack a Remote Paid Internship within an Year. For now, this is my primary goal. I am willing to learn another stack if need be.&lt;/p&gt;\n\n&lt;p&gt;Please advice me on what my course of action should be. Should I change domain? Or should I learn Data Science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ksnif", "is_robot_indexable": true, "report_reasons": null, "author": "Hi_im_Deep", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ksnif/starting_a_career_in_tech_with_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ksnif/starting_a_career_in_tech_with_data_engineering/", "subreddit_subscribers": 92161, "created_utc": 1678174276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! I have accepted an offer at a big bank for when I graduate as a software engineer. I can decide between two different roles. What they have available is big data engineer or ios/android app dev. I do want to end up in a more traditional SWE role like fullstack or web dev. But who knows I may like whatever I get into. Which of the two roles would a better start to my career? I personally feel like iOS/android dev is a bit too niche and I could transfer big data skills to other jobs. But I\u2019m not 100% which is why I\u2019m asking here. Any advice is appreciated!", "author_fullname": "t2_3y8aolho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding between two positions unrelated to what I want to do\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kmoho", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678156839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! I have accepted an offer at a big bank for when I graduate as a software engineer. I can decide between two different roles. What they have available is big data engineer or ios/android app dev. I do want to end up in a more traditional SWE role like fullstack or web dev. But who knows I may like whatever I get into. Which of the two roles would a better start to my career? I personally feel like iOS/android dev is a bit too niche and I could transfer big data skills to other jobs. But I\u2019m not 100% which is why I\u2019m asking here. Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11kmoho", "is_robot_indexable": true, "report_reasons": null, "author": "OOFBOSS", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11kmoho/deciding_between_two_positions_unrelated_to_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11kmoho/deciding_between_two_positions_unrelated_to_what/", "subreddit_subscribers": 92161, "created_utc": 1678156839.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}