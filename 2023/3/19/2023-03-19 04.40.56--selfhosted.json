{"kind": "Listing", "data": {"after": "t3_11uw995", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_n4bml56s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: unless you are using wildcard certificates, all your subdomains get published in a list of issued Let's Encrypt certificates. You can see if your subdomains are published here: https://crt.sh/", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uyw5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 322, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 322, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679169969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uyw5s", "is_robot_indexable": true, "report_reasons": null, "author": "snowcrashr", "discussion_type": null, "num_comments": 98, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uyw5s/psa_unless_you_are_using_wildcard_certificates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uyw5s/psa_unless_you_are_using_wildcard_certificates/", "subreddit_subscribers": 235652, "created_utc": 1679169969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_bbsx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-Hosted SaaS Alternatives: Replacing Paid Tools With FOSS Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 58, "top_awarded_type": null, "hide_score": false, "name": "t3_11ukedz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 167, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 167, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/28X_J5Pf032BkULARVmnPDDqEVf0ttTD41ZFbpekXjQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679135053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tedium.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tedium.co/2023/03/04/self-hosted-saas-app-alternatives/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OWADfVMJlPgYuEV5hFLLLzMgUQzMRBRyvBv_RjHqgZo.jpg?auto=webp&amp;v=enabled&amp;s=738ee6d6b1a157ac5c53b324192be4dc7c55680b", "width": 650, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/OWADfVMJlPgYuEV5hFLLLzMgUQzMRBRyvBv_RjHqgZo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3d1814330405dc1acc7f4765645982d70d3981a", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/OWADfVMJlPgYuEV5hFLLLzMgUQzMRBRyvBv_RjHqgZo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b94d81ed260d4753acee50504f9ff65893477f4", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/OWADfVMJlPgYuEV5hFLLLzMgUQzMRBRyvBv_RjHqgZo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edb517e84a2b6e81e1e7cf061e904f6db104df0c", "width": 320, "height": 132}, {"url": "https://external-preview.redd.it/OWADfVMJlPgYuEV5hFLLLzMgUQzMRBRyvBv_RjHqgZo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d2a72086c924018319007a416d874aacb61b7a7", "width": 640, "height": 265}], "variants": {}, "id": "AsIHfCJsbGEh4DSZ5ovsHTA5StnP4AO76nKFfibiKmQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ukedz", "is_robot_indexable": true, "report_reasons": null, "author": "theKovah", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11ukedz/selfhosted_saas_alternatives_replacing_paid_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tedium.co/2023/03/04/self-hosted-saas-app-alternatives/", "subreddit_subscribers": 235652, "created_utc": 1679135053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi everyone, \n\nAny suggestions for a self-hosted alternative to ClickUp? The free version does not support Teams.", "author_fullname": "t2_9r3lmph2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted Alternatived to ClickUp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ukkdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679135596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;Any suggestions for a self-hosted alternative to ClickUp? The free version does not support Teams.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ukkdy", "is_robot_indexable": true, "report_reasons": null, "author": "IllustriousFingering", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11ukkdy/selfhosted_alternatived_to_clickup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11ukkdy/selfhosted_alternatived_to_clickup/", "subreddit_subscribers": 235652, "created_utc": 1679135596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Just what the title says... Is bitwarden/vaultwarden still reigning king even with current known auto-fill exploit?\n\nCurrently running VaultWarden on Unraid, using bitwarden app.\n\n\\*edit1 - Hey thanks everyone for the responses. Everyone asking about what the exploit is here is a link that explains it quite well with a response by the bitwarden team:[https://www.techspot.com/news/97951-bitwarden-password-manager-browser-extension-has-known-exploit.html](https://www.techspot.com/news/97951-bitwarden-password-manager-browser-extension-has-known-exploit.html)\n\n\\*edit2 - I currently am using it with autofill turned off so not really an issue. Bitwarden wasn't just singled out for being one of many with the same issue the way it handles iframes vs many other is unsafe.\n\n[View Poll](https://www.reddit.com/poll/11ui61k)", "author_fullname": "t2_w0zpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best current self hosted password manager(2023)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ui61k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679176222.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679127085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just what the title says... Is bitwarden/vaultwarden still reigning king even with current known auto-fill exploit?&lt;/p&gt;\n\n&lt;p&gt;Currently running VaultWarden on Unraid, using bitwarden app.&lt;/p&gt;\n\n&lt;p&gt;*edit1 - Hey thanks everyone for the responses. Everyone asking about what the exploit is here is a link that explains it quite well with a response by the bitwarden team:&lt;a href=\"https://www.techspot.com/news/97951-bitwarden-password-manager-browser-extension-has-known-exploit.html\"&gt;https://www.techspot.com/news/97951-bitwarden-password-manager-browser-extension-has-known-exploit.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;*edit2 - I currently am using it with autofill turned off so not really an issue. Bitwarden wasn&amp;#39;t just singled out for being one of many with the same issue the way it handles iframes vs many other is unsafe.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11ui61k\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?auto=webp&amp;v=enabled&amp;s=1bc9167dfe8779ebc8f2f2613a0c4d6c19a73d43", "width": 2560, "height": 1652}, "resolutions": [{"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b634b690dc55ae593673819e8000aec6d91a30c1", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf964683ed9b50022597bedab675201a9ad475b2", "width": 216, "height": 139}, {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17e14d6db87df99f1d719d01d404e297600b6b66", "width": 320, "height": 206}, {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbabd0a1c677d7d1406e97633031d32bad9438a6", "width": 640, "height": 413}, {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0758f189f1717fe47f6ca1df91d1ac1ffa60ab2", "width": 960, "height": 619}, {"url": "https://external-preview.redd.it/erVGlsNyyQe7BYqOUDteVkRvr8ywAN679gZOy6pZgnM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ced1e7fc48c392bf309866325dbf00ed390ce40", "width": 1080, "height": 696}], "variants": {}, "id": "teVmVwrRz6frNL7F9OW9_eKe-KB7pUYi6k1gO9YImck"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ui61k", "is_robot_indexable": true, "report_reasons": null, "author": "modulateddreams", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679559085464, "options": [{"text": "Bitwarden/VaultWarden", "id": "22120270"}, {"text": "Psono", "id": "22120271"}, {"text": "Passbolt", "id": "22120272"}, {"text": "KeeWeb", "id": "22120273"}, {"text": "Other", "id": "22120274"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 1624, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11ui61k/best_current_self_hosted_password_manager2023/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/selfhosted/comments/11ui61k/best_current_self_hosted_password_manager2023/", "subreddit_subscribers": 235652, "created_utc": 1679127085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I can't seem to find anything that could fit my needs.  I let my kids watch some select channels on youtube, but I would like to control it better.  I was looking for a Youtube Frontend that (probably) has user accounts and would only show channels/videos that were approved by the admin (me).  I could populate it with a bunch of approved youtubers that I am fine with them watching.  I've tried just using yt-dlp and hosting the channels myself, but that only works for a few, not big, channels.  I think this frontend would on demand get the video and play it back through the front end.\n\nI am open to a halfway there solution or a completely different approach if  you had one, end result is just to limit the video selection to younger kids a bit.\n\nedit: Currently I do download the channels I find okay, but I am not looking to end up on /r/datahoarders and some channels are just too big and I am willing to add many channels.  For example, [https://www.youtube.com/@artforkidshub](https://www.youtube.com/@artforkidshub) is huge but one of their favorites.  I really want a proxy like frontend and not a solution to download all and serve them up.", "author_fullname": "t2_fwitc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "YouTube Frontend with parental controls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11umucl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679153330.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679141675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t seem to find anything that could fit my needs.  I let my kids watch some select channels on youtube, but I would like to control it better.  I was looking for a Youtube Frontend that (probably) has user accounts and would only show channels/videos that were approved by the admin (me).  I could populate it with a bunch of approved youtubers that I am fine with them watching.  I&amp;#39;ve tried just using yt-dlp and hosting the channels myself, but that only works for a few, not big, channels.  I think this frontend would on demand get the video and play it back through the front end.&lt;/p&gt;\n\n&lt;p&gt;I am open to a halfway there solution or a completely different approach if  you had one, end result is just to limit the video selection to younger kids a bit.&lt;/p&gt;\n\n&lt;p&gt;edit: Currently I do download the channels I find okay, but I am not looking to end up on &lt;a href=\"/r/datahoarders\"&gt;/r/datahoarders&lt;/a&gt; and some channels are just too big and I am willing to add many channels.  For example, &lt;a href=\"https://www.youtube.com/@artforkidshub\"&gt;https://www.youtube.com/@artforkidshub&lt;/a&gt; is huge but one of their favorites.  I really want a proxy like frontend and not a solution to download all and serve them up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l0-2FvlCW7yOSk3MzvYNuqoCrkS85Z30AoPMxLiDAgw.jpg?auto=webp&amp;v=enabled&amp;s=4489eb68a6e11bafb6a3dee41f0fe428ca606e3a", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/l0-2FvlCW7yOSk3MzvYNuqoCrkS85Z30AoPMxLiDAgw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d9b33ca32ec05f94fc071b3f7042909d0078cf1", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/l0-2FvlCW7yOSk3MzvYNuqoCrkS85Z30AoPMxLiDAgw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39ecda6c1595ff990523ce398035248cb393a0d9", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/l0-2FvlCW7yOSk3MzvYNuqoCrkS85Z30AoPMxLiDAgw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da9bbca642999dec59ccd62f1034f276097e9e5b", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/l0-2FvlCW7yOSk3MzvYNuqoCrkS85Z30AoPMxLiDAgw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed43383e10b7874297033fb8776783924e268e27", "width": 640, "height": 640}], "variants": {}, "id": "-r8EL5z7DHOuKmunytkWGPOkKnt3fWsS_N0asvpwdLg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11umucl", "is_robot_indexable": true, "report_reasons": null, "author": "eye_can_do_that", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11umucl/youtube_frontend_with_parental_controls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11umucl/youtube_frontend_with_parental_controls/", "subreddit_subscribers": 235652, "created_utc": 1679141675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have created a prometheus-immich exporter for grafana to track my library's growth. It tracks simple things like the amount of photos or videos uploaded by each user and overall storage stats. What else would you like to see added. \n[Github](https://github.com/friendlyFriend4000/prometheus-immich-exporter)\n[DockerHub](https://hub.docker.com/repository/docker/friendlyfriend/prometheus-immich-exporter/general)", "author_fullname": "t2_6b285", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A simple prometheus immich exporter to display metrics in grafana", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uuqzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679161335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created a prometheus-immich exporter for grafana to track my library&amp;#39;s growth. It tracks simple things like the amount of photos or videos uploaded by each user and overall storage stats. What else would you like to see added. \n&lt;a href=\"https://github.com/friendlyFriend4000/prometheus-immich-exporter\"&gt;Github&lt;/a&gt;\n&lt;a href=\"https://hub.docker.com/repository/docker/friendlyfriend/prometheus-immich-exporter/general\"&gt;DockerHub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?auto=webp&amp;v=enabled&amp;s=76246e9b01a7e5e0ee489456ad745230c6ebb5b8", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea07060a06e7488840621633a81db4c3fa05bcdd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4e21f829b943f3f659685c3c164e4d5f734066b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6354c6683185a854101656bf28aee4e4628fd223", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d37138f64d3eb992eeb6748fa1080a66f317683", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1474c9a151a1926c75a02319ef5c9447827bdbfe", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vmgzE-IQ0U-iTG3OjjH3sHCoTSpiTpju3nLDpGib5AE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8944a013f1c96da3c5507e2c16479cbfe09940b", "width": 1080, "height": 540}], "variants": {}, "id": "glEVeNvVZqeLWMVJ2yjoOvjUt0vCgrj0_VQHus3ugxM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uuqzi", "is_robot_indexable": true, "report_reasons": null, "author": "MeLurker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uuqzi/a_simple_prometheus_immich_exporter_to_display/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uuqzi/a_simple_prometheus_immich_exporter_to_display/", "subreddit_subscribers": 235652, "created_utc": 1679161335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_4a8ri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Standard Notes releasing simpler 2.0 self-hosting method", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11v1z36", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QXvCE8iM9c0a5RQ7j8W_CM6T0C-CR3J52DDbFjvVWjY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1679176225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "standardnotes.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://standardnotes.com/help/self-hosting/docker", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JXxE4-F0GqaypasVj77JvNN5eAkjEXu4ljqvaadNHIw.jpg?auto=webp&amp;v=enabled&amp;s=e616dbe45a6ce52e7a645aa0e0273763e317bd5c", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/JXxE4-F0GqaypasVj77JvNN5eAkjEXu4ljqvaadNHIw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b3eff7e41c96949e869b4c22b19ccc0cd8af56a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/JXxE4-F0GqaypasVj77JvNN5eAkjEXu4ljqvaadNHIw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c70a41e22f8fb600223640361e67d0037dab804", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/JXxE4-F0GqaypasVj77JvNN5eAkjEXu4ljqvaadNHIw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e62ff9ba1917496c573edda927c82e8ebee0c18f", "width": 320, "height": 320}], "variants": {}, "id": "20CKD5KPzmUt1R6r2xlvkTL-zB5nCR1Cgq-tHi4t2MY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v1z36", "is_robot_indexable": true, "report_reasons": null, "author": "poisonborz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v1z36/standard_notes_releasing_simpler_20_selfhosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://standardnotes.com/help/self-hosting/docker", "subreddit_subscribers": 235652, "created_utc": 1679176225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have a mini PC that I want to turn into a NAS. The main goal is to turn it into a book library (no comics or manga) for my father.\n\nMy father is almost 70 years old and he reads all the time. Until recently, he read on his Android smartphone because he can make the font size as large as he wants and he carries it on him all the time. But the screen is just too small so I gave him an Android tablet so he could read more comfortably.\n\nWhat I want to achieve is an epub library to be accessed and shared between his phone and  tablet  and that he can access remotely from anywhere, and that he can resume the reading at any time on any of the devices. Something similar to what Jellyfin, emby or plex do with series and movies.\n\nI've tried Calibre and Kavitan through OPSD, but they both download the epub to the device instead of accessing it remotely, so there is no way to resume the reading. Kavita can achieve this by being accessed remotely without OPSD and reading with the built in reader but you lose all the capabilities of an epub such as being able to highlight parts of the text or increase the font size.\n\nCould anyone suggest any combination of services and apps for android that would be able to achieve what I'm looking for? Of course, while my father can use the apps without a problem, I would like it to be as accessible as possible.\n\nThanks!", "author_fullname": "t2_2nxpntw7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any help about books/epub hosting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uubth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679160357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mini PC that I want to turn into a NAS. The main goal is to turn it into a book library (no comics or manga) for my father.&lt;/p&gt;\n\n&lt;p&gt;My father is almost 70 years old and he reads all the time. Until recently, he read on his Android smartphone because he can make the font size as large as he wants and he carries it on him all the time. But the screen is just too small so I gave him an Android tablet so he could read more comfortably.&lt;/p&gt;\n\n&lt;p&gt;What I want to achieve is an epub library to be accessed and shared between his phone and  tablet  and that he can access remotely from anywhere, and that he can resume the reading at any time on any of the devices. Something similar to what Jellyfin, emby or plex do with series and movies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried Calibre and Kavitan through OPSD, but they both download the epub to the device instead of accessing it remotely, so there is no way to resume the reading. Kavita can achieve this by being accessed remotely without OPSD and reading with the built in reader but you lose all the capabilities of an epub such as being able to highlight parts of the text or increase the font size.&lt;/p&gt;\n\n&lt;p&gt;Could anyone suggest any combination of services and apps for android that would be able to achieve what I&amp;#39;m looking for? Of course, while my father can use the apps without a problem, I would like it to be as accessible as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uubth", "is_robot_indexable": true, "report_reasons": null, "author": "Phonon_1", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uubth/any_help_about_booksepub_hosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uubth/any_help_about_booksepub_hosting/", "subreddit_subscribers": 235652, "created_utc": 1679160357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\nis it possible to host gpodder on docker and use it in AntennaPod to synchronise the podcasts?  \nIf yes, how to do it?", "author_fullname": "t2_4ihpurvq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to setup gpodder on docker for AntennaPod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11utw5b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679159319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;is it possible to host gpodder on docker and use it in AntennaPod to synchronise the podcasts?&lt;br/&gt;\nIf yes, how to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11utw5b", "is_robot_indexable": true, "report_reasons": null, "author": "update-freak", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11utw5b/how_to_setup_gpodder_on_docker_for_antennapod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11utw5b/how_to_setup_gpodder_on_docker_for_antennapod/", "subreddit_subscribers": 235652, "created_utc": 1679159319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I know I can just play it all via VLC but looking for a more elegant way of serving up my local music video collection. I have tried what Jellyfin and Kodi offer as far as Serving up music vids and im jut not feeling it. I really like being able to browse the sidebar on youtube while I have a video playing.\n\nAny Recommendations? Its a big daily missing piece in my media setup. Bonus points if I dont have to reupload somewhere else.", "author_fullname": "t2_8ahvf36d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Music Video/Clip App Similar to youtube for local Collection?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ugpop", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679121775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know I can just play it all via VLC but looking for a more elegant way of serving up my local music video collection. I have tried what Jellyfin and Kodi offer as far as Serving up music vids and im jut not feeling it. I really like being able to browse the sidebar on youtube while I have a video playing.&lt;/p&gt;\n\n&lt;p&gt;Any Recommendations? Its a big daily missing piece in my media setup. Bonus points if I dont have to reupload somewhere else.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ugpop", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Ad8986", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11ugpop/music_videoclip_app_similar_to_youtube_for_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11ugpop/music_videoclip_app_similar_to_youtube_for_local/", "subreddit_subscribers": 235652, "created_utc": 1679121775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have searched online for 2 years off and on for a small form factor computer/server that has two GBe ports. Everything I find seems to have celerons from as old as 2016. Many the recommendations on this Subreddit are for systems that are vulnerable. I just can't see spending money on something that is broken from the start. This is a router, it will be accessible to anyone on the internet. Doesn't that mean it should be secure?\n\nSo, does anyone know of any 2 GBe port small form factor hardware that is not vulnerable?\n\nA short list of needs:\n\n1. 4 GB RAM minimum\n2. GBe ports cannot be through the USB bus as fiber is coming soon and I want full throughput\n3. some kind of storage interface (flash, sd, sata, m2, just not usb)\n4. quad core preferred although dual core is fine\n\nI have learned a lot on this subreddit and I am thankful. Look forward to your suggestions.\n\nPS. I am willing to go ARM.", "author_fullname": "t2_gumkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Router hardware that is not Meltdown or Spectre vulnerable.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uwaur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679164922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have searched online for 2 years off and on for a small form factor computer/server that has two GBe ports. Everything I find seems to have celerons from as old as 2016. Many the recommendations on this Subreddit are for systems that are vulnerable. I just can&amp;#39;t see spending money on something that is broken from the start. This is a router, it will be accessible to anyone on the internet. Doesn&amp;#39;t that mean it should be secure?&lt;/p&gt;\n\n&lt;p&gt;So, does anyone know of any 2 GBe port small form factor hardware that is not vulnerable?&lt;/p&gt;\n\n&lt;p&gt;A short list of needs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;4 GB RAM minimum&lt;/li&gt;\n&lt;li&gt;GBe ports cannot be through the USB bus as fiber is coming soon and I want full throughput&lt;/li&gt;\n&lt;li&gt;some kind of storage interface (flash, sd, sata, m2, just not usb)&lt;/li&gt;\n&lt;li&gt;quad core preferred although dual core is fine&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I have learned a lot on this subreddit and I am thankful. Look forward to your suggestions.&lt;/p&gt;\n\n&lt;p&gt;PS. I am willing to go ARM.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uwaur", "is_robot_indexable": true, "report_reasons": null, "author": "phirestalker", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uwaur/router_hardware_that_is_not_meltdown_or_spectre/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uwaur/router_hardware_that_is_not_meltdown_or_spectre/", "subreddit_subscribers": 235652, "created_utc": 1679164922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi, I'm looking at setting up a media server and one thing I'm having trouble finding is a 'synced play/chat' feature like Netflix party that would allow chat within the media player.\n\nI've used Discord for this previously, but there were issues with the video.\n\nI've set up Plex, and I was thinking of trying Jellyfin, but the chat feature was something that I was really hoping to have and I wondered if anyone knew of a plug-in for either of those, or a different software entirely, that could allow synced playback and chat for multiple users?\n\nThanks very much!", "author_fullname": "t2_6m377", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teleparty / Netflix Party Alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uodki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679145736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking at setting up a media server and one thing I&amp;#39;m having trouble finding is a &amp;#39;synced play/chat&amp;#39; feature like Netflix party that would allow chat within the media player.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used Discord for this previously, but there were issues with the video.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve set up Plex, and I was thinking of trying Jellyfin, but the chat feature was something that I was really hoping to have and I wondered if anyone knew of a plug-in for either of those, or a different software entirely, that could allow synced playback and chat for multiple users?&lt;/p&gt;\n\n&lt;p&gt;Thanks very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uodki", "is_robot_indexable": true, "report_reasons": null, "author": "wonkytonk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uodki/teleparty_netflix_party_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uodki/teleparty_netflix_party_alternative/", "subreddit_subscribers": 235652, "created_utc": 1679145736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello everyone. I'm new to linux and selfhosting and I've been learning as much as I can over the past few weeks. I would like to ask for help or advice with what I want to do.\n\nI am currently running linux mint and I'm trying to self host a few apps in docker:\n\n\\- Vaultwarden\n\n\\- Pi-Hole\n\n\\- Rustdesk\n\n\\- Plex or Jellyfin\n\n\\- Nextcloud\n\nI also would like to set up a Wireguard VPN so that I can access all of these services from out of home.\n\nLastly, I want to use that VPN to set up my own VPN server for hiding my IP and torrenting.\n\n&amp;#x200B;\n\nI've been looking for tutorials, guides, anything on all of them, but none of them seem to work for me. Particularly everyone seems to be using reverse proxys instead of VPNs, so there aren't any VPN guides that I can find. I also know that linux mint isn't the most ideal for self hosting, but since I'm a complete beginner, I would like to stick to this for now.\n\nIf anyone is willing to point me in the right direction, please let me know. Thank yooou!!", "author_fullname": "t2_uqdtsn93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to selfhosting, advice appreciated", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uwk69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679165518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I&amp;#39;m new to linux and selfhosting and I&amp;#39;ve been learning as much as I can over the past few weeks. I would like to ask for help or advice with what I want to do.&lt;/p&gt;\n\n&lt;p&gt;I am currently running linux mint and I&amp;#39;m trying to self host a few apps in docker:&lt;/p&gt;\n\n&lt;p&gt;- Vaultwarden&lt;/p&gt;\n\n&lt;p&gt;- Pi-Hole&lt;/p&gt;\n\n&lt;p&gt;- Rustdesk&lt;/p&gt;\n\n&lt;p&gt;- Plex or Jellyfin&lt;/p&gt;\n\n&lt;p&gt;- Nextcloud&lt;/p&gt;\n\n&lt;p&gt;I also would like to set up a Wireguard VPN so that I can access all of these services from out of home.&lt;/p&gt;\n\n&lt;p&gt;Lastly, I want to use that VPN to set up my own VPN server for hiding my IP and torrenting.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking for tutorials, guides, anything on all of them, but none of them seem to work for me. Particularly everyone seems to be using reverse proxys instead of VPNs, so there aren&amp;#39;t any VPN guides that I can find. I also know that linux mint isn&amp;#39;t the most ideal for self hosting, but since I&amp;#39;m a complete beginner, I would like to stick to this for now.&lt;/p&gt;\n\n&lt;p&gt;If anyone is willing to point me in the right direction, please let me know. Thank yooou!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uwk69", "is_robot_indexable": true, "report_reasons": null, "author": "ApartWorld6038", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uwk69/new_to_selfhosting_advice_appreciated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uwk69/new_to_selfhosting_advice_appreciated/", "subreddit_subscribers": 235652, "created_utc": 1679165518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm moving a large number of documents from a manually-filed system over to paperless-ngx.  My current naming convention is `{isodate} {title}.pdf` for all my files.  I'm okay blowing away my folder hierarchy in favor of re-tagging everything, but I'd like to pull these two pieces of data out of the filename.\n\nIs there a way to set file metadata with the pre/post-consumption script?  Or is there another way to accomplish what I'm trying to do?", "author_fullname": "t2_5f0wl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pre-consumption scripts in paperless-ngx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "textstorage", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uwfly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Text Storage", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679165230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m moving a large number of documents from a manually-filed system over to paperless-ngx.  My current naming convention is &lt;code&gt;{isodate} {title}.pdf&lt;/code&gt; for all my files.  I&amp;#39;m okay blowing away my folder hierarchy in favor of re-tagging everything, but I&amp;#39;d like to pull these two pieces of data out of the filename.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to set file metadata with the pre/post-consumption script?  Or is there another way to accomplish what I&amp;#39;m trying to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "38c528e4-7e68-11e9-baff-0ec5f304b28c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uwfly", "is_robot_indexable": true, "report_reasons": null, "author": "phblj", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uwfly/preconsumption_scripts_in_paperlessngx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uwfly/preconsumption_scripts_in_paperlessngx/", "subreddit_subscribers": 235652, "created_utc": 1679165230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I recently started scanning every photo album in my extended family, and Id like to share it with everyone.\nDoes anyone know a way to share photos with non-tech savvy people in full quality?\nI\u2019ve already got a server and multiple domains.", "author_fullname": "t2_5xnuquq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image Sharing platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11umgpr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679140620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently started scanning every photo album in my extended family, and Id like to share it with everyone.\nDoes anyone know a way to share photos with non-tech savvy people in full quality?\nI\u2019ve already got a server and multiple domains.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11umgpr", "is_robot_indexable": true, "report_reasons": null, "author": "itaisls9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11umgpr/image_sharing_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11umgpr/image_sharing_platform/", "subreddit_subscribers": 235652, "created_utc": 1679140620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "It took me a while to finally try paperless-ngx. It's pretty cool and does some things that I didn't realize. That said, it's still half of what I'm looking for. I'm currently using Joplin for notes but would really like to have a document system that includes my notes. At least partly because my notes often have links or references to other files (images for instance). \n\nSome of the features I'm looking for:\n\nA) Add images to notes. This has been working pretty well in Joplin. I use MacOS a lot for daily driving stuff and I can (usually) open an image in Preview from a Joplin note, add annotation, close the image and it all just automatically saves in the note. \n\nB) Share notes publicly. Joplin can apparently now do this with the self hosted server but I haven't tried it yet. Regardless, this is something that I definitely want in the future. \n\nC) Apps for desktop (Linux, Macos) and mobile (iOS, Android). I think this is more about the mobile apps since some notes platforms have a number of options for viewing and editing notes on a desktop OS but I definitely want a solid experience on Android. \n\nD) Open source, selfhosted. Obsidian gets a lot of thumbs up but it is closed source (sort of) and I haven't figured out how to sync it with Nextcloud on Android. Syncthing might work?", "author_fullname": "t2_14jfaw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ways to merge paperless-ngx with a notes application?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "cloudstorage", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v55mb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud Storage", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679183859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It took me a while to finally try paperless-ngx. It&amp;#39;s pretty cool and does some things that I didn&amp;#39;t realize. That said, it&amp;#39;s still half of what I&amp;#39;m looking for. I&amp;#39;m currently using Joplin for notes but would really like to have a document system that includes my notes. At least partly because my notes often have links or references to other files (images for instance). &lt;/p&gt;\n\n&lt;p&gt;Some of the features I&amp;#39;m looking for:&lt;/p&gt;\n\n&lt;p&gt;A) Add images to notes. This has been working pretty well in Joplin. I use MacOS a lot for daily driving stuff and I can (usually) open an image in Preview from a Joplin note, add annotation, close the image and it all just automatically saves in the note. &lt;/p&gt;\n\n&lt;p&gt;B) Share notes publicly. Joplin can apparently now do this with the self hosted server but I haven&amp;#39;t tried it yet. Regardless, this is something that I definitely want in the future. &lt;/p&gt;\n\n&lt;p&gt;C) Apps for desktop (Linux, Macos) and mobile (iOS, Android). I think this is more about the mobile apps since some notes platforms have a number of options for viewing and editing notes on a desktop OS but I definitely want a solid experience on Android. &lt;/p&gt;\n\n&lt;p&gt;D) Open source, selfhosted. Obsidian gets a lot of thumbs up but it is closed source (sort of) and I haven&amp;#39;t figured out how to sync it with Nextcloud on Android. Syncthing might work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bc5f6346-7e67-11e9-a0fe-0e631119683e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v55mb", "is_robot_indexable": true, "report_reasons": null, "author": "chmedly020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v55mb/any_ways_to_merge_paperlessngx_with_a_notes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v55mb/any_ways_to_merge_paperlessngx_with_a_notes/", "subreddit_subscribers": 235652, "created_utc": 1679183859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "When just looking for self-hosted lists, we get [great resources](https://github.com/awesome-selfhosted/awesome-selfhosted). The same goes for sysadmin, devops, etc. So all good.\n\nHowever add \"SSO\" or \"single-sign-on\" and the main search engine switches to the awful revenue-driven advertising crap we are used to: we get lists over lists of bot-generated \"comparisons\" of SSO solutions and a few websites of such solutions, not SSO-supporting self-hosted services. Using quotes does not help, using `+`/`-` either and the \"reddit trick\" brings me here but about specific services. Going with \"LDAP\" or \"SAML\" brings all the enterprise awful revenue-driven advertising crap. Going \"OIDC\" or \"OAuth\" brings all the silicon valley revenue-driven advertising crap.\n\nSo, to put it bluntly, does such a list of SSO-supporting self-hosted services exist? Or is there a trick you people use to quickly find that information? Going in manually is much more tedious than expected, really...\n\n----\n\nedit: Just to make sure the discussion stays focused: I know about Authelia. I know it is nice. I also know that if I provide X services to Y users, I would still have to configure X services (actually X+1 services, since Authelia) to accept Y users, which is what I want *not* to do.", "author_fullname": "t2_cs1rt2a1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any resource listing self-hosted service supporting single-sign on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "wikis", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v37wb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Wiki's", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679179604.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679179244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When just looking for self-hosted lists, we get &lt;a href=\"https://github.com/awesome-selfhosted/awesome-selfhosted\"&gt;great resources&lt;/a&gt;. The same goes for sysadmin, devops, etc. So all good.&lt;/p&gt;\n\n&lt;p&gt;However add &amp;quot;SSO&amp;quot; or &amp;quot;single-sign-on&amp;quot; and the main search engine switches to the awful revenue-driven advertising crap we are used to: we get lists over lists of bot-generated &amp;quot;comparisons&amp;quot; of SSO solutions and a few websites of such solutions, not SSO-supporting self-hosted services. Using quotes does not help, using &lt;code&gt;+&lt;/code&gt;/&lt;code&gt;-&lt;/code&gt; either and the &amp;quot;reddit trick&amp;quot; brings me here but about specific services. Going with &amp;quot;LDAP&amp;quot; or &amp;quot;SAML&amp;quot; brings all the enterprise awful revenue-driven advertising crap. Going &amp;quot;OIDC&amp;quot; or &amp;quot;OAuth&amp;quot; brings all the silicon valley revenue-driven advertising crap.&lt;/p&gt;\n\n&lt;p&gt;So, to put it bluntly, does such a list of SSO-supporting self-hosted services exist? Or is there a trick you people use to quickly find that information? Going in manually is much more tedious than expected, really...&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;edit: Just to make sure the discussion stays focused: I know about Authelia. I know it is nice. I also know that if I provide X services to Y users, I would still have to configure X services (actually X+1 services, since Authelia) to accept Y users, which is what I want &lt;em&gt;not&lt;/em&gt; to do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?auto=webp&amp;v=enabled&amp;s=18d91a8ef0ec8f83fc60bd269bffd4f86808a9bf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cddd2978f2a0c15f57ab0a239ff53a1efe9b6d83", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b108df4180f95b3df49fe27cd1ac6b9fd19a845", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f8b1d6cbe32f5080b1d899e32fe545c1c0906c6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a19081084b6cb9a9a6acb4eec051527c81e7488d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ef96495d570299cda2ce1d7c3977a50b3c87b4a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/865kUJTrTqSRLVEhkPbksf44NsrTkkCfZtvwCMgbrag.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a2e8c4738b0a05fe5843d959d79b734041bbb8e", "width": 1080, "height": 540}], "variants": {}, "id": "ANPhxuLapVqlLsn1ImZmEYT9AUhpgiIuIYwSAc67pws"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "78dcb492-7e68-11e9-b4e7-0e296f55dc70", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v37wb", "is_robot_indexable": true, "report_reasons": null, "author": "InfamousAgency6784", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v37wb/is_there_any_resource_listing_selfhosted_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v37wb/is_there_any_resource_listing_selfhosted_service/", "subreddit_subscribers": 235652, "created_utc": 1679179244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_sfep5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Well, I was going to try Nginx Proxy Manager as I migrate to a new server (and from 16.04 to 22.04). But, 10 minutes with ChatGPT 4 and \"together\" we created the necessary conf files for Nginx.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ue0bs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679112735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ue0bs", "is_robot_indexable": true, "report_reasons": null, "author": "jj7753", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11ue0bs/well_i_was_going_to_try_nginx_proxy_manager_as_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11ue0bs/well_i_was_going_to_try_nginx_proxy_manager_as_i/", "subreddit_subscribers": 235652, "created_utc": 1679112735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "My friend recently told me that he's using some kind of service to automatically route every device on the network through a VPN for specific sites, like Netflix and HBO. Apparently all that is required is setting the device to use a specific DNS server, which transparently handles routing according to his preferences and makes his Apple TV work with HBO in another country.\n\nThere are a lot of interesting implications there, and I'm not sure precisely how it works. The only thing I can come up with is this:\n\nThe DNS server tells the TV that Netflix is located at 123.45.67.89, which is actually a server owned by the DNS provider. It then sets up a firewall rule that says all requests from &lt;originating IP&gt; to that specific IP are forwarded directly to Netflix, using the 123.45.67.89 server as a proxy and thus making Netflix believe the user is in a different region.\n\nMaybe this isn't how it works, but regardless, what I'm looking for is some kind of self-hosted DNS server that creates this kind of routing policy on-the-fly, or something that accomplishes the same thing\u2014transparently intercepts traffic to certain sites without the need for VPN software on the host device. My router (the Asus RT-AX88U) can route specific IP addresses through a VPN profile, but I don't know that I trust those IPs not to change, so it's not necessarily suitable for every situation. I was thinking I could set this up either on my local network or on a nearby VPS. I admit I'm kind of bad at Linux networking and this is certainly diving into the deep end of it, so I was hoping something can simplify the process a bit.", "author_fullname": "t2_sffr3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I heard about a combination DNS / VPN recently and was wondering if there are any self-hosted alternatives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11vald5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679198120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend recently told me that he&amp;#39;s using some kind of service to automatically route every device on the network through a VPN for specific sites, like Netflix and HBO. Apparently all that is required is setting the device to use a specific DNS server, which transparently handles routing according to his preferences and makes his Apple TV work with HBO in another country.&lt;/p&gt;\n\n&lt;p&gt;There are a lot of interesting implications there, and I&amp;#39;m not sure precisely how it works. The only thing I can come up with is this:&lt;/p&gt;\n\n&lt;p&gt;The DNS server tells the TV that Netflix is located at 123.45.67.89, which is actually a server owned by the DNS provider. It then sets up a firewall rule that says all requests from &amp;lt;originating IP&amp;gt; to that specific IP are forwarded directly to Netflix, using the 123.45.67.89 server as a proxy and thus making Netflix believe the user is in a different region.&lt;/p&gt;\n\n&lt;p&gt;Maybe this isn&amp;#39;t how it works, but regardless, what I&amp;#39;m looking for is some kind of self-hosted DNS server that creates this kind of routing policy on-the-fly, or something that accomplishes the same thing\u2014transparently intercepts traffic to certain sites without the need for VPN software on the host device. My router (the Asus RT-AX88U) can route specific IP addresses through a VPN profile, but I don&amp;#39;t know that I trust those IPs not to change, so it&amp;#39;s not necessarily suitable for every situation. I was thinking I could set this up either on my local network or on a nearby VPS. I admit I&amp;#39;m kind of bad at Linux networking and this is certainly diving into the deep end of it, so I was hoping something can simplify the process a bit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11vald5", "is_robot_indexable": true, "report_reasons": null, "author": "SLJ7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11vald5/i_heard_about_a_combination_dns_vpn_recently_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11vald5/i_heard_about_a_combination_dns_vpn_recently_and/", "subreddit_subscribers": 235652, "created_utc": 1679198120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm trying to run Akaunting, and after deploying, I get this error.\n\n    Module rewrite already enabled\n    Could not open input file: artisan\n\nI know the error is from something that has to do with a PHP framework, but I'm a noob so I dont know how to fix it. Here is my docker-compose\n\n    version: '3.7'\n    \n    services:\n    \n      akaunting:\n        container_name: akaunting\n        image: docker.io/akaunting/akaunting:latest\n        build:\n          context: .\n        ports:\n          - 8000:80\n        volumes:\n          - /xxx/akaunting/akaunting-data:/var/www/html\n        restart: unless-stopped\n        environment:\n          - AKAUNTING_SETUP=true\n          - APP_URL=http://192.168.x.xxx:8000/\n          - LOCALE=en-US\n          - DB_HOST=akaunting-db\n          - DB_PORT=3306\n          - DB_NAME=akaunting\n          - DB_USERNAME=admin\n          - DB_PASSWORD=xxx\n          - DB_PREFIX=asd_\n          - COMPANY_NAME=xxx xxx\n          - COMPANY_EMAIL=xxxx\n          - ADMIN_EMAIL=xxxx\n          - ADMIN_PASSWORD=xxxx\n        depends_on:\n          - akaunting-db\n    \n      akaunting-db:\n        container_name: akaunting-db\n        image: mariadb\n        volumes:\n          - /xxx/akaunting/akaunting-db:/var/lib/mysql\n        restart: unless-stopped\n        environment:\n          - MYSQL_DATABASE=akaunting\n          - MYSQL_USER=admin\n          - MYSQL_PASSWORD=xxx\n          - MYSQL_RANDOM_ROOT_PASSWORD=yes\n    \n    volumes:\n      akaunting-data:\n      akaunting-db:\n\nI'm using a QNAP NAS.", "author_fullname": "t2_yw72j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Akaunting error while installing in Portainer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11v9z6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679196379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to run Akaunting, and after deploying, I get this error.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Module rewrite already enabled\nCould not open input file: artisan\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I know the error is from something that has to do with a PHP framework, but I&amp;#39;m a noob so I dont know how to fix it. Here is my docker-compose&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;version: &amp;#39;3.7&amp;#39;\n\nservices:\n\n  akaunting:\n    container_name: akaunting\n    image: docker.io/akaunting/akaunting:latest\n    build:\n      context: .\n    ports:\n      - 8000:80\n    volumes:\n      - /xxx/akaunting/akaunting-data:/var/www/html\n    restart: unless-stopped\n    environment:\n      - AKAUNTING_SETUP=true\n      - APP_URL=http://192.168.x.xxx:8000/\n      - LOCALE=en-US\n      - DB_HOST=akaunting-db\n      - DB_PORT=3306\n      - DB_NAME=akaunting\n      - DB_USERNAME=admin\n      - DB_PASSWORD=xxx\n      - DB_PREFIX=asd_\n      - COMPANY_NAME=xxx xxx\n      - COMPANY_EMAIL=xxxx\n      - ADMIN_EMAIL=xxxx\n      - ADMIN_PASSWORD=xxxx\n    depends_on:\n      - akaunting-db\n\n  akaunting-db:\n    container_name: akaunting-db\n    image: mariadb\n    volumes:\n      - /xxx/akaunting/akaunting-db:/var/lib/mysql\n    restart: unless-stopped\n    environment:\n      - MYSQL_DATABASE=akaunting\n      - MYSQL_USER=admin\n      - MYSQL_PASSWORD=xxx\n      - MYSQL_RANDOM_ROOT_PASSWORD=yes\n\nvolumes:\n  akaunting-data:\n  akaunting-db:\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;m using a QNAP NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v9z6w", "is_robot_indexable": true, "report_reasons": null, "author": "Ayouby", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v9z6w/akaunting_error_while_installing_in_portainer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v9z6w/akaunting_error_while_installing_in_portainer/", "subreddit_subscribers": 235652, "created_utc": 1679196379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello All,\n\nYou have access to the [GitHub Student Development Pack](https://education.github.com/pack) and all of its offers\u00a0if you are a student or have a student email address through your school.\n\nSome of the services I believe this community may find interesting include:\n\n* DigitalOcean (Enjoy $200 in platform credit for 1 year!)\n* Heroku (Enjoy a credit of $13 USD per month for 12 months.)\n* GitLens (Free GitLens+ Pro while you are a student.)\n* Termius (Free access to the Premium plan while you're a student.)\n* Datadog (Pro Account, including 10 servers. Free for 2 years.)\n\n... and many other offerings.\n\nRecently, I've become immersed in the world of r/homelab, r/selfhosted, etc. I recently graduated from university, and now that I have this extra time, I consider this to be my new hobby. \n\nHaving an Unifi network, an Intel mini PC running proxmox and a number of Docker containers, and an Intel Mac Mini running TrueNAS Core, my setup is fairly simple, but I'm always interested in trying new things.\n\nI want to find out how I can use [Datadog](https://www.datadoghq.com/) in my configuration as\u00a0it is free to me. As it is a paid service, I think there is a lack of information available; therefore, any articles, tutorials, etc. would be appreciated that the community recommends. I've discovered that the Datadog UI can be difficult to navigate and look at so far.\n\nA dashboard to see logs (Live/Real Time) is something I'd like to keep an eye on and think Datadog can help with.\n\nFor example, I have a Docker container running Ubuntu 22.04.2 LTS. 100 snowflake nodes function as a Node Cluster/proxy cluster in this Docker container. I can view connections per proxy by running the command \"docker-compose logs snowflake-proxy\".\n\nIs it possible to make a live, real-time dashboard to display this log? Is DataDog the best option, should I use another service, or is what I'm seeking even feasible? Also, I don't want to go the Grafana route.\n\nSidenote:\n\n* Please be patient with me if my terminology is inaccurate and incorrect as I'm still learning.\n* I'm also questioning whether it would be more cost-effective or moral to enroll in a college or university in order to receive an email and gain access to the GitHub Student Developer Bundle. Would be interested in community\u00a0thoughts.\n\nTIA", "author_fullname": "t2_ud2vp4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can I do with Datadog and GitHub Student Developer Pack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v71ye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679188579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;You have access to the &lt;a href=\"https://education.github.com/pack\"&gt;GitHub Student Development Pack&lt;/a&gt; and all of its offers\u00a0if you are a student or have a student email address through your school.&lt;/p&gt;\n\n&lt;p&gt;Some of the services I believe this community may find interesting include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DigitalOcean (Enjoy $200 in platform credit for 1 year!)&lt;/li&gt;\n&lt;li&gt;Heroku (Enjoy a credit of $13 USD per month for 12 months.)&lt;/li&gt;\n&lt;li&gt;GitLens (Free GitLens+ Pro while you are a student.)&lt;/li&gt;\n&lt;li&gt;Termius (Free access to the Premium plan while you&amp;#39;re a student.)&lt;/li&gt;\n&lt;li&gt;Datadog (Pro Account, including 10 servers. Free for 2 years.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;... and many other offerings.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve become immersed in the world of &lt;a href=\"/r/homelab\"&gt;r/homelab&lt;/a&gt;, &lt;a href=\"/r/selfhosted\"&gt;r/selfhosted&lt;/a&gt;, etc. I recently graduated from university, and now that I have this extra time, I consider this to be my new hobby. &lt;/p&gt;\n\n&lt;p&gt;Having an Unifi network, an Intel mini PC running proxmox and a number of Docker containers, and an Intel Mac Mini running TrueNAS Core, my setup is fairly simple, but I&amp;#39;m always interested in trying new things.&lt;/p&gt;\n\n&lt;p&gt;I want to find out how I can use &lt;a href=\"https://www.datadoghq.com/\"&gt;Datadog&lt;/a&gt; in my configuration as\u00a0it is free to me. As it is a paid service, I think there is a lack of information available; therefore, any articles, tutorials, etc. would be appreciated that the community recommends. I&amp;#39;ve discovered that the Datadog UI can be difficult to navigate and look at so far.&lt;/p&gt;\n\n&lt;p&gt;A dashboard to see logs (Live/Real Time) is something I&amp;#39;d like to keep an eye on and think Datadog can help with.&lt;/p&gt;\n\n&lt;p&gt;For example, I have a Docker container running Ubuntu 22.04.2 LTS. 100 snowflake nodes function as a Node Cluster/proxy cluster in this Docker container. I can view connections per proxy by running the command &amp;quot;docker-compose logs snowflake-proxy&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to make a live, real-time dashboard to display this log? Is DataDog the best option, should I use another service, or is what I&amp;#39;m seeking even feasible? Also, I don&amp;#39;t want to go the Grafana route.&lt;/p&gt;\n\n&lt;p&gt;Sidenote:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Please be patient with me if my terminology is inaccurate and incorrect as I&amp;#39;m still learning.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m also questioning whether it would be more cost-effective or moral to enroll in a college or university in order to receive an email and gain access to the GitHub Student Developer Bundle. Would be interested in community\u00a0thoughts.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?auto=webp&amp;v=enabled&amp;s=99541f6bafca1dac37a33d04acedd770429e501f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=624bdc55641aa8c6245d6f74907c5c8baca75a63", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8da630f2591615b52662f0f45a8f3b1a90e5db4d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e379bafd541ce50d4f27dff340f37aa73348fa6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=369cfd5bd5841886c70839410ac653a7d6ebc33b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ba3f35023326f6f124bbdaeb02aeda0005c60db", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/gCRcDs0ew7t1JGPokHl57ab5TdeTUk92vKS3eRt-aAQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=036156595f84b6a27a29b6db334d5ad1d98017b1", "width": 1080, "height": 567}], "variants": {}, "id": "xtaSlIu1-_I3uKctZXa03MhFhjNbUipgNpBPwW7H7M0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v71ye", "is_robot_indexable": true, "report_reasons": null, "author": "forcemans11", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v71ye/what_can_i_do_with_datadog_and_github_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v71ye/what_can_i_do_with_datadog_and_github_student/", "subreddit_subscribers": 235652, "created_utc": 1679188579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello all! I am struggling a bit to find a decent Android app that supports my setup with the latest stable version of FreshRSS\n\nI am willing to try an app that:\n\n* supports self signed certificates;\n* supports HTTP Auth in front of FreshRSS (not much trust for external visitors).\n\nAnd, nice to have:\n\n* client TLS certificates for authentication.\n\nThanks in advance!\n\nNote: I have already tried with no luck what is listed in [https://github.com/FreshRSS/FreshRSS#apis--native-apps](https://github.com/FreshRSS/FreshRSS#apis--native-apps)", "author_fullname": "t2_7tws7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Android App for FreshRSS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v61ao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679187075.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679186000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I am struggling a bit to find a decent Android app that supports my setup with the latest stable version of FreshRSS&lt;/p&gt;\n\n&lt;p&gt;I am willing to try an app that:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;supports self signed certificates;&lt;/li&gt;\n&lt;li&gt;supports HTTP Auth in front of FreshRSS (not much trust for external visitors).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And, nice to have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;client TLS certificates for authentication.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;Note: I have already tried with no luck what is listed in &lt;a href=\"https://github.com/FreshRSS/FreshRSS#apis--native-apps\"&gt;https://github.com/FreshRSS/FreshRSS#apis--native-apps&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?auto=webp&amp;v=enabled&amp;s=102ebe9e5494ace24445e4a6bf2d360207393f3e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2d849b959e9c86e6238d651dfb8ea2677572939", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bea75d8cd8b358ab58e064204d0c28c574b45a0", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c1cde8eb2bb52b3aa8da63bf34bd216d3ffd5a0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bdc7cde85ea664c63b33a5eb57f2e0d2b750e82", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=270e57fdb1ca8a3518b8194f5e79f87e40e800b4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/a7WNkNr4T4Sng8G09lIxMEihmRfCWF4Btk39PN2QPj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43cc5a2ffc5bfc9b5305df71b372e3da001d4ce8", "width": 1080, "height": 540}], "variants": {}, "id": "FYyYadd0todCHl4PDzBpwuQLyhWiPmSMJozvZOenFrE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v61ao", "is_robot_indexable": true, "report_reasons": null, "author": "RenatoPensato", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v61ao/what_android_app_for_freshrss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v61ao/what_android_app_for_freshrss/", "subreddit_subscribers": 235652, "created_utc": 1679186000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello, I have recently started using Hetzner, they bill hourly per usage which means I can delete and create my VPS's at any time, and they provide the service then bill after 1 month of usage, I like this very much! But unfortunately their IP's are not good, they are very bad in terms of abuse etc.\n\nCan you suggest similar services that either provide hourly bills or allow prepaid services? Thanks a lot.", "author_fullname": "t2_9d7dmuu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hourly billed prepaid VPS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v4nfe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679182630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have recently started using Hetzner, they bill hourly per usage which means I can delete and create my VPS&amp;#39;s at any time, and they provide the service then bill after 1 month of usage, I like this very much! But unfortunately their IP&amp;#39;s are not good, they are very bad in terms of abuse etc.&lt;/p&gt;\n\n&lt;p&gt;Can you suggest similar services that either provide hourly bills or allow prepaid services? Thanks a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11v4nfe", "is_robot_indexable": true, "report_reasons": null, "author": "player9486", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11v4nfe/hourly_billed_prepaid_vps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11v4nfe/hourly_billed_prepaid_vps/", "subreddit_subscribers": 235652, "created_utc": 1679182630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey, I am currently building a server for some game servers like Minecraft and ark and some website hosting but anyways I have an i5-12600k and I may be getting my hands on a gtx 1060 from a friend soon for jellyfin transcoding or if I was to shut it down and turn it into a gaming pc temporarily for whatever reason and was wondering what Power Supply I should get? I am looking for something cheap but reliable enough that it won't fail and take a part with it. I was looking at \n\n[https://www.amazon.com/dp/B0058FAYQC?tag=pcpapi-20&amp;linkCode=ogi&amp;th=1&amp;psc=1](https://www.amazon.com/dp/B0058FAYQC?tag=pcpapi-20&amp;linkCode=ogi&amp;th=1&amp;psc=1)\n\nand I was also looking at\n\n[https://www.amazon.com/Thermaltake-Certified-Continuous-cooling-PS-SPD-0500NPCWUS-W/dp/B014W3EM2W?th=1](https://www.amazon.com/Thermaltake-Certified-Continuous-cooling-PS-SPD-0500NPCWUS-W/dp/B014W3EM2W?th=1)\n\nWill either of these work?", "author_fullname": "t2_8g9exf27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power supply for build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "gameserver ", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uzj4g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Game Server", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679171374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am currently building a server for some game servers like Minecraft and ark and some website hosting but anyways I have an i5-12600k and I may be getting my hands on a gtx 1060 from a friend soon for jellyfin transcoding or if I was to shut it down and turn it into a gaming pc temporarily for whatever reason and was wondering what Power Supply I should get? I am looking for something cheap but reliable enough that it won&amp;#39;t fail and take a part with it. I was looking at &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0058FAYQC?tag=pcpapi-20&amp;amp;linkCode=ogi&amp;amp;th=1&amp;amp;psc=1\"&gt;https://www.amazon.com/dp/B0058FAYQC?tag=pcpapi-20&amp;amp;linkCode=ogi&amp;amp;th=1&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and I was also looking at&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/Thermaltake-Certified-Continuous-cooling-PS-SPD-0500NPCWUS-W/dp/B014W3EM2W?th=1\"&gt;https://www.amazon.com/Thermaltake-Certified-Continuous-cooling-PS-SPD-0500NPCWUS-W/dp/B014W3EM2W?th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Will either of these work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e422e4c0-7e67-11e9-abac-0e2180cd4a4e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uzj4g", "is_robot_indexable": true, "report_reasons": null, "author": "JustNathan1_0", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uzj4g/power_supply_for_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/11uzj4g/power_supply_for_build/", "subreddit_subscribers": 235652, "created_utc": 1679171374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "KVM virtual machines on ZFS benchmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uw995", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_1k9muhb9", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "zfs", "selftext": "I'd like to create a dataset to store my VMs. In the end, I'd like to create a dedicated dataset for each VM within the main one so that they can inherit the options and I can perform snapshots though ZFS.\n\nThe pool is stored on 2 mirrored SSDs. I think there's a general consensus for most options and I'm mainly interested in the record size for now.\n\nI created 3 datasets with a record size of `16k`, `32k` and `64k`.\n\n```shell\nsudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=16k \\\n  -o xattr=sa \\\n  sonic/kvm_a\n\nsudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=32k \\\n  -o xattr=sa \\\n  sonic/kvm_b\n\nsudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=64k \\\n  -o xattr=sa \\\n  sonic/kvm_c\n```\n\nThen I created 3 new VMs using Terraform with the libvirt provider and the Ubuntu server cloudinit image to test each dataset.\n\n## Tests\n\n### hdparm\n\n```shell\nsudo hdparm -Tt /dev/vda1\n```\n\n#### A\n\n```\n/dev/vda1:\n Timing cached reads:   16928 MB in  1.99 seconds = 8518.88 MB/sec\n Timing buffered disk reads: 816 MB in  3.00 seconds = 271.66 MB/sec\n\n/dev/vda1:\n Timing cached reads:   16298 MB in  1.99 seconds = 8200.59 MB/sec\n Timing buffered disk reads: 1014 MB in  3.00 seconds = 337.94 MB/sec\n\n/dev/vda1:\n Timing cached reads:   18748 MB in  1.99 seconds = 9441.13 MB/sec\n Timing buffered disk reads: 1034 MB in  3.00 seconds = 344.13 MB/sec\n```\n\n#### B\n\n```\n/dev/vda1:\n Timing cached reads:   17572 MB in  1.99 seconds = 8845.21 MB/sec\n Timing buffered disk reads: 838 MB in  3.00 seconds = 279.10 MB/sec\nansible@ubuntu-b:~$ sudo hdparm -Tt /dev/vda1\n\n/dev/vda1:\n Timing cached reads:   21322 MB in  1.98 seconds = 10746.69 MB/sec\n Timing buffered disk reads: 1040 MB in  3.00 seconds = 346.23 MB/sec\nansible@ubuntu-b:~$ sudo hdparm -Tt /dev/vda1\n\n/dev/vda1:\n Timing cached reads:   19780 MB in  1.99 seconds = 9964.66 MB/sec\n Timing buffered disk reads: 1018 MB in  3.01 seconds = 338.76 MB/sec\n```\n\n#### C\n\n```\n/dev/vda1:\n Timing cached reads:   17806 MB in  1.99 seconds = 8963.92 MB/sec\n Timing buffered disk reads: 864 MB in  3.01 seconds = 287.43 MB/sec\n\n/dev/vda1:\n Timing cached reads:   20252 MB in  1.98 seconds = 10204.37 MB/sec\n Timing buffered disk reads: 1022 MB in  3.00 seconds = 340.41 MB/sec\n\n/dev/vda1:\n Timing cached reads:   20614 MB in  1.98 seconds = 10387.47 MB/sec\n Timing buffered disk reads: 1024 MB in  3.00 seconds = 341.14 MB/sec\n```\n\nNo clear differences. Maybe A is a bit worse?\n\n### dd: single 1G file\n\n```shell\ndd if=/dev/zero of=/tmp/test1.img bs=1G count=1 oflag=dsync\n```\n\n#### A\n\n```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.76707 s, 159 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.60403 s, 192 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 4.85411 s, 221 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 3.81485 s, 281 MB/s\n```\n\n#### B\n\n```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.72376 s, 623 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.42817 s, 752 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.53411 s, 700 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.68207 s, 638 MB/s\n```\n\n#### C\n\n```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.41152 s, 761 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.50187 s, 715 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.38623 s, 775 MB/s\n\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.38044 s, 778 MB/s\n```\n\nIt is clear that larger record sizes improve speeds for large sequential writes.\n\n### dd: 1000 512 kb files\n\n```shell\ndd if=/dev/zero of=/tmp/test2.img bs=512 count=1000 oflag=dsync\n```\n\n#### A\n\n```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.57906 s, 77.8 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.14773 s, 83.3 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.1368 s, 99.7 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.77948 s, 88.6 kB/s\n```\n\n#### B\n\n```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.1042 s, 100 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 4.97205 s, 103 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 7.59181 s, 67.4 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.35665 s, 95.6 kB/s\n```\n\n#### C\n\n```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 7.34869 s, 69.7 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.46702 s, 79.2 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.34012 s, 95.9 kB/s\n\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 4.31918 s, 119 kB/s\n```\n\nIn general, in this test I was expecting higher speeds. Is it ~100kB/s normal?\nAgain A seems to perform worse.\n\n### fio: throughput random r/w\n\n```shell\nsudo fio --filename=/tmp/fio_test --size=1GB --direct=1 --rw=randrw --bs=64k --ioengine=libaio --iodepth=64 --runtime=120 --numjobs=4 --time_based --group_reporting --name=throughput-test-job --eta-newline=1\n```\n\n#### A\n\n```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=9918: Sat Mar 18 20:37:10 2023\n  read: IOPS=1581, BW=98.8MiB/s (104MB/s)(19.8GiB/204946msec)\n    slat (usec): min=4, max=11800k, avg=59.83, stdev=20728.67\n    clat (usec): min=93, max=111581k, avg=27167.66, stdev=1312902.29\n     lat (usec): min=381, max=111581k, avg=27228.31, stdev=1313065.45\n    clat percentiles (usec):\n     |  1.00th=[     947],  5.00th=[    1205], 10.00th=[    1385],\n     | 20.00th=[    1729], 30.00th=[    2147], 40.00th=[    2540],\n     | 50.00th=[    2868], 60.00th=[    3195], 70.00th=[    3556],\n     | 80.00th=[    4293], 90.00th=[   10421], 95.00th=[   19530],\n     | 99.00th=[   45351], 99.50th=[   51643], 99.90th=[   81265],\n     | 99.95th=[11744052], 99.99th=[17112761]\n   bw (  KiB/s): min= 8576, max=2972800, per=100.00%, avg=715391.07, stdev=230058.88, samples=232\n   iops        : min=  134, max=46450, avg=11177.60, stdev=3594.66, samples=232\n  write: IOPS=1582, BW=98.9MiB/s (104MB/s)(19.8GiB/204946msec); 0 zone resets\n    slat (usec): min=5, max=129505, avg=28.35, stdev=385.96\n    clat (usec): min=450, max=111780k, avg=134549.88, stdev=3118589.26\n     lat (usec): min=695, max=111780k, avg=134579.08, stdev=3118589.82\n    clat percentiles (usec):\n     |  1.00th=[    1516],  5.00th=[    2057], 10.00th=[    2409],\n     | 20.00th=[    2868], 30.00th=[    3228], 40.00th=[    3589],\n     | 50.00th=[    4146], 60.00th=[    4817], 70.00th=[    5866],\n     | 80.00th=[    9110], 90.00th=[   43254], 95.00th=[   93848],\n     | 99.00th=[  233833], 99.50th=[  295699], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=10368, max=2970880, per=100.00%, avg=715405.76, stdev=229669.29, samples=232\n   iops        : min=  162, max=46420, avg=11177.83, stdev=3588.57, samples=232\n  lat (usec)   : 100=0.01%, 250=0.01%, 500=0.01%, 750=0.08%, 1000=0.68%\n  lat (msec)   : 2=14.87%, 4=47.01%, 10=22.69%, 20=5.15%, 50=4.65%\n  lat (msec)   : 100=2.49%, 250=1.91%, 500=0.28%, 750=0.01%, 1000=0.01%\n  lat (msec)   : 2000=0.01%, &gt;=2000=0.16%\n  cpu          : usr=0.68%, sys=1.68%, ctx=183293, majf=0, minf=89\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%\n     issued rwts: total=324077,324263,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64\n\nRun status group 0 (all jobs):\n   READ: bw=98.8MiB/s (104MB/s), 98.8MiB/s-98.8MiB/s (104MB/s-104MB/s), io=19.8GiB (21.2GB), run=204946-204946msec\n  WRITE: bw=98.9MiB/s (104MB/s), 98.9MiB/s-98.9MiB/s (104MB/s-104MB/s), io=19.8GiB (21.2GB), run=204946-204946msec\n\nDisk stats (read/write):\n  vda: ios=321666/318318, merge=2374/5773, ticks=4432050/18674905, in_queue=23191475, util=45.63%\n```\n\n#### B\n\n```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=8989: Sat Mar 18 20:42:32 2023\n  read: IOPS=1404, BW=87.8MiB/s (92.0MB/s)(12.0GiB/139864msec)\n    slat (usec): min=5, max=42395, avg=30.30, stdev=169.52\n    clat (usec): min=363, max=28007k, avg=37321.57, stdev=596311.37\n     lat (usec): min=400, max=28007k, avg=37352.97, stdev=596311.88\n    clat percentiles (usec):\n     |  1.00th=[     947],  5.00th=[    1303], 10.00th=[    1565],\n     | 20.00th=[    1975], 30.00th=[    2474], 40.00th=[    2933],\n     | 50.00th=[    3294], 60.00th=[    3654], 70.00th=[    4555],\n     | 80.00th=[   10945], 90.00th=[   39060], 95.00th=[   86508],\n     | 99.00th=[  337642], 99.50th=[  522191], 99.90th=[ 4462740],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min= 1024, max=2308992, per=100.00%, avg=158319.05, stdev=90631.26, samples=635\n   iops        : min=   16, max=36078, avg=2473.66, stdev=1416.12, samples=635\n  write: IOPS=1404, BW=87.8MiB/s (92.0MB/s)(12.0GiB/139864msec); 0 zone resets\n    slat (usec): min=7, max=65330, avg=35.09, stdev=177.92\n    clat (usec): min=325, max=30437k, avg=144908.72, stdev=1234566.23\n     lat (usec): min=573, max=30437k, avg=144944.96, stdev=1234567.83\n    clat percentiles (usec):\n     |  1.00th=[    1287],  5.00th=[    1844], 10.00th=[    2376],\n     | 20.00th=[    2966], 30.00th=[    3359], 40.00th=[    3851],\n     | 50.00th=[    5014], 60.00th=[    8356], 70.00th=[   20579],\n     | 80.00th=[   48497], 90.00th=[  149947], 95.00th=[  341836],\n     | 99.00th=[ 2038432], 99.50th=[ 4462740], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=  768, max=2300672, per=100.00%, avg=156201.55, stdev=90220.44, samples=643\n   iops        : min=   12, max=35948, avg=2440.58, stdev=1409.70, samples=643\n  lat (usec)   : 500=0.01%, 750=0.10%, 1000=0.70%\n  lat (msec)   : 2=12.62%, 4=40.65%, 10=16.70%, 20=6.57%, 50=8.62%\n  lat (msec)   : 100=5.19%, 250=4.75%, 500=2.05%, 750=0.65%, 1000=0.29%\n  lat (msec)   : 2000=0.53%, &gt;=2000=0.57%\n  cpu          : usr=0.77%, sys=1.83%, ctx=157624, majf=0, minf=78\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%\n     issued rwts: total=196420,196389,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64\n\nRun status group 0 (all jobs):\n   READ: bw=87.8MiB/s (92.0MB/s), 87.8MiB/s-87.8MiB/s (92.0MB/s-92.0MB/s), io=12.0GiB (12.9GB), run=139864-139864msec\n  WRITE: bw=87.8MiB/s (92.0MB/s), 87.8MiB/s-87.8MiB/s (92.0MB/s-92.0MB/s), io=12.0GiB (12.9GB), run=139864-139864msec\n\nDisk stats (read/write):\n  vda: ios=195137/192462, merge=1239/3762, ticks=6076641/22917416, in_queue=29103444, util=83.60%\n```\n\n#### C\n\n```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=8853: Sat Mar 18 20:46:32 2023\n  read: IOPS=867, BW=54.2MiB/s (56.8MB/s)(6792MiB/125331msec)\n    slat (usec): min=6, max=17499k, avg=189.28, stdev=53084.63\n    clat (usec): min=456, max=32532k, avg=67545.22, stdev=1121308.11\n     lat (usec): min=534, max=32532k, avg=67735.48, stdev=1122554.81\n    clat percentiles (usec):\n     |  1.00th=[    1045],  5.00th=[    1385], 10.00th=[    1663],\n     | 20.00th=[    2089], 30.00th=[    2540], 40.00th=[    2868],\n     | 50.00th=[    3130], 60.00th=[    3425], 70.00th=[    3949],\n     | 80.00th=[    6915], 90.00th=[   28181], 95.00th=[   69731],\n     | 99.00th=[  258999], 99.50th=[  421528], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min= 1536, max=2435421, per=100.00%, avg=207510.67, stdev=116361.03, samples=268\n   iops        : min=   24, max=38052, avg=3242.07, stdev=1818.12, samples=268\n  write: IOPS=871, BW=54.4MiB/s (57.1MB/s)(6824MiB/125331msec); 0 zone resets\n    slat (usec): min=7, max=17500k, avg=192.91, stdev=52962.95\n    clat (usec): min=554, max=34152k, avg=226243.08, stdev=2080405.14\n     lat (usec): min=565, max=34152k, avg=226437.02, stdev=2081062.76\n    clat percentiles (usec):\n     |  1.00th=[    1336],  5.00th=[    1876], 10.00th=[    2278],\n     | 20.00th=[    2737], 30.00th=[    3032], 40.00th=[    3359],\n     | 50.00th=[    3916], 60.00th=[    5080], 70.00th=[    9241],\n     | 80.00th=[   30278], 90.00th=[  122160], 95.00th=[  308282],\n     | 99.00th=[ 2533360], 99.50th=[17112761], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=  768, max=2403318, per=100.00%, avg=205971.15, stdev=116707.71, samples=271\n   iops        : min=   12, max=37551, avg=3218.02, stdev=1823.54, samples=271\n  lat (usec)   : 500=0.01%, 750=0.05%, 1000=0.40%\n  lat (msec)   : 2=11.58%, 4=48.67%, 10=16.00%, 20=5.25%, 50=6.40%\n  lat (msec)   : 100=4.27%, 250=3.94%, 500=1.61%, 750=0.65%, 1000=0.26%\n  lat (msec)   : 2000=0.24%, &gt;=2000=0.68%\n  cpu          : usr=0.45%, sys=1.01%, ctx=72974, majf=0, minf=86\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%\n     issued rwts: total=108674,109178,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64\n\nRun status group 0 (all jobs):\n   READ: bw=54.2MiB/s (56.8MB/s), 54.2MiB/s-54.2MiB/s (56.8MB/s-56.8MB/s), io=6792MiB (7122MB), run=125331-125331msec\n  WRITE: bw=54.4MiB/s (57.1MB/s), 54.4MiB/s-54.4MiB/s (57.1MB/s-57.1MB/s), io=6824MiB (7155MB), run=125331-125331msec\n\nDisk stats (read/write):\n  vda: ios=107803/107248, merge=802/1769, ticks=5959468/21001632, in_queue=27001189, util=83.98%\n```\n\n### fio: IOPS random r/w\n\n```\nsudo fio --filename=/tmp/fio_test --size=1GB --direct=1 --rw=randrw --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1\n```\n\n#### A\n\n```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=9930: Sat Mar 18 20:49:53 2023\n  read: IOPS=2359, BW=9440KiB/s (9666kB/s)(1239MiB/134354msec)\n    slat (usec): min=4, max=21443k, avg=847.29, stdev=104028.40\n    clat (msec): min=3, max=21477, avg=207.25, stdev=1698.00\n     lat (msec): min=3, max=21477, avg=208.10, stdev=1702.13\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    7], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   16], 80.00th=[   26], 90.00th=[   58], 95.00th=[   81],\n     | 99.00th=[ 9060], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  440, max=220423, per=100.00%, avg=57553.18, stdev=16013.25, samples=176\n   iops        : min=  110, max=55105, avg=14388.05, stdev=4003.26, samples=176\n  write: IOPS=2360, BW=9442KiB/s (9669kB/s)(1239MiB/134354msec); 0 zone resets\n    slat (usec): min=4, max=21445k, avg=832.68, stdev=87505.46\n    clat (msec): min=3, max=21486, avg=224.82, stdev=1766.54\n     lat (msec): min=3, max=21486, avg=225.65, stdev=1769.53\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   14],\n     | 70.00th=[   17], 80.00th=[   32], 90.00th=[   71], 95.00th=[  100],\n     | 99.00th=[ 9463], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  256, max=219369, per=100.00%, avg=57556.07, stdev=16000.22, samples=176\n   iops        : min=   64, max=54841, avg=14388.73, stdev=4000.00, samples=176\n  lat (msec)   : 4=0.02%, 10=36.09%, 20=39.51%, 50=11.26%, 100=9.30%\n  lat (msec)   : 250=2.14%, 500=0.02%, 1000=0.02%, 2000=0.02%, &gt;=2000=1.62%\n  cpu          : usr=0.73%, sys=1.66%, ctx=130555, majf=0, minf=75\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.1%\n     issued rwts: total=317065,317141,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256\n\nRun status group 0 (all jobs):\n   READ: bw=9440KiB/s (9666kB/s), 9440KiB/s-9440KiB/s (9666kB/s-9666kB/s), io=1239MiB (1299MB), run=134354-134354msec\n  WRITE: bw=9442KiB/s (9669kB/s), 9442KiB/s-9442KiB/s (9669kB/s-9669kB/s), io=1239MiB (1299MB), run=134354-134354msec\n\nDisk stats (read/write):\n  vda: ios=316955/316796, merge=57/175, ticks=9954181/19975950, in_queue=30044523, util=89.05%\n```\n\n#### B\n\n```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=9000: Sat Mar 18 20:52:19 2023\n  read: IOPS=1034, BW=4136KiB/s (4236kB/s)(520MiB/128643msec)\n    slat (usec): min=4, max=20599k, avg=1394.02, stdev=116730.82\n    clat (msec): min=3, max=20786, avg=451.36, stdev=2240.29\n     lat (msec): min=3, max=20786, avg=452.75, stdev=2243.60\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    8], 10.00th=[    9], 20.00th=[   10],\n     | 30.00th=[   11], 40.00th=[   13], 50.00th=[   17], 60.00th=[   25],\n     | 70.00th=[   40], 80.00th=[   69], 90.00th=[  116], 95.00th=[  456],\n     | 99.00th=[12684], 99.50th=[14295], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  168, max=107376, per=100.00%, avg=23984.04, stdev=7312.78, samples=177\n   iops        : min=   42, max=26844, avg=5995.82, stdev=1828.17, samples=177\n  write: IOPS=1037, BW=4151KiB/s (4250kB/s)(521MiB/128643msec); 0 zone resets\n    slat (usec): min=4, max=20595k, avg=2447.76, stdev=163324.82\n    clat (msec): min=3, max=20805, avg=532.11, stdev=2439.39\n     lat (msec): min=3, max=20805, avg=534.56, stdev=2444.95\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    9], 20.00th=[   10],\n     | 30.00th=[   12], 40.00th=[   14], 50.00th=[   19], 60.00th=[   31],\n     | 70.00th=[   48], 80.00th=[   88], 90.00th=[  148], 95.00th=[  885],\n     | 99.00th=[13355], 99.50th=[14295], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=   88, max=110048, per=100.00%, avg=23770.14, stdev=7351.18, samples=179\n   iops        : min=   22, max=27512, avg=5942.34, stdev=1837.77, samples=179\n  lat (msec)   : 4=0.01%, 10=22.50%, 20=30.51%, 50=19.58%, 100=12.28%\n  lat (msec)   : 250=9.59%, 500=0.30%, 750=0.43%, 1000=0.28%, 2000=0.26%\n  lat (msec)   : &gt;=2000=4.25%\n  cpu          : usr=0.35%, sys=0.84%, ctx=58830, majf=0, minf=74\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.1%\n     issued rwts: total=133032,133492,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256\n\nRun status group 0 (all jobs):\n   READ: bw=4136KiB/s (4236kB/s), 4136KiB/s-4136KiB/s (4236kB/s-4236kB/s), io=520MiB (545MB), run=128643-128643msec\n  WRITE: bw=4151KiB/s (4250kB/s), 4151KiB/s-4151KiB/s (4250kB/s-4250kB/s), io=521MiB (547MB), run=128643-128643msec\n\nDisk stats (read/write):\n  vda: ios=132999/133305, merge=18/113, ticks=7546314/23719324, in_queue=31338886, util=96.89%\n```\n\n#### C\n\n```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=8864: Sat Mar 18 20:56:07 2023\n  read: IOPS=1285, BW=5142KiB/s (5266kB/s)(651MiB/129637msec)\n    slat (usec): min=4, max=19549k, avg=1362.36, stdev=137078.20\n    clat (msec): min=3, max=19571, avg=390.11, stdev=2309.99\n     lat (msec): min=3, max=19571, avg=391.47, stdev=2313.86\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    8], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   15], 80.00th=[   21], 90.00th=[   55], 95.00th=[  107],\n     | 99.00th=[16442], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min= 5600, max=143264, per=100.00%, avg=53162.16, stdev=10136.46, samples=100\n   iops        : min= 1400, max=35816, avg=13290.40, stdev=2534.13, samples=100\n  write: IOPS=1284, BW=5140KiB/s (5263kB/s)(651MiB/129637msec); 0 zone resets\n    slat (usec): min=4, max=19546k, avg=1734.85, stdev=155866.95\n    clat (msec): min=3, max=19571, avg=403.00, stdev=2329.85\n     lat (msec): min=3, max=19571, avg=404.73, stdev=2334.82\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    9], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   16], 80.00th=[   23], 90.00th=[   67], 95.00th=[  136],\n     | 99.00th=[16442], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min= 5960, max=141976, per=100.00%, avg=53151.80, stdev=10034.58, samples=100\n   iops        : min= 1490, max=35494, avg=13287.76, stdev=2508.66, samples=100\n  lat (msec)   : 4=0.01%, 10=35.01%, 20=43.95%, 50=8.90%, 100=6.17%\n  lat (msec)   : 250=1.97%, 500=0.01%, 2000=0.92%, &gt;=2000=3.06%\n  cpu          : usr=0.41%, sys=0.93%, ctx=60272, majf=0, minf=74\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.1%\n     issued rwts: total=166653,166571,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256\n\nRun status group 0 (all jobs):\n   READ: bw=5142KiB/s (5266kB/s), 5142KiB/s-5142KiB/s (5266kB/s-5266kB/s), io=651MiB (683MB), run=129637-129637msec\n  WRITE: bw=5140KiB/s (5263kB/s), 5140KiB/s-5140KiB/s (5263kB/s-5263kB/s), io=651MiB (682MB), run=129637-129637msec\n\nDisk stats (read/write):\n  vda: ios=166538/166362, merge=28/82, ticks=9071574/19231451, in_queue=28325213, util=85.33%\n```\n\nConsidering that the only clear difference was in the large sequential writes I'd go for `recordsize=32k` or `64k`.\n\nPerhaps it would be interesting to also test `recordsize=128k`.\n\nAny thoughts?\n\nEDIT: Added fio tests", "author_fullname": "t2_1k9muhb9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "KVM virtual machines on ZFS benchmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/zfs", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11uw1b6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679169532.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679164323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.zfs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to create a dataset to store my VMs. In the end, I&amp;#39;d like to create a dedicated dataset for each VM within the main one so that they can inherit the options and I can perform snapshots though ZFS.&lt;/p&gt;\n\n&lt;p&gt;The pool is stored on 2 mirrored SSDs. I think there&amp;#39;s a general consensus for most options and I&amp;#39;m mainly interested in the record size for now.&lt;/p&gt;\n\n&lt;p&gt;I created 3 datasets with a record size of &lt;code&gt;16k&lt;/code&gt;, &lt;code&gt;32k&lt;/code&gt; and &lt;code&gt;64k&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;```shell\nsudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=16k \\\n  -o xattr=sa \\\n  sonic/kvm_a&lt;/p&gt;\n\n&lt;p&gt;sudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=32k \\\n  -o xattr=sa \\\n  sonic/kvm_b&lt;/p&gt;\n\n&lt;p&gt;sudo zfs create \\\n  -o atime=off \\\n  -o compression=lz4 \\\n  -o recordsize=64k \\\n  -o xattr=sa \\\n  sonic/kvm_c\n```&lt;/p&gt;\n\n&lt;p&gt;Then I created 3 new VMs using Terraform with the libvirt provider and the Ubuntu server cloudinit image to test each dataset.&lt;/p&gt;\n\n&lt;h2&gt;Tests&lt;/h2&gt;\n\n&lt;h3&gt;hdparm&lt;/h3&gt;\n\n&lt;p&gt;&lt;code&gt;shell\nsudo hdparm -Tt /dev/vda1\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h4&gt;A&lt;/h4&gt;\n\n&lt;p&gt;```\n/dev/vda1:\n Timing cached reads:   16928 MB in  1.99 seconds = 8518.88 MB/sec\n Timing buffered disk reads: 816 MB in  3.00 seconds = 271.66 MB/sec&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   16298 MB in  1.99 seconds = 8200.59 MB/sec\n Timing buffered disk reads: 1014 MB in  3.00 seconds = 337.94 MB/sec&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   18748 MB in  1.99 seconds = 9441.13 MB/sec\n Timing buffered disk reads: 1034 MB in  3.00 seconds = 344.13 MB/sec\n```&lt;/p&gt;\n\n&lt;h4&gt;B&lt;/h4&gt;\n\n&lt;p&gt;```\n/dev/vda1:\n Timing cached reads:   17572 MB in  1.99 seconds = 8845.21 MB/sec\n Timing buffered disk reads: 838 MB in  3.00 seconds = 279.10 MB/sec\nansible@ubuntu-b:~$ sudo hdparm -Tt /dev/vda1&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   21322 MB in  1.98 seconds = 10746.69 MB/sec\n Timing buffered disk reads: 1040 MB in  3.00 seconds = 346.23 MB/sec\nansible@ubuntu-b:~$ sudo hdparm -Tt /dev/vda1&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   19780 MB in  1.99 seconds = 9964.66 MB/sec\n Timing buffered disk reads: 1018 MB in  3.01 seconds = 338.76 MB/sec\n```&lt;/p&gt;\n\n&lt;h4&gt;C&lt;/h4&gt;\n\n&lt;p&gt;```\n/dev/vda1:\n Timing cached reads:   17806 MB in  1.99 seconds = 8963.92 MB/sec\n Timing buffered disk reads: 864 MB in  3.01 seconds = 287.43 MB/sec&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   20252 MB in  1.98 seconds = 10204.37 MB/sec\n Timing buffered disk reads: 1022 MB in  3.00 seconds = 340.41 MB/sec&lt;/p&gt;\n\n&lt;p&gt;/dev/vda1:\n Timing cached reads:   20614 MB in  1.98 seconds = 10387.47 MB/sec\n Timing buffered disk reads: 1024 MB in  3.00 seconds = 341.14 MB/sec\n```&lt;/p&gt;\n\n&lt;p&gt;No clear differences. Maybe A is a bit worse?&lt;/p&gt;\n\n&lt;h3&gt;dd: single 1G file&lt;/h3&gt;\n\n&lt;p&gt;&lt;code&gt;shell\ndd if=/dev/zero of=/tmp/test1.img bs=1G count=1 oflag=dsync\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h4&gt;A&lt;/h4&gt;\n\n&lt;p&gt;```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.76707 s, 159 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.60403 s, 192 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 4.85411 s, 221 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 3.81485 s, 281 MB/s\n```&lt;/p&gt;\n\n&lt;h4&gt;B&lt;/h4&gt;\n\n&lt;p&gt;```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.72376 s, 623 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.42817 s, 752 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.53411 s, 700 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.68207 s, 638 MB/s\n```&lt;/p&gt;\n\n&lt;h4&gt;C&lt;/h4&gt;\n\n&lt;p&gt;```\n1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.41152 s, 761 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.50187 s, 715 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.38623 s, 775 MB/s&lt;/p&gt;\n\n&lt;p&gt;1+0 records in\n1+0 records out\n1073741824 bytes (1.1 GB, 1.0 GiB) copied, 1.38044 s, 778 MB/s\n```&lt;/p&gt;\n\n&lt;p&gt;It is clear that larger record sizes improve speeds for large sequential writes.&lt;/p&gt;\n\n&lt;h3&gt;dd: 1000 512 kb files&lt;/h3&gt;\n\n&lt;p&gt;&lt;code&gt;shell\ndd if=/dev/zero of=/tmp/test2.img bs=512 count=1000 oflag=dsync\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h4&gt;A&lt;/h4&gt;\n\n&lt;p&gt;```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.57906 s, 77.8 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.14773 s, 83.3 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.1368 s, 99.7 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.77948 s, 88.6 kB/s\n```&lt;/p&gt;\n\n&lt;h4&gt;B&lt;/h4&gt;\n\n&lt;p&gt;```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.1042 s, 100 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 4.97205 s, 103 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 7.59181 s, 67.4 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.35665 s, 95.6 kB/s\n```&lt;/p&gt;\n\n&lt;h4&gt;C&lt;/h4&gt;\n\n&lt;p&gt;```\n1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 7.34869 s, 69.7 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 6.46702 s, 79.2 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 5.34012 s, 95.9 kB/s&lt;/p&gt;\n\n&lt;p&gt;1000+0 records in\n1000+0 records out\n512000 bytes (512 kB, 500 KiB) copied, 4.31918 s, 119 kB/s\n```&lt;/p&gt;\n\n&lt;p&gt;In general, in this test I was expecting higher speeds. Is it ~100kB/s normal?\nAgain A seems to perform worse.&lt;/p&gt;\n\n&lt;h3&gt;fio: throughput random r/w&lt;/h3&gt;\n\n&lt;p&gt;&lt;code&gt;shell\nsudo fio --filename=/tmp/fio_test --size=1GB --direct=1 --rw=randrw --bs=64k --ioengine=libaio --iodepth=64 --runtime=120 --numjobs=4 --time_based --group_reporting --name=throughput-test-job --eta-newline=1\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h4&gt;A&lt;/h4&gt;\n\n&lt;p&gt;```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=9918: Sat Mar 18 20:37:10 2023\n  read: IOPS=1581, BW=98.8MiB/s (104MB/s)(19.8GiB/204946msec)\n    slat (usec): min=4, max=11800k, avg=59.83, stdev=20728.67\n    clat (usec): min=93, max=111581k, avg=27167.66, stdev=1312902.29\n     lat (usec): min=381, max=111581k, avg=27228.31, stdev=1313065.45\n    clat percentiles (usec):\n     |  1.00th=[     947],  5.00th=[    1205], 10.00th=[    1385],\n     | 20.00th=[    1729], 30.00th=[    2147], 40.00th=[    2540],\n     | 50.00th=[    2868], 60.00th=[    3195], 70.00th=[    3556],\n     | 80.00th=[    4293], 90.00th=[   10421], 95.00th=[   19530],\n     | 99.00th=[   45351], 99.50th=[   51643], 99.90th=[   81265],\n     | 99.95th=[11744052], 99.99th=[17112761]\n   bw (  KiB/s): min= 8576, max=2972800, per=100.00%, avg=715391.07, stdev=230058.88, samples=232\n   iops        : min=  134, max=46450, avg=11177.60, stdev=3594.66, samples=232\n  write: IOPS=1582, BW=98.9MiB/s (104MB/s)(19.8GiB/204946msec); 0 zone resets\n    slat (usec): min=5, max=129505, avg=28.35, stdev=385.96\n    clat (usec): min=450, max=111780k, avg=134549.88, stdev=3118589.26\n     lat (usec): min=695, max=111780k, avg=134579.08, stdev=3118589.82\n    clat percentiles (usec):\n     |  1.00th=[    1516],  5.00th=[    2057], 10.00th=[    2409],\n     | 20.00th=[    2868], 30.00th=[    3228], 40.00th=[    3589],\n     | 50.00th=[    4146], 60.00th=[    4817], 70.00th=[    5866],\n     | 80.00th=[    9110], 90.00th=[   43254], 95.00th=[   93848],\n     | 99.00th=[  233833], 99.50th=[  295699], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=10368, max=2970880, per=100.00%, avg=715405.76, stdev=229669.29, samples=232\n   iops        : min=  162, max=46420, avg=11177.83, stdev=3588.57, samples=232\n  lat (usec)   : 100=0.01%, 250=0.01%, 500=0.01%, 750=0.08%, 1000=0.68%\n  lat (msec)   : 2=14.87%, 4=47.01%, 10=22.69%, 20=5.15%, 50=4.65%\n  lat (msec)   : 100=2.49%, 250=1.91%, 500=0.28%, 750=0.01%, 1000=0.01%\n  lat (msec)   : 2000=0.01%, &amp;gt;=2000=0.16%\n  cpu          : usr=0.68%, sys=1.68%, ctx=183293, majf=0, minf=89\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &amp;gt;=64=0.0%\n     issued rwts: total=324077,324263,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=98.8MiB/s (104MB/s), 98.8MiB/s-98.8MiB/s (104MB/s-104MB/s), io=19.8GiB (21.2GB), run=204946-204946msec\n  WRITE: bw=98.9MiB/s (104MB/s), 98.9MiB/s-98.9MiB/s (104MB/s-104MB/s), io=19.8GiB (21.2GB), run=204946-204946msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=321666/318318, merge=2374/5773, ticks=4432050/18674905, in_queue=23191475, util=45.63%\n```&lt;/p&gt;\n\n&lt;h4&gt;B&lt;/h4&gt;\n\n&lt;p&gt;```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=8989: Sat Mar 18 20:42:32 2023\n  read: IOPS=1404, BW=87.8MiB/s (92.0MB/s)(12.0GiB/139864msec)\n    slat (usec): min=5, max=42395, avg=30.30, stdev=169.52\n    clat (usec): min=363, max=28007k, avg=37321.57, stdev=596311.37\n     lat (usec): min=400, max=28007k, avg=37352.97, stdev=596311.88\n    clat percentiles (usec):\n     |  1.00th=[     947],  5.00th=[    1303], 10.00th=[    1565],\n     | 20.00th=[    1975], 30.00th=[    2474], 40.00th=[    2933],\n     | 50.00th=[    3294], 60.00th=[    3654], 70.00th=[    4555],\n     | 80.00th=[   10945], 90.00th=[   39060], 95.00th=[   86508],\n     | 99.00th=[  337642], 99.50th=[  522191], 99.90th=[ 4462740],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min= 1024, max=2308992, per=100.00%, avg=158319.05, stdev=90631.26, samples=635\n   iops        : min=   16, max=36078, avg=2473.66, stdev=1416.12, samples=635\n  write: IOPS=1404, BW=87.8MiB/s (92.0MB/s)(12.0GiB/139864msec); 0 zone resets\n    slat (usec): min=7, max=65330, avg=35.09, stdev=177.92\n    clat (usec): min=325, max=30437k, avg=144908.72, stdev=1234566.23\n     lat (usec): min=573, max=30437k, avg=144944.96, stdev=1234567.83\n    clat percentiles (usec):\n     |  1.00th=[    1287],  5.00th=[    1844], 10.00th=[    2376],\n     | 20.00th=[    2966], 30.00th=[    3359], 40.00th=[    3851],\n     | 50.00th=[    5014], 60.00th=[    8356], 70.00th=[   20579],\n     | 80.00th=[   48497], 90.00th=[  149947], 95.00th=[  341836],\n     | 99.00th=[ 2038432], 99.50th=[ 4462740], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=  768, max=2300672, per=100.00%, avg=156201.55, stdev=90220.44, samples=643\n   iops        : min=   12, max=35948, avg=2440.58, stdev=1409.70, samples=643\n  lat (usec)   : 500=0.01%, 750=0.10%, 1000=0.70%\n  lat (msec)   : 2=12.62%, 4=40.65%, 10=16.70%, 20=6.57%, 50=8.62%\n  lat (msec)   : 100=5.19%, 250=4.75%, 500=2.05%, 750=0.65%, 1000=0.29%\n  lat (msec)   : 2000=0.53%, &amp;gt;=2000=0.57%\n  cpu          : usr=0.77%, sys=1.83%, ctx=157624, majf=0, minf=78\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &amp;gt;=64=0.0%\n     issued rwts: total=196420,196389,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=87.8MiB/s (92.0MB/s), 87.8MiB/s-87.8MiB/s (92.0MB/s-92.0MB/s), io=12.0GiB (12.9GB), run=139864-139864msec\n  WRITE: bw=87.8MiB/s (92.0MB/s), 87.8MiB/s-87.8MiB/s (92.0MB/s-92.0MB/s), io=12.0GiB (12.9GB), run=139864-139864msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=195137/192462, merge=1239/3762, ticks=6076641/22917416, in_queue=29103444, util=83.60%\n```&lt;/p&gt;\n\n&lt;h4&gt;C&lt;/h4&gt;\n\n&lt;p&gt;```\nthroughput-test-job: (groupid=0, jobs=4): err= 0: pid=8853: Sat Mar 18 20:46:32 2023\n  read: IOPS=867, BW=54.2MiB/s (56.8MB/s)(6792MiB/125331msec)\n    slat (usec): min=6, max=17499k, avg=189.28, stdev=53084.63\n    clat (usec): min=456, max=32532k, avg=67545.22, stdev=1121308.11\n     lat (usec): min=534, max=32532k, avg=67735.48, stdev=1122554.81\n    clat percentiles (usec):\n     |  1.00th=[    1045],  5.00th=[    1385], 10.00th=[    1663],\n     | 20.00th=[    2089], 30.00th=[    2540], 40.00th=[    2868],\n     | 50.00th=[    3130], 60.00th=[    3425], 70.00th=[    3949],\n     | 80.00th=[    6915], 90.00th=[   28181], 95.00th=[   69731],\n     | 99.00th=[  258999], 99.50th=[  421528], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min= 1536, max=2435421, per=100.00%, avg=207510.67, stdev=116361.03, samples=268\n   iops        : min=   24, max=38052, avg=3242.07, stdev=1818.12, samples=268\n  write: IOPS=871, BW=54.4MiB/s (57.1MB/s)(6824MiB/125331msec); 0 zone resets\n    slat (usec): min=7, max=17500k, avg=192.91, stdev=52962.95\n    clat (usec): min=554, max=34152k, avg=226243.08, stdev=2080405.14\n     lat (usec): min=565, max=34152k, avg=226437.02, stdev=2081062.76\n    clat percentiles (usec):\n     |  1.00th=[    1336],  5.00th=[    1876], 10.00th=[    2278],\n     | 20.00th=[    2737], 30.00th=[    3032], 40.00th=[    3359],\n     | 50.00th=[    3916], 60.00th=[    5080], 70.00th=[    9241],\n     | 80.00th=[   30278], 90.00th=[  122160], 95.00th=[  308282],\n     | 99.00th=[ 2533360], 99.50th=[17112761], 99.90th=[17112761],\n     | 99.95th=[17112761], 99.99th=[17112761]\n   bw (  KiB/s): min=  768, max=2403318, per=100.00%, avg=205971.15, stdev=116707.71, samples=271\n   iops        : min=   12, max=37551, avg=3218.02, stdev=1823.54, samples=271\n  lat (usec)   : 500=0.01%, 750=0.05%, 1000=0.40%\n  lat (msec)   : 2=11.58%, 4=48.67%, 10=16.00%, 20=5.25%, 50=6.40%\n  lat (msec)   : 100=4.27%, 250=3.94%, 500=1.61%, 750=0.65%, 1000=0.26%\n  lat (msec)   : 2000=0.24%, &amp;gt;=2000=0.68%\n  cpu          : usr=0.45%, sys=1.01%, ctx=72974, majf=0, minf=86\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &amp;gt;=64=0.0%\n     issued rwts: total=108674,109178,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=64&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=54.2MiB/s (56.8MB/s), 54.2MiB/s-54.2MiB/s (56.8MB/s-56.8MB/s), io=6792MiB (7122MB), run=125331-125331msec\n  WRITE: bw=54.4MiB/s (57.1MB/s), 54.4MiB/s-54.4MiB/s (57.1MB/s-57.1MB/s), io=6824MiB (7155MB), run=125331-125331msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=107803/107248, merge=802/1769, ticks=5959468/21001632, in_queue=27001189, util=83.98%\n```&lt;/p&gt;\n\n&lt;h3&gt;fio: IOPS random r/w&lt;/h3&gt;\n\n&lt;p&gt;&lt;code&gt;\nsudo fio --filename=/tmp/fio_test --size=1GB --direct=1 --rw=randrw --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;h4&gt;A&lt;/h4&gt;\n\n&lt;p&gt;```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=9930: Sat Mar 18 20:49:53 2023\n  read: IOPS=2359, BW=9440KiB/s (9666kB/s)(1239MiB/134354msec)\n    slat (usec): min=4, max=21443k, avg=847.29, stdev=104028.40\n    clat (msec): min=3, max=21477, avg=207.25, stdev=1698.00\n     lat (msec): min=3, max=21477, avg=208.10, stdev=1702.13\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    7], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   16], 80.00th=[   26], 90.00th=[   58], 95.00th=[   81],\n     | 99.00th=[ 9060], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  440, max=220423, per=100.00%, avg=57553.18, stdev=16013.25, samples=176\n   iops        : min=  110, max=55105, avg=14388.05, stdev=4003.26, samples=176\n  write: IOPS=2360, BW=9442KiB/s (9669kB/s)(1239MiB/134354msec); 0 zone resets\n    slat (usec): min=4, max=21445k, avg=832.68, stdev=87505.46\n    clat (msec): min=3, max=21486, avg=224.82, stdev=1766.54\n     lat (msec): min=3, max=21486, avg=225.65, stdev=1769.53\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   14],\n     | 70.00th=[   17], 80.00th=[   32], 90.00th=[   71], 95.00th=[  100],\n     | 99.00th=[ 9463], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  256, max=219369, per=100.00%, avg=57556.07, stdev=16000.22, samples=176\n   iops        : min=   64, max=54841, avg=14388.73, stdev=4000.00, samples=176\n  lat (msec)   : 4=0.02%, 10=36.09%, 20=39.51%, 50=11.26%, 100=9.30%\n  lat (msec)   : 250=2.14%, 500=0.02%, 1000=0.02%, 2000=0.02%, &amp;gt;=2000=1.62%\n  cpu          : usr=0.73%, sys=1.66%, ctx=130555, majf=0, minf=75\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.1%\n     issued rwts: total=317065,317141,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=9440KiB/s (9666kB/s), 9440KiB/s-9440KiB/s (9666kB/s-9666kB/s), io=1239MiB (1299MB), run=134354-134354msec\n  WRITE: bw=9442KiB/s (9669kB/s), 9442KiB/s-9442KiB/s (9669kB/s-9669kB/s), io=1239MiB (1299MB), run=134354-134354msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=316955/316796, merge=57/175, ticks=9954181/19975950, in_queue=30044523, util=89.05%\n```&lt;/p&gt;\n\n&lt;h4&gt;B&lt;/h4&gt;\n\n&lt;p&gt;```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=9000: Sat Mar 18 20:52:19 2023\n  read: IOPS=1034, BW=4136KiB/s (4236kB/s)(520MiB/128643msec)\n    slat (usec): min=4, max=20599k, avg=1394.02, stdev=116730.82\n    clat (msec): min=3, max=20786, avg=451.36, stdev=2240.29\n     lat (msec): min=3, max=20786, avg=452.75, stdev=2243.60\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    8], 10.00th=[    9], 20.00th=[   10],\n     | 30.00th=[   11], 40.00th=[   13], 50.00th=[   17], 60.00th=[   25],\n     | 70.00th=[   40], 80.00th=[   69], 90.00th=[  116], 95.00th=[  456],\n     | 99.00th=[12684], 99.50th=[14295], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=  168, max=107376, per=100.00%, avg=23984.04, stdev=7312.78, samples=177\n   iops        : min=   42, max=26844, avg=5995.82, stdev=1828.17, samples=177\n  write: IOPS=1037, BW=4151KiB/s (4250kB/s)(521MiB/128643msec); 0 zone resets\n    slat (usec): min=4, max=20595k, avg=2447.76, stdev=163324.82\n    clat (msec): min=3, max=20805, avg=532.11, stdev=2439.39\n     lat (msec): min=3, max=20805, avg=534.56, stdev=2444.95\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    9], 20.00th=[   10],\n     | 30.00th=[   12], 40.00th=[   14], 50.00th=[   19], 60.00th=[   31],\n     | 70.00th=[   48], 80.00th=[   88], 90.00th=[  148], 95.00th=[  885],\n     | 99.00th=[13355], 99.50th=[14295], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min=   88, max=110048, per=100.00%, avg=23770.14, stdev=7351.18, samples=179\n   iops        : min=   22, max=27512, avg=5942.34, stdev=1837.77, samples=179\n  lat (msec)   : 4=0.01%, 10=22.50%, 20=30.51%, 50=19.58%, 100=12.28%\n  lat (msec)   : 250=9.59%, 500=0.30%, 750=0.43%, 1000=0.28%, 2000=0.26%\n  lat (msec)   : &amp;gt;=2000=4.25%\n  cpu          : usr=0.35%, sys=0.84%, ctx=58830, majf=0, minf=74\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.1%\n     issued rwts: total=133032,133492,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=4136KiB/s (4236kB/s), 4136KiB/s-4136KiB/s (4236kB/s-4236kB/s), io=520MiB (545MB), run=128643-128643msec\n  WRITE: bw=4151KiB/s (4250kB/s), 4151KiB/s-4151KiB/s (4250kB/s-4250kB/s), io=521MiB (547MB), run=128643-128643msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=132999/133305, merge=18/113, ticks=7546314/23719324, in_queue=31338886, util=96.89%\n```&lt;/p&gt;\n\n&lt;h4&gt;C&lt;/h4&gt;\n\n&lt;p&gt;```\niops-test-job: (groupid=0, jobs=4): err= 0: pid=8864: Sat Mar 18 20:56:07 2023\n  read: IOPS=1285, BW=5142KiB/s (5266kB/s)(651MiB/129637msec)\n    slat (usec): min=4, max=19549k, avg=1362.36, stdev=137078.20\n    clat (msec): min=3, max=19571, avg=390.11, stdev=2309.99\n     lat (msec): min=3, max=19571, avg=391.47, stdev=2313.86\n    clat percentiles (msec):\n     |  1.00th=[    6],  5.00th=[    8], 10.00th=[    8], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   15], 80.00th=[   21], 90.00th=[   55], 95.00th=[  107],\n     | 99.00th=[16442], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min= 5600, max=143264, per=100.00%, avg=53162.16, stdev=10136.46, samples=100\n   iops        : min= 1400, max=35816, avg=13290.40, stdev=2534.13, samples=100\n  write: IOPS=1284, BW=5140KiB/s (5263kB/s)(651MiB/129637msec); 0 zone resets\n    slat (usec): min=4, max=19546k, avg=1734.85, stdev=155866.95\n    clat (msec): min=3, max=19571, avg=403.00, stdev=2329.85\n     lat (msec): min=3, max=19571, avg=404.73, stdev=2334.82\n    clat percentiles (msec):\n     |  1.00th=[    7],  5.00th=[    8], 10.00th=[    9], 20.00th=[    9],\n     | 30.00th=[   10], 40.00th=[   11], 50.00th=[   12], 60.00th=[   13],\n     | 70.00th=[   16], 80.00th=[   23], 90.00th=[   67], 95.00th=[  136],\n     | 99.00th=[16442], 99.50th=[17113], 99.90th=[17113], 99.95th=[17113],\n     | 99.99th=[17113]\n   bw (  KiB/s): min= 5960, max=141976, per=100.00%, avg=53151.80, stdev=10034.58, samples=100\n   iops        : min= 1490, max=35494, avg=13287.76, stdev=2508.66, samples=100\n  lat (msec)   : 4=0.01%, 10=35.01%, 20=43.95%, 50=8.90%, 100=6.17%\n  lat (msec)   : 250=1.97%, 500=0.01%, 2000=0.92%, &amp;gt;=2000=3.06%\n  cpu          : usr=0.41%, sys=0.93%, ctx=60272, majf=0, minf=74\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=99.9%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.1%\n     issued rwts: total=166653,166571,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256&lt;/p&gt;\n\n&lt;p&gt;Run status group 0 (all jobs):\n   READ: bw=5142KiB/s (5266kB/s), 5142KiB/s-5142KiB/s (5266kB/s-5266kB/s), io=651MiB (683MB), run=129637-129637msec\n  WRITE: bw=5140KiB/s (5263kB/s), 5140KiB/s-5140KiB/s (5263kB/s-5263kB/s), io=651MiB (682MB), run=129637-129637msec&lt;/p&gt;\n\n&lt;p&gt;Disk stats (read/write):\n  vda: ios=166538/166362, merge=28/82, ticks=9071574/19231451, in_queue=28325213, util=85.33%\n```&lt;/p&gt;\n\n&lt;p&gt;Considering that the only clear difference was in the large sequential writes I&amp;#39;d go for &lt;code&gt;recordsize=32k&lt;/code&gt; or &lt;code&gt;64k&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Perhaps it would be interesting to also test &lt;code&gt;recordsize=128k&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n\n&lt;p&gt;EDIT: Added fio tests&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ruui", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uw1b6", "is_robot_indexable": true, "report_reasons": null, "author": "TheSuperHelios", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/zfs/comments/11uw1b6/kvm_virtual_machines_on_zfs_benchmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/zfs/comments/11uw1b6/kvm_virtual_machines_on_zfs_benchmarks/", "subreddit_subscribers": 26466, "created_utc": 1679164323.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1679164823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.zfs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/zfs/comments/11uw1b6/kvm_virtual_machines_on_zfs_benchmarks/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11uw995", "is_robot_indexable": true, "report_reasons": null, "author": "TheSuperHelios", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11uw1b6", "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/11uw995/kvm_virtual_machines_on_zfs_benchmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/zfs/comments/11uw1b6/kvm_virtual_machines_on_zfs_benchmarks/", "subreddit_subscribers": 235652, "created_utc": 1679164823.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}