{"kind": "Listing", "data": {"after": "t3_11lfwwb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area\n\nI make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.\n\nMy analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019\n\nI\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? \n\nThis might be too high level so happy to provide more detail.\n\nEdit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay", "author_fullname": "t2_ekymh22j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overpaid and don\u2019t see the point", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l5mg2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 415, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 415, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678212638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR - title is Data scientist. I feel like an overpaid analyst with 5 yoe. I make 220k in the Bay Area&lt;/p&gt;\n\n&lt;p&gt;I make reports and charts and do some basic data engineering to make it happen. Most of my academic rigor has faded over the years.&lt;/p&gt;\n\n&lt;p&gt;My analyses and findings go into reports that are supposed to inform the business - I don\u2019t think they help much. \nA lot of \u2018not enough evidence to conclude \u2026\u2019 or \u2018there appears to be a correlation between \u2026\u2019&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having an existential crisis. Is data science actually useful? Am I doing it wrong? &lt;/p&gt;\n\n&lt;p&gt;This might be too high level so happy to provide more detail.&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m sorry if this is in poor taste or comes off as a brag. I am grateful for the money. Was looking for other senior folks to weigh in on how they\u2019ve seen DS deliver value worth the pay&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5mg2", "is_robot_indexable": true, "report_reasons": null, "author": "leaver_believer", "discussion_type": null, "num_comments": 215, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5mg2/overpaid_and_dont_see_the_point/", "subreddit_subscribers": 854929, "created_utc": 1678210462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_479zgx6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rich Jupyter Notebook Diffs on GitHub... Finally.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_11l2ojh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 365, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 365, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/PvkJonCBrm55xEa1hSeNqwyOUAcm0SG1VzQFV17rHVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678203789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kvhebtuu7cma1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kvhebtuu7cma1.png?auto=webp&amp;v=enabled&amp;s=6c9567daa41908136cc898b0d1f1ee53c7727251", "width": 1222, "height": 805}, "resolutions": [{"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb23c929b73c2c109150b9b96faa2adbf2c28153", "width": 108, "height": 71}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=557a9586b2872506a27041bc5e5fd42c49d6fa5b", "width": 216, "height": 142}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7697cd5d5cc43d61881c88fe934174912082669", "width": 320, "height": 210}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df8b0f73a34fd987a2543626f8eee0cea16b768b", "width": 640, "height": 421}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93f05243bd0498494b82534038f49a42e4ba37ad", "width": 960, "height": 632}, {"url": "https://preview.redd.it/kvhebtuu7cma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed60a93aef191fde96aaa484504a2e11182b3384", "width": 1080, "height": 711}], "variants": {}, "id": "CS5aUJvi1pTuFwS4VGyg2ZqyibSL9XYgRap8O5u4-nY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l2ojh", "is_robot_indexable": true, "report_reasons": null, "author": "RandomForests92", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l2ojh/rich_jupyter_notebook_diffs_on_github_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kvhebtuu7cma1.png", "subreddit_subscribers": 854929, "created_utc": 1678203789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. \n\n&amp;#x200B;\n\nIs this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should working in DS be this boring?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11kzfdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678196070.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678195889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for two years as a data scientist for a pretty big and recognised company. I feel like my job has become so dull recently. In the beginning when everything was new it was interesting. I developed a data pipeline from scratch, performed data cleaning and feature engineering, and developed a model. Now that all of that is done. I find myself  just repeating boring tasks endlessly with no end in sight. My day to day mostly just involves chasing data engineers for more up to date data, accomodating this into my pipeline and retraining or tweaking the same model. There is no prospect of changing to new project or developing new types of models for different types of tasks. Just endless tweaking and maintenance. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this what working as a data scientist is? Or have I just been unlucky to find myself in a very unmotivating and boring role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11kzfdo", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11kzfdo/should_working_in_ds_be_this_boring/", "subreddit_subscribers": 854929, "created_utc": 1678195889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!\n\nI dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.\n\nI know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.\n\nI think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)", "author_fullname": "t2_4lqbue6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AMA: Broke into DS without masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ks4c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678172417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im about to finish my bachelor, and I recently accepted a full time permanent offer as a data scientist at one of the three large telecommunications companies (canada)!!&lt;/p&gt;\n\n&lt;p&gt;I dont have a DS internship, and I didnt have any referral either. I dont have a great gpa, nor any paper published. But I did get as many experiences as possible from my school for the past two years.&lt;/p&gt;\n\n&lt;p&gt;I know a lot of people here dont want to spend another 2 years doing masters just to get a job, if there is a way to get one without it. That has been my goal for a long time, and it worked out. Its not too common, and it wasnt easy for me either, but I saw it can happen without an \u201coutstanding\u201d resume.&lt;/p&gt;\n\n&lt;p&gt;I think those of you who are in your undergrad would find my story most relatable, but anyone can ask me anything :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ks4c2", "is_robot_indexable": true, "report_reasons": null, "author": "beecheee", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ks4c2/ama_broke_into_ds_without_masters/", "subreddit_subscribers": 854929, "created_utc": 1678172417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.\n\nI started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.\n\nTo fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it's saved with encryption). Then, all you have to do is write what you need in plain English, Ex. \"Users who have been online over 5 days this week\", and it writes the SQL query for you.\n\nI showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.\n\nWhat do you think? Would love to get your feedback. It's 100% free, you couldn't pay me even if you wanted to.", "author_fullname": "t2_11bl5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My AI tool to writes SQL queries for me now, so I don't have to. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l5jqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678210291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.&lt;/p&gt;\n\n&lt;p&gt;I started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.&lt;/p&gt;\n\n&lt;p&gt;To fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it&amp;#39;s saved with encryption). Then, all you have to do is write what you need in plain English, Ex. &amp;quot;Users who have been online over 5 days this week&amp;quot;, and it writes the SQL query for you.&lt;/p&gt;\n\n&lt;p&gt;I showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Would love to get your feedback. It&amp;#39;s 100% free, you couldn&amp;#39;t pay me even if you wanted to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5jqm", "is_robot_indexable": true, "report_reasons": null, "author": "slingshoota", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/", "subreddit_subscribers": 854929, "created_utc": 1678210291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_d45r1", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Using an AI plugin I made to guess gender from email, do sentiment analysis, and perform a simple segmentation analysis (link in comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6mx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 40, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gl7qbixaycma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gl7qbixaycma1/DASH_96.mp4", "dash_url": "https://v.redd.it/gl7qbixaycma1/DASHPlaylist.mpd?a=1680849811%2CZGQwMzJmZmY2M2Q3ZjYzMjUxYTBiNzM4YzZiZDk2MWVmYzczNTU3ZTg0NzFkZGNjOWFmMmE3N2FjMjdiMWRmYg%3D%3D&amp;v=1&amp;f=sd", "duration": 59, "hls_url": "https://v.redd.it/gl7qbixaycma1/HLSPlaylist.m3u8?a=1680849811%2CMjg1NjRmOWVjZGUxZGRmNTc0NDAwOGI5YzgzNmNmZmZkZGRjMTA2NGQ2NzFlZGEwZTNmYWNjNTg0ZmRmMWIxNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/n-kPPvWPj4MR9Q4LnV3nLDI0Ekf3ozNAqsj0vNaHp2M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678212732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/gl7qbixaycma1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=208b7756ddbcf6ddd289954408b6bfa17399b8fc", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c03433464c2d0fd616fd531fbce1a4d95b253574", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=48b0fe7a9b1f2a8a7ce37de03856ad356bb50350", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c555c144f46f0f4afdab95de55bfac9b6f72a444", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=23ed97680da41e8c2f2f9bb2b8d2d914bd68e25e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8681d0bf1822ad9e100b1cb8ceb39f986a82566b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ult2jtKYK_7MkT7cauw7HkD1nQEleYF9TTNLc36uYug.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d1307ec178800150011d9636b3929d9ef2cdf9ab", "width": 1080, "height": 607}], "variants": {}, "id": "uNAtrEjago7y_yM6VbHNDvEaHE2BvZVv0bvUxOr6VVg"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6mx3", "is_robot_indexable": true, "report_reasons": null, "author": "rtwalz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6mx3/using_an_ai_plugin_i_made_to_guess_gender_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/gl7qbixaycma1", "subreddit_subscribers": 854929, "created_utc": 1678212732.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/gl7qbixaycma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/gl7qbixaycma1/DASH_96.mp4", "dash_url": "https://v.redd.it/gl7qbixaycma1/DASHPlaylist.mpd?a=1680849811%2CZGQwMzJmZmY2M2Q3ZjYzMjUxYTBiNzM4YzZiZDk2MWVmYzczNTU3ZTg0NzFkZGNjOWFmMmE3N2FjMjdiMWRmYg%3D%3D&amp;v=1&amp;f=sd", "duration": 59, "hls_url": "https://v.redd.it/gl7qbixaycma1/HLSPlaylist.m3u8?a=1680849811%2CMjg1NjRmOWVjZGUxZGRmNTc0NDAwOGI5YzgzNmNmZmZkZGRjMTA2NGQ2NzFlZGEwZTNmYWNjNTg0ZmRmMWIxNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I don't have any skin in the game, just curious. I'm actually a DE, currently migrating company SAS code into DataBricks.\n\nFrom what I've read, SAS as a product doesn't offer anything truly unique, but in some areas like government, people resist change like the plague. \n\nI've never seen any SAS vs. R debates here. Any takers??", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use SAS anymore? Why is it still around?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lhieh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678237294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have any skin in the game, just curious. I&amp;#39;m actually a DE, currently migrating company SAS code into DataBricks.&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve read, SAS as a product doesn&amp;#39;t offer anything truly unique, but in some areas like government, people resist change like the plague. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never seen any SAS vs. R debates here. Any takers??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lhieh", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lhieh/does_anyone_use_sas_anymore_why_is_it_still_around/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lhieh/does_anyone_use_sas_anymore_why_is_it_still_around/", "subreddit_subscribers": 854929, "created_utc": 1678237294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I've been told I won't be kept on past that. I have 6 years experience in the field, so I'm quite surprised. I have had to upskill a lot, but the systems were messy and I've struggled to know how to approach finding data since whenever I've asked I've been drawn into a call with my supervisor who has then picked apart whatever I've been working on which isn't usually finished instead of just directing me to the correct database so I can figure it out. I'm a bit lost since I've been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn't have enough attention to detail (but I would argue most of the tasks I submit haven't been finished since they end up getting reviewed the moment I ask a question). \n\nAny advice on next steps? I've never failed probation before, so I'm a bit lost.", "author_fullname": "t2_9ku7bdlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been told I won't be kept on past probation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ky71w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678192527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a fairly large company in the new year with an initial 3 month probation which ends in 2 weeks and I&amp;#39;ve been told I won&amp;#39;t be kept on past that. I have 6 years experience in the field, so I&amp;#39;m quite surprised. I have had to upskill a lot, but the systems were messy and I&amp;#39;ve struggled to know how to approach finding data since whenever I&amp;#39;ve asked I&amp;#39;ve been drawn into a call with my supervisor who has then picked apart whatever I&amp;#39;ve been working on which isn&amp;#39;t usually finished instead of just directing me to the correct database so I can figure it out. I&amp;#39;m a bit lost since I&amp;#39;ve been putting in lots of overtime to keep this job which I enjoy for the most part, but I was told I didn&amp;#39;t have enough attention to detail (but I would argue most of the tasks I submit haven&amp;#39;t been finished since they end up getting reviewed the moment I ask a question). &lt;/p&gt;\n\n&lt;p&gt;Any advice on next steps? I&amp;#39;ve never failed probation before, so I&amp;#39;m a bit lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ky71w", "is_robot_indexable": true, "report_reasons": null, "author": "LazyTowels", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ky71w/ive_been_told_i_wont_be_kept_on_past_probation/", "subreddit_subscribers": 854929, "created_utc": 1678192527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_36ft48fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Runtime completion for complied data science libraries like NumPy or PyTorch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o0oda9i8gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=8ef57fdec22a638cd31c7e8c0b52267ee13e8048"}, {"y": 77, "x": 216, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f28dd96be1ef957c2ce03353670d2e787df5e0cd"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=c5271df2a69516467f17c606c8189ece511fc55b"}, {"y": 230, "x": 640, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=b5af76536900f11ce6e47935ffe48df6ac530f92"}, {"y": 346, "x": 960, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6ca36cf6e5215add16f858f86ce7fbb155e79256"}, {"y": 389, "x": 1080, "u": "https://preview.redd.it/o0oda9i8gama1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6f463d7949ce6a9d51ba375b1b38f1345053a114"}], "s": {"y": 464, "gif": "https://i.redd.it/o0oda9i8gama1.gif", "mp4": "https://preview.redd.it/o0oda9i8gama1.gif?format=mp4&amp;v=enabled&amp;s=36d5d4b24086cde32f50838f35cc72ab556c0316", "x": 1286}, "id": "o0oda9i8gama1"}, "lnjuf7f9gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d31f1010917b9b11e9aad2869d1d7e1628147600"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=6375bb64784d52479828bf317a7cb224397bdc1b"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=310ea65799c162162401f50ff7fdc5b9f51ac2e9"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/lnjuf7f9gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=badbe2de57d5e6af756a27fdfbaca015e1d2e1e8"}], "s": {"y": 464, "gif": "https://i.redd.it/lnjuf7f9gama1.gif", "mp4": "https://preview.redd.it/lnjuf7f9gama1.gif?format=mp4&amp;v=enabled&amp;s=0d640473048426611a3d361a183a2adebb690972", "x": 643}, "id": "lnjuf7f9gama1"}, "xbqpr029gama1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3cee312028b9a8a19f6fd001e3534091441878dd"}, {"y": 155, "x": 216, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=d62de689ec524f319a18b7f7bd3cee61e80370cb"}, {"y": 230, "x": 320, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=2534628b83e1d50b656191828cf03ee87f255928"}, {"y": 461, "x": 640, "u": "https://preview.redd.it/xbqpr029gama1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9dbcedb45167fda56e88d929a61599bb71e3b838"}], "s": {"y": 464, "gif": "https://i.redd.it/xbqpr029gama1.gif", "mp4": "https://preview.redd.it/xbqpr029gama1.gif?format=mp4&amp;v=enabled&amp;s=6ea8eaabc78a9d8ca17c0dbff282d71e3ed54e26", "x": 643}, "id": "xbqpr029gama1"}}, "name": "t3_11kuyu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Left hand side - during debugging with reloadium, right hand side, without debugging", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "o0oda9i8gama1", "id": 248228601}, {"caption": "Runtime completion with reloadium", "outbound_url": "https://github.com/reloadware/reloadium", "media_id": "xbqpr029gama1", "id": 248228602}, {"media_id": "lnjuf7f9gama1", "id": 248228603}]}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4Rwp5v78I_1uAbgPoQvdJI5LnpISGrOAxpfi4NNBVWI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678182816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/11kuyu6", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "11kuyu6", "is_robot_indexable": true, "report_reasons": null, "author": "kwazar90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11kuyu6/runtime_completion_for_complied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/reloadware/reloadium", "subreddit_subscribers": 854929, "created_utc": 1678182816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI'm working on [a time series database for blob data,](https://www.reduct.store) which I see as a suitable replacement for object storage if you need to access blob data over time intervals and remove old data when you run out of disk space.\n\nTo attract users and bring some value, I started collecting public datasets and hosting them with the database: [https://github.com/reductstore/datasets](https://github.com/reductstore/datasets). You can get the datasets using client SDKs or a CLI tool.\n\nPros:\n\n\\- The database is fast and free, you can mirror datasets on your own instance and use them locally.\n\n\\- You can download partial datasets \n\n\\- You can use databases directly from Python, C++, or Node.js\n\n\\- You can use annotations as a dictionary, no need to parse them manually. \n\nI hope someone finds this useful. I also appreciate any feedback (including criticism).", "author_fullname": "t2_mtjenemk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ReductStore - time series database for blob data with a focus on AI needs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11leui3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678230840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on &lt;a href=\"https://www.reduct.store\"&gt;a time series database for blob data,&lt;/a&gt; which I see as a suitable replacement for object storage if you need to access blob data over time intervals and remove old data when you run out of disk space.&lt;/p&gt;\n\n&lt;p&gt;To attract users and bring some value, I started collecting public datasets and hosting them with the database: &lt;a href=\"https://github.com/reductstore/datasets\"&gt;https://github.com/reductstore/datasets&lt;/a&gt;. You can get the datasets using client SDKs or a CLI tool.&lt;/p&gt;\n\n&lt;p&gt;Pros:&lt;/p&gt;\n\n&lt;p&gt;- The database is fast and free, you can mirror datasets on your own instance and use them locally.&lt;/p&gt;\n\n&lt;p&gt;- You can download partial datasets &lt;/p&gt;\n\n&lt;p&gt;- You can use databases directly from Python, C++, or Node.js&lt;/p&gt;\n\n&lt;p&gt;- You can use annotations as a dictionary, no need to parse them manually. &lt;/p&gt;\n\n&lt;p&gt;I hope someone finds this useful. I also appreciate any feedback (including criticism).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lY0nxswGrYH-BjPA7rZzU98sZQzog76TtuCBfEHboBo.jpg?auto=webp&amp;v=enabled&amp;s=da0f8ed34f3a7e08e44df730957c0873bed38e9a", "width": 800, "height": 391}, "resolutions": [{"url": "https://external-preview.redd.it/lY0nxswGrYH-BjPA7rZzU98sZQzog76TtuCBfEHboBo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbe88d94a6d28606572e7f2266ebd88c4c9696f3", "width": 108, "height": 52}, {"url": "https://external-preview.redd.it/lY0nxswGrYH-BjPA7rZzU98sZQzog76TtuCBfEHboBo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47251a920836162df6a2058a6d94b16ad87c3d87", "width": 216, "height": 105}, {"url": "https://external-preview.redd.it/lY0nxswGrYH-BjPA7rZzU98sZQzog76TtuCBfEHboBo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ea372f69ea01b3858e3e27b6653ad45353c1e45", "width": 320, "height": 156}, {"url": "https://external-preview.redd.it/lY0nxswGrYH-BjPA7rZzU98sZQzog76TtuCBfEHboBo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9aad96e3e24eb30e35a57791d803da5ee490710", "width": 640, "height": 312}], "variants": {}, "id": "CO5fYz5mcIgvc8Lt7YzFlK7gBM35xoQrxv3htwqSodI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11leui3", "is_robot_indexable": true, "report_reasons": null, "author": "alexey_timin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11leui3/reductstore_time_series_database_for_blob_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11leui3/reductstore_time_series_database_for_blob_data/", "subreddit_subscribers": 854929, "created_utc": 1678230840.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was asked by leadership to create a massive pdf that contains bunch of line graphs with week vs week data with all possible way that we can break out. Example: sales by country, sales by state, sales by market and so on.  The goal is the catch if something isn\u2019t right and\n99% of reports in the business are line graphs.\n\nIn my mind that is waste of time because no one will ever look at 500 pages PDF so I was thinking of suggesting algorithm that would highlight every week the biggest problem or drop based on historical performance. \n\n\nI was hoping to get some inspiration, or tools suggestions to help me get started.", "author_fullname": "t2_c24qzfnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anomaly detection Algorithms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lc2v9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678224783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked by leadership to create a massive pdf that contains bunch of line graphs with week vs week data with all possible way that we can break out. Example: sales by country, sales by state, sales by market and so on.  The goal is the catch if something isn\u2019t right and\n99% of reports in the business are line graphs.&lt;/p&gt;\n\n&lt;p&gt;In my mind that is waste of time because no one will ever look at 500 pages PDF so I was thinking of suggesting algorithm that would highlight every week the biggest problem or drop based on historical performance. &lt;/p&gt;\n\n&lt;p&gt;I was hoping to get some inspiration, or tools suggestions to help me get started.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lc2v9", "is_robot_indexable": true, "report_reasons": null, "author": "Grapeflavor_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lc2v9/anomaly_detection_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lc2v9/anomaly_detection_algorithms/", "subreddit_subscribers": 854929, "created_utc": 1678224783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I hope this is an appropriate question to ask here. I'm preparing for an upcoming interview and saw online that there is a live-coding portion using a practice dataset with this as the prompt.\n\nOff the top of my head, I'd probably start by running df.shape, df.head(), df.dtypes, and df.describe() to get a feel for what I'm working with. From there, I'd consider correcting any mislabeled dtypes then using .is\\_na().sum() and df.loc\\[df.duplicated()\\] to see what kind of cleaning might be needed. If prompted to go further, I'd probably make some histogram or kernel density plots of individual features, then create a correlation heatmap and pairplots and use those to look into feature relationships.\n\nOverall, this question seems like a good chance to show familiarity with pandas as well as my general approach to solving problems with data. I feel like my response would be decent, but it might be lacking some depth. I've never had a live coding interview and am generally a little unsure what the best approach would look like. I would love to hear how others would respond to this! I imagine there are some helpful options that I'm missing, and I'd really appreciate the chance to learn from someone more experienced. Thanks in advance for any thoughts.", "author_fullname": "t2_c3p7wy9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In an interview, you're asked to describe a dataset with Pandas. How would you approach the problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lf1u7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678231294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I hope this is an appropriate question to ask here. I&amp;#39;m preparing for an upcoming interview and saw online that there is a live-coding portion using a practice dataset with this as the prompt.&lt;/p&gt;\n\n&lt;p&gt;Off the top of my head, I&amp;#39;d probably start by running df.shape, df.head(), df.dtypes, and df.describe() to get a feel for what I&amp;#39;m working with. From there, I&amp;#39;d consider correcting any mislabeled dtypes then using .is_na().sum() and df.loc[df.duplicated()] to see what kind of cleaning might be needed. If prompted to go further, I&amp;#39;d probably make some histogram or kernel density plots of individual features, then create a correlation heatmap and pairplots and use those to look into feature relationships.&lt;/p&gt;\n\n&lt;p&gt;Overall, this question seems like a good chance to show familiarity with pandas as well as my general approach to solving problems with data. I feel like my response would be decent, but it might be lacking some depth. I&amp;#39;ve never had a live coding interview and am generally a little unsure what the best approach would look like. I would love to hear how others would respond to this! I imagine there are some helpful options that I&amp;#39;m missing, and I&amp;#39;d really appreciate the chance to learn from someone more experienced. Thanks in advance for any thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lf1u7", "is_robot_indexable": true, "report_reasons": null, "author": "HelpWithMusicPC", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lf1u7/in_an_interview_youre_asked_to_describe_a_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lf1u7/in_an_interview_youre_asked_to_describe_a_dataset/", "subreddit_subscribers": 854929, "created_utc": 1678231294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR; graduating with a Masters in Mathematics this May, seeking some guidance/advice for breaking into data science (or getting any sort of non-teaching job, really).\n\nI've been applying to both full-time jobs in data science/analytics and internships for 4-5 months and have received one final round interview so far for an internship. Lots of rejections. I know the market sucks in general right now, but I can't help think there's something I'm doing wrong or something I could improve on to help my chances. I've been a high achiever my entire life, but I just feel pretty down about choosing a math degree when what I want to do for a career is data science. People say math is a great choice, and I know I would make a wonderful employee, there is **great** value in having a math education, but I don't think tech recruiters are seeing that? I would love to hear some insight from folks who transitioned into data science from a non-CS degree (math in particular, or otherwise). Any tips, connections, or general empathy is super appreciated.\n\nAcademic Background: I have a BS in Pure Math from a small private liberal arts university, finishing up my MS in Mathematics this may from a mid-tier public state school. Graduated with a 4.0 from undergrad with Honors and I won my department's award for high achievement in mathematics. I currently have a 3.8 in grad school, and have been a graduate assistant for the past two years. The past year I have been instructor-of-record for a business calculus class. Courses from grad school include: 4 semesters of real analysis, Applied Probability, Dynamical Systems, Ordinary Differential Equations, Data Structures and Algorithms (CS course), Numerical Linear Algebra, and Numerical Linear Algebra II for Data Science. In the latter course we essentially learned the math behind a bunch of machine learning algorithms, as well as how to implement them from scratch in Python and using Scikit learn.\n\nSkills: Python (3 years), SQL (pretty much beginner level), Java, C++, MATLAB, packages in Python: numpy, pandas, scikit-learn, tensorflow, matplotlib.\n\nOther background: I'm a female, on the East Coast of the US, I was a collegiate athlete (swimming) and team captain, sorority member and served on the exec board, president of the math club in undergrad, and am currently secretary for the Math graduate student association at my university. I have no related work experience or internships (I've applied every summer for the past 2 years, no luck, I received one interview total)\n\nI have 2 data science projects listed on my resume. One is an image recognition program using CNN, and one is a clustering project. I also feel confident in my ability to do well in a technical interview, but I have not been given the chance yet.\n\nI will say, I don't as of right now have a github profile, and am not posting my work online. I understand why this would be quite important, but a math degree and teaching is time consuming and I haven't had the free time to put out work that I am proud of.\n\nThis leads me to a second question: I don't know exactly what the standard is for posting my work, how do I know if a certain project is good, has enough work done on it, isn't redundant from what others have done, etc? I guess I would say I know how to implement a bunch of machine learning algorithms including neural networks, and I know why they work and when to use which one, but in terms of putting together a nice example project, I'm unconfident.  What advice/resources/guidance can you give me on this specifically, and do you think this is the main reason I'm not getting interviews?\n\nThat felt a little all over the place, but hearing back from anyone with some encouragement and help would be appreciated. Thank you!", "author_fullname": "t2_5sy262lv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Math Masters graduate trying to get a job in DS, advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l80yy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678215814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; graduating with a Masters in Mathematics this May, seeking some guidance/advice for breaking into data science (or getting any sort of non-teaching job, really).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying to both full-time jobs in data science/analytics and internships for 4-5 months and have received one final round interview so far for an internship. Lots of rejections. I know the market sucks in general right now, but I can&amp;#39;t help think there&amp;#39;s something I&amp;#39;m doing wrong or something I could improve on to help my chances. I&amp;#39;ve been a high achiever my entire life, but I just feel pretty down about choosing a math degree when what I want to do for a career is data science. People say math is a great choice, and I know I would make a wonderful employee, there is &lt;strong&gt;great&lt;/strong&gt; value in having a math education, but I don&amp;#39;t think tech recruiters are seeing that? I would love to hear some insight from folks who transitioned into data science from a non-CS degree (math in particular, or otherwise). Any tips, connections, or general empathy is super appreciated.&lt;/p&gt;\n\n&lt;p&gt;Academic Background: I have a BS in Pure Math from a small private liberal arts university, finishing up my MS in Mathematics this may from a mid-tier public state school. Graduated with a 4.0 from undergrad with Honors and I won my department&amp;#39;s award for high achievement in mathematics. I currently have a 3.8 in grad school, and have been a graduate assistant for the past two years. The past year I have been instructor-of-record for a business calculus class. Courses from grad school include: 4 semesters of real analysis, Applied Probability, Dynamical Systems, Ordinary Differential Equations, Data Structures and Algorithms (CS course), Numerical Linear Algebra, and Numerical Linear Algebra II for Data Science. In the latter course we essentially learned the math behind a bunch of machine learning algorithms, as well as how to implement them from scratch in Python and using Scikit learn.&lt;/p&gt;\n\n&lt;p&gt;Skills: Python (3 years), SQL (pretty much beginner level), Java, C++, MATLAB, packages in Python: numpy, pandas, scikit-learn, tensorflow, matplotlib.&lt;/p&gt;\n\n&lt;p&gt;Other background: I&amp;#39;m a female, on the East Coast of the US, I was a collegiate athlete (swimming) and team captain, sorority member and served on the exec board, president of the math club in undergrad, and am currently secretary for the Math graduate student association at my university. I have no related work experience or internships (I&amp;#39;ve applied every summer for the past 2 years, no luck, I received one interview total)&lt;/p&gt;\n\n&lt;p&gt;I have 2 data science projects listed on my resume. One is an image recognition program using CNN, and one is a clustering project. I also feel confident in my ability to do well in a technical interview, but I have not been given the chance yet.&lt;/p&gt;\n\n&lt;p&gt;I will say, I don&amp;#39;t as of right now have a github profile, and am not posting my work online. I understand why this would be quite important, but a math degree and teaching is time consuming and I haven&amp;#39;t had the free time to put out work that I am proud of.&lt;/p&gt;\n\n&lt;p&gt;This leads me to a second question: I don&amp;#39;t know exactly what the standard is for posting my work, how do I know if a certain project is good, has enough work done on it, isn&amp;#39;t redundant from what others have done, etc? I guess I would say I know how to implement a bunch of machine learning algorithms including neural networks, and I know why they work and when to use which one, but in terms of putting together a nice example project, I&amp;#39;m unconfident.  What advice/resources/guidance can you give me on this specifically, and do you think this is the main reason I&amp;#39;m not getting interviews?&lt;/p&gt;\n\n&lt;p&gt;That felt a little all over the place, but hearing back from anyone with some encouragement and help would be appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l80yy", "is_robot_indexable": true, "report_reasons": null, "author": "tim-shel", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l80yy/math_masters_graduate_trying_to_get_a_job_in_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l80yy/math_masters_graduate_trying_to_get_a_job_in_ds/", "subreddit_subscribers": 854929, "created_utc": 1678215814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im taking a data science ethics course as part of my master\u2019s and I have been shocked by some of the readings, and curious what industry professionals generally think.\n\nI will reference the article linked at the bottom.\n\nIt is mostly about using informed consent and other good practices to ensure ethical treatment of subjects. \n\nThen we get to the last point number 10) \"Know when to break the rules\" ; particularly this quote: \n\n\"Likewise, the use of genetic or other biological data collected without informed consent might be vital in managing an emerging disease epidemic.\"\n\n\nI feel like this is wrong. We can always find reasons that the ends justify the means. We dont know what we dont know. We accept that by respecting ethical standards we are missing out on life saving discoveries not to mention profits. We could always find a way to justify breaking the rules. The authors do say its a slippery slope, but I dont feel this should belong at all. \n\nWhen I brought up these concerns in class I was told that the course is more about professional ethics than philosophy, but I felt that was just hand waving. \n\nWhat do practicing data scientists think? Should we ignore laws and ethical standards if we have compelling reasons? Am I being too inflexible?\n\nhttps://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005399&amp;type=printable", "author_fullname": "t2_ljhjrir7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ethics: Ends justify the means?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lin2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678240219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im taking a data science ethics course as part of my master\u2019s and I have been shocked by some of the readings, and curious what industry professionals generally think.&lt;/p&gt;\n\n&lt;p&gt;I will reference the article linked at the bottom.&lt;/p&gt;\n\n&lt;p&gt;It is mostly about using informed consent and other good practices to ensure ethical treatment of subjects. &lt;/p&gt;\n\n&lt;p&gt;Then we get to the last point number 10) &amp;quot;Know when to break the rules&amp;quot; ; particularly this quote: &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Likewise, the use of genetic or other biological data collected without informed consent might be vital in managing an emerging disease epidemic.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I feel like this is wrong. We can always find reasons that the ends justify the means. We dont know what we dont know. We accept that by respecting ethical standards we are missing out on life saving discoveries not to mention profits. We could always find a way to justify breaking the rules. The authors do say its a slippery slope, but I dont feel this should belong at all. &lt;/p&gt;\n\n&lt;p&gt;When I brought up these concerns in class I was told that the course is more about professional ethics than philosophy, but I felt that was just hand waving. &lt;/p&gt;\n\n&lt;p&gt;What do practicing data scientists think? Should we ignore laws and ethical standards if we have compelling reasons? Am I being too inflexible?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005399&amp;amp;type=printable\"&gt;https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005399&amp;amp;type=printable&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lin2s", "is_robot_indexable": true, "report_reasons": null, "author": "Unsurreality", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lin2s/ethics_ends_justify_the_means/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lin2s/ethics_ends_justify_the_means/", "subreddit_subscribers": 854929, "created_utc": 1678240219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " **TL;DR: My friends and I have a stupid hobby that's getting out of control and I need your help spiraling it further. Please help me create a fair power rankings system (using the attached spreadsheet for reference) for the Beerio Kart tournaments we host.**\n\n[**https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc\\_jHWbTZ\\_khS/edit?usp=sharing&amp;ouid=114408781303577995971&amp;rtpof=true&amp;sd=true**](https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;ouid=114408781303577995971&amp;rtpof=true&amp;sd=true)\n\nDear members of the Data Science community,\n\nI call humbly upon the mario kart champions, statisticians, mathematicians, programming aficionados, excel experts, sports analysts, and power rankings enthusiasts of this great community to assist me with a vital task -- creating a fair and representative power ranking formula for the International Beerio Kart Championships of the World.\n\nA little background: my buddies and I were trapped at home Thanksgiving of '21 for a fourteen day COVID quarantine. We were saddened by a missed opportunity to see our families, but with competitive spirit running through our veins and a surplus of leftover PBR from a party we threw (which was undoubtedly what gave us COVID), we found solace in roughly two weeks straight of fierce competition in the best drinking/video game pair to ever exist: Beerio Kart. For the uninitiated: Beerio Kart is Mario Kart, however, you need to finish your beer before the end of each race, and you can't drink and drive (i.e. chug and control your character simultaneously). Our version of the game has many extra rules and sub-rules, however, that's the basic premise of the game.\n\nAfter two weeks of this, we needed an outlet to determine who was truly the best of us, and thusly the International Beerio Kart Championships of the World were born. It started with a modest eight competitors, but interest has increased steadily over the past three years and in recent events we've had as many as 58 competitors fighting to compete in a 32 person bracket (surplus competitors play in Play-in Prix's for entry into the main bracket). We've now had 75 people play in official brackets and obtain power rankings, and close to 100 participate in the events overall. For a little context into how the tournaments are run, four competitors participate in each Grand Prix, and the top two competitors advance from each round until the championship. In the preliminary rounds, players must drink a beer on races two and four of each Grand Prix, and in the finals all four races are drinking rounds, thusly the final four competitors must drink a minimum of 10 beers to win the tournament.\n\nAs tournaments got larger and more intricate (and people started complaining that they were seeded unfairly), we realized we needed an objective ranking system to seed players so that the Prix's leading up to the championship were fair and quantitative. This background brings me to the hallowed undertaking I beseech your help with: **please help me figure out how to do this.**\n\nWe've tried a few formulas, but we are but amateur statisticians and none have felt like they effectively capture a player's skill level.\n\nFirst we tried the following formula: ibkc power ranking = 0.33t/60n + 0.33z/60 + 0.33y/60, where:\n\n1. 60 = the maximum number of possible points scored in any given grand prix\n2. t = total points accrued over all past tournaments attended\n3. n = total number of grand prix\u2019 held in all official tournaments\n4. z = average points scored per prix, per tournament, in all tournaments attended\n5. y = average points scored per prix, per tournament, in all tournaments attended this calendar year\n\nIt was a good start, but it unfairly biased players who had played in more tournaments, and wasn't an accurate reflection of *current* skill level. It would be like baseball power rankings putting the Yankees are at the top because they're an ancient ball club and have won 27 World Series', even though the last time they won was 2009, or the Astros low down on the power rankings because they didn't win their first Series until 2017, even though they've won twice in the past 5 years.\n\nWe then created a formula based on Pythagorean expectation, where a players skill level is calculated by averaging their (points accrued in a prix)/(points accrued in a prix + total number of possible points in a prix). Each round of a tournament was weighted heavier than the last, and tournaments with four rounds carry more weight than tournaments with three rounds. The player's Pythagorean expectation was then averaged over all tournaments they've participated in, averaged over the last four tournaments held, and averaged over the last two tournaments held. Their power score was then calculated by averaging these three numbers together with the intention that more recent tournaments would be weighted heavier than older ones. **This is the formula that the attached spreadsheet uses.**\n\nThis new formula was better than the first but has an inverse problem -- it weighs recent tournaments too heavily and doesn't account for any rank decay from missing tournaments. For example, you can see that BAT has won 6 of 8 tournaments, but after a huge upset in the semi's, BAT did not make the finals of the last tournament, and was booted from first place overall to third. All the while, Squirt4Boyz advanced from second place overall to first, even though Squirt4Boyz didn't even participate in the last tournament.\n\nThere's all sorts of hidden columns and rows and whatnot in this spreadsheet so please dm me with any questions you might have, but please, I beg of you fine and glorious proprietors of the world's most stressful game, help me create a ranking system that makes sense. **Ultimately we need a system that reflects how many points a player is expected to score, considers that player's tournament wins, podium finishes and finals appearances, accounts for rank decay, and like in global tennis or golf rankings, has some bias for recent events.**\n\nThank you, friends.\n\nYour servant,\n\nThe International Beerio Kart Championships of the World League Commissioner", "author_fullname": "t2_7kap8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "International Beerio Kart Championships of the World: Data Scientists, please help me!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11la0m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678220225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR: My friends and I have a stupid hobby that&amp;#39;s getting out of control and I need your help spiraling it further. Please help me create a fair power rankings system (using the attached spreadsheet for reference) for the Beerio Kart tournaments we host.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;amp;ouid=114408781303577995971&amp;amp;rtpof=true&amp;amp;sd=true\"&gt;&lt;strong&gt;https://docs.google.com/spreadsheets/d/1CS5pWnmgS8wIZAvFQL4cc_jHWbTZ_khS/edit?usp=sharing&amp;amp;ouid=114408781303577995971&amp;amp;rtpof=true&amp;amp;sd=true&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Dear members of the Data Science community,&lt;/p&gt;\n\n&lt;p&gt;I call humbly upon the mario kart champions, statisticians, mathematicians, programming aficionados, excel experts, sports analysts, and power rankings enthusiasts of this great community to assist me with a vital task -- creating a fair and representative power ranking formula for the International Beerio Kart Championships of the World.&lt;/p&gt;\n\n&lt;p&gt;A little background: my buddies and I were trapped at home Thanksgiving of &amp;#39;21 for a fourteen day COVID quarantine. We were saddened by a missed opportunity to see our families, but with competitive spirit running through our veins and a surplus of leftover PBR from a party we threw (which was undoubtedly what gave us COVID), we found solace in roughly two weeks straight of fierce competition in the best drinking/video game pair to ever exist: Beerio Kart. For the uninitiated: Beerio Kart is Mario Kart, however, you need to finish your beer before the end of each race, and you can&amp;#39;t drink and drive (i.e. chug and control your character simultaneously). Our version of the game has many extra rules and sub-rules, however, that&amp;#39;s the basic premise of the game.&lt;/p&gt;\n\n&lt;p&gt;After two weeks of this, we needed an outlet to determine who was truly the best of us, and thusly the International Beerio Kart Championships of the World were born. It started with a modest eight competitors, but interest has increased steadily over the past three years and in recent events we&amp;#39;ve had as many as 58 competitors fighting to compete in a 32 person bracket (surplus competitors play in Play-in Prix&amp;#39;s for entry into the main bracket). We&amp;#39;ve now had 75 people play in official brackets and obtain power rankings, and close to 100 participate in the events overall. For a little context into how the tournaments are run, four competitors participate in each Grand Prix, and the top two competitors advance from each round until the championship. In the preliminary rounds, players must drink a beer on races two and four of each Grand Prix, and in the finals all four races are drinking rounds, thusly the final four competitors must drink a minimum of 10 beers to win the tournament.&lt;/p&gt;\n\n&lt;p&gt;As tournaments got larger and more intricate (and people started complaining that they were seeded unfairly), we realized we needed an objective ranking system to seed players so that the Prix&amp;#39;s leading up to the championship were fair and quantitative. This background brings me to the hallowed undertaking I beseech your help with: &lt;strong&gt;please help me figure out how to do this.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve tried a few formulas, but we are but amateur statisticians and none have felt like they effectively capture a player&amp;#39;s skill level.&lt;/p&gt;\n\n&lt;p&gt;First we tried the following formula: ibkc power ranking = 0.33t/60n + 0.33z/60 + 0.33y/60, where:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;60 = the maximum number of possible points scored in any given grand prix&lt;/li&gt;\n&lt;li&gt;t = total points accrued over all past tournaments attended&lt;/li&gt;\n&lt;li&gt;n = total number of grand prix\u2019 held in all official tournaments&lt;/li&gt;\n&lt;li&gt;z = average points scored per prix, per tournament, in all tournaments attended&lt;/li&gt;\n&lt;li&gt;y = average points scored per prix, per tournament, in all tournaments attended this calendar year&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It was a good start, but it unfairly biased players who had played in more tournaments, and wasn&amp;#39;t an accurate reflection of &lt;em&gt;current&lt;/em&gt; skill level. It would be like baseball power rankings putting the Yankees are at the top because they&amp;#39;re an ancient ball club and have won 27 World Series&amp;#39;, even though the last time they won was 2009, or the Astros low down on the power rankings because they didn&amp;#39;t win their first Series until 2017, even though they&amp;#39;ve won twice in the past 5 years.&lt;/p&gt;\n\n&lt;p&gt;We then created a formula based on Pythagorean expectation, where a players skill level is calculated by averaging their (points accrued in a prix)/(points accrued in a prix + total number of possible points in a prix). Each round of a tournament was weighted heavier than the last, and tournaments with four rounds carry more weight than tournaments with three rounds. The player&amp;#39;s Pythagorean expectation was then averaged over all tournaments they&amp;#39;ve participated in, averaged over the last four tournaments held, and averaged over the last two tournaments held. Their power score was then calculated by averaging these three numbers together with the intention that more recent tournaments would be weighted heavier than older ones. &lt;strong&gt;This is the formula that the attached spreadsheet uses.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This new formula was better than the first but has an inverse problem -- it weighs recent tournaments too heavily and doesn&amp;#39;t account for any rank decay from missing tournaments. For example, you can see that BAT has won 6 of 8 tournaments, but after a huge upset in the semi&amp;#39;s, BAT did not make the finals of the last tournament, and was booted from first place overall to third. All the while, Squirt4Boyz advanced from second place overall to first, even though Squirt4Boyz didn&amp;#39;t even participate in the last tournament.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s all sorts of hidden columns and rows and whatnot in this spreadsheet so please dm me with any questions you might have, but please, I beg of you fine and glorious proprietors of the world&amp;#39;s most stressful game, help me create a ranking system that makes sense. &lt;strong&gt;Ultimately we need a system that reflects how many points a player is expected to score, considers that player&amp;#39;s tournament wins, podium finishes and finals appearances, accounts for rank decay, and like in global tennis or golf rankings, has some bias for recent events.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you, friends.&lt;/p&gt;\n\n&lt;p&gt;Your servant,&lt;/p&gt;\n\n&lt;p&gt;The International Beerio Kart Championships of the World League Commissioner&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?auto=webp&amp;v=enabled&amp;s=ac1c84de7cd76a29b4042b046e17d9acc84e1550", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31a7f4c0970e53d8d0aa95f02d1a52d7bc1490e0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=346452f887e8ffd2acede0d45fa23db46ec874a6", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=474adbb31de38cc3f64760877eb1ca96078c9e82", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49c12274105ddcb9e0084a2bdcd71f5f62953f78", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f29217fcf51a0aed6fe7aedb9422b247442b60", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/V-ce4ssUwLHZQBBLwP4Zl9g-IIxYa9LlAP0j2gBKiVM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78cc3c0091728d93e1d59045723d18144c83903c", "width": 1080, "height": 567}], "variants": {}, "id": "CZ1IT9UepvRZrTOmYYuoRJc5P5HRmKDk0Zc3vgIOFZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11la0m3", "is_robot_indexable": true, "report_reasons": null, "author": "zakarm22", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11la0m3/international_beerio_kart_championships_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11la0m3/international_beerio_kart_championships_of_the/", "subreddit_subscribers": 854929, "created_utc": 1678220225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anybody know a website besides Linkedin Jobs to find/filter DS/MLE jobs at startups (Series A/B/C/D/E)? \n\nIt is so hard to filter on Linkedin and it kind of pisses me off to see 6+ YOE DS jobs with \"Entry level\" tags on Linkedin.", "author_fullname": "t2_6gpihliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find DS jobs at funded Startups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l8h6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678216827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know a website besides Linkedin Jobs to find/filter DS/MLE jobs at startups (Series A/B/C/D/E)? &lt;/p&gt;\n\n&lt;p&gt;It is so hard to filter on Linkedin and it kind of pisses me off to see 6+ YOE DS jobs with &amp;quot;Entry level&amp;quot; tags on Linkedin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l8h6t", "is_robot_indexable": true, "report_reasons": null, "author": "wardrobe_creator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l8h6t/how_to_find_ds_jobs_at_funded_startups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l8h6t/how_to_find_ds_jobs_at_funded_startups/", "subreddit_subscribers": 854929, "created_utc": 1678216827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My professor strongly recommended UNCC dsba for my future Master in DS. It seems pretty good, but it would cost almost 4 times than going to Gatch omsa. \nAs on campus, I might get more involved with faculty and more opportunities, but I wonder that would be worth that much money. \n\nAs I am leaning toward Gatech, not only due to reputation but also cost and it being online, I also think UNCC is a great option as I could graduate a little earlier as a full time student with more possible opportunities through faculty and on campus benefits.\n\nCurriculum-wise, I think Gatech would be more centered with CS courses with various options, whereas UNCC is relatively slightly more business focused.\n\nI would appreciate anyone's advice!", "author_fullname": "t2_j8t5xiv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gatech Omsa vs UNC Charlotte dsba", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6vx9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678213284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My professor strongly recommended UNCC dsba for my future Master in DS. It seems pretty good, but it would cost almost 4 times than going to Gatch omsa. \nAs on campus, I might get more involved with faculty and more opportunities, but I wonder that would be worth that much money. &lt;/p&gt;\n\n&lt;p&gt;As I am leaning toward Gatech, not only due to reputation but also cost and it being online, I also think UNCC is a great option as I could graduate a little earlier as a full time student with more possible opportunities through faculty and on campus benefits.&lt;/p&gt;\n\n&lt;p&gt;Curriculum-wise, I think Gatech would be more centered with CS courses with various options, whereas UNCC is relatively slightly more business focused.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate anyone&amp;#39;s advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6vx9", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Tip-5097", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6vx9/gatech_omsa_vs_unc_charlotte_dsba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6vx9/gatech_omsa_vs_unc_charlotte_dsba/", "subreddit_subscribers": 854929, "created_utc": 1678213284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone\n\nI'm currently using key words to detect certain events in textual data. However, I'm wondering whether there is a more advanced tool I can use to help me in this application.\n\nSay I have two sentences:\n1- \"I woke up today and it was raining\"\n2- \"I woke up today and it was not raining\"\n\nI would like to add a \"rain\" tag to the first sentence and not the second sentence.\n\nI'm currently using regex but the patterns are getting too long and complex. Is there a better tool that could help me with this application?", "author_fullname": "t2_l1lf6s9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool for Event Detection in Textual Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6r3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using key words to detect certain events in textual data. However, I&amp;#39;m wondering whether there is a more advanced tool I can use to help me in this application.&lt;/p&gt;\n\n&lt;p&gt;Say I have two sentences:\n1- &amp;quot;I woke up today and it was raining&amp;quot;\n2- &amp;quot;I woke up today and it was not raining&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I would like to add a &amp;quot;rain&amp;quot; tag to the first sentence and not the second sentence.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using regex but the patterns are getting too long and complex. Is there a better tool that could help me with this application?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6r3h", "is_robot_indexable": true, "report_reasons": null, "author": "Unlikely_Silver_1650", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6r3h/tool_for_event_detection_in_textual_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6r3h/tool_for_event_detection_in_textual_data/", "subreddit_subscribers": 854929, "created_utc": 1678212993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Working with big economics datasets e.g. 10-50 gb. \n\nOnce I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift \n\nProblem is anytime I try to debug to see if it's working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. \n\nAssuming I've used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. \n\nWhat other things can I add to my code:\n\n1. To not have to read my data in every time I run the code while developing n debugging \n\n2. Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints \n\nOther economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it's in use", "author_fullname": "t2_rtximd9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for a way of reading big data files into python without having to read the same file everything I run ti debug", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11l6eff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678212199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with big economics datasets e.g. 10-50 gb. &lt;/p&gt;\n\n&lt;p&gt;Once I read the data, there are some data wrangling steps like value counts, combining some columns,loc functions, drop rows based on conditions, creating new volumes you get turn drift &lt;/p&gt;\n\n&lt;p&gt;Problem is anytime I try to debug to see if it&amp;#39;s working fine or if the new line of code I added functional; the data is read and consumes memory, time and delays my work. &lt;/p&gt;\n\n&lt;p&gt;Assuming I&amp;#39;ve used all the possible libraries such as pandas, dask, modin, pyarrow,ray etc. &lt;/p&gt;\n\n&lt;p&gt;What other things can I add to my code:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;To not have to read my data in every time I run the code while developing n debugging &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Save this csv virtually into my environment but without it taking away memory or cores thereby worsening my performance due to resource constraints &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Other economists I know use stata etc where once the file is loaded in, it stays there but it occupies memory for the time it&amp;#39;s in use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l6eff", "is_robot_indexable": true, "report_reasons": null, "author": "macORnvidia", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l6eff/looking_for_a_way_of_reading_big_data_files_into/", "subreddit_subscribers": 854929, "created_utc": 1678212199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello mate,\n\nI hope you're having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\n\n&amp;#x200B;\n\nIf you're interested, please let me know.\n\nRegards.", "author_fullname": "t2_pz75y30d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-study group in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9sx9e4zctcma1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=994986d8b07a3e4f8ad291f5cbe978300520f574"}, {"y": 101, "x": 216, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24a5f495456d645d38b0cb1af8fc31685927777f"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb0f287367e4ce6dac59921d8f82cb146c0ae4c2"}, {"y": 299, "x": 640, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55d615d054af3a149f11175552cfece01c9dcc8d"}, {"y": 449, "x": 960, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da595e5a003258ee901af025cda872299c0f3106"}, {"y": 505, "x": 1080, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa3e1d39e0691ee5645dcfe855f2d7d3708d900"}], "s": {"y": 702, "x": 1500, "u": "https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1"}, "id": "9sx9e4zctcma1"}}, "name": "t3_11l5v5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bwQQ0CPIFuVZOnxe3c1dP-4zbPvkO10SHhrXNu_vIDg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678211021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello mate,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re having a good day. I am going to create a group on Discord and/or Facebook in order to study Data Science based on textbook and ML models using projects from Kaggle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1\"&gt;https://preview.redd.it/9sx9e4zctcma1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bb003a4e0d96d28eeb2c690e7d01355416683b1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested, please let me know.&lt;/p&gt;\n\n&lt;p&gt;Regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11l5v5t", "is_robot_indexable": true, "report_reasons": null, "author": "Sam-Oden", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11l5v5t/selfstudy_group_in_data_science/", "subreddit_subscribers": 854929, "created_utc": 1678211021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am currently junior undergraduate student studying applied math and statitstics in US. I really want to be a data analyst; however, I don't have experience of SQL, but only R, python, excel, SAS, and STATA. I also have my publication on public journal about meta-analysis of health data(cancer), which is a kind of data analysis. I really want to get a job as a data analyst position, but most job position requires experience of SQL. Is there any data analyst position available which doesn't require SQL? I am serious and desperate. I really want to get an internship this summer. Thank you so much!", "author_fullname": "t2_pdm8totp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To be a data analyst(to get a job)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lm3t3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678249389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently junior undergraduate student studying applied math and statitstics in US. I really want to be a data analyst; however, I don&amp;#39;t have experience of SQL, but only R, python, excel, SAS, and STATA. I also have my publication on public journal about meta-analysis of health data(cancer), which is a kind of data analysis. I really want to get a job as a data analyst position, but most job position requires experience of SQL. Is there any data analyst position available which doesn&amp;#39;t require SQL? I am serious and desperate. I really want to get an internship this summer. Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lm3t3", "is_robot_indexable": true, "report_reasons": null, "author": "TieProfessional6402", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lm3t3/to_be_a_data_analystto_get_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lm3t3/to_be_a_data_analystto_get_a_job/", "subreddit_subscribers": 854929, "created_utc": 1678249389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable ([https://www.turntable.so/](https://www.turntable.so/))\n\nTwo weeks ago we [demo'd some early features](https://www.reddit.com/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/) and we were grateful for the community response.\n\nThe number one feature request from you all was a column level lineage view.\n\nToday, I'm excited to share that we now have column-level lineage to bring column understanding to dbt projects. Under the hood, we parse the dbt-compiled sql into an abstract syntax tree and then recurse through that tree to build the lineage.\n\nI\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!\n\n[https://www.loom.com/share/c77689096ee14952a5e4cdea969eaf7c](https://www.loom.com/share/c77689096ee14952a5e4cdea969eaf7c)\n\nIn the upcoming weeks we're launching inline docs, smart autocomplete and an AI copilot!", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building Column Level Lineage for dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11lm3k2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678249370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable (&lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Two weeks ago we &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/\"&gt;demo&amp;#39;d some early features&lt;/a&gt; and we were grateful for the community response.&lt;/p&gt;\n\n&lt;p&gt;The number one feature request from you all was a column level lineage view.&lt;/p&gt;\n\n&lt;p&gt;Today, I&amp;#39;m excited to share that we now have column-level lineage to bring column understanding to dbt projects. Under the hood, we parse the dbt-compiled sql into an abstract syntax tree and then recurse through that tree to build the lineage.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.loom.com/share/c77689096ee14952a5e4cdea969eaf7c\"&gt;https://www.loom.com/share/c77689096ee14952a5e4cdea969eaf7c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In the upcoming weeks we&amp;#39;re launching inline docs, smart autocomplete and an AI copilot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lm3k2", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lm3k2/building_column_level_lineage_for_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lm3k2/building_column_level_lineage_for_dbt/", "subreddit_subscribers": 854929, "created_utc": 1678249370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there,\n\nI'm a graduate student enrolled in a Data Science program. Right now I am trying to find an internship in Data Science. However, it has been difficult because I have only been through one quarter(my school uses the quarter system) of my first year. \n\nI got my BS in Earth Science. I did not come from a Math or CS background so that is not really helping me. \n\nIn addition, I did not have a data-related job after getting my BS so I do not have relevant work experience either.\n\nI want to gain some valuable experience but I do not feel qualified for many Data Science internships. \n\nWhat advice and suggestions do you guys have for me? I do not want to be one of those people that graduated without an internship but I don't feel qualified for internships until I graduate. \n\nI am at a loss here. Any advice and suggestions would be greatly appreciated.\n\nThanks,", "author_fullname": "t2_2h3ml9k2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New graduate student in need of some advice on data science internships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11llsfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678248496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a graduate student enrolled in a Data Science program. Right now I am trying to find an internship in Data Science. However, it has been difficult because I have only been through one quarter(my school uses the quarter system) of my first year. &lt;/p&gt;\n\n&lt;p&gt;I got my BS in Earth Science. I did not come from a Math or CS background so that is not really helping me. &lt;/p&gt;\n\n&lt;p&gt;In addition, I did not have a data-related job after getting my BS so I do not have relevant work experience either.&lt;/p&gt;\n\n&lt;p&gt;I want to gain some valuable experience but I do not feel qualified for many Data Science internships. &lt;/p&gt;\n\n&lt;p&gt;What advice and suggestions do you guys have for me? I do not want to be one of those people that graduated without an internship but I don&amp;#39;t feel qualified for internships until I graduate. &lt;/p&gt;\n\n&lt;p&gt;I am at a loss here. Any advice and suggestions would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11llsfx", "is_robot_indexable": true, "report_reasons": null, "author": "SterlingG007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11llsfx/new_graduate_student_in_need_of_some_advice_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11llsfx/new_graduate_student_in_need_of_some_advice_on/", "subreddit_subscribers": 854929, "created_utc": 1678248496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am wondering if Mathematica is capable of doing meaningful, and commercially viable DS. Thoughts? Is anyone using it and what\u2019s your experience?", "author_fullname": "t2_4qii5wi1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you all think of using MathematicaTM for datascience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ljpy4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678242968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering if Mathematica is capable of doing meaningful, and commercially viable DS. Thoughts? Is anyone using it and what\u2019s your experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11ljpy4", "is_robot_indexable": true, "report_reasons": null, "author": "GetInTheBackJames", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11ljpy4/what_do_you_all_think_of_using_mathematicatm_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11ljpy4/what_do_you_all_think_of_using_mathematicatm_for/", "subreddit_subscribers": 854929, "created_utc": 1678242968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently facing an issue with a model's architecture that I developed in Kaggle and trained successfully on both Kaggle and my personal computer. However, when I attempted to save the model in H5 format and upload it onto AWS SageMaker, it generated an error. Upon further inspection of the error message and replicating the architecture on SageMaker, I encountered the same error. I would appreciate any insights as to why this discrepancy exists, as it is perplexing given that the model runs smoothly on other platforms.   \n\n\nThanks in advance\n\n[The Architecture of the Model](https://preview.redd.it/x1rs0y1snema1.png?width=741&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=564784c94f54228f4d8039fc388bb5d312c63231)\n\n[Error Message](https://preview.redd.it/mr33wx1snema1.png?width=1255&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8edc3f5f46c6592703d24c279b451b2f555e7769)", "author_fullname": "t2_qog0dx5m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model architecture error on AWS SageMaker: Seeking insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"x1rs0y1snema1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 111, "x": 108, "u": "https://preview.redd.it/x1rs0y1snema1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c70d329be78a759dc2dd26b144a1cca145c96736"}, {"y": 222, "x": 216, "u": "https://preview.redd.it/x1rs0y1snema1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb7dcf4f21f72e81449214911e812adbfcd09eb0"}, {"y": 330, "x": 320, "u": "https://preview.redd.it/x1rs0y1snema1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0aec9c869c98d744415e38fe52f184dadf468a6"}, {"y": 660, "x": 640, "u": "https://preview.redd.it/x1rs0y1snema1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfa7b688fa86012ea6e3bbcbae68d079f1e2d56f"}], "s": {"y": 765, "x": 741, "u": "https://preview.redd.it/x1rs0y1snema1.png?width=741&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=564784c94f54228f4d8039fc388bb5d312c63231"}, "id": "x1rs0y1snema1"}, "mr33wx1snema1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/mr33wx1snema1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5df365d7a62bf300bc8453e26eadd1a85a512a0f"}, {"y": 129, "x": 216, "u": "https://preview.redd.it/mr33wx1snema1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1532f6502e9f69a205b8d46f0ed5f18eb7c5edf1"}, {"y": 192, "x": 320, "u": "https://preview.redd.it/mr33wx1snema1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53cbdcae91d8bccea770a2d1a2aa7aade052d1c5"}, {"y": 384, "x": 640, "u": "https://preview.redd.it/mr33wx1snema1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4270a26489516b90b59e146018f2e2899de78a6a"}, {"y": 576, "x": 960, "u": "https://preview.redd.it/mr33wx1snema1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed5441c199ec8916dc54115290fd231ca5cf841e"}, {"y": 648, "x": 1080, "u": "https://preview.redd.it/mr33wx1snema1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ebe65a10d5377c845dc62a537099a15df026a8c"}], "s": {"y": 754, "x": 1255, "u": "https://preview.redd.it/mr33wx1snema1.png?width=1255&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8edc3f5f46c6592703d24c279b451b2f555e7769"}, "id": "mr33wx1snema1"}}, "name": "t3_11lfwwb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NBv8iljcCdA-glEwsxn0JrY9xpgK7pFuK0KSUxGx9gw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678233348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently facing an issue with a model&amp;#39;s architecture that I developed in Kaggle and trained successfully on both Kaggle and my personal computer. However, when I attempted to save the model in H5 format and upload it onto AWS SageMaker, it generated an error. Upon further inspection of the error message and replicating the architecture on SageMaker, I encountered the same error. I would appreciate any insights as to why this discrepancy exists, as it is perplexing given that the model runs smoothly on other platforms.   &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/x1rs0y1snema1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=564784c94f54228f4d8039fc388bb5d312c63231\"&gt;The Architecture of the Model&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mr33wx1snema1.png?width=1255&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8edc3f5f46c6592703d24c279b451b2f555e7769\"&gt;Error Message&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11lfwwb", "is_robot_indexable": true, "report_reasons": null, "author": "Science-Tracker", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11lfwwb/model_architecture_error_on_aws_sagemaker_seeking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11lfwwb/model_architecture_error_on_aws_sagemaker_seeking/", "subreddit_subscribers": 854929, "created_utc": 1678233348.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}