{"kind": "Listing", "data": {"after": "t3_11mq5lc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I am working with a high-dimensional dataset that contains approximately 300 columns and 10,000 rows. The dataset is characterized by a significant number of columns with missing values. To gain a better understanding of the missing data patterns, I generated a nullity matrix, which revealed the following:   \n\n[nullity matrix](https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a)\n\n After careful consideration, I have devised a plan to divide the data into two datasets. The first dataset will consist of the first 5000 rows, while the second dataset will encompass the remaining rows after columns with a high number of missing values have been dropped. It is worth noting that the test dataset exhibits the same pattern of missing values, and will therefore undergo the same treatment. Subsequently, I will train my model using the first dataset to predict the outcomes of the first portion of the test data, and then repeat the process using the second dataset for the remaining portion of the test data. Is this approach valid, or is there a concern that important information will be lost? Do you have any suggestions for alternative, more optimal solutions for this particular challenge?", "author_fullname": "t2_7uwwf65z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dealing with a lot of missing values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6bhzfkds2qma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdb5bebc1d165d70a832076654f3a7abf1f76970"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c89d13eb9dc5c2781ba7cb82e25d9105c46ff5d"}, {"y": 126, "x": 320, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89947b0fdead6015965d641b52eaa672a95a05c5"}, {"y": 252, "x": 640, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efb348a7397231cefb27c03771c0de886de6eb3a"}, {"y": 378, "x": 960, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d41d281c1a3be7b98132ebf631891c7e8203aaa5"}, {"y": 425, "x": 1080, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1bf1b4135b3ff68b23bf181e04612b2e2c08bc9"}], "s": {"y": 817, "x": 2074, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a"}, "id": "6bhzfkds2qma1"}}, "name": "t3_11mtoua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Ai5OJ2cloS7xUaRLt83UptWtJpolBjcb2l13ISbhLM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678372315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with a high-dimensional dataset that contains approximately 300 columns and 10,000 rows. The dataset is characterized by a significant number of columns with missing values. To gain a better understanding of the missing data patterns, I generated a nullity matrix, which revealed the following:   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a\"&gt;nullity matrix&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After careful consideration, I have devised a plan to divide the data into two datasets. The first dataset will consist of the first 5000 rows, while the second dataset will encompass the remaining rows after columns with a high number of missing values have been dropped. It is worth noting that the test dataset exhibits the same pattern of missing values, and will therefore undergo the same treatment. Subsequently, I will train my model using the first dataset to predict the outcomes of the first portion of the test data, and then repeat the process using the second dataset for the remaining portion of the test data. Is this approach valid, or is there a concern that important information will be lost? Do you have any suggestions for alternative, more optimal solutions for this particular challenge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mtoua", "is_robot_indexable": true, "report_reasons": null, "author": "Hamdi_bks", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mtoua/dealing_with_a_lot_of_missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mtoua/dealing_with_a_lot_of_missing_values/", "subreddit_subscribers": 855608, "created_utc": 1678372315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m mentoring a junior data scientist on my team and we\u2019ve been going through the importance of exploratory data analysis. Most of the techniques I use are ones I\u2019ve just picked up or learned over time, but does anyone have any favorite resources (books, blog posts, videos, etc.) that put all these EDA best practices together? Like if you have x type of data, these are some recommended first steps for EDA? We\u2019re currently working on a lot of text data but more general EDA tips would be great as well.", "author_fullname": "t2_femmyhh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite resources for EDA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mz57q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678385283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m mentoring a junior data scientist on my team and we\u2019ve been going through the importance of exploratory data analysis. Most of the techniques I use are ones I\u2019ve just picked up or learned over time, but does anyone have any favorite resources (books, blog posts, videos, etc.) that put all these EDA best practices together? Like if you have x type of data, these are some recommended first steps for EDA? We\u2019re currently working on a lot of text data but more general EDA tips would be great as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mz57q", "is_robot_indexable": true, "report_reasons": null, "author": "umnosorry", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mz57q/favorite_resources_for_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mz57q/favorite_resources_for_eda/", "subreddit_subscribers": 855608, "created_utc": 1678385283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all!\n\nI'm currently working with time series data. My manager wants me to use a \"simple\" model that is explainable. He said to start off with tree models, so I went with XGBoost having seen it being used for time series. I'm new to time series though, so I'm a bit confused as to how some things work.\n\nMy question is, upon train/test split, do I have to use the tail end of the dataset for the test set?\n\nIt doesn't seem to me like that makes a huge amount of sense for an XGBoost. Does the XGBoost model really take into account the order of the data points?", "author_fullname": "t2_9a5zvrr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "XGBoost for time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11moqft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678357333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working with time series data. My manager wants me to use a &amp;quot;simple&amp;quot; model that is explainable. He said to start off with tree models, so I went with XGBoost having seen it being used for time series. I&amp;#39;m new to time series though, so I&amp;#39;m a bit confused as to how some things work.&lt;/p&gt;\n\n&lt;p&gt;My question is, upon train/test split, do I have to use the tail end of the dataset for the test set?&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem to me like that makes a huge amount of sense for an XGBoost. Does the XGBoost model really take into account the order of the data points?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11moqft", "is_robot_indexable": true, "report_reasons": null, "author": "No_Storm_1500", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11moqft/xgboost_for_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11moqft/xgboost_for_time_series/", "subreddit_subscribers": 855608, "created_utc": 1678357333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is power BI inefficient?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11nffdr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678424738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nffdr", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nffdr/is_power_bi_inefficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nffdr/is_power_bi_inefficient/", "subreddit_subscribers": 855608, "created_utc": 1678424738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello I'm looking for an open dataset for demand forecasting that has sales data, product data and price information for a number of different products, possibly across categories and including seasonality information. \n\nI'm also looking for instructive papers for baseline models and techniques used in demand forecasting or planning space. \n\nI've looked at lots of datasets online - kaggle, AWS, etc and I can't find a good one that fits my needs for FREE. Any help would be appreciated!", "author_fullname": "t2_bk9hp9qn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "demand forecasting datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n8bnt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678406201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I&amp;#39;m looking for an open dataset for demand forecasting that has sales data, product data and price information for a number of different products, possibly across categories and including seasonality information. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also looking for instructive papers for baseline models and techniques used in demand forecasting or planning space. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at lots of datasets online - kaggle, AWS, etc and I can&amp;#39;t find a good one that fits my needs for FREE. Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n8bnt", "is_robot_indexable": true, "report_reasons": null, "author": "perfectlylonely13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n8bnt/demand_forecasting_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n8bnt/demand_forecasting_datasets/", "subreddit_subscribers": 855608, "created_utc": 1678406201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have doubts about when should we use Batch Gradient Descent vs Stochastic Gradient descent and why? Their Pros and Cons?\n\nWhile we're on this topic, can we discuss Mini-Batch Gradient descent?", "author_fullname": "t2_c9374irg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch vs Stochastic Gradient Descent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nev6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678423160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have doubts about when should we use Batch Gradient Descent vs Stochastic Gradient descent and why? Their Pros and Cons?&lt;/p&gt;\n\n&lt;p&gt;While we&amp;#39;re on this topic, can we discuss Mini-Batch Gradient descent?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nev6x", "is_robot_indexable": true, "report_reasons": null, "author": "fluman24", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nev6x/batch_vs_stochastic_gradient_descent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nev6x/batch_vs_stochastic_gradient_descent/", "subreddit_subscribers": 855608, "created_utc": 1678423160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking for some free tools to get quick insights", "author_fullname": "t2_65chay6oh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good tools for exploratory data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n52b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678398839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some free tools to get quick insights&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n52b0", "is_robot_indexable": true, "report_reasons": null, "author": "Mona_Labs", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n52b0/what_are_some_good_tools_for_exploratory_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n52b0/what_are_some_good_tools_for_exploratory_data/", "subreddit_subscribers": 855608, "created_utc": 1678398839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR\nGive me your best resources about this topic. Guides, implementation, but most importantly, I would like to receive some resources that let me understand all the parameters I could change and how it affects the learning.\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nI have recently find out a possible approach for my problem (predictive maintenance) could be tackled using LSTM Autoencoders.\nThe idea is to learn normal representation of  my data (that is multi variate, I have more than 20 features), and then test some time intervals to see if the MAE or some other measure increase over a certain chosen threshold. \n\nSome doubts:\n-Historical data for my sensors cover more than 1 month and time steps are every 5 seconds.\nI would like to learn short temporal patterns since I am not sure if LSTM can handle large temporal series. So my sample is made of 180 timesteps(15 minutes in total). How to improve this?\n-Also how to handle the encoder decoder architecture? I mean since I have 10000 samples of 180 timesteps and each sample has multiple features per timestep, what can be the structure of the LSTM? \n-Also feel free to post every good resources you have used in the past about this", "author_fullname": "t2_i6lyoywf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSTM AutoEncoders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n6z1q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678403061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR\nGive me your best resources about this topic. Guides, implementation, but most importantly, I would like to receive some resources that let me understand all the parameters I could change and how it affects the learning.\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;I have recently find out a possible approach for my problem (predictive maintenance) could be tackled using LSTM Autoencoders.\nThe idea is to learn normal representation of  my data (that is multi variate, I have more than 20 features), and then test some time intervals to see if the MAE or some other measure increase over a certain chosen threshold. &lt;/p&gt;\n\n&lt;p&gt;Some doubts:\n-Historical data for my sensors cover more than 1 month and time steps are every 5 seconds.\nI would like to learn short temporal patterns since I am not sure if LSTM can handle large temporal series. So my sample is made of 180 timesteps(15 minutes in total). How to improve this?\n-Also how to handle the encoder decoder architecture? I mean since I have 10000 samples of 180 timesteps and each sample has multiple features per timestep, what can be the structure of the LSTM? \n-Also feel free to post every good resources you have used in the past about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n6z1q", "is_robot_indexable": true, "report_reasons": null, "author": "ginotherhino1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n6z1q/lstm_autoencoders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n6z1q/lstm_autoencoders/", "subreddit_subscribers": 855608, "created_utc": 1678403061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience community,\n\nI have been invited to give a lecture on \"*data science in practice*\" for a class of MSc. business analytics students. While I plan on covering some technical aspects of the field, I believe that it might be worthwhile to focus more on the non-technical insights and tricks that one picks up after some time in industry. The things you don't learn on Kaggle.\n\nThis got me thinking: *What are the important non-technical lessons to you guys*? Perhaps it's the importance of effective communication skills, the ability to work collaboratively with colleagues from diverse backgrounds, or the value of prioritizing business needs over technical perfectionism.\n\nI'm hoping to compile a list of key takeaways to share with the class (and this subreddit), and your insights would be incredibly valuable. Whether you're a seasoned data scientist or just starting out, I'd love to hear your thoughts on this topic.\n\nTo start the conversation off, I have considered the following two points:\n\n\\- **How to choose DS projects:** For example, I find it helpful to score the potential project on \"feasibility\", \"scalability\", \"maintainability\" and \"business importance\". \n\n\\- **Understanding the differences in** ***data science maturity*** across sectors and organizations. For many organisations, the barriers to success with DS/ML/AI are strategic alignment, data availability/integrity etc. or executive sponsorship/buy-in - not the technical know-how.\n\nLooking forward to hearing your thoughts.\n\n\ud83d\udcf7\ud83d\udcf7", "author_fullname": "t2_26n50qtm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What non-technical lessons are important for aspiring data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n1xgt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678391695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I have been invited to give a lecture on &amp;quot;&lt;em&gt;data science in practice&lt;/em&gt;&amp;quot; for a class of MSc. business analytics students. While I plan on covering some technical aspects of the field, I believe that it might be worthwhile to focus more on the non-technical insights and tricks that one picks up after some time in industry. The things you don&amp;#39;t learn on Kaggle.&lt;/p&gt;\n\n&lt;p&gt;This got me thinking: &lt;em&gt;What are the important non-technical lessons to you guys&lt;/em&gt;? Perhaps it&amp;#39;s the importance of effective communication skills, the ability to work collaboratively with colleagues from diverse backgrounds, or the value of prioritizing business needs over technical perfectionism.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping to compile a list of key takeaways to share with the class (and this subreddit), and your insights would be incredibly valuable. Whether you&amp;#39;re a seasoned data scientist or just starting out, I&amp;#39;d love to hear your thoughts on this topic.&lt;/p&gt;\n\n&lt;p&gt;To start the conversation off, I have considered the following two points:&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;How to choose DS projects:&lt;/strong&gt; For example, I find it helpful to score the potential project on &amp;quot;feasibility&amp;quot;, &amp;quot;scalability&amp;quot;, &amp;quot;maintainability&amp;quot; and &amp;quot;business importance&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Understanding the differences in&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;data science maturity&lt;/em&gt;&lt;/strong&gt; across sectors and organizations. For many organisations, the barriers to success with DS/ML/AI are strategic alignment, data availability/integrity etc. or executive sponsorship/buy-in - not the technical know-how.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing your thoughts.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcf7\ud83d\udcf7&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n1xgt", "is_robot_indexable": true, "report_reasons": null, "author": "Academy-", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n1xgt/what_nontechnical_lessons_are_important_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n1xgt/what_nontechnical_lessons_are_important_for/", "subreddit_subscribers": 855608, "created_utc": 1678391695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_akn4dziw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What major would go well with a data science minor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nbb1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678413637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nbb1m", "is_robot_indexable": true, "report_reasons": null, "author": "dahnzii", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nbb1m/what_major_would_go_well_with_a_data_science_minor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nbb1m/what_major_would_go_well_with_a_data_science_minor/", "subreddit_subscribers": 855608, "created_utc": 1678413637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The project I'm currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.\n\nWe are going to be expanding our data size by something like 4x-20x in the next year or two.\n\nWe want to find examples of companies doing similar data work to us, and seeing how they managed their data.\n\nOur main setup is:\n\n1. Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.\n2. Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.\n3. Post processing Feature values. We have a database of post processing features so we don't need to process the raw data each time we do a model training run.\n\nThe setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.\n\nAre there any good resources on how more established companies manage this setup?", "author_fullname": "t2_80ont", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog posts detailing ML companies data infrastructure / DB schema?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mzo1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678386478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The project I&amp;#39;m currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.&lt;/p&gt;\n\n&lt;p&gt;We are going to be expanding our data size by something like 4x-20x in the next year or two.&lt;/p&gt;\n\n&lt;p&gt;We want to find examples of companies doing similar data work to us, and seeing how they managed their data.&lt;/p&gt;\n\n&lt;p&gt;Our main setup is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.&lt;/li&gt;\n&lt;li&gt;Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.&lt;/li&gt;\n&lt;li&gt;Post processing Feature values. We have a database of post processing features so we don&amp;#39;t need to process the raw data each time we do a model training run.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources on how more established companies manage this setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mzo1f", "is_robot_indexable": true, "report_reasons": null, "author": "Cwlrs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mzo1f/blog_posts_detailing_ml_companies_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mzo1f/blog_posts_detailing_ml_companies_data/", "subreddit_subscribers": 855608, "created_utc": 1678386478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1zz7cefa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating operations on column-based data across multiple files using the Codex Davinci model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11msd2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/yl1xdh05upma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yl1xdh05upma1/DASH_96.mp4", "dash_url": "https://v.redd.it/yl1xdh05upma1/DASHPlaylist.mpd?a=1681022647%2CYzg3Yjk1MWQyNzA2YmM4M2U3MjA2YmU3YmFjMDc0ZDMyMjBlNmI5MjViNTNhMzkzYjk3YTRiM2FlYjczODA1Nw%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/yl1xdh05upma1/HLSPlaylist.m3u8?a=1681022647%2CYTY1Njk1ZWY1ODhlNTQwNTg1YWY2ODYwZGUwYjY3NWU1MWQ4ZTc4YzY5MTYzODI2YThmNGRmNGIzYzM0YzA0Mg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3J_Y0ezmKHiH2pX98m0wBU4FKskQlwwJWUkTGBqnLc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678368970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/yl1xdh05upma1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a08af611da44165a74d1c8e4a6ba151b3cfe8225", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=173556aff19a963730bb5c13645b06e0c87d2888", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8c9e849efa9fd3666c8c68dcf92fb8a5ba962ea2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7df886a3ceab54f2068538fe5828182fd267d7b0", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=32ef900b4ae0be5098352535f6183c1558a595c2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5d00980b8129c1e403c574d5a1f4fd9296db4e19", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6b0e9f98d5bf740c90650d6f66966a5f320ba66a", "width": 1080, "height": 607}], "variants": {}, "id": "sD1ViAqbGBOUiDB-PrxLdzGJ96XYSJnGoymD9gu3uww"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11msd2v", "is_robot_indexable": true, "report_reasons": null, "author": "kijubikal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11msd2v/automating_operations_on_columnbased_data_across/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/yl1xdh05upma1", "subreddit_subscribers": 855608, "created_utc": 1678368970.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/yl1xdh05upma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yl1xdh05upma1/DASH_96.mp4", "dash_url": "https://v.redd.it/yl1xdh05upma1/DASHPlaylist.mpd?a=1681022647%2CYzg3Yjk1MWQyNzA2YmM4M2U3MjA2YmU3YmFjMDc0ZDMyMjBlNmI5MjViNTNhMzkzYjk3YTRiM2FlYjczODA1Nw%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/yl1xdh05upma1/HLSPlaylist.m3u8?a=1681022647%2CYTY1Njk1ZWY1ODhlNTQwNTg1YWY2ODYwZGUwYjY3NWU1MWQ4ZTc4YzY5MTYzODI2YThmNGRmNGIzYzM0YzA0Mg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello people,\n\nI look for reference books for cleaning time series datasets. can anyone help me with this request.\n\nthanks", "author_fullname": "t2_eikjje19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "time series data cleaning reference books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mrkmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678366811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people,&lt;/p&gt;\n\n&lt;p&gt;I look for reference books for cleaning time series datasets. can anyone help me with this request.&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mrkmz", "is_robot_indexable": true, "report_reasons": null, "author": "jorgecormane", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mrkmz/time_series_data_cleaning_reference_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mrkmz/time_series_data_cleaning_reference_books/", "subreddit_subscribers": 855608, "created_utc": 1678366811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leading Technology Event - Big Data &amp; AI World 8-9 March, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "name": "t3_11mqftc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/05_goNF3kF_nE5zdGN6lwz4PVQTtvoB0uDyUhHCwjxo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678363345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/newsroom/discover-the-intelligent-future-at-big-data-ai-world-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?auto=webp&amp;v=enabled&amp;s=de57f865cc5e42243d5235a4715c71954269bf68", "width": 1600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adefb8b91ad01ebd34517d171d938b01bf5b8c66", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130ce02b62410f3ed6685924e4fad97aa13a0f04", "width": 216, "height": 81}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6ce1c7599c569b518259aecb7cb2d35a806b26b", "width": 320, "height": 120}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72ee3e8af1bf03361ac42916120b0d876e4d67ae", "width": 640, "height": 240}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=436adb0f6d9229cb591781aede5f372aab9eaaba", "width": 960, "height": 360}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f94cf3246648acceb7000a1bea76ef45d413850", "width": 1080, "height": 405}], "variants": {}, "id": "aFdnRqHZhCc_vlA3H683TQXP5YJ0qnajroSr9Kd4K0M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mqftc", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mqftc/leading_technology_event_big_data_ai_world_89/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/newsroom/discover-the-intelligent-future-at-big-data-ai-world-2023", "subreddit_subscribers": 855608, "created_utc": 1678363345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I got my bachelors in structural engineering. I\u2019ve been working in the field for 6 years now but the industry doesn\u2019t pay well and the technologies are pretty antiquated. I was hoping to transition to the tech world while also applying my structural engineering background. I\u2019m curious about ML and could foresee some crossover between the two fields. The machine learning programs I\u2019m applying to are rejecting me saying that my background isn\u2019t compatible. I\u2019m wondering if it\u2019s because I don\u2019t have a lot of experience with probability and statistics. What could I do to close that gap so that they think I\u2019m ready for the program? Could anyone suggest any programs that would suit my situation? Or if you have any advice in general?", "author_fullname": "t2_emztpeug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science for structural engineers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11nfrex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678425739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I got my bachelors in structural engineering. I\u2019ve been working in the field for 6 years now but the industry doesn\u2019t pay well and the technologies are pretty antiquated. I was hoping to transition to the tech world while also applying my structural engineering background. I\u2019m curious about ML and could foresee some crossover between the two fields. The machine learning programs I\u2019m applying to are rejecting me saying that my background isn\u2019t compatible. I\u2019m wondering if it\u2019s because I don\u2019t have a lot of experience with probability and statistics. What could I do to close that gap so that they think I\u2019m ready for the program? Could anyone suggest any programs that would suit my situation? Or if you have any advice in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nfrex", "is_robot_indexable": true, "report_reasons": null, "author": "DisplayImpossible771", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nfrex/data_science_for_structural_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nfrex/data_science_for_structural_engineers/", "subreddit_subscribers": 855608, "created_utc": 1678425739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not sure if \u201cheterogeneous\u201d is the right word here but I\u2019m doing KRR where features that appear to be more suited to a power/log transform, some more suited for centering to 0 mean and unit variance. If I\u2019m manually choosing \u201chow\u201d to encode each feature, maybe I should upgrade to a fancier model, like a a neural network with VAE? Curious to hear opinions on this.", "author_fullname": "t2_1k2rzmpm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mixed Feature Transformers for highly heterogeneous data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n1yol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678391771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if \u201cheterogeneous\u201d is the right word here but I\u2019m doing KRR where features that appear to be more suited to a power/log transform, some more suited for centering to 0 mean and unit variance. If I\u2019m manually choosing \u201chow\u201d to encode each feature, maybe I should upgrade to a fancier model, like a a neural network with VAE? Curious to hear opinions on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n1yol", "is_robot_indexable": true, "report_reasons": null, "author": "vent2012", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n1yol/mixed_feature_transformers_for_highly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n1yol/mixed_feature_transformers_for_highly/", "subreddit_subscribers": 855608, "created_utc": 1678391771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI have a question regarding encoding high cardinality categorical variables and learning embedding vectors.\n\nTo make the explanation easier, I will take the example of columns representing ingredients for a recipe. They are categorical variables:\n\nProtein (meat, fish, eggs, beans, etc.)\n\nGrains (wheat, rice, oat, etc.)\n\nSpices (cinammon, cumin, ginger, etc.)\n\nBecause some recipes contain more than 1 protein, or more than 1 spice, these columns appear multiple times (Spice\\_1, Spice\\_2, Spice\\_3, etc.)\n\nQuestion 1: Is it reasonable to label encode Spice\\_1, Spice\\_2, Spice\\_3 simulateneously? \n\nQuestion 2: My main goal here is to learn embeddings to represent all these categories. Typically, we can use embedding layers to learn the mapping between categories and a dense vector representation for each feature and its associated categories.\n\nIn my case, by following this approach, I end up with different embedding representation of the same spice, depending if it was in Spice\\_1 column, Spice\\_2 column, etc.\n\nWhat would be the best way to ensure that the embeddings learned for similar features (Spice\\_1, Spice\\_2, Spice\\_3) do match?\n\nPlease note that I am actually working with chemical codes, so pretrained language models cannot be leveraged.\n\nThank you for your suggestions!", "author_fullname": "t2_19qf9hu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Learning consistent embeddings across multiple features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mvn4z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678377096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question regarding encoding high cardinality categorical variables and learning embedding vectors.&lt;/p&gt;\n\n&lt;p&gt;To make the explanation easier, I will take the example of columns representing ingredients for a recipe. They are categorical variables:&lt;/p&gt;\n\n&lt;p&gt;Protein (meat, fish, eggs, beans, etc.)&lt;/p&gt;\n\n&lt;p&gt;Grains (wheat, rice, oat, etc.)&lt;/p&gt;\n\n&lt;p&gt;Spices (cinammon, cumin, ginger, etc.)&lt;/p&gt;\n\n&lt;p&gt;Because some recipes contain more than 1 protein, or more than 1 spice, these columns appear multiple times (Spice_1, Spice_2, Spice_3, etc.)&lt;/p&gt;\n\n&lt;p&gt;Question 1: Is it reasonable to label encode Spice_1, Spice_2, Spice_3 simulateneously? &lt;/p&gt;\n\n&lt;p&gt;Question 2: My main goal here is to learn embeddings to represent all these categories. Typically, we can use embedding layers to learn the mapping between categories and a dense vector representation for each feature and its associated categories.&lt;/p&gt;\n\n&lt;p&gt;In my case, by following this approach, I end up with different embedding representation of the same spice, depending if it was in Spice_1 column, Spice_2 column, etc.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to ensure that the embeddings learned for similar features (Spice_1, Spice_2, Spice_3) do match?&lt;/p&gt;\n\n&lt;p&gt;Please note that I am actually working with chemical codes, so pretrained language models cannot be leveraged.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mvn4z", "is_robot_indexable": true, "report_reasons": null, "author": "DreamyPen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mvn4z/d_learning_consistent_embeddings_across_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mvn4z/d_learning_consistent_embeddings_across_multiple/", "subreddit_subscribers": 855608, "created_utc": 1678377096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've seen that my university is organizing small training for Statistica software. I wonder if it's worth to go for it. I've never heard of this software so I would like to know how relevant is it in current marketplace", "author_fullname": "t2_tzpsm3bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth to learn Statistica?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mua99", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678373817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen that my university is organizing small training for Statistica software. I wonder if it&amp;#39;s worth to go for it. I&amp;#39;ve never heard of this software so I would like to know how relevant is it in current marketplace&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mua99", "is_robot_indexable": true, "report_reasons": null, "author": "PlusPlusMan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mua99/is_it_worth_to_learn_statistica/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mua99/is_it_worth_to_learn_statistica/", "subreddit_subscribers": 855608, "created_utc": 1678373817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! \n\nI'm currently looking for a dataset that would contain both ticket data and logs data (that was used to create the tickets or to solve it). \n\nI managed to find separate datasets for tickets or logs but I would need something that combines both, are you aware of such a dataset or a way to create it ?", "author_fullname": "t2_mi18lm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any logs + ticketing dataset available ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mszw0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678370581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking for a dataset that would contain both ticket data and logs data (that was used to create the tickets or to solve it). &lt;/p&gt;\n\n&lt;p&gt;I managed to find separate datasets for tickets or logs but I would need something that combines both, are you aware of such a dataset or a way to create it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mszw0", "is_robot_indexable": true, "report_reasons": null, "author": "GuinsooIsOverrated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mszw0/any_logs_ticketing_dataset_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mszw0/any_logs_ticketing_dataset_available/", "subreddit_subscribers": 855608, "created_utc": 1678370581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nI have an interview today for a founding team data science role at a startup in India. All other rounds are over and today is the final call. In the earlier rounds, they told me that the startup is well-funded. I graduated from a top IIT and have about 4 years' worth of work experience, although not in this domain. But I did do an extensive program in DS and ML recently. Given that the office is in BKC, Mumbai, India, how much CTC do you think I can ask for?\n\nUntil now, I have only worked in organisations where salary negotiations were straightforward and so, this is a bit new to me.\n\nI don't want to undervalue myself, nor do I want to scare them off with an exorbitant number. So, as per the current market rates for data science roles, could you please suggest a ballpark figure that I can ask for? It would be super helpful if I can understand the breakdown as well. Anyone with advice to offer, feel free to chime in.\n\nThanks a lot in advance :)", "author_fullname": "t2_gaxqj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CTC for founding team data science roles in India?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mp1g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678358460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I have an interview today for a founding team data science role at a startup in India. All other rounds are over and today is the final call. In the earlier rounds, they told me that the startup is well-funded. I graduated from a top IIT and have about 4 years&amp;#39; worth of work experience, although not in this domain. But I did do an extensive program in DS and ML recently. Given that the office is in BKC, Mumbai, India, how much CTC do you think I can ask for?&lt;/p&gt;\n\n&lt;p&gt;Until now, I have only worked in organisations where salary negotiations were straightforward and so, this is a bit new to me.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to undervalue myself, nor do I want to scare them off with an exorbitant number. So, as per the current market rates for data science roles, could you please suggest a ballpark figure that I can ask for? It would be super helpful if I can understand the breakdown as well. Anyone with advice to offer, feel free to chime in.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mp1g6", "is_robot_indexable": true, "report_reasons": null, "author": "yipra97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mp1g6/ctc_for_founding_team_data_science_roles_in_india/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mp1g6/ctc_for_founding_team_data_science_roles_in_india/", "subreddit_subscribers": 855608, "created_utc": 1678358460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Can feature engineering avoid overfitting? If yes, are there any relevant papers that state this?", "author_fullname": "t2_end0qlqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can feature engineering avoid overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mokzw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678356778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can feature engineering avoid overfitting? If yes, are there any relevant papers that state this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mokzw", "is_robot_indexable": true, "report_reasons": null, "author": "Constant-Cranberry29", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mokzw/can_feature_engineering_avoid_overfitting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mokzw/can_feature_engineering_avoid_overfitting/", "subreddit_subscribers": 855608, "created_utc": 1678356778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Following on from the post (https://www.reddit.com/r/datascience/comments/11m00fv/for_every_data_analyst_position_i_have/) where the commenters emphasised how important it is to know SQL for data science, I would like to ask **what in your opinion is the best online course to learn SQL?**", "author_fullname": "t2_uo0un", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best online course to learn SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mndqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678352152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Following on from the post (&lt;a href=\"https://www.reddit.com/r/datascience/comments/11m00fv/for_every_data_analyst_position_i_have/\"&gt;https://www.reddit.com/r/datascience/comments/11m00fv/for_every_data_analyst_position_i_have/&lt;/a&gt;) where the commenters emphasised how important it is to know SQL for data science, I would like to ask &lt;strong&gt;what in your opinion is the best online course to learn SQL?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mndqa", "is_robot_indexable": true, "report_reasons": null, "author": "mettugihunting", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mndqa/what_is_the_best_online_course_to_learn_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mndqa/what_is_the_best_online_course_to_learn_sql/", "subreddit_subscribers": 855608, "created_utc": 1678352152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you see a problem if you anonymise everything? For example recording a gif of a dashboard with different data. Or describing a problem and provided solution without a lot of details. Would you feel the same/different if it has been cleared with your client?", "author_fullname": "t2_dt302qdc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Work projects in portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n5t4j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678400470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you see a problem if you anonymise everything? For example recording a gif of a dashboard with different data. Or describing a problem and provided solution without a lot of details. Would you feel the same/different if it has been cleared with your client?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n5t4j", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Sort_104", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n5t4j/work_projects_in_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n5t4j/work_projects_in_portfolio/", "subreddit_subscribers": 855608, "created_utc": 1678400470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I am a 12th grader in a data science class and I chose my project to be on how data science can be used to learn aspects of history. I'm wondering what you all think about this, I've read some articles that were beneficial but I was interested in what you all had to say.\n\nthank you!", "author_fullname": "t2_62ubafd4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can data science be used to learn aspects of history?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n0d4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678388101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am a 12th grader in a data science class and I chose my project to be on how data science can be used to learn aspects of history. I&amp;#39;m wondering what you all think about this, I&amp;#39;ve read some articles that were beneficial but I was interested in what you all had to say.&lt;/p&gt;\n\n&lt;p&gt;thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n0d4p", "is_robot_indexable": true, "report_reasons": null, "author": "smellykenma", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n0d4p/how_can_data_science_be_used_to_learn_aspects_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n0d4p/how_can_data_science_be_used_to_learn_aspects_of/", "subreddit_subscribers": 855608, "created_utc": 1678388101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Based on the below options, which 4 should I pick if I want to structure my degree for DS?  \n\n\n* Intro to Statistical inference\n* Advanced topics in Probability\n* Stochastic modelling\n* Optimisations in operations research\n* Applied Multivariable analysis\n* Applied time series analysis\n* Statistic modelling\n* Bayesian statistics\n* Statistical computing with R", "author_fullname": "t2_t6i1musl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best uni stats courses for DS/ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mq5lc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678362462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Based on the below options, which 4 should I pick if I want to structure my degree for DS?  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Intro to Statistical inference&lt;/li&gt;\n&lt;li&gt;Advanced topics in Probability&lt;/li&gt;\n&lt;li&gt;Stochastic modelling&lt;/li&gt;\n&lt;li&gt;Optimisations in operations research&lt;/li&gt;\n&lt;li&gt;Applied Multivariable analysis&lt;/li&gt;\n&lt;li&gt;Applied time series analysis&lt;/li&gt;\n&lt;li&gt;Statistic modelling&lt;/li&gt;\n&lt;li&gt;Bayesian statistics&lt;/li&gt;\n&lt;li&gt;Statistical computing with R&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mq5lc", "is_robot_indexable": true, "report_reasons": null, "author": "Capital-Duty-744", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mq5lc/best_uni_stats_courses_for_dsml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mq5lc/best_uni_stats_courses_for_dsml/", "subreddit_subscribers": 855608, "created_utc": 1678362462.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}