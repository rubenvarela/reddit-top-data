{"kind": "Listing", "data": {"after": "t3_11njdr6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I am working with a high-dimensional dataset that contains approximately 300 columns and 10,000 rows. The dataset is characterized by a significant number of columns with missing values. To gain a better understanding of the missing data patterns, I generated a nullity matrix, which revealed the following:   \n\n[nullity matrix](https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a)\n\n After careful consideration, I have devised a plan to divide the data into two datasets. The first dataset will consist of the first 5000 rows, while the second dataset will encompass the remaining rows after columns with a high number of missing values have been dropped. It is worth noting that the test dataset exhibits the same pattern of missing values, and will therefore undergo the same treatment. Subsequently, I will train my model using the first dataset to predict the outcomes of the first portion of the test data, and then repeat the process using the second dataset for the remaining portion of the test data. Is this approach valid, or is there a concern that important information will be lost? Do you have any suggestions for alternative, more optimal solutions for this particular challenge?", "author_fullname": "t2_7uwwf65z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dealing with a lot of missing values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6bhzfkds2qma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdb5bebc1d165d70a832076654f3a7abf1f76970"}, {"y": 85, "x": 216, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c89d13eb9dc5c2781ba7cb82e25d9105c46ff5d"}, {"y": 126, "x": 320, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89947b0fdead6015965d641b52eaa672a95a05c5"}, {"y": 252, "x": 640, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efb348a7397231cefb27c03771c0de886de6eb3a"}, {"y": 378, "x": 960, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d41d281c1a3be7b98132ebf631891c7e8203aaa5"}, {"y": 425, "x": 1080, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1bf1b4135b3ff68b23bf181e04612b2e2c08bc9"}], "s": {"y": 817, "x": 2074, "u": "https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a"}, "id": "6bhzfkds2qma1"}}, "name": "t3_11mtoua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Ai5OJ2cloS7xUaRLt83UptWtJpolBjcb2l13ISbhLM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678372315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with a high-dimensional dataset that contains approximately 300 columns and 10,000 rows. The dataset is characterized by a significant number of columns with missing values. To gain a better understanding of the missing data patterns, I generated a nullity matrix, which revealed the following:   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6bhzfkds2qma1.png?width=2074&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=68c05b771136c8e20f2b2a39d7bd0fbd15a3950a\"&gt;nullity matrix&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After careful consideration, I have devised a plan to divide the data into two datasets. The first dataset will consist of the first 5000 rows, while the second dataset will encompass the remaining rows after columns with a high number of missing values have been dropped. It is worth noting that the test dataset exhibits the same pattern of missing values, and will therefore undergo the same treatment. Subsequently, I will train my model using the first dataset to predict the outcomes of the first portion of the test data, and then repeat the process using the second dataset for the remaining portion of the test data. Is this approach valid, or is there a concern that important information will be lost? Do you have any suggestions for alternative, more optimal solutions for this particular challenge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mtoua", "is_robot_indexable": true, "report_reasons": null, "author": "Hamdi_bks", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mtoua/dealing_with_a_lot_of_missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mtoua/dealing_with_a_lot_of_missing_values/", "subreddit_subscribers": 855666, "created_utc": 1678372315.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is power BI inefficient?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nffdr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678424738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nffdr", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nffdr/is_power_bi_inefficient/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nffdr/is_power_bi_inefficient/", "subreddit_subscribers": 855666, "created_utc": 1678424738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m mentoring a junior data scientist on my team and we\u2019ve been going through the importance of exploratory data analysis. Most of the techniques I use are ones I\u2019ve just picked up or learned over time, but does anyone have any favorite resources (books, blog posts, videos, etc.) that put all these EDA best practices together? Like if you have x type of data, these are some recommended first steps for EDA? We\u2019re currently working on a lot of text data but more general EDA tips would be great as well.", "author_fullname": "t2_femmyhh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite resources for EDA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mz57q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678385283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m mentoring a junior data scientist on my team and we\u2019ve been going through the importance of exploratory data analysis. Most of the techniques I use are ones I\u2019ve just picked up or learned over time, but does anyone have any favorite resources (books, blog posts, videos, etc.) that put all these EDA best practices together? Like if you have x type of data, these are some recommended first steps for EDA? We\u2019re currently working on a lot of text data but more general EDA tips would be great as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mz57q", "is_robot_indexable": true, "report_reasons": null, "author": "umnosorry", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mz57q/favorite_resources_for_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mz57q/favorite_resources_for_eda/", "subreddit_subscribers": 855666, "created_utc": 1678385283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have doubts about when should we use Batch Gradient Descent vs Stochastic Gradient descent and why? Their Pros and Cons?\n\nWhile we're on this topic, can we discuss Mini-Batch Gradient descent?", "author_fullname": "t2_c9374irg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Batch vs Stochastic Gradient Descent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nev6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678423160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have doubts about when should we use Batch Gradient Descent vs Stochastic Gradient descent and why? Their Pros and Cons?&lt;/p&gt;\n\n&lt;p&gt;While we&amp;#39;re on this topic, can we discuss Mini-Batch Gradient descent?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nev6x", "is_robot_indexable": true, "report_reasons": null, "author": "fluman24", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nev6x/batch_vs_stochastic_gradient_descent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nev6x/batch_vs_stochastic_gradient_descent/", "subreddit_subscribers": 855666, "created_utc": 1678423160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_akn4dziw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What major would go well with a data science minor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nbb1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678413637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nbb1m", "is_robot_indexable": true, "report_reasons": null, "author": "dahnzii", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nbb1m/what_major_would_go_well_with_a_data_science_minor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nbb1m/what_major_would_go_well_with_a_data_science_minor/", "subreddit_subscribers": 855666, "created_utc": 1678413637.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello I'm looking for an open dataset for demand forecasting that has sales data, product data and price information for a number of different products, possibly across categories and including seasonality information. \n\nI'm also looking for instructive papers for baseline models and techniques used in demand forecasting or planning space. \n\nI've looked at lots of datasets online - kaggle, AWS, etc and I can't find a good one that fits my needs for FREE. Any help would be appreciated!", "author_fullname": "t2_bk9hp9qn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "demand forecasting datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n8bnt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678406201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello I&amp;#39;m looking for an open dataset for demand forecasting that has sales data, product data and price information for a number of different products, possibly across categories and including seasonality information. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also looking for instructive papers for baseline models and techniques used in demand forecasting or planning space. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at lots of datasets online - kaggle, AWS, etc and I can&amp;#39;t find a good one that fits my needs for FREE. Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n8bnt", "is_robot_indexable": true, "report_reasons": null, "author": "perfectlylonely13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n8bnt/demand_forecasting_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n8bnt/demand_forecasting_datasets/", "subreddit_subscribers": 855666, "created_utc": 1678406201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking for some free tools to get quick insights", "author_fullname": "t2_65chay6oh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good tools for exploratory data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n52b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678398839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some free tools to get quick insights&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n52b0", "is_robot_indexable": true, "report_reasons": null, "author": "Mona_Labs", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n52b0/what_are_some_good_tools_for_exploratory_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n52b0/what_are_some_good_tools_for_exploratory_data/", "subreddit_subscribers": 855666, "created_utc": 1678398839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience community,\n\nI have been invited to give a lecture on \"*data science in practice*\" for a class of MSc. business analytics students. While I plan on covering some technical aspects of the field, I believe that it might be worthwhile to focus more on the non-technical insights and tricks that one picks up after some time in industry. The things you don't learn on Kaggle.\n\nThis got me thinking: *What are the important non-technical lessons to you guys*? Perhaps it's the importance of effective communication skills, the ability to work collaboratively with colleagues from diverse backgrounds, or the value of prioritizing business needs over technical perfectionism.\n\nI'm hoping to compile a list of key takeaways to share with the class (and this subreddit), and your insights would be incredibly valuable. Whether you're a seasoned data scientist or just starting out, I'd love to hear your thoughts on this topic.\n\nTo start the conversation off, I have considered the following two points:\n\n\\- **How to choose DS projects:** For example, I find it helpful to score the potential project on \"feasibility\", \"scalability\", \"maintainability\" and \"business importance\". \n\n\\- **Understanding the differences in** ***data science maturity*** across sectors and organizations. For many organisations, the barriers to success with DS/ML/AI are strategic alignment, data availability/integrity etc. or executive sponsorship/buy-in - not the technical know-how.\n\nLooking forward to hearing your thoughts.\n\n\ud83d\udcf7\ud83d\udcf7", "author_fullname": "t2_26n50qtm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What non-technical lessons are important for aspiring data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n1xgt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678391695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I have been invited to give a lecture on &amp;quot;&lt;em&gt;data science in practice&lt;/em&gt;&amp;quot; for a class of MSc. business analytics students. While I plan on covering some technical aspects of the field, I believe that it might be worthwhile to focus more on the non-technical insights and tricks that one picks up after some time in industry. The things you don&amp;#39;t learn on Kaggle.&lt;/p&gt;\n\n&lt;p&gt;This got me thinking: &lt;em&gt;What are the important non-technical lessons to you guys&lt;/em&gt;? Perhaps it&amp;#39;s the importance of effective communication skills, the ability to work collaboratively with colleagues from diverse backgrounds, or the value of prioritizing business needs over technical perfectionism.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping to compile a list of key takeaways to share with the class (and this subreddit), and your insights would be incredibly valuable. Whether you&amp;#39;re a seasoned data scientist or just starting out, I&amp;#39;d love to hear your thoughts on this topic.&lt;/p&gt;\n\n&lt;p&gt;To start the conversation off, I have considered the following two points:&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;How to choose DS projects:&lt;/strong&gt; For example, I find it helpful to score the potential project on &amp;quot;feasibility&amp;quot;, &amp;quot;scalability&amp;quot;, &amp;quot;maintainability&amp;quot; and &amp;quot;business importance&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Understanding the differences in&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;data science maturity&lt;/em&gt;&lt;/strong&gt; across sectors and organizations. For many organisations, the barriers to success with DS/ML/AI are strategic alignment, data availability/integrity etc. or executive sponsorship/buy-in - not the technical know-how.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing your thoughts.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcf7\ud83d\udcf7&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n1xgt", "is_robot_indexable": true, "report_reasons": null, "author": "Academy-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n1xgt/what_nontechnical_lessons_are_important_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n1xgt/what_nontechnical_lessons_are_important_for/", "subreddit_subscribers": 855666, "created_utc": 1678391695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR\nGive me your best resources about this topic. Guides, implementation, but most importantly, I would like to receive some resources that let me understand all the parameters I could change and how it affects the learning.\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nI have recently find out a possible approach for my problem (predictive maintenance) could be tackled using LSTM Autoencoders.\nThe idea is to learn normal representation of  my data (that is multi variate, I have more than 20 features), and then test some time intervals to see if the MAE or some other measure increase over a certain chosen threshold. \n\nSome doubts:\n-Historical data for my sensors cover more than 1 month and time steps are every 5 seconds.\nI would like to learn short temporal patterns since I am not sure if LSTM can handle large temporal series. So my sample is made of 180 timesteps(15 minutes in total). How to improve this?\n-Also how to handle the encoder decoder architecture? I mean since I have 10000 samples of 180 timesteps and each sample has multiple features per timestep, what can be the structure of the LSTM? \n-Also feel free to post every good resources you have used in the past about this", "author_fullname": "t2_i6lyoywf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSTM AutoEncoders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n6z1q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678403061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR\nGive me your best resources about this topic. Guides, implementation, but most importantly, I would like to receive some resources that let me understand all the parameters I could change and how it affects the learning.\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;I have recently find out a possible approach for my problem (predictive maintenance) could be tackled using LSTM Autoencoders.\nThe idea is to learn normal representation of  my data (that is multi variate, I have more than 20 features), and then test some time intervals to see if the MAE or some other measure increase over a certain chosen threshold. &lt;/p&gt;\n\n&lt;p&gt;Some doubts:\n-Historical data for my sensors cover more than 1 month and time steps are every 5 seconds.\nI would like to learn short temporal patterns since I am not sure if LSTM can handle large temporal series. So my sample is made of 180 timesteps(15 minutes in total). How to improve this?\n-Also how to handle the encoder decoder architecture? I mean since I have 10000 samples of 180 timesteps and each sample has multiple features per timestep, what can be the structure of the LSTM? \n-Also feel free to post every good resources you have used in the past about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n6z1q", "is_robot_indexable": true, "report_reasons": null, "author": "ginotherhino1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n6z1q/lstm_autoencoders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n6z1q/lstm_autoencoders/", "subreddit_subscribers": 855666, "created_utc": 1678403061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I got my bachelors in structural engineering. I\u2019ve been working in the field for 6 years now but the industry doesn\u2019t pay well and the technologies are pretty antiquated. I was hoping to transition to the tech world while also applying my structural engineering background. I\u2019m curious about ML and could foresee some crossover between the two fields. The machine learning programs I\u2019m applying to are rejecting me saying that my background isn\u2019t compatible. I\u2019m wondering if it\u2019s because I don\u2019t have a lot of experience with probability and statistics. What could I do to close that gap so that they think I\u2019m ready for the program? Could anyone suggest any programs that would suit my situation? Or if you have any advice in general?", "author_fullname": "t2_emztpeug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science for structural engineers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nfrex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678425739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I got my bachelors in structural engineering. I\u2019ve been working in the field for 6 years now but the industry doesn\u2019t pay well and the technologies are pretty antiquated. I was hoping to transition to the tech world while also applying my structural engineering background. I\u2019m curious about ML and could foresee some crossover between the two fields. The machine learning programs I\u2019m applying to are rejecting me saying that my background isn\u2019t compatible. I\u2019m wondering if it\u2019s because I don\u2019t have a lot of experience with probability and statistics. What could I do to close that gap so that they think I\u2019m ready for the program? Could anyone suggest any programs that would suit my situation? Or if you have any advice in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nfrex", "is_robot_indexable": true, "report_reasons": null, "author": "DisplayImpossible771", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nfrex/data_science_for_structural_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nfrex/data_science_for_structural_engineers/", "subreddit_subscribers": 855666, "created_utc": 1678425739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The project I'm currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.\n\nWe are going to be expanding our data size by something like 4x-20x in the next year or two.\n\nWe want to find examples of companies doing similar data work to us, and seeing how they managed their data.\n\nOur main setup is:\n\n1. Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.\n2. Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.\n3. Post processing Feature values. We have a database of post processing features so we don't need to process the raw data each time we do a model training run.\n\nThe setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.\n\nAre there any good resources on how more established companies manage this setup?", "author_fullname": "t2_80ont", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blog posts detailing ML companies data infrastructure / DB schema?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mzo1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678386478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The project I&amp;#39;m currently working on uses (relatively) small tables / DB sizes. We have a setup that is appropriate for our current size of team, size of data, ease of use to maintain, ease of use to extract, etc.&lt;/p&gt;\n\n&lt;p&gt;We are going to be expanding our data size by something like 4x-20x in the next year or two.&lt;/p&gt;\n\n&lt;p&gt;We want to find examples of companies doing similar data work to us, and seeing how they managed their data.&lt;/p&gt;\n\n&lt;p&gt;Our main setup is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Raw data (in the thousands of records, with thousands of datapoints, so relatively small all things considered). This is not expanding much.&lt;/li&gt;\n&lt;li&gt;Raw data processing pipelines. This is where the 4x-20x is coming from. We can edit the processing pipeline to give us different output features.&lt;/li&gt;\n&lt;li&gt;Post processing Feature values. We have a database of post processing features so we don&amp;#39;t need to process the raw data each time we do a model training run.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The setup as described above must be quite common - storing post processed feature values. Then combining different sets of features to do model training runs.&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources on how more established companies manage this setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mzo1f", "is_robot_indexable": true, "report_reasons": null, "author": "Cwlrs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mzo1f/blog_posts_detailing_ml_companies_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mzo1f/blog_posts_detailing_ml_companies_data/", "subreddit_subscribers": 855666, "created_utc": 1678386478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1zz7cefa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating operations on column-based data across multiple files using the Codex Davinci model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11msd2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/yl1xdh05upma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yl1xdh05upma1/DASH_96.mp4", "dash_url": "https://v.redd.it/yl1xdh05upma1/DASHPlaylist.mpd?a=1681040314%2CZjJmZDMwNDRhY2RkNTllYmM2NjY2Zjc3YWEzMWRmOTVhMzQwOWYxMDczMjllNWI1Y2VhOTcwZTRlNjM0NmM1Zg%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/yl1xdh05upma1/HLSPlaylist.m3u8?a=1681040314%2CY2ZlYTBkYmRiODQ2N2ViMzQyMDFmNjZiOTNiMDg4MDAxMjgxNjQ2MGNhY2M0NmE2ZjVkMWNlNDJkZDgxMWE3OA%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3J_Y0ezmKHiH2pX98m0wBU4FKskQlwwJWUkTGBqnLc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678368970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/yl1xdh05upma1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a08af611da44165a74d1c8e4a6ba151b3cfe8225", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=173556aff19a963730bb5c13645b06e0c87d2888", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8c9e849efa9fd3666c8c68dcf92fb8a5ba962ea2", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7df886a3ceab54f2068538fe5828182fd267d7b0", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=32ef900b4ae0be5098352535f6183c1558a595c2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5d00980b8129c1e403c574d5a1f4fd9296db4e19", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/zWzZYky2xe72zhpvlhfgSk3FnUP4VDziPj6VjOZ-h40.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6b0e9f98d5bf740c90650d6f66966a5f320ba66a", "width": 1080, "height": 607}], "variants": {}, "id": "sD1ViAqbGBOUiDB-PrxLdzGJ96XYSJnGoymD9gu3uww"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11msd2v", "is_robot_indexable": true, "report_reasons": null, "author": "kijubikal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11msd2v/automating_operations_on_columnbased_data_across/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/yl1xdh05upma1", "subreddit_subscribers": 855666, "created_utc": 1678368970.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/yl1xdh05upma1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/yl1xdh05upma1/DASH_96.mp4", "dash_url": "https://v.redd.it/yl1xdh05upma1/DASHPlaylist.mpd?a=1681040314%2CZjJmZDMwNDRhY2RkNTllYmM2NjY2Zjc3YWEzMWRmOTVhMzQwOWYxMDczMjllNWI1Y2VhOTcwZTRlNjM0NmM1Zg%3D%3D&amp;v=1&amp;f=sd", "duration": 19, "hls_url": "https://v.redd.it/yl1xdh05upma1/HLSPlaylist.m3u8?a=1681040314%2CY2ZlYTBkYmRiODQ2N2ViMzQyMDFmNjZiOTNiMDg4MDAxMjgxNjQ2MGNhY2M0NmE2ZjVkMWNlNDJkZDgxMWE3OA%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello people,\n\nI look for reference books for cleaning time series datasets. can anyone help me with this request.\n\nthanks", "author_fullname": "t2_eikjje19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "time series data cleaning reference books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mrkmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678366811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people,&lt;/p&gt;\n\n&lt;p&gt;I look for reference books for cleaning time series datasets. can anyone help me with this request.&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mrkmz", "is_robot_indexable": true, "report_reasons": null, "author": "jorgecormane", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mrkmz/time_series_data_cleaning_reference_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mrkmz/time_series_data_cleaning_reference_books/", "subreddit_subscribers": 855666, "created_utc": 1678366811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leading Technology Event - Big Data &amp; AI World 8-9 March, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "name": "t3_11mqftc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/05_goNF3kF_nE5zdGN6lwz4PVQTtvoB0uDyUhHCwjxo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678363345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/newsroom/discover-the-intelligent-future-at-big-data-ai-world-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?auto=webp&amp;v=enabled&amp;s=de57f865cc5e42243d5235a4715c71954269bf68", "width": 1600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adefb8b91ad01ebd34517d171d938b01bf5b8c66", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130ce02b62410f3ed6685924e4fad97aa13a0f04", "width": 216, "height": 81}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6ce1c7599c569b518259aecb7cb2d35a806b26b", "width": 320, "height": 120}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72ee3e8af1bf03361ac42916120b0d876e4d67ae", "width": 640, "height": 240}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=436adb0f6d9229cb591781aede5f372aab9eaaba", "width": 960, "height": 360}, {"url": "https://external-preview.redd.it/ZgSJAptt01NNKV_Cl-8-8PbzYtGuKaGM66kIRUpeXO8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f94cf3246648acceb7000a1bea76ef45d413850", "width": 1080, "height": 405}], "variants": {}, "id": "aFdnRqHZhCc_vlA3H683TQXP5YJ0qnajroSr9Kd4K0M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mqftc", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mqftc/leading_technology_event_big_data_ai_world_89/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/newsroom/discover-the-intelligent-future-at-big-data-ai-world-2023", "subreddit_subscribers": 855666, "created_utc": 1678363345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been working in a startup for 6 years now and it's been 3 years as a data scientist and ML engineer in the same company, but now I want to switch, so what salary can I expect and what should I answer when an HR asks about my expectations, also what is the industry standard salary for my experience? currently I am getting around 7LPA.\nIt'll be good if people can help me considering I am from India and I am asking in Indian context.", "author_fullname": "t2_srvlx6v7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What salary should I expect while switching after 6 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nkdjg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678440528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working in a startup for 6 years now and it&amp;#39;s been 3 years as a data scientist and ML engineer in the same company, but now I want to switch, so what salary can I expect and what should I answer when an HR asks about my expectations, also what is the industry standard salary for my experience? currently I am getting around 7LPA.\nIt&amp;#39;ll be good if people can help me considering I am from India and I am asking in Indian context.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nkdjg", "is_robot_indexable": true, "report_reasons": null, "author": "Adi1794", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nkdjg/what_salary_should_i_expect_while_switching_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nkdjg/what_salary_should_i_expect_while_switching_after/", "subreddit_subscribers": 855666, "created_utc": 1678440528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an IB (International Baccalaureat) student working on my EE (Extended Essay) in physics. I am investigating the oscillation system with a mass attached to a spring, and let it swing. Our school bought a licence for a data logging- and analysis software called \"Logger pro\". It was a one time download from a link and is not connected to the web, and it has a key feature that I need: The video analysis, where it could basically produce a graph by tracking a moving object in a video.\n\n[This is version 3.9, I don't know how old it is.](https://preview.redd.it/n6xa3p8upvma1.png?width=1006&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a7d037f92f8083ad815aa8c5ae26dc712dc22989)\n\nHowever, as in the picture shown my \"Video Capture\" option is grey and not usable. It worked on all other devices with it installed, and my teacher couldn't explain either. I am on windows 11, and I have had ideas that maybe it only supports Mac, but this software is only for windows. Does anybody know why I it is not working? Does it simply not support windows 11? If so, are there any alternative software that can produce a graph from video (Ideally free, but paid is fine too)? Any help is appreciated.", "author_fullname": "t2_cfxchzrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Logger pro not working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"n6xa3p8upvma1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20d1f91a8516482201fa109c242c78ad6f707b2e"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0be45b329c03de3fa1ce47f9db5dd512eb346188"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c6f32a2898086bd17d03d71cd5bfd4dbcc77fa8"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30c5eb99b68f17a60675917a8da3dce874b44571"}, {"y": 501, "x": 960, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b3873cf020ada5b47361b74c9846e9d52ecc748"}], "s": {"y": 526, "x": 1006, "u": "https://preview.redd.it/n6xa3p8upvma1.png?width=1006&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a7d037f92f8083ad815aa8c5ae26dc712dc22989"}, "id": "n6xa3p8upvma1"}}, "name": "t3_11nkbxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eNVLg2nNB6tkiYHUK8q6VUCk2677Doffu15L6kxkm0M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678440370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an IB (International Baccalaureat) student working on my EE (Extended Essay) in physics. I am investigating the oscillation system with a mass attached to a spring, and let it swing. Our school bought a licence for a data logging- and analysis software called &amp;quot;Logger pro&amp;quot;. It was a one time download from a link and is not connected to the web, and it has a key feature that I need: The video analysis, where it could basically produce a graph by tracking a moving object in a video.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/n6xa3p8upvma1.png?width=1006&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a7d037f92f8083ad815aa8c5ae26dc712dc22989\"&gt;This is version 3.9, I don&amp;#39;t know how old it is.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, as in the picture shown my &amp;quot;Video Capture&amp;quot; option is grey and not usable. It worked on all other devices with it installed, and my teacher couldn&amp;#39;t explain either. I am on windows 11, and I have had ideas that maybe it only supports Mac, but this software is only for windows. Does anybody know why I it is not working? Does it simply not support windows 11? If so, are there any alternative software that can produce a graph from video (Ideally free, but paid is fine too)? Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nkbxz", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Function778", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nkbxz/logger_pro_not_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nkbxz/logger_pro_not_working/", "subreddit_subscribers": 855666, "created_utc": 1678440370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, this is my first ever reddit post , but i feel like i need to ask for an advice. I\u2019ve done my masters in data science in Australia as an international student. I graduated two years ago and got occupied doing some random jobs cause was good money. I wanna get back into data science but don\u2019t know where to start. In my masters I\u2019ve studied python, R, PySpark,sql  but don\u2019t feel confident anymore. I need to start somewhere and from where i do not know..!! Please help", "author_fullname": "t2_6n0tvi3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nk880", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678440016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, this is my first ever reddit post , but i feel like i need to ask for an advice. I\u2019ve done my masters in data science in Australia as an international student. I graduated two years ago and got occupied doing some random jobs cause was good money. I wanna get back into data science but don\u2019t know where to start. In my masters I\u2019ve studied python, R, PySpark,sql  but don\u2019t feel confident anymore. I need to start somewhere and from where i do not know..!! Please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nk880", "is_robot_indexable": true, "report_reasons": null, "author": "jahanav_1011", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nk880/career_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nk880/career_in_data_science/", "subreddit_subscribers": 855666, "created_utc": 1678440016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHello everyone,\n\nI am currently working on creating a chatbot that can recommend solutions to log errors that occur in Java applications. To do this, I need a dataset that contains examples of log errors along with their corresponding solutions. I am hoping to find a dataset that is large enough to train a machine learning model to accurately suggest solutions based on the log error message.\n\nIf anyone knows of a dataset that would be helpful for this project or has any suggestions on where to find one, I would greatly appreciate it. Any information or assistance would be extremely valuable to me.\n\nThank you for your time and consideration.", "author_fullname": "t2_f4ljltqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a dataset to train a chatbot for recommending solutions to Java application log errors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11njj3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678437623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on creating a chatbot that can recommend solutions to log errors that occur in Java applications. To do this, I need a dataset that contains examples of log errors along with their corresponding solutions. I am hoping to find a dataset that is large enough to train a machine learning model to accurately suggest solutions based on the log error message.&lt;/p&gt;\n\n&lt;p&gt;If anyone knows of a dataset that would be helpful for this project or has any suggestions on where to find one, I would greatly appreciate it. Any information or assistance would be extremely valuable to me.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and consideration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11njj3h", "is_robot_indexable": true, "report_reasons": null, "author": "Farjou69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11njj3h/looking_for_a_dataset_to_train_a_chatbot_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11njj3h/looking_for_a_dataset_to_train_a_chatbot_for/", "subreddit_subscribers": 855666, "created_utc": 1678437623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working in ABAP programming language and it is super boring and outdated. I have good understanding of JAVA/Python  ,OOPS, Basic DSA ,Baic ML and want to switch to a data science career. I have graduation in non CS engineering. Any experienced data engineers/scientists professionals who can guide me on what strategies would be best to follow. I dont have any location constraints. I am 25,willing to relocate for a good work experience.Please help me..I am getting lost day by day.", "author_fullname": "t2_ua8ealox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "switch career to Data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11nj8kj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678436584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working in ABAP programming language and it is super boring and outdated. I have good understanding of JAVA/Python  ,OOPS, Basic DSA ,Baic ML and want to switch to a data science career. I have graduation in non CS engineering. Any experienced data engineers/scientists professionals who can guide me on what strategies would be best to follow. I dont have any location constraints. I am 25,willing to relocate for a good work experience.Please help me..I am getting lost day by day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nj8kj", "is_robot_indexable": true, "report_reasons": null, "author": "Cricket_umpire", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nj8kj/switch_career_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nj8kj/switch_career_to_data_science/", "subreddit_subscribers": 855666, "created_utc": 1678436584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not sure if \u201cheterogeneous\u201d is the right word here but I\u2019m doing KRR where features that appear to be more suited to a power/log transform, some more suited for centering to 0 mean and unit variance. If I\u2019m manually choosing \u201chow\u201d to encode each feature, maybe I should upgrade to a fancier model, like a a neural network with VAE? Curious to hear opinions on this.", "author_fullname": "t2_1k2rzmpm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mixed Feature Transformers for highly heterogeneous data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11n1yol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678391771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if \u201cheterogeneous\u201d is the right word here but I\u2019m doing KRR where features that appear to be more suited to a power/log transform, some more suited for centering to 0 mean and unit variance. If I\u2019m manually choosing \u201chow\u201d to encode each feature, maybe I should upgrade to a fancier model, like a a neural network with VAE? Curious to hear opinions on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11n1yol", "is_robot_indexable": true, "report_reasons": null, "author": "vent2012", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11n1yol/mixed_feature_transformers_for_highly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11n1yol/mixed_feature_transformers_for_highly/", "subreddit_subscribers": 855666, "created_utc": 1678391771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI have a question regarding encoding high cardinality categorical variables and learning embedding vectors.\n\nTo make the explanation easier, I will take the example of columns representing ingredients for a recipe. They are categorical variables:\n\nProtein (meat, fish, eggs, beans, etc.)\n\nGrains (wheat, rice, oat, etc.)\n\nSpices (cinammon, cumin, ginger, etc.)\n\nBecause some recipes contain more than 1 protein, or more than 1 spice, these columns appear multiple times (Spice\\_1, Spice\\_2, Spice\\_3, etc.)\n\nQuestion 1: Is it reasonable to label encode Spice\\_1, Spice\\_2, Spice\\_3 simulateneously? \n\nQuestion 2: My main goal here is to learn embeddings to represent all these categories. Typically, we can use embedding layers to learn the mapping between categories and a dense vector representation for each feature and its associated categories.\n\nIn my case, by following this approach, I end up with different embedding representation of the same spice, depending if it was in Spice\\_1 column, Spice\\_2 column, etc.\n\nWhat would be the best way to ensure that the embeddings learned for similar features (Spice\\_1, Spice\\_2, Spice\\_3) do match?\n\nPlease note that I am actually working with chemical codes, so pretrained language models cannot be leveraged.\n\nThank you for your suggestions!", "author_fullname": "t2_19qf9hu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Learning consistent embeddings across multiple features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mvn4z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678377096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question regarding encoding high cardinality categorical variables and learning embedding vectors.&lt;/p&gt;\n\n&lt;p&gt;To make the explanation easier, I will take the example of columns representing ingredients for a recipe. They are categorical variables:&lt;/p&gt;\n\n&lt;p&gt;Protein (meat, fish, eggs, beans, etc.)&lt;/p&gt;\n\n&lt;p&gt;Grains (wheat, rice, oat, etc.)&lt;/p&gt;\n\n&lt;p&gt;Spices (cinammon, cumin, ginger, etc.)&lt;/p&gt;\n\n&lt;p&gt;Because some recipes contain more than 1 protein, or more than 1 spice, these columns appear multiple times (Spice_1, Spice_2, Spice_3, etc.)&lt;/p&gt;\n\n&lt;p&gt;Question 1: Is it reasonable to label encode Spice_1, Spice_2, Spice_3 simulateneously? &lt;/p&gt;\n\n&lt;p&gt;Question 2: My main goal here is to learn embeddings to represent all these categories. Typically, we can use embedding layers to learn the mapping between categories and a dense vector representation for each feature and its associated categories.&lt;/p&gt;\n\n&lt;p&gt;In my case, by following this approach, I end up with different embedding representation of the same spice, depending if it was in Spice_1 column, Spice_2 column, etc.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to ensure that the embeddings learned for similar features (Spice_1, Spice_2, Spice_3) do match?&lt;/p&gt;\n\n&lt;p&gt;Please note that I am actually working with chemical codes, so pretrained language models cannot be leveraged.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mvn4z", "is_robot_indexable": true, "report_reasons": null, "author": "DreamyPen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mvn4z/d_learning_consistent_embeddings_across_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mvn4z/d_learning_consistent_embeddings_across_multiple/", "subreddit_subscribers": 855666, "created_utc": 1678377096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've seen that my university is organizing small training for Statistica software. I wonder if it's worth to go for it. I've never heard of this software so I would like to know how relevant is it in current marketplace", "author_fullname": "t2_tzpsm3bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth to learn Statistica?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mua99", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678373817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen that my university is organizing small training for Statistica software. I wonder if it&amp;#39;s worth to go for it. I&amp;#39;ve never heard of this software so I would like to know how relevant is it in current marketplace&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mua99", "is_robot_indexable": true, "report_reasons": null, "author": "PlusPlusMan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mua99/is_it_worth_to_learn_statistica/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mua99/is_it_worth_to_learn_statistica/", "subreddit_subscribers": 855666, "created_utc": 1678373817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone! \n\nI'm currently looking for a dataset that would contain both ticket data and logs data (that was used to create the tickets or to solve it). \n\nI managed to find separate datasets for tickets or logs but I would need something that combines both, are you aware of such a dataset or a way to create it ?", "author_fullname": "t2_mi18lm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any logs + ticketing dataset available ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11mszw0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678370581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking for a dataset that would contain both ticket data and logs data (that was used to create the tickets or to solve it). &lt;/p&gt;\n\n&lt;p&gt;I managed to find separate datasets for tickets or logs but I would need something that combines both, are you aware of such a dataset or a way to create it ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11mszw0", "is_robot_indexable": true, "report_reasons": null, "author": "GuinsooIsOverrated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11mszw0/any_logs_ticketing_dataset_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11mszw0/any_logs_ticketing_dataset_available/", "subreddit_subscribers": 855666, "created_utc": 1678370581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m training random forest classifier model on a dataset which contains account numbers- [56,57,58,59,60,61]. By doing train_test_split I\u2019m getting model performance as 96% (accuracy). Now when I use this dataset as my training data and a new data which contains all the above account numbers and also  unseen records, it\u2019s giving 95% accuracy which is good.\nBut when I test this model on the same new data with filtered account numbers(say [56,57]), the model performance is 71%. \n\nIs this expected? I would appreciate if someone explains the reason if this is expected? If not, what\u2019s the error?\n\n\nThanks!", "author_fullname": "t2_p657jjww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Random forest classifier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11nll8a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678444566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m training random forest classifier model on a dataset which contains account numbers- [56,57,58,59,60,61]. By doing train_test_split I\u2019m getting model performance as 96% (accuracy). Now when I use this dataset as my training data and a new data which contains all the above account numbers and also  unseen records, it\u2019s giving 95% accuracy which is good.\nBut when I test this model on the same new data with filtered account numbers(say [56,57]), the model performance is 71%. &lt;/p&gt;\n\n&lt;p&gt;Is this expected? I would appreciate if someone explains the reason if this is expected? If not, what\u2019s the error?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11nll8a", "is_robot_indexable": true, "report_reasons": null, "author": "tinkerpal", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11nll8a/random_forest_classifier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11nll8a/random_forest_classifier/", "subreddit_subscribers": 855666, "created_utc": 1678444566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am writing a paper on the topic and I am wondering which methods could be used for anomaly detection in time-series that utilize forecasting methods.\n\nThe overall picture I have is that:\n1. I do a forecast\n2. I calculate the error (and rolling average)\n3. I classify points that fall outside of forecast's confidence interval as anomalies\n\nIs that a sound method? What other methods could be used?\nWould anomaly detection method also depend on the type of forecasting model (ex.: Arima, LSTM etc.)?\nI would also very much appreciate any literature recommendations on the topic :)", "author_fullname": "t2_6sak8q8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect anomalies in time-series with forecasting methods?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11njdr6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678437091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am writing a paper on the topic and I am wondering which methods could be used for anomaly detection in time-series that utilize forecasting methods.&lt;/p&gt;\n\n&lt;p&gt;The overall picture I have is that:\n1. I do a forecast\n2. I calculate the error (and rolling average)\n3. I classify points that fall outside of forecast&amp;#39;s confidence interval as anomalies&lt;/p&gt;\n\n&lt;p&gt;Is that a sound method? What other methods could be used?\nWould anomaly detection method also depend on the type of forecasting model (ex.: Arima, LSTM etc.)?\nI would also very much appreciate any literature recommendations on the topic :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11njdr6", "is_robot_indexable": true, "report_reasons": null, "author": "moonkin1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11njdr6/how_to_detect_anomalies_in_timeseries_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11njdr6/how_to_detect_anomalies_in_timeseries_with/", "subreddit_subscribers": 855666, "created_utc": 1678437091.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}