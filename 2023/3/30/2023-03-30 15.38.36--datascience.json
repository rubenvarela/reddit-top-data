{"kind": "Listing", "data": {"after": "t3_126atge", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey!\n\n&amp;#x200B;\n\nMy friend, a Ph.D. student in Computer Science at Oxford and an MSc graduate from Cambridge, and I (a Backend Engineer), started a reading club where we go through 20 research papers that cover 80% of what matters today\n\nOur goal is to read one paper a week, then meet to discuss it and share knowledge, and insights and keep each other accountable, etc.\n\nI shared it with a few friends and was surprised by the high interest to join.\n\nSo I decided to invite you guys to join us as well.\n\nWe are looking for ML enthusiasts that want to join our reading clubs (there are already 3 groups).\n\nThe concept is simple - we have a discord that hosts all of the \u201creaders\u201d and I split all readers (by their background) into small groups of 6, some of them are more active (doing additional exercises, etc it depends on you.), and some are less demanding and mostly focus on reading the papers.\n\nAs for prerequisites, I think its recommended to have at least BSC in CS or equivalent knowledge and the ability to read scientific papers in English\n\n&amp;#x200B;\n\nIf any of you are interested to join please comment below\n\nAnd if you have any suggestions feel free to let me know\n\n&amp;#x200B;\n\nSome of the articles on our list:\n\n* Attention is all you need\n* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n* A Style-Based Generator Architecture for Generative Adversarial Networks\n* Mastering the Game of Go with Deep Neural Networks and Tree Search\n* Deep Neural Networks for YouTube Recommendations", "author_fullname": "t2_8lm3cr0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We are opening a Reading Club for ML papers. Who wants to join? \ud83c\udf93", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_125xdzd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 240, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 240, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680116443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My friend, a Ph.D. student in Computer Science at Oxford and an MSc graduate from Cambridge, and I (a Backend Engineer), started a reading club where we go through 20 research papers that cover 80% of what matters today&lt;/p&gt;\n\n&lt;p&gt;Our goal is to read one paper a week, then meet to discuss it and share knowledge, and insights and keep each other accountable, etc.&lt;/p&gt;\n\n&lt;p&gt;I shared it with a few friends and was surprised by the high interest to join.&lt;/p&gt;\n\n&lt;p&gt;So I decided to invite you guys to join us as well.&lt;/p&gt;\n\n&lt;p&gt;We are looking for ML enthusiasts that want to join our reading clubs (there are already 3 groups).&lt;/p&gt;\n\n&lt;p&gt;The concept is simple - we have a discord that hosts all of the \u201creaders\u201d and I split all readers (by their background) into small groups of 6, some of them are more active (doing additional exercises, etc it depends on you.), and some are less demanding and mostly focus on reading the papers.&lt;/p&gt;\n\n&lt;p&gt;As for prerequisites, I think its recommended to have at least BSC in CS or equivalent knowledge and the ability to read scientific papers in English&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If any of you are interested to join please comment below&lt;/p&gt;\n\n&lt;p&gt;And if you have any suggestions feel free to let me know&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Some of the articles on our list:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Attention is all you need&lt;/li&gt;\n&lt;li&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/li&gt;\n&lt;li&gt;A Style-Based Generator Architecture for Generative Adversarial Networks&lt;/li&gt;\n&lt;li&gt;Mastering the Game of Go with Deep Neural Networks and Tree Search&lt;/li&gt;\n&lt;li&gt;Deep Neural Networks for YouTube Recommendations&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "125xdzd", "is_robot_indexable": true, "report_reasons": null, "author": "__god_bless_you_", "discussion_type": null, "num_comments": 319, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125xdzd/we_are_opening_a_reading_club_for_ml_papers_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/125xdzd/we_are_opening_a_reading_club_for_ml_papers_who/", "subreddit_subscribers": 865134, "created_utc": 1680116443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_uc4m6si", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my data overfitting? I\u2019m new to this, this is my first lstm model and my RSME was 0.02 so I\u2019m just confused if it\u2019s a good model or it\u2019s overfitting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_125qy42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 164, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 164, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/g1hkTOkhJ6n0eL6BZQhw3X7U7wpG_tsB9M1gFQQZir0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680102404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/654jtsb1jqqa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?auto=webp&amp;v=enabled&amp;s=1fa9a8b1e22b41d826db97866ad15e3f04634212", "width": 1172, "height": 876}, "resolutions": [{"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fae1dc5f3ca2f5bf89290dc838091f4f0f4760cd", "width": 108, "height": 80}, {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57890605f461879b4b6fd8e46b348e2c996c4d5b", "width": 216, "height": 161}, {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3a07cbbe28543505fad1caac0489283fda6a3fb", "width": 320, "height": 239}, {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afc07c831be2e1862e06faa5a8d003cfc9bfcda8", "width": 640, "height": 478}, {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6876426c8b4e0b3b219ac78b82ac44c0fcaae0f0", "width": 960, "height": 717}, {"url": "https://preview.redd.it/654jtsb1jqqa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d374a41437c545b18a6d38bcbeba42d1745047f", "width": 1080, "height": 807}], "variants": {}, "id": "Qk3cI4fUvcxPB4YGsEhHKDX2Le3gNLmCGdQkguX_iwo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "125qy42", "is_robot_indexable": true, "report_reasons": null, "author": "wolfy14xc", "discussion_type": null, "num_comments": 154, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125qy42/is_my_data_overfitting_im_new_to_this_this_is_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/654jtsb1jqqa1.jpg", "subreddit_subscribers": 865134, "created_utc": 1680102404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My gf is looking into getting either a 2nd bachelors in DS (1st in writing &amp; rhetoric), or a masters in DS.\n\nWe habe done a ton of research and understand the massive undertaking the Masters would be.\n\nBut my main question, is DS as saturated as CS is? Essentially, would she be applying to 500 jobs a year like how many CS professionals describe their job hunts? Or is DS a little easier to get your foot in the door after a degree?\n\nEdit: What about Data Analysis rather than Data Science?", "author_fullname": "t2_udik4eoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is DS as saturated as CS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1262705", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680138455.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680127363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My gf is looking into getting either a 2nd bachelors in DS (1st in writing &amp;amp; rhetoric), or a masters in DS.&lt;/p&gt;\n\n&lt;p&gt;We habe done a ton of research and understand the massive undertaking the Masters would be.&lt;/p&gt;\n\n&lt;p&gt;But my main question, is DS as saturated as CS is? Essentially, would she be applying to 500 jobs a year like how many CS professionals describe their job hunts? Or is DS a little easier to get your foot in the door after a degree?&lt;/p&gt;\n\n&lt;p&gt;Edit: What about Data Analysis rather than Data Science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1262705", "is_robot_indexable": true, "report_reasons": null, "author": "Patient-Device-1135", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1262705/is_ds_as_saturated_as_cs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1262705/is_ds_as_saturated_as_cs/", "subreddit_subscribers": 865134, "created_utc": 1680127363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You have to present your work to your team to show value in data science. It\u2019s a sticky situation: your company hasn\u2019t reached data maturity\u2014it\u2019s early days. \n\nHow would you decide to communicate outcomes: data engineering successes, small low hanging fruit automation pipelines, dashboards? \n\nMy goal is to communicate outcomes and show data engineering value. I\u2019d like to do a high level presentation, and show how it\u2019s success is linked to our units targets. \n\nI\u2019m a bit lost on where to even start, and I can feel the imposter syndrome: I feel it\u2019s pointless and I\u2019m not that great. \n\nA bit lost.", "author_fullname": "t2_hs2wdeu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You\u2019re a solo data scientist, how do you communicate your work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126kas6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680176055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You have to present your work to your team to show value in data science. It\u2019s a sticky situation: your company hasn\u2019t reached data maturity\u2014it\u2019s early days. &lt;/p&gt;\n\n&lt;p&gt;How would you decide to communicate outcomes: data engineering successes, small low hanging fruit automation pipelines, dashboards? &lt;/p&gt;\n\n&lt;p&gt;My goal is to communicate outcomes and show data engineering value. I\u2019d like to do a high level presentation, and show how it\u2019s success is linked to our units targets. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m a bit lost on where to even start, and I can feel the imposter syndrome: I feel it\u2019s pointless and I\u2019m not that great. &lt;/p&gt;\n\n&lt;p&gt;A bit lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126kas6", "is_robot_indexable": true, "report_reasons": null, "author": "Livid-Shirt8831", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126kas6/youre_a_solo_data_scientist_how_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126kas6/youre_a_solo_data_scientist_how_do_you/", "subreddit_subscribers": 865134, "created_utc": 1680176055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey /r/datascience! We're building an open-source Python framework which makes it simple to build data-centric web applications. Today Datapane lets you build reports and full-stack apps in ~10 lines of Python, but our goal is to provide all the tools data teams need to create end-to-end internal apps (such as scheduled tasks, auth, integrations, OLAP) in a simple, standardized framework.\n\nOur GitHub is [https://github.com/datapane/datapane](https://github.com/datapane/datapane/) and you can get started here: https://docs.datapane.com/quickstart/\n\nDeploying internal data products requires a bunch of complex moving pieces, e.g. a front-end UI framework, backend server + REST/GraphQL, scheduled tasks, backend workers, caching, integrations into Slack/email, scheduled reports, and often a data layer for OLAP \u2013 the list goes on. Unsurprisingly, many companies opt to buy from external vendors instead of building in-house analytics products using open-source, as this usually requires months of development time and multiple teams.\n\nDatapane is a unified app framework which provides all the necessary parts of an internal data product, in a simple, Pythonic package, including:\n\n- A Python-based UI framework for constructing HTML views from data-centric blocks \u2013 like Plotly plots and pandas DataFrames. You can generate these from inside of pipelines, a Jupyter notebook, or on a schedule, and export\u00a0as standalone HTML reports or static web apps.\n- Ability to build data science web apps by connecting Python functions to forms and front-end events. You can check out an example of the code to create a simple app: [https://github.com/datapane/examples/blob/main/apps/iris-plotter/app.py](https://github.com/datapane/examples/blob/main/apps/iris-plotter/app.py)\n- Currently, we\u2019re adding support for background tasks, scheduled tasks, and a DuckDB-based data layer for OLAP, so you can ship a complete end-to-end app.\n\nWe would love your feedback and hear what you find difficult about building data apps so we can prioritize. You can also see a few apps we\u2019ve built already in our gallery: https://datapane.com/gallery\n\nThanks!", "author_fullname": "t2_7l5ng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datapane - Build full-stack data apps in 100% Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126lefj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680179061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/datascience\"&gt;/r/datascience&lt;/a&gt;! We&amp;#39;re building an open-source Python framework which makes it simple to build data-centric web applications. Today Datapane lets you build reports and full-stack apps in ~10 lines of Python, but our goal is to provide all the tools data teams need to create end-to-end internal apps (such as scheduled tasks, auth, integrations, OLAP) in a simple, standardized framework.&lt;/p&gt;\n\n&lt;p&gt;Our GitHub is &lt;a href=\"https://github.com/datapane/datapane/\"&gt;https://github.com/datapane/datapane&lt;/a&gt; and you can get started here: &lt;a href=\"https://docs.datapane.com/quickstart/\"&gt;https://docs.datapane.com/quickstart/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Deploying internal data products requires a bunch of complex moving pieces, e.g. a front-end UI framework, backend server + REST/GraphQL, scheduled tasks, backend workers, caching, integrations into Slack/email, scheduled reports, and often a data layer for OLAP \u2013 the list goes on. Unsurprisingly, many companies opt to buy from external vendors instead of building in-house analytics products using open-source, as this usually requires months of development time and multiple teams.&lt;/p&gt;\n\n&lt;p&gt;Datapane is a unified app framework which provides all the necessary parts of an internal data product, in a simple, Pythonic package, including:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A Python-based UI framework for constructing HTML views from data-centric blocks \u2013 like Plotly plots and pandas DataFrames. You can generate these from inside of pipelines, a Jupyter notebook, or on a schedule, and export\u00a0as standalone HTML reports or static web apps.&lt;/li&gt;\n&lt;li&gt;Ability to build data science web apps by connecting Python functions to forms and front-end events. You can check out an example of the code to create a simple app: &lt;a href=\"https://github.com/datapane/examples/blob/main/apps/iris-plotter/app.py\"&gt;https://github.com/datapane/examples/blob/main/apps/iris-plotter/app.py&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Currently, we\u2019re adding support for background tasks, scheduled tasks, and a DuckDB-based data layer for OLAP, so you can ship a complete end-to-end app.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We would love your feedback and hear what you find difficult about building data apps so we can prioritize. You can also see a few apps we\u2019ve built already in our gallery: &lt;a href=\"https://datapane.com/gallery\"&gt;https://datapane.com/gallery&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?auto=webp&amp;v=enabled&amp;s=5f43c6ab7f2cf0e0f771bc44101a6c1c4a0fe095", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2600c54183e3a5626604ed048837915edca1d2f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59396187d14550b1e199a4b49ffd2a2241763a84", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ea7a6d084ce5927803e1a4798f3c0595f2355bd", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58672ad315d87c6e37ece3a7a2f2f0a6c91f4205", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=955a0404ac47e437d47b756992f3892fef2d6c5b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Scb7l_ghRZux29K3dHrBhGzHQRBRY159OnlzNMOX4QQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c84b8c98d4db8b67e81a2c051c1b28dca3131b4", "width": 1080, "height": 540}], "variants": {}, "id": "PI0Z0SjXsKFrRf-gY0woFNTaAWvVgVdAukVtiHKVt4g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126lefj", "is_robot_indexable": true, "report_reasons": null, "author": "peatpeat", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126lefj/datapane_build_fullstack_data_apps_in_100_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126lefj/datapane_build_fullstack_data_apps_in_100_python/", "subreddit_subscribers": 865134, "created_utc": 1680179061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering what happens to tech workers when they get older. Do they increasingly get less relevant as cognitive capacities decrease with age, making it harder to keep up? Or will the field become more hiearchic with all the future 50/60 year old coders. Most people working in it are under 35 right now.", "author_fullname": "t2_306jokhm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Agism in tech, what happens when we get older", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1269xmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680146590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering what happens to tech workers when they get older. Do they increasingly get less relevant as cognitive capacities decrease with age, making it harder to keep up? Or will the field become more hiearchic with all the future 50/60 year old coders. Most people working in it are under 35 right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1269xmx", "is_robot_indexable": true, "report_reasons": null, "author": "dumbumbedeill", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1269xmx/agism_in_tech_what_happens_when_we_get_older/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1269xmx/agism_in_tech_what_happens_when_we_get_older/", "subreddit_subscribers": 865134, "created_utc": 1680146590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_n9wlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a detailed guide of how Pandas' read_csv() function actually works and the different engine options available, including new features in v2.0. Figured it might be of interest here!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_126mf78", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lo_wmsWGR2ghc8eHIgKx_qnii-nhoX0GoXJ92rSCotg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680181630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@finndersen/the-ultimate-guide-to-pandas-read-csv-function-5377874e27d5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?auto=webp&amp;v=enabled&amp;s=ea00598c9f0b63de05d6b5ef031c4eeca8f1aba2", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cbd34fea11d1ae23302998d10ffd24e386030e8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f188bc02afdabc62dfbf287fc901708d731cfb7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71c71cef271399f9caa6bdbcd1a67d9ab5e88e5d", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87e10d966de5dddbb2c3578cf907f542b8bb8851", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/5mLSBLvY5-Cjj2cgEfIAbBN2qqzPaLrjPv1mfcrCDuM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4473aba385f06f9725f17eeefd4e1469e904bffc", "width": 960, "height": 960}], "variants": {}, "id": "O_G12nam5J1x-7PfnDoaMZHPQ3uL0Gjy3RxGyTxyc-o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "126mf78", "is_robot_indexable": true, "report_reasons": null, "author": "Finndersen", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126mf78/i_wrote_a_detailed_guide_of_how_pandas_read_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@finndersen/the-ultimate-guide-to-pandas-read-csv-function-5377874e27d5", "subreddit_subscribers": 865134, "created_utc": 1680181630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone. I'm Dr. Suhrud Panchawagh, creator of the YouTube series 'Stats, stat' where I've created data libraries for budding data scientist, statisticians,, and researchers alike, to learn and perform basic to advanced statistical data analysis and modelling.\n\nThis new YouTube series will focus in R and SAS computing. I hope that it will serve you well. Please consider subscribing if you find my content helpful!\n\nCheers!", "author_fullname": "t2_70t7t5yd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R guide for beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_125sa5i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/0vKALzsHfKc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/0vKALzsHfKc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages\"&gt;&lt;/iframe&gt;", "author_name": "Stats, stat", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/0vKALzsHfKc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@dr.suhrudp"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/0vKALzsHfKc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/125sa5i", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aY1MWA4Vy9ZiYFTlJpfbIo7bkty2xeUoJ3cZeZcl2Fo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680105585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. I&amp;#39;m Dr. Suhrud Panchawagh, creator of the YouTube series &amp;#39;Stats, stat&amp;#39; where I&amp;#39;ve created data libraries for budding data scientist, statisticians,, and researchers alike, to learn and perform basic to advanced statistical data analysis and modelling.&lt;/p&gt;\n\n&lt;p&gt;This new YouTube series will focus in R and SAS computing. I hope that it will serve you well. Please consider subscribing if you find my content helpful!&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/0vKALzsHfKc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/h6th5VTFRAlUn2eCDhsgjCo8Dlqs06YHCMhXK3Y0dNg.jpg?auto=webp&amp;v=enabled&amp;s=d914702c4beb2ec8c29a5e99b364e4f2fc39f53b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/h6th5VTFRAlUn2eCDhsgjCo8Dlqs06YHCMhXK3Y0dNg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f220b34ff970ab9fd1c2df021840ebef7651ed5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/h6th5VTFRAlUn2eCDhsgjCo8Dlqs06YHCMhXK3Y0dNg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd62934062a4f6d645b31bfbbe7f9c614ad0cec", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/h6th5VTFRAlUn2eCDhsgjCo8Dlqs06YHCMhXK3Y0dNg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a20cd6cd23d2d38051295ca641b2c92ca501a7f8", "width": 320, "height": 240}], "variants": {}, "id": "DE5sqQ8dmMBGXEHjJaAeC14mr-2QvO6HFzHYk8o_Sro"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "125sa5i", "is_robot_indexable": true, "report_reasons": null, "author": "_sorude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125sa5i/r_guide_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/0vKALzsHfKc", "subreddit_subscribers": 865134, "created_utc": 1680105585.0, "num_crossposts": 1, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/0vKALzsHfKc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Exploratory and Descriptive Analysis in R using the `gtsummary` and `ggpubr` packages\"&gt;&lt;/iframe&gt;", "author_name": "Stats, stat", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/0vKALzsHfKc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@dr.suhrudp"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have noticed an uptick in jobs for things like prompt engineer, AI ethics lead, AI manager. When you look at these requirements it looks like relatively low entry: a familiarity with general AI and AI regulations (not that there is a ton of expertise to be had in this latter category). They don't require much or any technical skill. \n\nI'll admit, I find myself frustrated as I work in a highly technical role and feel like these opportunities are really 'low hanging fruit', due to the vagueness of the requirements. I'm sure many of us wear not just technical hats but also those of product management, coaching and training, etc. \n\nWhat do you think? Is it just a fad stemming from ChatGPT and Image gen promotion? Are you going to make a job switch and apply for these roles?", "author_fullname": "t2_8nb2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeing a lot of job openings for high-level AI and Data Analytics positions...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_126ndlu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680183711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have noticed an uptick in jobs for things like prompt engineer, AI ethics lead, AI manager. When you look at these requirements it looks like relatively low entry: a familiarity with general AI and AI regulations (not that there is a ton of expertise to be had in this latter category). They don&amp;#39;t require much or any technical skill. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll admit, I find myself frustrated as I work in a highly technical role and feel like these opportunities are really &amp;#39;low hanging fruit&amp;#39;, due to the vagueness of the requirements. I&amp;#39;m sure many of us wear not just technical hats but also those of product management, coaching and training, etc. &lt;/p&gt;\n\n&lt;p&gt;What do you think? Is it just a fad stemming from ChatGPT and Image gen promotion? Are you going to make a job switch and apply for these roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126ndlu", "is_robot_indexable": true, "report_reasons": null, "author": "fingin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126ndlu/seeing_a_lot_of_job_openings_for_highlevel_ai_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126ndlu/seeing_a_lot_of_job_openings_for_highlevel_ai_and/", "subreddit_subscribers": 865134, "created_utc": 1680183711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "From my experience in grad school just watching someone else go through code is pretty useless. Curious if the norm is a formal hands-on onboarding for all of you? Or is it common that it is just \u201clearn by watching\u201d at the beginning, and it takes longer than you expected to get up to speed?", "author_fullname": "t2_5m9xk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your onboarding process like? Did you receive formal training?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126hswg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680170126.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680169020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From my experience in grad school just watching someone else go through code is pretty useless. Curious if the norm is a formal hands-on onboarding for all of you? Or is it common that it is just \u201clearn by watching\u201d at the beginning, and it takes longer than you expected to get up to speed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126hswg", "is_robot_indexable": true, "report_reasons": null, "author": "heyiambob", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126hswg/what_was_your_onboarding_process_like_did_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126hswg/what_was_your_onboarding_process_like_did_you/", "subreddit_subscribers": 865134, "created_utc": 1680169020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know its a dumb question but hear me out.\n\nI just started a job as a junior data scientist for marketing analytics. I only have a BS in applied mathematics and statistics. I spent my electives on machine learning, sql fundamentals and programming fundamentals in python, giving me basic skills for data analytics.\n\nI'm very lucky I landed this job with no industrial experience at all. Even passing through their technical assessment and interview, i still find myself unfarmiliar and gaps in my knowledge for practical data science.\n\nI've been stalking my team seniors and supervisors on linkedin, and i notice all of them did computer science for their undergrad and did something relating to data science in their post grad.\n\nMy questions is, is a post grad necessary to be qualified for a higher level role even if im already a data scientist (junior)?", "author_fullname": "t2_wmz51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should i get a MS in DS if I'm already a junior data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_126ow39", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680186820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know its a dumb question but hear me out.&lt;/p&gt;\n\n&lt;p&gt;I just started a job as a junior data scientist for marketing analytics. I only have a BS in applied mathematics and statistics. I spent my electives on machine learning, sql fundamentals and programming fundamentals in python, giving me basic skills for data analytics.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very lucky I landed this job with no industrial experience at all. Even passing through their technical assessment and interview, i still find myself unfarmiliar and gaps in my knowledge for practical data science.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been stalking my team seniors and supervisors on linkedin, and i notice all of them did computer science for their undergrad and did something relating to data science in their post grad.&lt;/p&gt;\n\n&lt;p&gt;My questions is, is a post grad necessary to be qualified for a higher level role even if im already a data scientist (junior)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126ow39", "is_robot_indexable": true, "report_reasons": null, "author": "crowmonite", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126ow39/should_i_get_a_ms_in_ds_if_im_already_a_junior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126ow39/should_i_get_a_ms_in_ds_if_im_already_a_junior/", "subreddit_subscribers": 865134, "created_utc": 1680186820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone -- would appreciate advice on how to handle organizational issues related to productionizing machine learning models.\n\nLong story short, manager sampled data and ran neural networks to accomplish a task and has already sold the idea up the org hierarchy. This sample data is 2% of the full dataset the model likely needs to run on and it's difficult for me to see how we actually productionize this process on the full dataset. None of this has been tested at scale, across different local environments, or tested across different segments of the total population. New model is developed in R which is not used in any of our other processes. The process runs in a local environment -- to my knowledge we have no cloud environment/VM to run the model.\n\nI've already expressed my skepticism about productionizing this model to no avail.\n\nNeed advice on what would be next steps to take. Right now I'm thinking options:\n\n1. Build a back-up simpler model in the likely case we can't operationalize the ML model.\n2. Go with the flow, try to make it work and prepare for the politics of failure.\n\nAny advice or anecdotes from others in this situation would be much appreciated.", "author_fullname": "t2_5503u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice -- manager selling machine learning models upwards that likely will not work at scale.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_126pefg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680188016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone -- would appreciate advice on how to handle organizational issues related to productionizing machine learning models.&lt;/p&gt;\n\n&lt;p&gt;Long story short, manager sampled data and ran neural networks to accomplish a task and has already sold the idea up the org hierarchy. This sample data is 2% of the full dataset the model likely needs to run on and it&amp;#39;s difficult for me to see how we actually productionize this process on the full dataset. None of this has been tested at scale, across different local environments, or tested across different segments of the total population. New model is developed in R which is not used in any of our other processes. The process runs in a local environment -- to my knowledge we have no cloud environment/VM to run the model.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve already expressed my skepticism about productionizing this model to no avail.&lt;/p&gt;\n\n&lt;p&gt;Need advice on what would be next steps to take. Right now I&amp;#39;m thinking options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Build a back-up simpler model in the likely case we can&amp;#39;t operationalize the ML model.&lt;/li&gt;\n&lt;li&gt;Go with the flow, try to make it work and prepare for the politics of failure.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any advice or anecdotes from others in this situation would be much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126pefg", "is_robot_indexable": true, "report_reasons": null, "author": "Polus43", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126pefg/need_advice_manager_selling_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126pefg/need_advice_manager_selling_machine_learning/", "subreddit_subscribers": 865134, "created_utc": 1680188016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have to admit, I'm freaking out a bit. What would typical interview questions for an environmental data science and machine learning MSc degree at a top 10 global university be like?\n\nFor context, my undergrad was in Architecture. That's mostly why I'm freaking out, I don't have any formal background in computer science or mathematics (all my climate analysis and python skills are pretty much self taught) so the imposter syndrome is real; but surely they saw something in my application to give me an interview, and it would be insane to give me a hard programming question to tackle, right?\n\nIn the degree FAQ page it's said that \"A prerequisite for the course is a moderate level of knowledge of at least one programming language. This means that you should be comfortable with all the basic concepts of computer programming, such as variable types, control structures (e.g., loops and if statements) and functions and you should be able to implement short programs to perform simple tasks, such as reading data from a file and calculating quantities derived from those data.\" and \"We would normally expect students to have taken introductory courses as part of their first degree that cover calculus and linear algebra.\" I am comfortable with these concepts, but I'm still unsure what type of questions could be asked with this level of skill?\n\nIn the interview confirmation email it is also stated that \"The interview is \u201cintended to give candidates an opportunity to find out more about the course from academics leading the design and delivery of course content, as well as to give us an opportunity to learn more about the aspirations and background knowledge of prospective students\u201d. The interview will take about 30 minutes and there will be questions about programming and maths.\"\n\nThere will be an email sent 30 minutes before the interview time that will apparently give a programming problem to solve. Can anyone give some examples of problems I might be given, or some interview tips and resources in general? The help will be much appreciated!", "author_fullname": "t2_3s4p6x22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview for Environmental Data Science: what type of questions to expect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_126os53", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680186574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to admit, I&amp;#39;m freaking out a bit. What would typical interview questions for an environmental data science and machine learning MSc degree at a top 10 global university be like?&lt;/p&gt;\n\n&lt;p&gt;For context, my undergrad was in Architecture. That&amp;#39;s mostly why I&amp;#39;m freaking out, I don&amp;#39;t have any formal background in computer science or mathematics (all my climate analysis and python skills are pretty much self taught) so the imposter syndrome is real; but surely they saw something in my application to give me an interview, and it would be insane to give me a hard programming question to tackle, right?&lt;/p&gt;\n\n&lt;p&gt;In the degree FAQ page it&amp;#39;s said that &amp;quot;A prerequisite for the course is a moderate level of knowledge of at least one programming language. This means that you should be comfortable with all the basic concepts of computer programming, such as variable types, control structures (e.g., loops and if statements) and functions and you should be able to implement short programs to perform simple tasks, such as reading data from a file and calculating quantities derived from those data.&amp;quot; and &amp;quot;We would normally expect students to have taken introductory courses as part of their first degree that cover calculus and linear algebra.&amp;quot; I am comfortable with these concepts, but I&amp;#39;m still unsure what type of questions could be asked with this level of skill?&lt;/p&gt;\n\n&lt;p&gt;In the interview confirmation email it is also stated that &amp;quot;The interview is \u201cintended to give candidates an opportunity to find out more about the course from academics leading the design and delivery of course content, as well as to give us an opportunity to learn more about the aspirations and background knowledge of prospective students\u201d. The interview will take about 30 minutes and there will be questions about programming and maths.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;There will be an email sent 30 minutes before the interview time that will apparently give a programming problem to solve. Can anyone give some examples of problems I might be given, or some interview tips and resources in general? The help will be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126os53", "is_robot_indexable": true, "report_reasons": null, "author": "mezmezmeeez", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126os53/interview_for_environmental_data_science_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126os53/interview_for_environmental_data_science_what/", "subreddit_subscribers": 865134, "created_utc": 1680186574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://lab.amdatascience.com](https://lab.amdatascience.com)\n\nPowered by jupyterhub.\n\nI wanted to share a bunch of tools and environments that I've been working on and having a lot of fun with lately. You get a server with 15Gi of storage for free and access to python environments with OpenAI, torch, and pinecone all pre-installed and pre-configured.\n\nFeedback and suggestions are welcome", "author_fullname": "t2_8xk56o8z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dead simple Jupyter Lab workspace at lab.amdatascience.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126mtm8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680182595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://lab.amdatascience.com\"&gt;https://lab.amdatascience.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Powered by jupyterhub.&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a bunch of tools and environments that I&amp;#39;ve been working on and having a lot of fun with lately. You get a server with 15Gi of storage for free and access to python environments with OpenAI, torch, and pinecone all pre-installed and pre-configured.&lt;/p&gt;\n\n&lt;p&gt;Feedback and suggestions are welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126mtm8", "is_robot_indexable": true, "report_reasons": null, "author": "amdatascience", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126mtm8/dead_simple_jupyter_lab_workspace_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126mtm8/dead_simple_jupyter_lab_workspace_at/", "subreddit_subscribers": 865134, "created_utc": 1680182595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you guys setup DW(data warehouse) by yourself or some other role does this for you?\n\nFor what purpose do you use it, like what is the typical use-case?\n\nDo you maintain DWs and update it's design/schema as per use?\n\nWhat DW technology do you generally use? \n(Snowflake/bigquery etc. Which one do you use?)\n\nHow much you typically spend on them in monthly basis?\n\nI am asking this question because I am building a tool which helps optimising the queries you run on DWs and there by saving costs.\n\nWould like know your insights!!", "author_fullname": "t2_7t9felxr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Data Scientists typically deal with Datawarehouses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126i307", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680170042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys setup DW(data warehouse) by yourself or some other role does this for you?&lt;/p&gt;\n\n&lt;p&gt;For what purpose do you use it, like what is the typical use-case?&lt;/p&gt;\n\n&lt;p&gt;Do you maintain DWs and update it&amp;#39;s design/schema as per use?&lt;/p&gt;\n\n&lt;p&gt;What DW technology do you generally use? \n(Snowflake/bigquery etc. Which one do you use?)&lt;/p&gt;\n\n&lt;p&gt;How much you typically spend on them in monthly basis?&lt;/p&gt;\n\n&lt;p&gt;I am asking this question because I am building a tool which helps optimising the queries you run on DWs and there by saving costs.&lt;/p&gt;\n\n&lt;p&gt;Would like know your insights!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126i307", "is_robot_indexable": true, "report_reasons": null, "author": "query_optimization", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126i307/how_do_data_scientists_typically_deal_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126i307/how_do_data_scientists_typically_deal_with/", "subreddit_subscribers": 865134, "created_utc": 1680170042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I have an idea I\u2019d like to get your opinion on. \n\nI\u2019ve been a practicing data scientist for over a decade in a variety of industries and specialize in time series. I currently work in a department that sits between finance and engineering (resource planning) and have routinely given training sessions to new engineers / analysts on how to use R. \n\nI\u2019ve had a lot of positive feedback on my methods and content in these sessions and I love teaching. This makes me wonder if there\u2019s an opportunity to offer training services in a lecture format like this to companies (ideally within finance, as there\u2019s a big push to build technical competency beyond excel / VBA, and I have both academic and real world experience in the field).\n\nI live in one of the largest metro cities in the US and feel there has to be some demand for this around here. Lecture topics would focus around how to work pragmatically with R or Python, like setting repeatable project pipelines, how to work with others on projects, versioning, how to QA/QC your work, create reports or automation. \n\nDoes anyone have any experience selling training services like this to companies? The market is huge for trainings in areas like compliance, management, and HR related things, but I haven\u2019t much in the way of \u201cdata skills.\u201d \n\nThanks all", "author_fullname": "t2_7cadh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Training Sevices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126a0q7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680146834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have an idea I\u2019d like to get your opinion on. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been a practicing data scientist for over a decade in a variety of industries and specialize in time series. I currently work in a department that sits between finance and engineering (resource planning) and have routinely given training sessions to new engineers / analysts on how to use R. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve had a lot of positive feedback on my methods and content in these sessions and I love teaching. This makes me wonder if there\u2019s an opportunity to offer training services in a lecture format like this to companies (ideally within finance, as there\u2019s a big push to build technical competency beyond excel / VBA, and I have both academic and real world experience in the field).&lt;/p&gt;\n\n&lt;p&gt;I live in one of the largest metro cities in the US and feel there has to be some demand for this around here. Lecture topics would focus around how to work pragmatically with R or Python, like setting repeatable project pipelines, how to work with others on projects, versioning, how to QA/QC your work, create reports or automation. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience selling training services like this to companies? The market is huge for trainings in areas like compliance, management, and HR related things, but I haven\u2019t much in the way of \u201cdata skills.\u201d &lt;/p&gt;\n\n&lt;p&gt;Thanks all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126a0q7", "is_robot_indexable": true, "report_reasons": null, "author": "greenfootballs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126a0q7/data_science_training_sevices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126a0q7/data_science_training_sevices/", "subreddit_subscribers": 865134, "created_utc": 1680146834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a Data Scientist and just finished a 6 month internship with the company. They offered me a junior role and at the start of march and now I\u2019m being placed on a 3 week performance review and if I don\u2019t work to the standard they expect I\u2019m out? \n\nI feel like I\u2019m being bullied out of the company when they were only just saying 3 weeks ago how much they liked me?\n\nAdvice?", "author_fullname": "t2_ukaxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been put on a performance review 3 weeks into new role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_125xrlj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680117255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Data Scientist and just finished a 6 month internship with the company. They offered me a junior role and at the start of march and now I\u2019m being placed on a 3 week performance review and if I don\u2019t work to the standard they expect I\u2019m out? &lt;/p&gt;\n\n&lt;p&gt;I feel like I\u2019m being bullied out of the company when they were only just saying 3 weeks ago how much they liked me?&lt;/p&gt;\n\n&lt;p&gt;Advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "125xrlj", "is_robot_indexable": true, "report_reasons": null, "author": "dildan101", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125xrlj/been_put_on_a_performance_review_3_weeks_into_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/125xrlj/been_put_on_a_performance_review_3_weeks_into_new/", "subreddit_subscribers": 865134, "created_utc": 1680117255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the past I have used Python for data analysis of structured and unstructured data, but this is my first time trying to build and connect an SQL database to both a data processing pipeline as well as a web based dashboard. \n\nMy general approach has been to first build the SQL database using Node.js for the back end (instead of django?). My idea is I want to use javascript and HTML5 on the front end to build an interactive data visualization dashboard (show graphs, bar plots, etc) for my manager. My plan is to use either React or D3 javascript libraries. I have been able to use javascript for some basic things to test that out but as soon as I start importing modules like React, things get messy. I've read online that it might be helpful to use tools like webpack, is that something that is recommended?\n\nI also want to have a python front end for myself for more in depth filtering/analysis. Is the general direction I am going in appropriate? Or am I going to quickly run into issues that I am not foreseeing?\n\nThanks!!", "author_fullname": "t2_337qnz2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for general direction on first big project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_125xfwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680116545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the past I have used Python for data analysis of structured and unstructured data, but this is my first time trying to build and connect an SQL database to both a data processing pipeline as well as a web based dashboard. &lt;/p&gt;\n\n&lt;p&gt;My general approach has been to first build the SQL database using Node.js for the back end (instead of django?). My idea is I want to use javascript and HTML5 on the front end to build an interactive data visualization dashboard (show graphs, bar plots, etc) for my manager. My plan is to use either React or D3 javascript libraries. I have been able to use javascript for some basic things to test that out but as soon as I start importing modules like React, things get messy. I&amp;#39;ve read online that it might be helpful to use tools like webpack, is that something that is recommended?&lt;/p&gt;\n\n&lt;p&gt;I also want to have a python front end for myself for more in depth filtering/analysis. Is the general direction I am going in appropriate? Or am I going to quickly run into issues that I am not foreseeing?&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "125xfwj", "is_robot_indexable": true, "report_reasons": null, "author": "lstnwndrlnd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125xfwj/looking_for_general_direction_on_first_big_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/125xfwj/looking_for_general_direction_on_first_big_project/", "subreddit_subscribers": 865134, "created_utc": 1680116545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently joined a mid sized US based product company as a Senior data analyst.\nI have around 7 years of experience in data analytics worked through multiple roles in SaaS and Supply chain domains. With the kind of work I'm being assigned it looks more like a BA role. It's been almost 30 days since I haven't written a single SQL query but I'm being asked to create BRDs, conceptual data models, requirements gathering documentation. These guys are heavy on agile methodology so I know for sure projects in the pipeline for the next two sprints and all of them are on the same lines. Typical workflow being \n\nfeasibility analysis -&gt; creating BRD and getting signoff from business -&gt; creating stories for the next sprint so the Data engineering team would pick those up.\n\nThere's no actual analysis happening through our team. In my past roles it wasn't the case.\n\nI'm feeling stuck is this the ideal way that the DS team works?", "author_fullname": "t2_e35dgwi1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I hired in the wrong role or my entire career was a lie - advice/suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_125waig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680114053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined a mid sized US based product company as a Senior data analyst.\nI have around 7 years of experience in data analytics worked through multiple roles in SaaS and Supply chain domains. With the kind of work I&amp;#39;m being assigned it looks more like a BA role. It&amp;#39;s been almost 30 days since I haven&amp;#39;t written a single SQL query but I&amp;#39;m being asked to create BRDs, conceptual data models, requirements gathering documentation. These guys are heavy on agile methodology so I know for sure projects in the pipeline for the next two sprints and all of them are on the same lines. Typical workflow being &lt;/p&gt;\n\n&lt;p&gt;feasibility analysis -&amp;gt; creating BRD and getting signoff from business -&amp;gt; creating stories for the next sprint so the Data engineering team would pick those up.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no actual analysis happening through our team. In my past roles it wasn&amp;#39;t the case.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling stuck is this the ideal way that the DS team works?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "125waig", "is_robot_indexable": true, "report_reasons": null, "author": "sal_06", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/125waig/am_i_hired_in_the_wrong_role_or_my_entire_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/125waig/am_i_hired_in_the_wrong_role_or_my_entire_career/", "subreddit_subscribers": 865134, "created_utc": 1680114053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_mewo7cu7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] The Bitcoin adoption - Download mp4 and dataset here: https://tradervoice.io/visualnarratives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": true, "name": "t3_126pawa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/lsbavdn42wqa1/DASH_480.mp4?source=fallback", "height": 480, "width": 698, "scrubber_media_url": "https://v.redd.it/lsbavdn42wqa1/DASH_96.mp4", "dash_url": "https://v.redd.it/lsbavdn42wqa1/DASHPlaylist.mpd?a=1682782715%2CYmYzZWMyZTIzMzM0ZjIxMGNhMDgwN2VkZjBmMzczZDZlMGQyZDgxNzgxOWM3Y2UyM2M4OTAzYWMwMDBmOWEyZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 20, "hls_url": "https://v.redd.it/lsbavdn42wqa1/HLSPlaylist.m3u8?a=1682782715%2CNmNmNWNmM2ViNDJlODY5OGE1M2U5YTUzNWQzNTA1ZjJiODM5N2VmZTg4ODgwYTUwOTJjMTU2ZmVjOTk3ODY3Mg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gHV3_tOjEE9O6zWdhRYGJsNn2h7B7pG_woS9YnLxrwY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680187786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/lsbavdn42wqa1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/47-hxgLDDux1qcQzresxEhNGOqpBqoSFTZ1S7Z2cUhk.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=20eb1005076f845d1c0aa723e4bba8e7de520a3a", "width": 800, "height": 550}, "resolutions": [{"url": "https://external-preview.redd.it/47-hxgLDDux1qcQzresxEhNGOqpBqoSFTZ1S7Z2cUhk.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bac4c507b6193da9b7395c4d43b8158ca8fe1c0b", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/47-hxgLDDux1qcQzresxEhNGOqpBqoSFTZ1S7Z2cUhk.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=86fa1b92d7287126a1630174d7d8173ba1f2a517", "width": 216, "height": 148}, {"url": "https://external-preview.redd.it/47-hxgLDDux1qcQzresxEhNGOqpBqoSFTZ1S7Z2cUhk.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2ba609e5eddac386fa4bee75183d8fea52c31c17", "width": 320, "height": 220}, {"url": "https://external-preview.redd.it/47-hxgLDDux1qcQzresxEhNGOqpBqoSFTZ1S7Z2cUhk.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f76b524c54644db83006bbe0c28f831360ddf159", "width": 640, "height": 440}], "variants": {}, "id": "KKtZiKkhdZS4-C0aYvSA4ABLG2VgjF5MMmS-ZCV8Ceo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "126pawa", "is_robot_indexable": true, "report_reasons": null, "author": "KBindesboell", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126pawa/oc_the_bitcoin_adoption_download_mp4_and_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/lsbavdn42wqa1", "subreddit_subscribers": 865134, "created_utc": 1680187786.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/lsbavdn42wqa1/DASH_480.mp4?source=fallback", "height": 480, "width": 698, "scrubber_media_url": "https://v.redd.it/lsbavdn42wqa1/DASH_96.mp4", "dash_url": "https://v.redd.it/lsbavdn42wqa1/DASHPlaylist.mpd?a=1682782715%2CYmYzZWMyZTIzMzM0ZjIxMGNhMDgwN2VkZjBmMzczZDZlMGQyZDgxNzgxOWM3Y2UyM2M4OTAzYWMwMDBmOWEyZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 20, "hls_url": "https://v.redd.it/lsbavdn42wqa1/HLSPlaylist.m3u8?a=1682782715%2CNmNmNWNmM2ViNDJlODY5OGE1M2U5YTUzNWQzNTA1ZjJiODM5N2VmZTg4ODgwYTUwOTJjMTU2ZmVjOTk3ODY3Mg%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Save all your conversations via scraping with python and chatGPT Frontend API (no apikey needed) [ GitHub - rodolflying/GPT_scraper ] https://github.com/rodolflying/GPT_scraper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_126id1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_614orzb8", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aZcOIZ9JqWn1FkZHe1EROxpm8PSLr6fHQQv43QD9LOk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ChatGPT", "selftext": "\nThis repository provides a way to scrape full user history ChatGPT through 2 methods:\n\n1) frontend \"hidden\" API based v\u00eda a python automated script . The only thing needed its use the cookies of the site with your current session (see the first gif). The results can be viewed in the second gif ( json or csv). The scripts filter unnecessary data the responses.\n\n It can be helpful for :\n\n- avoiding the usage of API credits while still using ChatGPT programmatically.\n- analisys of your past prompt ( since the resulst are on csv or json ready to use)\n- filter valuable info that its too in the past to search for manuales\n\n2) the second version do the same but using selenium scraping, and using the  current chrome user session faldero to use the cookies. Its slower cause to avoid getting blocked you have to put at leats 10 seconds between each interaction. Anyways its easier too use since you only need chromedriver.exe\nOn \"C:/\",  also close any instances of Google chrome) , run the script and wait for it to finish\n\n\n- bonus: also there is a third script to have a conversation with chat gpt via selenium and save it to json. Obviously its better to interact directly with the chatgpt web page but if you want to do it programmatically you can take it as a starting point for your project.\n\nThe link its : guthub.com/rodolflying/GPT_scraper\n\nSee the readme for fuether details!", "author_fullname": "t2_614orzb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Save all your conversations with python and frontend chatGPT Frontend API [ GitHub - rodolflying/GPT_scraper ]", "link_flair_richtext": [{"e": "text", "t": "Resources "}], "subreddit_name_prefixed": "r/ChatGPT", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9b5k9pno8uqa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9514423d0e3ee31e9cc7af7ee031ac9f70b83e84"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=867693406baecb3a1f530cbd6eeb5085b7ff7299"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=256c98057f476375adeaf9203a0d9ef9983bb0a4"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=85bf69e6edbea849039948635aa67435e1bcae9c"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3cd77beaac7c4bfd10a864db1cb03fadd530ad05"}, {"y": 513, "x": 1080, "u": "https://preview.redd.it/9b5k9pno8uqa1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=1917f7069a84e4a074922f038ce23ad562daff5c"}], "s": {"y": 1823, "gif": "https://i.redd.it/9b5k9pno8uqa1.gif", "mp4": "https://preview.redd.it/9b5k9pno8uqa1.gif?format=mp4&amp;v=enabled&amp;s=f1cd3cabc43afa06194700995e150f6859d5d61b", "x": 3835}, "id": "9b5k9pno8uqa1"}, "tnt9nh9o8uqa1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=e8601f402607e8ca8f79d9daf54c1dcbf17572bb"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=775b853823d69b360ebedd242eee0a0755d897d9"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=fa5c7214b95ca35eaa9a1bb875f4fe6cfc648075"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=9b8506c9d6668f0c52da7f001fc48dcff78f8523"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=062eba1fd8894d5a3cdee983db8bf3c7e3a308e0"}, {"y": 513, "x": 1080, "u": "https://preview.redd.it/tnt9nh9o8uqa1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f381c2ee62b21086d69c41f307095e4f4cea84d5"}], "s": {"y": 1822, "gif": "https://i.redd.it/tnt9nh9o8uqa1.gif", "mp4": "https://preview.redd.it/tnt9nh9o8uqa1.gif?format=mp4&amp;v=enabled&amp;s=3def078af48f86a9cb4c14cf8294f0242535297b", "x": 3835}, "id": "tnt9nh9o8uqa1"}}, "name": "t3_126gr0p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "Copy headers to \"headers\" file you have to rename the file and type the \".py\" extension at the end)", "media_id": "tnt9nh9o8uqa1", "id": 257416065}, {"caption": "How run the script and how the results looks like ", "media_id": "9b5k9pno8uqa1", "id": 257416066}]}, "link_flair_text": "Resources ", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aZcOIZ9JqWn1FkZHe1EROxpm8PSLr6fHQQv43QD9LOk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680165359.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This repository provides a way to scrape full user history ChatGPT through 2 methods:&lt;/p&gt;\n\n&lt;p&gt;1) frontend &amp;quot;hidden&amp;quot; API based v\u00eda a python automated script . The only thing needed its use the cookies of the site with your current session (see the first gif). The results can be viewed in the second gif ( json or csv). The scripts filter unnecessary data the responses.&lt;/p&gt;\n\n&lt;p&gt;It can be helpful for :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;avoiding the usage of API credits while still using ChatGPT programmatically.&lt;/li&gt;\n&lt;li&gt;analisys of your past prompt ( since the resulst are on csv or json ready to use)&lt;/li&gt;\n&lt;li&gt;filter valuable info that its too in the past to search for manuales&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;2) the second version do the same but using selenium scraping, and using the  current chrome user session faldero to use the cookies. Its slower cause to avoid getting blocked you have to put at leats 10 seconds between each interaction. Anyways its easier too use since you only need chromedriver.exe\nOn &amp;quot;C:/&amp;quot;,  also close any instances of Google chrome) , run the script and wait for it to finish&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;bonus: also there is a third script to have a conversation with chat gpt via selenium and save it to json. Obviously its better to interact directly with the chatgpt web page but if you want to do it programmatically you can take it as a starting point for your project.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The link its : guthub.com/rodolflying/GPT_scraper&lt;/p&gt;\n\n&lt;p&gt;See the readme for fuether details!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/126gr0p", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c8a7075c-9962-11ed-86d0-b2c48b46bf22", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_7hqomg", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#373c3f", "id": "126gr0p", "is_robot_indexable": true, "report_reasons": null, "author": "Rodolflying", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ChatGPT/comments/126gr0p/save_all_your_conversations_with_python_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/126gr0p", "subreddit_subscribers": 784962, "created_utc": 1680165359.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1680171002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/126gr0p", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126id1o", "is_robot_indexable": true, "report_reasons": null, "author": "Rodolflying", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_126gr0p", "author_flair_text_color": null, "permalink": "/r/datascience/comments/126id1o/save_all_your_conversations_via_scraping_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/126gr0p", "subreddit_subscribers": 865134, "created_utc": 1680171002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks, I had a piece of content I was working on. I'm an engineer and not a content writer so I would appreciate your feedback :D\n\nIn today\u2019s dynamic environment, the main data processing steps include: data ingestion from a source, data storage, data transformation, data cleansing, and data validation. After these steps, data can be stored and used in further analyses and data analytics applications.\n\nData analysts are eager to find new ways of processing data since this kind of information always grows in both volume and variety, and data-processing tools are being constantly updated (multiple times every year).\n\n\u200d\n\nWhat Is Data Ingestion?\n\nData ingestion is the process of transporting data from one or more sources to a target site for further processing and analysis. The data can be taken from multiple sources, including data pools, SaaS applications, IoT devices, on-premises databases, etc., and would usually end up in different target environments, including cloud data marts and data warehouses.\n\n\u200d\n\nWhy Is Data Ingestion Important?\n\nData ingestion reorganizes company data to the desired format and helps ease its usage, especially during the extract, transform, and load (ETL) operations. Tools for data ingestion can both process a variety of data formats while simultaneously reorganizing large volumes of unstructured (raw) data.\n\nOnce data is ingested, organizations can employ analytical tools to get useful BI insights from multiple data sources. Companies can improve their applications and offer different features and services derived from the insights that are produced by ingested data sets. With proper data inputs, businesses can provide data analytics to authorized individuals more efficiently. Additionally, data ingestion brings the data to programs that need the most up-to-date data. For example, real-time data, when applied to the public transport system, can improve its efficiency (fuel consumption and traffic patterns), minimize arrival times, avoid congestion etc.\n\n\u200d\n\nHow To Best Conduct Data Ingestion?\n\nData ingestion can be done in 3 different ways. More specifically, this can be completed through either real-time, batches or a combination of both processes, known otherwise as lambda (or micro-batch approach). Companies can choose one of the three types depending on their business objectives, IT infrastructures, and financial feasibility.\n\n1. **Real-time data ingestion** is the process of the collection and transfer of data from multiple sources in real-time using tools such as change data capture (CDC). CDC continually monitors the transaction logs and moves the changed data without interfering with the database workload. Real-time ingestion is crucial in time-limited use cases, such as power grid monitoring or stock market trading, especially when companies need to react rapidly to new information. Real-time data pipelines are also important in making quick operational decisions and defining actions based on new insights.\n2. **Batch-based data ingestion**, on the other hand, is the process of the collection and transfer of data in batches but in pre-specified time intervals. The ingestion process will collect data based on certain conditions, event triggers, or some forms of logical order. Batch-based ingestion is applicable when companies need to collect specific data on a less rigorous daily basis and or simply don\u2019t need a constant inflow of data for real-time decision-making. An example could be a printed newspaper that collects information over 24 hours and publishes it (part of it) at a certain time.\n3. **Micro-batch ingestion** is a data ingestion process that consists of both real-time and batch methods. The process includes the batch, serving, and speed layers. The first two layers index data in batches, and the speed layer instantly indexes the data that should otherwise be picked up by the slower batch and serving layers. This ongoing data transfer between different layers ensures that data is available for querying with no delay.\n\nThe Benefits of Data Ingestion\n\nThese Data ingestion techniques provide various benefits, enabling firms to manage data while also improving their market positions effectively. Some of the advantages include the following:\n\n* Companies can save time and money: Data ingestion automates some of the tasks that are previously done manually by developers. With an automated system in place, however, critical developers can instead dedicate their time to other, more important tasks.\n* Dev-teams can improve their software applications: After implementation, dev-teams can utilize data ingestion techniques to ensure that their applications transfer data quickly and provide a smooth experience directly to the end-users.\n* Data is promptly available: Companies can gather data stored across various servers and move them all together to a unified environment available for immediate access and further analysis.\n* Data simplified: Data ingestion implementation, together with ETL tools, will convert different data types into pre-defined formats and then transfer them to a single data warehouse.\n* Improved decision-making: Real-time data ingestion allows businesses to uncover problems and opportunities on the spot, thereby making the right decisions at the right time.\n\nThe Must-Have Features For 2023 / Incoming Trends in 2023\n\nData ingestion tools can gather and transfer all structured, semi-structured, and unstructured data from multiple sources to target destinations. These tools automate manual ingestion processes and undertake processing steps that move data from one point to another. Other important features to pay attention to in the upcoming period are as follows:\n\n* **Data integration tools:** Traditional data integration platforms incorporate features for every step of the data value chain, and namely, the aforementioned data cleaning, data consolidation, ETL processes, data virtualization, and transfer and storage. They enable a regulated (and secure) flow of simplified data operations through increasing productivity without any processing delays.\n* **AI-powered search**: An AI-Powered Search can bring site visitors what they need right off the spot, and this will help business owners achieve better customer satisfaction, higher conversion rates, and increased revenues. An AI-based search engine will display results that are personalized to individual users based on their profiles, desires, and various other tendencies.\n* **Video-based search**: Implementing automated captions helps people consume media content effectively. With Omnisearch, you can utilize our advanced search functionality to find the exact video you need or navigate the database using filters such as topics, dates, and many more. Additionally, when you search for specific files, Omnisearch automatically tells you the relevance of various files to your search terms; this makes it quick and easy to navigate through your massive database to find and locate exactly what you need.", "author_fullname": "t2_o5qmz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The importance of data ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126girz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680164589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I had a piece of content I was working on. I&amp;#39;m an engineer and not a content writer so I would appreciate your feedback :D&lt;/p&gt;\n\n&lt;p&gt;In today\u2019s dynamic environment, the main data processing steps include: data ingestion from a source, data storage, data transformation, data cleansing, and data validation. After these steps, data can be stored and used in further analyses and data analytics applications.&lt;/p&gt;\n\n&lt;p&gt;Data analysts are eager to find new ways of processing data since this kind of information always grows in both volume and variety, and data-processing tools are being constantly updated (multiple times every year).&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;p&gt;What Is Data Ingestion?&lt;/p&gt;\n\n&lt;p&gt;Data ingestion is the process of transporting data from one or more sources to a target site for further processing and analysis. The data can be taken from multiple sources, including data pools, SaaS applications, IoT devices, on-premises databases, etc., and would usually end up in different target environments, including cloud data marts and data warehouses.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;p&gt;Why Is Data Ingestion Important?&lt;/p&gt;\n\n&lt;p&gt;Data ingestion reorganizes company data to the desired format and helps ease its usage, especially during the extract, transform, and load (ETL) operations. Tools for data ingestion can both process a variety of data formats while simultaneously reorganizing large volumes of unstructured (raw) data.&lt;/p&gt;\n\n&lt;p&gt;Once data is ingested, organizations can employ analytical tools to get useful BI insights from multiple data sources. Companies can improve their applications and offer different features and services derived from the insights that are produced by ingested data sets. With proper data inputs, businesses can provide data analytics to authorized individuals more efficiently. Additionally, data ingestion brings the data to programs that need the most up-to-date data. For example, real-time data, when applied to the public transport system, can improve its efficiency (fuel consumption and traffic patterns), minimize arrival times, avoid congestion etc.&lt;/p&gt;\n\n&lt;p&gt;\u200d&lt;/p&gt;\n\n&lt;p&gt;How To Best Conduct Data Ingestion?&lt;/p&gt;\n\n&lt;p&gt;Data ingestion can be done in 3 different ways. More specifically, this can be completed through either real-time, batches or a combination of both processes, known otherwise as lambda (or micro-batch approach). Companies can choose one of the three types depending on their business objectives, IT infrastructures, and financial feasibility.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Real-time data ingestion&lt;/strong&gt; is the process of the collection and transfer of data from multiple sources in real-time using tools such as change data capture (CDC). CDC continually monitors the transaction logs and moves the changed data without interfering with the database workload. Real-time ingestion is crucial in time-limited use cases, such as power grid monitoring or stock market trading, especially when companies need to react rapidly to new information. Real-time data pipelines are also important in making quick operational decisions and defining actions based on new insights.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Batch-based data ingestion&lt;/strong&gt;, on the other hand, is the process of the collection and transfer of data in batches but in pre-specified time intervals. The ingestion process will collect data based on certain conditions, event triggers, or some forms of logical order. Batch-based ingestion is applicable when companies need to collect specific data on a less rigorous daily basis and or simply don\u2019t need a constant inflow of data for real-time decision-making. An example could be a printed newspaper that collects information over 24 hours and publishes it (part of it) at a certain time.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Micro-batch ingestion&lt;/strong&gt; is a data ingestion process that consists of both real-time and batch methods. The process includes the batch, serving, and speed layers. The first two layers index data in batches, and the speed layer instantly indexes the data that should otherwise be picked up by the slower batch and serving layers. This ongoing data transfer between different layers ensures that data is available for querying with no delay.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The Benefits of Data Ingestion&lt;/p&gt;\n\n&lt;p&gt;These Data ingestion techniques provide various benefits, enabling firms to manage data while also improving their market positions effectively. Some of the advantages include the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Companies can save time and money: Data ingestion automates some of the tasks that are previously done manually by developers. With an automated system in place, however, critical developers can instead dedicate their time to other, more important tasks.&lt;/li&gt;\n&lt;li&gt;Dev-teams can improve their software applications: After implementation, dev-teams can utilize data ingestion techniques to ensure that their applications transfer data quickly and provide a smooth experience directly to the end-users.&lt;/li&gt;\n&lt;li&gt;Data is promptly available: Companies can gather data stored across various servers and move them all together to a unified environment available for immediate access and further analysis.&lt;/li&gt;\n&lt;li&gt;Data simplified: Data ingestion implementation, together with ETL tools, will convert different data types into pre-defined formats and then transfer them to a single data warehouse.&lt;/li&gt;\n&lt;li&gt;Improved decision-making: Real-time data ingestion allows businesses to uncover problems and opportunities on the spot, thereby making the right decisions at the right time.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The Must-Have Features For 2023 / Incoming Trends in 2023&lt;/p&gt;\n\n&lt;p&gt;Data ingestion tools can gather and transfer all structured, semi-structured, and unstructured data from multiple sources to target destinations. These tools automate manual ingestion processes and undertake processing steps that move data from one point to another. Other important features to pay attention to in the upcoming period are as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data integration tools:&lt;/strong&gt; Traditional data integration platforms incorporate features for every step of the data value chain, and namely, the aforementioned data cleaning, data consolidation, ETL processes, data virtualization, and transfer and storage. They enable a regulated (and secure) flow of simplified data operations through increasing productivity without any processing delays.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AI-powered search&lt;/strong&gt;: An AI-Powered Search can bring site visitors what they need right off the spot, and this will help business owners achieve better customer satisfaction, higher conversion rates, and increased revenues. An AI-based search engine will display results that are personalized to individual users based on their profiles, desires, and various other tendencies.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Video-based search&lt;/strong&gt;: Implementing automated captions helps people consume media content effectively. With Omnisearch, you can utilize our advanced search functionality to find the exact video you need or navigate the database using filters such as topics, dates, and many more. Additionally, when you search for specific files, Omnisearch automatically tells you the relevance of various files to your search terms; this makes it quick and easy to navigate through your massive database to find and locate exactly what you need.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126girz", "is_robot_indexable": true, "report_reasons": null, "author": "marin_smiljanic", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126girz/the_importance_of_data_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126girz/the_importance_of_data_ingestion/", "subreddit_subscribers": 865134, "created_utc": 1680164589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I coded the algo for sentiment analysis appropriate for my data. I need a test dataset that already has the outcome coded positive/negative/neutral so as to get an accuracy score of my algo.\n\nSuggestions please. Thanks!\n\nEDIT: my data is from semi-structured interviews, so it's a lot cleaner than online data such as Twitter data - no slang, no sarcasm, no emojis etc", "author_fullname": "t2_s6n4mlrr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best test data set out there for sentiment analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126d5id", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680155636.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680155252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I coded the algo for sentiment analysis appropriate for my data. I need a test dataset that already has the outcome coded positive/negative/neutral so as to get an accuracy score of my algo.&lt;/p&gt;\n\n&lt;p&gt;Suggestions please. Thanks!&lt;/p&gt;\n\n&lt;p&gt;EDIT: my data is from semi-structured interviews, so it&amp;#39;s a lot cleaner than online data such as Twitter data - no slang, no sarcasm, no emojis etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126d5id", "is_robot_indexable": true, "report_reasons": null, "author": "metalhead_nerd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126d5id/whats_the_best_test_data_set_out_there_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126d5id/whats_the_best_test_data_set_out_there_for/", "subreddit_subscribers": 865134, "created_utc": 1680155252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I first run multiple models (each with some hyper-parameters), then choose the best model based on CV error. **After I chose the model &amp; fit the data on the training set, can I use the same training data CV splits to tune hyper-parameters ?**\n\n&amp;#x200B;\n\n**I faintly recall someone telling me this isn't a good approach since it may introduce bias. But I don't see why.**\n\n&amp;#x200B;\n\n**I chose this workflow because:**\n\n1. **some models are very sensitive to hyper-parameters, so I like to have some hyper-parameters during the model selection process**\n2. I like to fine tune the model a lot more after choosing the appropriate model. In the example, it only had C:\\[0.5, 1, 5\\], but I would actually run hundreds of parameters. \n\n(code example provided by ChatGPT after I asked it to provide me a sample code detailing this workflow).\n\nhttps://preview.redd.it/ymvwn0laxsqa1.png?width=670&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ad6d2bba83ac768d1b74530f576d75d4624d60a1", "author_fullname": "t2_39zs9rkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this method of hyper-parameter tuning introduce any bias? Please help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ymvwn0laxsqa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 147, "x": 108, "u": "https://preview.redd.it/ymvwn0laxsqa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=641cf42fecdcbf1f341da9fa1599cca73253c477"}, {"y": 294, "x": 216, "u": "https://preview.redd.it/ymvwn0laxsqa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29849970b18d790dae38df5e20c1760e219b19d7"}, {"y": 437, "x": 320, "u": "https://preview.redd.it/ymvwn0laxsqa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26bae560e3fb12f51f56146eb3f63ab290fb709a"}, {"y": 874, "x": 640, "u": "https://preview.redd.it/ymvwn0laxsqa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=166dd8f2e8f66c1101c676ff7885af7e0d82b1e8"}], "s": {"y": 915, "x": 670, "u": "https://preview.redd.it/ymvwn0laxsqa1.png?width=670&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ad6d2bba83ac768d1b74530f576d75d4624d60a1"}, "id": "ymvwn0laxsqa1"}}, "name": "t3_126bauf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZB6ZvKEPwKYU1JAJ3EgLYABb5dI9JBth47VhPfTR_Js.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680149648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I first run multiple models (each with some hyper-parameters), then choose the best model based on CV error. &lt;strong&gt;After I chose the model &amp;amp; fit the data on the training set, can I use the same training data CV splits to tune hyper-parameters ?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I faintly recall someone telling me this isn&amp;#39;t a good approach since it may introduce bias. But I don&amp;#39;t see why.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I chose this workflow because:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;some models are very sensitive to hyper-parameters, so I like to have some hyper-parameters during the model selection process&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I like to fine tune the model a lot more after choosing the appropriate model. In the example, it only had C:[0.5, 1, 5], but I would actually run hundreds of parameters. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;(code example provided by ChatGPT after I asked it to provide me a sample code detailing this workflow).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ymvwn0laxsqa1.png?width=670&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ad6d2bba83ac768d1b74530f576d75d4624d60a1\"&gt;https://preview.redd.it/ymvwn0laxsqa1.png?width=670&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ad6d2bba83ac768d1b74530f576d75d4624d60a1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126bauf", "is_robot_indexable": true, "report_reasons": null, "author": "fatcatlover1993", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126bauf/does_this_method_of_hyperparameter_tuning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126bauf/does_this_method_of_hyperparameter_tuning/", "subreddit_subscribers": 865134, "created_utc": 1680149648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m an incoming civil engineering grad student with a fairly heavy computational and data science focus. I\u2019m thinking about pivoting into data science roles after graduation, but I just don\u2019t know much about this industry.  \n\nMy concentration is in water resources and coastal engineering specifically. Most jobs in this field require Python/Matlab/C/Fortran, Linux, and database management. High performance computing, incredibly large and messy data sets, and extensive data processing are kind of a given when creating and running large-scale water models. \n\nI\u2019ll also be gaining machine learning experience through my MS thesis. I\u2019ll be coupling a bunch of those large-scale water models to improve their parameterization mostly with ML tools. So I\u2019ll have a pretty neat domain-specific project utilizing a lot of different skills. \n\nDuring undergrad, I took python, Matlab, OO programming, data structures, numerical methods, stats (with R), and a bunch of applied math and statistics in the context of water systems. I was scripting pretty much every day for the last 2 years, although admittedly I have less experience on more extensive code and database projects.\n\nHow could I leverage this into a career in data science, and where could I start looking? I\u2019ve been under the impression that there\u2019s a growing branch of urban analytics and data science out there, but I\u2019ve been having trouble finding roles. I\u2019d also be interested in renewables and natural resources.\n\nAre there any glaring gaps that I should potentially try to fill? I\u2019m planning to learn SQL at some point and get some front-end knowledge as a start, since my degrees don\u2019t really touch those. If anyone is in these kind of roles, do you like it, and do you think the future is promising?", "author_fullname": "t2_1nykew10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Careers adjacent to civil/environmental engineering, planning, water resources, urban systems, etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_126atge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680148671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an incoming civil engineering grad student with a fairly heavy computational and data science focus. I\u2019m thinking about pivoting into data science roles after graduation, but I just don\u2019t know much about this industry.  &lt;/p&gt;\n\n&lt;p&gt;My concentration is in water resources and coastal engineering specifically. Most jobs in this field require Python/Matlab/C/Fortran, Linux, and database management. High performance computing, incredibly large and messy data sets, and extensive data processing are kind of a given when creating and running large-scale water models. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ll also be gaining machine learning experience through my MS thesis. I\u2019ll be coupling a bunch of those large-scale water models to improve their parameterization mostly with ML tools. So I\u2019ll have a pretty neat domain-specific project utilizing a lot of different skills. &lt;/p&gt;\n\n&lt;p&gt;During undergrad, I took python, Matlab, OO programming, data structures, numerical methods, stats (with R), and a bunch of applied math and statistics in the context of water systems. I was scripting pretty much every day for the last 2 years, although admittedly I have less experience on more extensive code and database projects.&lt;/p&gt;\n\n&lt;p&gt;How could I leverage this into a career in data science, and where could I start looking? I\u2019ve been under the impression that there\u2019s a growing branch of urban analytics and data science out there, but I\u2019ve been having trouble finding roles. I\u2019d also be interested in renewables and natural resources.&lt;/p&gt;\n\n&lt;p&gt;Are there any glaring gaps that I should potentially try to fill? I\u2019m planning to learn SQL at some point and get some front-end knowledge as a start, since my degrees don\u2019t really touch those. If anyone is in these kind of roles, do you like it, and do you think the future is promising?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "126atge", "is_robot_indexable": true, "report_reasons": null, "author": "esperantisto256", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/126atge/careers_adjacent_to_civilenvironmental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/126atge/careers_adjacent_to_civilenvironmental/", "subreddit_subscribers": 865134, "created_utc": 1680148671.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}