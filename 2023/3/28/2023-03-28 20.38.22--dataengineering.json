{"kind": "Listing", "data": {"after": "t3_124auid", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m05ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State of Data Engineering 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_124d6qi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 247, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 247, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XmlxxjlEhCNUJSpfPjnRzbG1hzK9Z09cc4VEVqVrHyo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679978995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3rc8hxffueqa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?auto=webp&amp;v=enabled&amp;s=5bfc9a5f597301e66c74afd35b5ca66828c9dd16", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a13140d19c377599589380edb419b3a63b68b8f2", "width": 108, "height": 60}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43bad1618623404a3bf95da32678a69518d1fe54", "width": 216, "height": 121}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d786150cd0e697484cf1dd7b5ae2bdd2888cbe76", "width": 320, "height": 180}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defadaa89bef2c15d0d3a5a57771d3e5a295b248", "width": 640, "height": 360}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7231f337000a18a5fdbedadfbb539d3a07b9cdaa", "width": 960, "height": 540}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8208f54f0c1783e220f30b7f8cb69071fe240b39", "width": 1080, "height": 607}], "variants": {}, "id": "it_5DM1yYpIndVcCpr5Y7cS912omKACEHGt4msvndo0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "124d6qi", "is_robot_indexable": true, "report_reasons": null, "author": "SyntheticBlood", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124d6qi/state_of_data_engineering_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3rc8hxffueqa1.jpg", "subreddit_subscribers": 94715, "created_utc": 1679978995.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Join us in the Rockies for an unforgettable conference featuring thought-provoking talks, workshops, craft beer tasting, hiking, and immersive experiences that will change the way you think about software development. Grab your Early Bird Ticket: [https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687](https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687)", "author_fullname": "t2_qhroetn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big news! LambdaConf returns Sept 16-19th and is better than ever! \ud83d\udd25", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ozln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 103, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 103, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680010541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Join us in the Rockies for an unforgettable conference featuring thought-provoking talks, workshops, craft beer tasting, hiking, and immersive experiences that will change the way you think about software development. Grab your Early Bird Ticket: &lt;a href=\"https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687\"&gt;https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?auto=webp&amp;v=enabled&amp;s=6813a1ea4b5d401e335caa02583865546ee29898", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b30c45d7350f71944e7ed6d27d03555b62a91684", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0379a777f803e71a1b906de4a5bcb32220be1005", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa1fdba3bf291c3b14470d653f8ebd575fd72c25", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4436df3f9c64439cf26ced83657393f9c08df83", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/hxaI5-DAbMoirpEPh7pmnmb5D3Nu_ItAo1OKuGSxoos.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f84ac18aab2e94b4f7e4951bca30d20fc0fb70c8", "width": 960, "height": 480}], "variants": {}, "id": "DaWPZMpGJTzhhl3d5dsciFzXnZ4QqNEDthE7iz5CkU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "124ozln", "is_robot_indexable": true, "report_reasons": null, "author": "Agataziverge", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ozln/big_news_lambdaconf_returns_sept_1619th_and_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ozln/big_news_lambdaconf_returns_sept_1619th_and_is/", "subreddit_subscribers": 94715, "created_utc": 1680010541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_92dedrzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SMBC-comics.com \"now squeeze your points together to make your results look big\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_124mi0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680004763.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cz9tbicqygqa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cz9tbicqygqa1.png?auto=webp&amp;v=enabled&amp;s=90836b30830e55386ac9b7c92ee4ab49d5b8c5ef", "width": 684, "height": 710}, "resolutions": [{"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b7b39b47ef18f4c425929d90b90df902a33a95e", "width": 108, "height": 112}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b047fb2fa23d8baa5445531cf278c8b4c1f9f87", "width": 216, "height": 224}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31c15c84067af3ef3911763420b5fb26c12c1733", "width": 320, "height": 332}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6aec00547714de581430e536c536f33ac4a5d2d", "width": 640, "height": 664}], "variants": {"obfuscated": {"source": {"url": "https://preview.redd.it/cz9tbicqygqa1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6519edc62e55abdf79ca69bce3f2da3a4214ad1c", "width": 684, "height": 710}, "resolutions": [{"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3ff45f8a205382c9be541f2f1ed00b65d08d001d", "width": 108, "height": 112}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bb493ae483cf64ca6319edf4804d970b4a9fc724", "width": 216, "height": 224}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6730631a29389d92806643438810c7fad87eb076", "width": 320, "height": 332}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=96deb0aba516333cefd018f89758acbd383c1131", "width": 640, "height": 664}]}, "nsfw": {"source": {"url": "https://preview.redd.it/cz9tbicqygqa1.png?blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6519edc62e55abdf79ca69bce3f2da3a4214ad1c", "width": 684, "height": 710}, "resolutions": [{"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3ff45f8a205382c9be541f2f1ed00b65d08d001d", "width": 108, "height": 112}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bb493ae483cf64ca6319edf4804d970b4a9fc724", "width": 216, "height": 224}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6730631a29389d92806643438810c7fad87eb076", "width": 320, "height": 332}, {"url": "https://preview.redd.it/cz9tbicqygqa1.png?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=96deb0aba516333cefd018f89758acbd383c1131", "width": 640, "height": 664}]}}, "id": "o_ZfZakw9vonrfxEDxzx3f9eg682BMvwf-Xnnf7ApQ0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "124mi0z", "is_robot_indexable": true, "report_reasons": null, "author": "rackhamlerouge9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124mi0z/smbccomicscom_now_squeeze_your_points_together_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cz9tbicqygqa1.png", "subreddit_subscribers": 94715, "created_utc": 1680004763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This has been bugging me for a while and I wanted to discuss it with you all. I have been working with spark for around 3 years\n\nWhenever I'm working on long spark jobs or running multiple iterations of shorter ones, I get super unproductive just waiting around for them to finish. I understand its not like app development where we get instant feedback. \n\nBut switching to another story/task sometimes feels like an unnecessary context switch, plus if I start browsing or learning something new, it's tough to snap back into the job at hand. \n\nHave you been on similar boat? What do you all do to stay productive or what would you do during these slow moments?", "author_fullname": "t2_3xh5j7zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productivity advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124385k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679958443.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679956362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has been bugging me for a while and I wanted to discuss it with you all. I have been working with spark for around 3 years&lt;/p&gt;\n\n&lt;p&gt;Whenever I&amp;#39;m working on long spark jobs or running multiple iterations of shorter ones, I get super unproductive just waiting around for them to finish. I understand its not like app development where we get instant feedback. &lt;/p&gt;\n\n&lt;p&gt;But switching to another story/task sometimes feels like an unnecessary context switch, plus if I start browsing or learning something new, it&amp;#39;s tough to snap back into the job at hand. &lt;/p&gt;\n\n&lt;p&gt;Have you been on similar boat? What do you all do to stay productive or what would you do during these slow moments?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124385k", "is_robot_indexable": true, "report_reasons": null, "author": "thedatumgirl", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124385k/productivity_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124385k/productivity_advice/", "subreddit_subscribers": 94715, "created_utc": 1679956362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0582491b373e38549a189d8c406f6327e9fd1c12\n\n In this article, we will walk through the process of setting up a real-time data processing and analytics environment for vehicle plate recognition. We will use Docker to manage our services, MySQL for data storage, Redpanda as a streaming platform, MinIO as an object storage server, and Apache Spark for data processing and analysis. We will also integrate the Twilio API to send SMS notifications in real-time based on the processed data. \n\n [https://medium.com/@stefentaime\\_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6](https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time Data Processing and Analytics with Docker, MySQL, Redpanda, MinIO, and Apache Spark Using Delta Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nrphxx8szdqa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5ad116c34e71f9dddc755296b06b5fbfca17612"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2a3766df5dc7f7bed8f725018b33c3b5d98d668"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d19325c5e912c3313afb88cb0c3e62dfa4854c"}, {"y": 326, "x": 640, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=997910e0a155aff7db6589537f7fa19814a36d84"}, {"y": 489, "x": 960, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fb64d1ebb85065c96c92fe6aa424ca2499053f7"}, {"y": 550, "x": 1080, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2793f52fb54e2a7d99c413858cab1151399c655e"}], "s": {"y": 758, "x": 1487, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0582491b373e38549a189d8c406f6327e9fd1c12"}, "id": "nrphxx8szdqa1"}}, "name": "t3_1248ypa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ygQa3znhbllPikDzZ5Ad85cOuEeLID0dBfu1J4qxE_w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1679968719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0582491b373e38549a189d8c406f6327e9fd1c12\"&gt;https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0582491b373e38549a189d8c406f6327e9fd1c12&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this article, we will walk through the process of setting up a real-time data processing and analytics environment for vehicle plate recognition. We will use Docker to manage our services, MySQL for data storage, Redpanda as a streaming platform, MinIO as an object storage server, and Apache Spark for data processing and analysis. We will also integrate the Twilio API to send SMS notifications in real-time based on the processed data. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6\"&gt;https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?auto=webp&amp;v=enabled&amp;s=d066d16326714a53d5f2235ccf69b8330488159e", "width": 1200, "height": 612}, "resolutions": [{"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=831af4d9535c6d553e7ad13d321f3d41cf4fa042", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0049e4bce7a56d3702088e375a3bf1dbc39f44c4", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0d6921d5e93d70550a256263b7c5c84b0e001a2", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d2fcfae67450d7709ae9bf049d2bc150ddb83ab", "width": 640, "height": 326}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db987f4d6848bdbccdca3fd69301316d23bd41e9", "width": 960, "height": 489}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=694b9e88b7cd101394b4d181d51a3506e76f5ab1", "width": 1080, "height": 550}], "variants": {}, "id": "E6PYkGbAH391Mdwd0tNLuKTj6PQyMltA3JaiUv53pU4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1248ypa", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1248ypa/realtime_data_processing_and_analytics_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1248ypa/realtime_data_processing_and_analytics_with/", "subreddit_subscribers": 94715, "created_utc": 1679968719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey /r/dataengineering! \n\nI\u2019m Toby and over the last few months, I\u2019ve been working with a team of engineers from Airbnb, Apple, Google, and Netflix, to simplify developing data pipelines with [SQLMesh](https://github.com/TobikoData/sqlmesh). \n\nWe\u2019re tired of fragile pipelines, untested SQL queries, and expensive staging environments for data. Software engineers have reaped the benefits of DevOps through unit tests, continuous integration, and continuous deployment for years. We felt like it was time for data teams to have the same confidence and efficiency in development as their peers. It\u2019s time for DataOps!\n\nSQLMesh can be used through a CLI/notebook or in our open source web based IDE (in preview). SQLMesh builds efficient dev / staging environments through \u201cVirtual Data Marts\u201d using views, which allows you to seamlessly rollback or roll forward your changes! With a simple pointer swap you can promote your \u201cstaging\u201d data into production. This means you get unlimited copy-on-write environments that make data exploration and preview of changes cheap, easy, safe. Some other key features are:\n\n* Automatic DAG generation by semantically parsing and understanding SQL or Python scripts\n* CI-Runnable Unit and Integration tests with optional conversion to DuckDB\n* Change detection and reconciliation through column level lineage \n* Native Airflow Integration\n* Import an existing DBT project and run it on SQLMesh\u2019s runtime (in preview)\n\nWe\u2019re just getting started on our journey to change the way data pipelines are built and deployed. We\u2019re huge proponents of open source and hope that we can grow together with your feedback and contributions. Try out SQLMesh by following the [quick start guide](https://sqlmesh.readthedocs.io/en/stable/quick_start/). We\u2019d love to chat and hear about your experiences and ideas in our [Slack community](https://join.slack.com/t/tobiko-data/shared_invite/zt-1ma66d79v-a4dbf4DUpLAQJ8ptQrJygg).", "author_fullname": "t2_56xhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQLMesh: The future of DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124tspm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680019793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m Toby and over the last few months, I\u2019ve been working with a team of engineers from Airbnb, Apple, Google, and Netflix, to simplify developing data pipelines with &lt;a href=\"https://github.com/TobikoData/sqlmesh\"&gt;SQLMesh&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re tired of fragile pipelines, untested SQL queries, and expensive staging environments for data. Software engineers have reaped the benefits of DevOps through unit tests, continuous integration, and continuous deployment for years. We felt like it was time for data teams to have the same confidence and efficiency in development as their peers. It\u2019s time for DataOps!&lt;/p&gt;\n\n&lt;p&gt;SQLMesh can be used through a CLI/notebook or in our open source web based IDE (in preview). SQLMesh builds efficient dev / staging environments through \u201cVirtual Data Marts\u201d using views, which allows you to seamlessly rollback or roll forward your changes! With a simple pointer swap you can promote your \u201cstaging\u201d data into production. This means you get unlimited copy-on-write environments that make data exploration and preview of changes cheap, easy, safe. Some other key features are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Automatic DAG generation by semantically parsing and understanding SQL or Python scripts&lt;/li&gt;\n&lt;li&gt;CI-Runnable Unit and Integration tests with optional conversion to DuckDB&lt;/li&gt;\n&lt;li&gt;Change detection and reconciliation through column level lineage &lt;/li&gt;\n&lt;li&gt;Native Airflow Integration&lt;/li&gt;\n&lt;li&gt;Import an existing DBT project and run it on SQLMesh\u2019s runtime (in preview)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We\u2019re just getting started on our journey to change the way data pipelines are built and deployed. We\u2019re huge proponents of open source and hope that we can grow together with your feedback and contributions. Try out SQLMesh by following the &lt;a href=\"https://sqlmesh.readthedocs.io/en/stable/quick_start/\"&gt;quick start guide&lt;/a&gt;. We\u2019d love to chat and hear about your experiences and ideas in our &lt;a href=\"https://join.slack.com/t/tobiko-data/shared_invite/zt-1ma66d79v-a4dbf4DUpLAQJ8ptQrJygg\"&gt;Slack community&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "124tspm", "is_robot_indexable": true, "report_reasons": null, "author": "captaintobs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124tspm/sqlmesh_the_future_of_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124tspm/sqlmesh_the_future_of_dataops/", "subreddit_subscribers": 94715, "created_utc": 1680019793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've just completed my 3rd data project to help me understand how to work with Airflow and running services in Docker.\n\n# Links\n\n* [GitHub Repository](https://github.com/digitalghost-dev/global-data-pipeline)\n* [Looker Studio Visualization](https://lookerstudio.google.com/reporting/3710d6bb-25b2-4d64-b6e8-2889bc57c74b) \\- not a great experience on mobile, Air Quality page doesn't seem to load.\n* [Documentation](https://github.com/digitalghost-dev/global-data-pipeline/wiki/Global-Data-Pipeline-Documentation) \\- tried my best with this, will need to run through it again and proof read.\n* [Discord Server Invite](https://discord.gg/j2HEfpebuH) \\- feel free to join to see the bot in action. There is only one channel and it's locked down so not much do in here but thought I would add it in case someone was curious. The bot will query the database and look for the highest current\\_temp and will send a message with the city name and the temperature in celsius.\n\n# Overview\n\n* A `docker-compose.yml` file runs Airflow, Postgres, and Redis in Docker containers.\n* Python scripts reach out to different data sources to extract, transform and load the data into a Postgres database, orchestrated through Airflow on various schedules.\n* Using Airflow operators, data is moved from Postgres to Google Cloud Storage then to BigQuery where the data is visualized with Looker Studio.\n* A Discord Airflow operator is used to send a daily message to a server with current weather stats.\n\n# Data Sources\n\nThis project uses two APIs and web scrapes some tables from Wikipedia. All the city data derives from choosing the 50 most populated cities in the world according to [MacroTrends](https://www.macrotrends.net/cities/largest-cities-by-population).\n\n* City Weather - (updated hourly) with [Weatherstack](https://weatherstack.com) API - costs $10 a month for 50,000 calls.\n   * Current temperature, humidity, precipitation, wind speed\n* City Air Quality - (updated hourly) with [OpenWeatherMap](https://openweathermap.org) API\n   * CO, NO2, O2, SO2, PM2.5, PM10\n* City population\n* Country statistics\n   * Fertility rates, homicide rates, Human Development Index, unemployments rates\n\n[Flowchart](https://preview.redd.it/zz181kpt6iqa1.png?width=2112&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b1485fbb458838ec703bbaeceea381cd635d2db1)\n\n# Notes\n\nSetting up Airflow was pretty painless with the predefined `docker-compose.yml` file found [here](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html). I did have to modify the original file a bit to allow containers to talk to each other on my host machine.\n\nSpeaking of host machines, all of this is running on my desktop.\n\nLooker Studio is okay... it's free so I guess I can't complain too much but the experience for viewers on mobile is pretty bad.\n\nThe visualizations I made in Looker Studio are elementary at best but my goal wasn't to build the prettiest dashboard. I will continue to update it though in the future.", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My 3rd data project, with Airflow, Docker, Postgres, and Looker Studio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zz181kpt6iqa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1cecb6cf097ae6c7442827e55a85ef64d18ca18e"}, {"y": 131, "x": 216, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edb440a66cf60727d5afd2ed6492dfb5a622d3f2"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f297b107b70090c6504a542f6185a35a12dd231"}, {"y": 390, "x": 640, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d551441f10fa5dc8df7c67ed23fcf42348b6058a"}, {"y": 585, "x": 960, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cdf0fa788b94f59330fcbf6e3633ed26e63095f"}, {"y": 658, "x": 1080, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f60f656bbef58516246acbe6296c717f4b87d6fa"}], "s": {"y": 1288, "x": 2112, "u": "https://preview.redd.it/zz181kpt6iqa1.png?width=2112&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b1485fbb458838ec703bbaeceea381cd635d2db1"}, "id": "zz181kpt6iqa1"}}, "name": "t3_124wcjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EWJ1r_6hf0lhfYglqOaweEIFjMkf0VQ2GvKa6YqbKS0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1680025179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just completed my 3rd data project to help me understand how to work with Airflow and running services in Docker.&lt;/p&gt;\n\n&lt;h1&gt;Links&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/digitalghost-dev/global-data-pipeline\"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://lookerstudio.google.com/reporting/3710d6bb-25b2-4d64-b6e8-2889bc57c74b\"&gt;Looker Studio Visualization&lt;/a&gt; - not a great experience on mobile, Air Quality page doesn&amp;#39;t seem to load.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/digitalghost-dev/global-data-pipeline/wiki/Global-Data-Pipeline-Documentation\"&gt;Documentation&lt;/a&gt; - tried my best with this, will need to run through it again and proof read.&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://discord.gg/j2HEfpebuH\"&gt;Discord Server Invite&lt;/a&gt; - feel free to join to see the bot in action. There is only one channel and it&amp;#39;s locked down so not much do in here but thought I would add it in case someone was curious. The bot will query the database and look for the highest current_temp and will send a message with the city name and the temperature in celsius.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Overview&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A &lt;code&gt;docker-compose.yml&lt;/code&gt; file runs Airflow, Postgres, and Redis in Docker containers.&lt;/li&gt;\n&lt;li&gt;Python scripts reach out to different data sources to extract, transform and load the data into a Postgres database, orchestrated through Airflow on various schedules.&lt;/li&gt;\n&lt;li&gt;Using Airflow operators, data is moved from Postgres to Google Cloud Storage then to BigQuery where the data is visualized with Looker Studio.&lt;/li&gt;\n&lt;li&gt;A Discord Airflow operator is used to send a daily message to a server with current weather stats.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Data Sources&lt;/h1&gt;\n\n&lt;p&gt;This project uses two APIs and web scrapes some tables from Wikipedia. All the city data derives from choosing the 50 most populated cities in the world according to &lt;a href=\"https://www.macrotrends.net/cities/largest-cities-by-population\"&gt;MacroTrends&lt;/a&gt;.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;City Weather - (updated hourly) with &lt;a href=\"https://weatherstack.com\"&gt;Weatherstack&lt;/a&gt; API - costs $10 a month for 50,000 calls.\n\n&lt;ul&gt;\n&lt;li&gt;Current temperature, humidity, precipitation, wind speed&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;City Air Quality - (updated hourly) with &lt;a href=\"https://openweathermap.org\"&gt;OpenWeatherMap&lt;/a&gt; API\n\n&lt;ul&gt;\n&lt;li&gt;CO, NO2, O2, SO2, PM2.5, PM10&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;City population&lt;/li&gt;\n&lt;li&gt;Country statistics\n\n&lt;ul&gt;\n&lt;li&gt;Fertility rates, homicide rates, Human Development Index, unemployments rates&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zz181kpt6iqa1.png?width=2112&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=b1485fbb458838ec703bbaeceea381cd635d2db1\"&gt;Flowchart&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Notes&lt;/h1&gt;\n\n&lt;p&gt;Setting up Airflow was pretty painless with the predefined &lt;code&gt;docker-compose.yml&lt;/code&gt; file found &lt;a href=\"https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html\"&gt;here&lt;/a&gt;. I did have to modify the original file a bit to allow containers to talk to each other on my host machine.&lt;/p&gt;\n\n&lt;p&gt;Speaking of host machines, all of this is running on my desktop.&lt;/p&gt;\n\n&lt;p&gt;Looker Studio is okay... it&amp;#39;s free so I guess I can&amp;#39;t complain too much but the experience for viewers on mobile is pretty bad.&lt;/p&gt;\n\n&lt;p&gt;The visualizations I made in Looker Studio are elementary at best but my goal wasn&amp;#39;t to build the prettiest dashboard. I will continue to update it though in the future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?auto=webp&amp;v=enabled&amp;s=dc7b06ba82e2a238e6a1e9732af3c38e0694e6b0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bcb73cfd09ed2e135d54bf6ee2c9ce08e61fea7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f22c542e5e61014373bc88e9fb88fbf5f092391", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0bea044b442d5c5cfc86170d6673d169d1d8f14", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68a01789cc3524d21df30163274621bf690ed230", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=995876c9cdc7ea26d77e80bede7d8c18bdebb1db", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/OY3Ko27YXRMrmtg6ra2zTCt3gzZXBS9ijnsbDea84L8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60a5df26e9b64687f8eb5b08795cc711fd35424b", "width": 1080, "height": 540}], "variants": {}, "id": "65nZrXRToPy1C10OOcyNpu-vcLkcCd-DzvBSwTc_SbY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "124wcjb", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124wcjb/my_3rd_data_project_with_airflow_docker_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124wcjb/my_3rd_data_project_with_airflow_docker_postgres/", "subreddit_subscribers": 94715, "created_utc": 1680025179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently passed my DP-203 certification exam with the lowest score possible. I was a little sad bc I put in about 3 weeks of studying for it but at the end of the day... a pass is a pass.\n\n**Background:** I recently moved into a Cloud Data Eng role within my company a month ago. I had little to no experience with data eng. All I had was just course on the concept of ETL Data Warehousing. Previous experience role: Developer Analyst in my companies logistics domain working with our Global WMS solution.\n\n**Conclusion:** Test was a lot harder than expected. The exam consisted of curveballs and trick questions which made consistently second guess myself.  I read a couple of other ppls post on this sub that passed the exam and they made it sound like the exam was piece of cake. I think I may have struggled more because I had little to no real life hands on experience in regards to Data Eng. Also, exam went into more detail in regards to syntax as well as security and access. \n\n**Prep:** I prepared for about a month. Below is what I did\n\n1)My company payed for me to take the instructor led course offered on the Microsoft website and it was a complete nightmare/waste of time. The course was outsourced to a company named Koenig and they were struggling with the fact that microsoft had updated course content earlier this year in February. The instructor felt scripted and the labs did not match the course content. The instructor also had no real life experience and struggled with scenario based questions. For example, \"in which case would this distribution be best'?'... The only good thing about the course is that they later gave me a workaround lab environment with the updated labs which provided me with some simple generic hands on experience. I think besides the lab environments, I would suggest to take the self paced version and go through it in a manner where you understand the content with detail. The level of detail that they covered did not suffice the level of detail that exam questions covered.\n\n2)Practice test offered on Microsoft test: this were good but again did not match the level of detail that the questions of the exams consisted off. I would \\*\\*suggest\\*\\* getting the questions wrong and studying the corresponding links of the knowledge articles that they provide.\n\n3)Knowledge check questions on the course. Similar to the practice test\n\n4)Labs on the course . \\*\\*Recommend\\*\\*: reading knowledge articles corresponding to each lab\n\n5)[www.examtopics.com/exams/microsoft/dp-203](https://www.examtopics.com/exams/microsoft/dp-203) : I didn't hit this that hard but I would recommend doing so. These are the type of questions that are on the exams.\n\nPlease feel free to reach out if you guys have any questions.", "author_fullname": "t2_hi3uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently passed DP-203 Certification Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124t0qi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680018157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently passed my DP-203 certification exam with the lowest score possible. I was a little sad bc I put in about 3 weeks of studying for it but at the end of the day... a pass is a pass.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; I recently moved into a Cloud Data Eng role within my company a month ago. I had little to no experience with data eng. All I had was just course on the concept of ETL Data Warehousing. Previous experience role: Developer Analyst in my companies logistics domain working with our Global WMS solution.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt; Test was a lot harder than expected. The exam consisted of curveballs and trick questions which made consistently second guess myself.  I read a couple of other ppls post on this sub that passed the exam and they made it sound like the exam was piece of cake. I think I may have struggled more because I had little to no real life hands on experience in regards to Data Eng. Also, exam went into more detail in regards to syntax as well as security and access. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Prep:&lt;/strong&gt; I prepared for about a month. Below is what I did&lt;/p&gt;\n\n&lt;p&gt;1)My company payed for me to take the instructor led course offered on the Microsoft website and it was a complete nightmare/waste of time. The course was outsourced to a company named Koenig and they were struggling with the fact that microsoft had updated course content earlier this year in February. The instructor felt scripted and the labs did not match the course content. The instructor also had no real life experience and struggled with scenario based questions. For example, &amp;quot;in which case would this distribution be best&amp;#39;?&amp;#39;... The only good thing about the course is that they later gave me a workaround lab environment with the updated labs which provided me with some simple generic hands on experience. I think besides the lab environments, I would suggest to take the self paced version and go through it in a manner where you understand the content with detail. The level of detail that they covered did not suffice the level of detail that exam questions covered.&lt;/p&gt;\n\n&lt;p&gt;2)Practice test offered on Microsoft test: this were good but again did not match the level of detail that the questions of the exams consisted off. I would **suggest** getting the questions wrong and studying the corresponding links of the knowledge articles that they provide.&lt;/p&gt;\n\n&lt;p&gt;3)Knowledge check questions on the course. Similar to the practice test&lt;/p&gt;\n\n&lt;p&gt;4)Labs on the course . **Recommend**: reading knowledge articles corresponding to each lab&lt;/p&gt;\n\n&lt;p&gt;5)&lt;a href=\"https://www.examtopics.com/exams/microsoft/dp-203\"&gt;www.examtopics.com/exams/microsoft/dp-203&lt;/a&gt; : I didn&amp;#39;t hit this that hard but I would recommend doing so. These are the type of questions that are on the exams.&lt;/p&gt;\n\n&lt;p&gt;Please feel free to reach out if you guys have any questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "124t0qi", "is_robot_indexable": true, "report_reasons": null, "author": "Jpvilla5454", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124t0qi/recently_passed_dp203_certification_exam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124t0qi/recently_passed_dp203_certification_exam/", "subreddit_subscribers": 94715, "created_utc": 1680018157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI'm data engineer with about 2 yrs experience. Working with SQL and Python on different projects in a SaaS startup. \nDo you recommend getting an online master or cloud certificates like AWS data engineer for career development? Aiming +140k CAD in next 2-3 years. \n\nThanks :)", "author_fullname": "t2_bfz4zq58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online Master Vs Cloud Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1243iwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679956939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m data engineer with about 2 yrs experience. Working with SQL and Python on different projects in a SaaS startup. \nDo you recommend getting an online master or cloud certificates like AWS data engineer for career development? Aiming +140k CAD in next 2-3 years. &lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1243iwk", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Ad_8085", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1243iwk/online_master_vs_cloud_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1243iwk/online_master_vs_cloud_certification/", "subreddit_subscribers": 94715, "created_utc": 1679956939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to get some tips or guidance regarding tools, pipeline or resources on building a simple datapipeline that runs daily and fetches the data from an sql database.\n\nWhere I have the most questions is after pulling the data from the sql database, and transform it and load it into s3, how can I make sure that the next day the new records added will be pulled and inserted into its respective tables? I don't think well built pipelines fetch all the tables on a daily basis, but the new information. (How to keep track of new records and old ones that were edited) \n\nThank you so much for your time", "author_fullname": "t2_5x9e117l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to insert new updates to dwh from transactional database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ebk0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679981134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to get some tips or guidance regarding tools, pipeline or resources on building a simple datapipeline that runs daily and fetches the data from an sql database.&lt;/p&gt;\n\n&lt;p&gt;Where I have the most questions is after pulling the data from the sql database, and transform it and load it into s3, how can I make sure that the next day the new records added will be pulled and inserted into its respective tables? I don&amp;#39;t think well built pipelines fetch all the tables on a daily basis, but the new information. (How to keep track of new records and old ones that were edited) &lt;/p&gt;\n\n&lt;p&gt;Thank you so much for your time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124ebk0", "is_robot_indexable": true, "report_reasons": null, "author": "readoyniando", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ebk0/how_to_insert_new_updates_to_dwh_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ebk0/how_to_insert_new_updates_to_dwh_from/", "subreddit_subscribers": 94715, "created_utc": 1679981134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I'm wondering if it's possible to automatically check if a) all columns and b) all models in my dbt project have docstrings, so I can include this check in my cicd tests to ensure that my dwh is fully documented for downstream teams. Any tips would be appreciated. Google results didn't yield what I was looking for, and neither did looking at the dbt docs.", "author_fullname": "t2_68y0hb6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt - is it possible to test it all docstrings are present?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ampx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679972755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I&amp;#39;m wondering if it&amp;#39;s possible to automatically check if a) all columns and b) all models in my dbt project have docstrings, so I can include this check in my cicd tests to ensure that my dwh is fully documented for downstream teams. Any tips would be appreciated. Google results didn&amp;#39;t yield what I was looking for, and neither did looking at the dbt docs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124ampx", "is_robot_indexable": true, "report_reasons": null, "author": "the_Wallie", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ampx/dbt_is_it_possible_to_test_it_all_docstrings_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ampx/dbt_is_it_possible_to_test_it_all_docstrings_are/", "subreddit_subscribers": 94715, "created_utc": 1679972755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel like frontend developers get a better developer experience as they can see impact from their code instantly on the browser as they update the code locally. Have you experienced something similar, where you can see the impact of your code changes on the data, using an iso-prod environment and that within seconds or minutes?", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best developer experience you had as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124nms9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680007509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like frontend developers get a better developer experience as they can see impact from their code instantly on the browser as they update the code locally. Have you experienced something similar, where you can see the impact of your code changes on the data, using an iso-prod environment and that within seconds or minutes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124nms9", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124nms9/what_is_the_best_developer_experience_you_had_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124nms9/what_is_the_best_developer_experience_you_had_as/", "subreddit_subscribers": 94715, "created_utc": 1680007509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the moment I'm loading to a temporary table, and if that succeeds I'm deleting that date range from my final table, then copying from temp -&gt; live. I'd like to avoid the extra copy step if possible. How can I do this?\n\nI see there's an option for [preactions](https://docs.snowflake.com/en/user-guide/spark-connector-use#setting-configuration-options-for-the-connector) with the Snowflake Spark connector but after testing it doesn't look like these commands roll back if the load fails.\n\nEDIT: Solved! Preactions/postactions can be rolled into a transaction with the data transfer by combining options as per [this article](https://community.snowflake.com/s/article/How-To-Execute-the-queries-under-a-transaction-in-Spark-connector).", "author_fullname": "t2_22ksp1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark to Snowflake: How to delete from table prior to load, but only if load is successful", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1245jyh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1680018328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679961088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the moment I&amp;#39;m loading to a temporary table, and if that succeeds I&amp;#39;m deleting that date range from my final table, then copying from temp -&amp;gt; live. I&amp;#39;d like to avoid the extra copy step if possible. How can I do this?&lt;/p&gt;\n\n&lt;p&gt;I see there&amp;#39;s an option for &lt;a href=\"https://docs.snowflake.com/en/user-guide/spark-connector-use#setting-configuration-options-for-the-connector\"&gt;preactions&lt;/a&gt; with the Snowflake Spark connector but after testing it doesn&amp;#39;t look like these commands roll back if the load fails.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Solved! Preactions/postactions can be rolled into a transaction with the data transfer by combining options as per &lt;a href=\"https://community.snowflake.com/s/article/How-To-Execute-the-queries-under-a-transaction-in-Spark-connector\"&gt;this article&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1245jyh", "is_robot_indexable": true, "report_reasons": null, "author": "x1084", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1245jyh/pyspark_to_snowflake_how_to_delete_from_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1245jyh/pyspark_to_snowflake_how_to_delete_from_table/", "subreddit_subscribers": 94715, "created_utc": 1679961088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just got the greenlight to implement airflow. What do you find the most scalable way to use it for ETL?\nDont feel pressured to answer everything. Any advice could help .\n\n Here's some background info:\n\n1. Handling Confidential data, not allowed to be on main ETL with rest of business. \n\n2. We just built a server with a fresh install\n\n3. I am the only data engineer outside ETL team. \n\n4. Using postgres data warehouse for this project.\n\n5. 6 different source systems, with API or SFTP drops.\n\n6. I usually  Use psycopg2 execute values because it's super fast. Pandas to SQL always seems too slow, but I love pandas for transformations before loading. I convert df to tuple value for speed.\n\nNow, here are my questions on extract and load:\n\nIn airflow, using python operator:\n\nHow do you structure the tasks within your DAG? Do you build the ETL all in a single task? Or do you split the extract, transform, load into different  tasks and make them a task group? If you don't need to transform (outside of selecting which fields you want from the API json format) is it cool to just put it all in one task? \n\nIf you need data from 10 different methods from a rest API , and are just doing a raw data pull, I am trying to determine if that should be 10,20 or 30 tasks. \n\nFor the loads in your DAG, are you passing the same connection to each of your functions, or are your tasks opening and closing the connections as they complete? ( Committing along the way)\n\nDo you use bash operator at all? Bash operator would be nice because we have a ton of stuff on cron and all of the scripts are built to run pull and load raw data. We could just swap to a different scheduler. At the same time, I have freedom and time to make this an ideal implementation. \n\n\n\n\nTransformations:\n\nNot allowed to use dbt, so the team before me made a bunch of view on view relationships to do transforms. They are BI analysts with no real tech support until now. I plan on using dbt cli in dev to re create the views as tables (or ephemeral if not used in any downstream queries and tables) and then stealing the create table scripts out of the target folder as a starting place and tweaking, adding some referential integrity, etc. \n\nDbt was really nice with scheduling transformations and building DAGs for them as you go. Airflow seems more manual (but way better than cron or view on view). How do you manage tons of different SQL based transformations? Are you using python operator to werap your SQL in ? or are you executing SQL files via bash operator?\n\nAnd I guess I'll leave it there.", "author_fullname": "t2_7mo0tj9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most ideal Airflow task structure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124mxjc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680005842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just got the greenlight to implement airflow. What do you find the most scalable way to use it for ETL?\nDont feel pressured to answer everything. Any advice could help .&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s some background info:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Handling Confidential data, not allowed to be on main ETL with rest of business. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;We just built a server with a fresh install&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am the only data engineer outside ETL team. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Using postgres data warehouse for this project.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;6 different source systems, with API or SFTP drops.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I usually  Use psycopg2 execute values because it&amp;#39;s super fast. Pandas to SQL always seems too slow, but I love pandas for transformations before loading. I convert df to tuple value for speed.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Now, here are my questions on extract and load:&lt;/p&gt;\n\n&lt;p&gt;In airflow, using python operator:&lt;/p&gt;\n\n&lt;p&gt;How do you structure the tasks within your DAG? Do you build the ETL all in a single task? Or do you split the extract, transform, load into different  tasks and make them a task group? If you don&amp;#39;t need to transform (outside of selecting which fields you want from the API json format) is it cool to just put it all in one task? &lt;/p&gt;\n\n&lt;p&gt;If you need data from 10 different methods from a rest API , and are just doing a raw data pull, I am trying to determine if that should be 10,20 or 30 tasks. &lt;/p&gt;\n\n&lt;p&gt;For the loads in your DAG, are you passing the same connection to each of your functions, or are your tasks opening and closing the connections as they complete? ( Committing along the way)&lt;/p&gt;\n\n&lt;p&gt;Do you use bash operator at all? Bash operator would be nice because we have a ton of stuff on cron and all of the scripts are built to run pull and load raw data. We could just swap to a different scheduler. At the same time, I have freedom and time to make this an ideal implementation. &lt;/p&gt;\n\n&lt;p&gt;Transformations:&lt;/p&gt;\n\n&lt;p&gt;Not allowed to use dbt, so the team before me made a bunch of view on view relationships to do transforms. They are BI analysts with no real tech support until now. I plan on using dbt cli in dev to re create the views as tables (or ephemeral if not used in any downstream queries and tables) and then stealing the create table scripts out of the target folder as a starting place and tweaking, adding some referential integrity, etc. &lt;/p&gt;\n\n&lt;p&gt;Dbt was really nice with scheduling transformations and building DAGs for them as you go. Airflow seems more manual (but way better than cron or view on view). How do you manage tons of different SQL based transformations? Are you using python operator to werap your SQL in ? or are you executing SQL files via bash operator?&lt;/p&gt;\n\n&lt;p&gt;And I guess I&amp;#39;ll leave it there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124mxjc", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Ranger_5", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124mxjc/most_ideal_airflow_task_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124mxjc/most_ideal_airflow_task_structure/", "subreddit_subscribers": 94715, "created_utc": 1680005842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.  Over the last few months we have been developing an open source CI/CD platform for dbt.\n\nThough it's possible to do CI/CD and orchestration with Gitlab, Jenkins, Airflow etc, I felt there was an opportunity to do something specific for dbt.  This would reduce the need to build a custom pipeline and mean that we could build a GUI that is tailored to Data Engineers.  \n\nThe bigger aim is also to help Data Engineers adopt a strict development workflow, with pull requests, environments, source control, CI/CD etc as sometimes this is lacking.  \n\nI would be really interested in any constructive feedback and thoughts on the idea and the more general problem of CI/CD with dbt and data transformation code.\n\nDemo video here - [https://www.youtube.com/watch?v=-s-bULKecvY&amp;t=64s](https://www.youtube.com/watch?v=-s-bULKecvY&amp;t=64s)\n\nIntroductory blog post here - [https://timeflow.systems/blog/introducing-timeflow](https://timeflow.systems/blog/introducing-timeflow)", "author_fullname": "t2_599jquwy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interested in thoughts on a CI/CD platform for dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124jhu3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679996823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.  Over the last few months we have been developing an open source CI/CD platform for dbt.&lt;/p&gt;\n\n&lt;p&gt;Though it&amp;#39;s possible to do CI/CD and orchestration with Gitlab, Jenkins, Airflow etc, I felt there was an opportunity to do something specific for dbt.  This would reduce the need to build a custom pipeline and mean that we could build a GUI that is tailored to Data Engineers.  &lt;/p&gt;\n\n&lt;p&gt;The bigger aim is also to help Data Engineers adopt a strict development workflow, with pull requests, environments, source control, CI/CD etc as sometimes this is lacking.  &lt;/p&gt;\n\n&lt;p&gt;I would be really interested in any constructive feedback and thoughts on the idea and the more general problem of CI/CD with dbt and data transformation code.&lt;/p&gt;\n\n&lt;p&gt;Demo video here - &lt;a href=\"https://www.youtube.com/watch?v=-s-bULKecvY&amp;amp;t=64s\"&gt;https://www.youtube.com/watch?v=-s-bULKecvY&amp;amp;t=64s&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Introductory blog post here - &lt;a href=\"https://timeflow.systems/blog/introducing-timeflow\"&gt;https://timeflow.systems/blog/introducing-timeflow&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wUvpuFvCbiBrKmgzAE51FmYH7I8w9Z8Oy7ssZvxNmMw.jpg?auto=webp&amp;v=enabled&amp;s=f3f3b026ff445ae93f720d470dbdbbd81bcd6d89", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/wUvpuFvCbiBrKmgzAE51FmYH7I8w9Z8Oy7ssZvxNmMw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf8f7ed84a73d257380e708f1bca6ab553436dfb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/wUvpuFvCbiBrKmgzAE51FmYH7I8w9Z8Oy7ssZvxNmMw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8a148459d5a3f1fd8bb082cd8e79c00fa55e844", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/wUvpuFvCbiBrKmgzAE51FmYH7I8w9Z8Oy7ssZvxNmMw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81794c66641227265b59927a713c6b8eed4dcdf4", "width": 320, "height": 240}], "variants": {}, "id": "Bk_76OB7iZZqNzV4J6Xz67nCfxKHvNH4IGGQd2J6RVo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "124jhu3", "is_robot_indexable": true, "report_reasons": null, "author": "benjaminwootton888", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124jhu3/interested_in_thoughts_on_a_cicd_platform_for_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124jhu3/interested_in_thoughts_on_a_cicd_platform_for_dbt/", "subreddit_subscribers": 94715, "created_utc": 1679996823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had planned to put together some beginners training material to cover the gambit from data collection and monitoring to analytics and reporting. Having recently joined this community, I have noticed some themes that made me want to ask: what would you like if you were new to data engineering? \n\nAdditionally, what sort of content? How detailed and technical? Does the tech stack matter? Do you prefer apps and code or Jupyter Notebooks? Let me know your thoughts! \n\nThanks and cheers all \ud83d\udcaa\ud83c\udffb", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes for good DE training material?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_124zowl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680032238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had planned to put together some beginners training material to cover the gambit from data collection and monitoring to analytics and reporting. Having recently joined this community, I have noticed some themes that made me want to ask: what would you like if you were new to data engineering? &lt;/p&gt;\n\n&lt;p&gt;Additionally, what sort of content? How detailed and technical? Does the tech stack matter? Do you prefer apps and code or Jupyter Notebooks? Let me know your thoughts! &lt;/p&gt;\n\n&lt;p&gt;Thanks and cheers all \ud83d\udcaa\ud83c\udffb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124zowl", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124zowl/what_makes_for_good_de_training_material/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124zowl/what_makes_for_good_de_training_material/", "subreddit_subscribers": 94715, "created_utc": 1680032238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently built a Data Catalog ROI Template to assist data people in evaluating the value and impact of their data catalog investments. Data catalogs are all the rage, but are we really getting the most out of them?  I'd love to get your feedback:\n\n\ud83d\udd17 [**Data Catalog ROI Template**](https://www.castordoc.com/blog/data-catalog-roi-a-primer)\n\nThis template will help you:\n\n1. Gauge your data catalog's current state and spot growth potential\n2. Pinpoint improvement areas to optimize performance\n3. Measure your data catalog's tangible benefits\n\nShare your feedback &amp; ideas to improve it.", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog ROI Template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124y0d8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1680028697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently built a Data Catalog ROI Template to assist data people in evaluating the value and impact of their data catalog investments. Data catalogs are all the rage, but are we really getting the most out of them?  I&amp;#39;d love to get your feedback:&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17 &lt;a href=\"https://www.castordoc.com/blog/data-catalog-roi-a-primer\"&gt;&lt;strong&gt;Data Catalog ROI Template&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This template will help you:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Gauge your data catalog&amp;#39;s current state and spot growth potential&lt;/li&gt;\n&lt;li&gt;Pinpoint improvement areas to optimize performance&lt;/li&gt;\n&lt;li&gt;Measure your data catalog&amp;#39;s tangible benefits&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Share your feedback &amp;amp; ideas to improve it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?auto=webp&amp;v=enabled&amp;s=2a34d956b4a6d3ac1880cdaeb89cbca64fb60ff2", "width": 1692, "height": 884}, "resolutions": [{"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b856feaa0456c35484f8e54bd714db9492aeece1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=207bf9a6898283f0d1439dd4f63dbfadec8fa701", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5313d3b5f2d563bcd54420d52ddd2cf1c33e27c8", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2986b7515841c0ce590048052d5af6783d11c36a", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f0a94bb36543c9ce1d5ac6e4ca53bf69eb69fa4", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/222mY5BSOGC-OD3ZSnmJxrRGa-KCal9aubA41u66CMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11d3ccfaeb8aac987f157348ca18b1cd2f39c525", "width": 1080, "height": 564}], "variants": {}, "id": "zs6zgWh0o00ZqNct8b7a2b5xz2XX77i6_ThrG6WNQY8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124y0d8", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124y0d8/data_catalog_roi_template/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124y0d8/data_catalog_roi_template/", "subreddit_subscribers": 94715, "created_utc": 1680028697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI like to do a personal project and welcome any advice, feedback, recommendations. First, an intro so you know my starting position.\n\n\\- I work in Data Analytics, Management, Governance, including the quality control, process improvement, stakeholder management, and creating internal tools.  \n\\- I've always been interested in the tech/IT side and truly excited and fascinated about all the available stuff these days, which is one of two reasons for this project  \n\\- I did research on 100 data-related manager/lead/director job openings (in my region) and one of the things that was mentioned in 78% of them was \"... knowledge and experiences of data pipelines, how they work, what every part does (on high level), and able to see opportunities to make it more effective, better quality checks, better security, and maximize the value\"; I fully agree with this requirement because even though I might not be the one who will actually do all this stuff, I find it important to understand what the department does, and what my IT colleagues are telling me.\n\n**So what am I thinking off (ballpark)**\n\n\\- not a giant spaghetti that will likely become an untamable beast to complete, but not a super small one just to guarantee success, I like a challenge and it needs to be valuable and relevant to today's business challenges  \n\\- something modular, so I can start with one part and at the end, it works, then move to a second part to expand the pipeline, not necessarily linear, but perhaps a side-chain  \n\\- a bit with automation and a bit with automated SQL transformation  \n\\- a bit with manual input, maybe to validate data which triggers different flows  \n\\- creating custom datasets specifically for this project (but I don't need a million datapoints please)  \n\\- a pipeline that is intentionally not 1000% optimized, I want it to reflect the common situation of companies growing their pipelines along the way to the point that it's just barely/acceptable to manage lol (you know what I mean) \n\n**What do I have available?**\n\n\\- MS 365 + Power Platform  \n\\- PostgreSQL and MySQL in cloud, plus dbeaver  \n\\- Retool\n\n**What Have I been looking at?**\n\n\\- Fivetran for both orchestration and transformation\n\n**What I want to exclude**\n\n\\- anything that requires me to be a programmer, I'm definitely not and will likely drown in the project due to the scripting part\n\n**What I am asking you**\n\nI've been trying to come up with the project content for two months and just drawing blank, coming up with something from scratch has never been my strong suit. I like to ask you for ideas.\n\nYou can throw anything to me: words, stories, bullet-points, even (or especially) sketches of pipelines that you ~~recommend~~ challenge me to do.\n\nThanks for reading and taking the effort to help.\n\nCheers.", "author_fullname": "t2_kh3ubtce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doing a personal project as a non-DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124v675", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680022693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I like to do a personal project and welcome any advice, feedback, recommendations. First, an intro so you know my starting position.&lt;/p&gt;\n\n&lt;p&gt;- I work in Data Analytics, Management, Governance, including the quality control, process improvement, stakeholder management, and creating internal tools.&lt;br/&gt;\n- I&amp;#39;ve always been interested in the tech/IT side and truly excited and fascinated about all the available stuff these days, which is one of two reasons for this project&lt;br/&gt;\n- I did research on 100 data-related manager/lead/director job openings (in my region) and one of the things that was mentioned in 78% of them was &amp;quot;... knowledge and experiences of data pipelines, how they work, what every part does (on high level), and able to see opportunities to make it more effective, better quality checks, better security, and maximize the value&amp;quot;; I fully agree with this requirement because even though I might not be the one who will actually do all this stuff, I find it important to understand what the department does, and what my IT colleagues are telling me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So what am I thinking off (ballpark)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- not a giant spaghetti that will likely become an untamable beast to complete, but not a super small one just to guarantee success, I like a challenge and it needs to be valuable and relevant to today&amp;#39;s business challenges&lt;br/&gt;\n- something modular, so I can start with one part and at the end, it works, then move to a second part to expand the pipeline, not necessarily linear, but perhaps a side-chain&lt;br/&gt;\n- a bit with automation and a bit with automated SQL transformation&lt;br/&gt;\n- a bit with manual input, maybe to validate data which triggers different flows&lt;br/&gt;\n- creating custom datasets specifically for this project (but I don&amp;#39;t need a million datapoints please)&lt;br/&gt;\n- a pipeline that is intentionally not 1000% optimized, I want it to reflect the common situation of companies growing their pipelines along the way to the point that it&amp;#39;s just barely/acceptable to manage lol (you know what I mean) &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What do I have available?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- MS 365 + Power Platform&lt;br/&gt;\n- PostgreSQL and MySQL in cloud, plus dbeaver&lt;br/&gt;\n- Retool&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What Have I been looking at?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Fivetran for both orchestration and transformation&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I want to exclude&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- anything that requires me to be a programmer, I&amp;#39;m definitely not and will likely drown in the project due to the scripting part&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I am asking you&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to come up with the project content for two months and just drawing blank, coming up with something from scratch has never been my strong suit. I like to ask you for ideas.&lt;/p&gt;\n\n&lt;p&gt;You can throw anything to me: words, stories, bullet-points, even (or especially) sketches of pipelines that you &lt;del&gt;recommend&lt;/del&gt; challenge me to do.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading and taking the effort to help.&lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124v675", "is_robot_indexable": true, "report_reasons": null, "author": "SquidsAndMartians", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124v675/doing_a_personal_project_as_a_nonde/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124v675/doing_a_personal_project_as_a_nonde/", "subreddit_subscribers": 94715, "created_utc": 1680022693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modeling, Visualizing, and Navigating a Transportation Network with Memgraph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_124nrnn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PIL_MqQBQnNitwsKOx28oRm-wvsdrXPtNVHxFxIuF3o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1680007823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/modeling-visualizing-navigating-a-transportation-network-with-memgraph", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?auto=webp&amp;v=enabled&amp;s=0c9f1b23bba282af67a247becd39519c0edbe17c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14ff056a80c39be180153fce59b2081bdeba8410", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8077d07db4e4c707984c73abab7eaee45f9f7c0", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0d59358e6ad575e0a5713660b78fd51b3b02f84", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68774c1f2e0e7d990b9f90069676d51b0d9f9cd1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4e0dc784f7bdb785a87fd524d6b846b89bf524f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-Hd4GDVZvJ2NWXM8_7PL81uV4r8flKuKXogDlLdQvIs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47361b6a6eb55fc89a8d1c50c67dbc1b5c29eab5", "width": 1080, "height": 540}], "variants": {}, "id": "N-DWmh8WkOxwsiQVxILtoW-lg1gVclggDSKUbODSu2M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "124nrnn", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124nrnn/modeling_visualizing_and_navigating_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/modeling-visualizing-navigating-a-transportation-network-with-memgraph", "subreddit_subscribers": 94715, "created_utc": 1680007823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll get to the point. I am taking as a premise that Sketch Engine and AntConc, which are commonly used for concordance searches, lie within the realm of data engineering inasmuch as they facilitate data. My understanding is that both accept data in XML, meaning that you can bring in a linguistic corpus with a predefined scheme for the tags and the software knows how to handle this. Am I correct about this?   \nEven if it's not the two examples I've noted, is it true that there is software which allows for data analysis (of varying sophistication) where the input is an XML document with its schema?  \n\n\nMany thanks in advance!", "author_fullname": "t2_graxcz2q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Quick Question] How do software such as Sketch Engine and AntConc work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ndnm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1680006917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll get to the point. I am taking as a premise that Sketch Engine and AntConc, which are commonly used for concordance searches, lie within the realm of data engineering inasmuch as they facilitate data. My understanding is that both accept data in XML, meaning that you can bring in a linguistic corpus with a predefined scheme for the tags and the software knows how to handle this. Am I correct about this?&lt;br/&gt;\nEven if it&amp;#39;s not the two examples I&amp;#39;ve noted, is it true that there is software which allows for data analysis (of varying sophistication) where the input is an XML document with its schema?  &lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124ndnm", "is_robot_indexable": true, "report_reasons": null, "author": "alpolvovolvere", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ndnm/quick_question_how_do_software_such_as_sketch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ndnm/quick_question_how_do_software_such_as_sketch/", "subreddit_subscribers": 94715, "created_utc": 1680006917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My expectations:\n\n&amp;#x200B;\n\n1. Open Source\n2. Relatively simple\n3. Support for SparQL", "author_fullname": "t2_8w2gvpfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please recommend a graph DB like RedisGraph but with SparQL support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124kfrg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679999665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My expectations:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Open Source&lt;/li&gt;\n&lt;li&gt;Relatively simple&lt;/li&gt;\n&lt;li&gt;Support for SparQL&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124kfrg", "is_robot_indexable": true, "report_reasons": null, "author": "Vitaly_v_ch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124kfrg/please_recommend_a_graph_db_like_redisgraph_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124kfrg/please_recommend_a_graph_db_like_redisgraph_but/", "subreddit_subscribers": 94715, "created_utc": 1679999665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,.\nWhat could be the best way to built Zoho CRM or any other crm streaming data pipeline inside gcp?\nI am thinking to use bigquery as a data warehouse. But confused about which tool to use or which will be better and cost efficient in this case. Any suggestions will be appreciated.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline for Zoho/other CRM in gcp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ira5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679994579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,.\nWhat could be the best way to built Zoho CRM or any other crm streaming data pipeline inside gcp?\nI am thinking to use bigquery as a data warehouse. But confused about which tool to use or which will be better and cost efficient in this case. Any suggestions will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124ira5", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ira5/data_pipeline_for_zohoother_crm_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ira5/data_pipeline_for_zohoother_crm_in_gcp/", "subreddit_subscribers": 94715, "created_utc": 1679994579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The org that I work for has never had wide adoption of a BI tool and insists on interacting with our data almost exclusively in the form of grids or tables. The data team has long been attempting to push for adoption of a BI tool in order to improve user data experience and push data literacy forward. Unfortunately, some people within the org do not see the leverage that visualizations and ease of data exploration can create so we do not put any resources towards education on our data tooling or structures. Has anyone had luck improving a situation like this? Any research/resources you would recommend that would be helpful in this endeavor?", "author_fullname": "t2_ahqse5d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Research on Graphs vs Grids?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124eqjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679982333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The org that I work for has never had wide adoption of a BI tool and insists on interacting with our data almost exclusively in the form of grids or tables. The data team has long been attempting to push for adoption of a BI tool in order to improve user data experience and push data literacy forward. Unfortunately, some people within the org do not see the leverage that visualizations and ease of data exploration can create so we do not put any resources towards education on our data tooling or structures. Has anyone had luck improving a situation like this? Any research/resources you would recommend that would be helpful in this endeavor?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124eqjr", "is_robot_indexable": true, "report_reasons": null, "author": "Express-Comb8675", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124eqjr/research_on_graphs_vs_grids/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124eqjr/research_on_graphs_vs_grids/", "subreddit_subscribers": 94715, "created_utc": 1679982333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First, This forum has helped me a lot in my journey toward data engineering. A lot of discussions and posts got me interested and made me realize the importance and value of Data engineering. Bit of a long post. Thanks a lot for taking the time to read it.\n\nShort: I am starting grad school, and the market seems crazy. How should I prepare to enter the workforce as a fresh grad and hopefully find a job?\n\nLong: I have been admitted into the MS Data Science program offered by the Software Engineering Department at RIT. The reason for this program is the curriculum and the focus on the SWE aspect of DS, Scholarship, and many elective options in SWE.\n\nI did a three-year degree, a BSc in Computer Science. I loved building automation and systems. I often find myself writing and deploying serverless scripts to send emails or alerts to my mobile to track specific events. I spend a lot of time in hackathons where I build backends for all my apps and websites.\n\nI have been working as a Data Engineer for an AI Startup focusing on Improving Debugging and Code generation. I design and work on their data pipelines and handle their deployment into GKE. My work also includes adapting the pipelines to use Dask. A lot of time, I needed more fundamental knowledge and figured I needed more time to learn and explore.\n\nQ1) I am planning to take courses on Parallel, and Distributed computing, NLP, and System Design. Am I on the right path?\n\nCurrently, I am proficient in Python, but I can't say the same for Java or C++.Q2) Is it Ideal to invest more time in java since many legacy systems are in Java and might be handy during interviews?\n\nQ3) Should I plan to get certifications? Does it really help?  \n\n\n Thanks a lot for reading through this. I would love to know how I can prepare myself.  \n( P.s: Reposting it since my prev post had a link to my resume, which breaks rule 8 )", "author_fullname": "t2_7vv90qx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I moving in the right direction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124b7ap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679974206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, This forum has helped me a lot in my journey toward data engineering. A lot of discussions and posts got me interested and made me realize the importance and value of Data engineering. Bit of a long post. Thanks a lot for taking the time to read it.&lt;/p&gt;\n\n&lt;p&gt;Short: I am starting grad school, and the market seems crazy. How should I prepare to enter the workforce as a fresh grad and hopefully find a job?&lt;/p&gt;\n\n&lt;p&gt;Long: I have been admitted into the MS Data Science program offered by the Software Engineering Department at RIT. The reason for this program is the curriculum and the focus on the SWE aspect of DS, Scholarship, and many elective options in SWE.&lt;/p&gt;\n\n&lt;p&gt;I did a three-year degree, a BSc in Computer Science. I loved building automation and systems. I often find myself writing and deploying serverless scripts to send emails or alerts to my mobile to track specific events. I spend a lot of time in hackathons where I build backends for all my apps and websites.&lt;/p&gt;\n\n&lt;p&gt;I have been working as a Data Engineer for an AI Startup focusing on Improving Debugging and Code generation. I design and work on their data pipelines and handle their deployment into GKE. My work also includes adapting the pipelines to use Dask. A lot of time, I needed more fundamental knowledge and figured I needed more time to learn and explore.&lt;/p&gt;\n\n&lt;p&gt;Q1) I am planning to take courses on Parallel, and Distributed computing, NLP, and System Design. Am I on the right path?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am proficient in Python, but I can&amp;#39;t say the same for Java or C++.Q2) Is it Ideal to invest more time in java since many legacy systems are in Java and might be handy during interviews?&lt;/p&gt;\n\n&lt;p&gt;Q3) Should I plan to get certifications? Does it really help?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for reading through this. I would love to know how I can prepare myself.&lt;br/&gt;\n( P.s: Reposting it since my prev post had a link to my resume, which breaks rule 8 )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "124b7ap", "is_robot_indexable": true, "report_reasons": null, "author": "Anush_Krishna", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124b7ap/am_i_moving_in_the_right_direction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124b7ap/am_i_moving_in_the_right_direction/", "subreddit_subscribers": 94715, "created_utc": 1679974206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uao4xuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to document your Snowflake code in 15 lines of code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "name": "t3_124auid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/52_eIguTFY4pN5Y0X4L3PgLfW-vFoEso-Myj4uxRenA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679973297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@adrian.white/documenting-your-code-how-to-generate-sql-documentation-in-15-lines-of-code-on-snowflake-c5fcec458440", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?auto=webp&amp;v=enabled&amp;s=7b10d921c4058f56dda986d51074fbf807083273", "width": 1200, "height": 343}, "resolutions": [{"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=224c181a005974a46fa0d1ee296e90b2a3ab06cf", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebf68966cc587428bc896871a4c28000c75be324", "width": 216, "height": 61}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa64eeecef4a3d98ef5e4f377af636b1530fb586", "width": 320, "height": 91}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eaea7a1ed9a24109646b66c5a9d0ee5fde84c5f", "width": 640, "height": 182}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3b786510a740c83bc29361f7c5e1d2b0038ec08", "width": 960, "height": 274}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69e479740ec499861c978053c761497edb20b7ed", "width": 1080, "height": 308}], "variants": {}, "id": "4ZjZaWAhfpkni37IOJUqRx7zmk5FIbg1mwgOMzyELGk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "124auid", "is_robot_indexable": true, "report_reasons": null, "author": "Jazzlike_Use6242", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124auid/how_to_document_your_snowflake_code_in_15_lines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@adrian.white/documenting-your-code-how-to-generate-sql-documentation-in-15-lines-of-code-on-snowflake-c5fcec458440", "subreddit_subscribers": 94715, "created_utc": 1679973297.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}