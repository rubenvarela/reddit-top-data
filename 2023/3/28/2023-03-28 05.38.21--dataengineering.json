{"kind": "Listing", "data": {"after": "t3_123vw7d", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&gt; It is simply a remnant of olden times, when it was used in contrast to batch processing. \"Online\" here means \"interactive\", that is, requests to the database are processed as they come and responses are given more or less immediately, or at least as soon as they are available. Batch processing would collect requests into, well, batches, and execute them on schedule; responses would be given after the entire batch execution (e.g. next morning).\n&gt;\n&gt;Abbreviations OLAP and OLTP hint at another historical artifact: [\"on-line\" used to be the more common spelling](https://english.stackexchange.com/questions/42044/which-is-correct-on-line-or-online) until mid-1980s.\n\nQuestion by user Zeruno answered by user mustaccio on StackExchange: https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp", "author_fullname": "t2_2yhiey78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exactly is the 'online' in OLAP and OLTP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123ie4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679911893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It is simply a remnant of olden times, when it was used in contrast to batch processing. &amp;quot;Online&amp;quot; here means &amp;quot;interactive&amp;quot;, that is, requests to the database are processed as they come and responses are given more or less immediately, or at least as soon as they are available. Batch processing would collect requests into, well, batches, and execute them on schedule; responses would be given after the entire batch execution (e.g. next morning).&lt;/p&gt;\n\n&lt;p&gt;Abbreviations OLAP and OLTP hint at another historical artifact: &lt;a href=\"https://english.stackexchange.com/questions/42044/which-is-correct-on-line-or-online\"&gt;&amp;quot;on-line&amp;quot; used to be the more common spelling&lt;/a&gt; until mid-1980s.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Question by user Zeruno answered by user mustaccio on StackExchange: &lt;a href=\"https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp\"&gt;https://dba.stackexchange.com/questions/240914/what-exactly-is-the-online-in-olap-and-oltp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?auto=webp&amp;v=enabled&amp;s=74121b8dbe2d32656e0828dd46b7915292ff355f", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6f8f5dd5b697e40a402a89c3a14d4e0c06cf737", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/1jRkwRUgnjv1KcM1xBZT7JqcIvwbUYhAFdztwkqwYQ8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fbff4349eb0afb2c9e14bdf8d8fd62d5e1953fc3", "width": 216, "height": 216}], "variants": {}, "id": "soV_PhsRxi7AgK_X5wV0MsICON67aUdimkXPFGxvnRg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Architect / Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123ie4i", "is_robot_indexable": true, "report_reasons": null, "author": "sib_n", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/123ie4i/what_exactly_is_the_online_in_olap_and_oltp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123ie4i/what_exactly_is_the_online_in_olap_and_oltp/", "subreddit_subscribers": 94636, "created_utc": 1679911893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This has been bugging me for a while and I wanted to discuss it with you all. I have been working with spark for around 3 years\n\nWhenever I'm working on long spark jobs or running multiple iterations of shorter ones, I get super unproductive just waiting around for them to finish. I understand its not like app development where we get instant feedback. \n\nBut switching to another story/task sometimes feels like an unnecessary context switch, plus if I start browsing or learning something new, it's tough to snap back into the job at hand. \n\nHave you been on similar boat? What do you all do to stay productive or what would you do during these slow moments?", "author_fullname": "t2_3xh5j7zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Productivity advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124385k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679958443.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679956362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has been bugging me for a while and I wanted to discuss it with you all. I have been working with spark for around 3 years&lt;/p&gt;\n\n&lt;p&gt;Whenever I&amp;#39;m working on long spark jobs or running multiple iterations of shorter ones, I get super unproductive just waiting around for them to finish. I understand its not like app development where we get instant feedback. &lt;/p&gt;\n\n&lt;p&gt;But switching to another story/task sometimes feels like an unnecessary context switch, plus if I start browsing or learning something new, it&amp;#39;s tough to snap back into the job at hand. &lt;/p&gt;\n\n&lt;p&gt;Have you been on similar boat? What do you all do to stay productive or what would you do during these slow moments?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "124385k", "is_robot_indexable": true, "report_reasons": null, "author": "thedatumgirl", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124385k/productivity_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124385k/productivity_advice/", "subreddit_subscribers": 94636, "created_utc": 1679956362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow vs Dagster - side by side comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_123d9st", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-uBTubhIxv2SrqYtjAjOyGy9itDShCPfy9EhdbN5Y8I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679896868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decube.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decube.io/post/apache-airflow-vs-dagster-side-by-side-comparison", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?auto=webp&amp;v=enabled&amp;s=c5f35e689cc56793fcdee93ccbf45d6127a92486", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e015e48a5988af103a576e83103edb2df4ab6b56", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33c69037e3fb9b9cabcfedd695007b219d0d1770", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/MwqO-eIA37BJe_yIb7c6f3N4Ltdm3KVVtBJMmNiZsc8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=466ae7a5652f7acc420034ed8dd1870be6a49634", "width": 320, "height": 168}], "variants": {}, "id": "_FuosWqJIC8e662XQzsbk2Y6-CMMfZ8p7TNNNHh6lPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "123d9st", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123d9st/apache_airflow_vs_dagster_side_by_side_comparison/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decube.io/post/apache-airflow-vs-dagster-side-by-side-comparison", "subreddit_subscribers": 94636, "created_utc": 1679896868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the pros and cons of both? Actually I am facing so many issues in deploying Airflow that I give up and I am thinking that I should try step functions because it might be easy to deploy and maintain.  \n\n\nPS : If you can give any good deployment guide for someone who is new to cloud that would be helpful too", "author_fullname": "t2_q27tep12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs Step Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123x94t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679944719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the pros and cons of both? Actually I am facing so many issues in deploying Airflow that I give up and I am thinking that I should try step functions because it might be easy to deploy and maintain.  &lt;/p&gt;\n\n&lt;p&gt;PS : If you can give any good deployment guide for someone who is new to cloud that would be helpful too&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123x94t", "is_robot_indexable": true, "report_reasons": null, "author": "__albatross", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123x94t/airflow_vs_step_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123x94t/airflow_vs_step_functions/", "subreddit_subscribers": 94636, "created_utc": 1679944719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently been reading the \"Data Mesh\" book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.\n\nThe author discusses the idea of \u201cdata as an asset\u201d and how it has dominated our big data management approach. The point the author makes is that \u201cdata as an asset\u201d mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.\n\nSince I don't have first-hand experience about it, I wanted to ask about the metrics currently being used to measure 'success of data. I know that hoarding data for the sake of it is an existing problem, but I'm hoping there are other measurement systems put in place\n\nThis is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.\n\n**TLDR**: *How do you measure the quality/success of your data independent from the value extraction process?*", "author_fullname": "t2_vbmhoyul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to measure the value of data apart from the process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123mypf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679924461.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679923758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently been reading the &amp;quot;Data Mesh&amp;quot; book, and it has been an interesting read so far. As someone who mainly works as a DBA, I have limited experience in data engineering structures. However, I came across a particular passage in the book that got me thinking about how we measure success in data that is collected.&lt;/p&gt;\n\n&lt;p&gt;The author discusses the idea of \u201cdata as an asset\u201d and how it has dominated our big data management approach. The point the author makes is that \u201cdata as an asset\u201d mentality led us to measure success by hoarding as much data as possible, rather than its actual impact on performance. She suggests shifting our perspective to view data as a product, which emphasizes product-thinking, continuous care, and user satisfaction, etc.&lt;/p&gt;\n\n&lt;p&gt;Since I don&amp;#39;t have first-hand experience about it, I wanted to ask about the metrics currently being used to measure &amp;#39;success of data. I know that hoarding data for the sake of it is an existing problem, but I&amp;#39;m hoping there are other measurement systems put in place&lt;/p&gt;\n\n&lt;p&gt;This is not necessarily about the lead time or the value extracted at the end of the flow but more about the value of data independently lying around in our warehouses or lakes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: &lt;em&gt;How do you measure the quality/success of your data independent from the value extraction process?&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123mypf", "is_robot_indexable": true, "report_reasons": null, "author": "Immediate-Mud-2996", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123mypf/how_to_measure_the_value_of_data_apart_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123mypf/how_to_measure_the_value_of_data_apart_from_the/", "subreddit_subscribers": 94636, "created_utc": 1679923758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I made it to the second round for a data engineering interview. Contrary to the first interview being a 1 hour video call, the 2nd interview is a 1 hour in-person interview. It's a remote job, so they are aware I am a 2.5 hour train trip away from the offices where the interview will be held. \n\nI've asked what format the interview will take and the answer was vague: \"they just want to ask more technical questions to gauge your experience and how they can support you in the role\".\n\nI like to prepare, and I like to prepare well. So my question to this sub-reddit is: what could they possibly want from me in-person that requires a 5 hour round trip commute that they cannot get in a video call?\n\nAre you thinking tests and live coding?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens at an in-person 2nd round interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123vraz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679941725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made it to the second round for a data engineering interview. Contrary to the first interview being a 1 hour video call, the 2nd interview is a 1 hour in-person interview. It&amp;#39;s a remote job, so they are aware I am a 2.5 hour train trip away from the offices where the interview will be held. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve asked what format the interview will take and the answer was vague: &amp;quot;they just want to ask more technical questions to gauge your experience and how they can support you in the role&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I like to prepare, and I like to prepare well. So my question to this sub-reddit is: what could they possibly want from me in-person that requires a 5 hour round trip commute that they cannot get in a video call?&lt;/p&gt;\n\n&lt;p&gt;Are you thinking tests and live coding?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "123vraz", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123vraz/what_happens_at_an_inperson_2nd_round_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123vraz/what_happens_at_an_inperson_2nd_round_interview/", "subreddit_subscribers": 94636, "created_utc": 1679941725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0582491b373e38549a189d8c406f6327e9fd1c12\n\n In this article, we will walk through the process of setting up a real-time data processing and analytics environment for vehicle plate recognition. We will use Docker to manage our services, MySQL for data storage, Redpanda as a streaming platform, MinIO as an object storage server, and Apache Spark for data processing and analysis. We will also integrate the Twilio API to send SMS notifications in real-time based on the processed data. \n\n [https://medium.com/@stefentaime\\_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6](https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time Data Processing and Analytics with Docker, MySQL, Redpanda, MinIO, and Apache Spark Using Delta Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nrphxx8szdqa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5ad116c34e71f9dddc755296b06b5fbfca17612"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2a3766df5dc7f7bed8f725018b33c3b5d98d668"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d19325c5e912c3313afb88cb0c3e62dfa4854c"}, {"y": 326, "x": 640, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=997910e0a155aff7db6589537f7fa19814a36d84"}, {"y": 489, "x": 960, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fb64d1ebb85065c96c92fe6aa424ca2499053f7"}, {"y": 550, "x": 1080, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2793f52fb54e2a7d99c413858cab1151399c655e"}], "s": {"y": 758, "x": 1487, "u": "https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0582491b373e38549a189d8c406f6327e9fd1c12"}, "id": "nrphxx8szdqa1"}}, "name": "t3_1248ypa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ygQa3znhbllPikDzZ5Ad85cOuEeLID0dBfu1J4qxE_w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1679968719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0582491b373e38549a189d8c406f6327e9fd1c12\"&gt;https://preview.redd.it/nrphxx8szdqa1.png?width=1487&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0582491b373e38549a189d8c406f6327e9fd1c12&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In this article, we will walk through the process of setting up a real-time data processing and analytics environment for vehicle plate recognition. We will use Docker to manage our services, MySQL for data storage, Redpanda as a streaming platform, MinIO as an object storage server, and Apache Spark for data processing and analysis. We will also integrate the Twilio API to send SMS notifications in real-time based on the processed data. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6\"&gt;https://medium.com/@stefentaime_10958/real-time-data-processing-and-analytics-with-docker-mysql-redpanda-minio-and-apache-spark-eca83f210ef6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?auto=webp&amp;v=enabled&amp;s=d066d16326714a53d5f2235ccf69b8330488159e", "width": 1200, "height": 612}, "resolutions": [{"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=831af4d9535c6d553e7ad13d321f3d41cf4fa042", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0049e4bce7a56d3702088e375a3bf1dbc39f44c4", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0d6921d5e93d70550a256263b7c5c84b0e001a2", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d2fcfae67450d7709ae9bf049d2bc150ddb83ab", "width": 640, "height": 326}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db987f4d6848bdbccdca3fd69301316d23bd41e9", "width": 960, "height": 489}, {"url": "https://external-preview.redd.it/IW1GXFCD2SMjmgzvyCi8QIHZXoCbz_6nbPAyzypvG5w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=694b9e88b7cd101394b4d181d51a3506e76f5ab1", "width": 1080, "height": 550}], "variants": {}, "id": "E6PYkGbAH391Mdwd0tNLuKTj6PQyMltA3JaiUv53pU4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1248ypa", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1248ypa/realtime_data_processing_and_analytics_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1248ypa/realtime_data_processing_and_analytics_with/", "subreddit_subscribers": 94636, "created_utc": 1679968719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm interested to hear what other people's first DE role entailed. I've been in my first DE role for over 2 months and I'm having some doubts about it. I came from an analyst job where I was an important member of the team and I knew I made a difference, to a DE team where I feel like I haven't progressed at all in.\n\nIn my time as a DE all I've really done is learn and try to pass certificates, which is good for my CV, but it hasn't made me any more knowledgeable about the job I'm doing. In the few non-certificate tasks I've been doing (pipelines, data processing in notebooks etc) I've not really had the support or training to complete the tasks and I get blocked/stuck very easily, which makes me feel very stupid. It often takes my manager a day to get round to helping me too, which leads me to looking back at the certificates.\n\nI just want to know if this is normal or not when you are starting out? Should I give it time? Are there DE jobs out there where you get hands on training by a colleague which takes precedence over doing certificates?\n\nThanks!", "author_fullname": "t2_igpqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your first experience as a DE like? few concerns about mine..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123l9ua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679919356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested to hear what other people&amp;#39;s first DE role entailed. I&amp;#39;ve been in my first DE role for over 2 months and I&amp;#39;m having some doubts about it. I came from an analyst job where I was an important member of the team and I knew I made a difference, to a DE team where I feel like I haven&amp;#39;t progressed at all in.&lt;/p&gt;\n\n&lt;p&gt;In my time as a DE all I&amp;#39;ve really done is learn and try to pass certificates, which is good for my CV, but it hasn&amp;#39;t made me any more knowledgeable about the job I&amp;#39;m doing. In the few non-certificate tasks I&amp;#39;ve been doing (pipelines, data processing in notebooks etc) I&amp;#39;ve not really had the support or training to complete the tasks and I get blocked/stuck very easily, which makes me feel very stupid. It often takes my manager a day to get round to helping me too, which leads me to looking back at the certificates.&lt;/p&gt;\n\n&lt;p&gt;I just want to know if this is normal or not when you are starting out? Should I give it time? Are there DE jobs out there where you get hands on training by a colleague which takes precedence over doing certificates?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123l9ua", "is_robot_indexable": true, "report_reasons": null, "author": "fastidiousthoughts", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123l9ua/what_was_your_first_experience_as_a_de_like_few/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123l9ua/what_was_your_first_experience_as_a_de_like_few/", "subreddit_subscribers": 94636, "created_utc": 1679919356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello together,\n\nMy job is about automating data processing for subsequent data science purposes. I'm curious to exchange knowledge with you and learn from each other!\n\nSo, I'm curious to learn what data processing techniques you use in your job? What data pipeline tools do you use/ dont use? What are the biggest challenges you face? \n\nThank you for your contributions!", "author_fullname": "t2_7yyt4sc3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does data processing look like at our work? Let's learn from each other!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123gnes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679906469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello together,&lt;/p&gt;\n\n&lt;p&gt;My job is about automating data processing for subsequent data science purposes. I&amp;#39;m curious to exchange knowledge with you and learn from each other!&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m curious to learn what data processing techniques you use in your job? What data pipeline tools do you use/ dont use? What are the biggest challenges you face? &lt;/p&gt;\n\n&lt;p&gt;Thank you for your contributions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123gnes", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzled-Lime141", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123gnes/how_does_data_processing_look_like_at_our_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123gnes/how_does_data_processing_look_like_at_our_work/", "subreddit_subscribers": 94636, "created_utc": 1679906469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've recently built a POC for Synapse Dedicated Pool, I used Synapse Pipelines to pull data from on premise, landed it in to the Data Lake and then in to an import table in a Dedicated Pool, then ran transformations with SPROC's (every 15 minutes)\n\nI landed the data in the data lake for two reasons:\n\n1) Polybase load in to Dedicated Pool\n2) To have a year/month/day/.. record of data loaded\n\nFor my main fact I have to join around 10-12 tables together, any of which could change, ranging from an order date of today back to 2008, so I couldn't see any way around having staging tables (other than using Spark &amp; Delta Lake, but I didn't want to spend even more on compute!)\n\nForgetting Dedicated Pool for a minute, the Synapse Pipelines alone for 50 or so tables is too expensive (running every 15 minutes)\n\nMy questions are:\n\n1) Does this architecture make sense?\n2) Is the cloud just expensive?  Or am I missing something?\n\nAny help or advice would be appreciated as I'm pulling my hair out with all the different options out there!\n\nFor context we're probably generating around 15GB of data a day, our key tables are a couple of hundred million rows.  We want to incrementally refresh every 15 minutes.", "author_fullname": "t2_9h6gf9pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Stack Help/Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123tztx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679938095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently built a POC for Synapse Dedicated Pool, I used Synapse Pipelines to pull data from on premise, landed it in to the Data Lake and then in to an import table in a Dedicated Pool, then ran transformations with SPROC&amp;#39;s (every 15 minutes)&lt;/p&gt;\n\n&lt;p&gt;I landed the data in the data lake for two reasons:&lt;/p&gt;\n\n&lt;p&gt;1) Polybase load in to Dedicated Pool\n2) To have a year/month/day/.. record of data loaded&lt;/p&gt;\n\n&lt;p&gt;For my main fact I have to join around 10-12 tables together, any of which could change, ranging from an order date of today back to 2008, so I couldn&amp;#39;t see any way around having staging tables (other than using Spark &amp;amp; Delta Lake, but I didn&amp;#39;t want to spend even more on compute!)&lt;/p&gt;\n\n&lt;p&gt;Forgetting Dedicated Pool for a minute, the Synapse Pipelines alone for 50 or so tables is too expensive (running every 15 minutes)&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;p&gt;1) Does this architecture make sense?\n2) Is the cloud just expensive?  Or am I missing something?&lt;/p&gt;\n\n&lt;p&gt;Any help or advice would be appreciated as I&amp;#39;m pulling my hair out with all the different options out there!&lt;/p&gt;\n\n&lt;p&gt;For context we&amp;#39;re probably generating around 15GB of data a day, our key tables are a couple of hundred million rows.  We want to incrementally refresh every 15 minutes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123tztx", "is_robot_indexable": true, "report_reasons": null, "author": "V10Matt", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123tztx/modern_stack_helpadvice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123tztx/modern_stack_helpadvice/", "subreddit_subscribers": 94636, "created_utc": 1679938095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many layers should there be in a typical data warehouse? I know my question is broad and not specific. For instance, at the company I am currently working at, we have three layers, the first one being the raw layer which we call acquisition, the second one being the conformed layer where we create normalized tables like Inmon suggests, and finally the third layer which we call Semantic which is basically fact and dimensions modelled in a Kimball way. I am curious to see if there is any literature on this topic and how one should go about architecting a data warehouse?", "author_fullname": "t2_7gmjdawc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data warehouse architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123hsbw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679910114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many layers should there be in a typical data warehouse? I know my question is broad and not specific. For instance, at the company I am currently working at, we have three layers, the first one being the raw layer which we call acquisition, the second one being the conformed layer where we create normalized tables like Inmon suggests, and finally the third layer which we call Semantic which is basically fact and dimensions modelled in a Kimball way. I am curious to see if there is any literature on this topic and how one should go about architecting a data warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123hsbw", "is_robot_indexable": true, "report_reasons": null, "author": "afnan_shahid1992", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123hsbw/data_warehouse_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123hsbw/data_warehouse_architecture/", "subreddit_subscribers": 94636, "created_utc": 1679910114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the moment I'm loading to a temporary table, and if that succeeds I'm deleting that date range from my final table, then copying from temp -&gt; live. I'd like to avoid the extra copy step if possible. How can I do this?\n\nI see there's an option for [preactions](https://docs.snowflake.com/en/user-guide/spark-connector-use#setting-configuration-options-for-the-connector) with the Snowflake Spark connector but after testing it doesn't look like these commands don't roll back if the load fails.\n\n  \nEDIT: Solved! Preactions/postactions can be rolled into a transaction with the data transfer by combining options as per [this article](https://community.snowflake.com/s/article/How-To-Execute-the-queries-under-a-transaction-in-Spark-connector).", "author_fullname": "t2_22ksp1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark to Snowflake: How to delete from table prior to load, but only if load is successful", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1245jyh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679980966.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679961088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the moment I&amp;#39;m loading to a temporary table, and if that succeeds I&amp;#39;m deleting that date range from my final table, then copying from temp -&amp;gt; live. I&amp;#39;d like to avoid the extra copy step if possible. How can I do this?&lt;/p&gt;\n\n&lt;p&gt;I see there&amp;#39;s an option for &lt;a href=\"https://docs.snowflake.com/en/user-guide/spark-connector-use#setting-configuration-options-for-the-connector\"&gt;preactions&lt;/a&gt; with the Snowflake Spark connector but after testing it doesn&amp;#39;t look like these commands don&amp;#39;t roll back if the load fails.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Solved! Preactions/postactions can be rolled into a transaction with the data transfer by combining options as per &lt;a href=\"https://community.snowflake.com/s/article/How-To-Execute-the-queries-under-a-transaction-in-Spark-connector\"&gt;this article&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1245jyh", "is_robot_indexable": true, "report_reasons": null, "author": "x1084", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1245jyh/pyspark_to_snowflake_how_to_delete_from_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1245jyh/pyspark_to_snowflake_how_to_delete_from_table/", "subreddit_subscribers": 94636, "created_utc": 1679961088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI'm data engineer with about 2 yrs experience. Working with SQL and Python on different projects in a SaaS startup. \nDo you recommend getting an online master or cloud certificates like AWS data engineer for career development? Aiming +140k CAD in next 2-3 years. \n\nThanks :)", "author_fullname": "t2_bfz4zq58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online Master Vs Cloud Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1243iwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679956939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m data engineer with about 2 yrs experience. Working with SQL and Python on different projects in a SaaS startup. \nDo you recommend getting an online master or cloud certificates like AWS data engineer for career development? Aiming +140k CAD in next 2-3 years. &lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1243iwk", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Ad_8085", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1243iwk/online_master_vs_cloud_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1243iwk/online_master_vs_cloud_certification/", "subreddit_subscribers": 94636, "created_utc": 1679956939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I'm wondering if it's possible to automatically check if a) all columns and b) all models in my dbt project have docstrings, so I can include this check in my cicd tests to ensure that my dwh is fully documented for downstream teams. Any tips would be appreciated. Google results didn't yield what I was looking for, and neither did looking at the dbt docs.", "author_fullname": "t2_68y0hb6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt - is it possible to test it all docstrings are present?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124ampx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679972755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I&amp;#39;m wondering if it&amp;#39;s possible to automatically check if a) all columns and b) all models in my dbt project have docstrings, so I can include this check in my cicd tests to ensure that my dwh is fully documented for downstream teams. Any tips would be appreciated. Google results didn&amp;#39;t yield what I was looking for, and neither did looking at the dbt docs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "124ampx", "is_robot_indexable": true, "report_reasons": null, "author": "the_Wallie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124ampx/dbt_is_it_possible_to_test_it_all_docstrings_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124ampx/dbt_is_it_possible_to_test_it_all_docstrings_are/", "subreddit_subscribers": 94636, "created_utc": 1679972755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a new initiative, and I need a data visualization tool that can be syndicated out to internal teams as well as external 3rd parties (business partners) to share common dashboards.\n\nI have not used Looker in a loooooong time (Pre-Google acquisition), so I am taking a fresh look at the new [https://datastudio.withgoogle.com/](https://datastudio.withgoogle.com/) thingy.  \nAre people using it in this kind of set-up? \n\nIt would be a high latency (\\~ twice daily refresh) setup with just a handful of KPIs on the dash.", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happened to Looker/Google Data Studio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123tojm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679937452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a new initiative, and I need a data visualization tool that can be syndicated out to internal teams as well as external 3rd parties (business partners) to share common dashboards.&lt;/p&gt;\n\n&lt;p&gt;I have not used Looker in a loooooong time (Pre-Google acquisition), so I am taking a fresh look at the new &lt;a href=\"https://datastudio.withgoogle.com/\"&gt;https://datastudio.withgoogle.com/&lt;/a&gt; thingy.&lt;br/&gt;\nAre people using it in this kind of set-up? &lt;/p&gt;\n\n&lt;p&gt;It would be a high latency (~ twice daily refresh) setup with just a handful of KPIs on the dash.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123tojm", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123tojm/what_happened_to_lookergoogle_data_studio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123tojm/what_happened_to_lookergoogle_data_studio/", "subreddit_subscribers": 94636, "created_utc": 1679937452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have sql code that turns a column into a list of values. \n\nSelect array_agg(distinct resortcode) as list_of_resorts \nfrom res_restrict \nWhere list name in (\u2018je\u2019, \u2018ps\u2019);\n\nI want to set a variable in Snowflake to reference this list in later queries in my worksheet.  Example -&gt; \u201cWhen resort_id not in $list_of_resorts\u201d instead of hard coding the the list of resorts \n\nThanks", "author_fullname": "t2_7xrbvyn2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake SQL - variable to store a list of values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123x96w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679944722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have sql code that turns a column into a list of values. &lt;/p&gt;\n\n&lt;p&gt;Select array_agg(distinct resortcode) as list_of_resorts \nfrom res_restrict \nWhere list name in (\u2018je\u2019, \u2018ps\u2019);&lt;/p&gt;\n\n&lt;p&gt;I want to set a variable in Snowflake to reference this list in later queries in my worksheet.  Example -&amp;gt; \u201cWhen resort_id not in $list_of_resorts\u201d instead of hard coding the the list of resorts &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "123x96w", "is_robot_indexable": true, "report_reasons": null, "author": "KMG3IU", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123x96w/snowflake_sql_variable_to_store_a_list_of_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123x96w/snowflake_sql_variable_to_store_a_list_of_values/", "subreddit_subscribers": 94636, "created_utc": 1679944722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, for example, you have dimensional models and so on, but you also have pdfs, images etc.\n\nHow would you go about it? \n\nI cannot find any good articles/resources on this.\n\nFrom the very few resources I've found, it appears that you can either:\n\n* have a table e.g. customer, which also has column(s) containing pointers to a separate  path of the delta lake containing some kind of file (e.g. image)\n* turn the image to binary file, and create a table with it, containing as columns metadata, like user\\_id, file\\_format (and anything else you want) and save it as table with saveAsTable. The only drawback here is the input/output bottleneck since this would include moving huge amounts of data back and forth.\n\n&amp;#x200B;\n\nIf you go with the first approach, you practically dump whatever unstructured data you have, in a location inside delta lake. But what best practices would you want to keep in mind? Would just dumping files at department/project/item/date be ok? \n\nI understand that this would get hectic really really fast.  Any documentation/article etc would be greatly appreciated.\n\n&amp;#x200B;\n\nThanks in advance.", "author_fullname": "t2_3cuv2cgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model Structured and Unstructured Data together in Delta Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123ieya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679911960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, for example, you have dimensional models and so on, but you also have pdfs, images etc.&lt;/p&gt;\n\n&lt;p&gt;How would you go about it? &lt;/p&gt;\n\n&lt;p&gt;I cannot find any good articles/resources on this.&lt;/p&gt;\n\n&lt;p&gt;From the very few resources I&amp;#39;ve found, it appears that you can either:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;have a table e.g. customer, which also has column(s) containing pointers to a separate  path of the delta lake containing some kind of file (e.g. image)&lt;/li&gt;\n&lt;li&gt;turn the image to binary file, and create a table with it, containing as columns metadata, like user_id, file_format (and anything else you want) and save it as table with saveAsTable. The only drawback here is the input/output bottleneck since this would include moving huge amounts of data back and forth.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you go with the first approach, you practically dump whatever unstructured data you have, in a location inside delta lake. But what best practices would you want to keep in mind? Would just dumping files at department/project/item/date be ok? &lt;/p&gt;\n\n&lt;p&gt;I understand that this would get hectic really really fast.  Any documentation/article etc would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "123ieya", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent-Style6371", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123ieya/model_structured_and_unstructured_data_together/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123ieya/model_structured_and_unstructured_data_together/", "subreddit_subscribers": 94636, "created_utc": 1679911960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working in python as backend developer for 2.5 years. I am thinking of switching my role to data engineer. Can someone suggest me what steps should I take or what resources can I start from to find a job as a data engineer or should I take up a course if yes then do you know any good course providers near mumbai", "author_fullname": "t2_4hecp9t0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some advice to switch my role to data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_124da5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679979155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working in python as backend developer for 2.5 years. I am thinking of switching my role to data engineer. Can someone suggest me what steps should I take or what resources can I start from to find a job as a data engineer or should I take up a course if yes then do you know any good course providers near mumbai&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "124da5f", "is_robot_indexable": true, "report_reasons": null, "author": "IllustriousPeak4648", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124da5f/i_need_some_advice_to_switch_my_role_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124da5f/i_need_some_advice_to_switch_my_role_to_data/", "subreddit_subscribers": 94636, "created_utc": 1679979155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m05ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State of Data Engineering 2022", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_124d6qi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XmlxxjlEhCNUJSpfPjnRzbG1hzK9Z09cc4VEVqVrHyo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679978995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/3rc8hxffueqa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?auto=webp&amp;v=enabled&amp;s=5bfc9a5f597301e66c74afd35b5ca66828c9dd16", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a13140d19c377599589380edb419b3a63b68b8f2", "width": 108, "height": 60}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43bad1618623404a3bf95da32678a69518d1fe54", "width": 216, "height": 121}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d786150cd0e697484cf1dd7b5ae2bdd2888cbe76", "width": 320, "height": 180}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defadaa89bef2c15d0d3a5a57771d3e5a295b248", "width": 640, "height": 360}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7231f337000a18a5fdbedadfbb539d3a07b9cdaa", "width": 960, "height": 540}, {"url": "https://preview.redd.it/3rc8hxffueqa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8208f54f0c1783e220f30b7f8cb69071fe240b39", "width": 1080, "height": 607}], "variants": {}, "id": "it_5DM1yYpIndVcCpr5Y7cS912omKACEHGt4msvndo0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "124d6qi", "is_robot_indexable": true, "report_reasons": null, "author": "SyntheticBlood", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124d6qi/state_of_data_engineering_2022/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/3rc8hxffueqa1.jpg", "subreddit_subscribers": 94636, "created_utc": 1679978995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody done or know what the interview process for Data Engineer is at Cloudflare? I\u2019ve been sent an invitation to schedule but no indication of what it will be like.", "author_fullname": "t2_cuu4ghb0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudflare Interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_124cii8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679977369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody done or know what the interview process for Data Engineer is at Cloudflare? I\u2019ve been sent an invitation to schedule but no indication of what it will be like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "124cii8", "is_robot_indexable": true, "report_reasons": null, "author": "HauntingWarning777", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124cii8/cloudflare_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124cii8/cloudflare_interview/", "subreddit_subscribers": 94636, "created_utc": 1679977369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First, This forum has helped me a lot in my journey toward data engineering. A lot of discussions and posts got me interested and made me realize the importance and value of Data engineering. Bit of a long post. Thanks a lot for taking the time to read it.\n\nShort: I am starting grad school, and the market seems crazy. How should I prepare to enter the workforce as a fresh grad and hopefully find a job?\n\nLong: I have been admitted into the MS Data Science program offered by the Software Engineering Department at RIT. The reason for this program is the curriculum and the focus on the SWE aspect of DS, Scholarship, and many elective options in SWE.\n\nI did a three-year degree, a BSc in Computer Science. I loved building automation and systems. I often find myself writing and deploying serverless scripts to send emails or alerts to my mobile to track specific events. I spend a lot of time in hackathons where I build backends for all my apps and websites.\n\nI have been working as a Data Engineer for an AI Startup focusing on Improving Debugging and Code generation. I design and work on their data pipelines and handle their deployment into GKE. My work also includes adapting the pipelines to use Dask. A lot of time, I needed more fundamental knowledge and figured I needed more time to learn and explore.\n\nQ1) I am planning to take courses on Parallel, and Distributed computing, NLP, and System Design. Am I on the right path?\n\nCurrently, I am proficient in Python, but I can't say the same for Java or C++.Q2) Is it Ideal to invest more time in java since many legacy systems are in Java and might be handy during interviews?\n\nQ3) Should I plan to get certifications? Does it really help?  \n\n\n Thanks a lot for reading through this. I would love to know how I can prepare myself.  \n( P.s: Reposting it since my prev post had a link to my resume, which breaks rule 8 )", "author_fullname": "t2_7vv90qx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I moving in the right direction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_124b7ap", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679974206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, This forum has helped me a lot in my journey toward data engineering. A lot of discussions and posts got me interested and made me realize the importance and value of Data engineering. Bit of a long post. Thanks a lot for taking the time to read it.&lt;/p&gt;\n\n&lt;p&gt;Short: I am starting grad school, and the market seems crazy. How should I prepare to enter the workforce as a fresh grad and hopefully find a job?&lt;/p&gt;\n\n&lt;p&gt;Long: I have been admitted into the MS Data Science program offered by the Software Engineering Department at RIT. The reason for this program is the curriculum and the focus on the SWE aspect of DS, Scholarship, and many elective options in SWE.&lt;/p&gt;\n\n&lt;p&gt;I did a three-year degree, a BSc in Computer Science. I loved building automation and systems. I often find myself writing and deploying serverless scripts to send emails or alerts to my mobile to track specific events. I spend a lot of time in hackathons where I build backends for all my apps and websites.&lt;/p&gt;\n\n&lt;p&gt;I have been working as a Data Engineer for an AI Startup focusing on Improving Debugging and Code generation. I design and work on their data pipelines and handle their deployment into GKE. My work also includes adapting the pipelines to use Dask. A lot of time, I needed more fundamental knowledge and figured I needed more time to learn and explore.&lt;/p&gt;\n\n&lt;p&gt;Q1) I am planning to take courses on Parallel, and Distributed computing, NLP, and System Design. Am I on the right path?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am proficient in Python, but I can&amp;#39;t say the same for Java or C++.Q2) Is it Ideal to invest more time in java since many legacy systems are in Java and might be handy during interviews?&lt;/p&gt;\n\n&lt;p&gt;Q3) Should I plan to get certifications? Does it really help?  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for reading through this. I would love to know how I can prepare myself.&lt;br/&gt;\n( P.s: Reposting it since my prev post had a link to my resume, which breaks rule 8 )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "124b7ap", "is_robot_indexable": true, "report_reasons": null, "author": "Anush_Krishna", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124b7ap/am_i_moving_in_the_right_direction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/124b7ap/am_i_moving_in_the_right_direction/", "subreddit_subscribers": 94636, "created_utc": 1679974206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uao4xuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to document your Snowflake code in 15 lines of code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 40, "top_awarded_type": null, "hide_score": false, "name": "t3_124auid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/52_eIguTFY4pN5Y0X4L3PgLfW-vFoEso-Myj4uxRenA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679973297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@adrian.white/documenting-your-code-how-to-generate-sql-documentation-in-15-lines-of-code-on-snowflake-c5fcec458440", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?auto=webp&amp;v=enabled&amp;s=7b10d921c4058f56dda986d51074fbf807083273", "width": 1200, "height": 343}, "resolutions": [{"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=224c181a005974a46fa0d1ee296e90b2a3ab06cf", "width": 108, "height": 30}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebf68966cc587428bc896871a4c28000c75be324", "width": 216, "height": 61}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa64eeecef4a3d98ef5e4f377af636b1530fb586", "width": 320, "height": 91}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eaea7a1ed9a24109646b66c5a9d0ee5fde84c5f", "width": 640, "height": 182}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3b786510a740c83bc29361f7c5e1d2b0038ec08", "width": 960, "height": 274}, {"url": "https://external-preview.redd.it/IscCrQgqGG_fgfcP3BS_ZB1tvO6PzZhcFGcSn98p44o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69e479740ec499861c978053c761497edb20b7ed", "width": 1080, "height": 308}], "variants": {}, "id": "4ZjZaWAhfpkni37IOJUqRx7zmk5FIbg1mwgOMzyELGk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "124auid", "is_robot_indexable": true, "report_reasons": null, "author": "Jazzlike_Use6242", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/124auid/how_to_document_your_snowflake_code_in_15_lines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@adrian.white/documenting-your-code-how-to-generate-sql-documentation-in-15-lines-of-code-on-snowflake-c5fcec458440", "subreddit_subscribers": 94636, "created_utc": 1679973297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "tldr; Struggling with Spark with just 1 machine what am i doing wrong and should i just switch to pandas or any other solution ?\n\nHello, i am currently on an internship at a company, it's been approx a month since i started and coding only started last week. My subject concerns the creation of a data quality framework, the main chunk of it essentially (i am a student on his last year, this internship is the last step before getting my master), i kind of read as much as i could and made some small diagrams (just high-level concepts) of how everything will work in the main part at least.  \n\n\nTools : At first i was supposed to use SAS but after asking my supervisor ( and then the fact that the enterprise doesn't have any license to spare to me), it was decided i could use python with Spark (with pandas as a back up in case spark fails due to some unforseen reasons).  \n\n\nThe provided enterprise computer consist of an i5 4th  generation and 8 GB of RAM with 2 physcial cores and 4 logical ones, the data i am currently processing is the first of many, and i am loosing my mind how slow everything is......  \nthe data has 3 Millon Rows and 700 columns. I am a beginner at Spark, currently learning it through this book : [https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf).  \n\n\nI am a data scientist student, with some background in data engineering (part of it cuz i love data eng and the other part is the need to be in control of the whole data processing before doing my models)  \n\n\nI am reading the data through jdbc to oracle. I don't know how to make many executors using one single machine (currently thinking of using a VM with 1 one core), and i have yet to try to grab the data and put it to disk temporarily then do my processing. I ended up understanding that running in local mode means everything runs through a single JVM and so everything end up bundled in the driver.  \nAlso i have noticed that my processor is not rising in usage while i am running tasks. I did configure a fetchsize and used the partition option when connecting to the jdbc, but still things are slow as shit.\n\n(oh btw i ended up finding this stack overflow question and i don't understand how he has so many executors while in local mode [https://stackoverflow.com/questions/41645679/spark-driver-memory-and-executor-memory](https://stackoverflow.com/questions/41645679/spark-driver-memory-and-executor-memory) neither if they are actually helping speed up the process)  \n\n\nI am currently weighting weither i should continue to pursue trying with spark (but i am 99% i am not going to get more machines, cloud or a better computer) or switch to pandas and just try to optimize from there. I am currently in the step of data profiling (automatisation also of this step)  and i can't even get some basic stat about my data since it takes so long to just compute anything (it takes 16 min to collect the row containing the result of counting the nulls of 50 columns + one of the column cause an sql numerical overflow) which i am currently investigating)\n\n(Oh also just personal curiosity but do you think that just basic SAS would be able to do it faster and better ? be it in terms of speed, coding etc)  \n\n\nAny advice on what i should do or any kind of information that i am (certainly) lacking would be appreciated, i am kinda stuck and i can't progress anymore.  \nIn the meantime will keep reading the book.....", "author_fullname": "t2_fcv4rhtp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Internship) Data Scientist &amp; Troubles with Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12438lo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679956387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tldr; Struggling with Spark with just 1 machine what am i doing wrong and should i just switch to pandas or any other solution ?&lt;/p&gt;\n\n&lt;p&gt;Hello, i am currently on an internship at a company, it&amp;#39;s been approx a month since i started and coding only started last week. My subject concerns the creation of a data quality framework, the main chunk of it essentially (i am a student on his last year, this internship is the last step before getting my master), i kind of read as much as i could and made some small diagrams (just high-level concepts) of how everything will work in the main part at least.  &lt;/p&gt;\n\n&lt;p&gt;Tools : At first i was supposed to use SAS but after asking my supervisor ( and then the fact that the enterprise doesn&amp;#39;t have any license to spare to me), it was decided i could use python with Spark (with pandas as a back up in case spark fails due to some unforseen reasons).  &lt;/p&gt;\n\n&lt;p&gt;The provided enterprise computer consist of an i5 4th  generation and 8 GB of RAM with 2 physcial cores and 4 logical ones, the data i am currently processing is the first of many, and i am loosing my mind how slow everything is......&lt;br/&gt;\nthe data has 3 Millon Rows and 700 columns. I am a beginner at Spark, currently learning it through this book : &lt;a href=\"https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf\"&gt;https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;I am a data scientist student, with some background in data engineering (part of it cuz i love data eng and the other part is the need to be in control of the whole data processing before doing my models)  &lt;/p&gt;\n\n&lt;p&gt;I am reading the data through jdbc to oracle. I don&amp;#39;t know how to make many executors using one single machine (currently thinking of using a VM with 1 one core), and i have yet to try to grab the data and put it to disk temporarily then do my processing. I ended up understanding that running in local mode means everything runs through a single JVM and so everything end up bundled in the driver.&lt;br/&gt;\nAlso i have noticed that my processor is not rising in usage while i am running tasks. I did configure a fetchsize and used the partition option when connecting to the jdbc, but still things are slow as shit.&lt;/p&gt;\n\n&lt;p&gt;(oh btw i ended up finding this stack overflow question and i don&amp;#39;t understand how he has so many executors while in local mode &lt;a href=\"https://stackoverflow.com/questions/41645679/spark-driver-memory-and-executor-memory\"&gt;https://stackoverflow.com/questions/41645679/spark-driver-memory-and-executor-memory&lt;/a&gt; neither if they are actually helping speed up the process)  &lt;/p&gt;\n\n&lt;p&gt;I am currently weighting weither i should continue to pursue trying with spark (but i am 99% i am not going to get more machines, cloud or a better computer) or switch to pandas and just try to optimize from there. I am currently in the step of data profiling (automatisation also of this step)  and i can&amp;#39;t even get some basic stat about my data since it takes so long to just compute anything (it takes 16 min to collect the row containing the result of counting the nulls of 50 columns + one of the column cause an sql numerical overflow) which i am currently investigating)&lt;/p&gt;\n\n&lt;p&gt;(Oh also just personal curiosity but do you think that just basic SAS would be able to do it faster and better ? be it in terms of speed, coding etc)  &lt;/p&gt;\n\n&lt;p&gt;Any advice on what i should do or any kind of information that i am (certainly) lacking would be appreciated, i am kinda stuck and i can&amp;#39;t progress anymore.&lt;br/&gt;\nIn the meantime will keep reading the book.....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12438lo", "is_robot_indexable": true, "report_reasons": null, "author": "Still-W1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12438lo/internship_data_scientist_troubles_with_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12438lo/internship_data_scientist_troubles_with_spark/", "subreddit_subscribers": 94636, "created_utc": 1679956387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys\u2026 first time here.\nI don\u2019t know if we had this kind of discussion before, but I would like some guidance here\n\nI have a long experience with Analytics and Data transformation\u2026 but never had a DE job.\nMy last job was as Analytics Engineer and my scope was the same as DE. Now I am a digital transformation coordinator and totally frustrated. \nThey sold me an opportunity of create a data lake from zero, create and architecture and train data analysts\u2026 I ended creating power points and using excel to create data flows. \n\nBut since I have zero experience as data engineer, it is quite complicated to land a job. I know how make API requests, create an ingestion flow\u2026 but I am no software engineer. \nI don\u2019t have knowledge in Kubernetes, Helm, NOSQL,and DevOps. I only know Python, Spark, SQL, AWS S3, RDS, EMR\u2026 and a little bit of Flink and Kafka. \nMy degree was in Materials Engineering but I shifted my area to BI/DA 6 years ago. Dataviz, Modeling, Analytics.. I can handle easily.\n\nI am no junior\u2026 but I believe I am no senior. My job is frustrating and these layoffs worsen my mental health, in terms of find a new opportunity.\n\nWhat should I do to go back to what I really love, that is Data Engineering? Should I focus on Junior roles or try Mid level? Senior is out of question.\n\nThanks in advance, I feel lighter talking about it here.", "author_fullname": "t2_b614u9x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to place myself in DE career ladder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_123w6io", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679957334.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679942571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys\u2026 first time here.\nI don\u2019t know if we had this kind of discussion before, but I would like some guidance here&lt;/p&gt;\n\n&lt;p&gt;I have a long experience with Analytics and Data transformation\u2026 but never had a DE job.\nMy last job was as Analytics Engineer and my scope was the same as DE. Now I am a digital transformation coordinator and totally frustrated. \nThey sold me an opportunity of create a data lake from zero, create and architecture and train data analysts\u2026 I ended creating power points and using excel to create data flows. &lt;/p&gt;\n\n&lt;p&gt;But since I have zero experience as data engineer, it is quite complicated to land a job. I know how make API requests, create an ingestion flow\u2026 but I am no software engineer. \nI don\u2019t have knowledge in Kubernetes, Helm, NOSQL,and DevOps. I only know Python, Spark, SQL, AWS S3, RDS, EMR\u2026 and a little bit of Flink and Kafka. \nMy degree was in Materials Engineering but I shifted my area to BI/DA 6 years ago. Dataviz, Modeling, Analytics.. I can handle easily.&lt;/p&gt;\n\n&lt;p&gt;I am no junior\u2026 but I believe I am no senior. My job is frustrating and these layoffs worsen my mental health, in terms of find a new opportunity.&lt;/p&gt;\n\n&lt;p&gt;What should I do to go back to what I really love, that is Data Engineering? Should I focus on Junior roles or try Mid level? Senior is out of question.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, I feel lighter talking about it here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "123w6io", "is_robot_indexable": true, "report_reasons": null, "author": "EmployeeNo7189", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123w6io/how_to_place_myself_in_de_career_ladder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/123w6io/how_to_place_myself_in_de_career_ladder/", "subreddit_subscribers": 94636, "created_utc": 1679942571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_20a1cwjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting Data from Wikidata Using SPARQL and Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_123vw7d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b9i_Vv35fsfz7a5uQgZekF1l8Pd2gbSchgq7_NgN2M8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679941992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jelle.vankerkvoorde/extracting-data-from-wikidata-using-sparql-and-python-59e0037996f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?auto=webp&amp;v=enabled&amp;s=694ec3da828a3bbbc14a0f430f98694efd741d66", "width": 960, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c30b51cf895b75d2ca0924e5012462104163f3f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=200ed081790522c6a86dbcef8aec6f091d784813", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e4ef087c1aaffea665b395faecd5a12f7275dce", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6960866b9cfe547403cdd4112a5790001ca4641e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/W18wIqajhVaQ4QS07umrXEIWHxgQPmFJ9ne3JZatAKc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f454652383797a23f4cc9493376712b9da85d6f0", "width": 960, "height": 540}], "variants": {}, "id": "1tu1M-UZ6LVJB9xkVokCrmIdNeD935qI6tYyQkiRgRw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "123vw7d", "is_robot_indexable": true, "report_reasons": null, "author": "jkspiderdog", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/123vw7d/extracting_data_from_wikidata_using_sparql_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jelle.vankerkvoorde/extracting-data-from-wikidata-using-sparql-and-python-59e0037996f", "subreddit_subscribers": 94636, "created_utc": 1679941992.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}