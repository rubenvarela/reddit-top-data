{"kind": "Listing", "data": {"after": "t3_11he6z1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How many applications are you getting? and how many of them are actual qualified applicants?\n\nJust trying to get some actual information on this to inform people on the job search. I'll sometimes pass on applying to a company that already has like 200+ applications on Linkedin.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question for people who are hiring or have hired recently. How many applications are you getting? and how many of them are actual qualified applicants?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h1xff", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677853177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How many applications are you getting? and how many of them are actual qualified applicants?&lt;/p&gt;\n\n&lt;p&gt;Just trying to get some actual information on this to inform people on the job search. I&amp;#39;ll sometimes pass on applying to a company that already has like 200+ applications on Linkedin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h1xff", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11h1xff/question_for_people_who_are_hiring_or_have_hired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h1xff/question_for_people_who_are_hiring_or_have_hired/", "subreddit_subscribers": 91856, "created_utc": 1677853177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I work or a large pharma company and we have been asked to start exploring azure as a cloud service. We currently do all our work on prem with sql servers and SSIS as our ETL tool. We just finished up a one week training on adf and I don't think this is the right tool for my team. We write lots of code and ADF is very low code and in the low code set up, simple tasks feel painful to accomplish and very clunky.  My question can azure databricks be set up where all our pipelines run in an a databricks notebook? My goal would be to have notebooks set up and then use adf to kick off those notebooks on a schedule. I want to stay as far away from all the tools and widgets within adf. I simply want to use it as a means to kick off a notebook with a pipeline in it. Is this something that a lot of you do or have seen people do?\n\n&amp;#x200B;\n\nthanks,", "author_fullname": "t2_stdv2q27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "azure datafactory.....ouch...help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hngbs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677898524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I work or a large pharma company and we have been asked to start exploring azure as a cloud service. We currently do all our work on prem with sql servers and SSIS as our ETL tool. We just finished up a one week training on adf and I don&amp;#39;t think this is the right tool for my team. We write lots of code and ADF is very low code and in the low code set up, simple tasks feel painful to accomplish and very clunky.  My question can azure databricks be set up where all our pipelines run in an a databricks notebook? My goal would be to have notebooks set up and then use adf to kick off those notebooks on a schedule. I want to stay as far away from all the tools and widgets within adf. I simply want to use it as a means to kick off a notebook with a pipeline in it. Is this something that a lot of you do or have seen people do?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hngbs", "is_robot_indexable": true, "report_reasons": null, "author": "xrt679", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hngbs/azure_datafactoryouchhelp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hngbs/azure_datafactoryouchhelp/", "subreddit_subscribers": 91856, "created_utc": 1677898524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are many different descriptions of these two careers. Some of them say they are totally different things, others equate them or say that BI development is part of DE. How do you differentiate these two?\n\nAs a Data Analyst who is steering his career towards DE, should I consider BI dev as a solid entry point?\n\nEdit for clarification: BI developer is different than BI analyst.", "author_fullname": "t2_nmja4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the knowledge gaps between BI developer and Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h87vp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677872525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677865491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many different descriptions of these two careers. Some of them say they are totally different things, others equate them or say that BI development is part of DE. How do you differentiate these two?&lt;/p&gt;\n\n&lt;p&gt;As a Data Analyst who is steering his career towards DE, should I consider BI dev as a solid entry point?&lt;/p&gt;\n\n&lt;p&gt;Edit for clarification: BI developer is different than BI analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h87vp", "is_robot_indexable": true, "report_reasons": null, "author": "we_need_more_lumber", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h87vp/what_are_the_knowledge_gaps_between_bi_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h87vp/what_are_the_knowledge_gaps_between_bi_developer/", "subreddit_subscribers": 91856, "created_utc": 1677865491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We recently started using Cloud Composer for our data engineering pipelines. For even a small environment that autoscales from 1 to 3 (in fact using just 1 worker most of the time), it's quite expensive at \\~$350/month. We don't currently have many DAGs running and each dag runs just daily for around 5 to 10 minutes. So our Cloud Composer environment is actually just sitting idlely the vast majority of the time. Since you get charged for the environment which is running 24/7, not just when the tasks are running, the value proposition is not great currently for us, as you can see.\n\nBecause of this, I am in quite a bit of contention with my teammate. Despite the unfortunate cost structure at the moment, I still think Airflow/Cloud Composer is the best solution for building and managing data pipelines and going forward we will certainly have more DAGs and more frequently running DAGs so the value proposition will surely improve significantly. I am very much in favor of using a technology that\u2019s future-proof.\n\nHowever my teammate just can't get over the fact that Cloud Composer is set up such that it's running 24/7 regardless of whether there's task running or not and we are getting charged for all those idling minutes. To him, the dollar cost per task execution time is just ridiculous. He thinks this is clearly a flaw in Airflow\u2019s implementation/design, that nodes are running and cost is building when nothing is being processed. He contends that we can build a much cheaper and equally capable system ourself, say using Cloud Scheduler, Cloud Run/Cloud Functions and taking advantage of background trigger functionalities in Google Cloud document store (i.e., Firestore), e.g., onCreate(), onUpdate() and etc to trigger dependencies between tasks. So in such a system, the fixed cost is much much lower and the vCPU/memory cost is only incurring when tasks are actually running.\n\nMy view is that reinventing the wheel, building our own data engineering tool, when there\u2019s a tried and tested solution for our need, is completely unnecessary, especially since the pubic available solution is proven to be scalable and reliable. But, I am really struggling to convince him and counter his arguments.\n\nSo here are some questions that I really appreciate your input:\n\n1. Why is Cloud Composer using GKE under the hood instead of Cloud Run, or some other mechanism that can completely turn on and off between task executions and hence not running up cost? Is this a flaw in Airflow/Cloud Composer\u2019s architecture but people are still willing to pay for it because of the convenience and there\u2019s no other alternative? Or was it an intentional design decision and engineering necessity?\n2. What advantages does a managed Airflow service, e.g., Cloud Composer, provide compared to an in-house solution like the one mentioned above, that are important but not immediately obvious?\n3. In general, if you are Cloud Composer user, how do you feel about it and how do you justify its expense; has it been worth it?", "author_fullname": "t2_o0hab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think Cloud Composer or other managed Airflow service is worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hjk4a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677888285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We recently started using Cloud Composer for our data engineering pipelines. For even a small environment that autoscales from 1 to 3 (in fact using just 1 worker most of the time), it&amp;#39;s quite expensive at ~$350/month. We don&amp;#39;t currently have many DAGs running and each dag runs just daily for around 5 to 10 minutes. So our Cloud Composer environment is actually just sitting idlely the vast majority of the time. Since you get charged for the environment which is running 24/7, not just when the tasks are running, the value proposition is not great currently for us, as you can see.&lt;/p&gt;\n\n&lt;p&gt;Because of this, I am in quite a bit of contention with my teammate. Despite the unfortunate cost structure at the moment, I still think Airflow/Cloud Composer is the best solution for building and managing data pipelines and going forward we will certainly have more DAGs and more frequently running DAGs so the value proposition will surely improve significantly. I am very much in favor of using a technology that\u2019s future-proof.&lt;/p&gt;\n\n&lt;p&gt;However my teammate just can&amp;#39;t get over the fact that Cloud Composer is set up such that it&amp;#39;s running 24/7 regardless of whether there&amp;#39;s task running or not and we are getting charged for all those idling minutes. To him, the dollar cost per task execution time is just ridiculous. He thinks this is clearly a flaw in Airflow\u2019s implementation/design, that nodes are running and cost is building when nothing is being processed. He contends that we can build a much cheaper and equally capable system ourself, say using Cloud Scheduler, Cloud Run/Cloud Functions and taking advantage of background trigger functionalities in Google Cloud document store (i.e., Firestore), e.g., onCreate(), onUpdate() and etc to trigger dependencies between tasks. So in such a system, the fixed cost is much much lower and the vCPU/memory cost is only incurring when tasks are actually running.&lt;/p&gt;\n\n&lt;p&gt;My view is that reinventing the wheel, building our own data engineering tool, when there\u2019s a tried and tested solution for our need, is completely unnecessary, especially since the pubic available solution is proven to be scalable and reliable. But, I am really struggling to convince him and counter his arguments.&lt;/p&gt;\n\n&lt;p&gt;So here are some questions that I really appreciate your input:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Why is Cloud Composer using GKE under the hood instead of Cloud Run, or some other mechanism that can completely turn on and off between task executions and hence not running up cost? Is this a flaw in Airflow/Cloud Composer\u2019s architecture but people are still willing to pay for it because of the convenience and there\u2019s no other alternative? Or was it an intentional design decision and engineering necessity?&lt;/li&gt;\n&lt;li&gt;What advantages does a managed Airflow service, e.g., Cloud Composer, provide compared to an in-house solution like the one mentioned above, that are important but not immediately obvious?&lt;/li&gt;\n&lt;li&gt;In general, if you are Cloud Composer user, how do you feel about it and how do you justify its expense; has it been worth it?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hjk4a", "is_robot_indexable": true, "report_reasons": null, "author": "not_a_thrownaway", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hjk4a/do_you_think_cloud_composer_or_other_managed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hjk4a/do_you_think_cloud_composer_or_other_managed/", "subreddit_subscribers": 91856, "created_utc": 1677888285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a 100% PostgreSQL-based data platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_11h2aqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Blp6Wl_N-GH0byJRXZbC5s32tLjK_aG6-l6NPAL2Gb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677854140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/full-stack-architecture/elt-data-platforms-and-sql-extracting-and-transforming-data-from-restful-services-cc8b2e059972", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?auto=webp&amp;v=enabled&amp;s=17464a227155bb693c618d139c0a40247798bbfb", "width": 630, "height": 472}, "resolutions": [{"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46d60896c58dd64134396b4210797d4fb810372e", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8dff35778af8a41a4b222dee69ab8690dcee35b", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/jqKZ1yQg6FjnZEfi4Wluaxp5x98-0cNypqeaWNCB5dE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1a7cdf35e048bd844714f61e67fa23f59370b67", "width": 320, "height": 239}], "variants": {}, "id": "4pYoDEXa-f44_Nlw1mGsRh73X7lw0TPA7IP0H1LW6F8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11h2aqp", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11h2aqp/building_a_100_postgresqlbased_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/full-stack-architecture/elt-data-platforms-and-sql-extracting-and-transforming-data-from-restful-services-cc8b2e059972", "subreddit_subscribers": 91856, "created_utc": 1677854140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am not even sure how to phrase the title of this question. I work as a data analyst, and I'm reading Kimball, but I haven't work at all on the database development side of things, but I'm interested in learning all aspects. so I have an incredibly dumb question for you guys...Go ahead and pass the dunce cap over to me.\n\nWhat takes up most of your time? Some things seem straightforward, but the developers/admins will give timelines of weeks or months. Example:\n\nWe are moving from Hadoop to another platform that has been in use for a few years, so there should be plenty of experienced people for this move. But what takes so long with moving these tables? Is it just that they are really big? Several tables have millions of rows. For certain the total is in the billions of rows across dozens of tables. But they are going to replicate just 7 tables to start with, to test.\n\nI am being very uninformed on this, I know, I think that there is a big difference between reading about database development and what actually happens. But even setting up the tables with no records has at least a week long process. It's just some DDL commands to create it? A database connections from 1 database to another and some more DDL to copy and insert the records, right?\n\nNot talking about data quality rules, or creating triggers based on events, or even setting up the realtime feed to the new DB. Just replicating. What takes weeks or months to do just that?", "author_fullname": "t2_2qobkynl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the time consuming activites of your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hhajg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677882927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am not even sure how to phrase the title of this question. I work as a data analyst, and I&amp;#39;m reading Kimball, but I haven&amp;#39;t work at all on the database development side of things, but I&amp;#39;m interested in learning all aspects. so I have an incredibly dumb question for you guys...Go ahead and pass the dunce cap over to me.&lt;/p&gt;\n\n&lt;p&gt;What takes up most of your time? Some things seem straightforward, but the developers/admins will give timelines of weeks or months. Example:&lt;/p&gt;\n\n&lt;p&gt;We are moving from Hadoop to another platform that has been in use for a few years, so there should be plenty of experienced people for this move. But what takes so long with moving these tables? Is it just that they are really big? Several tables have millions of rows. For certain the total is in the billions of rows across dozens of tables. But they are going to replicate just 7 tables to start with, to test.&lt;/p&gt;\n\n&lt;p&gt;I am being very uninformed on this, I know, I think that there is a big difference between reading about database development and what actually happens. But even setting up the tables with no records has at least a week long process. It&amp;#39;s just some DDL commands to create it? A database connections from 1 database to another and some more DDL to copy and insert the records, right?&lt;/p&gt;\n\n&lt;p&gt;Not talking about data quality rules, or creating triggers based on events, or even setting up the realtime feed to the new DB. Just replicating. What takes weeks or months to do just that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hhajg", "is_robot_indexable": true, "report_reasons": null, "author": "Shwoomie", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hhajg/what_is_the_time_consuming_activites_of_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hhajg/what_is_the_time_consuming_activites_of_your_job/", "subreddit_subscribers": 91856, "created_utc": 1677882927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/@stefentaime\\_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb](https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a\n\n In today\u2019s data-driven world, processing large volumes of data in real-time has become essential for many organizations. The Extract, Transform, Load (ETL) process is a common way to manage the flow of data between systems. In this article, we\u2019ll walk through how to build a scalable ETL pipeline using Apache Airflow, Kafka, and Python, Mongo and Flask \n\nIn this pipeline, the RSS feeds are scraped using a Python library called feedparser. This library is used to parse the XML data in the RSS feeds and extract the relevant information. The parsed data is then transformed into a standardized JSON format using Python's built-in json library. This format includes fields such as title, summary, link, published\\_date, and language, which make the data easier to analyze and consume.", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Scalable RSS Feed Pipeline with Apache Airflow, Kafka, and MongoDB, Flask Api", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cw0ny0xe3lla1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=906a9e84c5c3b27a02ead564d9094ab316759988"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6731aebac6fb9bfc8d7d74b85cad5fc0a1d70f34"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0eee400b3475883b825d5980b3355998bbac6b8e"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a"}, "id": "cw0ny0xe3lla1"}}, "name": "t3_11hdy54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sZ25bG-V-FiLzLwMOO2O-bnR-pdaidqQq5_4ymlblrI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677875379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb\"&gt;https://medium.com/@stefentaime_10958/building-a-scalable-rss-feed-pipeline-with-apache-airflow-kafka-and-mongodb-flask-api-da379cc2e3fb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a\"&gt;https://preview.redd.it/cw0ny0xe3lla1.png?width=500&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c579c53ceaf6a3d0c219768455602feb0f2c4d2a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In today\u2019s data-driven world, processing large volumes of data in real-time has become essential for many organizations. The Extract, Transform, Load (ETL) process is a common way to manage the flow of data between systems. In this article, we\u2019ll walk through how to build a scalable ETL pipeline using Apache Airflow, Kafka, and Python, Mongo and Flask &lt;/p&gt;\n\n&lt;p&gt;In this pipeline, the RSS feeds are scraped using a Python library called feedparser. This library is used to parse the XML data in the RSS feeds and extract the relevant information. The parsed data is then transformed into a standardized JSON format using Python&amp;#39;s built-in json library. This format includes fields such as title, summary, link, published_date, and language, which make the data easier to analyze and consume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?auto=webp&amp;v=enabled&amp;s=ee9818bce162ebfcb69268e842d337c035e5b567", "width": 1200, "height": 564}, "resolutions": [{"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f784cea76c85073a0a9074b20d4bd68ab7d68ce", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce84ff7be54e3fcfb68e870f63fa6e2d4603aba5", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52a34c1619925b79c20f923f917be2348dafe8dc", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43ff471735006a845946aa4e4cecba39fdab0d48", "width": 640, "height": 300}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83bf78180fbb5a751676350b1bb13764c353f73e", "width": 960, "height": 451}, {"url": "https://external-preview.redd.it/4jHHWX47A37cnRvst-RD_iLAGfCS4hqxq4oTwK9vnRA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7a04270a792befa0fafc11e1cdcb8e490969047", "width": 1080, "height": 507}], "variants": {}, "id": "tH9jmMo8wbU5z-SQC6-NTsGwT9qhuVhdZXUeDxBZR1c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "11hdy54", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hdy54/building_a_scalable_rss_feed_pipeline_with_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hdy54/building_a_scalable_rss_feed_pipeline_with_apache/", "subreddit_subscribers": 91856, "created_utc": 1677875379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am 26F and finished my psychology bachelor last September. I have also studied two years of artificial intelligence before that but did not finish it. Now my question is, would I be able to do well in a data engineering job? I got approached by a recruiter who offered me an interview for a full time job at a good company as a data engineer but I\u2019m worried about my lack of programming skills (as it\u2019s a long time ago I last programmed anything).", "author_fullname": "t2_hiwfhmhv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering job with a psychology degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hiauo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677885296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 26F and finished my psychology bachelor last September. I have also studied two years of artificial intelligence before that but did not finish it. Now my question is, would I be able to do well in a data engineering job? I got approached by a recruiter who offered me an interview for a full time job at a good company as a data engineer but I\u2019m worried about my lack of programming skills (as it\u2019s a long time ago I last programmed anything).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11hiauo", "is_robot_indexable": true, "report_reasons": null, "author": "Sapphicorns", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hiauo/data_engineering_job_with_a_psychology_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hiauo/data_engineering_job_with_a_psychology_degree/", "subreddit_subscribers": 91856, "created_utc": 1677885296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked for 3-4 years in positions where I helped structure ETLs, DWs and alike. However, I'm now on the cusp of being hired to help structure the area in a big investment fund here, helping the research area have an easier time focusing on their models. My previous experience led me to grasp DBT, SQL, and most of my experience came from using a Microsoft stack with SSIS, Analysis Services and the like. I'm feeling wayyyy over my head to start building this, and the multitude of possible stacks make me very afraid that I might overengineer this, and I will initially be alone in the area. What do I do? Fake it till I make it? I never lied in my resume, so it's not like they expect a senior with plenty of experience but still... I read this: https://github.com/zsvoboda/ngods-stocks\nAnd it seems like a good starter, albeit overly complex for our use case. I could use suggestions, people to talk to, etc. Please help", "author_fullname": "t2_bdy92fyd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm way over my head", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hrslk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677911084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked for 3-4 years in positions where I helped structure ETLs, DWs and alike. However, I&amp;#39;m now on the cusp of being hired to help structure the area in a big investment fund here, helping the research area have an easier time focusing on their models. My previous experience led me to grasp DBT, SQL, and most of my experience came from using a Microsoft stack with SSIS, Analysis Services and the like. I&amp;#39;m feeling wayyyy over my head to start building this, and the multitude of possible stacks make me very afraid that I might overengineer this, and I will initially be alone in the area. What do I do? Fake it till I make it? I never lied in my resume, so it&amp;#39;s not like they expect a senior with plenty of experience but still... I read this: &lt;a href=\"https://github.com/zsvoboda/ngods-stocks\"&gt;https://github.com/zsvoboda/ngods-stocks&lt;/a&gt;\nAnd it seems like a good starter, albeit overly complex for our use case. I could use suggestions, people to talk to, etc. Please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?auto=webp&amp;v=enabled&amp;s=88e89113dc866e0e79fa88564a4f48a99ed855ad", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8897f11c5e7d5e70d199037ed7dfaccd3c3c0a1a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a160100e6d40cd3bdbb96cd34c20bbe25c13d78", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c9080ad13764e5f268aa4daded940814aeb7720", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5587ba5e9d5302f52bb216098a8a4fa7fd8aebb3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebdd3df5c4ea18925de03f6a8fed9046791ec9a4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/x5qGvo9MIQSyBaMiEo0_R16WbBJr11puC9XKh4O9gLc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=becdd468015d3ca5d3f9f328713ddcb43d451167", "width": 1080, "height": 540}], "variants": {}, "id": "MRb-72j-QWKEXts0uiG7NHtqLI7h3MqEkjGblqeZ07Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11hrslk", "is_robot_indexable": true, "report_reasons": null, "author": "BelugaGolfinho", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hrslk/im_way_over_my_head/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hrslk/im_way_over_my_head/", "subreddit_subscribers": 91856, "created_utc": 1677911084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I'm trying to set up a development environment with Kafka, Pyspark and zookeeper for a pet project but I've been facing some issues with stream reading the data from my Kafka broker, can someone please share a docker-compose file or tutorial on how to properly setup an environment with docker . Thx in advance", "author_fullname": "t2_386krewr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark + Kafka in docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hktx8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677891500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m trying to set up a development environment with Kafka, Pyspark and zookeeper for a pet project but I&amp;#39;ve been facing some issues with stream reading the data from my Kafka broker, can someone please share a docker-compose file or tutorial on how to properly setup an environment with docker . Thx in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11hktx8", "is_robot_indexable": true, "report_reasons": null, "author": "Lord_Gonz0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11hktx8/apache_spark_kafka_in_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hktx8/apache_spark_kafka_in_docker/", "subreddit_subscribers": 91856, "created_utc": 1677891500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say there are two duplicated rows like it:\n\ncolA   colB\n\n10      10\n\n10      10\n\nShould the fact be modeled to store duplicated rows like it? or there is no rule?\n\ncolA   colB    Total\n\n10       10       2\n\nCurrently I've created a DW for my project, but there are some duplicated rows. Must I remove duplicated rows?", "author_fullname": "t2_h7b2azu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can fact table have duplicated rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hpim1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677904364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say there are two duplicated rows like it:&lt;/p&gt;\n\n&lt;p&gt;colA   colB&lt;/p&gt;\n\n&lt;p&gt;10      10&lt;/p&gt;\n\n&lt;p&gt;10      10&lt;/p&gt;\n\n&lt;p&gt;Should the fact be modeled to store duplicated rows like it? or there is no rule?&lt;/p&gt;\n\n&lt;p&gt;colA   colB    Total&lt;/p&gt;\n\n&lt;p&gt;10       10       2&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;ve created a DW for my project, but there are some duplicated rows. Must I remove duplicated rows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hpim1", "is_robot_indexable": true, "report_reasons": null, "author": "SuddenlyCaralho", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hpim1/can_fact_table_have_duplicated_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hpim1/can_fact_table_have_duplicated_rows/", "subreddit_subscribers": 91856, "created_utc": 1677904364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the overlap in your organization between Data Engineering, which is usually discussed in the context of providing data for some sort of BI, and Data Integration, connecting systems (internal, external) with the data they need to operate.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overlap Between Integration and Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h7f4c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677864605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the overlap in your organization between Data Engineering, which is usually discussed in the context of providing data for some sort of BI, and Data Integration, connecting systems (internal, external) with the data they need to operate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11h7f4c", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h7f4c/overlap_between_integration_and_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h7f4c/overlap_between_integration_and_data_engineering/", "subreddit_subscribers": 91856, "created_utc": 1677864605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have almost no experience with R and I need to refactor a pipeline from R to Python. For now, I'm using pandas but eventually, I may need to use PySpark since the data is reasonably \"big\".\n\nAre there common \"gotchas\" to watch out for or \"best practices\" used in R that might not make sense to someone with no familiarity with R?\n\nAny suggestions or warnings are appreciated, thanks in advance!", "author_fullname": "t2_32t0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refactoring a pipeline from R to Python -- advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hjvp9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677889078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have almost no experience with R and I need to refactor a pipeline from R to Python. For now, I&amp;#39;m using pandas but eventually, I may need to use PySpark since the data is reasonably &amp;quot;big&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Are there common &amp;quot;gotchas&amp;quot; to watch out for or &amp;quot;best practices&amp;quot; used in R that might not make sense to someone with no familiarity with R?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or warnings are appreciated, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hjvp9", "is_robot_indexable": true, "report_reasons": null, "author": "monocongo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hjvp9/refactoring_a_pipeline_from_r_to_python_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hjvp9/refactoring_a_pipeline_from_r_to_python_advice/", "subreddit_subscribers": 91856, "created_utc": 1677889078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://rockset.com/blog/introducing-compute-compute-separation/](https://rockset.com/blog/introducing-compute-compute-separation/)", "author_fullname": "t2_6z7i3sub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compute-compute separation for real-time analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h9iwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677866953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://rockset.com/blog/introducing-compute-compute-separation/\"&gt;https://rockset.com/blog/introducing-compute-compute-separation/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?auto=webp&amp;v=enabled&amp;s=89dd38ed783c6f7b7fd7f8a17627b8e8f1da0e7a", "width": 2560, "height": 1340}, "resolutions": [{"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=247a68b121d0b644ebe5bfe9f0f1c683d2b524d1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dc2f025685a904f8a4eb25e207e532356d455aa", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bf9ab91a5de48ce74898c29cba065fb8af49a77", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d05cdbfcd757cfa3878eeda6a6ec5c64397d018", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f83a112bf05ab56fce8e857edd29a6c0f2e5eff", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/T--AH8Y2CaRWttjNj1wS8fJhfle9eIWdwIGGGrVyHpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7954c4e0cd0bb31f7443964e591d1812196391ea", "width": 1080, "height": 565}], "variants": {}, "id": "HgiipNxAl6VoCgJ3fWfRmRgX0dMxHDG92I8seBbhnKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11h9iwd", "is_robot_indexable": true, "report_reasons": null, "author": "jmills2010", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h9iwd/computecompute_separation_for_realtime_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h9iwd/computecompute_separation_for_realtime_analytics/", "subreddit_subscribers": 91856, "created_utc": 1677866953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nI was wondering if there are any EL tools that make it easy to work with multiple environments.\n\nReason is, I have a postgresql database from which I want to extract data. However this database has some 165 tables, and some of these tables have over 100 columns.\n\nI definitely don't need all the tables and in most tables I don't need all the columns, often just a small subset of those.\n\nAt the same time, I want to be able to have at least 2 environments (staging and prod), and would like to manage my EL tool of choice with proper DevOps practices.\n\nDo you know of any solution that makes this easy to work with?\n\n\\_\\_\\_\n\n*PS: If you're thinking Fivetran with REST APIs, consider that the data volume is quite small and would easily qualify for Fivetran free tier, which however doesn't allow to use their REST APIs.*", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EL softwares that support CI/CD or multiple environments/deployments natively?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11hy1c7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677932803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there are any EL tools that make it easy to work with multiple environments.&lt;/p&gt;\n\n&lt;p&gt;Reason is, I have a postgresql database from which I want to extract data. However this database has some 165 tables, and some of these tables have over 100 columns.&lt;/p&gt;\n\n&lt;p&gt;I definitely don&amp;#39;t need all the tables and in most tables I don&amp;#39;t need all the columns, often just a small subset of those.&lt;/p&gt;\n\n&lt;p&gt;At the same time, I want to be able to have at least 2 environments (staging and prod), and would like to manage my EL tool of choice with proper DevOps practices.&lt;/p&gt;\n\n&lt;p&gt;Do you know of any solution that makes this easy to work with?&lt;/p&gt;\n\n&lt;p&gt;___&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;PS: If you&amp;#39;re thinking Fivetran with REST APIs, consider that the data volume is quite small and would easily qualify for Fivetran free tier, which however doesn&amp;#39;t allow to use their REST APIs.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hy1c7", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hy1c7/el_softwares_that_support_cicd_or_multiple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hy1c7/el_softwares_that_support_cicd_or_multiple/", "subreddit_subscribers": 91856, "created_utc": 1677932803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I asked this question over in r/aws and got crickets. . . so asking here. Does anyone on r/dataengineering have experience using Textract and/or Rekognition and if so are they decent?\n\nI have a big pile of images in S3 and I need to extract text strings (labels, brands, sizes e.g. a lot of the images are consumer goods like clothes) in some cases and in other cases I need to generate descriptions and keywords  of images e.g. with an image of a black horse, I would expect output words like black, horse, mammal, etc.\n\nLike many AWS services, I can't tell immediately if these are worth pursuing.", "author_fullname": "t2_clyss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Textract and Rekognition: yay or nay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11hxdn2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677930389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked this question over in &lt;a href=\"/r/aws\"&gt;r/aws&lt;/a&gt; and got crickets. . . so asking here. Does anyone on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; have experience using Textract and/or Rekognition and if so are they decent?&lt;/p&gt;\n\n&lt;p&gt;I have a big pile of images in S3 and I need to extract text strings (labels, brands, sizes e.g. a lot of the images are consumer goods like clothes) in some cases and in other cases I need to generate descriptions and keywords  of images e.g. with an image of a black horse, I would expect output words like black, horse, mammal, etc.&lt;/p&gt;\n\n&lt;p&gt;Like many AWS services, I can&amp;#39;t tell immediately if these are worth pursuing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hxdn2", "is_robot_indexable": true, "report_reasons": null, "author": "tech_tuna", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hxdn2/textract_and_rekognition_yay_or_nay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hxdn2/textract_and_rekognition_yay_or_nay/", "subreddit_subscribers": 91856, "created_utc": 1677930389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m2u4lsxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applications of Databricks Certified Data Engineer Associate Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_11hwvz2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0cxNVrlAn15Yh8ImdY4SibGQkUIESutPIhiGSr8xZos.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677928464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amaaira.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://amaaira.medium.com/applications-of-databricks-certified-data-engineer-associate-certification-7012b280777", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_9xtibO49R0ZYfabP0HEe4oQdgXjQK6cHfz6SdGJJJU.jpg?auto=webp&amp;v=enabled&amp;s=c5bcc0e04a593333574c1717c4493723d760a1b9", "width": 700, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/_9xtibO49R0ZYfabP0HEe4oQdgXjQK6cHfz6SdGJJJU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bea3f44f11434b8d582bb711f355663afd7a33f", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/_9xtibO49R0ZYfabP0HEe4oQdgXjQK6cHfz6SdGJJJU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81cf9d7f4f32227445a586c79a21f596da31774b", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/_9xtibO49R0ZYfabP0HEe4oQdgXjQK6cHfz6SdGJJJU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ee064baf6a417b75961818d228d360486f941eb", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/_9xtibO49R0ZYfabP0HEe4oQdgXjQK6cHfz6SdGJJJU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cedc119d2b7b1ba59183496e6cbe1de927e8d5ba", "width": 640, "height": 365}], "variants": {}, "id": "RJnwMUotgoAorp6h3pkOVgfZWhCUlskVXYq0HVII79M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11hwvz2", "is_robot_indexable": true, "report_reasons": null, "author": "certfun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hwvz2/applications_of_databricks_certified_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://amaaira.medium.com/applications-of-databricks-certified-data-engineer-associate-certification-7012b280777", "subreddit_subscribers": 91856, "created_utc": 1677928464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fbliz6iq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sending OpenTelemetry data to Google Cloud Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "name": "t3_11hvnme", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zhuvO2Be4-l8QVtLMm8joTHZxVlWDfmMaz6X_JpIq2w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677924098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "keyval.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://keyval.dev/sending-otel-to-gcs/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GS01qHh_JdLNWzEB0M-NgzHYA3AWjgUkhDlQ9gvn4wM.jpg?auto=webp&amp;v=enabled&amp;s=d213a85174c20068a7faed9b818c0a54b23426b7", "width": 738, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/GS01qHh_JdLNWzEB0M-NgzHYA3AWjgUkhDlQ9gvn4wM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=304fd50828294e724d118605eeae316168bb424c", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/GS01qHh_JdLNWzEB0M-NgzHYA3AWjgUkhDlQ9gvn4wM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d5a5bde5877c53271251ee4782b62ceac09b38c", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/GS01qHh_JdLNWzEB0M-NgzHYA3AWjgUkhDlQ9gvn4wM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c763c707065652d4a31ba82ad47dba2fa57b1c46", "width": 320, "height": 272}, {"url": "https://external-preview.redd.it/GS01qHh_JdLNWzEB0M-NgzHYA3AWjgUkhDlQ9gvn4wM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ee2be40f0e8a6ce3b54050946875368d47e6d0f", "width": 640, "height": 544}], "variants": {}, "id": "bR1vLdd9Hcr6jlHtfCqi23c6-Qem3rzYz0QT0ObYEWI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11hvnme", "is_robot_indexable": true, "report_reasons": null, "author": "Barakikia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hvnme/sending_opentelemetry_data_to_google_cloud_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://keyval.dev/sending-otel-to-gcs/", "subreddit_subscribers": 91856, "created_utc": 1677924098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kubeflow 1.7 is around the corner. If you would like to be the first one who tries a beta, follow us closely. We got big news.\n\nJoin us on 8th of March live, learn more about the latest release and ask your questions right away.\n\nLink:\nhttps://www.linkedin.com/video/event/urn:li:ugcPost:7035904245740539904/", "author_fullname": "t2_3z4miuvs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kubeflow 1.7 Beta", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hrwp9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677911429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kubeflow 1.7 is around the corner. If you would like to be the first one who tries a beta, follow us closely. We got big news.&lt;/p&gt;\n\n&lt;p&gt;Join us on 8th of March live, learn more about the latest release and ask your questions right away.&lt;/p&gt;\n\n&lt;p&gt;Link:\n&lt;a href=\"https://www.linkedin.com/video/event/urn:li:ugcPost:7035904245740539904/\"&gt;https://www.linkedin.com/video/event/urn:li:ugcPost:7035904245740539904/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;v=enabled&amp;s=751b05e77b1c50dfc8477f4c599cb33affc7e2fc", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11hrwp9", "is_robot_indexable": true, "report_reasons": null, "author": "andreea-mun", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hrwp9/kubeflow_17_beta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hrwp9/kubeflow_17_beta/", "subreddit_subscribers": 91856, "created_utc": 1677911429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope someone can guide me in the right direction.\n\nWe have a hub for team members. It draws primarily from our HR system.\n\nWe have a second for appointments.\n\nWe might have multiple team members linked to an appointment, but fulfilling different roles.\n\nDoes our link become three-way (as in not just a appointment-customer link, but an appointment-customer-role link)? It seems so, but I wanted to double check.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DV2.0 links question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hosx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677902305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope someone can guide me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;We have a hub for team members. It draws primarily from our HR system.&lt;/p&gt;\n\n&lt;p&gt;We have a second for appointments.&lt;/p&gt;\n\n&lt;p&gt;We might have multiple team members linked to an appointment, but fulfilling different roles.&lt;/p&gt;\n\n&lt;p&gt;Does our link become three-way (as in not just a appointment-customer link, but an appointment-customer-role link)? It seems so, but I wanted to double check.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11hosx6", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hosx6/dv20_links_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hosx6/dv20_links_question/", "subreddit_subscribers": 91856, "created_utc": 1677902305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently on an internship and I think I\u2019ll be able to have the choice of choosing what role or department to go to, and I\u2019m really tending towards data engineering. \n\nI\u2019m interested in programming, and think back end is something I would enjoy most. Things I was looking at were \n\n1) stress / work life balance / flexibility\n2) pay \n3) how much time is spent on meetings v coding/building \n4) development - continuous learning and enjoyment. Will I be able to move to other roles easily if this doesn\u2019t work out or after being in the role for a few years etc\n5) whether I would struggle at the work - needs to be something I can complete. \n\nI feel like when you have so many fields that look appealing it feels like a really difficult decision to make when starting your career out. I\u2019ve been thinking about this for so long. \n\nFrom the U.K. if that makes a difference. And I have limited programming experience in terms of python. Not much on SQL.\n\nThanks!", "author_fullname": "t2_3f2ev3jx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know if this is for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11h16th", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677851235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently on an internship and I think I\u2019ll be able to have the choice of choosing what role or department to go to, and I\u2019m really tending towards data engineering. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested in programming, and think back end is something I would enjoy most. Things I was looking at were &lt;/p&gt;\n\n&lt;p&gt;1) stress / work life balance / flexibility\n2) pay \n3) how much time is spent on meetings v coding/building \n4) development - continuous learning and enjoyment. Will I be able to move to other roles easily if this doesn\u2019t work out or after being in the role for a few years etc\n5) whether I would struggle at the work - needs to be something I can complete. &lt;/p&gt;\n\n&lt;p&gt;I feel like when you have so many fields that look appealing it feels like a really difficult decision to make when starting your career out. I\u2019ve been thinking about this for so long. &lt;/p&gt;\n\n&lt;p&gt;From the U.K. if that makes a difference. And I have limited programming experience in terms of python. Not much on SQL.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11h16th", "is_robot_indexable": true, "report_reasons": null, "author": "studying4exams", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11h16th/how_do_i_know_if_this_is_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11h16th/how_do_i_know_if_this_is_for_me/", "subreddit_subscribers": 91856, "created_utc": 1677851235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a software engineer for 4 years most of which working with js, but I took a senior position a year ago working mostly Java (backend micro services etc..) I completed a masters in data analytics during Covid thinking I would be able to move into more of a data role either DE MLE, or DS, but I\u2019m afraid I don\u2019t have the experience to convert without taking a paycut. Anyone else have this problem and what did you do?", "author_fullname": "t2_9lu6pf0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SE with masters trying to switch to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11hy7ne", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677933430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a software engineer for 4 years most of which working with js, but I took a senior position a year ago working mostly Java (backend micro services etc..) I completed a masters in data analytics during Covid thinking I would be able to move into more of a data role either DE MLE, or DS, but I\u2019m afraid I don\u2019t have the experience to convert without taking a paycut. Anyone else have this problem and what did you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11hy7ne", "is_robot_indexable": true, "report_reasons": null, "author": "NoManufacturer6751", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hy7ne/se_with_masters_trying_to_switch_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hy7ne/se_with_masters_trying_to_switch_to_de/", "subreddit_subscribers": 91856, "created_utc": 1677933430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nMy company is building a new data warehouse on SQL Server . We are trying to get some data from an oracle db. \n\nFor those who have experience migrating data from oracle to SQL Server :  \n1 - Have you ever loaded data from oracle to an azure data lake ? if Yes, what tool did use to do that ? I am currently using the azure data factory but I can see it's a time consuming process ?  \n2 - I tested SSIS with script component. the issue is I have to type the input and output columns for each table manually which is not efficient.  \n3- Does anyone worked on a similar project and what would be some good tips ? like tool used for ETLs or ELTs , did you use sql server or azure synapse analytics ?", "author_fullname": "t2_g0kwnodf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Data from Oracle db to SQL SERVER", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hfwfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677879775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;My company is building a new data warehouse on SQL Server . We are trying to get some data from an oracle db. &lt;/p&gt;\n\n&lt;p&gt;For those who have experience migrating data from oracle to SQL Server :&lt;br/&gt;\n1 - Have you ever loaded data from oracle to an azure data lake ? if Yes, what tool did use to do that ? I am currently using the azure data factory but I can see it&amp;#39;s a time consuming process ?&lt;br/&gt;\n2 - I tested SSIS with script component. the issue is I have to type the input and output columns for each table manually which is not efficient.&lt;br/&gt;\n3- Does anyone worked on a similar project and what would be some good tips ? like tool used for ETLs or ELTs , did you use sql server or azure synapse analytics ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11hfwfb", "is_robot_indexable": true, "report_reasons": null, "author": "That-Refrigerator901", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hfwfb/migrate_data_from_oracle_db_to_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hfwfb/migrate_data_from_oracle_db_to_sql_server/", "subreddit_subscribers": 91856, "created_utc": 1677879775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given the following use case, how do you fit this into the modern de/bi architecture?\n\n1. Most of the data is structured\n2. Users need consistent set of data with business knowledge built into it, available both for self-service to end users and analysts for drilling, ml, etc.\n\nIf this was 2005, the recommendation would be to put it in a traditional data warehouse (with cubes, and maybe pre-aggregated analytics), with some data marts and pre-aggregated data. \n\nI get that this is less flexible and scalable, and that many organizations are dealing with massive amounts of unstructured data of all sorts of types constantly showing up .\n\nThe current approach is to put into file-like structures, distributed (with containers, etc.), and then analysts are the ones who somehow grab the data and organize it. No longer is there a single source of organized, business-knowledge-embedded data. While this seems great for some use cases, it doesn't seem to fit the original use case.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Target for Mostly Structured Data, Goal of Standard Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11hfijs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677878889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given the following use case, how do you fit this into the modern de/bi architecture?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Most of the data is structured&lt;/li&gt;\n&lt;li&gt;Users need consistent set of data with business knowledge built into it, available both for self-service to end users and analysts for drilling, ml, etc.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If this was 2005, the recommendation would be to put it in a traditional data warehouse (with cubes, and maybe pre-aggregated analytics), with some data marts and pre-aggregated data. &lt;/p&gt;\n\n&lt;p&gt;I get that this is less flexible and scalable, and that many organizations are dealing with massive amounts of unstructured data of all sorts of types constantly showing up .&lt;/p&gt;\n\n&lt;p&gt;The current approach is to put into file-like structures, distributed (with containers, etc.), and then analysts are the ones who somehow grab the data and organize it. No longer is there a single source of organized, business-knowledge-embedded data. While this seems great for some use cases, it doesn&amp;#39;t seem to fit the original use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11hfijs", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11hfijs/target_for_mostly_structured_data_goal_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11hfijs/target_for_mostly_structured_data_goal_of/", "subreddit_subscribers": 91856, "created_utc": 1677878889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I\u2019m looking to do some research on building a potential SDK model for my company\u2019s data visualization platform. Hoping to better understand what value we can add rather than just being a data viz SDK. If you could wish for any features in a data visualization SDK what would it be? Thank you in advance \ud83d\ude0a", "author_fullname": "t2_5mmilr0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you could have anything in a data viz SDK Model what would you wish for?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11he6z1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677875932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I\u2019m looking to do some research on building a potential SDK model for my company\u2019s data visualization platform. Hoping to better understand what value we can add rather than just being a data viz SDK. If you could wish for any features in a data visualization SDK what would it be? Thank you in advance \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11he6z1", "is_robot_indexable": true, "report_reasons": null, "author": "frozenbutterstick", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11he6z1/if_you_could_have_anything_in_a_data_viz_sdk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11he6z1/if_you_could_have_anything_in_a_data_viz_sdk/", "subreddit_subscribers": 91856, "created_utc": 1677875932.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}