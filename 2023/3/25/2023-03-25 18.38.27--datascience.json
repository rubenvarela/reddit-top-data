{"kind": "Listing", "data": {"after": "t3_121k7ei", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been tasked with simulating the flow of ~150 parts inventory thru our process where there are two primary flows of planned demand (shipments scheduled to customers) and unplanned demand (units in the field that have failed and need replaced ASAP).  These are parts of capital equipment worth $100k+.  \n\nHave some limited historical data to support this and gain some insight on failures and future demand forecasting. \n\nMy idea was to generate hundreds of simulation runs using assumed distributions for demand and failure and the appropriate build and shipping times.  \n\nBut after generating these simulations be able to optimize across all the runs to see what level of inventory or build schedule satisfies most simulated conditions.  And what would be the most effective strategy computationally. \n\nMy initial thoughts sim thru time and store each day for each run in a matrix where the rows are diff days into the future and each column is a diff simulation.  Then have one matrix for planned demand, one for unplanned another matrix which is the cost of each component type.  Then use scalar changes in inventory levels across the matrices for the optimization component.  \n\nAnyone done something similar or have a better approach?", "author_fullname": "t2_2lc8bvy9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inventory Simulation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121b9ag", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679720358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been tasked with simulating the flow of ~150 parts inventory thru our process where there are two primary flows of planned demand (shipments scheduled to customers) and unplanned demand (units in the field that have failed and need replaced ASAP).  These are parts of capital equipment worth $100k+.  &lt;/p&gt;\n\n&lt;p&gt;Have some limited historical data to support this and gain some insight on failures and future demand forecasting. &lt;/p&gt;\n\n&lt;p&gt;My idea was to generate hundreds of simulation runs using assumed distributions for demand and failure and the appropriate build and shipping times.  &lt;/p&gt;\n\n&lt;p&gt;But after generating these simulations be able to optimize across all the runs to see what level of inventory or build schedule satisfies most simulated conditions.  And what would be the most effective strategy computationally. &lt;/p&gt;\n\n&lt;p&gt;My initial thoughts sim thru time and store each day for each run in a matrix where the rows are diff days into the future and each column is a diff simulation.  Then have one matrix for planned demand, one for unplanned another matrix which is the cost of each component type.  Then use scalar changes in inventory levels across the matrices for the optimization component.  &lt;/p&gt;\n\n&lt;p&gt;Anyone done something similar or have a better approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121b9ag", "is_robot_indexable": true, "report_reasons": null, "author": "jimtoberfest", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121b9ag/inventory_simulation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121b9ag/inventory_simulation/", "subreddit_subscribers": 862376, "created_utc": 1679720358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_j6enx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the best twitter accounts you follow for data science news and articles.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121gvv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679737541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121gvv0", "is_robot_indexable": true, "report_reasons": null, "author": "amcelvanna783", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121gvv0/what_are_some_of_the_best_twitter_accounts_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121gvv0/what_are_some_of_the_best_twitter_accounts_you/", "subreddit_subscribers": 862376, "created_utc": 1679737541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve got a job with an awesome company, working on projects I feel good about, but holy smokes I hate dealing with the shitshow that is my teams data entry practices from pre-2021. I spend a solid half of my time figuring out where the hell the inconsistencies are, then the other half figuring out what values to sub in for the inconsistencies to make the data workable. At that point how useful is the data, how trustworthy? Not useful or trustworthy! The teams leads wonder why I\u2019m giving them models that explain nothing, and then act surprised when I tell them it\u2019s because the old data was essentially made up. The circle is endless. This isn\u2019t science, this is like working at a daycare cleaning up after toddlers, and when the parents pick them up they complain about the child\u2019s poor behavior.", "author_fullname": "t2_59l9bdfsa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gotta vent about wasted time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121r76h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679762068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got a job with an awesome company, working on projects I feel good about, but holy smokes I hate dealing with the shitshow that is my teams data entry practices from pre-2021. I spend a solid half of my time figuring out where the hell the inconsistencies are, then the other half figuring out what values to sub in for the inconsistencies to make the data workable. At that point how useful is the data, how trustworthy? Not useful or trustworthy! The teams leads wonder why I\u2019m giving them models that explain nothing, and then act surprised when I tell them it\u2019s because the old data was essentially made up. The circle is endless. This isn\u2019t science, this is like working at a daycare cleaning up after toddlers, and when the parents pick them up they complain about the child\u2019s poor behavior.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121r76h", "is_robot_indexable": true, "report_reasons": null, "author": "ExtraSpecialCake", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121r76h/gotta_vent_about_wasted_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121r76h/gotta_vent_about_wasted_time/", "subreddit_subscribers": 862376, "created_utc": 1679762068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Personally, I\u2019ve experienced data scientist and analyst interviews change. 5 years ago (and even 3 years ago) when I was job hunting for DS and DA positions, the interview process was INCREDIBLY long, with panel interviews ranging from 6-8 people back-to-back, live coding sessions, take-home projects that would take days, multiple technical rounds, and even some with Fermi problems. And these were for JUNIOR positions!\n\nI just finished another successful job hunt and landed a DS position. I actually had 3 job offers. But in all 3 of those companies, none had a crazy amount of panel interviews (2 max), none involved take-home projects, and none involved live coding. They all focused on talking about past experiences and technical questions or case problems sprinkled in.\n\nGranted, the 3 companies in question are non-tech (yet have mature data capabilities) while the interviews from 3-5 years ago were mostly from tech. But even the non-tech companies from that time period had grueling interview processes.\n\nJust wondering if anyone else has experienced the same, and if it\u2019s any indicator that DS interviews are finally \u201cleveling out\u201d and cutting out all the BS.", "author_fullname": "t2_h5j8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have Data Scientist &amp; Analyst interviews changed over the past 5+ years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120svtx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679681732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Personally, I\u2019ve experienced data scientist and analyst interviews change. 5 years ago (and even 3 years ago) when I was job hunting for DS and DA positions, the interview process was INCREDIBLY long, with panel interviews ranging from 6-8 people back-to-back, live coding sessions, take-home projects that would take days, multiple technical rounds, and even some with Fermi problems. And these were for JUNIOR positions!&lt;/p&gt;\n\n&lt;p&gt;I just finished another successful job hunt and landed a DS position. I actually had 3 job offers. But in all 3 of those companies, none had a crazy amount of panel interviews (2 max), none involved take-home projects, and none involved live coding. They all focused on talking about past experiences and technical questions or case problems sprinkled in.&lt;/p&gt;\n\n&lt;p&gt;Granted, the 3 companies in question are non-tech (yet have mature data capabilities) while the interviews from 3-5 years ago were mostly from tech. But even the non-tech companies from that time period had grueling interview processes.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone else has experienced the same, and if it\u2019s any indicator that DS interviews are finally \u201cleveling out\u201d and cutting out all the BS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120svtx", "is_robot_indexable": true, "report_reasons": null, "author": "redditisthenewblak", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120svtx/have_data_scientist_analyst_interviews_changed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120svtx/have_data_scientist_analyst_interviews_changed/", "subreddit_subscribers": 862376, "created_utc": 1679681732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When building a multiple linear regression through Python, to select my independent variables, i was thinking of building a heat map to determine correlation using pearson. Does anyone have a better alternative?", "author_fullname": "t2_a24n8dl6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking for a friend \ud83d\ude02", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121pizx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679758423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When building a multiple linear regression through Python, to select my independent variables, i was thinking of building a heat map to determine correlation using pearson. Does anyone have a better alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121pizx", "is_robot_indexable": true, "report_reasons": null, "author": "MiamiTaco627", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121pizx/asking_for_a_friend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121pizx/asking_for_a_friend/", "subreddit_subscribers": 862376, "created_utc": 1679758423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, see a lot of posts on here about technical courses. As much as I like the technical side of things, I appreciate I will probably never be able to implement technical components. I would love to know more about data science applications, when to use (or not use) them?\n\nAny ideas ? Thank you", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good courses on machine learning but at a managerial level?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121d5wv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679725715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, see a lot of posts on here about technical courses. As much as I like the technical side of things, I appreciate I will probably never be able to implement technical components. I would love to know more about data science applications, when to use (or not use) them?&lt;/p&gt;\n\n&lt;p&gt;Any ideas ? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121d5wv", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121d5wv/any_good_courses_on_machine_learning_but_at_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121d5wv/any_good_courses_on_machine_learning_but_at_a/", "subreddit_subscribers": 862376, "created_utc": 1679725715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a Data Scientist Consultant for an IT consulting firm for nearly 2 years now. Most of the projects with the client (signed contract) usually last about 3-6 months like my CV (around 4 clients now) but some people actually stay longer with the client continuing to phrase 2 or even 3. When I ask my friend from another Consulting firm as a Strategist, he said it is normal to actually change that fast for his position but not so sure about mine. Is it a red flag to jump clients that much or would it be better to stay at least 9-12 months with one client exclusively?", "author_fullname": "t2_3ct6vq4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the appropriate duration for a new account/project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1212myx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679700118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Data Scientist Consultant for an IT consulting firm for nearly 2 years now. Most of the projects with the client (signed contract) usually last about 3-6 months like my CV (around 4 clients now) but some people actually stay longer with the client continuing to phrase 2 or even 3. When I ask my friend from another Consulting firm as a Strategist, he said it is normal to actually change that fast for his position but not so sure about mine. Is it a red flag to jump clients that much or would it be better to stay at least 9-12 months with one client exclusively?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1212myx", "is_robot_indexable": true, "report_reasons": null, "author": "taylortiki", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1212myx/what_is_the_appropriate_duration_for_a_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1212myx/what_is_the_appropriate_duration_for_a_new/", "subreddit_subscribers": 862376, "created_utc": 1679700118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 can solve most SQL interview questions. In 5 years, do you think Acing a SQL Interview will still be important?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_121tjz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6zm7tswg", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "SQL", "selftext": "GPT-4 can write SQL queries and solve most easy &amp; medium SQL interview questions on DataLemur. So I'm curious, will Acing the SQL Interview still be important in 5 years? What about in 10?\n\n[View Poll](https://www.reddit.com/poll/121q7nt)", "author_fullname": "t2_6zm7tswg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 can solve most SQL interview questions. In 5 years, do you think Acing a SQL Interview will still be important?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/SQL", "hidden": false, "pwls": 6, "link_flair_css_class": "h", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121q7nt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "01031502-de87-11e6-b05e-0e1ce54f6a26", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679766346.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679759953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.SQL", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GPT-4 can write SQL queries and solve most easy &amp;amp; medium SQL interview questions on DataLemur. So I&amp;#39;m curious, will Acing the SQL Interview still be important in 5 years? What about in 10?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/121q7nt\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5cb03a64-2769-11ea-aa04-0ed301f44875", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Author of Ace the Data Science Interview \ud83d\udcd5", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qp8q", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "121q7nt", "is_robot_indexable": true, "report_reasons": null, "author": "NickSinghTechCareers", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1680364753748, "options": [{"text": "SQL Interview Will Be Obsolete", "id": "22238479"}, {"text": "SQL Interviews Might Go Away", "id": "22238480"}, {"text": "SQL Interviews Won't Go Away", "id": "22238481"}, {"text": "Show Results", "id": "22238482"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 177, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/SQL/comments/121q7nt/gpt4_can_solve_most_sql_interview_questions_in_5/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/SQL/comments/121q7nt/gpt4_can_solve_most_sql_interview_questions_in_5/", "subreddit_subscribers": 144286, "created_utc": 1679759953.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679766802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.SQL", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/SQL/comments/121q7nt/gpt4_can_solve_most_sql_interview_questions_in_5/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Author | Ace the Data Science Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121tjz7", "is_robot_indexable": true, "report_reasons": null, "author": "NickSinghTechCareers", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_121q7nt", "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/121tjz7/gpt4_can_solve_most_sql_interview_questions_in_5/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/SQL/comments/121q7nt/gpt4_can_solve_most_sql_interview_questions_in_5/", "subreddit_subscribers": 862376, "created_utc": 1679766802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a building a dashboard using Streamlit, Plotly Ex, python, pandas, numpy, scikit-learn, etc. The goal is to allow the audience to interactively explore the data. Different people will be using the dashboard and their data would be different, but they all have some commonalities. I want to build a dashboard that is \"generic\" enough to be applicable for most situations.\n\nThe data can contain categorical and numeric data, but mostly categorical. They all deal with consumer studies. The column of interest is typically some kind of categorical preference question (do you prefer A or B), or (would you buy this or no). There would be some demographic info of the consumer, some numeric columns that might pertain to ratings of a certain feature, and some categorical responses (multiple choice questions). \n\nThere are usually many features compared to number of observations. (ie, you might have only 100 consumers, but you asked them a bunch of questions)\n\nI think pair plots can be useful. Maybe give the user to ability to select some variables of interest, and run pair plots on them. \n\nI also plan to give the user the ability to group by variables and do various aggregations. \n\nSome filtering capability would also be built. (say, only want to see those with age &gt; 30)\n\nI'm also thinking running a random forest on the column of interest (such as preference) and determining the most important features. (not sure if this is a good idea given that the data typically have many features and not enough observations. A typical dataset might have 100 rows, and 40 columns) \n\nI don't plan on doing anything too specific (like stat tests) as those requires an understanding of what they are trying to do. Just want to build something automated and is general enough, and has enough functionalities to be useful, without doing \"too much\" that can cause issues.\n\nPlease advise on what you would or would not include.\n\nThanks", "author_fullname": "t2_6fty441r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a generic interactive business dashboard, what would you include?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_121s7p2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679764140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a building a dashboard using Streamlit, Plotly Ex, python, pandas, numpy, scikit-learn, etc. The goal is to allow the audience to interactively explore the data. Different people will be using the dashboard and their data would be different, but they all have some commonalities. I want to build a dashboard that is &amp;quot;generic&amp;quot; enough to be applicable for most situations.&lt;/p&gt;\n\n&lt;p&gt;The data can contain categorical and numeric data, but mostly categorical. They all deal with consumer studies. The column of interest is typically some kind of categorical preference question (do you prefer A or B), or (would you buy this or no). There would be some demographic info of the consumer, some numeric columns that might pertain to ratings of a certain feature, and some categorical responses (multiple choice questions). &lt;/p&gt;\n\n&lt;p&gt;There are usually many features compared to number of observations. (ie, you might have only 100 consumers, but you asked them a bunch of questions)&lt;/p&gt;\n\n&lt;p&gt;I think pair plots can be useful. Maybe give the user to ability to select some variables of interest, and run pair plots on them. &lt;/p&gt;\n\n&lt;p&gt;I also plan to give the user the ability to group by variables and do various aggregations. &lt;/p&gt;\n\n&lt;p&gt;Some filtering capability would also be built. (say, only want to see those with age &amp;gt; 30)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also thinking running a random forest on the column of interest (such as preference) and determining the most important features. (not sure if this is a good idea given that the data typically have many features and not enough observations. A typical dataset might have 100 rows, and 40 columns) &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t plan on doing anything too specific (like stat tests) as those requires an understanding of what they are trying to do. Just want to build something automated and is general enough, and has enough functionalities to be useful, without doing &amp;quot;too much&amp;quot; that can cause issues.&lt;/p&gt;\n\n&lt;p&gt;Please advise on what you would or would not include.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121s7p2", "is_robot_indexable": true, "report_reasons": null, "author": "engineheat2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121s7p2/building_a_generic_interactive_business_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121s7p2/building_a_generic_interactive_business_dashboard/", "subreddit_subscribers": 862376, "created_utc": 1679764140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nUsing the backend hidden api from chat gpt, Maximize your ChatGPT experience scrap9kg your history with GPT_Scraper - the tool that makes scraping a breeze!\n\n\n4 min read\n\n#ChatGPT #NaturalLanguageProcessing #PythonProgramming #DataScraping #AItools", "author_fullname": "t2_614orzb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping All your Conversations with ChatGPT Made Easy with GPT_Scraper!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_121teme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GyB3sJR_185irtYjUpzZsvBV1xBZqbkmG0iErD8xucs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679766506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using the backend hidden api from chat gpt, Maximize your ChatGPT experience scrap9kg your history with GPT_Scraper - the tool that makes scraping a breeze!&lt;/p&gt;\n\n&lt;p&gt;4 min read&lt;/p&gt;\n\n&lt;h1&gt;ChatGPT #NaturalLanguageProcessing #PythonProgramming #DataScraping #AItools&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/SjIRhBXFsyb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hjgAw6PWSvTt0SHNJGjaIWajIKpiTIrYd-G6xijwKgo.jpg?auto=webp&amp;v=enabled&amp;s=6a33f773a4ed1f54ce32c6f6bc6d8e9118d985d7", "width": 944, "height": 1049}, "resolutions": [{"url": "https://external-preview.redd.it/hjgAw6PWSvTt0SHNJGjaIWajIKpiTIrYd-G6xijwKgo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a86adee9e13be3c16b5c946b6cd74643e52378f", "width": 108, "height": 120}, {"url": "https://external-preview.redd.it/hjgAw6PWSvTt0SHNJGjaIWajIKpiTIrYd-G6xijwKgo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3611b8b5186f4f9af0edc45cf0c25a5846515774", "width": 216, "height": 240}, {"url": "https://external-preview.redd.it/hjgAw6PWSvTt0SHNJGjaIWajIKpiTIrYd-G6xijwKgo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed600cf574e807e2a7d061f4c68fcc4af9bf1365", "width": 320, "height": 355}, {"url": "https://external-preview.redd.it/hjgAw6PWSvTt0SHNJGjaIWajIKpiTIrYd-G6xijwKgo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58631293aea5d0d141a931a3551d724b2d08ad62", "width": 640, "height": 711}], "variants": {}, "id": "Hb3UbW-jOhzfdsOmkxhU1RMiefbzoiWODqAJVsLva74"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=32add54efce28cc8ce035c5e2bc89a27286a815e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dfb00ece05340570177df7cfa1af6d2737c0910b", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8b0b87b868f6cd6313e2c90975dac636e4a0412", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=2a3ad7ec2ccc57b6c65b17e2b57647a81f335039", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d4a8ca64b391e8b057408067d77f503752c29b7e", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=4efb20a46b5cee58042da74830ee914d1547236c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=83e8bea70baef2140842017e967f163a9f530a9d", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=14fb29ce140b35a21a7cc7ee1c4d212ce0b1179d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=533b05085677b48f15004bd7f9ff19ec5b29099f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=6f767b3c289e5cb2a733b24da5f4c46d9c079bc7", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "121teme", "is_robot_indexable": true, "report_reasons": null, "author": "Rodolflying", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121teme/scraping_all_your_conversations_with_chatgpt_made/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/SjIRhBXFsyb", "subreddit_subscribers": 862376, "created_utc": 1679766506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "second year student currently doing bachelors in cs. fell in love with data science and recently started doing online courses on ML/DL. i have a good knowledge of python, sql and math (stats, linear algebra, matrices) so the topics and algos seem very easy. decent gpa. i havent started working on a project yet. im about to enter my third year and havent participated in any hackathons or competitions in my college so i feel like im very behind. could someone tell me how quickly i should finish these courses and what projects i should do next? im a bit scared for my future placements and internships. all suggestions are welcome! thanks", "author_fullname": "t2_6xtnh1e4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "afraid of falling behind", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_121sou6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679765080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;second year student currently doing bachelors in cs. fell in love with data science and recently started doing online courses on ML/DL. i have a good knowledge of python, sql and math (stats, linear algebra, matrices) so the topics and algos seem very easy. decent gpa. i havent started working on a project yet. im about to enter my third year and havent participated in any hackathons or competitions in my college so i feel like im very behind. could someone tell me how quickly i should finish these courses and what projects i should do next? im a bit scared for my future placements and internships. all suggestions are welcome! thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121sou6", "is_robot_indexable": true, "report_reasons": null, "author": "mk2k3", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121sou6/afraid_of_falling_behind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121sou6/afraid_of_falling_behind/", "subreddit_subscribers": 862376, "created_utc": 1679765080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a line graph with x/y axis. X refers to time and Y refers to a count.\n\nNow the correct graph looks very similar to a gamma distribution, but not quite. This is what is considered the \"standard/expected\" shape.\n\nWhen I graph new data, I need to detect if the shape deviates significantly from the standard. The shape is the most important and not necessarily the values.\n\nFor example, the standard shape could go up to 2000 on the y-axis on one graph, and only 200 on the other, but it's the shape that matters.\n\nSo if you took the standard shape, copied it, and moved it +100 in the positive x-direction, and then scaled the y-axis up 1000, it would still follow the standaed shape, so it would be labeled as \"standard\".\n\nI tried a Whitney-Mann U test and wasn't successful. I'm a little at a loss. Any suggestions?", "author_fullname": "t2_bzw9ivz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a statistical test to compare two sets of data based on the shape of the graph and not necessarily the difference in the data itself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1212g4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679699727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a line graph with x/y axis. X refers to time and Y refers to a count.&lt;/p&gt;\n\n&lt;p&gt;Now the correct graph looks very similar to a gamma distribution, but not quite. This is what is considered the &amp;quot;standard/expected&amp;quot; shape.&lt;/p&gt;\n\n&lt;p&gt;When I graph new data, I need to detect if the shape deviates significantly from the standard. The shape is the most important and not necessarily the values.&lt;/p&gt;\n\n&lt;p&gt;For example, the standard shape could go up to 2000 on the y-axis on one graph, and only 200 on the other, but it&amp;#39;s the shape that matters.&lt;/p&gt;\n\n&lt;p&gt;So if you took the standard shape, copied it, and moved it +100 in the positive x-direction, and then scaled the y-axis up 1000, it would still follow the standaed shape, so it would be labeled as &amp;quot;standard&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I tried a Whitney-Mann U test and wasn&amp;#39;t successful. I&amp;#39;m a little at a loss. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1212g4u", "is_robot_indexable": true, "report_reasons": null, "author": "yukobeam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1212g4u/is_there_a_statistical_test_to_compare_two_sets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1212g4u/is_there_a_statistical_test_to_compare_two_sets/", "subreddit_subscribers": 862376, "created_utc": 1679699727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I am working on a demand forecasting model. It predicts the demand in the upcoming month. How can I produce quantiles as forecast instead of a single estimate. I need qunatiles to account for the capital availability. If the available capital is low for example take the 50th percentile as the forecast. If it's high on the other hand take the 75th.", "author_fullname": "t2_8jmib0lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quantiles as predictions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120zqr5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679694159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I am working on a demand forecasting model. It predicts the demand in the upcoming month. How can I produce quantiles as forecast instead of a single estimate. I need qunatiles to account for the capital availability. If the available capital is low for example take the 50th percentile as the forecast. If it&amp;#39;s high on the other hand take the 75th.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120zqr5", "is_robot_indexable": true, "report_reasons": null, "author": "Riolite55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120zqr5/quantiles_as_predictions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120zqr5/quantiles_as_predictions/", "subreddit_subscribers": 862376, "created_utc": 1679694159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nDoes any redditor here works as a DS in civil engineer or construction?\n\nI have experience in that industry and I was wondering what uses DS can have or what companies merge these two areas.\n\nCongrats on the sub!", "author_fullname": "t2_4hwr77yk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Civil Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120xg7n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679689849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Does any redditor here works as a DS in civil engineer or construction?&lt;/p&gt;\n\n&lt;p&gt;I have experience in that industry and I was wondering what uses DS can have or what companies merge these two areas.&lt;/p&gt;\n\n&lt;p&gt;Congrats on the sub!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120xg7n", "is_robot_indexable": true, "report_reasons": null, "author": "_r_u_i_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120xg7n/data_science_in_civil_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120xg7n/data_science_in_civil_engineering/", "subreddit_subscribers": 862376, "created_utc": 1679689849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 2.5 YOE as a DS in academia. I am now working as a DE in consulting. I took the DE role to get some experience in that area. I am completing my MS in Data Science. What is the optimal path to becoming a CDO at a medium to large company? Continue in consulting? Get an MBA after my MS?\n\nI know the path is not set in stone. Just wondering if anyone knows the general way people become CDOs.", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to become a Chief Data Officer. What is the typical path to CDO?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120wj8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679688156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2.5 YOE as a DS in academia. I am now working as a DE in consulting. I took the DE role to get some experience in that area. I am completing my MS in Data Science. What is the optimal path to becoming a CDO at a medium to large company? Continue in consulting? Get an MBA after my MS?&lt;/p&gt;\n\n&lt;p&gt;I know the path is not set in stone. Just wondering if anyone knows the general way people become CDOs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120wj8t", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120wj8t/i_want_to_become_a_chief_data_officer_what_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120wj8t/i_want_to_become_a_chief_data_officer_what_is_the/", "subreddit_subscribers": 862376, "created_utc": 1679688156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to export my tableau dashboards to a pdf and email them to my clients on a weekly basis. What options do I have for doing this that don\u2019t involve my clients having to download anything?", "author_fullname": "t2_da67df26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating Tableau Reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120vvi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679687216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to export my tableau dashboards to a pdf and email them to my clients on a weekly basis. What options do I have for doing this that don\u2019t involve my clients having to download anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120vvi6", "is_robot_indexable": true, "report_reasons": null, "author": "Subject-Resort5893", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120vvi6/automating_tableau_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120vvi6/automating_tableau_reports/", "subreddit_subscribers": 862376, "created_utc": 1679687216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow data scientists! \nSorry if this is against the rules , but I didn\u2019t see anything explicitly banning this, so here goes. I\u2019m working in the US and my visa runs out at the end of the year. That\u2019s fine, because I\u2019m planning to move to the UK with my partner. I\u2019m originally from India, so I\u2019ll have to be sponsored for a visa. I have a PhD in explainable machine learning and have been a lead Data Scientist at a small startup for the last year or so. I have a fair bit of experience in document processing and structured data handling. If you or anyone you know is hiring in the UK and is willing to sponsor a work visa, I\u2019d love to hear about it. I have also worked with huggingface\u2019s BigScience initiative including BigCode, BigBio and BLOOM. Looking forward to any pointers you might have. \nThanks!", "author_fullname": "t2_nmj51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job opportunities in UK", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120tzl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679683929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data scientists! \nSorry if this is against the rules , but I didn\u2019t see anything explicitly banning this, so here goes. I\u2019m working in the US and my visa runs out at the end of the year. That\u2019s fine, because I\u2019m planning to move to the UK with my partner. I\u2019m originally from India, so I\u2019ll have to be sponsored for a visa. I have a PhD in explainable machine learning and have been a lead Data Scientist at a small startup for the last year or so. I have a fair bit of experience in document processing and structured data handling. If you or anyone you know is hiring in the UK and is willing to sponsor a work visa, I\u2019d love to hear about it. I have also worked with huggingface\u2019s BigScience initiative including BigCode, BigBio and BLOOM. Looking forward to any pointers you might have. \nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120tzl3", "is_robot_indexable": true, "report_reasons": null, "author": "thatphotoguy89", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120tzl3/job_opportunities_in_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120tzl3/job_opportunities_in_uk/", "subreddit_subscribers": 862376, "created_utc": 1679683929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\nI am trying to get a certification in data science from data camp. I failed the final project and the reason is that the data validation was insufficient. I did all the required steps to clean out the data : outliers, unique values, no null values, log method etc. what could be the extra steps for a better data validation ?\nThank you in advance", "author_fullname": "t2_t1ls7aqf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Steps for data validation (please help)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120t4s8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679682220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,\nI am trying to get a certification in data science from data camp. I failed the final project and the reason is that the data validation was insufficient. I did all the required steps to clean out the data : outliers, unique values, no null values, log method etc. what could be the extra steps for a better data validation ?\nThank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120t4s8", "is_robot_indexable": true, "report_reasons": null, "author": "bach678", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120t4s8/steps_for_data_validation_please_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120t4s8/steps_for_data_validation_please_help/", "subreddit_subscribers": 862376, "created_utc": 1679682220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just started a new role as a Demand Planner.  I have been asked to update and maintain a file that calculates forecast \"accuracy\", which was created by a person who retired.  I have my doubts that the file has been set up properly.  The company's goal is for forecasts to reach 80% \"accuracy\" (where 100% would be perfect forecasts).  But shouldn't it be the other way around?  Shouldn't the KPI be 20% Forecast Error or lower?  Because in cases of extreme under-forecasting or over-forecasting, the error will exceed 100%, so representing the accuracy by subtracting the error from 100% is meaningless.  \n\n&amp;#x200B;\n\nTo get around this issue, the file calculates the percent error as (Actual - Forecast)/Actual if the Absolute Error is less than the Actual, and it calculates the percent error as (Actual - Forecast)/Forecast if the Absolute Error is greater than the Actual.  Then it subtracts the Abs % Error from 100% to obtain the Forecast Accuracy.\n\n&amp;#x200B;\n\nHere are some examples of how the current file calculates forecast accuracy:\n\n&amp;#x200B;\n\n|Forecast|Actual|Abs Error|Abs % Error (Actual as Denominator)|Abs % Error (Forecast as Denominator)|Abs % Error (shown on the file)|Accuracy|\n|:-|:-|:-|:-|:-|:-|:-|\n|100|0|100|error|100%|100%|0%|\n|100|10|90|900%|90%|90%|10%|\n|100|75|25|33%|25%|33%|67%|\n|100|100|0|0%|0%|0%|100%|\n|100|250|150|60%|150%|60%|40%|\n|100|1000|900|90%|900%|90%|10%|\n|0|100|100|100%|error|100%|0%|\n\n&amp;#x200B;\n\nIs this the correct way to calculate Forecast Accuracy?", "author_fullname": "t2_tmaq0p4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecast Accuracy = 1 - Forecast Error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120sznw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679681946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started a new role as a Demand Planner.  I have been asked to update and maintain a file that calculates forecast &amp;quot;accuracy&amp;quot;, which was created by a person who retired.  I have my doubts that the file has been set up properly.  The company&amp;#39;s goal is for forecasts to reach 80% &amp;quot;accuracy&amp;quot; (where 100% would be perfect forecasts).  But shouldn&amp;#39;t it be the other way around?  Shouldn&amp;#39;t the KPI be 20% Forecast Error or lower?  Because in cases of extreme under-forecasting or over-forecasting, the error will exceed 100%, so representing the accuracy by subtracting the error from 100% is meaningless.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To get around this issue, the file calculates the percent error as (Actual - Forecast)/Actual if the Absolute Error is less than the Actual, and it calculates the percent error as (Actual - Forecast)/Forecast if the Absolute Error is greater than the Actual.  Then it subtracts the Abs % Error from 100% to obtain the Forecast Accuracy.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here are some examples of how the current file calculates forecast accuracy:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Forecast&lt;/th&gt;\n&lt;th align=\"left\"&gt;Actual&lt;/th&gt;\n&lt;th align=\"left\"&gt;Abs Error&lt;/th&gt;\n&lt;th align=\"left\"&gt;Abs % Error (Actual as Denominator)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Abs % Error (Forecast as Denominator)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Abs % Error (shown on the file)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Accuracy&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;error&lt;/td&gt;\n&lt;td align=\"left\"&gt;100%&lt;/td&gt;\n&lt;td align=\"left\"&gt;100%&lt;/td&gt;\n&lt;td align=\"left\"&gt;0%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;90&lt;/td&gt;\n&lt;td align=\"left\"&gt;900%&lt;/td&gt;\n&lt;td align=\"left\"&gt;90%&lt;/td&gt;\n&lt;td align=\"left\"&gt;90%&lt;/td&gt;\n&lt;td align=\"left\"&gt;10%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;75&lt;/td&gt;\n&lt;td align=\"left\"&gt;25&lt;/td&gt;\n&lt;td align=\"left\"&gt;33%&lt;/td&gt;\n&lt;td align=\"left\"&gt;25%&lt;/td&gt;\n&lt;td align=\"left\"&gt;33%&lt;/td&gt;\n&lt;td align=\"left\"&gt;67%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0%&lt;/td&gt;\n&lt;td align=\"left\"&gt;0%&lt;/td&gt;\n&lt;td align=\"left\"&gt;0%&lt;/td&gt;\n&lt;td align=\"left\"&gt;100%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;250&lt;/td&gt;\n&lt;td align=\"left\"&gt;150&lt;/td&gt;\n&lt;td align=\"left\"&gt;60%&lt;/td&gt;\n&lt;td align=\"left\"&gt;150%&lt;/td&gt;\n&lt;td align=\"left\"&gt;60%&lt;/td&gt;\n&lt;td align=\"left\"&gt;40%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;1000&lt;/td&gt;\n&lt;td align=\"left\"&gt;900&lt;/td&gt;\n&lt;td align=\"left\"&gt;90%&lt;/td&gt;\n&lt;td align=\"left\"&gt;900%&lt;/td&gt;\n&lt;td align=\"left\"&gt;90%&lt;/td&gt;\n&lt;td align=\"left\"&gt;10%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;100&lt;/td&gt;\n&lt;td align=\"left\"&gt;100%&lt;/td&gt;\n&lt;td align=\"left\"&gt;error&lt;/td&gt;\n&lt;td align=\"left\"&gt;100%&lt;/td&gt;\n&lt;td align=\"left\"&gt;0%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this the correct way to calculate Forecast Accuracy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120sznw", "is_robot_indexable": true, "report_reasons": null, "author": "iamindemand", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120sznw/forecast_accuracy_1_forecast_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120sznw/forecast_accuracy_1_forecast_error/", "subreddit_subscribers": 862376, "created_utc": 1679681946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, so if you are not a Baseball Nerd, OOTP is a baseball simulation game that lets you manage an MLB or other professional baseball team. It\u2019s basically a glorified spreadsheet since it keeps tons of stats. \n\nI\u2019ve been thinking of how fun it would be to create some machine learning models to predict player performance and create basically a mini fangraphs for our fictional online league.  \n\nThe question I have, is would this be too silly to put on my public GitHub? Would employers think it\u2019s a little silly to have models based off a video game? Should I just keep the repo private? I\u2019m about to graduate with my Masters and I\u2019m job hunting.", "author_fullname": "t2_dozq1t0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OOTP Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120sr9b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679681471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, so if you are not a Baseball Nerd, OOTP is a baseball simulation game that lets you manage an MLB or other professional baseball team. It\u2019s basically a glorified spreadsheet since it keeps tons of stats. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been thinking of how fun it would be to create some machine learning models to predict player performance and create basically a mini fangraphs for our fictional online league.  &lt;/p&gt;\n\n&lt;p&gt;The question I have, is would this be too silly to put on my public GitHub? Would employers think it\u2019s a little silly to have models based off a video game? Should I just keep the repo private? I\u2019m about to graduate with my Masters and I\u2019m job hunting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120sr9b", "is_robot_indexable": true, "report_reasons": null, "author": "Nooneofsignificance2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120sr9b/ootp_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120sr9b/ootp_machine_learning/", "subreddit_subscribers": 862376, "created_utc": 1679681471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So decision letters came out and I just found out that I was admitted into my top 2 choices: Carnegie Mellon and USC. I have heard about how USC has an unorthodox program but I don't really have any idea what that means. As a student who picked the Data Science major due to my love for statistics, where do you think I should go?   \nAny opinions on the respective programs would be amazing.", "author_fullname": "t2_m1zmpk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CMU vs USC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_121scpk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679764419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So decision letters came out and I just found out that I was admitted into my top 2 choices: Carnegie Mellon and USC. I have heard about how USC has an unorthodox program but I don&amp;#39;t really have any idea what that means. As a student who picked the Data Science major due to my love for statistics, where do you think I should go?&lt;br/&gt;\nAny opinions on the respective programs would be amazing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121scpk", "is_robot_indexable": true, "report_reasons": null, "author": "micancer", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121scpk/cmu_vs_usc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121scpk/cmu_vs_usc/", "subreddit_subscribers": 862376, "created_utc": 1679764419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for an entry level job as a Data Analyst and was wondering: what is the best way to showcase my abilities on LinkedIn? This sound like a silly question, but as a newbie, I wonder what do the recruiters want to see? Do they want to see Power BI dashboards? Do they want to see my thinking process? Should I post my SQL/python code lines? \n\nThere are so many possibilities that it's hard for me to find focus.", "author_fullname": "t2_ax0lvvdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I draw recruiters attention?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120yovb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679691998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an entry level job as a Data Analyst and was wondering: what is the best way to showcase my abilities on LinkedIn? This sound like a silly question, but as a newbie, I wonder what do the recruiters want to see? Do they want to see Power BI dashboards? Do they want to see my thinking process? Should I post my SQL/python code lines? &lt;/p&gt;\n\n&lt;p&gt;There are so many possibilities that it&amp;#39;s hard for me to find focus.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120yovb", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional-Reach818", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120yovb/how_can_i_draw_recruiters_attention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120yovb/how_can_i_draw_recruiters_attention/", "subreddit_subscribers": 862376, "created_utc": 1679691998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\n\nHello fellow data scientists,\n\nI have been working in the field of data science for a few years now and have noticed something peculiar among my colleagues. Many of them seem to be content with working in a corporate environment and are not interested in starting their own business, even though they possess a lot of knowledge about business data.\n\nI am curious to know why this is the case. As someone who is interested in entrepreneurship, I find it puzzling that data scientists who have a deep understanding of how businesses operate are not interested in starting their own ventures.\n\nIs it because of the fear of failure? Or is it because data scientists are more comfortable in a cooperative job environment where they can work with other professionals and learn from them? Maybe it's because they don't want to take the risk of investing their time and resources in a venture that may not succeed.\n\nI would love to hear your thoughts on this topic. As data scientists, we possess a unique set of skills that could be put to great use in the world of business. I believe that if we could combine our analytical skills with our entrepreneurial spirit, we could create some amazing businesses.\n\nSo, why do you think data scientists tend to shy away from starting their own businesses? Let's have a discussion and share our thoughts on this topic. Thank you!", "author_fullname": "t2_66fjdm6x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do data scientists avoid starting their own businesses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120wv8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679688730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data scientists,&lt;/p&gt;\n\n&lt;p&gt;I have been working in the field of data science for a few years now and have noticed something peculiar among my colleagues. Many of them seem to be content with working in a corporate environment and are not interested in starting their own business, even though they possess a lot of knowledge about business data.&lt;/p&gt;\n\n&lt;p&gt;I am curious to know why this is the case. As someone who is interested in entrepreneurship, I find it puzzling that data scientists who have a deep understanding of how businesses operate are not interested in starting their own ventures.&lt;/p&gt;\n\n&lt;p&gt;Is it because of the fear of failure? Or is it because data scientists are more comfortable in a cooperative job environment where they can work with other professionals and learn from them? Maybe it&amp;#39;s because they don&amp;#39;t want to take the risk of investing their time and resources in a venture that may not succeed.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this topic. As data scientists, we possess a unique set of skills that could be put to great use in the world of business. I believe that if we could combine our analytical skills with our entrepreneurial spirit, we could create some amazing businesses.&lt;/p&gt;\n\n&lt;p&gt;So, why do you think data scientists tend to shy away from starting their own businesses? Let&amp;#39;s have a discussion and share our thoughts on this topic. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120wv8m", "is_robot_indexable": true, "report_reasons": null, "author": "Eezikwultoo", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120wv8m/why_do_data_scientists_avoid_starting_their_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120wv8m/why_do_data_scientists_avoid_starting_their_own/", "subreddit_subscribers": 862376, "created_utc": 1679688730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm an experienced data scientist(4+ years). Recently joined a 100-150 people tech startup company that went bankrupt last two years. They're back in the game after receiving external fundinf. Lately I've been thinking if the expectations set upon my role are realistically achievable. My manager is more of a middle management guy with zero experience in data. When I was interviewing for them, it seemed like a match for my skills. They're looking to build predictive and prescriptive analytics using machine learning on a large scale.I was under the impression that they have  data engineers maintaining the data pipeline. I was also open to double hat data science and MLops as I've had experience doing both. I was surprised when I started working here that it's a one man data team job. Apparently, all of the data team left during layoffs last two years. The data science projects were also scattered across different locations(i.e cloud, local environment, etc.) and built using a custom library. Management wanted me to improve the current machine learning powered features of the app such that it can be reused by other companies. Unfortunately, it's tightly coupled with our backend services. The experiment platform for online testing was also built without understanding about the statistics behind it. It's a whole revamp of the data infrastructure if they wanted to achieve their goal to deploy machine learning solutions in large scale. I learned from the ex-data scientist working here that the current infra was built with tech debt since they wanted to ship things fast before(i.e series A funding). I've communicated what needs to be done first before they can achieve what they want. I asked for a data engineer since the ETL pipeline has been acting up lately and the staging environment crashes when I deploy new experiments. Nobody in the current team knows why it crashes so I'm left with very limited options on how to deliver value. I tried debugging it out on my own but it's beyond my understanding too. As of the moment, I'm finding out how they built their current model so I can at least tweak it and deliver value. Most of the notebooks are missing from the codebase and the remaining few are long notebooks with no context or comments on the purpose of the analysis done. There was also no documentation left. I guess because it was sudden layoffs and everyone didn't have time to document etc. I've been trying my best to do it all on my own hoping to make things happen for the past three months. I've pitched ideas for resources to achieve the goals but they always end up rejected by the engineers but approved by our manager. The hierarchy of decision making in the team is still confusing to me right now. I've also proposed solutions to make it easier to maintain the data infra as it's only me doing a one man data team job. It has been frustrating for me as my job became completely different as I've expected it to be when I joined here. To be fair, I think they didn't know what they need when they were hiring and they were also not aware of things that need fixing in the data pipeline. \n\nJust last week, I learned there are restructuring plans in the making. They're trying to get the manager fired as he is always missing and rarely communicating with the software engineers. Team's morale has been low since then.", "author_fullname": "t2_896476q8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One man data team, should I resign?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120srqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679681497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an experienced data scientist(4+ years). Recently joined a 100-150 people tech startup company that went bankrupt last two years. They&amp;#39;re back in the game after receiving external fundinf. Lately I&amp;#39;ve been thinking if the expectations set upon my role are realistically achievable. My manager is more of a middle management guy with zero experience in data. When I was interviewing for them, it seemed like a match for my skills. They&amp;#39;re looking to build predictive and prescriptive analytics using machine learning on a large scale.I was under the impression that they have  data engineers maintaining the data pipeline. I was also open to double hat data science and MLops as I&amp;#39;ve had experience doing both. I was surprised when I started working here that it&amp;#39;s a one man data team job. Apparently, all of the data team left during layoffs last two years. The data science projects were also scattered across different locations(i.e cloud, local environment, etc.) and built using a custom library. Management wanted me to improve the current machine learning powered features of the app such that it can be reused by other companies. Unfortunately, it&amp;#39;s tightly coupled with our backend services. The experiment platform for online testing was also built without understanding about the statistics behind it. It&amp;#39;s a whole revamp of the data infrastructure if they wanted to achieve their goal to deploy machine learning solutions in large scale. I learned from the ex-data scientist working here that the current infra was built with tech debt since they wanted to ship things fast before(i.e series A funding). I&amp;#39;ve communicated what needs to be done first before they can achieve what they want. I asked for a data engineer since the ETL pipeline has been acting up lately and the staging environment crashes when I deploy new experiments. Nobody in the current team knows why it crashes so I&amp;#39;m left with very limited options on how to deliver value. I tried debugging it out on my own but it&amp;#39;s beyond my understanding too. As of the moment, I&amp;#39;m finding out how they built their current model so I can at least tweak it and deliver value. Most of the notebooks are missing from the codebase and the remaining few are long notebooks with no context or comments on the purpose of the analysis done. There was also no documentation left. I guess because it was sudden layoffs and everyone didn&amp;#39;t have time to document etc. I&amp;#39;ve been trying my best to do it all on my own hoping to make things happen for the past three months. I&amp;#39;ve pitched ideas for resources to achieve the goals but they always end up rejected by the engineers but approved by our manager. The hierarchy of decision making in the team is still confusing to me right now. I&amp;#39;ve also proposed solutions to make it easier to maintain the data infra as it&amp;#39;s only me doing a one man data team job. It has been frustrating for me as my job became completely different as I&amp;#39;ve expected it to be when I joined here. To be fair, I think they didn&amp;#39;t know what they need when they were hiring and they were also not aware of things that need fixing in the data pipeline. &lt;/p&gt;\n\n&lt;p&gt;Just last week, I learned there are restructuring plans in the making. They&amp;#39;re trying to get the manager fired as he is always missing and rarely communicating with the software engineers. Team&amp;#39;s morale has been low since then.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "120srqt", "is_robot_indexable": true, "report_reasons": null, "author": "ramenmaster2021", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/120srqt/one_man_data_team_should_i_resign/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/120srqt/one_man_data_team_should_i_resign/", "subreddit_subscribers": 862376, "created_utc": 1679681497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been given time series of N stock prices and time series of K sectoral indices. (Sectoral index is index made from all stocks belonging to that sector.)\nI have not been given names of any of those stocks or indices.\nI want to know which stocks belong to the same sector and sectoral indices.\nI am able to cluster the stocks. But how should I decide which sectoral index time series they correspond to? Should I just cluster stocks and indices together (N+K timeseries) instead of clustering N stocks independently? Will that be correct approach?", "author_fullname": "t2_aaamk24y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Determining clusters of time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121k7ei", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679746800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been given time series of N stock prices and time series of K sectoral indices. (Sectoral index is index made from all stocks belonging to that sector.)\nI have not been given names of any of those stocks or indices.\nI want to know which stocks belong to the same sector and sectoral indices.\nI am able to cluster the stocks. But how should I decide which sectoral index time series they correspond to? Should I just cluster stocks and indices together (N+K timeseries) instead of clustering N stocks independently? Will that be correct approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "121k7ei", "is_robot_indexable": true, "report_reasons": null, "author": "SnooHabits4550", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/121k7ei/determining_clusters_of_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/121k7ei/determining_clusters_of_time_series/", "subreddit_subscribers": 862376, "created_utc": 1679746800.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}