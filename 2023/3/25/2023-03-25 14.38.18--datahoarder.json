{"kind": "Listing", "data": {"after": "t3_12139w5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://twitter.com/PublishersWkly/status/1639390560820637697", "author_fullname": "t2_letnweep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Internet Archive lost their court case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1215jex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1337, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1337, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679706404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://twitter.com/PublishersWkly/status/1639390560820637697\"&gt;https://twitter.com/PublishersWkly/status/1639390560820637697&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3Ao8vrzfFp4Zw8QSg3Hzra1zs7omlJGMWhh8kqSOFHU.jpg?auto=webp&amp;v=enabled&amp;s=1993111c232d8c2b365ac8f3ba4adf75e428a44d", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/3Ao8vrzfFp4Zw8QSg3Hzra1zs7omlJGMWhh8kqSOFHU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba03f7841f2ae02e68decb0337039bfe5b8803a2", "width": 108, "height": 108}], "variants": {}, "id": "5wr6SJ9PVElR6WBc9k4bFzaTEWpExddZpa0MzZFbhTs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1215jex", "is_robot_indexable": true, "report_reasons": null, "author": "safels2", "discussion_type": null, "num_comments": 234, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1215jex/the_internet_archive_lost_their_court_case/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/1215jex/the_internet_archive_lost_their_court_case/", "subreddit_subscribers": 675028, "created_utc": 1679706404.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16ozdb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Brand new 12TB: I\u2019m hosed aren\u2019t I? (My fault)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_120vlu8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 420, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 420, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6tdM2zGZqx-bxAUodJUxfVkqYzgM9uSSHWdjlop_SpI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679686691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sub09trw6spa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sub09trw6spa1.jpg?auto=webp&amp;v=enabled&amp;s=c709098c5388f3491da581ab9c34e5ecd41fea36", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45ba704cab1858fbbfc7e66dc2949e2ce95e36d8", "width": 108, "height": 144}, {"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a0f9f3a3fc53161a97e7446d5dbb6a2e1abc626", "width": 216, "height": 288}, {"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=387417c83433af22f0274c3998a7402a34ec6e2b", "width": 320, "height": 426}, {"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1818e8a3e893db11e7b2147011f94342789f04e1", "width": 640, "height": 853}, {"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5310ae39c1c94f56b2bd57cc9316718e6a0fbe1", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/sub09trw6spa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f40dcb21b567b712f7f3e63d00e86385405e7a2c", "width": 1080, "height": 1440}], "variants": {}, "id": "orfLY8aLeui4WxnMaJi5wetq-v31UO0bR1OlVqhcHu4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "120vlu8", "is_robot_indexable": true, "report_reasons": null, "author": "LubbersDelight", "discussion_type": null, "num_comments": 127, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/120vlu8/brand_new_12tb_im_hosed_arent_i_my_fault/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sub09trw6spa1.jpg", "subreddit_subscribers": 675028, "created_utc": 1679686691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cb0uz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Judge Decides Against Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 118, "top_awarded_type": null, "hide_score": false, "name": "t3_1215rel", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 107, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PlJPbo6B9jOvLn5PnuvTkDM-EoCJpA7XDjL0rfRbSSE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679706907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "file770.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://file770.com/judge-decides-against-internet-archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8X9lI0XcuJu0pqYO96S-yr4Pqpqfm9FCABoPHQW20tc.jpg?auto=webp&amp;v=enabled&amp;s=4501e94d0c6955ea897079050e6c0fe640b135f5", "width": 540, "height": 456}, "resolutions": [{"url": "https://external-preview.redd.it/8X9lI0XcuJu0pqYO96S-yr4Pqpqfm9FCABoPHQW20tc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d445aaa47139a70086499ca9079351c62cb4284e", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/8X9lI0XcuJu0pqYO96S-yr4Pqpqfm9FCABoPHQW20tc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4c79a3272dfa66f738f22e29f325884cf951a03", "width": 216, "height": 182}, {"url": "https://external-preview.redd.it/8X9lI0XcuJu0pqYO96S-yr4Pqpqfm9FCABoPHQW20tc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=539ac8108ce2ff20b5d61e8a29680966b348d73f", "width": 320, "height": 270}], "variants": {}, "id": "zqroW1v6UbK8RCJtA9M6TALwU8g-ODuXMJU6s0qqM9s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1215rel", "is_robot_indexable": true, "report_reasons": null, "author": "nnomadic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1215rel/judge_decides_against_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://file770.com/judge-decides-against-internet-archive/", "subreddit_subscribers": 675028, "created_utc": 1679706907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cb0uz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - internetarchive/dweb-mirror: Offline Internet Archive project - Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1215qn9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gn-bV-sF0iXGR3XkczPE8T5b0hHlNtxWAXMPNMfL2Y0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679706857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/internetarchive/dweb-mirror", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?auto=webp&amp;v=enabled&amp;s=0c9c8ab52468511f289fe2d68ee7483603df460b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d4a14df248f9038188c309dc8486e4815479101", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f240eda8f2150e4e0f44e715cf1725ab74be1d1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9623cfa6c50aef21d156dcde79e8c6d3dce7ba72", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b55999e16de21d0cd2f42f8f6355bf529c1c832b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b626ac50336f9c9711167bd8522b222f03e6a852", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/vc_1QWOj2c9S7yEdmPflBudMeUdqXmmf_PxorW9TSBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0647cc5071c2932c511d13a315ff9ba97eafdc4d", "width": 1080, "height": 540}], "variants": {}, "id": "MLCXgSX2qF5KhUBag99ABR4htaVPJLAMOFoWNyOFEGo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1215qn9", "is_robot_indexable": true, "report_reasons": null, "author": "nnomadic", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1215qn9/github_internetarchivedwebmirror_offline_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/internetarchive/dweb-mirror", "subreddit_subscribers": 675028, "created_utc": 1679706857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_jub31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any glaring omissions? (other than Krazy Kat)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_12131s1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/HjBWev0lIy3xKbEQsceTtkT8jAR_LctA6B4wXndTpGo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679700998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/T4xotIX.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?auto=webp&amp;v=enabled&amp;s=1e4eaa00a3f7442c04d931539075028c506d7c39", "width": 1308, "height": 1720}, "resolutions": [{"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf27a8d6e0438f36ba7777fe00f683b4c0a85528", "width": 108, "height": 142}, {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a60c86a868809eee7de258539a7070fb269f96f", "width": 216, "height": 284}, {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e30ecd16140c293a7bf0e99ade52b4673da7c37", "width": 320, "height": 420}, {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e7383f703b77eadda8409fb05f8200e9fdaf188", "width": 640, "height": 841}, {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f98834df5a1dae38bee969efb7bd265e76757ad", "width": 960, "height": 1262}, {"url": "https://external-preview.redd.it/ZAZSorqbzMn32lse9pUSTaxAJ98SEDH-WJL2zlrIwH0.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3573f09607ad64ad89231e516e3fde2ad8171084", "width": 1080, "height": 1420}], "variants": {}, "id": "bpJ6jTwB9tI-xS-7b6IU00iDfepLEM4V1vtqpXQKXOU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12131s1", "is_robot_indexable": true, "report_reasons": null, "author": "hrrsnmb", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12131s1/any_glaring_omissions_other_than_krazy_kat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/T4xotIX.png", "subreddit_subscribers": 675028, "created_utc": 1679700998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As an aspiring datahoarder, I've found myself very disorganized (and here I thought I *was* organized). My current setup is an rPi 4B with a 14TB easyStore plugged in^(1), which is currently being a seedbox and Jellyfin server. \n\nIdeally, I'd like to have Jellyfin running on my old laptop so that I can actually transcode things, as well as use the rPi as a proper reverse proxy for said Jellyfin server. I also need to reorganize things, as everything that I haven't personally ripped is only catalogued with metadata on Jellyfin.\n\nWhat I was thinking was having my rPi being the brains of my \"NAS\"^(2), with my old laptop then accessing all those files via SMB or NFS and serving them up for Jellyfin^(2). So... how do I accomplish this securely? Both are running Debian Linux, both are headless, and they are physically close to each other (as well as being connected to the same unmanaged Ethernet switch). Thank you in advance.\n\n^(1) I have a single cold backup and will *eventually* switch to having two or more disks using ZFS/RAID 5/both(?)\n\n^(2) I feel like it makes sense to have my rPi continue to be a seedbox (and soulseek client), but if I'm mistaken please let me know", "author_fullname": "t2_1hutcmww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use SMB or NFS for local network filesharing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120tnnt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679683267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an aspiring datahoarder, I&amp;#39;ve found myself very disorganized (and here I thought I &lt;em&gt;was&lt;/em&gt; organized). My current setup is an rPi 4B with a 14TB easyStore plugged in&lt;sup&gt;1&lt;/sup&gt;, which is currently being a seedbox and Jellyfin server. &lt;/p&gt;\n\n&lt;p&gt;Ideally, I&amp;#39;d like to have Jellyfin running on my old laptop so that I can actually transcode things, as well as use the rPi as a proper reverse proxy for said Jellyfin server. I also need to reorganize things, as everything that I haven&amp;#39;t personally ripped is only catalogued with metadata on Jellyfin.&lt;/p&gt;\n\n&lt;p&gt;What I was thinking was having my rPi being the brains of my &amp;quot;NAS&amp;quot;&lt;sup&gt;2&lt;/sup&gt;, with my old laptop then accessing all those files via SMB or NFS and serving them up for Jellyfin&lt;sup&gt;2&lt;/sup&gt;. So... how do I accomplish this securely? Both are running Debian Linux, both are headless, and they are physically close to each other (as well as being connected to the same unmanaged Ethernet switch). Thank you in advance.&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; I have a single cold backup and will &lt;em&gt;eventually&lt;/em&gt; switch to having two or more disks using ZFS/RAID 5/both(?)&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; I feel like it makes sense to have my rPi continue to be a seedbox (and soulseek client), but if I&amp;#39;m mistaken please let me know&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Spent $405 for a single show", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "120tnnt", "is_robot_indexable": true, "report_reasons": null, "author": "General-Stryker", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/120tnnt/should_i_use_smb_or_nfs_for_local_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/120tnnt/should_i_use_smb_or_nfs_for_local_network/", "subreddit_subscribers": 675028, "created_utc": 1679683267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm almost totally set on moving to an e-Reader like Kindle Scribe or something of that size for the all of my book reading, if possible.  I like the idea of being able to also take notes, highlight, and etc., without ruining the book itself.\n\nThe only thing keeping me from moving all-in on an e-Reader is that there are some books that are unavailable in electronic format.  Specifically, I have some finance books that are hardcover that I'd like to convert to PDF or ePub format (or the like), but I don't really want to damage them by de-spining or having to push the hardcover flat against some glass in order to scan.  I also don't want to pay the cost to de-spine and have the pages scanned at Staples or the like.  \n\nSo I'm looking for my best options in 2023 that are reasonably efficient yet affordable.  I saw something about the hanging type of scanners that take images from above your book, so nothing is pressed against the book or putting pressure on the spine.  It seems that there is software that can de-warp and produce a pretty good quality resulting image/scan.  I'm wondering if this is the best way to go or if there are better ways.\n\nAlso, I'm wondering how long it would take me to scan an 800 page hardcover book, for example.  \n\nThanks in advance for any tips!", "author_fullname": "t2_7n02583k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2023 - Most affordable (yet efficient) way to scan a book into PDF/ePub without de-spining or damaging book?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1215s2k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679706944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m almost totally set on moving to an e-Reader like Kindle Scribe or something of that size for the all of my book reading, if possible.  I like the idea of being able to also take notes, highlight, and etc., without ruining the book itself.&lt;/p&gt;\n\n&lt;p&gt;The only thing keeping me from moving all-in on an e-Reader is that there are some books that are unavailable in electronic format.  Specifically, I have some finance books that are hardcover that I&amp;#39;d like to convert to PDF or ePub format (or the like), but I don&amp;#39;t really want to damage them by de-spining or having to push the hardcover flat against some glass in order to scan.  I also don&amp;#39;t want to pay the cost to de-spine and have the pages scanned at Staples or the like.  &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m looking for my best options in 2023 that are reasonably efficient yet affordable.  I saw something about the hanging type of scanners that take images from above your book, so nothing is pressed against the book or putting pressure on the spine.  It seems that there is software that can de-warp and produce a pretty good quality resulting image/scan.  I&amp;#39;m wondering if this is the best way to go or if there are better ways.&lt;/p&gt;\n\n&lt;p&gt;Also, I&amp;#39;m wondering how long it would take me to scan an 800 page hardcover book, for example.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1215s2k", "is_robot_indexable": true, "report_reasons": null, "author": "Necessary-Helpful", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1215s2k/2023_most_affordable_yet_efficient_way_to_scan_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1215s2k/2023_most_affordable_yet_efficient_way_to_scan_a/", "subreddit_subscribers": 675028, "created_utc": 1679706944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120xf9i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679689811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "120xf9i", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/120xf9i/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/120xf9i/datahoarder_discussion/", "subreddit_subscribers": 675028, "created_utc": 1679689811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I wanted to ask how y\u2019all transfer your main storage on your pc to a new drive? (500 GB SSD to 2TB SSD in my case) without failures or data loss? \nI have a 14TB external drive in storage, should I move the stuff from 500SSD there? \n\n\nHow do I move system files that aren\u2019t transferable by clicking and dragging? \n\nIdk how backups work technically- I\u2019m not sure if using my 14TB as a backup will wipe what\u2019s already on there.\n\nThanks in advance for any answers!", "author_fullname": "t2_4f7g5wsh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noobie scared of transferring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121bhjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679720956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wanted to ask how y\u2019all transfer your main storage on your pc to a new drive? (500 GB SSD to 2TB SSD in my case) without failures or data loss? \nI have a 14TB external drive in storage, should I move the stuff from 500SSD there? &lt;/p&gt;\n\n&lt;p&gt;How do I move system files that aren\u2019t transferable by clicking and dragging? &lt;/p&gt;\n\n&lt;p&gt;Idk how backups work technically- I\u2019m not sure if using my 14TB as a backup will wipe what\u2019s already on there.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any answers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121bhjq", "is_robot_indexable": true, "report_reasons": null, "author": "juneloner", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121bhjq/noobie_scared_of_transferring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121bhjq/noobie_scared_of_transferring/", "subreddit_subscribers": 675028, "created_utc": 1679720956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok so everyone knows the deal with DPR, and the amount of grieving on the internet is heartbreaking. But we can't just sit and watch, right? \n\nYes there's [an ongoing effort](https://www.reddit.com/r/DataHoarder/comments/11zucov/dpreview_is_being_archived_by_the_archive_team/) to archive the entire site. While that's amazing and necessary, it won't bring DPR back by itself, which is what I think we have to do. And we can coordinate both efforts.\n\nOK, so here's what we can do \u2014 if enough people jump on, we can kickstart a new DPR2.0 and roll over a good part of the DPR value to a new place. \n\nMost valuable things about DPR are:\n\n1. content\n2. community\n3. team\n\n**1.** **Content**\n\nThe DPR is offering everyone to [download their personal data](https://www.dpreview.com/data-download). If you're a user, go ahead and do that. it takes a few seconds to request.\n\nNow, there's not *a ton* of value for you downloading your data to your hard drive. However, if enough users downloaded their data and *we then* *pooled it* *back together*, it would make up for a big valuable chunk of content that we can make available online again. We can literally re-create part of the resource - reviews, forums, etc.  \n\\--\n\n**2. Community**\n\nPerhaps the most valuable part is the user base DPR built over 25 years. If folks still want to hang together, we just need to offer them a new home. Ideally, with part/most/all of their content migrated there. We just need to get in front of as many DPR users as possible and rally them to move! \n\n\\--\n\n**3. Team** Nothing we can really do, but to help them find a new job \ud83d\udc94\n\n\\--\n\n**So, what do we do now?**\n\n1. Get on the list. If you are a DPR user and want to go ahead with this idea, fill out this google form [https://forms.gle/2aGQtnQGw6SJCqVE7](https://forms.gle/2aGQtnQGw6SJCqVE7) to add yourself.\n2. Go and request your data (you have until April 6, 2023)\u00a0[https://www.dpreview.com/data-download](https://www.dpreview.com/data-download)\n\n**What happens next?**\n\n..This is a bit of act now, figure it out later. If this plan works, we will collect the data, and then start the work on making it available again online, and build a new, modern service on top of it.\n\nNB While I can't personally commit to re-building an entire DPR project (it won't be the same anyway), I believe I can make something happen. I've created a number of web things to date (i.e. co-founded republic.com, meetingpulse.net, etc).\u00a0\n\nPlus there's surely going to be enough community members, willing to contribute.\n\nWDYT?", "author_fullname": "t2_8uzv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lets just build a new home for DPReview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120wkz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679688227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok so everyone knows the deal with DPR, and the amount of grieving on the internet is heartbreaking. But we can&amp;#39;t just sit and watch, right? &lt;/p&gt;\n\n&lt;p&gt;Yes there&amp;#39;s &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/11zucov/dpreview_is_being_archived_by_the_archive_team/\"&gt;an ongoing effort&lt;/a&gt; to archive the entire site. While that&amp;#39;s amazing and necessary, it won&amp;#39;t bring DPR back by itself, which is what I think we have to do. And we can coordinate both efforts.&lt;/p&gt;\n\n&lt;p&gt;OK, so here&amp;#39;s what we can do \u2014 if enough people jump on, we can kickstart a new DPR2.0 and roll over a good part of the DPR value to a new place. &lt;/p&gt;\n\n&lt;p&gt;Most valuable things about DPR are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;content&lt;/li&gt;\n&lt;li&gt;community&lt;/li&gt;\n&lt;li&gt;team&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;Content&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The DPR is offering everyone to &lt;a href=\"https://www.dpreview.com/data-download\"&gt;download their personal data&lt;/a&gt;. If you&amp;#39;re a user, go ahead and do that. it takes a few seconds to request.&lt;/p&gt;\n\n&lt;p&gt;Now, there&amp;#39;s not &lt;em&gt;a ton&lt;/em&gt; of value for you downloading your data to your hard drive. However, if enough users downloaded their data and &lt;em&gt;we then&lt;/em&gt; &lt;em&gt;pooled it&lt;/em&gt; &lt;em&gt;back together&lt;/em&gt;, it would make up for a big valuable chunk of content that we can make available online again. We can literally re-create part of the resource - reviews, forums, etc.&lt;br/&gt;\n--&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. Community&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Perhaps the most valuable part is the user base DPR built over 25 years. If folks still want to hang together, we just need to offer them a new home. Ideally, with part/most/all of their content migrated there. We just need to get in front of as many DPR users as possible and rally them to move! &lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3. Team&lt;/strong&gt; Nothing we can really do, but to help them find a new job \ud83d\udc94&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So, what do we do now?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get on the list. If you are a DPR user and want to go ahead with this idea, fill out this google form &lt;a href=\"https://forms.gle/2aGQtnQGw6SJCqVE7\"&gt;https://forms.gle/2aGQtnQGw6SJCqVE7&lt;/a&gt; to add yourself.&lt;/li&gt;\n&lt;li&gt;Go and request your data (you have until April 6, 2023)\u00a0&lt;a href=\"https://www.dpreview.com/data-download\"&gt;https://www.dpreview.com/data-download&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;What happens next?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;..This is a bit of act now, figure it out later. If this plan works, we will collect the data, and then start the work on making it available again online, and build a new, modern service on top of it.&lt;/p&gt;\n\n&lt;p&gt;NB While I can&amp;#39;t personally commit to re-building an entire DPR project (it won&amp;#39;t be the same anyway), I believe I can make something happen. I&amp;#39;ve created a number of web things to date (i.e. co-founded republic.com, meetingpulse.net, etc).\u00a0&lt;/p&gt;\n\n&lt;p&gt;Plus there&amp;#39;s surely going to be enough community members, willing to contribute.&lt;/p&gt;\n\n&lt;p&gt;WDYT?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "120wkz4", "is_robot_indexable": true, "report_reasons": null, "author": "petergreeen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/120wkz4/lets_just_build_a_new_home_for_dpreview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/120wkz4/lets_just_build_a_new_home_for_dpreview/", "subreddit_subscribers": 675028, "created_utc": 1679688227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Soooo, just joined the NAS 96TB club. Dumped about 17 drives and 10 years of photography into it.  \n\nNow to sort. I've gone through all the threads about duplicates, but no one has talked about keeping all the variations of an image, just the highest quality of each.\n\nNote: the programs that I've tried just say it's the \"newer\" version and want to write over it, re: Beyond Compare. \n\nIf you're familiar with photography, it's the same image, just various edits exported through lightroom.\n\nIs there a program capable of this?", "author_fullname": "t2_4vd01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deleting duplicates without deleting imperceptibly minor edits?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12179bt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679710379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Soooo, just joined the NAS 96TB club. Dumped about 17 drives and 10 years of photography into it.  &lt;/p&gt;\n\n&lt;p&gt;Now to sort. I&amp;#39;ve gone through all the threads about duplicates, but no one has talked about keeping all the variations of an image, just the highest quality of each.&lt;/p&gt;\n\n&lt;p&gt;Note: the programs that I&amp;#39;ve tried just say it&amp;#39;s the &amp;quot;newer&amp;quot; version and want to write over it, re: Beyond Compare. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re familiar with photography, it&amp;#39;s the same image, just various edits exported through lightroom.&lt;/p&gt;\n\n&lt;p&gt;Is there a program capable of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12179bt", "is_robot_indexable": true, "report_reasons": null, "author": "UABSamurai", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12179bt/deleting_duplicates_without_deleting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12179bt/deleting_duplicates_without_deleting/", "subreddit_subscribers": 675028, "created_utc": 1679710379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am hoping to download specifically my saved videos on tiktok. This is a different category from liked videos, and all the software/extensions/online tools I can find only offer the option to download my likes or to download videos individually.\n\nDoes anyone know of a tool I can use for this purpose?", "author_fullname": "t2_14xhzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking to download TikTok bookmarked videos (not liked)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120mhwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679669112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am hoping to download specifically my saved videos on tiktok. This is a different category from liked videos, and all the software/extensions/online tools I can find only offer the option to download my likes or to download videos individually.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of a tool I can use for this purpose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "120mhwj", "is_robot_indexable": true, "report_reasons": null, "author": "gameoldtime", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/120mhwj/looking_to_download_tiktok_bookmarked_videos_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/120mhwj/looking_to_download_tiktok_bookmarked_videos_not/", "subreddit_subscribers": 675028, "created_utc": 1679669112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi guys, i'm torn between getting a desktop hd or an ssd or a NAS.\n\nany recommendations for data storage that goes up to 10+ years for time machine backups + photos and videos? \n\ni'm a videographer looking to have a permanent backup drive for all my files. i have some external hdds + ssds but those are starting to get full. don't wanna keep purchasing them if i need more storage lol. thank you!", "author_fullname": "t2_bsg2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused on what's best to get for permanent data backup :(", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121fs8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679733917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi guys, i&amp;#39;m torn between getting a desktop hd or an ssd or a NAS.&lt;/p&gt;\n\n&lt;p&gt;any recommendations for data storage that goes up to 10+ years for time machine backups + photos and videos? &lt;/p&gt;\n\n&lt;p&gt;i&amp;#39;m a videographer looking to have a permanent backup drive for all my files. i have some external hdds + ssds but those are starting to get full. don&amp;#39;t wanna keep purchasing them if i need more storage lol. thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121fs8l", "is_robot_indexable": true, "report_reasons": null, "author": "tujuh777", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121fs8l/confused_on_whats_best_to_get_for_permanent_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121fs8l/confused_on_whats_best_to_get_for_permanent_data/", "subreddit_subscribers": 675028, "created_utc": 1679733917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been trying to figure this out for a couple of days now, and I wanted to see if anyone on here has any advice. I have a collection of games on itch.io that I want to archive the devlogs for. The problem is that I only want a section of a page to be downloaded, so no comments section below the post, or other parts of the website. Now obviously I can do this by hand, problem is I'm talking about around 1000 games, each with who knows how many devlogs, so anything I can do to speed up the process would be really helpful. I've been able to find the section I want to download with the inspect tool, but that's as far as my limited knowledge can get me. If anyone knows any tools or scripts that could help me, it would be much appreciated. Thank you so much.\n\nHere is an example of a devlog page so you can see what I mean - https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now", "author_fullname": "t2_ciglcn3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically downloading only specific sections of website as a pdf?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121fr76", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679733823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to figure this out for a couple of days now, and I wanted to see if anyone on here has any advice. I have a collection of games on itch.io that I want to archive the devlogs for. The problem is that I only want a section of a page to be downloaded, so no comments section below the post, or other parts of the website. Now obviously I can do this by hand, problem is I&amp;#39;m talking about around 1000 games, each with who knows how many devlogs, so anything I can do to speed up the process would be really helpful. I&amp;#39;ve been able to find the section I want to download with the inspect tool, but that&amp;#39;s as far as my limited knowledge can get me. If anyone knows any tools or scripts that could help me, it would be much appreciated. Thank you so much.&lt;/p&gt;\n\n&lt;p&gt;Here is an example of a devlog page so you can see what I mean - &lt;a href=\"https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now\"&gt;https://huntern.itch.io/the-portraits/devlog/497582/the-portraits-available-now&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?auto=webp&amp;v=enabled&amp;s=79877c8a54f6df80ac24693492241a4605cea412", "width": 822, "height": 618}, "resolutions": [{"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7a9729310b232847fedd6134f72722335ef8ad8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33f00c72cf83df5764e8588cb397203ecabdfe71", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d10eae4aa5f724b510d8eabff5ec39866e7f24fd", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/klDIQygnb6tOqQa_HB6Bq67nTzOwysfPouMF1bclWNw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51045ff1f318feaeb7bb2618d9c7e90cc61fb713", "width": 640, "height": 481}], "variants": {}, "id": "S2yIyabmqY8JphdEv5Him23A3z_iYFiPUT5XuSsvrpM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121fr76", "is_robot_indexable": true, "report_reasons": null, "author": "ImRikun", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121fr76/automatically_downloading_only_specific_sections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121fr76/automatically_downloading_only_specific_sections/", "subreddit_subscribers": 675028, "created_utc": 1679733823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Using Debian and I have 2, LSI 9207-8i's. About a week ago, my Seasonic power supply had a catastrophic failure. It was powering a Rosewill RSV-L4412U chassis. Luckily, nothing was damaged except for the 3 drive cages. The drives inside (mdadm RAID 5 array) were AOK as was everything else. I think.\n\nI replaced the drives cages and am back up and running but during the boot process, I see this displayed on the screen for about 5 or so seconds then the system continues the boot process and everything works as expected:\n\nmpt2sas\\_cm1: overriding NVDATA EEDPTagMode setting\n\nI don't know if it's always had this delay during boot since it's my backup server and I never really watch the output on the monitor during startup. After I put everything back together, I was sitting in front of it watching the boot process and noticed it 'hanging' there for a bit. I have a 9207-8i in another system and don't see this delay during the boot. Any ideas or you think that's normal for it to hang there for a few seconds at boot on that line?", "author_fullname": "t2_amep8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my LSI card OK after my power supply died?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1216vc1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679709477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using Debian and I have 2, LSI 9207-8i&amp;#39;s. About a week ago, my Seasonic power supply had a catastrophic failure. It was powering a Rosewill RSV-L4412U chassis. Luckily, nothing was damaged except for the 3 drive cages. The drives inside (mdadm RAID 5 array) were AOK as was everything else. I think.&lt;/p&gt;\n\n&lt;p&gt;I replaced the drives cages and am back up and running but during the boot process, I see this displayed on the screen for about 5 or so seconds then the system continues the boot process and everything works as expected:&lt;/p&gt;\n\n&lt;p&gt;mpt2sas_cm1: overriding NVDATA EEDPTagMode setting&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s always had this delay during boot since it&amp;#39;s my backup server and I never really watch the output on the monitor during startup. After I put everything back together, I was sitting in front of it watching the boot process and noticed it &amp;#39;hanging&amp;#39; there for a bit. I have a 9207-8i in another system and don&amp;#39;t see this delay during the boot. Any ideas or you think that&amp;#39;s normal for it to hang there for a few seconds at boot on that line?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1216vc1", "is_robot_indexable": true, "report_reasons": null, "author": "road_hazard", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1216vc1/is_my_lsi_card_ok_after_my_power_supply_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1216vc1/is_my_lsi_card_ok_after_my_power_supply_died/", "subreddit_subscribers": 675028, "created_utc": 1679709477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll build a NAS, don't know yet if it will be an unRAID or TrueNAS and move out of the cloud with my data. I have mainly two big worries at the moment, first, which application can I use to have a Google Photos like experience?, second, how to protect the photos from being deleted by accident by my family members?\n\nI'll have proper backups in place, probably two Bluray copies stored on different locations, but this is still not enough. What if my son deletes by mistake an old photo? I'll probably not see that or even if I know it was deleted, it will be really hard to recover it from Blurays.", "author_fullname": "t2_26q3bbaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating 2TB of photos out of Google Photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1212vtr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679700645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll build a NAS, don&amp;#39;t know yet if it will be an unRAID or TrueNAS and move out of the cloud with my data. I have mainly two big worries at the moment, first, which application can I use to have a Google Photos like experience?, second, how to protect the photos from being deleted by accident by my family members?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have proper backups in place, probably two Bluray copies stored on different locations, but this is still not enough. What if my son deletes by mistake an old photo? I&amp;#39;ll probably not see that or even if I know it was deleted, it will be really hard to recover it from Blurays.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1212vtr", "is_robot_indexable": true, "report_reasons": null, "author": "fenugurod", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1212vtr/migrating_2tb_of_photos_out_of_google_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1212vtr/migrating_2tb_of_photos_out_of_google_photos/", "subreddit_subscribers": 675028, "created_utc": 1679700645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Back in 2021 I purchased a SAMSUNG 870 QVO SATA III 2.5\" SSD 8TB to use in my OWC ThunderBay External Storage Enclosure.  It's worked out pretty well.  \n\nLast week I was looking for another but wanted a larger size and 8TB seems to be it.  Has SSD technology slowed down?  \n\nWould have figured by now they'd have 10-12TB now.", "author_fullname": "t2_al7qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything larger than an 8TB 2.5\" SSD Drive these days?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1211oc7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679698134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Back in 2021 I purchased a SAMSUNG 870 QVO SATA III 2.5&amp;quot; SSD 8TB to use in my OWC ThunderBay External Storage Enclosure.  It&amp;#39;s worked out pretty well.  &lt;/p&gt;\n\n&lt;p&gt;Last week I was looking for another but wanted a larger size and 8TB seems to be it.  Has SSD technology slowed down?  &lt;/p&gt;\n\n&lt;p&gt;Would have figured by now they&amp;#39;d have 10-12TB now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1211oc7", "is_robot_indexable": true, "report_reasons": null, "author": "jb4647", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1211oc7/anything_larger_than_an_8tb_25_ssd_drive_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1211oc7/anything_larger_than_an_8tb_25_ssd_drive_these/", "subreddit_subscribers": 675028, "created_utc": 1679698134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Oftentimes i will come across forum threads with valuable information buried 100+ pages deep. Is there a script or program that will remove the pagination and allow for 1 long continuous page? Or maybe turn the thread into a  multi page pdf/word document?", "author_fullname": "t2_r8wf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Depaginate a forum thread?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120qyl6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679677903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Oftentimes i will come across forum threads with valuable information buried 100+ pages deep. Is there a script or program that will remove the pagination and allow for 1 long continuous page? Or maybe turn the thread into a  multi page pdf/word document?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "120qyl6", "is_robot_indexable": true, "report_reasons": null, "author": "Koshox", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/120qyl6/depaginate_a_forum_thread/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/120qyl6/depaginate_a_forum_thread/", "subreddit_subscribers": 675028, "created_utc": 1679677903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_a7kq8bkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive Ruling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": true, "name": "t3_121mmot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gLmexXD_sumhGyylboFQCuN1I9I2WfuScPvWUCmmxGg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679752667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "apnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://apnews.com/article/0674119646bd920492f87490e8d2027b", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?auto=webp&amp;v=enabled&amp;s=269713ea00bd4cef48ce4ecef7f7ecb05ffc1c22", "width": 700, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=020b844ba9242930016a8b75af9198e33a67d8a5", "width": 108, "height": 69}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=115e7ee575c2ee0ccf7972be5f495f8f9e42ac0f", "width": 216, "height": 138}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed2f002bf68f11af1260a7ffa902fdd06c835646", "width": 320, "height": 205}, {"url": "https://external-preview.redd.it/p3LeiM48jenBIuVsqq8MGxPQUkzAzuWF89nU4oBLPyE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85d3fca289ea340eaec0a7e8f6217b2689d598df", "width": 640, "height": 411}], "variants": {}, "id": "R2LP5YXZK5pskfP-9eZMdFi42my_VF_Bgzy0IdiKrJQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121mmot", "is_robot_indexable": true, "report_reasons": null, "author": "TomBel71", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121mmot/archive_ruling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://apnews.com/article/0674119646bd920492f87490e8d2027b", "subreddit_subscribers": 675028, "created_utc": 1679752667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey y'all, \n\nI've been searching and searching but I can't seem to find something written in layman's terms talking about the differences and advantages of the Wayback Machine and/or [archive.today](https://archive.today).\n\nI'm a researcher, so really I'd just like to make sure that I'm using the best database to archive websites for future use by other researchers. As a music researcher, I'm usually just recording things like news articles and occasionally old blogs. I'm not super worried about re-downloading webpages or if the language is CSS or HTML, I'd mostly just like to make sure that text and images on websites are archived.\n\nSo far, I've been using the Wayback Machine, but should I make the switch?\n\nthanks!", "author_fullname": "t2_6k6lkegt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wayback Machine vs. Archive.today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_121m0z4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679751273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching and searching but I can&amp;#39;t seem to find something written in layman&amp;#39;s terms talking about the differences and advantages of the Wayback Machine and/or &lt;a href=\"https://archive.today\"&gt;archive.today&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a researcher, so really I&amp;#39;d just like to make sure that I&amp;#39;m using the best database to archive websites for future use by other researchers. As a music researcher, I&amp;#39;m usually just recording things like news articles and occasionally old blogs. I&amp;#39;m not super worried about re-downloading webpages or if the language is CSS or HTML, I&amp;#39;d mostly just like to make sure that text and images on websites are archived.&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve been using the Wayback Machine, but should I make the switch?&lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cMsDEjZcw1yJ2-Oox97YXjr_B80QoYA7KKKBUw8desk.jpg?auto=webp&amp;v=enabled&amp;s=70049ac5e4587eb732d86f2bf3c7f941a6314e91", "width": 144, "height": 144}, "resolutions": [{"url": "https://external-preview.redd.it/cMsDEjZcw1yJ2-Oox97YXjr_B80QoYA7KKKBUw8desk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81d09b8bf08f6c2e49210b8e709ad2fba21fef5", "width": 108, "height": 108}], "variants": {}, "id": "5WAXcyxu5qzeFIANl2gYNgI5-HT3q1BW7sA5zqtskZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121m0z4", "is_robot_indexable": true, "report_reasons": null, "author": "nicguynicecar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121m0z4/wayback_machine_vs_archivetoday/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121m0z4/wayback_machine_vs_archivetoday/", "subreddit_subscribers": 675028, "created_utc": 1679751273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For a single drive, is there any point in writing multiple duplicated versions of the same files to the drive?\n\nMy heuristics tells me that in the case of bit rot or bad sectors surely not all sectors are going to be affected. If you have multiple versions of, say a Word document, you will have a higher chance of finding a version that is not corrupted, right?", "author_fullname": "t2_whddz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filling a drive with duplicates to protect against bit rot and drive failure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121glkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679736610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a single drive, is there any point in writing multiple duplicated versions of the same files to the drive?&lt;/p&gt;\n\n&lt;p&gt;My heuristics tells me that in the case of bit rot or bad sectors surely not all sectors are going to be affected. If you have multiple versions of, say a Word document, you will have a higher chance of finding a version that is not corrupted, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121glkm", "is_robot_indexable": true, "report_reasons": null, "author": "--Arete", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121glkm/filling_a_drive_with_duplicates_to_protect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121glkm/filling_a_drive_with_duplicates_to_protect/", "subreddit_subscribers": 675028, "created_utc": 1679736610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I hate this platform so many issues all the time, so rather want to download the content i bought so i can view it from pc.", "author_fullname": "t2_13m7y1td", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to download crowdcast webinars?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_121ackm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679717975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hate this platform so many issues all the time, so rather want to download the content i bought so i can view it from pc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "121ackm", "is_robot_indexable": true, "report_reasons": null, "author": "BuddhaInAstripclub", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/121ackm/easiest_way_to_download_crowdcast_webinars/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/121ackm/easiest_way_to_download_crowdcast_webinars/", "subreddit_subscribers": 675028, "created_utc": 1679717975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I really like how ZFS and BTRFS allow you to make snapshots of your system and roll back to them. However, drive failures are a thing and even with RAID, there are ways for corruption to replicate between drives.  \n\n\nAs a backup-backup, what I would like would be to first make a clone of the drive I want to back up, and then incrementally save only changes into a seperate file(s), also on the backup drive. This way, even if my main drives exploded and my last backup contained whatever it was that made my drives explode, I could still take my backup and then roll it back without having to have multiple entire clones of my drive.\n\n&amp;#x200B;\n\nIs this a thing?", "author_fullname": "t2_r25yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External backup + CoW snapshotting: Is there such a tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1219oo1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679716310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really like how ZFS and BTRFS allow you to make snapshots of your system and roll back to them. However, drive failures are a thing and even with RAID, there are ways for corruption to replicate between drives.  &lt;/p&gt;\n\n&lt;p&gt;As a backup-backup, what I would like would be to first make a clone of the drive I want to back up, and then incrementally save only changes into a seperate file(s), also on the backup drive. This way, even if my main drives exploded and my last backup contained whatever it was that made my drives explode, I could still take my backup and then roll it back without having to have multiple entire clones of my drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is this a thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1219oo1", "is_robot_indexable": true, "report_reasons": null, "author": "nKephalos", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1219oo1/external_backup_cow_snapshotting_is_there_such_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1219oo1/external_backup_cow_snapshotting_is_there_such_a/", "subreddit_subscribers": 675028, "created_utc": 1679716310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Evening all, originally posted to r/HyperV but they recommended asking you guys :)\n\nI have a DL380p Gen8 running server 2022 on the bare metal and have been tooling around with DDA in Hyper-V. So far so good, having passed a GPU to my Plex VM for hardware transcoding.\n\nI\u2019ve now added a LSI9211-8i based HBA (just had three of these laying around) to connect to a second 8 bay enclosure with the intention of using DDA to pass it to a VM running TrueNAS Core in order to give ZFS direct access to the attached drives, but I\u2019m stuck at the following issue.\n\n***BIOS requires that this device remain attached to BIOS-owned memory. Not assignable.***\n\nHow on earth do I get around this? The HBA is firmware flashed into IT mode, and I even forwent flashing the bios stuff back to the card. only the IT mode firmware. So nothing now shows up on server boot, just skips right past it.\n\nIs there something I can do in the server bios to have it just ignore the card but not outright disable it or is this built into the card\u2019s firmware and I\u2019m S-O-L ?\n\nBeen googling this for a couple of hours and I have found lots of people that have passed HBA\u2019s through to VM\u2019s but no information on what specific hardware. And nothing on how to address my issue, if it is even possible.\n\nHappy to go and purchase another HBA if this one is not useable for this config, but don\u2019t have a lot of leads on which cards would work.\n\nIs it also possible this is a Legacy Bios limitation? These servers didn\u2019t go UEFI until gen 9 I believe, so UEFI is not an option on a gen 8. Although my server is as up to date as it can be with all the latest available firmware\u2019s and BIOS.\n\nAppreciate any suggestions and insights you might have. Or even recommendations on a HBA that has the right modes for ZFS and supports PCIe passthrough with DDA.", "author_fullname": "t2_y90mo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hyper-V DDA, HBA\u2019s and BIOS attachment issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12175jy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679710590.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679710136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Evening all, originally posted to &lt;a href=\"/r/HyperV\"&gt;r/HyperV&lt;/a&gt; but they recommended asking you guys :)&lt;/p&gt;\n\n&lt;p&gt;I have a DL380p Gen8 running server 2022 on the bare metal and have been tooling around with DDA in Hyper-V. So far so good, having passed a GPU to my Plex VM for hardware transcoding.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve now added a LSI9211-8i based HBA (just had three of these laying around) to connect to a second 8 bay enclosure with the intention of using DDA to pass it to a VM running TrueNAS Core in order to give ZFS direct access to the attached drives, but I\u2019m stuck at the following issue.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;BIOS requires that this device remain attached to BIOS-owned memory. Not assignable.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How on earth do I get around this? The HBA is firmware flashed into IT mode, and I even forwent flashing the bios stuff back to the card. only the IT mode firmware. So nothing now shows up on server boot, just skips right past it.&lt;/p&gt;\n\n&lt;p&gt;Is there something I can do in the server bios to have it just ignore the card but not outright disable it or is this built into the card\u2019s firmware and I\u2019m S-O-L ?&lt;/p&gt;\n\n&lt;p&gt;Been googling this for a couple of hours and I have found lots of people that have passed HBA\u2019s through to VM\u2019s but no information on what specific hardware. And nothing on how to address my issue, if it is even possible.&lt;/p&gt;\n\n&lt;p&gt;Happy to go and purchase another HBA if this one is not useable for this config, but don\u2019t have a lot of leads on which cards would work.&lt;/p&gt;\n\n&lt;p&gt;Is it also possible this is a Legacy Bios limitation? These servers didn\u2019t go UEFI until gen 9 I believe, so UEFI is not an option on a gen 8. Although my server is as up to date as it can be with all the latest available firmware\u2019s and BIOS.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any suggestions and insights you might have. Or even recommendations on a HBA that has the right modes for ZFS and supports PCIe passthrough with DDA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12175jy", "is_robot_indexable": true, "report_reasons": null, "author": "x1234km", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12175jy/hyperv_dda_hbas_and_bios_attachment_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12175jy/hyperv_dda_hbas_and_bios_attachment_issues/", "subreddit_subscribers": 675028, "created_utc": 1679710136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seen this question asked here before but the answers were pc. I wanted to know if there is a way to download videos on Android.", "author_fullname": "t2_ldt1tknd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do download videos from doodstream on Android?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12139w5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679701489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seen this question asked here before but the answers were pc. I wanted to know if there is a way to download videos on Android.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "12139w5", "is_robot_indexable": true, "report_reasons": null, "author": "Alone-Eye-3988", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/12139w5/how_do_download_videos_from_doodstream_on_android/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/12139w5/how_do_download_videos_from_doodstream_on_android/", "subreddit_subscribers": 675028, "created_utc": 1679701489.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}