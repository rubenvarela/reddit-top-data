{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My boss has a DBA background and we don't have a single unit test or integration test, pipelines are slow because the code isn't optimised, no sprint planning sessions, no formal code review process, no runbooks and yet he pushes back every time I try to work on tickets that would fix these issues. Instead he wants to add features, features, features. \n\nI understand that data engineering is somewhat different from traditional software engineering and a lot of people have a SQL-heavy background, but is this common?", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does your team adhere to software engineering best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120qt0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679680904.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679677683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My boss has a DBA background and we don&amp;#39;t have a single unit test or integration test, pipelines are slow because the code isn&amp;#39;t optimised, no sprint planning sessions, no formal code review process, no runbooks and yet he pushes back every time I try to work on tickets that would fix these issues. Instead he wants to add features, features, features. &lt;/p&gt;\n\n&lt;p&gt;I understand that data engineering is somewhat different from traditional software engineering and a lot of people have a SQL-heavy background, but is this common?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "120qt0v", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120qt0v/does_your_team_adhere_to_software_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120qt0v/does_your_team_adhere_to_software_engineering/", "subreddit_subscribers": 94295, "created_utc": 1679677683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently ~1 year into my career as a DE in the UK.\n\nTech stack at current role is Hadoop, Scala/Spark, Python and Bash for scripting, some CICD tooling. It's on prem so no cloud exposure.\n\nI've been offered a new role, 28% payrise (48% if including on target bonus). Tech stack will be Python, AWS, Terraform and Kafka.\n\nI love my current role and company, and I'm only just feeling like I've settled in. I'm in 2 minds whether to see if my current company will counter offer because if money is taken out of the equation, is the new tech stack a no brainer move for my career development?", "author_fullname": "t2_ymaam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take this role to develop my skills as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120e3zq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679647145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently ~1 year into my career as a DE in the UK.&lt;/p&gt;\n\n&lt;p&gt;Tech stack at current role is Hadoop, Scala/Spark, Python and Bash for scripting, some CICD tooling. It&amp;#39;s on prem so no cloud exposure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been offered a new role, 28% payrise (48% if including on target bonus). Tech stack will be Python, AWS, Terraform and Kafka.&lt;/p&gt;\n\n&lt;p&gt;I love my current role and company, and I&amp;#39;m only just feeling like I&amp;#39;ve settled in. I&amp;#39;m in 2 minds whether to see if my current company will counter offer because if money is taken out of the equation, is the new tech stack a no brainer move for my career development?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "120e3zq", "is_robot_indexable": true, "report_reasons": null, "author": "elotrovert", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120e3zq/should_i_take_this_role_to_develop_my_skills_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120e3zq/should_i_take_this_role_to_develop_my_skills_as_a/", "subreddit_subscribers": 94295, "created_utc": 1679647145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been a data engineer for over a year now and came from a data analyst -&gt; BI Developer -&gt; Data engineering path.  The weakest part of knowledge in this job is the networking aspect.  I don't mean connecting to snowflake via python connector, more like setting up a VPN tunnel between our virtual network and an external oracle server...or if I deploy an application via Azure web apps, how do I control who can access?   \n\nI see all these options like private endpoints, hybrid connections, gateways, network interfaces, virtual networks etc...  \n\nIn your opinion, how much should a DE know about networking? Super important or passing knowledge sufficient?  \n\nSecondly, any suggestions to brush up on this subject for a noob? (azure preferred but I'll take anything)", "author_fullname": "t2_szv0ygic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Networking tips and resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120kpsq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679665374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been a data engineer for over a year now and came from a data analyst -&amp;gt; BI Developer -&amp;gt; Data engineering path.  The weakest part of knowledge in this job is the networking aspect.  I don&amp;#39;t mean connecting to snowflake via python connector, more like setting up a VPN tunnel between our virtual network and an external oracle server...or if I deploy an application via Azure web apps, how do I control who can access?   &lt;/p&gt;\n\n&lt;p&gt;I see all these options like private endpoints, hybrid connections, gateways, network interfaces, virtual networks etc...  &lt;/p&gt;\n\n&lt;p&gt;In your opinion, how much should a DE know about networking? Super important or passing knowledge sufficient?  &lt;/p&gt;\n\n&lt;p&gt;Secondly, any suggestions to brush up on this subject for a noob? (azure preferred but I&amp;#39;ll take anything)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "120kpsq", "is_robot_indexable": true, "report_reasons": null, "author": "Hippodick666420", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120kpsq/networking_tips_and_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120kpsq/networking_tips_and_resources/", "subreddit_subscribers": 94295, "created_utc": 1679665374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started using Memgraph Lab more that year ago and since then I'm following their progress. Few days ago I installed Docker image that has [new version of Lab](https://medium.com/memgraph/memgraph-lab-2-5-0-is-out-232228bb6187). With a bunch of custom queries that I have a new filter option will be a life saver.   \n\n\nAre there any other Memgraph Lab users here?   \n\n\nDISCALIMER: I'm an open source contributor to many projects, Memgraph projects are one of them.", "author_fullname": "t2_tyl6qdc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Memgraph Lab 2.5 has just been released", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120kgyu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679664859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started using Memgraph Lab more that year ago and since then I&amp;#39;m following their progress. Few days ago I installed Docker image that has &lt;a href=\"https://medium.com/memgraph/memgraph-lab-2-5-0-is-out-232228bb6187\"&gt;new version of Lab&lt;/a&gt;. With a bunch of custom queries that I have a new filter option will be a life saver.   &lt;/p&gt;\n\n&lt;p&gt;Are there any other Memgraph Lab users here?   &lt;/p&gt;\n\n&lt;p&gt;DISCALIMER: I&amp;#39;m an open source contributor to many projects, Memgraph projects are one of them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?auto=webp&amp;v=enabled&amp;s=393cc7dd8c472010f34eb75963af14404612e709", "width": 1200, "height": 650}, "resolutions": [{"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b708e1ab273c6a5117dc61f1e5bb6065050006ae", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff060cceda2e0661000d1e20c0f43274e1dd2b7f", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2faf41648d88054f08dc69f6fdbf779dd7a05be7", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f44d5b7a812088280242cf5ca18091e38e635bf2", "width": 640, "height": 346}, {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a2d5421dc435d7df6a0f01c41ddd1e9478b3c6c", "width": 960, "height": 520}, {"url": "https://external-preview.redd.it/9Ut9jD67lQR3gWVofzZ1MGZbmxtC1rhNvXMzyAm6hf0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f7b55a8d955801d07b7a7b3556a6d96928568b6", "width": 1080, "height": 585}], "variants": {}, "id": "0N3Wh6dNCxCR76_FMTiU_hS_yBYsWdQX2N-quleiiUw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "120kgyu", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Plan591", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120kgyu/memgraph_lab_25_has_just_been_released/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120kgyu/memgraph_lab_25_has_just_been_released/", "subreddit_subscribers": 94295, "created_utc": 1679664859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am starting my data engineer career on a small company. We run our DAGs on Airflow, and we have it run on Google Composer (we use gcp). Our workflow usually involves running new DAGs, then uploading it manually to the Google Storage bucket were the dags folder is. We have a bitbucket repo where we keep locally the DAG files updated.\n\nI was wondering if it is possible to automatically sync the dags folder with the master branch on our repo so that our workflow is facilitated and we don't have to manually upload the new files everytime a thing is changed. I assume this is a trivial question, but I wasn't able to find this issue online and I have almost no experience.\n\nSorry if this is the wrong place to post these kind of questions.\n\nThanks in advance", "author_fullname": "t2_itjojy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with synchronizing Airflow DAGs via git", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120mv0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679669894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am starting my data engineer career on a small company. We run our DAGs on Airflow, and we have it run on Google Composer (we use gcp). Our workflow usually involves running new DAGs, then uploading it manually to the Google Storage bucket were the dags folder is. We have a bitbucket repo where we keep locally the DAG files updated.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if it is possible to automatically sync the dags folder with the master branch on our repo so that our workflow is facilitated and we don&amp;#39;t have to manually upload the new files everytime a thing is changed. I assume this is a trivial question, but I wasn&amp;#39;t able to find this issue online and I have almost no experience.&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong place to post these kind of questions.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "120mv0o", "is_robot_indexable": true, "report_reasons": null, "author": "lucasfanti", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120mv0o/help_with_synchronizing_airflow_dags_via_git/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120mv0o/help_with_synchronizing_airflow_dags_via_git/", "subreddit_subscribers": 94295, "created_utc": 1679669894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\na few days ago in a thread here there it was mentioned how much of a pain in the ass is to develop and test AWS Glue jobs locally.\n\nSo I created a devcontainer template repository that provides an out of the box experience to do exactly that.\n\nYou can find it here: [https://github.com/wtfzambo/glue-devcontainer-template](https://github.com/wtfzambo/glue-devcontainer-template)\n\nAlso, any feedback is much appreciated!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue jobs devcontainer - template repo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120uauq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679684525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;a few days ago in a thread here there it was mentioned how much of a pain in the ass is to develop and test AWS Glue jobs locally.&lt;/p&gt;\n\n&lt;p&gt;So I created a devcontainer template repository that provides an out of the box experience to do exactly that.&lt;/p&gt;\n\n&lt;p&gt;You can find it here: &lt;a href=\"https://github.com/wtfzambo/glue-devcontainer-template\"&gt;https://github.com/wtfzambo/glue-devcontainer-template&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also, any feedback is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?auto=webp&amp;v=enabled&amp;s=1104a9db884083f7266403774fd648b4ba6d91af", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0fb924c12f5cf67f20262b28568d22a33e08e81", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8eda3c803027589a0d7a00bad4c185a2472da99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb77e5ba790615477f99f15dd919549a8dc1a4b1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3eddd898233eaeaddc10ee43c5ad4aee681c3c28", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f9ae8edd2e0e03b4529c57201474d899cf8950e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1ZW_E_r-KhaMoTpgldvEDZW-FGKuA5tX48h900Nk8lY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c93808062a792650e64743c5dd7409610940f53", "width": 1080, "height": 540}], "variants": {}, "id": "SVV1KjNMma4pVoM38J-XV6jRSgfarECxm8kl1WaZIok"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "120uauq", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120uauq/aws_glue_jobs_devcontainer_template_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120uauq/aws_glue_jobs_devcontainer_template_repo/", "subreddit_subscribers": 94295, "created_utc": 1679684525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_mnzkoz4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying Airbyte on Kubernetes Using Plural", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_120l9e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0MBjht0_3mi0H0qORTHWCWuOCXgIvDE6de_lE5ZWGdo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679666514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "plural.sh", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.plural.sh/blog/deploying-airbyte-on-kubernetes-using-plural/?utm_medium=social&amp;utm_source=Reddit&amp;utm_campaign=Airbyte", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?auto=webp&amp;v=enabled&amp;s=e565ca37ad6166c0cf43b152ca89cd305e312349", "width": 1100, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfb9d87533630d8b68ae65031110633527c864ae", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d4bc0ef6676390be63ba91a665488f7426fade8", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4bda0232ece6e1102ae7da307d09b6743705b03", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0fc5baeb34ff24f1fba73a7e65d3e584425a8b19", "width": 640, "height": 349}, {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97f28c5fdb5156f5c29168651e168bb8b056d28e", "width": 960, "height": 523}, {"url": "https://external-preview.redd.it/uwyFqr0Y2NEWQsz38lu9CsGlLw2XoagvWO-hLF7uB1w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f3aac436f25a06f4a322b477bdae75577498bca", "width": 1080, "height": 589}], "variants": {}, "id": "ilvHNv9oe6fz_ZyrkBa7L1KDyiDqAhSPQPEZFpQr4pM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "120l9e3", "is_robot_indexable": true, "report_reasons": null, "author": "techdatanerd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120l9e3/deploying_airbyte_on_kubernetes_using_plural/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.plural.sh/blog/deploying-airbyte-on-kubernetes-using-plural/?utm_medium=social&amp;utm_source=Reddit&amp;utm_campaign=Airbyte", "subreddit_subscribers": 94295, "created_utc": 1679666514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm making a ELT Pipeline. First grabbing source data putting it i. S3 then transforming the data to be used in production systems and putting it in another s3 bucket.\n\nI'll have 2 lambdas to do this, one to grab the data and put it on s3 and another to do the transformation.\n\nMy question is, should I use an orchestrator like step functions to do this, or can I just put event bridge triggers to look for new files placed on the s3 bucket for the second lambda and a scheduled rate for the first lambda? \n\nBoth seem fine to me. Anyone have opinions about this?", "author_fullname": "t2_88w2s61v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS ELT Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120xk1d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679690012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m making a ELT Pipeline. First grabbing source data putting it i. S3 then transforming the data to be used in production systems and putting it in another s3 bucket.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have 2 lambdas to do this, one to grab the data and put it on s3 and another to do the transformation.&lt;/p&gt;\n\n&lt;p&gt;My question is, should I use an orchestrator like step functions to do this, or can I just put event bridge triggers to look for new files placed on the s3 bucket for the second lambda and a scheduled rate for the first lambda? &lt;/p&gt;\n\n&lt;p&gt;Both seem fine to me. Anyone have opinions about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "120xk1d", "is_robot_indexable": true, "report_reasons": null, "author": "TheLoneKid", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120xk1d/aws_elt_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120xk1d/aws_elt_pipeline/", "subreddit_subscribers": 94295, "created_utc": 1679690012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w70zh2x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Five Lines of Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_120k0or", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/APdaacGmDew?list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Five Lines of Codes \u2022 Christian Clausen \u2022 GOTO 2022", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/APdaacGmDew?list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/APdaacGmDew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/APdaacGmDew?list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/120k0or", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/yJX9rRU1FO8weD6CN77R-xu8BcnF0fSGEsyg0WZyIUk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679663868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=APdaacGmDew&amp;list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Io8aH1oKbbvzPgYtprTzQO0BnrDfJDM110btwZj9kgY.jpg?auto=webp&amp;v=enabled&amp;s=cad6f301d46202fb5c402f4a37e32fa4d0e354ca", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Io8aH1oKbbvzPgYtprTzQO0BnrDfJDM110btwZj9kgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64c00b0fb1e61550886ae66b2ff78eed1e215318", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Io8aH1oKbbvzPgYtprTzQO0BnrDfJDM110btwZj9kgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3390d0f2d1f136768bd14eedc6cd7abed15ff364", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Io8aH1oKbbvzPgYtprTzQO0BnrDfJDM110btwZj9kgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81839617faf6277693856c7a5bfa47c8a2e3d8b3", "width": 320, "height": 240}], "variants": {}, "id": "YCAIah5NOjVQ4vhQYZCu2GNKHv35VR-WP3_5eIDmgus"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "120k0or", "is_robot_indexable": true, "report_reasons": null, "author": "Juggernaut20023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120k0or/five_lines_of_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=APdaacGmDew&amp;list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt", "subreddit_subscribers": 94295, "created_utc": 1679663868.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Five Lines of Codes \u2022 Christian Clausen \u2022 GOTO 2022", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/APdaacGmDew?list=PLEx5khR4g7PIEgcDlsEP5veliuyKgnpbt\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;", "author_name": "GOTO Conferences", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/APdaacGmDew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@GOTO-"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I have been looking into IT as a career recently, and settled on working towards working in Cloud Engineering. I was told to start working on getting a CompTIA A+ certification, but I am unsure if that is the first step, where to take the exam or training, or what the next steps would be. \n\nI want to get there through certifications if possible as I am not in a position to go to college.", "author_fullname": "t2_5t16cove", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps and certifications should I get if I want to get into Cloud Engineering as a career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120xqne", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679690300.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I have been looking into IT as a career recently, and settled on working towards working in Cloud Engineering. I was told to start working on getting a CompTIA A+ certification, but I am unsure if that is the first step, where to take the exam or training, or what the next steps would be. &lt;/p&gt;\n\n&lt;p&gt;I want to get there through certifications if possible as I am not in a position to go to college.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "120xqne", "is_robot_indexable": true, "report_reasons": null, "author": "GingerKit07", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120xqne/what_steps_and_certifications_should_i_get_if_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120xqne/what_steps_and_certifications_should_i_get_if_i/", "subreddit_subscribers": 94295, "created_utc": 1679690300.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[**Kaufland e-commerce**](https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#), one of the fastest-growing online marketplaces in Germany, has implemented [**Secoda**](https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#) to streamline its data ecosystem. With over 15,000 tables and triple digit growth in active data users, Kaufland E-Commerce needed a system to make data discoverable and efficiently used. \n\n[**Richard Hondrich**](https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#), Head of Data and Analytics at Kaufland E-Commerce, created and maintained a consolidated view of all data assets with Secoda. The Secoda workspace is organized so each functional area and team is represented by a Collection, allowing for a single data repository for documents, questions, and knowledge. Every table across Kaufland E-Commerce's entire data stack maps to a specific Collection and has a dedicated owner. The Secoda platform also enables automated stakeholder communication, reducing downtime and increasing data accuracy.\n\nRead more here:\n\n[https://www.secoda.co/customers/kaufland-e-commerce-case-study](https://www.secoda.co/customers/kaufland-e-commerce-case-study)", "author_fullname": "t2_aiinah9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Kaufland E-Commerce automates data governance across over 15K tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120s83g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679680404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#\"&gt;&lt;strong&gt;Kaufland e-commerce&lt;/strong&gt;&lt;/a&gt;, one of the fastest-growing online marketplaces in Germany, has implemented &lt;a href=\"https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#\"&gt;&lt;strong&gt;Secoda&lt;/strong&gt;&lt;/a&gt; to streamline its data ecosystem. With over 15,000 tables and triple digit growth in active data users, Kaufland E-Commerce needed a system to make data discoverable and efficiently used. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin#\"&gt;&lt;strong&gt;Richard Hondrich&lt;/strong&gt;&lt;/a&gt;, Head of Data and Analytics at Kaufland E-Commerce, created and maintained a consolidated view of all data assets with Secoda. The Secoda workspace is organized so each functional area and team is represented by a Collection, allowing for a single data repository for documents, questions, and knowledge. Every table across Kaufland E-Commerce&amp;#39;s entire data stack maps to a specific Collection and has a dedicated owner. The Secoda platform also enables automated stakeholder communication, reducing downtime and increasing data accuracy.&lt;/p&gt;\n\n&lt;p&gt;Read more here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.secoda.co/customers/kaufland-e-commerce-case-study\"&gt;https://www.secoda.co/customers/kaufland-e-commerce-case-study&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;v=enabled&amp;s=751b05e77b1c50dfc8477f4c599cb33affc7e2fc", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "120s83g", "is_robot_indexable": true, "report_reasons": null, "author": "secodaHQ", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120s83g/how_kaufland_ecommerce_automates_data_governance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120s83g/how_kaufland_ecommerce_automates_data_governance/", "subreddit_subscribers": 94295, "created_utc": 1679680404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mods remove if not allowed, I come in peace.\n\nI have been tasked with curating SQL training for new learners. Sounds easy enough, problem is bossman wont give me a DB to work with, but he will give me a data bricks cluster. So essentially, I need to figure out how to create a fictitious database that can later be queried for students in the data bricks IDE. \n\nWhile I am a Jr. DE, this surely does not sound like the best (or certainly most cost effective) mode to deliver content. However, it is what I am expected to do. Could anyone provide me with some insight (or point me to some reading material) that would help me accomplish this? My google searches aren't cutting it.\n\nAlso, if this question is just absolutely hilarious, please point that out as well. I am brand new to data bricks and while I understand SQL and relational databases, I could not tell you how data is even being stored in DB.\n\nThanks,", "author_fullname": "t2_2saw9ds3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating Relational Data in Data Bricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120rylw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679679862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mods remove if not allowed, I come in peace.&lt;/p&gt;\n\n&lt;p&gt;I have been tasked with curating SQL training for new learners. Sounds easy enough, problem is bossman wont give me a DB to work with, but he will give me a data bricks cluster. So essentially, I need to figure out how to create a fictitious database that can later be queried for students in the data bricks IDE. &lt;/p&gt;\n\n&lt;p&gt;While I am a Jr. DE, this surely does not sound like the best (or certainly most cost effective) mode to deliver content. However, it is what I am expected to do. Could anyone provide me with some insight (or point me to some reading material) that would help me accomplish this? My google searches aren&amp;#39;t cutting it.&lt;/p&gt;\n\n&lt;p&gt;Also, if this question is just absolutely hilarious, please point that out as well. I am brand new to data bricks and while I understand SQL and relational databases, I could not tell you how data is even being stored in DB.&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "120rylw", "is_robot_indexable": true, "report_reasons": null, "author": "likely-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120rylw/creating_relational_data_in_data_bricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120rylw/creating_relational_data_in_data_bricks/", "subreddit_subscribers": 94295, "created_utc": 1679679862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I have to process data in Databricks + PySpark, joining tables from Snowflake and also CSVs that are in S3. I'm newish to Databricks and Spark (but not new to Python/SQL/AWS).\n\nI'm migrating SQL code from somewhere else so my initial idea was to retain the query structure, but should I process these as dataframes? Does it matter? \n\nI read in a Snowflake table like this:\n\n`q = 'select * from ' + snowflake_table`\n\n`snow_df = spark.read.format(\"snowflake\").options(**sfOptions).option(\"query\", q).load()`\n\nAnd then got the CSV: \n\n`s3_df = (`[`spark.read`](https://spark.read)\n\n  `.format(\"csv\")`\n\n  `.option(\"mode\", \"PERMISSIVE\")`\n\n  `.option(\"header\", \"true\")`\n\n  `.load(s3_path))`\n\nI assume I could \"merge\" since they are dataframes but wondering if I could use SQL instead. It would ensure I don't break the logic. Like,\n\n`snow_df.createOrReplaceTempView('snow_view')`\n\nAnd then use spark.sql to run queries against it?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using Databricks/Spark/Snowflake/S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120need", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679671029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have to process data in Databricks + PySpark, joining tables from Snowflake and also CSVs that are in S3. I&amp;#39;m newish to Databricks and Spark (but not new to Python/SQL/AWS).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m migrating SQL code from somewhere else so my initial idea was to retain the query structure, but should I process these as dataframes? Does it matter? &lt;/p&gt;\n\n&lt;p&gt;I read in a Snowflake table like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;q = &amp;#39;select * from &amp;#39; + snowflake_table&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;snow_df = spark.read.format(&amp;quot;snowflake&amp;quot;).options(**sfOptions).option(&amp;quot;query&amp;quot;, q).load()&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;And then got the CSV: &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;s3_df = (&lt;/code&gt;&lt;a href=\"https://spark.read\"&gt;&lt;code&gt;spark.read&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;.format(&amp;quot;csv&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;.option(&amp;quot;mode&amp;quot;, &amp;quot;PERMISSIVE&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;.option(&amp;quot;header&amp;quot;, &amp;quot;true&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;.load(s3_path))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I assume I could &amp;quot;merge&amp;quot; since they are dataframes but wondering if I could use SQL instead. It would ensure I don&amp;#39;t break the logic. Like,&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;snow_df.createOrReplaceTempView(&amp;#39;snow_view&amp;#39;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;And then use spark.sql to run queries against it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "120need", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120need/question_about_using_databrickssparksnowflakes3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120need/question_about_using_databrickssparksnowflakes3/", "subreddit_subscribers": 94295, "created_utc": 1679671029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interested in observability, ClickHouse, or both? Our upcoming webinar shows a top-to-bottom use case of using ClickHouse on Kubernetes at OpsVerse to offer better observability capabilities to end users. We'll cover both key ClickHouse capabilities as well as cloud native operation using the Altinity Operator for ClickHouse. The solution is deployed and working well. Join us to [find out more.](https://altinity.com/events/supercharging-observability-at-opsverse-using-clickhouse-realtime-analytics)", "author_fullname": "t2_s3zu6zpl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Supercharging Observability at OpsVerse using ClickHouse Real-Time Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1212n6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679700131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interested in observability, ClickHouse, or both? Our upcoming webinar shows a top-to-bottom use case of using ClickHouse on Kubernetes at OpsVerse to offer better observability capabilities to end users. We&amp;#39;ll cover both key ClickHouse capabilities as well as cloud native operation using the Altinity Operator for ClickHouse. The solution is deployed and working well. Join us to &lt;a href=\"https://altinity.com/events/supercharging-observability-at-opsverse-using-clickhouse-realtime-analytics\"&gt;find out more.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?auto=webp&amp;v=enabled&amp;s=34af15d35d9f21298c8ce61e9c609e2dcb3d7ed4", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc6a268670aab771ec14273e8014c7ba818d8378", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=813c76e4bd454d3e57918d666417360298e951ba", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68f047442b400f75f89acc8296532165c65f54cd", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e941d1bdd97bedb1f5cbbad6d902d4ca997bba3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6354c15bf6a79652ae8d00ca7d89e19579df1690", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/DEYX6YSkXZ4ODNyc1yL_TkAtzMcL19R2RER6w0bejt0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95a760900d9886bf1dc46f9640c015a448a91e00", "width": 1080, "height": 607}], "variants": {}, "id": "1DvOlwCOyWVgnZlqccNEhkvL8YcYma0EUWaPTbsVdUs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1212n6p", "is_robot_indexable": true, "report_reasons": null, "author": "RyhanSunny_Altinity", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1212n6p/supercharging_observability_at_opsverse_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1212n6p/supercharging_observability_at_opsverse_using/", "subreddit_subscribers": 94295, "created_utc": 1679700131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a question regarding the most efficient method for data transformations. I have been tasked with performing ETL processes at my company and am the sole person responsible for the data.\n\nI have extracted additional information from a Dynamodb and RDS using AWS Glue. I then read the table with Athena, created a view, and loaded it into Power BI using the Athena Connector.\n\nMy question is, what is the best way to perform transformations on the data, such as adding columns with rank functions and others? Should I use Pyspark in the transform part while running the job in Glue, or should I use SQL to add the columns in the Athena view? Or should I try something different?\n\nThank you in advance!", "author_fullname": "t2_a3f7s3y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transformations of ETL process on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_12127c9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679699217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a question regarding the most efficient method for data transformations. I have been tasked with performing ETL processes at my company and am the sole person responsible for the data.&lt;/p&gt;\n\n&lt;p&gt;I have extracted additional information from a Dynamodb and RDS using AWS Glue. I then read the table with Athena, created a view, and loaded it into Power BI using the Athena Connector.&lt;/p&gt;\n\n&lt;p&gt;My question is, what is the best way to perform transformations on the data, such as adding columns with rank functions and others? Should I use Pyspark in the transform part while running the job in Glue, or should I use SQL to add the columns in the Athena view? Or should I try something different?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "12127c9", "is_robot_indexable": true, "report_reasons": null, "author": "IllRevolution7113", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/12127c9/transformations_of_etl_process_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/12127c9/transformations_of_etl_process_on_aws/", "subreddit_subscribers": 94295, "created_utc": 1679699217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working as a Data Engineer for a bit now, but most of my background is in full stack development utilizing Node, dotNet, and front-end frameworks, and both noSQL and SQL databases etc., but rarely Python. Python was always used as a scripting language or for hobbies. Now, in the world of \"data fill-in-the-blank\" Python is the bee's knees. I do like it..., and have decided to move forward with a sticker on my Mac but at what point an I forcing a round peg in an octagon hole? I have been using Python to write small pipelines moving a million rows or less from various flat-files or DB tables to some data warehouse. Everything seems simple: Read in a CSV with Pandas, do some cleaning, upload to the whatever database, etc. However, some of the projects I'm working on are requiring a bit more sophistication or heavy lifting. Pandas and Sqlalchemy seem chunky and not great (slow) for migrating greater than a million rows from one source to another. Are there options other than Sqlalchemy or Pandas in the Python world for moving data or have I been reading too many articles by Data Scientists?", "author_fullname": "t2_74fehzbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what point is Python not answer for piping data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1211nsk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679698103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a Data Engineer for a bit now, but most of my background is in full stack development utilizing Node, dotNet, and front-end frameworks, and both noSQL and SQL databases etc., but rarely Python. Python was always used as a scripting language or for hobbies. Now, in the world of &amp;quot;data fill-in-the-blank&amp;quot; Python is the bee&amp;#39;s knees. I do like it..., and have decided to move forward with a sticker on my Mac but at what point an I forcing a round peg in an octagon hole? I have been using Python to write small pipelines moving a million rows or less from various flat-files or DB tables to some data warehouse. Everything seems simple: Read in a CSV with Pandas, do some cleaning, upload to the whatever database, etc. However, some of the projects I&amp;#39;m working on are requiring a bit more sophistication or heavy lifting. Pandas and Sqlalchemy seem chunky and not great (slow) for migrating greater than a million rows from one source to another. Are there options other than Sqlalchemy or Pandas in the Python world for moving data or have I been reading too many articles by Data Scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1211nsk", "is_robot_indexable": true, "report_reasons": null, "author": "afivegallonbucket", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1211nsk/at_what_point_is_python_not_answer_for_piping_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1211nsk/at_what_point_is_python_not_answer_for_piping_data/", "subreddit_subscribers": 94295, "created_utc": 1679698103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any non technical jobs out there to transition into (no coding, devops, tool management etc) in which DE skills might be a good fit for?", "author_fullname": "t2_foq4s5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some transferable skills coming out of data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120v31a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679685777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any non technical jobs out there to transition into (no coding, devops, tool management etc) in which DE skills might be a good fit for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "120v31a", "is_robot_indexable": true, "report_reasons": null, "author": "sumApples", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120v31a/what_are_some_transferable_skills_coming_out_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120v31a/what_are_some_transferable_skills_coming_out_of/", "subreddit_subscribers": 94295, "created_utc": 1679685777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I\u2019m a sophomore (so keep in mind that I\u2019m saying this in context to junior year recruiting) and recently received an offer from AMD for a data engineering Co-Op. \n\nI received a couple of offers from other companies (namely workday and ibm) for swe, but I\u2019m interested in taking AMD as I enjoyed working with data pipelines in my classes and because AMD is a strong brand. \n\nHowever, my main concern is that once I step into DE, I won\u2019t be able to leave. This is my first real industry internship, so I honestly have no idea what swe, DE, or DS work is like. Do you think having a data engineering job on my resume would limit my potential to get swe jobs in the future?", "author_fullname": "t2_w8nqcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a good idea to take up a Data Engineering internship if I\u2019m not sure what I\u2019m interested in yet.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120sbqa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679680612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I\u2019m a sophomore (so keep in mind that I\u2019m saying this in context to junior year recruiting) and recently received an offer from AMD for a data engineering Co-Op. &lt;/p&gt;\n\n&lt;p&gt;I received a couple of offers from other companies (namely workday and ibm) for swe, but I\u2019m interested in taking AMD as I enjoyed working with data pipelines in my classes and because AMD is a strong brand. &lt;/p&gt;\n\n&lt;p&gt;However, my main concern is that once I step into DE, I won\u2019t be able to leave. This is my first real industry internship, so I honestly have no idea what swe, DE, or DS work is like. Do you think having a data engineering job on my resume would limit my potential to get swe jobs in the future?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "120sbqa", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Cuddlesz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120sbqa/is_it_a_good_idea_to_take_up_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120sbqa/is_it_a_good_idea_to_take_up_a_data_engineering/", "subreddit_subscribers": 94295, "created_utc": 1679680612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to get the correct Modern Data Stack being:\n\nData ingestion (EL) tool --&gt; Snowflake (maybe GBQ) --&gt; dbt Cloud --&gt; Hex\n\nData ingestion is the stumbling block at the moment.  I need to ingest ActiveCampaign and a handful of other bespoke APIs.  Tool must also be HIPAA compliant.  My thoughts were:\n\nFiveTran - but it doesn't do bespoke APIs and not HIPAA compliant really ([https://fivetran.com/docs/security#hipaa](https://fivetran.com/docs/security#hipaa))\n\nStitch - feels a bit restrictive, but definitely not HIPAA compliant\n\nHevo - does ActiveCampaign, bespoke APIs and is HIPAA compliant\n\n&amp;#x200B;\n\nBut is there anything else there that's more cost-effective per month/year?", "author_fullname": "t2_353ucr1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me find the right data ingestion tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120jb4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679662286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to get the correct Modern Data Stack being:&lt;/p&gt;\n\n&lt;p&gt;Data ingestion (EL) tool --&amp;gt; Snowflake (maybe GBQ) --&amp;gt; dbt Cloud --&amp;gt; Hex&lt;/p&gt;\n\n&lt;p&gt;Data ingestion is the stumbling block at the moment.  I need to ingest ActiveCampaign and a handful of other bespoke APIs.  Tool must also be HIPAA compliant.  My thoughts were:&lt;/p&gt;\n\n&lt;p&gt;FiveTran - but it doesn&amp;#39;t do bespoke APIs and not HIPAA compliant really (&lt;a href=\"https://fivetran.com/docs/security#hipaa\"&gt;https://fivetran.com/docs/security#hipaa&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Stitch - feels a bit restrictive, but definitely not HIPAA compliant&lt;/p&gt;\n\n&lt;p&gt;Hevo - does ActiveCampaign, bespoke APIs and is HIPAA compliant&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But is there anything else there that&amp;#39;s more cost-effective per month/year?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "120jb4i", "is_robot_indexable": true, "report_reasons": null, "author": "cmcau", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120jb4i/help_me_find_the_right_data_ingestion_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120jb4i/help_me_find_the_right_data_ingestion_tool/", "subreddit_subscribers": 94295, "created_utc": 1679662286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I'm currently working as a project manager but not having the best time. I'm only really beginning my career but already know I don't particularly enjoy networking, long meetings, or organising other people - literally the job description of a project manager. I want a job where I'm responsible for myself and myself alone. I asked my manager if I can transition to the role of DE. He's on board with it because he can tell I'm not having fun in my current role. I know it's a huge undertaking because I'm essentially trying to catch up to people who have Master's degrees in this field (I have a Master's in Engineering, in a field completely unrelated to data). I've done some programming in the past and liked it and always had a very \"organising\" type of mindset? If that makes sense. He arranged some professional coaching for me, about 4h a week, and I'm currently following an online bootcamp so I can get the basics down. I'm gonna start with some easy data analysis work to get me familiar with working with traditional data, from there continue to work with databases, programming, data infrastructure and Big Data. \n\nI really want to do it but I'm wondering if I'm just way out of my depth here? Is there anybody else who's done something similar and can share what they did?", "author_fullname": "t2_w3ez8i7a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_120g82p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679653799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m currently working as a project manager but not having the best time. I&amp;#39;m only really beginning my career but already know I don&amp;#39;t particularly enjoy networking, long meetings, or organising other people - literally the job description of a project manager. I want a job where I&amp;#39;m responsible for myself and myself alone. I asked my manager if I can transition to the role of DE. He&amp;#39;s on board with it because he can tell I&amp;#39;m not having fun in my current role. I know it&amp;#39;s a huge undertaking because I&amp;#39;m essentially trying to catch up to people who have Master&amp;#39;s degrees in this field (I have a Master&amp;#39;s in Engineering, in a field completely unrelated to data). I&amp;#39;ve done some programming in the past and liked it and always had a very &amp;quot;organising&amp;quot; type of mindset? If that makes sense. He arranged some professional coaching for me, about 4h a week, and I&amp;#39;m currently following an online bootcamp so I can get the basics down. I&amp;#39;m gonna start with some easy data analysis work to get me familiar with working with traditional data, from there continue to work with databases, programming, data infrastructure and Big Data. &lt;/p&gt;\n\n&lt;p&gt;I really want to do it but I&amp;#39;m wondering if I&amp;#39;m just way out of my depth here? Is there anybody else who&amp;#39;s done something similar and can share what they did?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "120g82p", "is_robot_indexable": true, "report_reasons": null, "author": "thr0wawaeeh12345", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120g82p/transition_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/120g82p/transition_to_de/", "subreddit_subscribers": 94295, "created_utc": 1679653799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So really interested on thoughts here. There is a big cloud data warehouse provider. Well known, works well, sales oriented approach to building its user base.\n\nThere is a new solution on the market. Open source, kinda data lakehouse without the need for Spark. You can clone the git, or grab the docker image and just ise it. They also have a cloud offering (think dbt-cli vs. dbt cloud). Their cloud offering has more transparent pricing than the big provider, and their website has a direct comparison to that cloud provider.\n\nThe thing is, when you log in to their cloud offering, you\u2019d be forgiven for thinking it **was** the big provider. Layout, color scheme, even the way it returns values with a summary on the right. It\u2019s almost identical.\n\nSo, longevity/risk of collapse of the company aside, would you/your company consider using a \u2018clone\u2019 if it were cheaper?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ethics of using clones/knock-offs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1213bem", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679701571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So really interested on thoughts here. There is a big cloud data warehouse provider. Well known, works well, sales oriented approach to building its user base.&lt;/p&gt;\n\n&lt;p&gt;There is a new solution on the market. Open source, kinda data lakehouse without the need for Spark. You can clone the git, or grab the docker image and just ise it. They also have a cloud offering (think dbt-cli vs. dbt cloud). Their cloud offering has more transparent pricing than the big provider, and their website has a direct comparison to that cloud provider.&lt;/p&gt;\n\n&lt;p&gt;The thing is, when you log in to their cloud offering, you\u2019d be forgiven for thinking it &lt;strong&gt;was&lt;/strong&gt; the big provider. Layout, color scheme, even the way it returns values with a summary on the right. It\u2019s almost identical.&lt;/p&gt;\n\n&lt;p&gt;So, longevity/risk of collapse of the company aside, would you/your company consider using a \u2018clone\u2019 if it were cheaper?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1213bem", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1213bem/ethics_of_using_clonesknockoffs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1213bem/ethics_of_using_clonesknockoffs/", "subreddit_subscribers": 94295, "created_utc": 1679701571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why You Should Become A Data Product Manager In 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_120ev9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.36, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GC6bdYLLDAQQu7qn_5iUBgeB8_F6LeKFfPOTQoGhekE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679649519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/why-you-should-become-a-data-product-manager-in-2023-323940895e6c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?auto=webp&amp;v=enabled&amp;s=ec7194c874028cd3a50bcdefcce449c3bfda4f90", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94a3374030c3fdd8337a54fb47e51740caf0f969", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=986f6f7c2167f92712019db858fda8e66ae7706f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6c72f9eb93f6f5bda03eaa22daf6812d553ed1c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57ed12dac0663deaa268fae620aee310aad62b87", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d9d5e497449115be36fc817a5598e1bfc3a6348", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/riiqHWCQgfKSX2B1pomp_nyw-lzM_SfURN3IJ-8_HGU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=929ada467e23ff512a60cace7b50796eb1e57b76", "width": 1080, "height": 607}], "variants": {}, "id": "m8fzfW5_487SUqy2Cgveu_iDLPLnnl5NwYXC0ozs45E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "120ev9g", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/120ev9g/why_you_should_become_a_data_product_manager_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/why-you-should-become-a-data-product-manager-in-2023-323940895e6c", "subreddit_subscribers": 94295, "created_utc": 1679649519.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}