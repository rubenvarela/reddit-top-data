{"kind": "Listing", "data": {"after": "t3_11sysbc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5i67k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie firm plans $2,800 add-in card that holds up to 21 PCIe 4.0 SSDs, 168TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_11st3i9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 547, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 547, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/_Lhp8G-Nd3iib1AdCgd5XccEaXJVs8dC-NmXGZgmt84.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1678970594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/gadgets/2023/03/newbie-firm-plans-2800-add-in-card-that-holds-up-to-21-pcie-4-0-ssds-168tb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JEfaRH7zbZB2w3obBVqs8YStnmO-JoA14qkca4TjHXI.jpg?auto=webp&amp;v=enabled&amp;s=4b05bf4c1f7c8f277585f4631163586fd924ccdb", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/JEfaRH7zbZB2w3obBVqs8YStnmO-JoA14qkca4TjHXI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c7b37c85aa467dcf342be0a4cf4a5a915b67c91", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JEfaRH7zbZB2w3obBVqs8YStnmO-JoA14qkca4TjHXI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4e18c168fababb447c4d8999e752e9535b6407c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JEfaRH7zbZB2w3obBVqs8YStnmO-JoA14qkca4TjHXI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0b3beae309e904f109f0aef0a7d2fa564aae941", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JEfaRH7zbZB2w3obBVqs8YStnmO-JoA14qkca4TjHXI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05343bb4cc80eb7f6ba475f6e986a0f3eeeaa396", "width": 640, "height": 320}], "variants": {}, "id": "0JfzsqTrXPS4wsPWgDo33pHlZU7X1yq6zfe0CaTvOTk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB + NSA DATACENTER", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11st3i9", "is_robot_indexable": true, "report_reasons": null, "author": "benderunit9000", "discussion_type": null, "num_comments": 102, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11st3i9/newbie_firm_plans_2800_addin_card_that_holds_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/gadgets/2023/03/newbie-firm-plans-2800-add-in-card-that-holds-up-to-21-pcie-4-0-ssds-168tb/", "subreddit_subscribers": 673509, "created_utc": 1678970594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI hope you're all well,\n\nI'm incredibly interested in what happened to Mega. Who owns it now? Kim Dotcom claims that the NZ government own it [here](https://yro.slashdot.org/story/15/07/27/200204/interviews-kim-dotcom-answers-your-questions):\n\n' I'm not involved in Mega anymore. Neither in a managing nor in a shareholder capacity. The company has suffered from a hostile takeover by a Chinese investor who is wanted in China for fraud. He used a number of straw-men and businesses to accumulate more and more Mega shares. Recently his shares have been seized by the NZ government. Which means the NZ government is in control.'\n\nBut do they really? The company lists the various roles on their website, but does anyone know who really owns the service now?\n\nI admire the company for doing zero knowledge encryption, however, I would like to know who owns the company so that I can gauge them as a person or group. I need to be sure that my data is secure and private.\n\nI have trust in Kim Dotcom because I know he deeply believes in freedom and privacy and has demonstrated that through his actions over the years. He's openly said he distrusts MEGA now. I think the fact that the owner of the company doesn't seem to be public information is a bit of a red flag for me. But I would like to see for myself.\n\nMEGA has a great Linux client it seems, which Dropbox certainly does not, so I am considering a migration, however, I would like to know who owns the company so I can gauge how much trust I should put in it.\n\nMany thanks in advance :)", "author_fullname": "t2_u3bzwcsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who owns Mega now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3hqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678997421.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678994329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all well,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m incredibly interested in what happened to Mega. Who owns it now? Kim Dotcom claims that the NZ government own it &lt;a href=\"https://yro.slashdot.org/story/15/07/27/200204/interviews-kim-dotcom-answers-your-questions\"&gt;here&lt;/a&gt;:&lt;/p&gt;\n\n&lt;p&gt;&amp;#39; I&amp;#39;m not involved in Mega anymore. Neither in a managing nor in a shareholder capacity. The company has suffered from a hostile takeover by a Chinese investor who is wanted in China for fraud. He used a number of straw-men and businesses to accumulate more and more Mega shares. Recently his shares have been seized by the NZ government. Which means the NZ government is in control.&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;But do they really? The company lists the various roles on their website, but does anyone know who really owns the service now?&lt;/p&gt;\n\n&lt;p&gt;I admire the company for doing zero knowledge encryption, however, I would like to know who owns the company so that I can gauge them as a person or group. I need to be sure that my data is secure and private.&lt;/p&gt;\n\n&lt;p&gt;I have trust in Kim Dotcom because I know he deeply believes in freedom and privacy and has demonstrated that through his actions over the years. He&amp;#39;s openly said he distrusts MEGA now. I think the fact that the owner of the company doesn&amp;#39;t seem to be public information is a bit of a red flag for me. But I would like to see for myself.&lt;/p&gt;\n\n&lt;p&gt;MEGA has a great Linux client it seems, which Dropbox certainly does not, so I am considering a migration, however, I would like to know who owns the company so I can gauge how much trust I should put in it.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BAPvmcnMj-DMmgQcRsE6pa0T1EG7NXU1hR8T55UrDzM.jpg?auto=webp&amp;v=enabled&amp;s=71e98b037b48a6176dd4ce8c61462ffc03adfaa5", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "_j1MTgi3ZN4ckSmdak5zroJ-Cq0PzLPGJlMjCJvUPQs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t3hqh", "is_robot_indexable": true, "report_reasons": null, "author": "Gloriouscal9001", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t3hqh/who_owns_mega_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t3hqh/who_owns_mega_now/", "subreddit_subscribers": 673509, "created_utc": 1678994329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So... in the process of upgrading my PC, I bought a new case with better airflow: the Fractal Design Pop Airflow. To my surprise, it has TWO 5.2\" bays, in which I wanted to install internal optical disc drives. \n\nI have almost ZERO knowledge about these drives and so, I ask you all what would be the best internal ODD for reading and writing I can buy right now? And whether I will be able to use the drive with Windows 10/11?", "author_fullname": "t2_nln6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best internal optical disc drive (for reading and writing)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11st663", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678970782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So... in the process of upgrading my PC, I bought a new case with better airflow: the Fractal Design Pop Airflow. To my surprise, it has TWO 5.2&amp;quot; bays, in which I wanted to install internal optical disc drives. &lt;/p&gt;\n\n&lt;p&gt;I have almost ZERO knowledge about these drives and so, I ask you all what would be the best internal ODD for reading and writing I can buy right now? And whether I will be able to use the drive with Windows 10/11?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11st663", "is_robot_indexable": true, "report_reasons": null, "author": "kikirevi", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11st663/best_internal_optical_disc_drive_for_reading_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11st663/best_internal_optical_disc_drive_for_reading_and/", "subreddit_subscribers": 673509, "created_utc": 1678970782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he's here lol). \n\nMy friend is into retro game preservation and it just reminded me of him.", "author_fullname": "t2_g4f3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is the guy who is trying to download every single game?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11toc7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679052290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he&amp;#39;s here lol). &lt;/p&gt;\n\n&lt;p&gt;My friend is into retro game preservation and it just reminded me of him.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11toc7v", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveChairs", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "subreddit_subscribers": 673509, "created_utc": 1679052290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "basically to use them for a media server NAS, and I have found very good options on ebay.\n\nIt is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.", "author_fullname": "t2_6hxjwymn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth buying used hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11taniw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;basically to use them for a media server NAS, and I have found very good options on ebay.&lt;/p&gt;\n\n&lt;p&gt;It is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11taniw", "is_robot_indexable": true, "report_reasons": null, "author": "AngelGrade", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "subreddit_subscribers": 673509, "created_utc": 1679010838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tdbsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_56nr0oo0", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskReddit", "selftext": "", "author_fullname": "t2_56nr0oo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskReddit", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11td7zc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679016585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh1i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11td7zc", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 40230129, "created_utc": 1679016585.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679016871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tdbsu", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11td7zc", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tdbsu/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 673509, "created_utc": 1679016871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.youtube.com/watch?v=Jqg1G78cH2A](https://www.youtube.com/watch?v=Jqg1G78cH2A)", "author_fullname": "t2_twm9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level 1 Techs take on Home Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tklqs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679039756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=Jqg1G78cH2A\"&gt;https://www.youtube.com/watch?v=Jqg1G78cH2A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?auto=webp&amp;v=enabled&amp;s=e10203b6f26b668551d1bf3bfa0ade3d815217bc", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eef7149926b12a2a271680da9e54badc728f73", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a2f22518553258836e69a6d5c85158f1db9c269", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba2226fc27492309a02fc71d9fda027f75e56d4c", "width": 320, "height": 240}], "variants": {}, "id": "gPB9teADkSdeoYYiYccNMY4LdCypTI_dFt6qjnKE2BY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "103TB - Keep on Shucking....", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tklqs", "is_robot_indexable": true, "report_reasons": null, "author": "Graham2405", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "subreddit_subscribers": 673509, "created_utc": 1679039756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What I need to do is quite easy, but I dont know which tools to use or how to do it with said tools:\n\nWhat I need: I want to find files with similar name. The names are almost the same but the end of some of them has a suffix, for example **video.mp4** and **video-compressed.mp4**. The first one is a higher resolution and the 2nd one was compressed and named by adding the **-compressed** part.\n\nI need something that will show me when both files exist, the **\\*.\\*** one and the **\\*-compressed.\\*** one.\n\nI tried Voidools Everything, Fast Duplicate File Finder and Czkawka but cant seems to create a filter or a search that will do the trick.\n\nAnyone more intelligent than me want to chip in?\n\nThanks in advance!", "author_fullname": "t2_bs3r2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to find similar filenames...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t410y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678995593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What I need to do is quite easy, but I dont know which tools to use or how to do it with said tools:&lt;/p&gt;\n\n&lt;p&gt;What I need: I want to find files with similar name. The names are almost the same but the end of some of them has a suffix, for example &lt;strong&gt;video.mp4&lt;/strong&gt; and &lt;strong&gt;video-compressed.mp4&lt;/strong&gt;. The first one is a higher resolution and the 2nd one was compressed and named by adding the &lt;strong&gt;-compressed&lt;/strong&gt; part.&lt;/p&gt;\n\n&lt;p&gt;I need something that will show me when both files exist, the &lt;strong&gt;*.\\&lt;/strong&gt;* one and the &lt;strong&gt;*-compressed.\\&lt;/strong&gt;* one.&lt;/p&gt;\n\n&lt;p&gt;I tried Voidools Everything, Fast Duplicate File Finder and Czkawka but cant seems to create a filter or a search that will do the trick.&lt;/p&gt;\n\n&lt;p&gt;Anyone more intelligent than me want to chip in?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t410y", "is_robot_indexable": true, "report_reasons": null, "author": "Namaperv", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t410y/need_to_find_similar_filenames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t410y/need_to_find_similar_filenames/", "subreddit_subscribers": 673509, "created_utc": 1678995593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After searching all of the internet, I believe this has become my last bastion of hope for some support. I've never posted here, but have followed many users and appreciated much of the advice shared here. However, I am now in need of help. I have email Areca, called every distributer that would take my call, read every FAQ, support page, YouTube video, and any other media I could find, all to no avail.\n\nMy array has been online since July of 2022. It a Areca 8050T3U-8 with 8 - Seagate Exos X18 18TB 7200RPM. The drives are renewed, but all of them reported fine when I bought them.\n\nThe array is connected via Thunderbolt 4 to a new\u00a0 computer build I finished around a month ago and worked fine. I also still have my old computer build, which was TB3, and it worked fine there as well. I have not updated any software, firmware, or anything prior to this issue arising, but since have updated windows and my motherboard bios.\n\nThe issue:\n\nWhile video editing from the array, I noticed that a single frame was reporting \"media offline\" in my timeline. I thought it was just a bug, but I then noticed the rest of the timeline was now not accessible (was fine before). The software then crashed.\u00a0\n\nUpon restarting the program, the same error persisted. I opened a previous project I had edited to test the array but it too, would not open. No files on the array worked, but I could still see the file tree in file explorer. I accessed the raid volume in file explorer and everything looked fine but at some point, if I clicked on folder it would give the \"this no longer exist\" error.\n\nI opened ArchTTP and ArcSAP and the array reported normal there. No drive failures, errors, or anything.\u00a0Still, I have no logs saying there is any issue besides a few times where Windows reports a \"fatal device error\" when the array locks up.\n\nWhenever I accessed a file, the screen on the front turned off and the activity lights went blue. I restarted my computer and the error persisted. I unplugged the thunderbolt cable (since my array does not have a power button) and that also did nothing (this something areca advised before). On startup, I notice the disk in the array spin up, then begin to stop, then spin up again, and begin to stop again, with the LED quickly turning on orange the red, then turning off.\u00a0This is new behavior.\n\nThe PC takes much longer to post than it normally does (the screen is black with a white bar \\_ on the top left. I have ran SFC scan and it found and issue and repaired it, but the issue remain. After some time the lights on the array cut on, it goes through it's startup sequence, and everything is green. It just goes offline if I read from it. The data is there. At times, it can transfer files for 30 seconds, other times, 10 minutes, other times, less than a second.\n\nI was able to hook up the array to my old desktop where I had some empty fast storage. I could get it to transfer files for a little bit, then it would fail so I would unplug the thunderbolt, plug it back in, wait for the drives to initialize, then tell windows to try again and it would work until it happened again. I sat there transferring 6Tb of wedding footage doing this cycle until it was all off. The data seems fine? So I guess that is good at least.\n\nCurrently, the array is \"online\" as I can access ArchTTP and can see it in file explorer with all my files and folders. But whenever I access a file, like a video to watch, the array the lights go to blue, screen cuts off, and I can access nothing.\u00a0 At times, all the lights go blue, or just a few go blue and some are green, but there is no pattern.\n\nConnecting via USB C to USB A does not help, repairing thunderbolt drivers does not help, different cables do not help. I have done the reset where you unplug everything, connect power and then hold the reset button, let it power on and setup, then reset it again to turn it off, but that also did not work.\n\n\u00a0Please advise on what I can do because currently, I am out of work with the array offline. I have three brides waiting for the wedding video and I am freaking out a little because I have no way to edit them. Most of the footage is stored on slow external drives now, but several of the projects are 2-3Tb which is larger than my fastest SSD.\n\nIf you can help, I am beyond thankful, if not I understand and apologize\u00a0for wasting your time.\u00a0", "author_fullname": "t2_176q7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Areca 8050T3U-8 DAS has suddenly stopped working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11syx6n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678984211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After searching all of the internet, I believe this has become my last bastion of hope for some support. I&amp;#39;ve never posted here, but have followed many users and appreciated much of the advice shared here. However, I am now in need of help. I have email Areca, called every distributer that would take my call, read every FAQ, support page, YouTube video, and any other media I could find, all to no avail.&lt;/p&gt;\n\n&lt;p&gt;My array has been online since July of 2022. It a Areca 8050T3U-8 with 8 - Seagate Exos X18 18TB 7200RPM. The drives are renewed, but all of them reported fine when I bought them.&lt;/p&gt;\n\n&lt;p&gt;The array is connected via Thunderbolt 4 to a new\u00a0 computer build I finished around a month ago and worked fine. I also still have my old computer build, which was TB3, and it worked fine there as well. I have not updated any software, firmware, or anything prior to this issue arising, but since have updated windows and my motherboard bios.&lt;/p&gt;\n\n&lt;p&gt;The issue:&lt;/p&gt;\n\n&lt;p&gt;While video editing from the array, I noticed that a single frame was reporting &amp;quot;media offline&amp;quot; in my timeline. I thought it was just a bug, but I then noticed the rest of the timeline was now not accessible (was fine before). The software then crashed.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Upon restarting the program, the same error persisted. I opened a previous project I had edited to test the array but it too, would not open. No files on the array worked, but I could still see the file tree in file explorer. I accessed the raid volume in file explorer and everything looked fine but at some point, if I clicked on folder it would give the &amp;quot;this no longer exist&amp;quot; error.&lt;/p&gt;\n\n&lt;p&gt;I opened ArchTTP and ArcSAP and the array reported normal there. No drive failures, errors, or anything.\u00a0Still, I have no logs saying there is any issue besides a few times where Windows reports a &amp;quot;fatal device error&amp;quot; when the array locks up.&lt;/p&gt;\n\n&lt;p&gt;Whenever I accessed a file, the screen on the front turned off and the activity lights went blue. I restarted my computer and the error persisted. I unplugged the thunderbolt cable (since my array does not have a power button) and that also did nothing (this something areca advised before). On startup, I notice the disk in the array spin up, then begin to stop, then spin up again, and begin to stop again, with the LED quickly turning on orange the red, then turning off.\u00a0This is new behavior.&lt;/p&gt;\n\n&lt;p&gt;The PC takes much longer to post than it normally does (the screen is black with a white bar _ on the top left. I have ran SFC scan and it found and issue and repaired it, but the issue remain. After some time the lights on the array cut on, it goes through it&amp;#39;s startup sequence, and everything is green. It just goes offline if I read from it. The data is there. At times, it can transfer files for 30 seconds, other times, 10 minutes, other times, less than a second.&lt;/p&gt;\n\n&lt;p&gt;I was able to hook up the array to my old desktop where I had some empty fast storage. I could get it to transfer files for a little bit, then it would fail so I would unplug the thunderbolt, plug it back in, wait for the drives to initialize, then tell windows to try again and it would work until it happened again. I sat there transferring 6Tb of wedding footage doing this cycle until it was all off. The data seems fine? So I guess that is good at least.&lt;/p&gt;\n\n&lt;p&gt;Currently, the array is &amp;quot;online&amp;quot; as I can access ArchTTP and can see it in file explorer with all my files and folders. But whenever I access a file, like a video to watch, the array the lights go to blue, screen cuts off, and I can access nothing.\u00a0 At times, all the lights go blue, or just a few go blue and some are green, but there is no pattern.&lt;/p&gt;\n\n&lt;p&gt;Connecting via USB C to USB A does not help, repairing thunderbolt drivers does not help, different cables do not help. I have done the reset where you unplug everything, connect power and then hold the reset button, let it power on and setup, then reset it again to turn it off, but that also did not work.&lt;/p&gt;\n\n&lt;p&gt;\u00a0Please advise on what I can do because currently, I am out of work with the array offline. I have three brides waiting for the wedding video and I am freaking out a little because I have no way to edit them. Most of the footage is stored on slow external drives now, but several of the projects are 2-3Tb which is larger than my fastest SSD.&lt;/p&gt;\n\n&lt;p&gt;If you can help, I am beyond thankful, if not I understand and apologize\u00a0for wasting your time.\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11syx6n", "is_robot_indexable": true, "report_reasons": null, "author": "CrossAerial", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11syx6n/areca_8050t3u8_das_has_suddenly_stopped_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11syx6n/areca_8050t3u8_das_has_suddenly_stopped_working/", "subreddit_subscribers": 673509, "created_utc": 1678984211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seek the wisdom of the veterans in this comunity of data hoarders!\n\nI'm sure this has been posted before but wars, sanctions, and natural disasters affect the cost of goods all the time so... I guess it's worth asking again?\n\nWith roughly 1000$-1200$ budget and and the ambition of setting up a fully redundant 8TB (2 x 8TB drives in mirroring) what is my best option, no media streaming just storing files with no chance of losing them.\n\nSpeed and ability to access from anywhere are the two main conerns,   \nwould you get an old pc and use a paid dynamic dns service or a Synology \u200eDS920+ with two 8TB drives for data and one ssd for the OS?\n\n&amp;#x200B;\n\nI have an old synology nas and there are things I love about it ( like the [quickconnect.to](https://quickconnect.to) dns thing ) and things i hate, impossibility to upgrade hardware weird file being renamed if accessed using smb or afs. \n\n&amp;#x200B;\n\nwhat is the consensus of the experts here?\n\n&amp;#x200B;\n\nis there a third option i'm not seeing?\n\n&amp;#x200B;\n\nthanks in advance!", "author_fullname": "t2_7webob1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nas, DIY or buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tne63", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679049386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seek the wisdom of the veterans in this comunity of data hoarders!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure this has been posted before but wars, sanctions, and natural disasters affect the cost of goods all the time so... I guess it&amp;#39;s worth asking again?&lt;/p&gt;\n\n&lt;p&gt;With roughly 1000$-1200$ budget and and the ambition of setting up a fully redundant 8TB (2 x 8TB drives in mirroring) what is my best option, no media streaming just storing files with no chance of losing them.&lt;/p&gt;\n\n&lt;p&gt;Speed and ability to access from anywhere are the two main conerns,&lt;br/&gt;\nwould you get an old pc and use a paid dynamic dns service or a Synology \u200eDS920+ with two 8TB drives for data and one ssd for the OS?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have an old synology nas and there are things I love about it ( like the &lt;a href=\"https://quickconnect.to\"&gt;quickconnect.to&lt;/a&gt; dns thing ) and things i hate, impossibility to upgrade hardware weird file being renamed if accessed using smb or afs. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the consensus of the experts here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is there a third option i&amp;#39;m not seeing?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tne63", "is_robot_indexable": true, "report_reasons": null, "author": "ja_maz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tne63/nas_diy_or_buy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tne63/nas_diy_or_buy/", "subreddit_subscribers": 673509, "created_utc": 1679049386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all!\n\nThis is my first post on this subreddit, please forgive me if I step on any toes \ud83d\ude2c I have a server running OMV and one of the plugins is MergerFS. It's fairly straightforward to setup MergerFS and I understand the fundamentals of MergerFS, but there is a behavior that I cannot get a clear answer on.\n\nThe behavior I am looking for is the following: If I move a folder into the MergedFS share, I would like to keep the entire folder in a single drive without splitting the internal files across multiple drives. For example: Folder A contains 10 files. I move Folder A into MergedFS\\_1. Keep Folder A and all of its files together on Disk 1 instead of spanning the 10 files over Disk 1, Disk 2, Disk 3, etc...\n\nIs MergerFS capable of this?\n\nThank you!", "author_fullname": "t2_rpu19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you keep files in folder transfers together in MergerFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t2fj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678991904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;This is my first post on this subreddit, please forgive me if I step on any toes \ud83d\ude2c I have a server running OMV and one of the plugins is MergerFS. It&amp;#39;s fairly straightforward to setup MergerFS and I understand the fundamentals of MergerFS, but there is a behavior that I cannot get a clear answer on.&lt;/p&gt;\n\n&lt;p&gt;The behavior I am looking for is the following: If I move a folder into the MergedFS share, I would like to keep the entire folder in a single drive without splitting the internal files across multiple drives. For example: Folder A contains 10 files. I move Folder A into MergedFS_1. Keep Folder A and all of its files together on Disk 1 instead of spanning the 10 files over Disk 1, Disk 2, Disk 3, etc...&lt;/p&gt;\n\n&lt;p&gt;Is MergerFS capable of this?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t2fj7", "is_robot_indexable": true, "report_reasons": null, "author": "Meisgoot312", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t2fj7/can_you_keep_files_in_folder_transfers_together/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t2fj7/can_you_keep_files_in_folder_transfers_together/", "subreddit_subscribers": 673509, "created_utc": 1678991904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bought a new 4TB WD My Passport, and the wife dropped it 2 feet before I even used it (though it was unpacked when it fell).\n\nTesting it now, it works great - no noise/clicks, extended WD test pass, SMART pass HD Tune Pro long health scan is also good.\n\nDoes this mean the drive is suitable to use? Or a problem waiting to happen?\n\nEdit: The drive was powered off, it had 0 powered on hours", "author_fullname": "t2_eq1t7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can a portable drive survive a fall?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t1ynl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678994298.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678990845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bought a new 4TB WD My Passport, and the wife dropped it 2 feet before I even used it (though it was unpacked when it fell).&lt;/p&gt;\n\n&lt;p&gt;Testing it now, it works great - no noise/clicks, extended WD test pass, SMART pass HD Tune Pro long health scan is also good.&lt;/p&gt;\n\n&lt;p&gt;Does this mean the drive is suitable to use? Or a problem waiting to happen?&lt;/p&gt;\n\n&lt;p&gt;Edit: The drive was powered off, it had 0 powered on hours&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t1ynl", "is_robot_indexable": true, "report_reasons": null, "author": "Deadpool128", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t1ynl/can_a_portable_drive_survive_a_fall/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t1ynl/can_a_portable_drive_survive_a_fall/", "subreddit_subscribers": 673509, "created_utc": 1678990845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a solution for samba mounts from a remote server that perform poorly over slow wifi (which is understandable). However, writes to those mounts don't need to block applications I think - they could be written to local disk and synced to the remote in the background.\n\nI don't have control over samba server. SyncThing looks great, but I'd rather cache files \"on-demand\" rather than download all (or some of the) folders.\n\nI'm looking at [FS-Cache](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/getting-started-with-fs-cache_managing-file-systems) hoping that it can provide this type of \"write caching\" mechanism.", "author_fullname": "t2_64r00bk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asynchronous Samba mount over slow wifi - can it be written to local disk and synced in the background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t0fpt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678987500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a solution for samba mounts from a remote server that perform poorly over slow wifi (which is understandable). However, writes to those mounts don&amp;#39;t need to block applications I think - they could be written to local disk and synced to the remote in the background.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have control over samba server. SyncThing looks great, but I&amp;#39;d rather cache files &amp;quot;on-demand&amp;quot; rather than download all (or some of the) folders.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at &lt;a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/getting-started-with-fs-cache_managing-file-systems\"&gt;FS-Cache&lt;/a&gt; hoping that it can provide this type of &amp;quot;write caching&amp;quot; mechanism.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j_6JFpTyAb529aFFUtqJLwfG7Nk9HmJZ1fFddzdFZUA.jpg?auto=webp&amp;v=enabled&amp;s=a3039bc3e886c2e0fc3e4ab81d46274fae15fb12", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/j_6JFpTyAb529aFFUtqJLwfG7Nk9HmJZ1fFddzdFZUA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=777068ff10ea15815ed475e98b3e21c64cf17b85", "width": 108, "height": 108}], "variants": {}, "id": "P_zmebI4M-oYdEJfUjUsYDg1AfSpdydL9iAszP40fTE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t0fpt", "is_robot_indexable": true, "report_reasons": null, "author": "danielkraj", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t0fpt/asynchronous_samba_mount_over_slow_wifi_can_it_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t0fpt/asynchronous_samba_mount_over_slow_wifi_can_it_be/", "subreddit_subscribers": 673509, "created_utc": 1678987500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to utilize one of my Samsung T7 SSDs as a hot storage device for some key files and keep it plugged in to my Unraid server as an unassigned device. \n\nAll I know is that it's good to power up SSDs regularly to prevent cells decay.\n\nSo...  it may be a stupid question but is it actually safe, good for the drive, to keep it plugged in for months or years potentially? It doesn't mean it'll active all that time (I'd expect the TBW be stay pretty low). Do SSDs have some kind of \"spin down\" function, like HDDs do, that would prevent key components from wearing down?", "author_fullname": "t2_9ws2pmbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it safe to keep external SSD plugged-in all the time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11svc9g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678976031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to utilize one of my Samsung T7 SSDs as a hot storage device for some key files and keep it plugged in to my Unraid server as an unassigned device. &lt;/p&gt;\n\n&lt;p&gt;All I know is that it&amp;#39;s good to power up SSDs regularly to prevent cells decay.&lt;/p&gt;\n\n&lt;p&gt;So...  it may be a stupid question but is it actually safe, good for the drive, to keep it plugged in for months or years potentially? It doesn&amp;#39;t mean it&amp;#39;ll active all that time (I&amp;#39;d expect the TBW be stay pretty low). Do SSDs have some kind of &amp;quot;spin down&amp;quot; function, like HDDs do, that would prevent key components from wearing down?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11svc9g", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Meet842", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11svc9g/is_it_safe_to_keep_external_ssd_pluggedin_all_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11svc9g/is_it_safe_to_keep_external_ssd_pluggedin_all_the/", "subreddit_subscribers": 673509, "created_utc": 1678976031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello !\n\nI have a 4 nvme enclosure (OWC 4m2 + 4 WD black 2tb sn850x) 8tb capacity. I want maximum speed so I have it set at raid 0. I'm looking for a backup solution in case of failure since raid 0 is not reliable. Maybe these questions are beginner ones so I'm sorry for that.\n\nFirst option would be a single 8tb external HDD. After calculation, if my ssd array dies, I think it could take up to 24 hours to transfer it back to a new array. I'm not shure if having an external drive running for that long would be a good idea.\n\nThe second option would be to get a 2 drives enclosure and 2 4tb HDD and put it in raid 0. The advantage would be speed in case of a recovery and backups would be speedier too. But again reliability.\n\nThe third option would be to again get that 2 hdd enclosure but get 2 8tb drives and put it in raid 1. I wont gain any speed but there would be more reliability.\n\nThe cheapest solution would be of course the single drive but for that of data, I don't know if a single drive would be the most safe solution. I would of course prefer if the cheapest solution would be enough.\n\nWhat do you think ?\n\nThanks", "author_fullname": "t2_xmstz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a backup solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11strnn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678972296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello !&lt;/p&gt;\n\n&lt;p&gt;I have a 4 nvme enclosure (OWC 4m2 + 4 WD black 2tb sn850x) 8tb capacity. I want maximum speed so I have it set at raid 0. I&amp;#39;m looking for a backup solution in case of failure since raid 0 is not reliable. Maybe these questions are beginner ones so I&amp;#39;m sorry for that.&lt;/p&gt;\n\n&lt;p&gt;First option would be a single 8tb external HDD. After calculation, if my ssd array dies, I think it could take up to 24 hours to transfer it back to a new array. I&amp;#39;m not shure if having an external drive running for that long would be a good idea.&lt;/p&gt;\n\n&lt;p&gt;The second option would be to get a 2 drives enclosure and 2 4tb HDD and put it in raid 0. The advantage would be speed in case of a recovery and backups would be speedier too. But again reliability.&lt;/p&gt;\n\n&lt;p&gt;The third option would be to again get that 2 hdd enclosure but get 2 8tb drives and put it in raid 1. I wont gain any speed but there would be more reliability.&lt;/p&gt;\n\n&lt;p&gt;The cheapest solution would be of course the single drive but for that of data, I don&amp;#39;t know if a single drive would be the most safe solution. I would of course prefer if the cheapest solution would be enough.&lt;/p&gt;\n\n&lt;p&gt;What do you think ?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11strnn", "is_robot_indexable": true, "report_reasons": null, "author": "PhilippePaquet", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11strnn/looking_for_a_backup_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11strnn/looking_for_a_backup_solution/", "subreddit_subscribers": 673509, "created_utc": 1678972296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.\n\nI want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.\n\nIs it possible to do with Synology?", "author_fullname": "t2_6c8sl4j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to use one bay of a synology as a separated volume backups of my friend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11tnzul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679051241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.&lt;/p&gt;\n\n&lt;p&gt;I want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to do with Synology?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tnzul", "is_robot_indexable": true, "report_reasons": null, "author": "Bit-Beats", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "subreddit_subscribers": 673509, "created_utc": 1679051241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11tnub1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_11rvc4", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ipfs", "selftext": "Hello All,\n\nWith DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.\n\nTo me, there seems to be a couple straight forward solutions:\n\n* quay.io: open source but still centralized and ran by single for profit\n* Gitlab.com registry: open source but still centralized and ran by single for profit\n* GitHub.com registry: Same boat as DockerHub but larger corporation\n* Running your own personal registry: Additional work for each party involved, low discovery options.\n\nNow with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.\n\nHere some decentralized options and strategies I've found so far:\n\n## nerdctl ipfs support\n\n[nerdctl](https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md) supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn't exactly a cloud native approach (running systemd services on each node...). \n\n## IPDR: InterPlanetary Docker Registry\n\n[IPDR](https://github.com/ipdr/ipdr) is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec\n\n## ociipfs OCI layer to IPFS content translation\n\n[ociipfs](https://github.com/mkmik/ocipfs) this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.\n\n## My thoughts\nIf you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for [BuildKit](https://github.com/moby/buildkit/pull/3510) that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.\n\nThe last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.\n\nLastly, this is just some last minute research on my part and would love to hear more people's thoughts!\n\nEdit 1 some points made in discussion:\n\nHaving a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.\n\n[Gitea](https://nlnet.nl/project/Gitea/) and it's fork [Forgejo](https://forgejo.org/) both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.", "author_fullname": "t2_11rvc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ipfs", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tjca7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679050398.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679035047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;With DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.&lt;/p&gt;\n\n&lt;p&gt;To me, there seems to be a couple straight forward solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;quay.io: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;Gitlab.com registry: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;GitHub.com registry: Same boat as DockerHub but larger corporation&lt;/li&gt;\n&lt;li&gt;Running your own personal registry: Additional work for each party involved, low discovery options.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.&lt;/p&gt;\n\n&lt;p&gt;Here some decentralized options and strategies I&amp;#39;ve found so far:&lt;/p&gt;\n\n&lt;h2&gt;nerdctl ipfs support&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md\"&gt;nerdctl&lt;/a&gt; supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn&amp;#39;t exactly a cloud native approach (running systemd services on each node...). &lt;/p&gt;\n\n&lt;h2&gt;IPDR: InterPlanetary Docker Registry&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ipdr/ipdr\"&gt;IPDR&lt;/a&gt; is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec&lt;/p&gt;\n\n&lt;h2&gt;ociipfs OCI layer to IPFS content translation&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mkmik/ocipfs\"&gt;ociipfs&lt;/a&gt; this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.&lt;/p&gt;\n\n&lt;h2&gt;My thoughts&lt;/h2&gt;\n\n&lt;p&gt;If you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for &lt;a href=\"https://github.com/moby/buildkit/pull/3510\"&gt;BuildKit&lt;/a&gt; that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.&lt;/p&gt;\n\n&lt;p&gt;The last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.&lt;/p&gt;\n\n&lt;p&gt;Lastly, this is just some last minute research on my part and would love to hear more people&amp;#39;s thoughts!&lt;/p&gt;\n\n&lt;p&gt;Edit 1 some points made in discussion:&lt;/p&gt;\n\n&lt;p&gt;Having a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nlnet.nl/project/Gitea/\"&gt;Gitea&lt;/a&gt; and it&amp;#39;s fork &lt;a href=\"https://forgejo.org/\"&gt;Forgejo&lt;/a&gt; both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_34dae", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tjca7", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 14717, "created_utc": 1679035047.0, "num_crossposts": 12, "media": null, "is_video": false}], "created": 1679050817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11tnub1", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11tjca7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnub1/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 673509, "created_utc": 1679050817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to DL entire sites and only download the newer content later on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tahpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tahpv", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "subreddit_subscribers": 673509, "created_utc": 1679010437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. \n\nI\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. \n\nI\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. \n\nI am so excited to get this little project finished, so any and all help is super appreciated.", "author_fullname": "t2_bkmhazam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help picking NVME drives for my NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t8akp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679005468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. &lt;/p&gt;\n\n&lt;p&gt;I am so excited to get this little project finished, so any and all help is super appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t8akp", "is_robot_indexable": true, "report_reasons": null, "author": "MaxBando420", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "subreddit_subscribers": 673509, "created_utc": 1679005468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\n I would like to confirm the sustained sequential write of an nvme Gen4 into a system with gen3 slot. As with transfert on a samsung gen3 970, after 20sec of 3gbps it drop to 1.5gpbs for the rest of time(after 2,4,9min). But for a FireCuda 530 / Adata Legend 960 or Sabrent Rocket 4 : sustained is at 3.8gb for 4min   And the samsung 990 is 1.4gbps.\n\n So with the Firecuda, Adata or Sabrent put into a gen3 slot = will they fully give a continuous sustain speed of about 3.6gbps , maxing out the bus fully ?   .. and then have the best  speed...\n\n&amp;#x200B;\n\nThanks on that", "author_fullname": "t2_2qipul6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using gen4 nvme in gen3 slot for high Sustained transfert speed ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t68qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I would like to confirm the sustained sequential write of an nvme Gen4 into a system with gen3 slot. As with transfert on a samsung gen3 970, after 20sec of 3gbps it drop to 1.5gpbs for the rest of time(after 2,4,9min). But for a FireCuda 530 / Adata Legend 960 or Sabrent Rocket 4 : sustained is at 3.8gb for 4min   And the samsung 990 is 1.4gbps.&lt;/p&gt;\n\n&lt;p&gt;So with the Firecuda, Adata or Sabrent put into a gen3 slot = will they fully give a continuous sustain speed of about 3.6gbps , maxing out the bus fully ?   .. and then have the best  speed...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks on that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t68qw", "is_robot_indexable": true, "report_reasons": null, "author": "Docop1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t68qw/using_gen4_nvme_in_gen3_slot_for_high_sustained/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t68qw/using_gen4_nvme_in_gen3_slot_for_high_sustained/", "subreddit_subscribers": 673509, "created_utc": 1679000692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "THANKFULLY, this wasn't my main server but it was a secondary server that I back the main one up to and it needs fixed ASAP.\n\nIt was a 4U Rosewill server (RSV-L4412U), using a Gigabyte ATX board and a Seasonic power supply. It's been humming along for years with zero problems and then today, the power supply suffered a massive failure. When I shake the ps, there's something lose in there. UPS flipped out, LOUD pop, etc., etc.\n\nI put a new ps in the system and turned it back on to see what all was damaged. While Debian 11 is booting, I see this at the top of the screen for a while:\n\n'mpt2sas\\_cm1: overriding NVDATA EEDPTagMode setting'   ...... but eventually the OS loads and I'm at the desktop.\n\nLooking in the 'Disks' app, I see that my MDADM array is offline (expected because....) of my 11, 8TB drives, only 8 are showing up. I have two, LSI 9207-8i HBA's installed. Card 1 has 2 SFF cables going to it (and controlling a total of 8 drives) and the 2nd card has 1 SFF cable (controlling 3 drives).\n\nAt this point you're probably thinking.....\"well duh, the card with the 3 drives is the culprit\" but that's not so. Because the 3 drives that card 2 is controlling.... 2 of the 3 show up. And on the first card, 2 of the 8 drives it's controlling aren't showing up.\n\nI pulled the drives from their disk trays and checked them individually in a USB dock on another system and the other Linux box was able to see that they're all part of an array so I'm fairly confident (crossing my finders) that the data on them is intact.\n\nAfter some troubleshooting and sitting down to think, I don't believe the motherboard or HBAs are damaged. It's looking more and more like the back plane in the Rosewill is at fault. I think this because as I mentioned above, one of the HBAs can see 2 of its' 3 drives. If the PCI slots were damaged, I don't think EITHER HBA would work or either HBA would see ANY of their attached drives. Sure, I could do some more swapping of cards/drives but I don't want to spend any more time on it and I need to get the backup system up and running fast.\n\nWould appreciate your thoughts on all that but my big question is this..... what's the best way out of this mess?\n\nOption 1. $360 - Buy a new Rosewill RSV-L4412U and a new power supply :) and put everything back together.\n\nOption 2. $219+$80+100=$400 Which is a SuperMicro CSE-846+ 3, quiet, replacement fans (FAN-0104L4)+$100 (or so) for the quiet version of a power supply because stock SuperMicro power supplies are...... noisy. (Any problems with 8TB SATA drives with the SAS826A back plane?)\n\nOption 3. $600 - Buy a CSE-847 (BPN-SAS3-846EL1 back plane). The reason I was thinking of this route is because I currently have 20'ish 4TB drives in my main server and I was thinking about expanding. I like using 4TB drives to reduce resilver times so I could move my existing motherboard into this new unit and take the guts from the Rosewill case and put them in my existing SC-846 chassis. BUT..... the CPU cooler I'm using in my 24 bay SC-846 won't fit in the SC-847 so I'll need a low profile cooler for my i7 7700K so not a huge deal, just mo' money. :(\n\nSo there you have it............ would greatly appreciate any and all comments!", "author_fullname": "t2_amep8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent help and advice needed please, power supply suffered massive failure and now some of my drives are gone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t5sg5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;THANKFULLY, this wasn&amp;#39;t my main server but it was a secondary server that I back the main one up to and it needs fixed ASAP.&lt;/p&gt;\n\n&lt;p&gt;It was a 4U Rosewill server (RSV-L4412U), using a Gigabyte ATX board and a Seasonic power supply. It&amp;#39;s been humming along for years with zero problems and then today, the power supply suffered a massive failure. When I shake the ps, there&amp;#39;s something lose in there. UPS flipped out, LOUD pop, etc., etc.&lt;/p&gt;\n\n&lt;p&gt;I put a new ps in the system and turned it back on to see what all was damaged. While Debian 11 is booting, I see this at the top of the screen for a while:&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;mpt2sas_cm1: overriding NVDATA EEDPTagMode setting&amp;#39;   ...... but eventually the OS loads and I&amp;#39;m at the desktop.&lt;/p&gt;\n\n&lt;p&gt;Looking in the &amp;#39;Disks&amp;#39; app, I see that my MDADM array is offline (expected because....) of my 11, 8TB drives, only 8 are showing up. I have two, LSI 9207-8i HBA&amp;#39;s installed. Card 1 has 2 SFF cables going to it (and controlling a total of 8 drives) and the 2nd card has 1 SFF cable (controlling 3 drives).&lt;/p&gt;\n\n&lt;p&gt;At this point you&amp;#39;re probably thinking.....&amp;quot;well duh, the card with the 3 drives is the culprit&amp;quot; but that&amp;#39;s not so. Because the 3 drives that card 2 is controlling.... 2 of the 3 show up. And on the first card, 2 of the 8 drives it&amp;#39;s controlling aren&amp;#39;t showing up.&lt;/p&gt;\n\n&lt;p&gt;I pulled the drives from their disk trays and checked them individually in a USB dock on another system and the other Linux box was able to see that they&amp;#39;re all part of an array so I&amp;#39;m fairly confident (crossing my finders) that the data on them is intact.&lt;/p&gt;\n\n&lt;p&gt;After some troubleshooting and sitting down to think, I don&amp;#39;t believe the motherboard or HBAs are damaged. It&amp;#39;s looking more and more like the back plane in the Rosewill is at fault. I think this because as I mentioned above, one of the HBAs can see 2 of its&amp;#39; 3 drives. If the PCI slots were damaged, I don&amp;#39;t think EITHER HBA would work or either HBA would see ANY of their attached drives. Sure, I could do some more swapping of cards/drives but I don&amp;#39;t want to spend any more time on it and I need to get the backup system up and running fast.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate your thoughts on all that but my big question is this..... what&amp;#39;s the best way out of this mess?&lt;/p&gt;\n\n&lt;p&gt;Option 1. $360 - Buy a new Rosewill RSV-L4412U and a new power supply :) and put everything back together.&lt;/p&gt;\n\n&lt;p&gt;Option 2. $219+$80+100=$400 Which is a SuperMicro CSE-846+ 3, quiet, replacement fans (FAN-0104L4)+$100 (or so) for the quiet version of a power supply because stock SuperMicro power supplies are...... noisy. (Any problems with 8TB SATA drives with the SAS826A back plane?)&lt;/p&gt;\n\n&lt;p&gt;Option 3. $600 - Buy a CSE-847 (BPN-SAS3-846EL1 back plane). The reason I was thinking of this route is because I currently have 20&amp;#39;ish 4TB drives in my main server and I was thinking about expanding. I like using 4TB drives to reduce resilver times so I could move my existing motherboard into this new unit and take the guts from the Rosewill case and put them in my existing SC-846 chassis. BUT..... the CPU cooler I&amp;#39;m using in my 24 bay SC-846 won&amp;#39;t fit in the SC-847 so I&amp;#39;ll need a low profile cooler for my i7 7700K so not a huge deal, just mo&amp;#39; money. :(&lt;/p&gt;\n\n&lt;p&gt;So there you have it............ would greatly appreciate any and all comments!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t5sg5", "is_robot_indexable": true, "report_reasons": null, "author": "road_hazard", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t5sg5/urgent_help_and_advice_needed_please_power_supply/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t5sg5/urgent_help_and_advice_needed_please_power_supply/", "subreddit_subscribers": 673509, "created_utc": 1678999652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anybody have a fix to why it only downloads 40 images when i try to download 250? I put the settings to allow it at about 300 but it still decides to download only 40. I couldn't find anywhere an answer...", "author_fullname": "t2_4hzbvtau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About Bulk Image Downloader", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3mff", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678994629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody have a fix to why it only downloads 40 images when i try to download 250? I put the settings to allow it at about 300 but it still decides to download only 40. I couldn&amp;#39;t find anywhere an answer...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t3mff", "is_robot_indexable": true, "report_reasons": null, "author": "Zlatevlad", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t3mff/about_bulk_image_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t3mff/about_bulk_image_downloader/", "subreddit_subscribers": 673509, "created_utc": 1678994629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I\u2019m having a lot of trouble downloading the lectures on Teams. \n\nI tried ffmpeg, destreamer but every time I get invalid url.\n\nI followed every guide available, got the manifest url, but still gave me an error. Tried with MacOS on M1, Windows 7 on x86, OS X 10.9.\n\nI can\u2019t download.\n\nIf anyone can help me, it would mean a lot to me", "author_fullname": "t2_nj3wh15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Teams Videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t1veg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678990640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m having a lot of trouble downloading the lectures on Teams. &lt;/p&gt;\n\n&lt;p&gt;I tried ffmpeg, destreamer but every time I get invalid url.&lt;/p&gt;\n\n&lt;p&gt;I followed every guide available, got the manifest url, but still gave me an error. Tried with MacOS on M1, Windows 7 on x86, OS X 10.9.&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t download.&lt;/p&gt;\n\n&lt;p&gt;If anyone can help me, it would mean a lot to me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t1veg", "is_robot_indexable": true, "report_reasons": null, "author": "XD_avide", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t1veg/microsoft_teams_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t1veg/microsoft_teams_videos/", "subreddit_subscribers": 673509, "created_utc": 1678990640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't have a NAS but now a small hoard of external drives 4x18tb.  I haven't decided on my backup strategy but let's say I can easily fill up 2x18tb with my archives.  \n\nI'm looking at using remote storage as another backup method.  I'm not overly concerned with Google/etc seeing my data as it's encrypted and and sharded basically making it opaque.  \n\nI've looked at Yandex lately as a solution.  Is anyone using it currently and if so what has been your experience?  I don't want to touch Wasabi as I've had a lot of failures with them.  Any thoughts on this one?", "author_fullname": "t2_vrtzqi2l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating cloud storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sz1m1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678984477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have a NAS but now a small hoard of external drives 4x18tb.  I haven&amp;#39;t decided on my backup strategy but let&amp;#39;s say I can easily fill up 2x18tb with my archives.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at using remote storage as another backup method.  I&amp;#39;m not overly concerned with Google/etc seeing my data as it&amp;#39;s encrypted and and sharded basically making it opaque.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at Yandex lately as a solution.  Is anyone using it currently and if so what has been your experience?  I don&amp;#39;t want to touch Wasabi as I&amp;#39;ve had a lot of failures with them.  Any thoughts on this one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11sz1m1", "is_robot_indexable": true, "report_reasons": null, "author": "EssayOk6358", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11sz1m1/evaluating_cloud_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11sz1m1/evaluating_cloud_storage/", "subreddit_subscribers": 673509, "created_utc": 1678984477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Cinematographer and video production company owner here. Starting to get overwhelmed with drives and data need some advice on building a 60tb ish NAS. \n\nKey thing I would like to achieve:\n1. Cloud storage. I currently pay for G Drive and WeTransfer, I would love to be able to access my new NAS from the cloud, and use it to share links with clients. \n\n2. Editable. I shoot mostly in Canon RAW and Arriraw, so it would be great if I could actually edit straight off the NAS. One caveat, my house is wired with cat5e, but I am wondering if there is a way to do DAS between my workstation and the NAS with a 10 gigabit NIC, and then gigabit to the internet and other machines on my network. \n\n3. Cost effective, to an extent. I have 2k soft budgeted for this project, so I'm wondering if there is a spinning disk solution with big caching power that can keep my cost down but still editable? Tell me your thoughts. \n\n4. Ideally, I can use some of my existing hardware. I have an i7-2600k gathering dust with 24gb of ram, an r9 270 and a 650w 80plus gold PSU. Is this any good for this application, or should I get something better?\n\nLooking for any advice on drives, configurations software etc. Have you built a system that kind of fits this setup? Tell me about it!\n\nTldr: need to build a cloud server at home that I can edit off of for a reasonable price.", "author_fullname": "t2_yl48d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some NAS Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sysbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678983907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Cinematographer and video production company owner here. Starting to get overwhelmed with drives and data need some advice on building a 60tb ish NAS. &lt;/p&gt;\n\n&lt;p&gt;Key thing I would like to achieve:\n1. Cloud storage. I currently pay for G Drive and WeTransfer, I would love to be able to access my new NAS from the cloud, and use it to share links with clients. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Editable. I shoot mostly in Canon RAW and Arriraw, so it would be great if I could actually edit straight off the NAS. One caveat, my house is wired with cat5e, but I am wondering if there is a way to do DAS between my workstation and the NAS with a 10 gigabit NIC, and then gigabit to the internet and other machines on my network. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Cost effective, to an extent. I have 2k soft budgeted for this project, so I&amp;#39;m wondering if there is a spinning disk solution with big caching power that can keep my cost down but still editable? Tell me your thoughts. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Ideally, I can use some of my existing hardware. I have an i7-2600k gathering dust with 24gb of ram, an r9 270 and a 650w 80plus gold PSU. Is this any good for this application, or should I get something better?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Looking for any advice on drives, configurations software etc. Have you built a system that kind of fits this setup? Tell me about it!&lt;/p&gt;\n\n&lt;p&gt;Tldr: need to build a cloud server at home that I can edit off of for a reasonable price.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11sysbc", "is_robot_indexable": true, "report_reasons": null, "author": "dutche99", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11sysbc/need_some_nas_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11sysbc/need_some_nas_advice/", "subreddit_subscribers": 673509, "created_utc": 1678983907.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}