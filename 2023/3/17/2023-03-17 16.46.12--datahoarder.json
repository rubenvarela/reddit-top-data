{"kind": "Listing", "data": {"after": "t3_11t5sg5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he's here lol). \n\nMy friend is into retro game preservation and it just reminded me of him.", "author_fullname": "t2_g4f3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is the guy who is trying to download every single game?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11toc7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 208, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 208, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679052290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he&amp;#39;s here lol). &lt;/p&gt;\n\n&lt;p&gt;My friend is into retro game preservation and it just reminded me of him.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11toc7v", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveChairs", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "subreddit_subscribers": 673510, "created_utc": 1679052290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI hope you're all well,\n\nI'm incredibly interested in what happened to Mega. Who owns it now? Kim Dotcom claims that the NZ government own it [here](https://yro.slashdot.org/story/15/07/27/200204/interviews-kim-dotcom-answers-your-questions):\n\n' I'm not involved in Mega anymore. Neither in a managing nor in a shareholder capacity. The company has suffered from a hostile takeover by a Chinese investor who is wanted in China for fraud. He used a number of straw-men and businesses to accumulate more and more Mega shares. Recently his shares have been seized by the NZ government. Which means the NZ government is in control.'\n\nBut do they really? The company lists the various roles on their website, but does anyone know who really owns the service now?\n\nI admire the company for doing zero knowledge encryption, however, I would like to know who owns the company so that I can gauge them as a person or group. I need to be sure that my data is secure and private.\n\nI have trust in Kim Dotcom because I know he deeply believes in freedom and privacy and has demonstrated that through his actions over the years. He's openly said he distrusts MEGA now. I think the fact that the owner of the company doesn't seem to be public information is a bit of a red flag for me. But I would like to see for myself.\n\nMEGA has a great Linux client it seems, which Dropbox certainly does not, so I am considering a migration, however, I would like to know who owns the company so I can gauge how much trust I should put in it.\n\nMany thanks in advance :)", "author_fullname": "t2_u3bzwcsd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who owns Mega now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3hqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678997421.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678994329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all well,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m incredibly interested in what happened to Mega. Who owns it now? Kim Dotcom claims that the NZ government own it &lt;a href=\"https://yro.slashdot.org/story/15/07/27/200204/interviews-kim-dotcom-answers-your-questions\"&gt;here&lt;/a&gt;:&lt;/p&gt;\n\n&lt;p&gt;&amp;#39; I&amp;#39;m not involved in Mega anymore. Neither in a managing nor in a shareholder capacity. The company has suffered from a hostile takeover by a Chinese investor who is wanted in China for fraud. He used a number of straw-men and businesses to accumulate more and more Mega shares. Recently his shares have been seized by the NZ government. Which means the NZ government is in control.&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;But do they really? The company lists the various roles on their website, but does anyone know who really owns the service now?&lt;/p&gt;\n\n&lt;p&gt;I admire the company for doing zero knowledge encryption, however, I would like to know who owns the company so that I can gauge them as a person or group. I need to be sure that my data is secure and private.&lt;/p&gt;\n\n&lt;p&gt;I have trust in Kim Dotcom because I know he deeply believes in freedom and privacy and has demonstrated that through his actions over the years. He&amp;#39;s openly said he distrusts MEGA now. I think the fact that the owner of the company doesn&amp;#39;t seem to be public information is a bit of a red flag for me. But I would like to see for myself.&lt;/p&gt;\n\n&lt;p&gt;MEGA has a great Linux client it seems, which Dropbox certainly does not, so I am considering a migration, however, I would like to know who owns the company so I can gauge how much trust I should put in it.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BAPvmcnMj-DMmgQcRsE6pa0T1EG7NXU1hR8T55UrDzM.jpg?auto=webp&amp;v=enabled&amp;s=71e98b037b48a6176dd4ce8c61462ffc03adfaa5", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "_j1MTgi3ZN4ckSmdak5zroJ-Cq0PzLPGJlMjCJvUPQs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t3hqh", "is_robot_indexable": true, "report_reasons": null, "author": "Gloriouscal9001", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t3hqh/who_owns_mega_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t3hqh/who_owns_mega_now/", "subreddit_subscribers": 673510, "created_utc": 1678994329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "basically to use them for a media server NAS, and I have found very good options on ebay.\n\nIt is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.", "author_fullname": "t2_6hxjwymn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth buying used hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11taniw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;basically to use them for a media server NAS, and I have found very good options on ebay.&lt;/p&gt;\n\n&lt;p&gt;It is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11taniw", "is_robot_indexable": true, "report_reasons": null, "author": "AngelGrade", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "subreddit_subscribers": 673510, "created_utc": 1679010838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.youtube.com/watch?v=Jqg1G78cH2A](https://www.youtube.com/watch?v=Jqg1G78cH2A)", "author_fullname": "t2_twm9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level 1 Techs take on Home Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tklqs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679039756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=Jqg1G78cH2A\"&gt;https://www.youtube.com/watch?v=Jqg1G78cH2A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?auto=webp&amp;v=enabled&amp;s=e10203b6f26b668551d1bf3bfa0ade3d815217bc", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eef7149926b12a2a271680da9e54badc728f73", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a2f22518553258836e69a6d5c85158f1db9c269", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba2226fc27492309a02fc71d9fda027f75e56d4c", "width": 320, "height": 240}], "variants": {}, "id": "gPB9teADkSdeoYYiYccNMY4LdCypTI_dFt6qjnKE2BY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "103TB - Keep on Shucking....", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tklqs", "is_robot_indexable": true, "report_reasons": null, "author": "Graham2405", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "subreddit_subscribers": 673510, "created_utc": 1679039756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tdbsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_56nr0oo0", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskReddit", "selftext": "", "author_fullname": "t2_56nr0oo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskReddit", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11td7zc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679016585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh1i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11td7zc", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 40232434, "created_utc": 1679016585.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679016871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tdbsu", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11td7zc", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tdbsu/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 673510, "created_utc": 1679016871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.\n\nI want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.\n\nIs it possible to do with Synology?", "author_fullname": "t2_6c8sl4j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to use one bay of a synology as a separated volume backups of my friend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tnzul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679051241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.&lt;/p&gt;\n\n&lt;p&gt;I want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to do with Synology?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tnzul", "is_robot_indexable": true, "report_reasons": null, "author": "Bit-Beats", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "subreddit_subscribers": 673510, "created_utc": 1679051241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tnub1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_11rvc4", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ipfs", "selftext": "Hello All,\n\nWith DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.\n\nTo me, there seems to be a couple straight forward solutions:\n\n* quay.io: open source but still centralized and ran by single for profit\n* Gitlab.com registry: open source but still centralized and ran by single for profit\n* GitHub.com registry: Same boat as DockerHub but larger corporation\n* Running your own personal registry: Additional work for each party involved, low discovery options.\n\nNow with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.\n\nHere some decentralized options and strategies I've found so far:\n\n## nerdctl ipfs support\n\n[nerdctl](https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md) supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn't exactly a cloud native approach (running systemd services on each node...). \n\n## IPDR: InterPlanetary Docker Registry\n\n[IPDR](https://github.com/ipdr/ipdr) is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec\n\n## ociipfs OCI layer to IPFS content translation\n\n[ociipfs](https://github.com/mkmik/ocipfs) this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.\n\n## My thoughts\nIf you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for [BuildKit](https://github.com/moby/buildkit/pull/3510) that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.\n\nThe last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.\n\nLastly, this is just some last minute research on my part and would love to hear more people's thoughts!\n\nEdit 1 some points made in discussion:\n\nHaving a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.\n\n[Gitea](https://nlnet.nl/project/Gitea/) and it's fork [Forgejo](https://forgejo.org/) both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.", "author_fullname": "t2_11rvc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ipfs", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tjca7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679050398.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679035047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;With DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.&lt;/p&gt;\n\n&lt;p&gt;To me, there seems to be a couple straight forward solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;quay.io: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;Gitlab.com registry: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;GitHub.com registry: Same boat as DockerHub but larger corporation&lt;/li&gt;\n&lt;li&gt;Running your own personal registry: Additional work for each party involved, low discovery options.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.&lt;/p&gt;\n\n&lt;p&gt;Here some decentralized options and strategies I&amp;#39;ve found so far:&lt;/p&gt;\n\n&lt;h2&gt;nerdctl ipfs support&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md\"&gt;nerdctl&lt;/a&gt; supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn&amp;#39;t exactly a cloud native approach (running systemd services on each node...). &lt;/p&gt;\n\n&lt;h2&gt;IPDR: InterPlanetary Docker Registry&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ipdr/ipdr\"&gt;IPDR&lt;/a&gt; is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec&lt;/p&gt;\n\n&lt;h2&gt;ociipfs OCI layer to IPFS content translation&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mkmik/ocipfs\"&gt;ociipfs&lt;/a&gt; this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.&lt;/p&gt;\n\n&lt;h2&gt;My thoughts&lt;/h2&gt;\n\n&lt;p&gt;If you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for &lt;a href=\"https://github.com/moby/buildkit/pull/3510\"&gt;BuildKit&lt;/a&gt; that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.&lt;/p&gt;\n\n&lt;p&gt;The last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.&lt;/p&gt;\n\n&lt;p&gt;Lastly, this is just some last minute research on my part and would love to hear more people&amp;#39;s thoughts!&lt;/p&gt;\n\n&lt;p&gt;Edit 1 some points made in discussion:&lt;/p&gt;\n\n&lt;p&gt;Having a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nlnet.nl/project/Gitea/\"&gt;Gitea&lt;/a&gt; and it&amp;#39;s fork &lt;a href=\"https://forgejo.org/\"&gt;Forgejo&lt;/a&gt; both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_34dae", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tjca7", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 14721, "created_utc": 1679035047.0, "num_crossposts": 12, "media": null, "is_video": false}], "created": 1679050817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11tnub1", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11tjca7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnub1/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 673510, "created_utc": 1679050817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What I need to do is quite easy, but I dont know which tools to use or how to do it with said tools:\n\nWhat I need: I want to find files with similar name. The names are almost the same but the end of some of them has a suffix, for example **video.mp4** and **video-compressed.mp4**. The first one is a higher resolution and the 2nd one was compressed and named by adding the **-compressed** part.\n\nI need something that will show me when both files exist, the **\\*.\\*** one and the **\\*-compressed.\\*** one.\n\nI tried Voidools Everything, Fast Duplicate File Finder and Czkawka but cant seems to create a filter or a search that will do the trick.\n\nAnyone more intelligent than me want to chip in?\n\nThanks in advance!", "author_fullname": "t2_bs3r2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to find similar filenames...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t410y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678995593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What I need to do is quite easy, but I dont know which tools to use or how to do it with said tools:&lt;/p&gt;\n\n&lt;p&gt;What I need: I want to find files with similar name. The names are almost the same but the end of some of them has a suffix, for example &lt;strong&gt;video.mp4&lt;/strong&gt; and &lt;strong&gt;video-compressed.mp4&lt;/strong&gt;. The first one is a higher resolution and the 2nd one was compressed and named by adding the &lt;strong&gt;-compressed&lt;/strong&gt; part.&lt;/p&gt;\n\n&lt;p&gt;I need something that will show me when both files exist, the &lt;strong&gt;*.\\&lt;/strong&gt;* one and the &lt;strong&gt;*-compressed.\\&lt;/strong&gt;* one.&lt;/p&gt;\n\n&lt;p&gt;I tried Voidools Everything, Fast Duplicate File Finder and Czkawka but cant seems to create a filter or a search that will do the trick.&lt;/p&gt;\n\n&lt;p&gt;Anyone more intelligent than me want to chip in?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t410y", "is_robot_indexable": true, "report_reasons": null, "author": "Namaperv", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t410y/need_to_find_similar_filenames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t410y/need_to_find_similar_filenames/", "subreddit_subscribers": 673510, "created_utc": 1678995593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bought a new 4TB WD My Passport, and the wife dropped it 2 feet before I even used it (though it was unpacked when it fell).\n\nTesting it now, it works great - no noise/clicks, extended WD test pass, SMART pass HD Tune Pro long health scan is also good.\n\nDoes this mean the drive is suitable to use? Or a problem waiting to happen?\n\nEdit: The drive was powered off, it had 0 powered on hours", "author_fullname": "t2_eq1t7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can a portable drive survive a fall?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t1ynl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678994298.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678990845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bought a new 4TB WD My Passport, and the wife dropped it 2 feet before I even used it (though it was unpacked when it fell).&lt;/p&gt;\n\n&lt;p&gt;Testing it now, it works great - no noise/clicks, extended WD test pass, SMART pass HD Tune Pro long health scan is also good.&lt;/p&gt;\n\n&lt;p&gt;Does this mean the drive is suitable to use? Or a problem waiting to happen?&lt;/p&gt;\n\n&lt;p&gt;Edit: The drive was powered off, it had 0 powered on hours&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t1ynl", "is_robot_indexable": true, "report_reasons": null, "author": "Deadpool128", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t1ynl/can_a_portable_drive_survive_a_fall/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t1ynl/can_a_portable_drive_survive_a_fall/", "subreddit_subscribers": 673510, "created_utc": 1678990845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After searching all of the internet, I believe this has become my last bastion of hope for some support. I've never posted here, but have followed many users and appreciated much of the advice shared here. However, I am now in need of help. I have email Areca, called every distributer that would take my call, read every FAQ, support page, YouTube video, and any other media I could find, all to no avail.\n\nMy array has been online since July of 2022. It a Areca 8050T3U-8 with 8 - Seagate Exos X18 18TB 7200RPM. The drives are renewed, but all of them reported fine when I bought them.\n\nThe array is connected via Thunderbolt 4 to a new\u00a0 computer build I finished around a month ago and worked fine. I also still have my old computer build, which was TB3, and it worked fine there as well. I have not updated any software, firmware, or anything prior to this issue arising, but since have updated windows and my motherboard bios.\n\nThe issue:\n\nWhile video editing from the array, I noticed that a single frame was reporting \"media offline\" in my timeline. I thought it was just a bug, but I then noticed the rest of the timeline was now not accessible (was fine before). The software then crashed.\u00a0\n\nUpon restarting the program, the same error persisted. I opened a previous project I had edited to test the array but it too, would not open. No files on the array worked, but I could still see the file tree in file explorer. I accessed the raid volume in file explorer and everything looked fine but at some point, if I clicked on folder it would give the \"this no longer exist\" error.\n\nI opened ArchTTP and ArcSAP and the array reported normal there. No drive failures, errors, or anything.\u00a0Still, I have no logs saying there is any issue besides a few times where Windows reports a \"fatal device error\" when the array locks up.\n\nWhenever I accessed a file, the screen on the front turned off and the activity lights went blue. I restarted my computer and the error persisted. I unplugged the thunderbolt cable (since my array does not have a power button) and that also did nothing (this something areca advised before). On startup, I notice the disk in the array spin up, then begin to stop, then spin up again, and begin to stop again, with the LED quickly turning on orange the red, then turning off.\u00a0This is new behavior.\n\nThe PC takes much longer to post than it normally does (the screen is black with a white bar \\_ on the top left. I have ran SFC scan and it found and issue and repaired it, but the issue remain. After some time the lights on the array cut on, it goes through it's startup sequence, and everything is green. It just goes offline if I read from it. The data is there. At times, it can transfer files for 30 seconds, other times, 10 minutes, other times, less than a second.\n\nI was able to hook up the array to my old desktop where I had some empty fast storage. I could get it to transfer files for a little bit, then it would fail so I would unplug the thunderbolt, plug it back in, wait for the drives to initialize, then tell windows to try again and it would work until it happened again. I sat there transferring 6Tb of wedding footage doing this cycle until it was all off. The data seems fine? So I guess that is good at least.\n\nCurrently, the array is \"online\" as I can access ArchTTP and can see it in file explorer with all my files and folders. But whenever I access a file, like a video to watch, the array the lights go to blue, screen cuts off, and I can access nothing.\u00a0 At times, all the lights go blue, or just a few go blue and some are green, but there is no pattern.\n\nConnecting via USB C to USB A does not help, repairing thunderbolt drivers does not help, different cables do not help. I have done the reset where you unplug everything, connect power and then hold the reset button, let it power on and setup, then reset it again to turn it off, but that also did not work.\n\n\u00a0Please advise on what I can do because currently, I am out of work with the array offline. I have three brides waiting for the wedding video and I am freaking out a little because I have no way to edit them. Most of the footage is stored on slow external drives now, but several of the projects are 2-3Tb which is larger than my fastest SSD.\n\nIf you can help, I am beyond thankful, if not I understand and apologize\u00a0for wasting your time.\u00a0", "author_fullname": "t2_176q7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Areca 8050T3U-8 DAS has suddenly stopped working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11syx6n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678984211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After searching all of the internet, I believe this has become my last bastion of hope for some support. I&amp;#39;ve never posted here, but have followed many users and appreciated much of the advice shared here. However, I am now in need of help. I have email Areca, called every distributer that would take my call, read every FAQ, support page, YouTube video, and any other media I could find, all to no avail.&lt;/p&gt;\n\n&lt;p&gt;My array has been online since July of 2022. It a Areca 8050T3U-8 with 8 - Seagate Exos X18 18TB 7200RPM. The drives are renewed, but all of them reported fine when I bought them.&lt;/p&gt;\n\n&lt;p&gt;The array is connected via Thunderbolt 4 to a new\u00a0 computer build I finished around a month ago and worked fine. I also still have my old computer build, which was TB3, and it worked fine there as well. I have not updated any software, firmware, or anything prior to this issue arising, but since have updated windows and my motherboard bios.&lt;/p&gt;\n\n&lt;p&gt;The issue:&lt;/p&gt;\n\n&lt;p&gt;While video editing from the array, I noticed that a single frame was reporting &amp;quot;media offline&amp;quot; in my timeline. I thought it was just a bug, but I then noticed the rest of the timeline was now not accessible (was fine before). The software then crashed.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Upon restarting the program, the same error persisted. I opened a previous project I had edited to test the array but it too, would not open. No files on the array worked, but I could still see the file tree in file explorer. I accessed the raid volume in file explorer and everything looked fine but at some point, if I clicked on folder it would give the &amp;quot;this no longer exist&amp;quot; error.&lt;/p&gt;\n\n&lt;p&gt;I opened ArchTTP and ArcSAP and the array reported normal there. No drive failures, errors, or anything.\u00a0Still, I have no logs saying there is any issue besides a few times where Windows reports a &amp;quot;fatal device error&amp;quot; when the array locks up.&lt;/p&gt;\n\n&lt;p&gt;Whenever I accessed a file, the screen on the front turned off and the activity lights went blue. I restarted my computer and the error persisted. I unplugged the thunderbolt cable (since my array does not have a power button) and that also did nothing (this something areca advised before). On startup, I notice the disk in the array spin up, then begin to stop, then spin up again, and begin to stop again, with the LED quickly turning on orange the red, then turning off.\u00a0This is new behavior.&lt;/p&gt;\n\n&lt;p&gt;The PC takes much longer to post than it normally does (the screen is black with a white bar _ on the top left. I have ran SFC scan and it found and issue and repaired it, but the issue remain. After some time the lights on the array cut on, it goes through it&amp;#39;s startup sequence, and everything is green. It just goes offline if I read from it. The data is there. At times, it can transfer files for 30 seconds, other times, 10 minutes, other times, less than a second.&lt;/p&gt;\n\n&lt;p&gt;I was able to hook up the array to my old desktop where I had some empty fast storage. I could get it to transfer files for a little bit, then it would fail so I would unplug the thunderbolt, plug it back in, wait for the drives to initialize, then tell windows to try again and it would work until it happened again. I sat there transferring 6Tb of wedding footage doing this cycle until it was all off. The data seems fine? So I guess that is good at least.&lt;/p&gt;\n\n&lt;p&gt;Currently, the array is &amp;quot;online&amp;quot; as I can access ArchTTP and can see it in file explorer with all my files and folders. But whenever I access a file, like a video to watch, the array the lights go to blue, screen cuts off, and I can access nothing.\u00a0 At times, all the lights go blue, or just a few go blue and some are green, but there is no pattern.&lt;/p&gt;\n\n&lt;p&gt;Connecting via USB C to USB A does not help, repairing thunderbolt drivers does not help, different cables do not help. I have done the reset where you unplug everything, connect power and then hold the reset button, let it power on and setup, then reset it again to turn it off, but that also did not work.&lt;/p&gt;\n\n&lt;p&gt;\u00a0Please advise on what I can do because currently, I am out of work with the array offline. I have three brides waiting for the wedding video and I am freaking out a little because I have no way to edit them. Most of the footage is stored on slow external drives now, but several of the projects are 2-3Tb which is larger than my fastest SSD.&lt;/p&gt;\n\n&lt;p&gt;If you can help, I am beyond thankful, if not I understand and apologize\u00a0for wasting your time.\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11syx6n", "is_robot_indexable": true, "report_reasons": null, "author": "CrossAerial", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11syx6n/areca_8050t3u8_das_has_suddenly_stopped_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11syx6n/areca_8050t3u8_das_has_suddenly_stopped_working/", "subreddit_subscribers": 673510, "created_utc": 1678984211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently I have an 8tb usb external drive hooked up to my router, and while it works, its really only good for backups, as the USB speeds is its limiting factor. Its unbearably slow, and if I want to edit any photos, I have to transfer them to my computer first, edit, then transfer them back.\n\nWhat I'm wanting to do:\n\n- Media storage ( movies, photos, etc ) with a connection that is at least fast enough to edit photos off of. \n\n- Accessible from my local network, and it would be amazing if I were able to access it from anywhere.\n\n- I don't mind paying for software, but I absolutely don't want any subscription cost. \n\n- Must be windows/osx compatible. \n\n- At least 2 drive spaces, 4 is ideal but may be beyond budget. Say a budget of $400 max. ( excluding drives ) \n\n\n-----\n\nShould I just buy a simple pre-built nas system? ( and if so, what should I get? )\n\nor should I look into buying a used PC and turning it into a nas? ( i'd love to build an itx system, but that would be way beyond my budget ) \n\nThanks", "author_fullname": "t2_s661yw6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to buy/build a NAS system. suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11tt931", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679064745.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679064563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I have an 8tb usb external drive hooked up to my router, and while it works, its really only good for backups, as the USB speeds is its limiting factor. Its unbearably slow, and if I want to edit any photos, I have to transfer them to my computer first, edit, then transfer them back.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m wanting to do:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Media storage ( movies, photos, etc ) with a connection that is at least fast enough to edit photos off of. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Accessible from my local network, and it would be amazing if I were able to access it from anywhere.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I don&amp;#39;t mind paying for software, but I absolutely don&amp;#39;t want any subscription cost. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Must be windows/osx compatible. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;At least 2 drive spaces, 4 is ideal but may be beyond budget. Say a budget of $400 max. ( excluding drives ) &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Should I just buy a simple pre-built nas system? ( and if so, what should I get? )&lt;/p&gt;\n\n&lt;p&gt;or should I look into buying a used PC and turning it into a nas? ( i&amp;#39;d love to build an itx system, but that would be way beyond my budget ) &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tt931", "is_robot_indexable": true, "report_reasons": null, "author": "boobumblebee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tt931/i_want_to_buybuild_a_nas_system_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tt931/i_want_to_buybuild_a_nas_system_suggestions/", "subreddit_subscribers": 673510, "created_utc": 1679064563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been beating my brains out trying to figure this out. Most of the documentation is more technical than what I understand. However , as far as I can tell , the following powershell commands SHOULD work to create a tiered Storage Space. However, it fails on line 16 ( New-StorageTier command ).\n\n  Set-PhysicalDisk -FriendlyName \"HPT Disk 0\\_0\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_1\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_2\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_3\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_4\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_5\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_6\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_7\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_8\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_9\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_10\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_11\" -MediaType HDD\n\nGet-PhysicalDisk -CanPool $True | Format-Table -Property FriendlyName, OperationalStatus, Size, MediaType\n\n$storage = Get-StorageSubSystem\n\nNew-StoragePool -StorageSubSystemId $storage.UniqueId -FriendlyName Pool -PhysicalDisks (Get-PhysicalDisk -CanPool $true)\n\nGet-StoragePool Pool | New-StorageTier \u2013FriendlyName SSD \u2013MediaType SSD\n\nGet-StoragePool Pool | New-StorageTier \u2013FriendlyName HDD \u2013MediaType HDD\n\nGet-StoragePool Pool | Set-ResiliencySetting -Name Simple -NumberOfColumnsDefault 3\n\n$SSD = Get-StorageTier -FriendlyName SSD $HDD = Get-StorageTier -FriendlyName HDD\n\nGet-StoragePool Pool | New-VirtualDisk -FriendlyName Space -ResiliencySettingName Simple \u2013StorageTiers $SSD, $HDD -StorageTierSizes 900GB, 3.55TB -WriteCacheSize 25GB\n\n&amp;#x200B;\n\nThe error it gives is New-StorageTier: A positional parameter cannot be found that accepts argument 'SSD'.\n\nLine 18 also throws an error saying Friendlyname is specified more than once and to use Array syntax to provide multiple values.\n\nThe goal is to have the HDD's in a simple Storage Space ( fast reads , this PC is used mostly for gaming , although I do some geneology stuff too , lots of family pictures. ), backed by a fast SSD tier .\n\nI do daily backups , so redundancy isn't an issue ( although I wouldn't be adverse to using this as a parity space if I would lose less capacity than a 2 way mirror space).\n\n&amp;#x200B;\n\nAny idea why it fails ? Is there a better script to use to accomplish this ?\n\n  I'm using Windows 11 Pro for Workstations", "author_fullname": "t2_h2mbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help figuring out why creating a storage space fails,", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11trrnc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679061262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been beating my brains out trying to figure this out. Most of the documentation is more technical than what I understand. However , as far as I can tell , the following powershell commands SHOULD work to create a tiered Storage Space. However, it fails on line 16 ( New-StorageTier command ).&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_0&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_1&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_2&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_3&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_4&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_5&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_6&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_7&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_8&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_9&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_10&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_11&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Get-PhysicalDisk -CanPool $True | Format-Table -Property FriendlyName, OperationalStatus, Size, MediaType&lt;/p&gt;\n\n&lt;p&gt;$storage = Get-StorageSubSystem&lt;/p&gt;\n\n&lt;p&gt;New-StoragePool -StorageSubSystemId $storage.UniqueId -FriendlyName Pool -PhysicalDisks (Get-PhysicalDisk -CanPool $true)&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-StorageTier \u2013FriendlyName SSD \u2013MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-StorageTier \u2013FriendlyName HDD \u2013MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | Set-ResiliencySetting -Name Simple -NumberOfColumnsDefault 3&lt;/p&gt;\n\n&lt;p&gt;$SSD = Get-StorageTier -FriendlyName SSD $HDD = Get-StorageTier -FriendlyName HDD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-VirtualDisk -FriendlyName Space -ResiliencySettingName Simple \u2013StorageTiers $SSD, $HDD -StorageTierSizes 900GB, 3.55TB -WriteCacheSize 25GB&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The error it gives is New-StorageTier: A positional parameter cannot be found that accepts argument &amp;#39;SSD&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;Line 18 also throws an error saying Friendlyname is specified more than once and to use Array syntax to provide multiple values.&lt;/p&gt;\n\n&lt;p&gt;The goal is to have the HDD&amp;#39;s in a simple Storage Space ( fast reads , this PC is used mostly for gaming , although I do some geneology stuff too , lots of family pictures. ), backed by a fast SSD tier .&lt;/p&gt;\n\n&lt;p&gt;I do daily backups , so redundancy isn&amp;#39;t an issue ( although I wouldn&amp;#39;t be adverse to using this as a parity space if I would lose less capacity than a 2 way mirror space).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any idea why it fails ? Is there a better script to use to accomplish this ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Windows 11 Pro for Workstations&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11trrnc", "is_robot_indexable": true, "report_reasons": null, "author": "goobermatic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11trrnc/help_figuring_out_why_creating_a_storage_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11trrnc/help_figuring_out_why_creating_a_storage_space/", "subreddit_subscribers": 673510, "created_utc": 1679061262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seek the wisdom of the veterans in this comunity of data hoarders!\n\nI'm sure this has been posted before but wars, sanctions, and natural disasters affect the cost of goods all the time so... I guess it's worth asking again?\n\nWith roughly 1000$-1200$ budget and and the ambition of setting up a fully redundant 8TB (2 x 8TB drives in mirroring) what is my best option, no media streaming just storing files with no chance of losing them.\n\nSpeed and ability to access from anywhere are the two main conerns,   \nwould you get an old pc and use a paid dynamic dns service or a Synology \u200eDS920+ with two 8TB drives for data and one ssd for the OS?\n\n&amp;#x200B;\n\nI have an old synology nas and there are things I love about it ( like the [quickconnect.to](https://quickconnect.to) dns thing ) and things i hate, impossibility to upgrade hardware weird file being renamed if accessed using smb or afs. \n\n&amp;#x200B;\n\nwhat is the consensus of the experts here?\n\n&amp;#x200B;\n\nis there a third option i'm not seeing?\n\n&amp;#x200B;\n\nthanks in advance!", "author_fullname": "t2_7webob1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nas, DIY or buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tne63", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679049386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seek the wisdom of the veterans in this comunity of data hoarders!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure this has been posted before but wars, sanctions, and natural disasters affect the cost of goods all the time so... I guess it&amp;#39;s worth asking again?&lt;/p&gt;\n\n&lt;p&gt;With roughly 1000$-1200$ budget and and the ambition of setting up a fully redundant 8TB (2 x 8TB drives in mirroring) what is my best option, no media streaming just storing files with no chance of losing them.&lt;/p&gt;\n\n&lt;p&gt;Speed and ability to access from anywhere are the two main conerns,&lt;br/&gt;\nwould you get an old pc and use a paid dynamic dns service or a Synology \u200eDS920+ with two 8TB drives for data and one ssd for the OS?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have an old synology nas and there are things I love about it ( like the &lt;a href=\"https://quickconnect.to\"&gt;quickconnect.to&lt;/a&gt; dns thing ) and things i hate, impossibility to upgrade hardware weird file being renamed if accessed using smb or afs. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what is the consensus of the experts here?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is there a third option i&amp;#39;m not seeing?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tne63", "is_robot_indexable": true, "report_reasons": null, "author": "ja_maz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tne63/nas_diy_or_buy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tne63/nas_diy_or_buy/", "subreddit_subscribers": 673510, "created_utc": 1679049386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have my main Windows PC with some valuable personal things, old photos etc, sub 50gb of valuable data, entire drive is 500GB if I wanted to backup the entire drive at once. \n\nI also have a headless Linux based NAS with 4TB of less valuable content on it, mostly movies.\n\nI want to setup full 3-2-1 backups on my main Windows PC, cloud + external HDD + main drive, and for my NAS I want it to be backed up only once on an external drive.\n\nI could imagine it is highly time consuming and frustrating to set this up, having to install probably different software on my main PC and the headless NAS via command line, then execute if via command line too, etc., but I have never actually tried it before and couldn't find any reading material for this.\n\nHow difficult would this be to setup?", "author_fullname": "t2_cc458uu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Tricky is it to Setup External HDD backups of Two Different Machines on One Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11teuab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679020997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my main Windows PC with some valuable personal things, old photos etc, sub 50gb of valuable data, entire drive is 500GB if I wanted to backup the entire drive at once. &lt;/p&gt;\n\n&lt;p&gt;I also have a headless Linux based NAS with 4TB of less valuable content on it, mostly movies.&lt;/p&gt;\n\n&lt;p&gt;I want to setup full 3-2-1 backups on my main Windows PC, cloud + external HDD + main drive, and for my NAS I want it to be backed up only once on an external drive.&lt;/p&gt;\n\n&lt;p&gt;I could imagine it is highly time consuming and frustrating to set this up, having to install probably different software on my main PC and the headless NAS via command line, then execute if via command line too, etc., but I have never actually tried it before and couldn&amp;#39;t find any reading material for this.&lt;/p&gt;\n\n&lt;p&gt;How difficult would this be to setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11teuab", "is_robot_indexable": true, "report_reasons": null, "author": "SleepingAndy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11teuab/how_tricky_is_it_to_setup_external_hdd_backups_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11teuab/how_tricky_is_it_to_setup_external_hdd_backups_of/", "subreddit_subscribers": 673510, "created_utc": 1679020997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Essentially what I want to do is some data analysis to find commonalities, connections or themes between different sources of information. But my disability is such that it's getting increasingly difficult for me to do this manually. Is there software that can help me do this and will output a dynamic/interactive network graph?\n\nI would ideally like to be able to input a bunch of text (from numerous sources), have the software find keywords or themes (it's OK if I have to use separate software to mine text for keywords) and then draw connections between the different sources and output that to a network graph.\n\nThe sources are sometimes hundreds of pages long or could be as short as a single sentence. The short ones are fine to manually find connections and commonalities with but when I'm looking at hundreds of pages of text from some sources, it would take a really, really long time to sift through and with my disability, I would likely miss important data points.\n\nThe idea is that I can search for a keyword or theme and find where it's connected in all the sources of information and/or find overall patterns. Or to look at a source and find commonalities in other sources.\n\nHopefully you understand what I mean, I'm tired and sore today. Thank you!", "author_fullname": "t2_5c9sus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to make sense of huge amounts of data from different sources in a visual way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tdxsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679018927.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679018514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially what I want to do is some data analysis to find commonalities, connections or themes between different sources of information. But my disability is such that it&amp;#39;s getting increasingly difficult for me to do this manually. Is there software that can help me do this and will output a dynamic/interactive network graph?&lt;/p&gt;\n\n&lt;p&gt;I would ideally like to be able to input a bunch of text (from numerous sources), have the software find keywords or themes (it&amp;#39;s OK if I have to use separate software to mine text for keywords) and then draw connections between the different sources and output that to a network graph.&lt;/p&gt;\n\n&lt;p&gt;The sources are sometimes hundreds of pages long or could be as short as a single sentence. The short ones are fine to manually find connections and commonalities with but when I&amp;#39;m looking at hundreds of pages of text from some sources, it would take a really, really long time to sift through and with my disability, I would likely miss important data points.&lt;/p&gt;\n\n&lt;p&gt;The idea is that I can search for a keyword or theme and find where it&amp;#39;s connected in all the sources of information and/or find overall patterns. Or to look at a source and find commonalities in other sources.&lt;/p&gt;\n\n&lt;p&gt;Hopefully you understand what I mean, I&amp;#39;m tired and sore today. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tdxsk", "is_robot_indexable": true, "report_reasons": null, "author": "Thorned_Rose", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tdxsk/software_to_make_sense_of_huge_amounts_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tdxsk/software_to_make_sense_of_huge_amounts_of_data/", "subreddit_subscribers": 673510, "created_utc": 1679018514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can you take a look at smart.  \nNew HDD from: Seagate,  \nModel: ironwolf pro 4tb,  \nScreenshot, after the first read and write speed tests in the hd tune pro program.  \nIs it good/correct, no errors?  \nI don't know how to interpret this data:  \nI am worried about the increase in raw values \u200b\u200bin the column: 01, 07, C3.  \nWill you help me?  \nThank you in advance for your help.  \nThe drive was connected directly to the computer using a sata cable in order to make a copy of the most important data from a 2.5-inch SSD.\n\nhttps://preview.redd.it/lhijmpwby5oa1.jpg?width=672&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=93be7674644f536448a7aa860d024d2d3979e9cd", "author_fullname": "t2_vgc4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to interpret the smart of the new drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lhijmpwby5oa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 122, "x": 108, "u": "https://preview.redd.it/lhijmpwby5oa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30c3bd96c75876ab0e2052fa7fc41edd03ca9ef6"}, {"y": 244, "x": 216, "u": "https://preview.redd.it/lhijmpwby5oa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=029d600eca3da3bd8af4a9e8e852006af3d2eca4"}, {"y": 362, "x": 320, "u": "https://preview.redd.it/lhijmpwby5oa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8be325969037a915862dc333e415e350fe913aa4"}, {"y": 724, "x": 640, "u": "https://preview.redd.it/lhijmpwby5oa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a819643d0fd4264ee839284491c8302d7d2bc34"}], "s": {"y": 761, "x": 672, "u": "https://preview.redd.it/lhijmpwby5oa1.jpg?width=672&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=93be7674644f536448a7aa860d024d2d3979e9cd"}, "id": "lhijmpwby5oa1"}}, "name": "t3_11t5t6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GrOd0twRjW-p3UU7L04eEdMW58LS7XZcfyk3NzEIUAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can you take a look at smart.&lt;br/&gt;\nNew HDD from: Seagate,&lt;br/&gt;\nModel: ironwolf pro 4tb,&lt;br/&gt;\nScreenshot, after the first read and write speed tests in the hd tune pro program.&lt;br/&gt;\nIs it good/correct, no errors?&lt;br/&gt;\nI don&amp;#39;t know how to interpret this data:&lt;br/&gt;\nI am worried about the increase in raw values \u200b\u200bin the column: 01, 07, C3.&lt;br/&gt;\nWill you help me?&lt;br/&gt;\nThank you in advance for your help.&lt;br/&gt;\nThe drive was connected directly to the computer using a sata cable in order to make a copy of the most important data from a 2.5-inch SSD.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lhijmpwby5oa1.jpg?width=672&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=93be7674644f536448a7aa860d024d2d3979e9cd\"&gt;https://preview.redd.it/lhijmpwby5oa1.jpg?width=672&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=93be7674644f536448a7aa860d024d2d3979e9cd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t5t6c", "is_robot_indexable": true, "report_reasons": null, "author": "4Orzeszek", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t5t6c/how_to_interpret_the_smart_of_the_new_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t5t6c/how_to_interpret_the_smart_of_the_new_drive/", "subreddit_subscribers": 673510, "created_utc": 1678999699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all!\n\nThis is my first post on this subreddit, please forgive me if I step on any toes \ud83d\ude2c I have a server running OMV and one of the plugins is MergerFS. It's fairly straightforward to setup MergerFS and I understand the fundamentals of MergerFS, but there is a behavior that I cannot get a clear answer on.\n\nThe behavior I am looking for is the following: If I move a folder into the MergedFS share, I would like to keep the entire folder in a single drive without splitting the internal files across multiple drives. For example: Folder A contains 10 files. I move Folder A into MergedFS\\_1. Keep Folder A and all of its files together on Disk 1 instead of spanning the 10 files over Disk 1, Disk 2, Disk 3, etc...\n\nIs MergerFS capable of this?\n\nThank you!", "author_fullname": "t2_rpu19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you keep files in folder transfers together in MergerFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t2fj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678991904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;This is my first post on this subreddit, please forgive me if I step on any toes \ud83d\ude2c I have a server running OMV and one of the plugins is MergerFS. It&amp;#39;s fairly straightforward to setup MergerFS and I understand the fundamentals of MergerFS, but there is a behavior that I cannot get a clear answer on.&lt;/p&gt;\n\n&lt;p&gt;The behavior I am looking for is the following: If I move a folder into the MergedFS share, I would like to keep the entire folder in a single drive without splitting the internal files across multiple drives. For example: Folder A contains 10 files. I move Folder A into MergedFS_1. Keep Folder A and all of its files together on Disk 1 instead of spanning the 10 files over Disk 1, Disk 2, Disk 3, etc...&lt;/p&gt;\n\n&lt;p&gt;Is MergerFS capable of this?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t2fj7", "is_robot_indexable": true, "report_reasons": null, "author": "Meisgoot312", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t2fj7/can_you_keep_files_in_folder_transfers_together/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t2fj7/can_you_keep_files_in_folder_transfers_together/", "subreddit_subscribers": 673510, "created_utc": 1678991904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a solution for samba mounts from a remote server that perform poorly over slow wifi (which is understandable). However, writes to those mounts don't need to block applications I think - they could be written to local disk and synced to the remote in the background.\n\nI don't have control over samba server. SyncThing looks great, but I'd rather cache files \"on-demand\" rather than download all (or some of the) folders.\n\nI'm looking at [FS-Cache](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/getting-started-with-fs-cache_managing-file-systems) hoping that it can provide this type of \"write caching\" mechanism.", "author_fullname": "t2_64r00bk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asynchronous Samba mount over slow wifi - can it be written to local disk and synced in the background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t0fpt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678987500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a solution for samba mounts from a remote server that perform poorly over slow wifi (which is understandable). However, writes to those mounts don&amp;#39;t need to block applications I think - they could be written to local disk and synced to the remote in the background.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have control over samba server. SyncThing looks great, but I&amp;#39;d rather cache files &amp;quot;on-demand&amp;quot; rather than download all (or some of the) folders.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at &lt;a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/getting-started-with-fs-cache_managing-file-systems\"&gt;FS-Cache&lt;/a&gt; hoping that it can provide this type of &amp;quot;write caching&amp;quot; mechanism.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j_6JFpTyAb529aFFUtqJLwfG7Nk9HmJZ1fFddzdFZUA.jpg?auto=webp&amp;v=enabled&amp;s=a3039bc3e886c2e0fc3e4ab81d46274fae15fb12", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/j_6JFpTyAb529aFFUtqJLwfG7Nk9HmJZ1fFddzdFZUA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=777068ff10ea15815ed475e98b3e21c64cf17b85", "width": 108, "height": 108}], "variants": {}, "id": "P_zmebI4M-oYdEJfUjUsYDg1AfSpdydL9iAszP40fTE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t0fpt", "is_robot_indexable": true, "report_reasons": null, "author": "danielkraj", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t0fpt/asynchronous_samba_mount_over_slow_wifi_can_it_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t0fpt/asynchronous_samba_mount_over_slow_wifi_can_it_be/", "subreddit_subscribers": 673510, "created_utc": 1678987500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I recently watch several youtube videos of people building a NAS, and I come across people using this shucking method, of WD Elements. It would save me $200 if I use this method to get (WDBWLG0080HBK-NESN 8TB) [Amazon link](https://www.amazon.com/Elements-Desktop-Hard-Drive-WDBWLG0080HBK-NESN/dp/B07D5V2ZXD/ref=mp_s_a_1_2?crid=1VTOLSLCZ28LL&amp;keywords=wd+element+8+tb&amp;qid=1679035936&amp;sprefix=wd+element+8+%2Caps%2C534&amp;sr=8-2)instead of ST8000VN004 Seagate Ironwolf 8 TB. Is this a good method?", "author_fullname": "t2_8siy7ss6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Shucking a good method if I want to get cheaper NAS drives? (WDBWLG0080HBK-NESN 8TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj0r3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679036644.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679033934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I recently watch several youtube videos of people building a NAS, and I come across people using this shucking method, of WD Elements. It would save me $200 if I use this method to get (WDBWLG0080HBK-NESN 8TB) &lt;a href=\"https://www.amazon.com/Elements-Desktop-Hard-Drive-WDBWLG0080HBK-NESN/dp/B07D5V2ZXD/ref=mp_s_a_1_2?crid=1VTOLSLCZ28LL&amp;amp;keywords=wd+element+8+tb&amp;amp;qid=1679035936&amp;amp;sprefix=wd+element+8+%2Caps%2C534&amp;amp;sr=8-2\"&gt;Amazon link&lt;/a&gt;instead of ST8000VN004 Seagate Ironwolf 8 TB. Is this a good method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tj0r3", "is_robot_indexable": true, "report_reasons": null, "author": "SciencioGT", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tj0r3/is_shucking_a_good_method_if_i_want_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tj0r3/is_shucking_a_good_method_if_i_want_to_get/", "subreddit_subscribers": 673510, "created_utc": 1679033934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looked on reddit and not much info.\n\nJust got a Hitachi Ultrastar 3TB HDD. Price Amazon $29. Did not really research the purchase adequately.\n\nGot the drive. Smart OK. 35 start stop cycles. 87,000 hrs pwr on (10 years). Sealed package and looks new but probably not touched since installed in large raid.\n\nNo real info on WD/Hitachi since drive is so old. Probably manufactured 2012 and put in a large raid system and then pulled at 10 years.\n\nThese drives rated at 10 million hours MTBF. Does that mean anything.\n\nI know any drive can fail at any time but does the age/hours mean that much in a enterprise level HDD. I imagine so since there is a reason the company pulled it on a timetable.\n\nWhat are your thoughts as one of a pair of backup drives.", "author_fullname": "t2_bc94dl74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Member thoughts on Ultrastar HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tbe0t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679012581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looked on reddit and not much info.&lt;/p&gt;\n\n&lt;p&gt;Just got a Hitachi Ultrastar 3TB HDD. Price Amazon $29. Did not really research the purchase adequately.&lt;/p&gt;\n\n&lt;p&gt;Got the drive. Smart OK. 35 start stop cycles. 87,000 hrs pwr on (10 years). Sealed package and looks new but probably not touched since installed in large raid.&lt;/p&gt;\n\n&lt;p&gt;No real info on WD/Hitachi since drive is so old. Probably manufactured 2012 and put in a large raid system and then pulled at 10 years.&lt;/p&gt;\n\n&lt;p&gt;These drives rated at 10 million hours MTBF. Does that mean anything.&lt;/p&gt;\n\n&lt;p&gt;I know any drive can fail at any time but does the age/hours mean that much in a enterprise level HDD. I imagine so since there is a reason the company pulled it on a timetable.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts as one of a pair of backup drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tbe0t", "is_robot_indexable": true, "report_reasons": null, "author": "redd-or45", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tbe0t/member_thoughts_on_ultrastar_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tbe0t/member_thoughts_on_ultrastar_hdd/", "subreddit_subscribers": 673510, "created_utc": 1679012581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to DL entire sites and only download the newer content later on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tahpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tahpv", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "subreddit_subscribers": 673510, "created_utc": 1679010437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. \n\nI\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. \n\nI\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. \n\nI am so excited to get this little project finished, so any and all help is super appreciated.", "author_fullname": "t2_bkmhazam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help picking NVME drives for my NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t8akp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679005468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. &lt;/p&gt;\n\n&lt;p&gt;I am so excited to get this little project finished, so any and all help is super appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t8akp", "is_robot_indexable": true, "report_reasons": null, "author": "MaxBando420", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "subreddit_subscribers": 673510, "created_utc": 1679005468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been looking for a good cpu / mobo / ram combo that is as efficient as possible for a long time. I happened upon a video of\n\n\"Wolfgang's Channel\" and he managed to consume less than 25 watts at idle. he used an i3 i3-6100 32gb ram and a Fujitsu D3402-B11 which, however, I find impossible to buy second hand (from Europe). In the video he also shows other alternative mobos, but which are all unobtainable on the used market.\n\n&amp;#x200B;\n\nNow I'm looking for alternatives, maybe with the same consumption/performance but with ECC ram support.\n\n&amp;#x200B;\n\nAnyone have any ideas?\n\nThanks in advance", "author_fullname": "t2_adfzn4qg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nas build with low power draw", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t7krb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679003817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for a good cpu / mobo / ram combo that is as efficient as possible for a long time. I happened upon a video of&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Wolfgang&amp;#39;s Channel&amp;quot; and he managed to consume less than 25 watts at idle. he used an i3 i3-6100 32gb ram and a Fujitsu D3402-B11 which, however, I find impossible to buy second hand (from Europe). In the video he also shows other alternative mobos, but which are all unobtainable on the used market.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m looking for alternatives, maybe with the same consumption/performance but with ECC ram support.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone have any ideas?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t7krb", "is_robot_indexable": true, "report_reasons": null, "author": "Armed_Carlo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t7krb/nas_build_with_low_power_draw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t7krb/nas_build_with_low_power_draw/", "subreddit_subscribers": 673510, "created_utc": 1679003817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\n I would like to confirm the sustained sequential write of an nvme Gen4 into a system with gen3 slot. As with transfert on a samsung gen3 970, after 20sec of 3gbps it drop to 1.5gpbs for the rest of time(after 2,4,9min). But for a FireCuda 530 / Adata Legend 960 or Sabrent Rocket 4 : sustained is at 3.8gb for 4min   And the samsung 990 is 1.4gbps.\n\n So with the Firecuda, Adata or Sabrent put into a gen3 slot = will they fully give a continuous sustain speed of about 3.6gbps , maxing out the bus fully ?   .. and then have the best  speed...\n\n&amp;#x200B;\n\nThanks on that", "author_fullname": "t2_2qipul6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using gen4 nvme in gen3 slot for high Sustained transfert speed ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t68qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I would like to confirm the sustained sequential write of an nvme Gen4 into a system with gen3 slot. As with transfert on a samsung gen3 970, after 20sec of 3gbps it drop to 1.5gpbs for the rest of time(after 2,4,9min). But for a FireCuda 530 / Adata Legend 960 or Sabrent Rocket 4 : sustained is at 3.8gb for 4min   And the samsung 990 is 1.4gbps.&lt;/p&gt;\n\n&lt;p&gt;So with the Firecuda, Adata or Sabrent put into a gen3 slot = will they fully give a continuous sustain speed of about 3.6gbps , maxing out the bus fully ?   .. and then have the best  speed...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks on that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t68qw", "is_robot_indexable": true, "report_reasons": null, "author": "Docop1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t68qw/using_gen4_nvme_in_gen3_slot_for_high_sustained/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t68qw/using_gen4_nvme_in_gen3_slot_for_high_sustained/", "subreddit_subscribers": 673510, "created_utc": 1679000692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "THANKFULLY, this wasn't my main server but it was a secondary server that I back the main one up to and it needs fixed ASAP.\n\nIt was a 4U Rosewill server (RSV-L4412U), using a Gigabyte ATX board and a Seasonic power supply. It's been humming along for years with zero problems and then today, the power supply suffered a massive failure. When I shake the ps, there's something lose in there. UPS flipped out, LOUD pop, etc., etc.\n\nI put a new ps in the system and turned it back on to see what all was damaged. While Debian 11 is booting, I see this at the top of the screen for a while:\n\n'mpt2sas\\_cm1: overriding NVDATA EEDPTagMode setting'   ...... but eventually the OS loads and I'm at the desktop.\n\nLooking in the 'Disks' app, I see that my MDADM array is offline (expected because....) of my 11, 8TB drives, only 8 are showing up. I have two, LSI 9207-8i HBA's installed. Card 1 has 2 SFF cables going to it (and controlling a total of 8 drives) and the 2nd card has 1 SFF cable (controlling 3 drives).\n\nAt this point you're probably thinking.....\"well duh, the card with the 3 drives is the culprit\" but that's not so. Because the 3 drives that card 2 is controlling.... 2 of the 3 show up. And on the first card, 2 of the 8 drives it's controlling aren't showing up.\n\nI pulled the drives from their disk trays and checked them individually in a USB dock on another system and the other Linux box was able to see that they're all part of an array so I'm fairly confident (crossing my finders) that the data on them is intact.\n\nAfter some troubleshooting and sitting down to think, I don't believe the motherboard or HBAs are damaged. It's looking more and more like the back plane in the Rosewill is at fault. I think this because as I mentioned above, one of the HBAs can see 2 of its' 3 drives. If the PCI slots were damaged, I don't think EITHER HBA would work or either HBA would see ANY of their attached drives. Sure, I could do some more swapping of cards/drives but I don't want to spend any more time on it and I need to get the backup system up and running fast.\n\nWould appreciate your thoughts on all that but my big question is this..... what's the best way out of this mess?\n\nOption 1. $360 - Buy a new Rosewill RSV-L4412U and a new power supply :) and put everything back together.\n\nOption 2. $219+$80+100=$400 Which is a SuperMicro CSE-846+ 3, quiet, replacement fans (FAN-0104L4)+$100 (or so) for the quiet version of a power supply because stock SuperMicro power supplies are...... noisy. (Any problems with 8TB SATA drives with the SAS826A back plane?)\n\nOption 3. $600 - Buy a CSE-847 (BPN-SAS3-846EL1 back plane). The reason I was thinking of this route is because I currently have 20'ish 4TB drives in my main server and I was thinking about expanding. I like using 4TB drives to reduce resilver times so I could move my existing motherboard into this new unit and take the guts from the Rosewill case and put them in my existing SC-846 chassis. BUT..... the CPU cooler I'm using in my 24 bay SC-846 won't fit in the SC-847 so I'll need a low profile cooler for my i7 7700K so not a huge deal, just mo' money. :(\n\nSo there you have it............ would greatly appreciate any and all comments!", "author_fullname": "t2_amep8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Urgent help and advice needed please, power supply suffered massive failure and now some of my drives are gone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t5sg5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;THANKFULLY, this wasn&amp;#39;t my main server but it was a secondary server that I back the main one up to and it needs fixed ASAP.&lt;/p&gt;\n\n&lt;p&gt;It was a 4U Rosewill server (RSV-L4412U), using a Gigabyte ATX board and a Seasonic power supply. It&amp;#39;s been humming along for years with zero problems and then today, the power supply suffered a massive failure. When I shake the ps, there&amp;#39;s something lose in there. UPS flipped out, LOUD pop, etc., etc.&lt;/p&gt;\n\n&lt;p&gt;I put a new ps in the system and turned it back on to see what all was damaged. While Debian 11 is booting, I see this at the top of the screen for a while:&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;mpt2sas_cm1: overriding NVDATA EEDPTagMode setting&amp;#39;   ...... but eventually the OS loads and I&amp;#39;m at the desktop.&lt;/p&gt;\n\n&lt;p&gt;Looking in the &amp;#39;Disks&amp;#39; app, I see that my MDADM array is offline (expected because....) of my 11, 8TB drives, only 8 are showing up. I have two, LSI 9207-8i HBA&amp;#39;s installed. Card 1 has 2 SFF cables going to it (and controlling a total of 8 drives) and the 2nd card has 1 SFF cable (controlling 3 drives).&lt;/p&gt;\n\n&lt;p&gt;At this point you&amp;#39;re probably thinking.....&amp;quot;well duh, the card with the 3 drives is the culprit&amp;quot; but that&amp;#39;s not so. Because the 3 drives that card 2 is controlling.... 2 of the 3 show up. And on the first card, 2 of the 8 drives it&amp;#39;s controlling aren&amp;#39;t showing up.&lt;/p&gt;\n\n&lt;p&gt;I pulled the drives from their disk trays and checked them individually in a USB dock on another system and the other Linux box was able to see that they&amp;#39;re all part of an array so I&amp;#39;m fairly confident (crossing my finders) that the data on them is intact.&lt;/p&gt;\n\n&lt;p&gt;After some troubleshooting and sitting down to think, I don&amp;#39;t believe the motherboard or HBAs are damaged. It&amp;#39;s looking more and more like the back plane in the Rosewill is at fault. I think this because as I mentioned above, one of the HBAs can see 2 of its&amp;#39; 3 drives. If the PCI slots were damaged, I don&amp;#39;t think EITHER HBA would work or either HBA would see ANY of their attached drives. Sure, I could do some more swapping of cards/drives but I don&amp;#39;t want to spend any more time on it and I need to get the backup system up and running fast.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate your thoughts on all that but my big question is this..... what&amp;#39;s the best way out of this mess?&lt;/p&gt;\n\n&lt;p&gt;Option 1. $360 - Buy a new Rosewill RSV-L4412U and a new power supply :) and put everything back together.&lt;/p&gt;\n\n&lt;p&gt;Option 2. $219+$80+100=$400 Which is a SuperMicro CSE-846+ 3, quiet, replacement fans (FAN-0104L4)+$100 (or so) for the quiet version of a power supply because stock SuperMicro power supplies are...... noisy. (Any problems with 8TB SATA drives with the SAS826A back plane?)&lt;/p&gt;\n\n&lt;p&gt;Option 3. $600 - Buy a CSE-847 (BPN-SAS3-846EL1 back plane). The reason I was thinking of this route is because I currently have 20&amp;#39;ish 4TB drives in my main server and I was thinking about expanding. I like using 4TB drives to reduce resilver times so I could move my existing motherboard into this new unit and take the guts from the Rosewill case and put them in my existing SC-846 chassis. BUT..... the CPU cooler I&amp;#39;m using in my 24 bay SC-846 won&amp;#39;t fit in the SC-847 so I&amp;#39;ll need a low profile cooler for my i7 7700K so not a huge deal, just mo&amp;#39; money. :(&lt;/p&gt;\n\n&lt;p&gt;So there you have it............ would greatly appreciate any and all comments!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t5sg5", "is_robot_indexable": true, "report_reasons": null, "author": "road_hazard", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t5sg5/urgent_help_and_advice_needed_please_power_supply/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t5sg5/urgent_help_and_advice_needed_please_power_supply/", "subreddit_subscribers": 673510, "created_utc": 1678999652.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}