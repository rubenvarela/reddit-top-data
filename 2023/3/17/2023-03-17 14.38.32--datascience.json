{"kind": "Listing", "data": {"after": "t3_11t644y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Today at work, I heard one guy say something along the lines of \"Yea we can move the data to trix and then slurpy it to plex\" and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha", "author_fullname": "t2_d8yn6ekd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science terminology can be wild", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3t3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 333, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 333, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678995071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today at work, I heard one guy say something along the lines of &amp;quot;Yea we can move the data to trix and then slurpy it to plex&amp;quot; and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t3t3v", "is_robot_indexable": true, "report_reasons": null, "author": "No_Boysenberry_7138", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "subreddit_subscribers": 858151, "created_utc": 1678995071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?", "author_fullname": "t2_rugmcqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the McKinsey of Data Science Consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t60oq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t60oq", "is_robot_indexable": true, "report_reasons": null, "author": "Whathefish", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "subreddit_subscribers": 858151, "created_utc": 1679000181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t171s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_47sfqfo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "who's applying and what are you planning to build???  [https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge](https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge)", "author_fullname": "t2_47sfqfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "two", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8yk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678913695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;who&amp;#39;s applying and what are you planning to build???  &lt;a href=\"https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge\"&gt;https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11s8yk2", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 2600862, "created_utc": 1678913695.0, "num_crossposts": 8, "media": null, "is_video": false}], "created": 1678989165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t171s", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11s8yk2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t171s/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 858151, "created_utc": 1678989165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to this and so I've been wanting to know what other people have been using to make their work feel as smooth as butter. Since I've been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. **The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!**\n\nIDE: **VSCode with the Jupyter Notebook Extension**. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that **Jupyter Lab** has something like this, so if anyone has used both VSCode's notebooks and used Lab, your input would be appreciated. I hear good things about **PyCharm and Spyder**. Some people also use **Google Collab, DataSpell, and DeepNote** but I don't know enough about it. I did play around with DeepNote, and it was very cool but I didn't feel compelled to switch (and you have to pay for it!). \n\nTools:\n\n* A code helper: A few months back I was googling everything and I would've listed **Stackoverflow**. I might actually use that occasionally, but these days I use **ChatGPT** and **Bing AI**. For more current info or news-based I'll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it's great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I'm talking about and can provide a better explanation as to which is better for what purpose.\n* Software: **Excel** is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don't need with Ctrl+click to select, it's easier and quicker than copy + pasting or typing out each of the string column names I want to \"df.drop()\". Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as **Alteryx, KNIME, and Orange**. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a \"lite\" version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven't found a huge use case for them since I've been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.\n* Version Control: This is where I'm primarily lacking, but I know that **Github** is the go-to. I don't use this but I know that a ton of people do. I don't even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I'm also not too aware of what other innovative tools for version control exist.\n* Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I've recently found out about this library called **Polars**. It's basically a Rust version of Pandas, and it's super powerful. Some operations that I've run, that would've taken hours with Pandas, took me minutes. But I've been hearing that **Pandas 2.0** which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is **DuckDB** but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I'll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.\n\nAnyway, that's just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.\n\nhttps://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a", "author_fullname": "t2_gk7up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your digital workspace, tools, setup, etc. for ETL, research, production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qj2cywt1r4oa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6026f61ce2eac4655501946e87ff28b630eafef"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=465f2b0ba6e556d68c2e38da6a0cbf88d55bdae0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78622791ecd096a9586bd2fa375924ecfa71e40c"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa7f19b7612f47b30d08371d8a6aa7c45868cab6"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df91ed30b6053048ed5f1619bcfa1bc9ca731ee0"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eaf1df085449f3113dea76a3a8a86913761bf9c"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a"}, "id": "qj2cywt1r4oa1"}}, "name": "t3_11szca1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OuxRKRDebneIMbv8ljpRG_Aszt8idVQ8R-QV3AksOJQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678985129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to this and so I&amp;#39;ve been wanting to know what other people have been using to make their work feel as smooth as butter. Since I&amp;#39;ve been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. &lt;strong&gt;The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;IDE: &lt;strong&gt;VSCode with the Jupyter Notebook Extension&lt;/strong&gt;. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that &lt;strong&gt;Jupyter Lab&lt;/strong&gt; has something like this, so if anyone has used both VSCode&amp;#39;s notebooks and used Lab, your input would be appreciated. I hear good things about &lt;strong&gt;PyCharm and Spyder&lt;/strong&gt;. Some people also use &lt;strong&gt;Google Collab, DataSpell, and DeepNote&lt;/strong&gt; but I don&amp;#39;t know enough about it. I did play around with DeepNote, and it was very cool but I didn&amp;#39;t feel compelled to switch (and you have to pay for it!). &lt;/p&gt;\n\n&lt;p&gt;Tools:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A code helper: A few months back I was googling everything and I would&amp;#39;ve listed &lt;strong&gt;Stackoverflow&lt;/strong&gt;. I might actually use that occasionally, but these days I use &lt;strong&gt;ChatGPT&lt;/strong&gt; and &lt;strong&gt;Bing AI&lt;/strong&gt;. For more current info or news-based I&amp;#39;ll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it&amp;#39;s great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I&amp;#39;m talking about and can provide a better explanation as to which is better for what purpose.&lt;/li&gt;\n&lt;li&gt;Software: &lt;strong&gt;Excel&lt;/strong&gt; is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don&amp;#39;t need with Ctrl+click to select, it&amp;#39;s easier and quicker than copy + pasting or typing out each of the string column names I want to &amp;quot;df.drop()&amp;quot;. Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as &lt;strong&gt;Alteryx, KNIME, and Orange&lt;/strong&gt;. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a &amp;quot;lite&amp;quot; version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven&amp;#39;t found a huge use case for them since I&amp;#39;ve been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.&lt;/li&gt;\n&lt;li&gt;Version Control: This is where I&amp;#39;m primarily lacking, but I know that &lt;strong&gt;Github&lt;/strong&gt; is the go-to. I don&amp;#39;t use this but I know that a ton of people do. I don&amp;#39;t even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I&amp;#39;m also not too aware of what other innovative tools for version control exist.&lt;/li&gt;\n&lt;li&gt;Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I&amp;#39;ve recently found out about this library called &lt;strong&gt;Polars&lt;/strong&gt;. It&amp;#39;s basically a Rust version of Pandas, and it&amp;#39;s super powerful. Some operations that I&amp;#39;ve run, that would&amp;#39;ve taken hours with Pandas, took me minutes. But I&amp;#39;ve been hearing that &lt;strong&gt;Pandas 2.0&lt;/strong&gt; which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is &lt;strong&gt;DuckDB&lt;/strong&gt; but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I&amp;#39;ll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyway, that&amp;#39;s just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a\"&gt;https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11szca1", "is_robot_indexable": true, "report_reasons": null, "author": "BreathAether", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "subreddit_subscribers": 858151, "created_utc": 1678985129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been browsing a lot of jobs that require high level SQL as well as the usual coding skills. I have a few years of experience working in data science but mostly use python and pyspark for everything. Other than a small project many years ago back in university I have never really had a reason to use SQL. \n\nNow that I am looking at other jobs it seems like by this stage in my career I should be more familiar with SQL. I took a fundamentals course online which taught me the basics but I'd like to develop beyond this to write more naturally like I do in other languages. How do you think I should go about improving my skills? As I understand it is mostly just used to query databases so I'm not really sure about any interesting side projects I could do to use it.", "author_fullname": "t2_jip2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I improve my SQL skills if I don't use it in work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tmeki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679046202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been browsing a lot of jobs that require high level SQL as well as the usual coding skills. I have a few years of experience working in data science but mostly use python and pyspark for everything. Other than a small project many years ago back in university I have never really had a reason to use SQL. &lt;/p&gt;\n\n&lt;p&gt;Now that I am looking at other jobs it seems like by this stage in my career I should be more familiar with SQL. I took a fundamentals course online which taught me the basics but I&amp;#39;d like to develop beyond this to write more naturally like I do in other languages. How do you think I should go about improving my skills? As I understand it is mostly just used to query databases so I&amp;#39;m not really sure about any interesting side projects I could do to use it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tmeki", "is_robot_indexable": true, "report_reasons": null, "author": "RastaSalad", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tmeki/how_can_i_improve_my_sql_skills_if_i_dont_use_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tmeki/how_can_i_improve_my_sql_skills_if_i_dont_use_it/", "subreddit_subscribers": 858151, "created_utc": 1679046202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_d26sfzn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Microsoft 365 Copilot | Your Copilot for Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11t9l7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bzLOoZFvtyzBrxNO8L_ikH0-f6HG55F6-OzvgdLNV0s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679008365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blogs.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?auto=webp&amp;v=enabled&amp;s=c210621c80ef098f128f34791a8cbba8804fa192", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2fadab9efd22b498f898701c58b245b01fbfa941", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=436eff9ded232646d99b0408ca91aedf25756e46", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e02245a69576d0650ddacf27ac86f9072cd1ba88", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf4035c1f7f1f33e0aceef3d92793b7b7386d58f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b1ab2dd811546ce3177d32023a00f4a5fb48ac1", "width": 960, "height": 540}], "variants": {}, "id": "Hd-I8fTFvygbpn1E58xOKqk2mcbMlHNowXS58ZCeu4k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t9l7v", "is_robot_indexable": true, "report_reasons": null, "author": "International-Tap841", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t9l7v/introducing_microsoft_365_copilot_your_copilot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/", "subreddit_subscribers": 858151, "created_utc": 1679008365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to work on research projects where I use Twitter data for text mining. However, I don't know the exact new regulations about the new Twitter API since Elon Musk bought Twitter and changed the API specifics. I see that you can apply for academic access but this seems quite hard..does anyone know if I can still get access to the Twitter API without paying?", "author_fullname": "t2_vyat88zw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I have to pay now for the Twitter API if I want to use it for data analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tlvpd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679047833.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679044463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to work on research projects where I use Twitter data for text mining. However, I don&amp;#39;t know the exact new regulations about the new Twitter API since Elon Musk bought Twitter and changed the API specifics. I see that you can apply for academic access but this seems quite hard..does anyone know if I can still get access to the Twitter API without paying?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tlvpd", "is_robot_indexable": true, "report_reasons": null, "author": "admired_potato", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tlvpd/do_i_have_to_pay_now_for_the_twitter_api_if_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tlvpd/do_i_have_to_pay_now_for_the_twitter_api_if_i/", "subreddit_subscribers": 858151, "created_utc": 1679044463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\nThis week, I applied for a data science job at my dream company.\n\nFrom what I can see on LinkedIn, the data team lead has the same academic background as I do. He completed his PhD the year I was born, became a professor, and then transitioned to DS around the 2008 recession. I completed my PhD a few years ago, and got my first data science position shortly after. For additional information, the field of academia we share is tiny - a subfield of physics with about 2,000 people worldwide.\n\n**Should I write a cold email to the team lead?** My goal is to boost my chances for an interview.\n\nI'll add that the job posting did not have the team lead's email. I ended up finding his email on RocketReach. It does not look like he's very active on LinkedIn, otherwise I'd send him a message there. Unfortunately, it also doesn't look like he's kept up with anyone in our field of academia, otherwise I'd wrangle an intro.\n\nThanks for reading!", "author_fullname": "t2_eedxi6py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I write a cold email to the team lead at my dream company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tbhbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679028560.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679012665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;This week, I applied for a data science job at my dream company.&lt;/p&gt;\n\n&lt;p&gt;From what I can see on LinkedIn, the data team lead has the same academic background as I do. He completed his PhD the year I was born, became a professor, and then transitioned to DS around the 2008 recession. I completed my PhD a few years ago, and got my first data science position shortly after. For additional information, the field of academia we share is tiny - a subfield of physics with about 2,000 people worldwide.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Should I write a cold email to the team lead?&lt;/strong&gt; My goal is to boost my chances for an interview.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll add that the job posting did not have the team lead&amp;#39;s email. I ended up finding his email on RocketReach. It does not look like he&amp;#39;s very active on LinkedIn, otherwise I&amp;#39;d send him a message there. Unfortunately, it also doesn&amp;#39;t look like he&amp;#39;s kept up with anyone in our field of academia, otherwise I&amp;#39;d wrangle an intro.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tbhbh", "is_robot_indexable": true, "report_reasons": null, "author": "SabinReed", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tbhbh/should_i_write_a_cold_email_to_the_team_lead_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tbhbh/should_i_write_a_cold_email_to_the_team_lead_at/", "subreddit_subscribers": 858151, "created_utc": 1679012665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019d often see job postings with data scientists, senior data scientists, and staff data scientists. \n\nWhat are the general responsibilities and expectations at each level? Seems like they differ depending on the company as well.", "author_fullname": "t2_kq3pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do levels of data scientists differ in responsiblity and expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t7m7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679011344.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679003914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d often see job postings with data scientists, senior data scientists, and staff data scientists. &lt;/p&gt;\n\n&lt;p&gt;What are the general responsibilities and expectations at each level? Seems like they differ depending on the company as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t7m7b", "is_robot_indexable": true, "report_reasons": null, "author": "marlinclark", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t7m7b/how_do_levels_of_data_scientists_differ_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t7m7b/how_do_levels_of_data_scientists_differ_in/", "subreddit_subscribers": 858151, "created_utc": 1679003914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been hearing a lot about Polars recently (PyData Conference, YouTube videos) and was just wondering if you guys could share your thoughts on the following,\n\n1. When does the speed of pandas become a major dependency in your workflow?\n2. Is Polars something you already use in your workflow and if so I\u2019d really appreciate any thoughts on it.\n\nThanks all!", "author_fullname": "t2_swkdetcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars vs Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tod38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679052364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been hearing a lot about Polars recently (PyData Conference, YouTube videos) and was just wondering if you guys could share your thoughts on the following,&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;When does the speed of pandas become a major dependency in your workflow?&lt;/li&gt;\n&lt;li&gt;Is Polars something you already use in your workflow and if so I\u2019d really appreciate any thoughts on it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tod38", "is_robot_indexable": true, "report_reasons": null, "author": "StoicPanda5", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tod38/polars_vs_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tod38/polars_vs_pandas/", "subreddit_subscribers": 858151, "created_utc": 1679052364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I have a large dataset (700GB) stored in an S3 bucket. I'm carrying out the training on an EC2 instance which has a GPU. \n\nI'm curious to hear your approaches to minimizing the time spent on IO in such a situation, at the minute I'm downloading each batch on the fly, training on it and then removing it from disk. There is a lot of time spent on downloading the batches\n \nI have seen that there are many possible ways.\n\n- Get bigger instance eith higher disk space and throughput and download the contents of the bucket to disk before training \n- S3 fast transfer\n- Create a volume and mount it to the EC2 instance\n- Stream data using some other service\n- spark with sagemaker\n\nAnyone who had some success in maximizing throughput in such a setting, please let me know what method you decided upon! \n\nThanks!", "author_fullname": "t2_vic3bbmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimizing IO for Large Datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11tq6c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679057616.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679057364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I have a large dataset (700GB) stored in an S3 bucket. I&amp;#39;m carrying out the training on an EC2 instance which has a GPU. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear your approaches to minimizing the time spent on IO in such a situation, at the minute I&amp;#39;m downloading each batch on the fly, training on it and then removing it from disk. There is a lot of time spent on downloading the batches&lt;/p&gt;\n\n&lt;p&gt;I have seen that there are many possible ways.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Get bigger instance eith higher disk space and throughput and download the contents of the bucket to disk before training &lt;/li&gt;\n&lt;li&gt;S3 fast transfer&lt;/li&gt;\n&lt;li&gt;Create a volume and mount it to the EC2 instance&lt;/li&gt;\n&lt;li&gt;Stream data using some other service&lt;/li&gt;\n&lt;li&gt;spark with sagemaker&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyone who had some success in maximizing throughput in such a setting, please let me know what method you decided upon! &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tq6c2", "is_robot_indexable": true, "report_reasons": null, "author": "yaksnowball", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tq6c2/minimizing_io_for_large_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tq6c2/minimizing_io_for_large_datasets/", "subreddit_subscribers": 858151, "created_utc": 1679057364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently in a MS-Business Data Analytics program. I just started in January. I have an extensive background in sales where my love of numbers really blossomed and my undergraduate degree is a BBA. \n\nI\u2019m currently learning management information systems, Python and SQL, and brushing up on Excel so that I can include some of that work on the website I\u2019m creating. \n\nDespite the lack of portfolio, I\u2019ve applied to about 50 data analyst internships thus far. A lot of them don\u2019t require much beyond soft skills, but I\u2019m just wondering if maybe, given that I\u2019m not young and I have quite a bit of work experience, I should just learn a little more and then seek an entry level position? Or do I keep trying to land an internship?\n\nFor context, I\u2019m in the Midwest and I\u2019m interested in the travel, entertainment, automotive or retail sectors, but would take a job anywhere to get some real hands-on experience.", "author_fullname": "t2_vfyb5e64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I just go for an entry level job vs an internship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11toqj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679053492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently in a MS-Business Data Analytics program. I just started in January. I have an extensive background in sales where my love of numbers really blossomed and my undergraduate degree is a BBA. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently learning management information systems, Python and SQL, and brushing up on Excel so that I can include some of that work on the website I\u2019m creating. &lt;/p&gt;\n\n&lt;p&gt;Despite the lack of portfolio, I\u2019ve applied to about 50 data analyst internships thus far. A lot of them don\u2019t require much beyond soft skills, but I\u2019m just wondering if maybe, given that I\u2019m not young and I have quite a bit of work experience, I should just learn a little more and then seek an entry level position? Or do I keep trying to land an internship?&lt;/p&gt;\n\n&lt;p&gt;For context, I\u2019m in the Midwest and I\u2019m interested in the travel, entertainment, automotive or retail sectors, but would take a job anywhere to get some real hands-on experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11toqj7", "is_robot_indexable": true, "report_reasons": null, "author": "Cheap-Selection-2406", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11toqj7/should_i_just_go_for_an_entry_level_job_vs_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11toqj7/should_i_just_go_for_an_entry_level_job_vs_an/", "subreddit_subscribers": 858151, "created_utc": 1679053492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "To get a practical + theoretical understanding with a critical review of:\n- ANOVA vs Linear Regression ~ overlap, pros vs cons, when to apply, which assumptions are important vs. not important, , how to test assumptions, how to deal when assumptions are violated (e.g. sample sizes not equal, heterogenous variance, etc.)\n- Bootstrap Approaches &amp; Permutation Testing - pros and cons, when to apply, pros vs cons, assumptioms if any, etc. \n- General best practices for statistical testing in practice (e.g. Applied to AB testing) \n\nNote: There's such a mess of contradictory resources online re: statistics.", "author_fullname": "t2_vjpbgi84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation for books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj6nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679034506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To get a practical + theoretical understanding with a critical review of:\n- ANOVA vs Linear Regression ~ overlap, pros vs cons, when to apply, which assumptions are important vs. not important, , how to test assumptions, how to deal when assumptions are violated (e.g. sample sizes not equal, heterogenous variance, etc.)\n- Bootstrap Approaches &amp;amp; Permutation Testing - pros and cons, when to apply, pros vs cons, assumptioms if any, etc. \n- General best practices for statistical testing in practice (e.g. Applied to AB testing) &lt;/p&gt;\n\n&lt;p&gt;Note: There&amp;#39;s such a mess of contradictory resources online re: statistics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tj6nj", "is_robot_indexable": true, "report_reasons": null, "author": "AlwaysHungry4Data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tj6nj/recommendation_for_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tj6nj/recommendation_for_books/", "subreddit_subscribers": 858151, "created_utc": 1679034506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset consisting of about 1 Billion strings.\n\nI\u2019m trying to find a quick way to search for substrings within the strings and I haven\u2019t been able to figure it out yet. I want to be able to search for substrings in a few different ways:\n\nSample string: \u201chello\u201d\n\nSearches that should return that string:\nhell*\n*ello\n*ell*\nhe*lo\n*e*l*\n\nNote that * represents wildcard in this example\n\nI can successfully get this to work using splunk but it\u2019s very slow. I can get it to work with Elasticsearch and Kibana but I hate maintaining that stack. I tried another tool called zincsearch but it wasn\u2019t very happy with the amount of records I was using.\n\nIs there a simple and fast tool that would allow me to run the sort of searches that I want to run on such a big dataset.\n\nSorry if this is a massive noob question, I work in cyber security and do a fair bit of data analysis but I\u2019m definitely new to the world of data science tools.", "author_fullname": "t2_hssvfekn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools for searching a huge text dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj1nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679034016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset consisting of about 1 Billion strings.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to find a quick way to search for substrings within the strings and I haven\u2019t been able to figure it out yet. I want to be able to search for substrings in a few different ways:&lt;/p&gt;\n\n&lt;p&gt;Sample string: \u201chello\u201d&lt;/p&gt;\n\n&lt;p&gt;Searches that should return that string:\nhell*\n&lt;em&gt;ello\n*ell&lt;/em&gt;\nhe&lt;em&gt;lo\n*e&lt;/em&gt;l*&lt;/p&gt;\n\n&lt;p&gt;Note that * represents wildcard in this example&lt;/p&gt;\n\n&lt;p&gt;I can successfully get this to work using splunk but it\u2019s very slow. I can get it to work with Elasticsearch and Kibana but I hate maintaining that stack. I tried another tool called zincsearch but it wasn\u2019t very happy with the amount of records I was using.&lt;/p&gt;\n\n&lt;p&gt;Is there a simple and fast tool that would allow me to run the sort of searches that I want to run on such a big dataset.&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is a massive noob question, I work in cyber security and do a fair bit of data analysis but I\u2019m definitely new to the world of data science tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tj1nj", "is_robot_indexable": true, "report_reasons": null, "author": "k7r7f80d", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tj1nj/tools_for_searching_a_huge_text_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tj1nj/tools_for_searching_a_huge_text_dataset/", "subreddit_subscribers": 858151, "created_utc": 1679034016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello hello \ud83d\udc4b.\n\nI hope you are doing well.\n\nThis is Ella 24F , I am looking for a friend good at SQL,excel and python.A friend who is passionate about building skills and whom we can help each other grow career wise\ud83d\ude0a\ud83d\ude0a\nBesides the mentioned skills, I am open to learning other skills .If you enjoy such topics and discussions DM.\n\nAbout me:\n\ud83d\udd16Control and instrumentation scientist.\n\ud83d\udd16Currently learning software engnr\n\ud83d\udd16Open to learning new skills, to perform well in my current role .( team handling, data analysis and reporting )\n\nLet's grow together \ud83e\udd70\u2728\ud83e\udd70", "author_fullname": "t2_6n12vsxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL,excel, python study friend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t83jn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679005020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello hello \ud83d\udc4b.&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;This is Ella 24F , I am looking for a friend good at SQL,excel and python.A friend who is passionate about building skills and whom we can help each other grow career wise\ud83d\ude0a\ud83d\ude0a\nBesides the mentioned skills, I am open to learning other skills .If you enjoy such topics and discussions DM.&lt;/p&gt;\n\n&lt;p&gt;About me:\n\ud83d\udd16Control and instrumentation scientist.\n\ud83d\udd16Currently learning software engnr\n\ud83d\udd16Open to learning new skills, to perform well in my current role .( team handling, data analysis and reporting )&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s grow together \ud83e\udd70\u2728\ud83e\udd70&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t83jn", "is_robot_indexable": true, "report_reasons": null, "author": "Flosy22", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t83jn/sqlexcel_python_study_friend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t83jn/sqlexcel_python_study_friend/", "subreddit_subscribers": 858151, "created_utc": 1679005020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just released an instruct version of GPT-J using Stanford Alpaca's dataset.The result of this experiment is very cool and confirms that, when fine-tuned on the right data, GPT-J is a very powerful AI model!You can download the model from the HuggingFace hub: [https://huggingface.co/nlpcloud/instruct-gpt-j-fp16](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16)\n\nHere is an example:\n\n`from transformers import pipeline import torch`\n\n`generator = pipeline(model=\"nlpcloud/instruct-gpt-j-fp16\", torch_dtype=torch.float16, device=0)`\n\n`prompt = \"Correct spelling and grammar from the following text.\\nI do not wan to go\\n\" print(generator(prompt))`\n\nMore details about this experiment here: [https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;utm_campaign=jwu8d596-3816-11ed-a261-0242ac140007)\n\nI hope it will be useful! Please don't hesitate to share some feedbacks!\n\nJulien", "author_fullname": "t2_4z4m2qcs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An Instruct Version Of GPT-J Using Stanford Alpaca's Dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11tqiab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679059313.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679058183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just released an instruct version of GPT-J using Stanford Alpaca&amp;#39;s dataset.The result of this experiment is very cool and confirms that, when fine-tuned on the right data, GPT-J is a very powerful AI model!You can download the model from the HuggingFace hub: &lt;a href=\"https://huggingface.co/nlpcloud/instruct-gpt-j-fp16\"&gt;https://huggingface.co/nlpcloud/instruct-gpt-j-fp16&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is an example:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;from transformers import pipeline import torch&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;generator = pipeline(model=&amp;quot;nlpcloud/instruct-gpt-j-fp16&amp;quot;, torch_dtype=torch.float16, device=0)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;prompt = &amp;quot;Correct spelling and grammar from the following text.\\nI do not wan to go\\n&amp;quot; print(generator(prompt))&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;More details about this experiment here: &lt;a href=\"https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;amp;utm_campaign=jwu8d596-3816-11ed-a261-0242ac140007\"&gt;https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope it will be useful! Please don&amp;#39;t hesitate to share some feedbacks!&lt;/p&gt;\n\n&lt;p&gt;Julien&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?auto=webp&amp;v=enabled&amp;s=1c8cde537c241baa3f0c32b7a90610959a059067", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c00246fd55fa30e6f4b8fd0c8d04a5a842fc609a", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6a0dcbc33dfd54fdfcc562bb615738bd292b06b", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d19766847839d747ccfc6c0c0c56af270fac2f77", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e7dc3c96eed6a9ce152fd97f54a8454e4aee4d8", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41a3ff025954664ce6fb9a4cc45a00957abbaf52", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/MS-wuUuYUsaR7MzthiYW42GiKRvYXTwrduOCp4NM9BQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fc3a5cefe8f82a0a179f7a2a61ef1ea7267d400", "width": 1080, "height": 583}], "variants": {}, "id": "Q-9vAQSe-Z3JUhwIAABN3G9zc2dfuoB2WSKCa1jNM3M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tqiab", "is_robot_indexable": true, "report_reasons": null, "author": "juliensalinas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tqiab/an_instruct_version_of_gptj_using_stanford/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tqiab/an_instruct_version_of_gptj_using_stanford/", "subreddit_subscribers": 858151, "created_utc": 1679058183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone , \n\nI am a Brazilian Jiu Jitsu hobbyist and i would like to create a small project out of it.\n\nI am thinking about first finding data of competitions , To see how points are scored (takedowns,sweeps etc) , what submissions are the most successful. \n\nI would love any ideas on how to enrich the project and if anyone has done anything similar i would love to take a look.  \n\n(Please note that i am fairly new to DS and ML)", "author_fullname": "t2_11cw6lt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BJJ Project ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tpucd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679056523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone , &lt;/p&gt;\n\n&lt;p&gt;I am a Brazilian Jiu Jitsu hobbyist and i would like to create a small project out of it.&lt;/p&gt;\n\n&lt;p&gt;I am thinking about first finding data of competitions , To see how points are scored (takedowns,sweeps etc) , what submissions are the most successful. &lt;/p&gt;\n\n&lt;p&gt;I would love any ideas on how to enrich the project and if anyone has done anything similar i would love to take a look.  &lt;/p&gt;\n\n&lt;p&gt;(Please note that i am fairly new to DS and ML)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tpucd", "is_robot_indexable": true, "report_reasons": null, "author": "daskou_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tpucd/bjj_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tpucd/bjj_project_ideas/", "subreddit_subscribers": 858151, "created_utc": 1679056523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, im currently still a student and looking forward to work in data science or maybe AI/ML. I will be starting my degree in the upcoming winter semester 2023. Currently im still considering either taking Mathematics or Computer science. Any advise for me which course should I take ? is there any difference between these two ( in term of finding job) ?\n\nFeel free to write your opinion :) , and thank you in advance", "author_fullname": "t2_4s2yhg3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tmpx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679047240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, im currently still a student and looking forward to work in data science or maybe AI/ML. I will be starting my degree in the upcoming winter semester 2023. Currently im still considering either taking Mathematics or Computer science. Any advise for me which course should I take ? is there any difference between these two ( in term of finding job) ?&lt;/p&gt;\n\n&lt;p&gt;Feel free to write your opinion :) , and thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tmpx3", "is_robot_indexable": true, "report_reasons": null, "author": "Notyf007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tmpx3/advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tmpx3/advice_needed/", "subreddit_subscribers": 858151, "created_utc": 1679047240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I am very new to gans and am creating my own gan to generate images of dogs. \\[Here\\]([https://www.kaggle.com/datasets/sapal6/motion](https://www.kaggle.com/datasets/sapal6/motion)) is the dataset from which I have removed the kids label. I have experimented with many different hyperparameters but all seem to only produce random noise. I am using the mnist digit generator as a reference. \\[Here\\]([https://colab.research.google.com/drive/1sFLNIqmSjbbZPkRXlU8W6fxiA0U4ab56?usp=sharing](https://colab.research.google.com/drive/1sFLNIqmSjbbZPkRXlU8W6fxiA0U4ab56?usp=sharing)) is my colab notebook\n\n&amp;#x200B;\n\nThis is what it generated at epoch 1:\n\n[https://i.stack.imgur.com/b1Lva.png](https://i.stack.imgur.com/b1Lva.png)\n\nThis is what it generated at epoch 50:\n\n  \\[2\\]: [https://i.stack.imgur.com/k4yeu.png](https://i.stack.imgur.com/k4yeu.png)", "author_fullname": "t2_uubridic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dog DCGan just produces random noise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tlc4k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679042977.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679042515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am very new to gans and am creating my own gan to generate images of dogs. [Here](&lt;a href=\"https://www.kaggle.com/datasets/sapal6/motion\"&gt;https://www.kaggle.com/datasets/sapal6/motion&lt;/a&gt;) is the dataset from which I have removed the kids label. I have experimented with many different hyperparameters but all seem to only produce random noise. I am using the mnist digit generator as a reference. [Here](&lt;a href=\"https://colab.research.google.com/drive/1sFLNIqmSjbbZPkRXlU8W6fxiA0U4ab56?usp=sharing\"&gt;https://colab.research.google.com/drive/1sFLNIqmSjbbZPkRXlU8W6fxiA0U4ab56?usp=sharing&lt;/a&gt;) is my colab notebook&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is what it generated at epoch 1:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.stack.imgur.com/b1Lva.png\"&gt;https://i.stack.imgur.com/b1Lva.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is what it generated at epoch 50:&lt;/p&gt;\n\n&lt;p&gt;[2]: &lt;a href=\"https://i.stack.imgur.com/k4yeu.png\"&gt;https://i.stack.imgur.com/k4yeu.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IYiXesU2vSta-jnuZl4VB7Rax-KgXS_DHNji_oDbYeU.png?auto=webp&amp;v=enabled&amp;s=b25d5ce774fdbee78bb0836f146b9ae2c474de9c", "width": 360, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/IYiXesU2vSta-jnuZl4VB7Rax-KgXS_DHNji_oDbYeU.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee618e4f241530284f5827d99a885c5fc4930177", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/IYiXesU2vSta-jnuZl4VB7Rax-KgXS_DHNji_oDbYeU.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe6b09e450f040a7ee882f7e8f5cf1ee1e0a06ea", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/IYiXesU2vSta-jnuZl4VB7Rax-KgXS_DHNji_oDbYeU.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28b05491cde530afae6958ba42b5e903cf2e422d", "width": 320, "height": 320}], "variants": {}, "id": "EiujrNJfCNA4oXJM2_hccgdx4TzRREddsNIEA0YgYAk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tlc4k", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Leg4739", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tlc4k/dog_dcgan_just_produces_random_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tlc4k/dog_dcgan_just_produces_random_noise/", "subreddit_subscribers": 858151, "created_utc": 1679042515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am having trouble understanding a few things and I am certain that there is an error somewhere since the results are too good. \nI have a dataset that has 4 input features and about a thousand output features (the dataset is large ~40k instances). It's a tough problem but when I train an MLP it works just fine (the whole standard by the book approach), no train/validation loss over-fitting, the metrics are good and the kfold cross-validation shows good results.\n\nNow I was a little annoyed by the 1000 output feature space so I had the idea to try and see if I could apply PCA on the output set, and it turns out that the explained variance is about 86% for only one principal component which is quite strange (this is the first weird part and in the context of my problem I don't even know how to interpret it). The output features are equally meaningful in the context of the problem I am modeling. When I try to see the compression-decompression error it can do it perfectly when the problem is reduced to around 10 components.\n\nMy procedure was like this: split the data into training and testing sets - fit a scaler/pca on the train set, transform the test set with the trained scaler/pca models, do an inverse transform and reconstruct the test set and compare it with the original test set (comparison metrics are r2/rmse). I also did this with several folds just to see the uncertainty and it seems there is (almost) none.\n\nEssentially, with this knowledge, I tried to incorporate the PCA procedure into training the MLP by splitting the data into test/train/validation set. I apply the scaler/pca on the train set and transform the validation set with the scaler/pca models. Then I train the MLP with the train set and incorporate the validation set to get the loss. No over-fitting. When the model is trained I get my predictions based on the input test set and convert them to the original space with the pca/scaler inverse transform.\n\n\nI do not touch the test set with the scaling/pca transforms as it only serves to get the accuracy metrics (RRMSE, R2 etc). So essentially, this not only makes things go faster, there are no signs of overfitting and even the accuracy is improved.\n\nI am extremely confident that I making a mistake with my procedure, so if someone could point this out I would appreciate it!\nThank you.", "author_fullname": "t2_ebzvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying PCA on the output features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t7ewi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679003425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am having trouble understanding a few things and I am certain that there is an error somewhere since the results are too good. \nI have a dataset that has 4 input features and about a thousand output features (the dataset is large ~40k instances). It&amp;#39;s a tough problem but when I train an MLP it works just fine (the whole standard by the book approach), no train/validation loss over-fitting, the metrics are good and the kfold cross-validation shows good results.&lt;/p&gt;\n\n&lt;p&gt;Now I was a little annoyed by the 1000 output feature space so I had the idea to try and see if I could apply PCA on the output set, and it turns out that the explained variance is about 86% for only one principal component which is quite strange (this is the first weird part and in the context of my problem I don&amp;#39;t even know how to interpret it). The output features are equally meaningful in the context of the problem I am modeling. When I try to see the compression-decompression error it can do it perfectly when the problem is reduced to around 10 components.&lt;/p&gt;\n\n&lt;p&gt;My procedure was like this: split the data into training and testing sets - fit a scaler/pca on the train set, transform the test set with the trained scaler/pca models, do an inverse transform and reconstruct the test set and compare it with the original test set (comparison metrics are r2/rmse). I also did this with several folds just to see the uncertainty and it seems there is (almost) none.&lt;/p&gt;\n\n&lt;p&gt;Essentially, with this knowledge, I tried to incorporate the PCA procedure into training the MLP by splitting the data into test/train/validation set. I apply the scaler/pca on the train set and transform the validation set with the scaler/pca models. Then I train the MLP with the train set and incorporate the validation set to get the loss. No over-fitting. When the model is trained I get my predictions based on the input test set and convert them to the original space with the pca/scaler inverse transform.&lt;/p&gt;\n\n&lt;p&gt;I do not touch the test set with the scaling/pca transforms as it only serves to get the accuracy metrics (RRMSE, R2 etc). So essentially, this not only makes things go faster, there are no signs of overfitting and even the accuracy is improved.&lt;/p&gt;\n\n&lt;p&gt;I am extremely confident that I making a mistake with my procedure, so if someone could point this out I would appreciate it!\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t7ewi", "is_robot_indexable": true, "report_reasons": null, "author": "cosmic_conspiracy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t7ewi/applying_pca_on_the_output_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t7ewi/applying_pca_on_the_output_features/", "subreddit_subscribers": 858151, "created_utc": 1679003425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey !\n\nI'm kind of a beginner and i've tasked with my first misson in my internship and i'm  not sure how to handle it .\n\nFor some context , we have multiple sentences (tasks) and each one has its own price tag .   \nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .\n\nMy mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .   \nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .\n\nI also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity \n\nAny help or advice  would be welcome !", "author_fullname": "t2_rn9s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeding embedded sentences to another model for price prediction ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sw4os", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678977870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey !&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of a beginner and i&amp;#39;ve tasked with my first misson in my internship and i&amp;#39;m  not sure how to handle it .&lt;/p&gt;\n\n&lt;p&gt;For some context , we have multiple sentences (tasks) and each one has its own price tag .&lt;br/&gt;\nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .&lt;/p&gt;\n\n&lt;p&gt;My mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .&lt;br/&gt;\nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .&lt;/p&gt;\n\n&lt;p&gt;I also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity &lt;/p&gt;\n\n&lt;p&gt;Any help or advice  would be welcome !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sw4os", "is_robot_indexable": true, "report_reasons": null, "author": "Avencher", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "subreddit_subscribers": 858151, "created_utc": 1678977870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11thgi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_svzav4ot", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.\n\nTraditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)\n\n[View Poll](https://www.reddit.com/poll/11r1c0z)", "author_fullname": "t2_svzav4ot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1c0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678785050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.&lt;/p&gt;\n\n&lt;p&gt;Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11r1c0z\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r1c0z", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceIntelligent6910", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679389850291, "options": [{"text": "Traditional Data Engineering Approach (Tool Based)", "id": "22056451"}, {"text": "Cloud based Data Engineering Approach (Cloud Services)", "id": "22056452"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 114, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "subreddit_subscribers": 93368, "created_utc": 1678785050.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1679028725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11thgi2", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceIntelligent6910", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11r1c0z", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11thgi2/traditional_data_engineering_approachonprem_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "subreddit_subscribers": 858151, "created_utc": 1679028725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I'm having second thoughts and I would loved if anyone have any info on the school, it seems shady but I'm not sure, if not what other schools you might advise me ? thank you !", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ScienceTech Institute (Paris)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t5ovw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I&amp;#39;m having second thoughts and I would loved if anyone have any info on the school, it seems shady but I&amp;#39;m not sure, if not what other schools you might advise me ? thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t5ovw", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "subreddit_subscribers": 858151, "created_utc": 1678999427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. \n\nFor example, say you want to predict whether a customer churns in the next month\n\nI assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?\n\nWhat about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?\n\nThank you!", "author_fullname": "t2_w9lhl6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best timeline to pull data for classification if predicting whether something happens within a month?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t49ti", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678996402.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678996167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. &lt;/p&gt;\n\n&lt;p&gt;For example, say you want to predict whether a customer churns in the next month&lt;/p&gt;\n\n&lt;p&gt;I assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?&lt;/p&gt;\n\n&lt;p&gt;What about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t49ti", "is_robot_indexable": true, "report_reasons": null, "author": "BlaseRaptor544", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "subreddit_subscribers": 858151, "created_utc": 1678996167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any help please?", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Science masters in paris ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t644y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any help please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t644y", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "subreddit_subscribers": 858151, "created_utc": 1679000406.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}