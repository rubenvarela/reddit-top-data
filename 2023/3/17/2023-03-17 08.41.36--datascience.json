{"kind": "Listing", "data": {"after": "t3_11t4dlm", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Today at work, I heard one guy say something along the lines of \"Yea we can move the data to trix and then slurpy it to plex\" and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha", "author_fullname": "t2_d8yn6ekd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science terminology can be wild", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t3t3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 241, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 241, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678995071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today at work, I heard one guy say something along the lines of &amp;quot;Yea we can move the data to trix and then slurpy it to plex&amp;quot; and I just had to hold in my laugh for a few minutes. Who the fuck comes up with this terminology ahahahaha&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t3t3v", "is_robot_indexable": true, "report_reasons": null, "author": "No_Boysenberry_7138", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t3t3v/data_science_terminology_can_be_wild/", "subreddit_subscribers": 858045, "created_utc": 1678995071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t171s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_47sfqfo", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "who's applying and what are you planning to build???  [https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge](https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge)", "author_fullname": "t2_47sfqfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[N] Mozilla launched a responsible AI challenge and I'm stoked about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "two", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11s8yk2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678913695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;who&amp;#39;s applying and what are you planning to build???  &lt;a href=\"https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge\"&gt;https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11s8yk2", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 2600679, "created_utc": 1678913695.0, "num_crossposts": 8, "media": null, "is_video": false}], "created": 1678989165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?auto=webp&amp;v=enabled&amp;s=872f3933723cb313c5d2d3b1c59034d195b75bc1", "width": 1366, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d26b7c9096be5df5b81ad9f7f8b908b5bd43cb54", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7214504ad55413bf36a73496e2b953798bca648", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb60ce098e8dfd1bc07b815c48a53ff8af523c74", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1393c5e705fd20e95c822b4780eb90de03f8a5c2", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a475f116f8e0d065e5efcd1b9fee3ad76befcda5", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/QIgIL0-aAfkHxaT4GcQo4VCtNdOkLVO-9BlNaIAXwRE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1f6ac8806a765c792c4804cba024c3a1f7ae24", "width": 1080, "height": 607}], "variants": {}, "id": "93LN4uKTPJPfx7v8NhE7DBvDKl7oaP5aVsVfZ7Rxbqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t171s", "is_robot_indexable": true, "report_reasons": null, "author": "joodfish", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11s8yk2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t171s/n_mozilla_launched_a_responsible_ai_challenge_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/", "subreddit_subscribers": 858045, "created_utc": 1678989165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?", "author_fullname": "t2_rugmcqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the McKinsey of Data Science Consulting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t60oq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am living in Berlin, Germany, and looking for a Job in Data Science Consulting. During my studies I have gathered a total of 6 years of data-related work experience, habe decent grades and am now looking for a fast-paced job in data (science/engineering) consulting. I am willing to put in long hours and can learn quickly. Therefore looking for a consultancy that does top-notch projects for rather large companies. Does anyone know any suiting companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t60oq", "is_robot_indexable": true, "report_reasons": null, "author": "Whathefish", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t60oq/what_is_the_mckinsey_of_data_science_consulting/", "subreddit_subscribers": 858045, "created_utc": 1679000181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new to this and so I've been wanting to know what other people have been using to make their work feel as smooth as butter. Since I've been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. **The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!**\n\nIDE: **VSCode with the Jupyter Notebook Extension**. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that **Jupyter Lab** has something like this, so if anyone has used both VSCode's notebooks and used Lab, your input would be appreciated. I hear good things about **PyCharm and Spyder**. Some people also use **Google Collab, DataSpell, and DeepNote** but I don't know enough about it. I did play around with DeepNote, and it was very cool but I didn't feel compelled to switch (and you have to pay for it!). \n\nTools:\n\n* A code helper: A few months back I was googling everything and I would've listed **Stackoverflow**. I might actually use that occasionally, but these days I use **ChatGPT** and **Bing AI**. For more current info or news-based I'll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it's great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I'm talking about and can provide a better explanation as to which is better for what purpose.\n* Software: **Excel** is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don't need with Ctrl+click to select, it's easier and quicker than copy + pasting or typing out each of the string column names I want to \"df.drop()\". Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as **Alteryx, KNIME, and Orange**. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a \"lite\" version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven't found a huge use case for them since I've been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.\n* Version Control: This is where I'm primarily lacking, but I know that **Github** is the go-to. I don't use this but I know that a ton of people do. I don't even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I'm also not too aware of what other innovative tools for version control exist.\n* Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I've recently found out about this library called **Polars**. It's basically a Rust version of Pandas, and it's super powerful. Some operations that I've run, that would've taken hours with Pandas, took me minutes. But I've been hearing that **Pandas 2.0** which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is **DuckDB** but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I'll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.\n\nAnyway, that's just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.\n\nhttps://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a", "author_fullname": "t2_gk7up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your digital workspace, tools, setup, etc. for ETL, research, production?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qj2cywt1r4oa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6026f61ce2eac4655501946e87ff28b630eafef"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=465f2b0ba6e556d68c2e38da6a0cbf88d55bdae0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78622791ecd096a9586bd2fa375924ecfa71e40c"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa7f19b7612f47b30d08371d8a6aa7c45868cab6"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df91ed30b6053048ed5f1619bcfa1bc9ca731ee0"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5eaf1df085449f3113dea76a3a8a86913761bf9c"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a"}, "id": "qj2cywt1r4oa1"}}, "name": "t3_11szca1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OuxRKRDebneIMbv8ljpRG_Aszt8idVQ8R-QV3AksOJQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678985129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to this and so I&amp;#39;ve been wanting to know what other people have been using to make their work feel as smooth as butter. Since I&amp;#39;ve been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. &lt;strong&gt;The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;IDE: &lt;strong&gt;VSCode with the Jupyter Notebook Extension&lt;/strong&gt;. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that &lt;strong&gt;Jupyter Lab&lt;/strong&gt; has something like this, so if anyone has used both VSCode&amp;#39;s notebooks and used Lab, your input would be appreciated. I hear good things about &lt;strong&gt;PyCharm and Spyder&lt;/strong&gt;. Some people also use &lt;strong&gt;Google Collab, DataSpell, and DeepNote&lt;/strong&gt; but I don&amp;#39;t know enough about it. I did play around with DeepNote, and it was very cool but I didn&amp;#39;t feel compelled to switch (and you have to pay for it!). &lt;/p&gt;\n\n&lt;p&gt;Tools:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A code helper: A few months back I was googling everything and I would&amp;#39;ve listed &lt;strong&gt;Stackoverflow&lt;/strong&gt;. I might actually use that occasionally, but these days I use &lt;strong&gt;ChatGPT&lt;/strong&gt; and &lt;strong&gt;Bing AI&lt;/strong&gt;. For more current info or news-based I&amp;#39;ll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it&amp;#39;s great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I&amp;#39;m talking about and can provide a better explanation as to which is better for what purpose.&lt;/li&gt;\n&lt;li&gt;Software: &lt;strong&gt;Excel&lt;/strong&gt; is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don&amp;#39;t need with Ctrl+click to select, it&amp;#39;s easier and quicker than copy + pasting or typing out each of the string column names I want to &amp;quot;df.drop()&amp;quot;. Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as &lt;strong&gt;Alteryx, KNIME, and Orange&lt;/strong&gt;. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a &amp;quot;lite&amp;quot; version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven&amp;#39;t found a huge use case for them since I&amp;#39;ve been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.&lt;/li&gt;\n&lt;li&gt;Version Control: This is where I&amp;#39;m primarily lacking, but I know that &lt;strong&gt;Github&lt;/strong&gt; is the go-to. I don&amp;#39;t use this but I know that a ton of people do. I don&amp;#39;t even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I&amp;#39;m also not too aware of what other innovative tools for version control exist.&lt;/li&gt;\n&lt;li&gt;Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I&amp;#39;ve recently found out about this library called &lt;strong&gt;Polars&lt;/strong&gt;. It&amp;#39;s basically a Rust version of Pandas, and it&amp;#39;s super powerful. Some operations that I&amp;#39;ve run, that would&amp;#39;ve taken hours with Pandas, took me minutes. But I&amp;#39;ve been hearing that &lt;strong&gt;Pandas 2.0&lt;/strong&gt; which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is &lt;strong&gt;DuckDB&lt;/strong&gt; but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I&amp;#39;ll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyway, that&amp;#39;s just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a\"&gt;https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=01626413e867c03a18d40309ea3a7fdd16c4064a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11szca1", "is_robot_indexable": true, "report_reasons": null, "author": "BreathAether", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/", "subreddit_subscribers": 858045, "created_utc": 1678985129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am an international student studying Statistics &amp; Data Science at one of the UCs.\n\nAs an international student, I have to land my first job within 60+90 days using OPT after graduating.\n\nI have applied to over 300+ jobs on LinkedIn(mainly data analyst roles), however, I've had 2 interviews so far.  I've been working on SQL and Tableau to boost my skills and I thought I had a solid resume with a good GPA(3.66).  \n\n\nAt this point, I thought I needed to make some changes so I could SURVIVE.   \n**Other than, keep applying to jobs with no experience, what do you guys think is the best way to land a first data science-related job?**  \n\n\nAny advice, personal experience, or anything would help me so much!!", "author_fullname": "t2_7ocdqoxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling) Data Science Jobs with NO EXPERIENCE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t6kkj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679001448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am an international student studying Statistics &amp;amp; Data Science at one of the UCs.&lt;/p&gt;\n\n&lt;p&gt;As an international student, I have to land my first job within 60+90 days using OPT after graduating.&lt;/p&gt;\n\n&lt;p&gt;I have applied to over 300+ jobs on LinkedIn(mainly data analyst roles), however, I&amp;#39;ve had 2 interviews so far.  I&amp;#39;ve been working on SQL and Tableau to boost my skills and I thought I had a solid resume with a good GPA(3.66).  &lt;/p&gt;\n\n&lt;p&gt;At this point, I thought I needed to make some changes so I could SURVIVE.&lt;br/&gt;\n&lt;strong&gt;Other than, keep applying to jobs with no experience, what do you guys think is the best way to land a first data science-related job?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Any advice, personal experience, or anything would help me so much!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t6kkj", "is_robot_indexable": true, "report_reasons": null, "author": "Revolutionary_Ad5908", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t6kkj/struggling_data_science_jobs_with_no_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t6kkj/struggling_data_science_jobs_with_no_experience/", "subreddit_subscribers": 858045, "created_utc": 1679001448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_d26sfzn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Microsoft 365 Copilot | Your Copilot for Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11t9l7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bzLOoZFvtyzBrxNO8L_ikH0-f6HG55F6-OzvgdLNV0s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679008365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blogs.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?auto=webp&amp;v=enabled&amp;s=c210621c80ef098f128f34791a8cbba8804fa192", "width": 1024, "height": 576}, "resolutions": [{"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2fadab9efd22b498f898701c58b245b01fbfa941", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=436eff9ded232646d99b0408ca91aedf25756e46", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e02245a69576d0650ddacf27ac86f9072cd1ba88", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf4035c1f7f1f33e0aceef3d92793b7b7386d58f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/de8dZiT3h-lX7e0rRZgU2uQWf3JkkVi3Gdbq6JhZDIE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b1ab2dd811546ce3177d32023a00f4a5fb48ac1", "width": 960, "height": 540}], "variants": {}, "id": "Hd-I8fTFvygbpn1E58xOKqk2mcbMlHNowXS58ZCeu4k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t9l7v", "is_robot_indexable": true, "report_reasons": null, "author": "International-Tap841", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t9l7v/introducing_microsoft_365_copilot_your_copilot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/", "subreddit_subscribers": 858045, "created_utc": 1679008365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\nThis week, I applied for a data science job at my dream company.\n\nFrom what I can see on LinkedIn, the data team lead has the same academic background as I do. He completed his PhD the year I was born, became a professor, and then transitioned to DS around the 2008 recession. I completed my PhD a few years ago, and got my first data science position shortly after. For additional information, the field of academia we share is tiny - a subfield of physics with about 2,000 people worldwide.\n\n**Should I write a cold email to the team lead?** My goal is to boost my chances for an interview.\n\nI'll add that the job posting did not have the team lead's email. I ended up finding his email on RocketReach. It does not look like he's very active on LinkedIn, otherwise I'd send him a message there. Unfortunately, it also doesn't look like he's kept up with anyone in our field of academia, otherwise I'd wrangle an intro.\n\nThanks for reading!", "author_fullname": "t2_eedxi6py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I write a cold email to the team lead at my dream company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tbhbh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679028560.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679012665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;This week, I applied for a data science job at my dream company.&lt;/p&gt;\n\n&lt;p&gt;From what I can see on LinkedIn, the data team lead has the same academic background as I do. He completed his PhD the year I was born, became a professor, and then transitioned to DS around the 2008 recession. I completed my PhD a few years ago, and got my first data science position shortly after. For additional information, the field of academia we share is tiny - a subfield of physics with about 2,000 people worldwide.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Should I write a cold email to the team lead?&lt;/strong&gt; My goal is to boost my chances for an interview.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll add that the job posting did not have the team lead&amp;#39;s email. I ended up finding his email on RocketReach. It does not look like he&amp;#39;s very active on LinkedIn, otherwise I&amp;#39;d send him a message there. Unfortunately, it also doesn&amp;#39;t look like he&amp;#39;s kept up with anyone in our field of academia, otherwise I&amp;#39;d wrangle an intro.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tbhbh", "is_robot_indexable": true, "report_reasons": null, "author": "SabinReed", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tbhbh/should_i_write_a_cold_email_to_the_team_lead_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tbhbh/should_i_write_a_cold_email_to_the_team_lead_at/", "subreddit_subscribers": 858045, "created_utc": 1679012665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A comprehensive library of features from various industries, complete with methodologies and ideas, that will significantly enhance the efficiency of ML/AI projects.\n\nWe are still in the early stages of development, and we would love to collaborate with experienced professionals in data science, ML/AI, and related fields. \n\n[https://github.com/FeatureHub-AI/FeatureHub](https://github.com/FeatureHub-AI/FeatureHub)", "author_fullname": "t2_73c7xq817", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The library of features for various AI/ML projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sskaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678969257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A comprehensive library of features from various industries, complete with methodologies and ideas, that will significantly enhance the efficiency of ML/AI projects.&lt;/p&gt;\n\n&lt;p&gt;We are still in the early stages of development, and we would love to collaborate with experienced professionals in data science, ML/AI, and related fields. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/FeatureHub-AI/FeatureHub\"&gt;https://github.com/FeatureHub-AI/FeatureHub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sskaq", "is_robot_indexable": true, "report_reasons": null, "author": "irynagrv", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sskaq/the_library_of_features_for_various_aiml_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sskaq/the_library_of_features_for_various_aiml_projects/", "subreddit_subscribers": 858045, "created_utc": 1678969257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019d often see job postings with data scientists, senior data scientists, and staff data scientists. \n\nWhat are the general responsibilities and expectations at each level? Seems like they differ depending on the company as well.", "author_fullname": "t2_kq3pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do levels of data scientists differ in responsiblity and expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t7m7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679011344.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679003914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d often see job postings with data scientists, senior data scientists, and staff data scientists. &lt;/p&gt;\n\n&lt;p&gt;What are the general responsibilities and expectations at each level? Seems like they differ depending on the company as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t7m7b", "is_robot_indexable": true, "report_reasons": null, "author": "marlinclark", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t7m7b/how_do_levels_of_data_scientists_differ_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t7m7b/how_do_levels_of_data_scientists_differ_in/", "subreddit_subscribers": 858045, "created_utc": 1679003914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "To get a practical + theoretical understanding with a critical review of:\n- ANOVA vs Linear Regression ~ overlap, pros vs cons, when to apply, which assumptions are important vs. not important, , how to test assumptions, how to deal when assumptions are violated (e.g. sample sizes not equal, heterogenous variance, etc.)\n- Bootstrap Approaches &amp; Permutation Testing - pros and cons, when to apply, pros vs cons, assumptioms if any, etc. \n- General best practices for statistical testing in practice (e.g. Applied to AB testing) \n\nNote: There's such a mess of contradictory resources online re: statistics.", "author_fullname": "t2_vjpbgi84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation for books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj6nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679034506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To get a practical + theoretical understanding with a critical review of:\n- ANOVA vs Linear Regression ~ overlap, pros vs cons, when to apply, which assumptions are important vs. not important, , how to test assumptions, how to deal when assumptions are violated (e.g. sample sizes not equal, heterogenous variance, etc.)\n- Bootstrap Approaches &amp;amp; Permutation Testing - pros and cons, when to apply, pros vs cons, assumptioms if any, etc. \n- General best practices for statistical testing in practice (e.g. Applied to AB testing) &lt;/p&gt;\n\n&lt;p&gt;Note: There&amp;#39;s such a mess of contradictory resources online re: statistics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tj6nj", "is_robot_indexable": true, "report_reasons": null, "author": "AlwaysHungry4Data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tj6nj/recommendation_for_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tj6nj/recommendation_for_books/", "subreddit_subscribers": 858045, "created_utc": 1679034506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset consisting of about 1 Billion strings.\n\nI\u2019m trying to find a quick way to search for substrings within the strings and I haven\u2019t been able to figure it out yet. I want to be able to search for substrings in a few different ways:\n\nSample string: \u201chello\u201d\n\nSearches that should return that string:\nhell*\n*ello\n*ell*\nhe*lo\n*e*l*\n\nNote that * represents wildcard in this example\n\nI can successfully get this to work using splunk but it\u2019s very slow. I can get it to work with Elasticsearch and Kibana but I hate maintaining that stack. I tried another tool called zincsearch but it wasn\u2019t very happy with the amount of records I was using.\n\nIs there a simple and fast tool that would allow me to run the sort of searches that I want to run on such a big dataset.\n\nSorry if this is a massive noob question, I work in cyber security and do a fair bit of data analysis but I\u2019m definitely new to the world of data science tools.", "author_fullname": "t2_hssvfekn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tools for searching a huge text dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj1nj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679034016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset consisting of about 1 Billion strings.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to find a quick way to search for substrings within the strings and I haven\u2019t been able to figure it out yet. I want to be able to search for substrings in a few different ways:&lt;/p&gt;\n\n&lt;p&gt;Sample string: \u201chello\u201d&lt;/p&gt;\n\n&lt;p&gt;Searches that should return that string:\nhell*\n&lt;em&gt;ello\n*ell&lt;/em&gt;\nhe&lt;em&gt;lo\n*e&lt;/em&gt;l*&lt;/p&gt;\n\n&lt;p&gt;Note that * represents wildcard in this example&lt;/p&gt;\n\n&lt;p&gt;I can successfully get this to work using splunk but it\u2019s very slow. I can get it to work with Elasticsearch and Kibana but I hate maintaining that stack. I tried another tool called zincsearch but it wasn\u2019t very happy with the amount of records I was using.&lt;/p&gt;\n\n&lt;p&gt;Is there a simple and fast tool that would allow me to run the sort of searches that I want to run on such a big dataset.&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is a massive noob question, I work in cyber security and do a fair bit of data analysis but I\u2019m definitely new to the world of data science tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tj1nj", "is_robot_indexable": true, "report_reasons": null, "author": "k7r7f80d", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11tj1nj/tools_for_searching_a_huge_text_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11tj1nj/tools_for_searching_a_huge_text_dataset/", "subreddit_subscribers": 858045, "created_utc": 1679034016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello hello \ud83d\udc4b.\n\nI hope you are doing well.\n\nThis is Ella 24F , I am looking for a friend good at SQL,excel and python.A friend who is passionate about building skills and whom we can help each other grow career wise\ud83d\ude0a\ud83d\ude0a\nBesides the mentioned skills, I am open to learning other skills .If you enjoy such topics and discussions DM.\n\nAbout me:\n\ud83d\udd16Control and instrumentation scientist.\n\ud83d\udd16Currently learning software engnr\n\ud83d\udd16Open to learning new skills, to perform well in my current role .( team handling, data analysis and reporting )\n\nLet's grow together \ud83e\udd70\u2728\ud83e\udd70", "author_fullname": "t2_6n12vsxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL,excel, python study friend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t83jn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679005020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello hello \ud83d\udc4b.&lt;/p&gt;\n\n&lt;p&gt;I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;This is Ella 24F , I am looking for a friend good at SQL,excel and python.A friend who is passionate about building skills and whom we can help each other grow career wise\ud83d\ude0a\ud83d\ude0a\nBesides the mentioned skills, I am open to learning other skills .If you enjoy such topics and discussions DM.&lt;/p&gt;\n\n&lt;p&gt;About me:\n\ud83d\udd16Control and instrumentation scientist.\n\ud83d\udd16Currently learning software engnr\n\ud83d\udd16Open to learning new skills, to perform well in my current role .( team handling, data analysis and reporting )&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s grow together \ud83e\udd70\u2728\ud83e\udd70&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t83jn", "is_robot_indexable": true, "report_reasons": null, "author": "Flosy22", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t83jn/sqlexcel_python_study_friend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t83jn/sqlexcel_python_study_friend/", "subreddit_subscribers": 858045, "created_utc": 1679005020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am having trouble understanding a few things and I am certain that there is an error somewhere since the results are too good. \nI have a dataset that has 4 input features and about a thousand output features (the dataset is large ~40k instances). It's a tough problem but when I train an MLP it works just fine (the whole standard by the book approach), no train/validation loss over-fitting, the metrics are good and the kfold cross-validation shows good results.\n\nNow I was a little annoyed by the 1000 output feature space so I had the idea to try and see if I could apply PCA on the output set, and it turns out that the explained variance is about 86% for only one principal component which is quite strange (this is the first weird part and in the context of my problem I don't even know how to interpret it). The output features are equally meaningful in the context of the problem I am modeling. When I try to see the compression-decompression error it can do it perfectly when the problem is reduced to around 10 components.\n\nMy procedure was like this: split the data into training and testing sets - fit a scaler/pca on the train set, transform the test set with the trained scaler/pca models, do an inverse transform and reconstruct the test set and compare it with the original test set (comparison metrics are r2/rmse). I also did this with several folds just to see the uncertainty and it seems there is (almost) none.\n\nEssentially, with this knowledge, I tried to incorporate the PCA procedure into training the MLP by splitting the data into test/train/validation set. I apply the scaler/pca on the train set and transform the validation set with the scaler/pca models. Then I train the MLP with the train set and incorporate the validation set to get the loss. No over-fitting. When the model is trained I get my predictions based on the input test set and convert them to the original space with the pca/scaler inverse transform.\n\n\nI do not touch the test set with the scaling/pca transforms as it only serves to get the accuracy metrics (RRMSE, R2 etc). So essentially, this not only makes things go faster, there are no signs of overfitting and even the accuracy is improved.\n\nI am extremely confident that I making a mistake with my procedure, so if someone could point this out I would appreciate it!\nThank you.", "author_fullname": "t2_ebzvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying PCA on the output features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t7ewi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679003425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am having trouble understanding a few things and I am certain that there is an error somewhere since the results are too good. \nI have a dataset that has 4 input features and about a thousand output features (the dataset is large ~40k instances). It&amp;#39;s a tough problem but when I train an MLP it works just fine (the whole standard by the book approach), no train/validation loss over-fitting, the metrics are good and the kfold cross-validation shows good results.&lt;/p&gt;\n\n&lt;p&gt;Now I was a little annoyed by the 1000 output feature space so I had the idea to try and see if I could apply PCA on the output set, and it turns out that the explained variance is about 86% for only one principal component which is quite strange (this is the first weird part and in the context of my problem I don&amp;#39;t even know how to interpret it). The output features are equally meaningful in the context of the problem I am modeling. When I try to see the compression-decompression error it can do it perfectly when the problem is reduced to around 10 components.&lt;/p&gt;\n\n&lt;p&gt;My procedure was like this: split the data into training and testing sets - fit a scaler/pca on the train set, transform the test set with the trained scaler/pca models, do an inverse transform and reconstruct the test set and compare it with the original test set (comparison metrics are r2/rmse). I also did this with several folds just to see the uncertainty and it seems there is (almost) none.&lt;/p&gt;\n\n&lt;p&gt;Essentially, with this knowledge, I tried to incorporate the PCA procedure into training the MLP by splitting the data into test/train/validation set. I apply the scaler/pca on the train set and transform the validation set with the scaler/pca models. Then I train the MLP with the train set and incorporate the validation set to get the loss. No over-fitting. When the model is trained I get my predictions based on the input test set and convert them to the original space with the pca/scaler inverse transform.&lt;/p&gt;\n\n&lt;p&gt;I do not touch the test set with the scaling/pca transforms as it only serves to get the accuracy metrics (RRMSE, R2 etc). So essentially, this not only makes things go faster, there are no signs of overfitting and even the accuracy is improved.&lt;/p&gt;\n\n&lt;p&gt;I am extremely confident that I making a mistake with my procedure, so if someone could point this out I would appreciate it!\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t7ewi", "is_robot_indexable": true, "report_reasons": null, "author": "cosmic_conspiracy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t7ewi/applying_pca_on_the_output_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t7ewi/applying_pca_on_the_output_features/", "subreddit_subscribers": 858045, "created_utc": 1679003425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey !\n\nI'm kind of a beginner and i've tasked with my first misson in my internship and i'm  not sure how to handle it .\n\nFor some context , we have multiple sentences (tasks) and each one has its own price tag .   \nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .\n\nMy mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .   \nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .\n\nI also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity \n\nAny help or advice  would be welcome !", "author_fullname": "t2_rn9s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeding embedded sentences to another model for price prediction ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sw4os", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678977870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey !&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of a beginner and i&amp;#39;ve tasked with my first misson in my internship and i&amp;#39;m  not sure how to handle it .&lt;/p&gt;\n\n&lt;p&gt;For some context , we have multiple sentences (tasks) and each one has its own price tag .&lt;br/&gt;\nThe goal is to predict the price of new sentences . The method currently used is embedding the tasks using SBERT and then using cosine similarity to find the K nearest neighbors in the train database to guess the price .&lt;/p&gt;\n\n&lt;p&gt;My mission consist of finding an alternative to the Knearest neighbor method  by feeding the sentences embedding to a regression(or other) model .&lt;br/&gt;\nI tried feeding the embeddings to some basic regression models ( lasso regressor , neural networks) but the results are disastrous .&lt;/p&gt;\n\n&lt;p&gt;I also tried looking for some papers/articles to see if someone has tried doing the same before but everyone just uses cosine similarity &lt;/p&gt;\n\n&lt;p&gt;Any help or advice  would be welcome !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sw4os", "is_robot_indexable": true, "report_reasons": null, "author": "Avencher", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sw4os/feeding_embedded_sentences_to_another_model_for/", "subreddit_subscribers": 858045, "created_utc": 1678977870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have tables stored in a datalake that are being treated via pyspark. They are upwards to 10million rows for each month, some pilling up to hundreds of millions.\nThe total values  counted last week, regarding data from February chenged when  counted again today.\n\nThe date of reference is the date that the row was processed, so there is not new data being added, since it would be counted as being processed in march if it was inputed this week.\n\nThe only process that is running that changes the total is a deduplication process that follows the logic of Last position of the client if they had a positive decision or the last negative decision, nothing else.\n\nI can't for the love of god discover why this happens, and there seems to be no connection to the table size since some really small tables(some hundred thousands rows) are behaving the same way.", "author_fullname": "t2_axhjl6nf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can cause changes in a data lake table total observations???", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sshqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678969078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tables stored in a datalake that are being treated via pyspark. They are upwards to 10million rows for each month, some pilling up to hundreds of millions.\nThe total values  counted last week, regarding data from February chenged when  counted again today.&lt;/p&gt;\n\n&lt;p&gt;The date of reference is the date that the row was processed, so there is not new data being added, since it would be counted as being processed in march if it was inputed this week.&lt;/p&gt;\n\n&lt;p&gt;The only process that is running that changes the total is a deduplication process that follows the logic of Last position of the client if they had a positive decision or the last negative decision, nothing else.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t for the love of god discover why this happens, and there seems to be no connection to the table size since some really small tables(some hundred thousands rows) are behaving the same way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sshqn", "is_robot_indexable": true, "report_reasons": null, "author": "One_Kaleidoscope_271", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sshqn/what_can_cause_changes_in_a_data_lake_table_total/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sshqn/what_can_cause_changes_in_a_data_lake_table_total/", "subreddit_subscribers": 858045, "created_utc": 1678969078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)", "author_fullname": "t2_7dah3w1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Smarty-GPT: library of prompts/contexts (connected with Awesome Prompts Chat GPT)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sp0yn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1678958500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a &lt;strong&gt;TRANSPARENT&lt;/strong&gt; way to end users.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/citiususc/Smarty-GPT\"&gt;https://github.com/citiususc/Smarty-GPT&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?auto=webp&amp;v=enabled&amp;s=4c4e24f34f2d2048c36c709970f8b0a1f554763b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08317e2847b960e563e3760767f8996f74ffec91", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5ffa97632b3db9cdbcadea2e79c7397fcee942a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=150c1fc2bcb8f1988d5c51893f9f39430a052aeb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1161943b7223878b97b477932eab962225efd7d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6a7c3f67eda6e09b4e1c5da80509311d705e723", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/eYPgtTfoCyHYZ23pDzz3APKQFsu-KhhtcT9KhrG2Mbk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=965bf12a639553a1544471b20965e8ffffb1020e", "width": 1080, "height": 540}], "variants": {}, "id": "-sE09W2NVnKrkkxWVPCHfeOdIP9QoKJRenZt2uMdLIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sp0yn", "is_robot_indexable": true, "report_reasons": null, "author": "usc-ur", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sp0yn/smartygpt_library_of_promptscontexts_connected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sp0yn/smartygpt_library_of_promptscontexts_connected/", "subreddit_subscribers": 858045, "created_utc": 1678958500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, hope you\u2019re doing well.\n\nAs part of one of the requests, we\u2019re analysing the data of lost sales opportunities for a particular customer of ours. I wanted to know if there\u2019s any insight that we could generate from this data, other than the usual (Account owner wise wins, Sales cycle time etc).\n\nThanks in advance!", "author_fullname": "t2_7l62js01", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insights for lost sales opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11so12z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678954869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, hope you\u2019re doing well.&lt;/p&gt;\n\n&lt;p&gt;As part of one of the requests, we\u2019re analysing the data of lost sales opportunities for a particular customer of ours. I wanted to know if there\u2019s any insight that we could generate from this data, other than the usual (Account owner wise wins, Sales cycle time etc).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11so12z", "is_robot_indexable": true, "report_reasons": null, "author": "MuayThaiandMolly", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11so12z/insights_for_lost_sales_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11so12z/insights_for_lost_sales_opportunities/", "subreddit_subscribers": 858045, "created_utc": 1678954869.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11thgi2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_svzav4ot", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.\n\nTraditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)\n\n[View Poll](https://www.reddit.com/poll/11r1c0z)", "author_fullname": "t2_svzav4ot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11r1c0z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678785050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Put your thoughts on where are the current demands and what will be the future demand, Which will sustain for longer.&lt;/p&gt;\n\n&lt;p&gt;Traditional Data Engineering approach(On-Prem Tools) vs Cloud Based approach (Native features in Azure/AWS/GCP)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11r1c0z\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11r1c0z", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceIntelligent6910", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679389850291, "options": [{"text": "Traditional Data Engineering Approach (Tool Based)", "id": "22056451"}, {"text": "Cloud based Data Engineering Approach (Cloud Services)", "id": "22056452"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 111, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "subreddit_subscribers": 93346, "created_utc": 1678785050.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1679028725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11thgi2", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceIntelligent6910", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11r1c0z", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11thgi2/traditional_data_engineering_approachonprem_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataengineering/comments/11r1c0z/traditional_data_engineering_approachonprem_tools/", "subreddit_subscribers": 858045, "created_utc": 1679028725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I'm having second thoughts and I would loved if anyone have any info on the school, it seems shady but I'm not sure, if not what other schools you might advise me ? thank you !", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ScienceTech Institute (Paris)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t5ovw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678999427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI applied to dsti, went through the entry exam, interview etc..I&amp;#39;m having second thoughts and I would loved if anyone have any info on the school, it seems shady but I&amp;#39;m not sure, if not what other schools you might advise me ? thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t5ovw", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t5ovw/data_sciencetech_institute_paris/", "subreddit_subscribers": 858045, "created_utc": 1678999427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. \n\nFor example, say you want to predict whether a customer churns in the next month\n\nI assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?\n\nWhat about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?\n\nThank you!", "author_fullname": "t2_w9lhl6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the best timeline to pull data for classification if predicting whether something happens within a month?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t49ti", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1678996402.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678996167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, hoping you guys can help my understanding of the data to pull when you wanna classify within a time period.  I\u2019ve done a bit of classification project work but was confused on this part. &lt;/p&gt;\n\n&lt;p&gt;For example, say you want to predict whether a customer churns in the next month&lt;/p&gt;\n\n&lt;p&gt;I assume you\u2019d gather data for the customer for the month prior?  Would you aggregate data for the past or look at them solely during that month eg their active packages during that month?&lt;/p&gt;\n\n&lt;p&gt;What about the 0 classes, as in people who didn\u2019t churn to compare to.  Would you just gather random months for them or do something different?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t49ti", "is_robot_indexable": true, "report_reasons": null, "author": "BlaseRaptor544", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t49ti/whats_the_best_timeline_to_pull_data_for/", "subreddit_subscribers": 858045, "created_utc": 1678996167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/citiususc/pyplexity](https://github.com/citiususc/pyplexity)", "author_fullname": "t2_7dah3w1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyplexity: cleaning scraped text (better than BS4!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11sp1iu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678958557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/citiususc/pyplexity\"&gt;https://github.com/citiususc/pyplexity&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11sp1iu", "is_robot_indexable": true, "report_reasons": null, "author": "usc-ur", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11sp1iu/pyplexity_cleaning_scraped_text_better_than_bs4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11sp1iu/pyplexity_cleaning_scraped_text_better_than_bs4/", "subreddit_subscribers": 858045, "created_utc": 1678958557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any help please?", "author_fullname": "t2_qvxqo1oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Science masters in paris ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t644y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679000406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any help please?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t644y", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Fall_2660", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t644y/best_data_science_masters_in_paris/", "subreddit_subscribers": 858045, "created_utc": 1679000406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i am a beginner but have some theoretical knowledge about data science as an undergrad student.\n\ni travel by public transportation all the time and the frequency is supposed to be 15 mins but it goes up to an hour sometimes.  i want to find out what factors affect the time and how it can be solved!", "author_fullname": "t2_uz1t4ape", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "looking for some guidance on personal data science project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t0j0a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678987695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i am a beginner but have some theoretical knowledge about data science as an undergrad student.&lt;/p&gt;\n\n&lt;p&gt;i travel by public transportation all the time and the frequency is supposed to be 15 mins but it goes up to an hour sometimes.  i want to find out what factors affect the time and how it can be solved!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t0j0a", "is_robot_indexable": true, "report_reasons": null, "author": "mani-maau", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t0j0a/looking_for_some_guidance_on_personal_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t0j0a/looking_for_some_guidance_on_personal_data/", "subreddit_subscribers": 858045, "created_utc": 1678987695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, can you help me finding a PC? Im an economics studente and i Will start learning some R and phyton. After the bachelor i will go for a masters in statistica and i think i would like to get into data science after it. My budget Is 1500 but i evacuate every best deal\nAnother question: you think a MacBook Air would be fine?", "author_fullname": "t2_qynyfdtk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best pc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t4qkx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678997230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, can you help me finding a PC? Im an economics studente and i Will start learning some R and phyton. After the bachelor i will go for a masters in statistica and i think i would like to get into data science after it. My budget Is 1500 but i evacuate every best deal\nAnother question: you think a MacBook Air would be fine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11t4qkx", "is_robot_indexable": true, "report_reasons": null, "author": "AcanthaceaeTiny2348", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t4qkx/best_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11t4qkx/best_pc/", "subreddit_subscribers": 858045, "created_utc": 1678997230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I am building my firsts deep-learning based projects and i just noticed that pytorch 2.0 is officially available. I started to learn tensorflow a while ago, but i have heard that pytorch is one of the most popular DL frameworks out there besides tf. Which one you guys prefer and why?\n\n[View Poll](https://www.reddit.com/poll/11t4dlm)", "author_fullname": "t2_cl9x61e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choose wisely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t4dlm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1678996409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I am building my firsts deep-learning based projects and i just noticed that pytorch 2.0 is officially available. I started to learn tensorflow a while ago, but i have heard that pytorch is one of the most popular DL frameworks out there besides tf. Which one you guys prefer and why?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11t4dlm\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "11t4dlm", "is_robot_indexable": true, "report_reasons": null, "author": "nickpngc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1679255609122, "options": [{"text": "Tensorflow 2.0", "id": "22095470"}, {"text": "Pytorch 2.0", "id": "22095471"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 106, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11t4dlm/choose_wisely/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/11t4dlm/choose_wisely/", "subreddit_subscribers": 858045, "created_utc": 1678996409.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}