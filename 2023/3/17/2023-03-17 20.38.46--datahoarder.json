{"kind": "Listing", "data": {"after": "t3_11t8akp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he's here lol). \n\nMy friend is into retro game preservation and it just reminded me of him.\n\nEdit: Thanks for all the responses. Idek who to reply to hahaha I was expecting like one person to respond and that was it.", "author_fullname": "t2_g4f3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is the guy who is trying to download every single game?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11toc7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 321, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 321, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679082899.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679052290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I vaguely remember reading or watching an article about this dude who is trying to download every single game ever made. He had something like 40000 unique titles dating back to when games first started. I figured you guys might know him (or maybe he&amp;#39;s here lol). &lt;/p&gt;\n\n&lt;p&gt;My friend is into retro game preservation and it just reminded me of him.&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for all the responses. Idek who to reply to hahaha I was expecting like one person to respond and that was it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11toc7v", "is_robot_indexable": true, "report_reasons": null, "author": "AggressiveChairs", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11toc7v/who_is_the_guy_who_is_trying_to_download_every/", "subreddit_subscribers": 673526, "created_utc": 1679052290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "basically to use them for a media server NAS, and I have found very good options on ebay.\n\nIt is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.", "author_fullname": "t2_6hxjwymn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth buying used hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11taniw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;basically to use them for a media server NAS, and I have found very good options on ebay.&lt;/p&gt;\n\n&lt;p&gt;It is possible to know what to buy and if there is any indicator that you should know in order to make a good purchase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11taniw", "is_robot_indexable": true, "report_reasons": null, "author": "AngelGrade", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11taniw/is_it_worth_buying_used_hard_drives/", "subreddit_subscribers": 673526, "created_utc": 1679010838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.youtube.com/watch?v=Jqg1G78cH2A](https://www.youtube.com/watch?v=Jqg1G78cH2A)", "author_fullname": "t2_twm9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Level 1 Techs take on Home Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tklqs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679039756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=Jqg1G78cH2A\"&gt;https://www.youtube.com/watch?v=Jqg1G78cH2A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?auto=webp&amp;v=enabled&amp;s=e10203b6f26b668551d1bf3bfa0ade3d815217bc", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45eef7149926b12a2a271680da9e54badc728f73", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a2f22518553258836e69a6d5c85158f1db9c269", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HbrFY6sZbBnHfDuFaYHFRCyhVgLoszYApq3aNNvWpJc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba2226fc27492309a02fc71d9fda027f75e56d4c", "width": 320, "height": 240}], "variants": {}, "id": "gPB9teADkSdeoYYiYccNMY4LdCypTI_dFt6qjnKE2BY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "103TB - Keep on Shucking....", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tklqs", "is_robot_indexable": true, "report_reasons": null, "author": "Graham2405", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tklqs/level_1_techs_take_on_home_server/", "subreddit_subscribers": 673526, "created_utc": 1679039756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.\n\nI want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.\n\nIs it possible to do with Synology?", "author_fullname": "t2_6c8sl4j0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to use one bay of a synology as a separated volume backups of my friend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tnzul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679051241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is not really clear what I want reading the question. Thats because I dont really know how to ask it. I will explain.&lt;/p&gt;\n\n&lt;p&gt;I want to populate my 5-bay with four 4 TB drives. And the last one I want to use as a backup for my friends synology. The trick is - I want the 5th backup volume to have a different size of 16-20 TB. And it will be exclusively used to backup my friends synology NAS.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to do with Synology?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tnzul", "is_robot_indexable": true, "report_reasons": null, "author": "Bit-Beats", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tnzul/is_it_possible_to_use_one_bay_of_a_synology_as_a/", "subreddit_subscribers": 673526, "created_utc": 1679051241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tnub1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_11rvc4", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ipfs", "selftext": "Hello All,\n\nWith DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.\n\nTo me, there seems to be a couple straight forward solutions:\n\n* quay.io: open source but still centralized and ran by single for profit\n* Gitlab.com registry: open source but still centralized and ran by single for profit\n* GitHub.com registry: Same boat as DockerHub but larger corporation\n* Running your own personal registry: Additional work for each party involved, low discovery options.\n\nNow with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.\n\nHere some decentralized options and strategies I've found so far:\n\n## nerdctl ipfs support\n\n[nerdctl](https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md) supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn't exactly a cloud native approach (running systemd services on each node...). \n\n## IPDR: InterPlanetary Docker Registry\n\n[IPDR](https://github.com/ipdr/ipdr) is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec\n\n## ociipfs OCI layer to IPFS content translation\n\n[ociipfs](https://github.com/mkmik/ocipfs) this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.\n\n## My thoughts\nIf you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for [BuildKit](https://github.com/moby/buildkit/pull/3510) that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.\n\nThe last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.\n\nLastly, this is just some last minute research on my part and would love to hear more people's thoughts!\n\nEdit 1 some points made in discussion:\n\nHaving a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.\n\n[Gitea](https://nlnet.nl/project/Gitea/) and it's fork [Forgejo](https://forgejo.org/) both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.\n\nEdit 2\nSister post on [Mastadon/Fediverse](https://qoto.org/@fruitywelsh/110040008742819906)!", "author_fullname": "t2_11rvc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DockerHub replacement stratagy and options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ipfs", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tjca7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679083651.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679035047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;With DockerHub removing its free tier and potential for future shenanigans, people are looking to move away from them for free and personal use.&lt;/p&gt;\n\n&lt;p&gt;To me, there seems to be a couple straight forward solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;quay.io: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;Gitlab.com registry: open source but still centralized and ran by single for profit&lt;/li&gt;\n&lt;li&gt;GitHub.com registry: Same boat as DockerHub but larger corporation&lt;/li&gt;\n&lt;li&gt;Running your own personal registry: Additional work for each party involved, low discovery options.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now with the boring, straightforward solutions mentioned, and the bar set, I am going to suggest that we take this opportunity to push for a better long term solution.\nPush for decentralized storage of OCI images and federated metadata support. The only urgency I see is that, because of the bone headiness of the latest Docker decision, frogs are actually jumping out of the pot, and I fear they might turn down the temp to a slower boil, or people might just jump into a slower cooker like github. Either way, the status quo looks to be a slow boiling away of the common infrastructure we are used today.&lt;/p&gt;\n\n&lt;p&gt;Here some decentralized options and strategies I&amp;#39;ve found so far:&lt;/p&gt;\n\n&lt;h2&gt;nerdctl ipfs support&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/containerd/nerdctl/blob/main/docs/ipfs.md\"&gt;nerdctl&lt;/a&gt; supports IPFS for both image pulling and pushing, including encrypted images and eStargz lazy pulling. For building, the current method is a locally hosted translator so that the traditional pulls can be converted to work over IPFS. They even have docs on running it on k8s node, though if my reading is correct this isn&amp;#39;t exactly a cloud native approach (running systemd services on each node...). &lt;/p&gt;\n\n&lt;h2&gt;IPDR: InterPlanetary Docker Registry&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ipdr/ipdr\"&gt;IPDR&lt;/a&gt; is a service to allow for images stored on IPFS to be accessible over Docker Registry HTTP API V2 Spec&lt;/p&gt;\n\n&lt;h2&gt;ociipfs OCI layer to IPFS content translation&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/mkmik/ocipfs\"&gt;ociipfs&lt;/a&gt; this is tool to be able to translate to IPFS stored layers as the expected OCI layers and pulls found in the Docker build system.&lt;/p&gt;\n\n&lt;h2&gt;My thoughts&lt;/h2&gt;\n\n&lt;p&gt;If you notice, the same thing I noticed in this list is that most of these are workarounds to support the web2 api on IPFS. There is a pull in draft for &lt;a href=\"https://github.com/moby/buildkit/pull/3510\"&gt;BuildKit&lt;/a&gt; that may make native IPFS image support better on the image build side. With the work on the nerdctl side being the most direct support for images for pushing and pulling images with IPFS hashes.&lt;/p&gt;\n\n&lt;p&gt;The last piece I hope you noticed is that none of these answer the discoverability question, and with none human friendly name spacing on the hashes do not serve well for code readability on either the ops or build side of the house. IPNS could serve to help the latter, but I think that something like an ActivityPub/Fediverse enabled site may better serve as a hosting point for images, allowing for multiple actors to better curate images, tags, Cosign, ipfs links, and other metadata for end users to select from.&lt;/p&gt;\n\n&lt;p&gt;Lastly, this is just some last minute research on my part and would love to hear more people&amp;#39;s thoughts!&lt;/p&gt;\n\n&lt;p&gt;Edit 1 some points made in discussion:&lt;/p&gt;\n\n&lt;p&gt;Having a hard requirement on running a full IPFS daemon and node would be barriar to entry for a lot of people, and so if IPFS is used it should more ideally be used in a totally contained way.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nlnet.nl/project/Gitea/\"&gt;Gitea&lt;/a&gt; and it&amp;#39;s fork &lt;a href=\"https://forgejo.org/\"&gt;Forgejo&lt;/a&gt; both have federation via ForgePub in work and registry support, and thus maybe solid points targets for a federated/decentralized platform.&lt;/p&gt;\n\n&lt;p&gt;Edit 2\nSister post on &lt;a href=\"https://qoto.org/@fruitywelsh/110040008742819906\"&gt;Mastadon/Fediverse&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_34dae", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11tjca7", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 14724, "created_utc": 1679035047.0, "num_crossposts": 13, "media": null, "is_video": false}], "created": 1679050817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ipfs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?auto=webp&amp;v=enabled&amp;s=1f4708f79efddbe54bbaf9cf461dfef5cdf551c6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488d993d8de8f8c9ba0ddae74adcc9f501ca583d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3e44531a3637ff640720468efc2758f114a2010", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84009f2729ab788ee83d9d98518fb8706b02324b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=884f5508875ba3da8d5aa33bb6c2685ee5515d03", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c527718ff9712371f13e271c3acd04612331e1", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qAlm5m_PVz21r1Tt3ZQBx_6AP6MpRklZ5CFGiHDETnw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d0a00c5d5c7b4c733ebd988c4ce0d17acdb3079", "width": 1080, "height": 540}], "variants": {}, "id": "qWUDNvhfNz630K6uipOcFbaT3eN7OJmri6AfClGiomM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11tnub1", "is_robot_indexable": true, "report_reasons": null, "author": "FruityWelsh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11tjca7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tnub1/dockerhub_replacement_stratagy_and_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ipfs/comments/11tjca7/dockerhub_replacement_stratagy_and_options/", "subreddit_subscribers": 673526, "created_utc": 1679050817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tdbsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_56nr0oo0", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "AskReddit", "selftext": "", "author_fullname": "t2_56nr0oo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which desktop application do people use to search for duplicate files in Google Drive ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/AskReddit", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11td7zc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679016585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh1i", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11td7zc", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 40235273, "created_utc": 1679016585.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1679016871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.AskReddit", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tdbsu", "is_robot_indexable": true, "report_reasons": null, "author": "ArdyLaing", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11td7zc", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tdbsu/which_desktop_application_do_people_use_to_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/AskReddit/comments/11td7zc/which_desktop_application_do_people_use_to_search/", "subreddit_subscribers": 673526, "created_utc": 1679016871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Due to a lack of data management skills and being afraid of deleting the wrong files I have too many duplicate files, especially images now. (I rather have duplicates than data loss!) Google Files is working very well for finding duplicate images and comparing them on Android. Does anyone know a good and cheap or free software, maybe even open-source, for Windows that can be used for finding and comparing duplicate images in chosen folders? I found some but they look like from Windows 2000 and I want to use something modern.", "author_fullname": "t2_2m2bms7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software for finding duplicate images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u1xyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679083105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Due to a lack of data management skills and being afraid of deleting the wrong files I have too many duplicate files, especially images now. (I rather have duplicates than data loss!) Google Files is working very well for finding duplicate images and comparing them on Android. Does anyone know a good and cheap or free software, maybe even open-source, for Windows that can be used for finding and comparing duplicate images in chosen folders? I found some but they look like from Windows 2000 and I want to use something modern.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u1xyd", "is_robot_indexable": true, "report_reasons": null, "author": "Rationale-Glum-Power", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u1xyd/software_for_finding_duplicate_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u1xyd/software_for_finding_duplicate_images/", "subreddit_subscribers": 673526, "created_utc": 1679083105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve spent several days researching the differences between cloud storage, syncing, and backup, as well as the different provider options (pCloud, OneDrive, Google One, Sync, etc.). I can\u2019t seem to choose the correct one because each one seems like it checks off 5/6 of my needs and not all of them. Any advice/recs from people with more knowledge is appreciated. I\u2019d like a cloud service to give me the following options:\n\n1) I only need cloud storage where I manually upload files into it - no need for auto-syncing or backing up from my phone. I use Google Photos for a constant backup of my camera roll. \n\n2) Need a service that will NOT delete old files or my account due to inactivity. I want a place to digitally store photos forever, in essence, from my childhood until I\u2019m 90 years old, without me having to log in every 30-60 days. \n\n3) Starting with 100GB and being able to upgrade later on is preferred, but I would more prefer a site that has the option of unlimited storage space, no matter how much I\u2019m paying. \n\n4) I don\u2019t really care about encryption; I will only be uploading photos and videos from my different cameras, not any proprietary information. Granted I don\u2019t want to get hacked either but don\u2019t need top secret security. \n\n5) The ability to just click on a photo or video and be able to look at it in full res, without waiting forever for it to download. I don\u2019t necessarily need to access files offline, but I know even with iCloud, some of my old stuff takes several minutes to load before it becomes not blurry. \n\nI\u2019d like to add that I can\u2019t use OneDrive because I only have a work computer (that I use as my personal) that already uses OneDrive and I don\u2019t want the confusion between 2 different accounts. PCloud was my second choice but reviews are mixed on it. Granted, every provider has people saying something like \u201cthey deleted 2TB of my files out of nowhere and I can\u2019t recover them\u201d and that skeeves me out, but I\u2019m wondering if those are mostly due to user error and not the platform itself\u2026\n\nThank in advance!!", "author_fullname": "t2_4x00evoi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot choose the best cloud storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u13yr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679081638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679081304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve spent several days researching the differences between cloud storage, syncing, and backup, as well as the different provider options (pCloud, OneDrive, Google One, Sync, etc.). I can\u2019t seem to choose the correct one because each one seems like it checks off 5/6 of my needs and not all of them. Any advice/recs from people with more knowledge is appreciated. I\u2019d like a cloud service to give me the following options:&lt;/p&gt;\n\n&lt;p&gt;1) I only need cloud storage where I manually upload files into it - no need for auto-syncing or backing up from my phone. I use Google Photos for a constant backup of my camera roll. &lt;/p&gt;\n\n&lt;p&gt;2) Need a service that will NOT delete old files or my account due to inactivity. I want a place to digitally store photos forever, in essence, from my childhood until I\u2019m 90 years old, without me having to log in every 30-60 days. &lt;/p&gt;\n\n&lt;p&gt;3) Starting with 100GB and being able to upgrade later on is preferred, but I would more prefer a site that has the option of unlimited storage space, no matter how much I\u2019m paying. &lt;/p&gt;\n\n&lt;p&gt;4) I don\u2019t really care about encryption; I will only be uploading photos and videos from my different cameras, not any proprietary information. Granted I don\u2019t want to get hacked either but don\u2019t need top secret security. &lt;/p&gt;\n\n&lt;p&gt;5) The ability to just click on a photo or video and be able to look at it in full res, without waiting forever for it to download. I don\u2019t necessarily need to access files offline, but I know even with iCloud, some of my old stuff takes several minutes to load before it becomes not blurry. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to add that I can\u2019t use OneDrive because I only have a work computer (that I use as my personal) that already uses OneDrive and I don\u2019t want the confusion between 2 different accounts. PCloud was my second choice but reviews are mixed on it. Granted, every provider has people saying something like \u201cthey deleted 2TB of my files out of nowhere and I can\u2019t recover them\u201d and that skeeves me out, but I\u2019m wondering if those are mostly due to user error and not the platform itself\u2026&lt;/p&gt;\n\n&lt;p&gt;Thank in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u13yr", "is_robot_indexable": true, "report_reasons": null, "author": "everydayanswers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u13yr/cannot_choose_the_best_cloud_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u13yr/cannot_choose_the_best_cloud_storage/", "subreddit_subscribers": 673526, "created_utc": 1679081304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nFinally decided to post the help here as I was literally pulling my hair on this dilemma...\n\n\\-------Lengthy post alert...----------\n\nBought an OWC Thunderbay Flex 8 last year and been using their SoftRaid, with a RAID5 8x8TB setup. Also built a new PC with Asus H670-Pro WiFi D4 and ThunderboltEX 4 adapter, to support this enclosure. I'm aware that 8 bays on a RAID5 is pretty alarming but the Windows version only supports RAID 1/0/5 even till now.\n\n&amp;#x200B;\n\nFast forward to last month, I finally pulled the trigger and bought an LSI Megaraid 9271-8i card, since this enclosure has spare PCIE slots that can be tunneled via Thunderbolt. Hoping to turn this enclosure into a hardware-raid system (which is under their advertisement).\n\nThat's when the nightmare begins. For the life of me, I just couldn't get the card to be detected at all in Windows (10/11). Even though I've managed to boot into the ROM BIOS and set up the raid and everything, the Windows Device Manager just doesn't see it at all. I even took the card out and installed it directly into my PC's motherboard, to replace the thunderbolt adapter, still no luck.\n\nFrom my research, this is a pretty old card that the latest driver and firmware stopped around 2016 or so. Alright, returned it.\n\n&amp;#x200B;\n\nThis month, I got a Megaraid 9362-8i (set up a RAID10), which supposedly has newer support. This time, it'd get detected in Windows, if it's directly installed on the motherboard, but not in the thunderbolt enclosure.\n\nAlright, gotta be something with the thunderbolt PCIE tunneling I suppose, progress!\n\nThen I started fiddling around with the motherboard's thunderbolt-related settings in the BIOS, e.g. Discrete Thunderbolt Support, DTBT Controller Configuration, Control IOMMU Pre-boot Behavior, etc. Toggling everything I could and check if it makes it better.\n\nOn one instance, I accidentally discovered, that after a period of time after booting to Windows, the enclosure would turn to Standby mode (as it's not being detected/used for a while I guess). But if I open the Device Manager and Scan for hardware changes, all of the sudden, it'd \"wake up\" the card/enclosure and it shows up in the Device Manager finally!\n\nHowever, it comes with big caveats, as it'd only work after each fresh reboot of Windows (and not 100% for some reason); the Raid volume shows as a \"removable storage\", and I'd have to change the Removal Policy in the Device Manager every time to make it \"Better performance\";\n\nLast and the biggest caveat is, probably due to it's detected after booting, neither MegaRAID Storage Manager, nor the LSA software would find the controller host. So there's no way to monitor the raid while using it.\n\nAt this point, I was almost certain that it has something to do with the Thunderbolt PCIE tunneling. But for the life of me, I couldn't find the right settings/tweak (if there's one). Funny thing is, I have a 10G PCIE ethernet card installed in the enclosure, and it works perfectly regardless when I connect the enclosure to the PC. Of course I've swapped the PCIE slots of the 10G card and the Megarad, just to rule out factors.\n\nI even tried a Virtual Machine just to see if virtual tunneling via IOMMU does anything, but I've already reached my knowledge/limit on this.\n\n&amp;#x200B;\n\nWondering if anyone can share some insight or should I just give up and go back to SoftRAID with RAID5?\n\n&amp;#x200B;\n\nSummary of specs:\n\nWindows 11 Pro\n\ni7-12900KF\n\nAsus H670-Pro WiFi D4\n\n128GB DDR4\n\nThunderboltEX 4 add-on\n\n&amp;#x200B;\n\nOWC Thunderbay Flex 8, 8x8TB HDD\n\nAvago/LSI Megaraid 9362-8i", "author_fullname": "t2_bp3asz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Megaraid in a Thunderbolt enclosure + Windows = no go?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u1iyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679082190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Finally decided to post the help here as I was literally pulling my hair on this dilemma...&lt;/p&gt;\n\n&lt;p&gt;-------Lengthy post alert...----------&lt;/p&gt;\n\n&lt;p&gt;Bought an OWC Thunderbay Flex 8 last year and been using their SoftRaid, with a RAID5 8x8TB setup. Also built a new PC with Asus H670-Pro WiFi D4 and ThunderboltEX 4 adapter, to support this enclosure. I&amp;#39;m aware that 8 bays on a RAID5 is pretty alarming but the Windows version only supports RAID 1/0/5 even till now.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Fast forward to last month, I finally pulled the trigger and bought an LSI Megaraid 9271-8i card, since this enclosure has spare PCIE slots that can be tunneled via Thunderbolt. Hoping to turn this enclosure into a hardware-raid system (which is under their advertisement).&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s when the nightmare begins. For the life of me, I just couldn&amp;#39;t get the card to be detected at all in Windows (10/11). Even though I&amp;#39;ve managed to boot into the ROM BIOS and set up the raid and everything, the Windows Device Manager just doesn&amp;#39;t see it at all. I even took the card out and installed it directly into my PC&amp;#39;s motherboard, to replace the thunderbolt adapter, still no luck.&lt;/p&gt;\n\n&lt;p&gt;From my research, this is a pretty old card that the latest driver and firmware stopped around 2016 or so. Alright, returned it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This month, I got a Megaraid 9362-8i (set up a RAID10), which supposedly has newer support. This time, it&amp;#39;d get detected in Windows, if it&amp;#39;s directly installed on the motherboard, but not in the thunderbolt enclosure.&lt;/p&gt;\n\n&lt;p&gt;Alright, gotta be something with the thunderbolt PCIE tunneling I suppose, progress!&lt;/p&gt;\n\n&lt;p&gt;Then I started fiddling around with the motherboard&amp;#39;s thunderbolt-related settings in the BIOS, e.g. Discrete Thunderbolt Support, DTBT Controller Configuration, Control IOMMU Pre-boot Behavior, etc. Toggling everything I could and check if it makes it better.&lt;/p&gt;\n\n&lt;p&gt;On one instance, I accidentally discovered, that after a period of time after booting to Windows, the enclosure would turn to Standby mode (as it&amp;#39;s not being detected/used for a while I guess). But if I open the Device Manager and Scan for hardware changes, all of the sudden, it&amp;#39;d &amp;quot;wake up&amp;quot; the card/enclosure and it shows up in the Device Manager finally!&lt;/p&gt;\n\n&lt;p&gt;However, it comes with big caveats, as it&amp;#39;d only work after each fresh reboot of Windows (and not 100% for some reason); the Raid volume shows as a &amp;quot;removable storage&amp;quot;, and I&amp;#39;d have to change the Removal Policy in the Device Manager every time to make it &amp;quot;Better performance&amp;quot;;&lt;/p&gt;\n\n&lt;p&gt;Last and the biggest caveat is, probably due to it&amp;#39;s detected after booting, neither MegaRAID Storage Manager, nor the LSA software would find the controller host. So there&amp;#39;s no way to monitor the raid while using it.&lt;/p&gt;\n\n&lt;p&gt;At this point, I was almost certain that it has something to do with the Thunderbolt PCIE tunneling. But for the life of me, I couldn&amp;#39;t find the right settings/tweak (if there&amp;#39;s one). Funny thing is, I have a 10G PCIE ethernet card installed in the enclosure, and it works perfectly regardless when I connect the enclosure to the PC. Of course I&amp;#39;ve swapped the PCIE slots of the 10G card and the Megarad, just to rule out factors.&lt;/p&gt;\n\n&lt;p&gt;I even tried a Virtual Machine just to see if virtual tunneling via IOMMU does anything, but I&amp;#39;ve already reached my knowledge/limit on this.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Wondering if anyone can share some insight or should I just give up and go back to SoftRAID with RAID5?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Summary of specs:&lt;/p&gt;\n\n&lt;p&gt;Windows 11 Pro&lt;/p&gt;\n\n&lt;p&gt;i7-12900KF&lt;/p&gt;\n\n&lt;p&gt;Asus H670-Pro WiFi D4&lt;/p&gt;\n\n&lt;p&gt;128GB DDR4&lt;/p&gt;\n\n&lt;p&gt;ThunderboltEX 4 add-on&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;OWC Thunderbay Flex 8, 8x8TB HDD&lt;/p&gt;\n\n&lt;p&gt;Avago/LSI Megaraid 9362-8i&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u1iyh", "is_robot_indexable": true, "report_reasons": null, "author": "hys17", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u1iyh/megaraid_in_a_thunderbolt_enclosure_windows_no_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u1iyh/megaraid_in_a_thunderbolt_enclosure_windows_no_go/", "subreddit_subscribers": 673526, "created_utc": 1679082190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everybody!\n\n(Hi, Dr. Nick!)\n\nI'm venturing into NAS territory. I feel comfortable tinkering around with tech, and it really scratches an itch. I'm an artist, which just adds to the media hoarding. Big PSD files with versions FTW.\n\nGoing to be using it for local \"backup\", but mostly as a jellyfin server. Unless I find something else that sounds fun.\n\nold case, mobo, cpu should be great for this.\n i5 3570 and a 1050ti if some help is needed with transcoding.\n\nMy issue is the widely varying costs of drives. I keep trying to find the sweet spot. I'm thinking raid5 4 6 or 8tb drives. I have a small ssd for an os drive already.\n\n$400 US budget. The cheap price of refurbished drives is a siren's call... but i dunno. Amazon also has low pricws on MaxDigitalData drives, but I haven't heard of them.\n\n\nAny suggestions?", "author_fullname": "t2_3myb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building my first NAS from an old PC. Drives (cost) is the biggest issue.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u1a6d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679081659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody!&lt;/p&gt;\n\n&lt;p&gt;(Hi, Dr. Nick!)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m venturing into NAS territory. I feel comfortable tinkering around with tech, and it really scratches an itch. I&amp;#39;m an artist, which just adds to the media hoarding. Big PSD files with versions FTW.&lt;/p&gt;\n\n&lt;p&gt;Going to be using it for local &amp;quot;backup&amp;quot;, but mostly as a jellyfin server. Unless I find something else that sounds fun.&lt;/p&gt;\n\n&lt;p&gt;old case, mobo, cpu should be great for this.\n i5 3570 and a 1050ti if some help is needed with transcoding.&lt;/p&gt;\n\n&lt;p&gt;My issue is the widely varying costs of drives. I keep trying to find the sweet spot. I&amp;#39;m thinking raid5 4 6 or 8tb drives. I have a small ssd for an os drive already.&lt;/p&gt;\n\n&lt;p&gt;$400 US budget. The cheap price of refurbished drives is a siren&amp;#39;s call... but i dunno. Amazon also has low pricws on MaxDigitalData drives, but I haven&amp;#39;t heard of them.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u1a6d", "is_robot_indexable": true, "report_reasons": null, "author": "Hurm", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u1a6d/building_my_first_nas_from_an_old_pc_drives_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u1a6d/building_my_first_nas_from_an_old_pc_drives_cost/", "subreddit_subscribers": 673526, "created_utc": 1679081659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently I have a 4TB Seagate Barracuda drive on my PC for general storage.\n\nI was thinking about replacing it with an IronWolf 8TB. Keep in mind this is not for NAS, but for inside my PC.\n\nIs this the way to go, or do you have other suggestions?", "author_fullname": "t2_37lnd1hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8TB Drive Suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u09bx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679079526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I have a 4TB Seagate Barracuda drive on my PC for general storage.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about replacing it with an IronWolf 8TB. Keep in mind this is not for NAS, but for inside my PC.&lt;/p&gt;\n\n&lt;p&gt;Is this the way to go, or do you have other suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u09bx", "is_robot_indexable": true, "report_reasons": null, "author": "JohnsonZ887", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u09bx/8tb_drive_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u09bx/8tb_drive_suggestions/", "subreddit_subscribers": 673526, "created_utc": 1679079526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Seagate 14tb ironwolf $210\n\n&amp;#x200B;\n\n[https://www.newegg.com/seagate-ironwolf-st14000vn0008-14tb/p/N82E16822184759](https://www.newegg.com/seagate-ironwolf-st14000vn0008-14tb/p/N82E16822184759)", "author_fullname": "t2_1sn1hpzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate 14tb ironwolf $210", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u001b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679078976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seagate 14tb ironwolf $210&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.newegg.com/seagate-ironwolf-st14000vn0008-14tb/p/N82E16822184759\"&gt;https://www.newegg.com/seagate-ironwolf-st14000vn0008-14tb/p/N82E16822184759&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ndJuVOxxQPwC1p1BfcxezFhN3CmAP3Fzi2F8tJ08NCY.jpg?auto=webp&amp;v=enabled&amp;s=d2a7a31183e2854c7eaef7276fbe31f45a4eda3b", "width": 640, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/ndJuVOxxQPwC1p1BfcxezFhN3CmAP3Fzi2F8tJ08NCY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c2cb3f089ce383d3f88759450c6da1761445dc3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ndJuVOxxQPwC1p1BfcxezFhN3CmAP3Fzi2F8tJ08NCY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48c2ff8d34683159801033e12a8d3b7cdd9b93ca", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ndJuVOxxQPwC1p1BfcxezFhN3CmAP3Fzi2F8tJ08NCY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b35410e10c29dfbdcfb035b041aab8f4ba4b6656", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/ndJuVOxxQPwC1p1BfcxezFhN3CmAP3Fzi2F8tJ08NCY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aec091614b7bd23b7d2fd01943156e18f4f42e27", "width": 640, "height": 480}], "variants": {}, "id": "4AeykAl9fEfRMeBMo_sqlqEjLIk8ma5hvYbsJ6J5hhg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u001b", "is_robot_indexable": true, "report_reasons": null, "author": "TheTrulyInsane1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u001b/seagate_14tb_ironwolf_210/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u001b/seagate_14tb_ironwolf_210/", "subreddit_subscribers": 673526, "created_utc": 1679078976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3xunvi1q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Update on 3rd party seller tosh MG series 16tb for 230 free ship -", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w49zsbm4sboa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=827991dc95a64e40cc944e5069b9e10b4e258185"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbb65961354c6ce119e3800f518d52b7389ed53e"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=950994625ddc33da0df80f3af6011cd9d3555a14"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dcf34c71b2c3f30346bd2b6b6d834d1c962628e7"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2979411fe7b8d2e94597348f959589819e28195b"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db680da022729ff58578fa954c890d93760bf923"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/w49zsbm4sboa1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bea428de0888c4e0a44f2376801b7e269841c96a"}, "id": "w49zsbm4sboa1"}, "rzgg9dm4sboa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa47e89c4fae7dce98868fb9c1a6935e4c75909c"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1802715b47ebd165b21e74131dee67c47eb6561b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32c5a028386d3ec710aaf1aef394c476da7c95a8"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e77dfc7769bdb0ba65a8aaaecb5a1e5ca2ee91d"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a98cb7d88a2f605032c2245c521adaa66f4f682"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c18e27739a83c7121d4b2154f06ed1202334c1cf"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/rzgg9dm4sboa1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f3ebb2ff3406e37d10b56a41a3e91336e9cea34a"}, "id": "rzgg9dm4sboa1"}}, "name": "t3_11tvu0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "w49zsbm4sboa1", "id": 252153086}, {"media_id": "rzgg9dm4sboa1", "id": 252153087}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/tIBynVEW-NNSMISUV6OxsWmh-gJzGBFJcL4Gg2qMaI8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679070175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/11tvu0v", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tvu0v", "is_robot_indexable": true, "report_reasons": null, "author": "PythonsByX", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tvu0v/update_on_3rd_party_seller_tosh_mg_series_16tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/11tvu0v", "subreddit_subscribers": 673526, "created_utc": 1679070175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there :)  \n\n\nI'm looking for a way to ensure that the data I have (mostly family photos / music) don't get corrupted over time or when I copy them to a new location.\n\nA few days ago I found on this sub a thread mentioning scorch (Silent CORruption CHecker) but it missed a way to stay alerted when a file get corrupted / missing :( so I developed a small program which executes scorch checks and send report as email :D\n\n[https://gitlab.com/daufinsyd/robespierre](https://gitlab.com/daufinsyd/robespierre)\n\nI hope this can be useful for others too !  \nIt's the first time I openly advertise something here, I'd be glad to have you feedback :)", "author_fullname": "t2_887kavsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Robespierre, a wrapper to check and alert on file corruption", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tmqmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679047290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there :)  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a way to ensure that the data I have (mostly family photos / music) don&amp;#39;t get corrupted over time or when I copy them to a new location.&lt;/p&gt;\n\n&lt;p&gt;A few days ago I found on this sub a thread mentioning scorch (Silent CORruption CHecker) but it missed a way to stay alerted when a file get corrupted / missing :( so I developed a small program which executes scorch checks and send report as email :D&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gitlab.com/daufinsyd/robespierre\"&gt;https://gitlab.com/daufinsyd/robespierre&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope this can be useful for others too !&lt;br/&gt;\nIt&amp;#39;s the first time I openly advertise something here, I&amp;#39;d be glad to have you feedback :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?auto=webp&amp;v=enabled&amp;s=925d591d1893dc66a053371b9623bd48b1c0cc2d", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d73d30c4a976a9fb5c388cde336d739a30d86d3c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e0569fedeb2075914f293bb3153c56c085fe0f8", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=307006897eba43a38e5b740f1c7facdc35b63ac7", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f78638881bdc8f54941a33b02149e437756e8a8a", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/ZquPAU8cZhn0mo04ZhRduLjfjWqLtXZZPPqxxp1O98E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e07b101e57d2f2ce4655b1e8bb55dfa40e8c5e20", "width": 960, "height": 960}], "variants": {}, "id": "Vw3bBu31aiMSJTxYckiYR6DzhREt281xzPoVcP66tdI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tmqmx", "is_robot_indexable": true, "report_reasons": null, "author": "rhurth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tmqmx/robespierre_a_wrapper_to_check_and_alert_on_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tmqmx/robespierre_a_wrapper_to_check_and_alert_on_file/", "subreddit_subscribers": 673526, "created_utc": 1679047290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I recently watch several youtube videos of people building a NAS, and I come across people using this shucking method, of WD Elements. It would save me $200 if I use this method to get (WDBWLG0080HBK-NESN 8TB) [Amazon link](https://www.amazon.com/Elements-Desktop-Hard-Drive-WDBWLG0080HBK-NESN/dp/B07D5V2ZXD/ref=mp_s_a_1_2?crid=1VTOLSLCZ28LL&amp;keywords=wd+element+8+tb&amp;qid=1679035936&amp;sprefix=wd+element+8+%2Caps%2C534&amp;sr=8-2)instead of ST8000VN004 Seagate Ironwolf 8 TB. Is this a good method?", "author_fullname": "t2_8siy7ss6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Shucking a good method if I want to get cheaper NAS drives? (WDBWLG0080HBK-NESN 8TB)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tj0r3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679036644.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679033934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I recently watch several youtube videos of people building a NAS, and I come across people using this shucking method, of WD Elements. It would save me $200 if I use this method to get (WDBWLG0080HBK-NESN 8TB) &lt;a href=\"https://www.amazon.com/Elements-Desktop-Hard-Drive-WDBWLG0080HBK-NESN/dp/B07D5V2ZXD/ref=mp_s_a_1_2?crid=1VTOLSLCZ28LL&amp;amp;keywords=wd+element+8+tb&amp;amp;qid=1679035936&amp;amp;sprefix=wd+element+8+%2Caps%2C534&amp;amp;sr=8-2\"&gt;Amazon link&lt;/a&gt;instead of ST8000VN004 Seagate Ironwolf 8 TB. Is this a good method?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tj0r3", "is_robot_indexable": true, "report_reasons": null, "author": "SciencioGT", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tj0r3/is_shucking_a_good_method_if_i_want_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tj0r3/is_shucking_a_good_method_if_i_want_to_get/", "subreddit_subscribers": 673526, "created_utc": 1679033934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have my main Windows PC with some valuable personal things, old photos etc, sub 50gb of valuable data, entire drive is 500GB if I wanted to backup the entire drive at once. \n\nI also have a headless Linux based NAS with 4TB of less valuable content on it, mostly movies.\n\nI want to setup full 3-2-1 backups on my main Windows PC, cloud + external HDD + main drive, and for my NAS I want it to be backed up only once on an external drive.\n\nI could imagine it is highly time consuming and frustrating to set this up, having to install probably different software on my main PC and the headless NAS via command line, then execute if via command line too, etc., but I have never actually tried it before and couldn't find any reading material for this.\n\nHow difficult would this be to setup?", "author_fullname": "t2_cc458uu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Tricky is it to Setup External HDD backups of Two Different Machines on One Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11teuab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679020997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have my main Windows PC with some valuable personal things, old photos etc, sub 50gb of valuable data, entire drive is 500GB if I wanted to backup the entire drive at once. &lt;/p&gt;\n\n&lt;p&gt;I also have a headless Linux based NAS with 4TB of less valuable content on it, mostly movies.&lt;/p&gt;\n\n&lt;p&gt;I want to setup full 3-2-1 backups on my main Windows PC, cloud + external HDD + main drive, and for my NAS I want it to be backed up only once on an external drive.&lt;/p&gt;\n\n&lt;p&gt;I could imagine it is highly time consuming and frustrating to set this up, having to install probably different software on my main PC and the headless NAS via command line, then execute if via command line too, etc., but I have never actually tried it before and couldn&amp;#39;t find any reading material for this.&lt;/p&gt;\n\n&lt;p&gt;How difficult would this be to setup?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11teuab", "is_robot_indexable": true, "report_reasons": null, "author": "SleepingAndy", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11teuab/how_tricky_is_it_to_setup_external_hdd_backups_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11teuab/how_tricky_is_it_to_setup_external_hdd_backups_of/", "subreddit_subscribers": 673526, "created_utc": 1679020997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Essentially what I want to do is some data analysis to find commonalities, connections or themes between different sources of information. But my disability is such that it's getting increasingly difficult for me to do this manually. Is there software that can help me do this and will output a dynamic/interactive network graph?\n\nI would ideally like to be able to input a bunch of text (from numerous sources), have the software find keywords or themes (it's OK if I have to use separate software to mine text for keywords) and then draw connections between the different sources and output that to a network graph.\n\nThe sources are sometimes hundreds of pages long or could be as short as a single sentence. The short ones are fine to manually find connections and commonalities with but when I'm looking at hundreds of pages of text from some sources, it would take a really, really long time to sift through and with my disability, I would likely miss important data points.\n\nThe idea is that I can search for a keyword or theme and find where it's connected in all the sources of information and/or find overall patterns. Or to look at a source and find commonalities in other sources.\n\nHopefully you understand what I mean, I'm tired and sore today. Thank you!", "author_fullname": "t2_5c9sus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to make sense of huge amounts of data from different sources in a visual way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tdxsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679018927.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679018514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially what I want to do is some data analysis to find commonalities, connections or themes between different sources of information. But my disability is such that it&amp;#39;s getting increasingly difficult for me to do this manually. Is there software that can help me do this and will output a dynamic/interactive network graph?&lt;/p&gt;\n\n&lt;p&gt;I would ideally like to be able to input a bunch of text (from numerous sources), have the software find keywords or themes (it&amp;#39;s OK if I have to use separate software to mine text for keywords) and then draw connections between the different sources and output that to a network graph.&lt;/p&gt;\n\n&lt;p&gt;The sources are sometimes hundreds of pages long or could be as short as a single sentence. The short ones are fine to manually find connections and commonalities with but when I&amp;#39;m looking at hundreds of pages of text from some sources, it would take a really, really long time to sift through and with my disability, I would likely miss important data points.&lt;/p&gt;\n\n&lt;p&gt;The idea is that I can search for a keyword or theme and find where it&amp;#39;s connected in all the sources of information and/or find overall patterns. Or to look at a source and find commonalities in other sources.&lt;/p&gt;\n\n&lt;p&gt;Hopefully you understand what I mean, I&amp;#39;m tired and sore today. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tdxsk", "is_robot_indexable": true, "report_reasons": null, "author": "Thorned_Rose", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tdxsk/software_to_make_sense_of_huge_amounts_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tdxsk/software_to_make_sense_of_huge_amounts_of_data/", "subreddit_subscribers": 673526, "created_utc": 1679018514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI've had a go at searching for this without any clear results. I'm looking for a tool to bulk download Instagram profiles (Twitter and tiktok would also be handy, but Instagram is the focus for now) for academic research purposes. Is there anything out there that would let me do that? Ideally for free...\n\nThanks in advance \ud83d\ude0a", "author_fullname": "t2_rwhiewfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk archiving tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11u0te2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679080683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a go at searching for this without any clear results. I&amp;#39;m looking for a tool to bulk download Instagram profiles (Twitter and tiktok would also be handy, but Instagram is the focus for now) for academic research purposes. Is there anything out there that would let me do that? Ideally for free...&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11u0te2", "is_robot_indexable": true, "report_reasons": null, "author": "franklyeddie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11u0te2/bulk_archiving_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11u0te2/bulk_archiving_tools/", "subreddit_subscribers": 673526, "created_utc": 1679080683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Pretty much like the subject says. We need to find an old file that was backed up on a Windows 2000 machine to LTO2 tape. Dusted off the Win2k machine and it fired right up. After locating all the right SCSI cables and terminator, we are able to access the tapes. But we have one for which there is no catalog in the Backup application, and I can't for the life of me figure out how to generate one so we can see what's on it. It was definitely made on this very machine, using Windows Backup, not with another application.\n\nAny ideas? It seems to only want to let me see what's on the tape if I have an entry for it in the Restore Tab. -- there has to be a way to get it to catalog a tape it's not familiar with or doesn't have a catalog file for, right?", "author_fullname": "t2_bbs73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to restore an LTO2 tape made with Windows Backup on Win 2000 -- with no catalog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ty7gh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679076339.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679075138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much like the subject says. We need to find an old file that was backed up on a Windows 2000 machine to LTO2 tape. Dusted off the Win2k machine and it fired right up. After locating all the right SCSI cables and terminator, we are able to access the tapes. But we have one for which there is no catalog in the Backup application, and I can&amp;#39;t for the life of me figure out how to generate one so we can see what&amp;#39;s on it. It was definitely made on this very machine, using Windows Backup, not with another application.&lt;/p&gt;\n\n&lt;p&gt;Any ideas? It seems to only want to let me see what&amp;#39;s on the tape if I have an entry for it in the Restore Tab. -- there has to be a way to get it to catalog a tape it&amp;#39;s not familiar with or doesn&amp;#39;t have a catalog file for, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ty7gh", "is_robot_indexable": true, "report_reasons": null, "author": "friolator", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ty7gh/how_to_restore_an_lto2_tape_made_with_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ty7gh/how_to_restore_an_lto2_tape_made_with_windows/", "subreddit_subscribers": 673526, "created_utc": 1679075138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently I have an 8tb usb external drive hooked up to my router, and while it works, its really only good for backups, as the USB speeds is its limiting factor. Its unbearably slow, and if I want to edit any photos, I have to transfer them to my computer first, edit, then transfer them back.\n\nWhat I'm wanting to do:\n\n- Media storage ( movies, photos, etc ) with a connection that is at least fast enough to edit photos off of. \n\n- Accessible from my local network, and it would be amazing if I were able to access it from anywhere.\n\n- I don't mind paying for software, but I absolutely don't want any subscription cost. \n\n- Must be windows/osx compatible. \n\n- At least 2 drive spaces, 4 is ideal but may be beyond budget. Say a budget of $400 max. ( excluding drives ) \n\n\n-----\n\nShould I just buy a simple pre-built nas system? ( and if so, what should I get? )\n\nor should I look into buying a used PC and turning it into a nas? ( i'd love to build an itx system, but that would be way beyond my budget ) \n\nThanks", "author_fullname": "t2_s661yw6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to buy/build a NAS system. suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tt931", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679064745.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679064563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I have an 8tb usb external drive hooked up to my router, and while it works, its really only good for backups, as the USB speeds is its limiting factor. Its unbearably slow, and if I want to edit any photos, I have to transfer them to my computer first, edit, then transfer them back.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m wanting to do:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Media storage ( movies, photos, etc ) with a connection that is at least fast enough to edit photos off of. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Accessible from my local network, and it would be amazing if I were able to access it from anywhere.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I don&amp;#39;t mind paying for software, but I absolutely don&amp;#39;t want any subscription cost. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Must be windows/osx compatible. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;At least 2 drive spaces, 4 is ideal but may be beyond budget. Say a budget of $400 max. ( excluding drives ) &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Should I just buy a simple pre-built nas system? ( and if so, what should I get? )&lt;/p&gt;\n\n&lt;p&gt;or should I look into buying a used PC and turning it into a nas? ( i&amp;#39;d love to build an itx system, but that would be way beyond my budget ) &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tt931", "is_robot_indexable": true, "report_reasons": null, "author": "boobumblebee", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tt931/i_want_to_buybuild_a_nas_system_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tt931/i_want_to_buybuild_a_nas_system_suggestions/", "subreddit_subscribers": 673526, "created_utc": 1679064563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(If this is the wrong sub please delete or direct me to the correct one)\n\nI have four 12 TB HD's of storage that are almost full. I use these mostly for my Plex Media Server. My problem is that I have no more extra USB ports on my PC to add any more external drives. What are my options for add another drive or two to my setup? I've looked into a 4 port NAS but I'm not sure that will solve my dilemma. My PC handles all the transcoding just fine. Thanks in advance.", "author_fullname": "t2_6i2ukuedc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running out of room need help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tt8qp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679064546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(If this is the wrong sub please delete or direct me to the correct one)&lt;/p&gt;\n\n&lt;p&gt;I have four 12 TB HD&amp;#39;s of storage that are almost full. I use these mostly for my Plex Media Server. My problem is that I have no more extra USB ports on my PC to add any more external drives. What are my options for add another drive or two to my setup? I&amp;#39;ve looked into a 4 port NAS but I&amp;#39;m not sure that will solve my dilemma. My PC handles all the transcoding just fine. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tt8qp", "is_robot_indexable": true, "report_reasons": null, "author": "MrPicklesGhost", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tt8qp/running_out_of_room_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tt8qp/running_out_of_room_need_help/", "subreddit_subscribers": 673526, "created_utc": 1679064546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been beating my brains out trying to figure this out. Most of the documentation is more technical than what I understand. However , as far as I can tell , the following powershell commands SHOULD work to create a tiered Storage Space. However, it fails on line 16 ( New-StorageTier command ).\n\n  Set-PhysicalDisk -FriendlyName \"HPT Disk 0\\_0\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_1\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_2\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_3\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_4\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_5\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_6\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_7\" -MediaType SSD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_8\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_9\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_10\" -MediaType HDD\n\nSet-PhysicalDisk -FriendlyName \"HPT Disk 0\\_11\" -MediaType HDD\n\nGet-PhysicalDisk -CanPool $True | Format-Table -Property FriendlyName, OperationalStatus, Size, MediaType\n\n$storage = Get-StorageSubSystem\n\nNew-StoragePool -StorageSubSystemId $storage.UniqueId -FriendlyName Pool -PhysicalDisks (Get-PhysicalDisk -CanPool $true)\n\nGet-StoragePool Pool | New-StorageTier \u2013FriendlyName SSD \u2013MediaType SSD\n\nGet-StoragePool Pool | New-StorageTier \u2013FriendlyName HDD \u2013MediaType HDD\n\nGet-StoragePool Pool | Set-ResiliencySetting -Name Simple -NumberOfColumnsDefault 3\n\n$SSD = Get-StorageTier -FriendlyName SSD $HDD = Get-StorageTier -FriendlyName HDD\n\nGet-StoragePool Pool | New-VirtualDisk -FriendlyName Space -ResiliencySettingName Simple \u2013StorageTiers $SSD, $HDD -StorageTierSizes 900GB, 3.55TB -WriteCacheSize 25GB\n\n&amp;#x200B;\n\nThe error it gives is New-StorageTier: A positional parameter cannot be found that accepts argument 'SSD'.\n\nLine 18 also throws an error saying Friendlyname is specified more than once and to use Array syntax to provide multiple values.\n\nThe goal is to have the HDD's in a simple Storage Space ( fast reads , this PC is used mostly for gaming , although I do some geneology stuff too , lots of family pictures. ), backed by a fast SSD tier .\n\nI do daily backups , so redundancy isn't an issue ( although I wouldn't be adverse to using this as a parity space if I would lose less capacity than a 2 way mirror space).\n\n&amp;#x200B;\n\nAny idea why it fails ? Is there a better script to use to accomplish this ?\n\n  I'm using Windows 11 Pro for Workstations", "author_fullname": "t2_h2mbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help figuring out why creating a storage space fails,", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11trrnc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": "", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679061262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been beating my brains out trying to figure this out. Most of the documentation is more technical than what I understand. However , as far as I can tell , the following powershell commands SHOULD work to create a tiered Storage Space. However, it fails on line 16 ( New-StorageTier command ).&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_0&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_1&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_2&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_3&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_4&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_5&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_6&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_7&amp;quot; -MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_8&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_9&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_10&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Set-PhysicalDisk -FriendlyName &amp;quot;HPT Disk 0_11&amp;quot; -MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Get-PhysicalDisk -CanPool $True | Format-Table -Property FriendlyName, OperationalStatus, Size, MediaType&lt;/p&gt;\n\n&lt;p&gt;$storage = Get-StorageSubSystem&lt;/p&gt;\n\n&lt;p&gt;New-StoragePool -StorageSubSystemId $storage.UniqueId -FriendlyName Pool -PhysicalDisks (Get-PhysicalDisk -CanPool $true)&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-StorageTier \u2013FriendlyName SSD \u2013MediaType SSD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-StorageTier \u2013FriendlyName HDD \u2013MediaType HDD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | Set-ResiliencySetting -Name Simple -NumberOfColumnsDefault 3&lt;/p&gt;\n\n&lt;p&gt;$SSD = Get-StorageTier -FriendlyName SSD $HDD = Get-StorageTier -FriendlyName HDD&lt;/p&gt;\n\n&lt;p&gt;Get-StoragePool Pool | New-VirtualDisk -FriendlyName Space -ResiliencySettingName Simple \u2013StorageTiers $SSD, $HDD -StorageTierSizes 900GB, 3.55TB -WriteCacheSize 25GB&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The error it gives is New-StorageTier: A positional parameter cannot be found that accepts argument &amp;#39;SSD&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;Line 18 also throws an error saying Friendlyname is specified more than once and to use Array syntax to provide multiple values.&lt;/p&gt;\n\n&lt;p&gt;The goal is to have the HDD&amp;#39;s in a simple Storage Space ( fast reads , this PC is used mostly for gaming , although I do some geneology stuff too , lots of family pictures. ), backed by a fast SSD tier .&lt;/p&gt;\n\n&lt;p&gt;I do daily backups , so redundancy isn&amp;#39;t an issue ( although I wouldn&amp;#39;t be adverse to using this as a parity space if I would lose less capacity than a 2 way mirror space).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any idea why it fails ? Is there a better script to use to accomplish this ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Windows 11 Pro for Workstations&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11trrnc", "is_robot_indexable": true, "report_reasons": null, "author": "goobermatic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11trrnc/help_figuring_out_why_creating_a_storage_space/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11trrnc/help_figuring_out_why_creating_a_storage_space/", "subreddit_subscribers": 673526, "created_utc": 1679061262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looked on reddit and not much info.\n\nJust got a Hitachi Ultrastar 3TB HDD. Price Amazon $29. Did not really research the purchase adequately.\n\nGot the drive. Smart OK. 35 start stop cycles. 87,000 hrs pwr on (10 years). Sealed package and looks new but probably not touched since installed in large raid.\n\nNo real info on WD/Hitachi since drive is so old. Probably manufactured 2012 and put in a large raid system and then pulled at 10 years.\n\nThese drives rated at 10 million hours MTBF. Does that mean anything.\n\nI know any drive can fail at any time but does the age/hours mean that much in a enterprise level HDD. I imagine so since there is a reason the company pulled it on a timetable.\n\nWhat are your thoughts as one of a pair of backup drives.", "author_fullname": "t2_bc94dl74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Member thoughts on Ultrastar HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tbe0t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679012581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looked on reddit and not much info.&lt;/p&gt;\n\n&lt;p&gt;Just got a Hitachi Ultrastar 3TB HDD. Price Amazon $29. Did not really research the purchase adequately.&lt;/p&gt;\n\n&lt;p&gt;Got the drive. Smart OK. 35 start stop cycles. 87,000 hrs pwr on (10 years). Sealed package and looks new but probably not touched since installed in large raid.&lt;/p&gt;\n\n&lt;p&gt;No real info on WD/Hitachi since drive is so old. Probably manufactured 2012 and put in a large raid system and then pulled at 10 years.&lt;/p&gt;\n\n&lt;p&gt;These drives rated at 10 million hours MTBF. Does that mean anything.&lt;/p&gt;\n\n&lt;p&gt;I know any drive can fail at any time but does the age/hours mean that much in a enterprise level HDD. I imagine so since there is a reason the company pulled it on a timetable.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts as one of a pair of backup drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tbe0t", "is_robot_indexable": true, "report_reasons": null, "author": "redd-or45", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tbe0t/member_thoughts_on_ultrastar_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tbe0t/member_thoughts_on_ultrastar_hdd/", "subreddit_subscribers": 673526, "created_utc": 1679012581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to DL entire sites and only download the newer content later on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11tahpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679010437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;E.g. Httrack but I dont want to redownload the entire site and just the latest additions every time I download later on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11tahpv", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11tahpv/how_to_dl_entire_sites_and_only_download_the/", "subreddit_subscribers": 673526, "created_utc": 1679010437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. \n\nI\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. \n\nI\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. \n\nI am so excited to get this little project finished, so any and all help is super appreciated.", "author_fullname": "t2_bkmhazam", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help picking NVME drives for my NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11t8akp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679005468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am hoping you can help me out. I just got a new Terramaster F4-423 NAS to use as a mini Plex server and keep the load off some other hardware, and I need to pick out two NVME drives for disk caching. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m using 4x18tb Iron Wolf Pros in it and it supports two Gen3 NVME drives. I\u2019m not sure what type of drive would be the best for this. I\u2019m trying to avoid spending more than I need to, but I also don\u2019t want to have buyers remorse later. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m in the USA so NewEgg / Amazon / Microcenter will be my hunting grounds. &lt;/p&gt;\n\n&lt;p&gt;I am so excited to get this little project finished, so any and all help is super appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11t8akp", "is_robot_indexable": true, "report_reasons": null, "author": "MaxBando420", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11t8akp/need_help_picking_nvme_drives_for_my_nas/", "subreddit_subscribers": 673526, "created_utc": 1679005468.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}