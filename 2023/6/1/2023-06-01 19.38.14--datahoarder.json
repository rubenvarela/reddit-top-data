{"kind": "Listing", "data": {"after": "t3_13x94an", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I see the writing on the wall for reddit, at least for me personally. Is there a data hoarder forum elsewhere?", "author_fullname": "t2_1ev1ev2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there another community similar to this subreddit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xjmxn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685631199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see the writing on the wall for reddit, at least for me personally. Is there a data hoarder forum elsewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13xjmxn", "is_robot_indexable": true, "report_reasons": null, "author": "Readingyourprofile", "discussion_type": null, "num_comments": 108, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xjmxn/is_there_another_community_similar_to_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xjmxn/is_there_another_community_similar_to_this/", "subreddit_subscribers": 685568, "created_utc": 1685631199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Seeing that the move to make the Reddit API cost cash, I'm afraid that something like [ this](https://github.com/josephrcox/easy-reddit-downloader/) won't function when I'm done seeing what I want to archive from this place. So, I'm asking to see what options from Website Mirroring tools I got, and how to set them up to fetch media files as well, other than just the website's layout and such.\n\nI know that HTTrack exists, but any configuration I've tried doesn't work (No media saved and mirrored page doesn't load properly [blank page after a second]). I've also tried wget, with similar results. \n\nIf you got any app recommendations or any idea to make those two work in the way I need (Media files downloaded [videos with audio, images etc], page layout saved) I would be very thankful. Assuming those will not be limited by some way from Reddit.\n\nI guess I can try the WayBack Machine, but I know that sometimes video files do not get saved. And that they are dealing with some issues from too many requests.", "author_fullname": "t2_4jvz448c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving Reddit without using an app that relies on their API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xcwyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685611619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeing that the move to make the Reddit API cost cash, I&amp;#39;m afraid that something like &lt;a href=\"https://github.com/josephrcox/easy-reddit-downloader/\"&gt; this&lt;/a&gt; won&amp;#39;t function when I&amp;#39;m done seeing what I want to archive from this place. So, I&amp;#39;m asking to see what options from Website Mirroring tools I got, and how to set them up to fetch media files as well, other than just the website&amp;#39;s layout and such.&lt;/p&gt;\n\n&lt;p&gt;I know that HTTrack exists, but any configuration I&amp;#39;ve tried doesn&amp;#39;t work (No media saved and mirrored page doesn&amp;#39;t load properly [blank page after a second]). I&amp;#39;ve also tried wget, with similar results. &lt;/p&gt;\n\n&lt;p&gt;If you got any app recommendations or any idea to make those two work in the way I need (Media files downloaded [videos with audio, images etc], page layout saved) I would be very thankful. Assuming those will not be limited by some way from Reddit.&lt;/p&gt;\n\n&lt;p&gt;I guess I can try the WayBack Machine, but I know that sometimes video files do not get saved. And that they are dealing with some issues from too many requests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?auto=webp&amp;v=enabled&amp;s=a6f8c537fc477a58e97d9b5702b3ffefd22cb479", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1978657c075ffc19276bd2b5facefbb7594a8e92", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f562f0fb44574853d9640f5d25085db68cf1210", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef9201b7b60ca058c7aa9d89863c3d68f6920431", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7565d8e1adeccf025d7f89cc75eee16c307eb15c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7392af432fa22f7098fccd402ef033d594895b0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/20_yBn9EI9pHlks9qAMG62yca16m852MxTDae2g38sI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4101d603c888bccab346c7b45877964f63f1edbe", "width": 1080, "height": 540}], "variants": {}, "id": "S9npPUS6gLDx6jaYCVwfSj_EASTj5BMx7eenXvVVigY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xcwyu", "is_robot_indexable": true, "report_reasons": null, "author": "NoExplorer_Gr", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xcwyu/archiving_reddit_without_using_an_app_that_relies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xcwyu/archiving_reddit_without_using_an_app_that_relies/", "subreddit_subscribers": 685568, "created_utc": 1685611619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, i wanted to download video from my subscribed member before the plan expires, so i searched everywhere and found nothing, no IDM worked, no Inspect element worked, not even searching in the code for .mp4, VOD, or Vimeo worked. \n\nyou see i am not expert on the coding n data but i see there while playing the videos i see data transfer in chunks coming to my ip and then there was no way to find it. you can't even download these videos with Patreon downloader or any other proxy settings. damn that was a hard thing. \n\n**so i came across a really old post on** [**here**](https://www.reddit.com/r/DataHoarder/comments/gtq8ud/comment/hlsssy6/?utm_source=share&amp;utm_medium=web2x&amp;context=3) **and just gave it a final shot. remember our good old** [**Jdownloader**](https://beta.jdownloader.org/) **?** \n\nso there is one important thing about this process which isnt mentioned in the earlier post. you need to install a plugin which the Jdownloader prompts i.e.  [FFmpeg](https://support.jdownloader.org/Knowledgebase/Article/View/ffmpeg-installation-and-troubleshooting/5) ,  the setup will prompt to update/install this. so install and restart the jdownloader. \n\nand when it is done you will find the add link option and add selected video or patreon page there. \n\non clicking on continue it will analyse the webpage and in the Link Grabber tab, select the videos sort option and wait for it to grab the videos of your favorite creator or video links. and then download it..\n\nHappy Downloading.", "author_fullname": "t2_l9ta9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution : A way to download private Vimeo videos from any webpage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xc75c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685608945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i wanted to download video from my subscribed member before the plan expires, so i searched everywhere and found nothing, no IDM worked, no Inspect element worked, not even searching in the code for .mp4, VOD, or Vimeo worked. &lt;/p&gt;\n\n&lt;p&gt;you see i am not expert on the coding n data but i see there while playing the videos i see data transfer in chunks coming to my ip and then there was no way to find it. you can&amp;#39;t even download these videos with Patreon downloader or any other proxy settings. damn that was a hard thing. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;so i came across a really old post on&lt;/strong&gt; &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/gtq8ud/comment/hlsssy6/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;and just gave it a final shot. remember our good old&lt;/strong&gt; &lt;a href=\"https://beta.jdownloader.org/\"&gt;&lt;strong&gt;Jdownloader&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;so there is one important thing about this process which isnt mentioned in the earlier post. you need to install a plugin which the Jdownloader prompts i.e.  &lt;a href=\"https://support.jdownloader.org/Knowledgebase/Article/View/ffmpeg-installation-and-troubleshooting/5\"&gt;FFmpeg&lt;/a&gt; ,  the setup will prompt to update/install this. so install and restart the jdownloader. &lt;/p&gt;\n\n&lt;p&gt;and when it is done you will find the add link option and add selected video or patreon page there. &lt;/p&gt;\n\n&lt;p&gt;on clicking on continue it will analyse the webpage and in the Link Grabber tab, select the videos sort option and wait for it to grab the videos of your favorite creator or video links. and then download it..&lt;/p&gt;\n\n&lt;p&gt;Happy Downloading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Moon \ud83c\udf15", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xc75c", "is_robot_indexable": true, "report_reasons": null, "author": "monsieurg3", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13xc75c/solution_a_way_to_download_private_vimeo_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xc75c/solution_a_way_to_download_private_vimeo_videos/", "subreddit_subscribers": 685568, "created_utc": 1685608945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not a hardcore data hoarder (though I respect you all!) and have not done something like this before. I mostly just hoard old documents and video files etc. But the recent changes to Reddit's API and how it will affect third-party apps has me considering leaving Reddit. However, the wikis and FAQs that certain communities have put together here are just irreplaceable. Seriously, some of these are the best collection of information on specific topics you can find anywhere. Is there an easy way to save them in a usable format?", "author_fullname": "t2_4qjaedk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anybody know a good way to quickly save the Wikis and FAQs from specific subreddits?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x228a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685576522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a hardcore data hoarder (though I respect you all!) and have not done something like this before. I mostly just hoard old documents and video files etc. But the recent changes to Reddit&amp;#39;s API and how it will affect third-party apps has me considering leaving Reddit. However, the wikis and FAQs that certain communities have put together here are just irreplaceable. Seriously, some of these are the best collection of information on specific topics you can find anywhere. Is there an easy way to save them in a usable format?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13x228a", "is_robot_indexable": true, "report_reasons": null, "author": "great_kio", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13x228a/does_anybody_know_a_good_way_to_quickly_save_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13x228a/does_anybody_know_a_good_way_to_quickly_save_the/", "subreddit_subscribers": 685568, "created_utc": 1685576522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16feol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I noticed a gradual decrease in speeds from 268MBPS to around 150MBPS in both read and write tests towards the end of their tests. Is that normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_13xan2a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nfr_yxe2PP4bOi5Mi1D6f2CxYG-oi5GJcvp63F5CRQA.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685602905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4bmah2aeuc3b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?auto=webp&amp;v=enabled&amp;s=260a136c1c563ecae3bc2e69e9636a1bf237c4e5", "width": 1905, "height": 851}, "resolutions": [{"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fbb906a6779e59e3259e873b75e4d1efbc3e729", "width": 108, "height": 48}, {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=191f6955686e8fad8a175c03c8bc7cd6347d7a82", "width": 216, "height": 96}, {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afcba322c063f8beb138a421a9ea643115a6c293", "width": 320, "height": 142}, {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1cd84eec91519dcb770e836cd001ff561b5b6b48", "width": 640, "height": 285}, {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed2b8d33de28099cf5253373f29f7c790bcf6d61", "width": 960, "height": 428}, {"url": "https://preview.redd.it/4bmah2aeuc3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6790744aa9b501e95447d8caa97a93bb2b932fdb", "width": 1080, "height": 482}], "variants": {}, "id": "SjuqVC42LQnIFxy4s--bwhBosYj3EZCYMaG8mefaKBU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16+14+10 HDD | 2TB SSD", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xan2a", "is_robot_indexable": true, "report_reasons": null, "author": "giratina143", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13xan2a/i_noticed_a_gradual_decrease_in_speeds_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4bmah2aeuc3b1.png", "subreddit_subscribers": 685568, "created_utc": 1685602905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_np8mb41h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reddit-user-to-sqlite Pull Reddit user data into a searchable SQLite database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13wyxhf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/HUZQkY26SEIYBUd1m2I_GJN4LhUQw6QhhoNlXPUkcT0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685569110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/xavdid/reddit-user-to-sqlite/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?auto=webp&amp;v=enabled&amp;s=c0b9e7eb77f28c703a31ca464415a2dd27dc104c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=638f1a36e35ddbd0056eae59c84a31039af86765", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce35ed2f0ca0dd5c9af27151a9cc4eaa878518fd", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39f71614b83f7315d8c7aa47a612c50a92cb28f8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=435bd64f0abb9c17d2ebdbb9e92d31bfe7973dbf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=592d66c1a959745d6cf791ffa563e969f09398f0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Qtp-BFjgqm13q5LglbPW7q58yWZtc0Wz2TSATB2c1w0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22c07f75b930fdfe0e37db33c6ac71e58c6d8f6c", "width": 1080, "height": 540}], "variants": {}, "id": "1ZAS0CSAXCQl0h0wVTynGz3WJpboBL3RVVYAA3OKs7w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13wyxhf", "is_robot_indexable": true, "report_reasons": null, "author": "xavdid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13wyxhf/redditusertosqlite_pull_reddit_user_data_into_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/xavdid/reddit-user-to-sqlite/", "subreddit_subscribers": 685568, "created_utc": 1685569110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All\n\nSo I've had a single-seat subscription for the past few years. I've been paying around \u00a310 per month, which I use for back-ups, and I use around 1.5TB worth of storage there.\n\nsuddenly this month I've been billed \u00a323... What are the hell are they smoking over there!\n\nHas anybody else experienced this?\n\nIt looks like my current subscription is \"**Google Workspace Enterprise Plus**\", not sure if I selected that, or they took the liberty of assuming I'd want to pay them more!\n\nThanks", "author_fullname": "t2_6qoaxe19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WTH - Google Workspace price doubled since last month...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xmci0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685637364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve had a single-seat subscription for the past few years. I&amp;#39;ve been paying around \u00a310 per month, which I use for back-ups, and I use around 1.5TB worth of storage there.&lt;/p&gt;\n\n&lt;p&gt;suddenly this month I&amp;#39;ve been billed \u00a323... What are the hell are they smoking over there!&lt;/p&gt;\n\n&lt;p&gt;Has anybody else experienced this?&lt;/p&gt;\n\n&lt;p&gt;It looks like my current subscription is &amp;quot;&lt;strong&gt;Google Workspace Enterprise Plus&lt;/strong&gt;&amp;quot;, not sure if I selected that, or they took the liberty of assuming I&amp;#39;d want to pay them more!&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xmci0", "is_robot_indexable": true, "report_reasons": null, "author": "Fluffer_Wuffer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xmci0/wth_google_workspace_price_doubled_since_last/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xmci0/wth_google_workspace_price_doubled_since_last/", "subreddit_subscribers": 685568, "created_utc": 1685637364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone, I'm not sure if this is a good place to ask, but if anyone has some tips I'd be very grateful.\n\nUntil yesterday I never seriously thought about storing data in any way because well, I can always just download anything I want right? Certain events have transpired and I changed my mind in the span of 30 minutes, and now I'm looking to create a sort of a small, personal, library of content. Basically my idea was to just buy an external HDD and store everything I want on it, is that enough? I never even used external storage before, but I figured it would be the easiest way.   \n\n\nSorry for the potentially stupid question, any tips and advice is much appreciated, thanks!", "author_fullname": "t2_6geo8ysd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to create a small, personal library?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xc9yy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685609254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m not sure if this is a good place to ask, but if anyone has some tips I&amp;#39;d be very grateful.&lt;/p&gt;\n\n&lt;p&gt;Until yesterday I never seriously thought about storing data in any way because well, I can always just download anything I want right? Certain events have transpired and I changed my mind in the span of 30 minutes, and now I&amp;#39;m looking to create a sort of a small, personal, library of content. Basically my idea was to just buy an external HDD and store everything I want on it, is that enough? I never even used external storage before, but I figured it would be the easiest way.   &lt;/p&gt;\n\n&lt;p&gt;Sorry for the potentially stupid question, any tips and advice is much appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xc9yy", "is_robot_indexable": true, "report_reasons": null, "author": "IAmJacksBrokenHeart7", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xc9yy/how_to_create_a_small_personal_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xc9yy/how_to_create_a_small_personal_library/", "subreddit_subscribers": 685568, "created_utc": 1685609254.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI am interested in the navigation of the 3d model, measuring distance between points in the model. How can I archive the model for offline usage?\n\nhttps://my.matterport.com/show/?m=qfgTi6ikuof\n\nThanks in advance!", "author_fullname": "t2_47ewkr7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive a 3d site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x83h6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685593746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am interested in the navigation of the 3d model, measuring distance between points in the model. How can I archive the model for offline usage?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://my.matterport.com/show/?m=qfgTi6ikuof\"&gt;https://my.matterport.com/show/?m=qfgTi6ikuof&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?auto=webp&amp;v=enabled&amp;s=48798a57255da28436b143a50b494c011f89358f", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ec6738d4ec2b8e2c6dde5ae5377716826322a4d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef980f7c593f7d744896c1c0dbfa4a4a49e49a31", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5262fa98ea7346976faa15bf3f7f9763ee6ae060", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b162753c3dabdbc10634b588bc9439d2a66cf8aa", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60da08e03f12b64bf081e342d7d039f113df858d", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/9MjEiFnqdigVRuQxdV1AoeiZv0UJQjmbsoFUP7yeObE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8afff51932a7452f0e3d294ff0400031417f7587", "width": 1080, "height": 607}], "variants": {}, "id": "nhsJK38BgCHu4xMdbj0-ouwVhmvfJbveK1MCx4YNWEo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13x83h6", "is_robot_indexable": true, "report_reasons": null, "author": "njitzyc", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13x83h6/how_can_i_archive_a_3d_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13x83h6/how_can_i_archive_a_3d_site/", "subreddit_subscribers": 685568, "created_utc": 1685593746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been looking at buying these for a while now &amp; wanted some advice if these were any good / Legit?\n\nSorry if this type of question has been answered\n\nThe 4Tb is $89.00 before tax\n\nAnd the 400 Gb  micro SD card is 49.98 before tax\n\nThank you to anyone willing to take their time!", "author_fullname": "t2_3yf2c6tv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Are these any good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rl7lernhbb3b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ca49af2179b146cec9e9411221d0107995092dc"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=992ec72e3b9e6d3288884aefa00cf8fbaec4526b"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=207895e297363019b3b34816b391446c4b1c3272"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01a853da07f1fe6988d971d237cf1a5153ee340f"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=852a8f4061bffcc7bedb2cbc830e3970d2a80a74"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e1c2e4e0baf946e2a82e60107d80786db59bd6a"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/rl7lernhbb3b1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9150ad21154d23c046e3cdc24bed2e756a331049"}, "id": "rl7lernhbb3b1"}, "r9l45czhbb3b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98b88b82e65ac0899d16dd87fcd4e289f1a44279"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53a8deda719ac0bf9bc31075ece9baa7a9c28bb7"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=415772199b56b41a0b40e94593ef0e746edd5191"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd15249b0d842248a31a1505484f6eaf0c77dc47"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e21881ef5de1dd547eb65a1cb389900ba44ffc12"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc3819e745b985022e3c9fac52c1e36e6b0f2fb4"}], "s": {"y": 3000, "x": 4000, "u": "https://preview.redd.it/r9l45czhbb3b1.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=04b1de8870e322c301f37ac5b04a9dd9ec8034c0"}, "id": "r9l45czhbb3b1"}}, "name": "t3_13x5085", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "ups": 5, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "rl7lernhbb3b1", "id": 282231361}, {"media_id": "r9l45czhbb3b1", "id": 282231362}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3Ohr4ZhEODSv7yEWpPtI71KcrRZHDedRRjGqrJ5s7wE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685584291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking at buying these for a while now &amp;amp; wanted some advice if these were any good / Legit?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this type of question has been answered&lt;/p&gt;\n\n&lt;p&gt;The 4Tb is $89.00 before tax&lt;/p&gt;\n\n&lt;p&gt;And the 400 Gb  micro SD card is 49.98 before tax&lt;/p&gt;\n\n&lt;p&gt;Thank you to anyone willing to take their time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13x5085", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13x5085", "is_robot_indexable": true, "report_reasons": null, "author": "Base201000", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13x5085/are_these_any_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/13x5085", "subreddit_subscribers": 685568, "created_utc": 1685584291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI've purchased a Quantum 8-00976-01 LTO 6 drive to read an archive at work. Unfortunately I've now discovered that this drive is meant to fit in a library, which I don't have access to. On top of that, being an idiot, I've stuck an LTO tape in there (I wanted to make sure it would fit, before I realised what I was dealing with)!\n\nSo at the moment, I can't power it to get the tape out, and I desperately need the tape. Is there a manual override to get the tape out? Ideally without opening up the inside of the drive itself since that will void the warranty... Although if I have no choice but to open the drive to get the tape out, I'd appreciate instructions!\n\nAny help is appreciated, thank you\n\n(Images of the drive below)", "author_fullname": "t2_ci3i6kj73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quantum 8-00976-01 LTO 6 Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xfrc2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685621388.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685620995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve purchased a Quantum 8-00976-01 LTO 6 drive to read an archive at work. Unfortunately I&amp;#39;ve now discovered that this drive is meant to fit in a library, which I don&amp;#39;t have access to. On top of that, being an idiot, I&amp;#39;ve stuck an LTO tape in there (I wanted to make sure it would fit, before I realised what I was dealing with)!&lt;/p&gt;\n\n&lt;p&gt;So at the moment, I can&amp;#39;t power it to get the tape out, and I desperately need the tape. Is there a manual override to get the tape out? Ideally without opening up the inside of the drive itself since that will void the warranty... Although if I have no choice but to open the drive to get the tape out, I&amp;#39;d appreciate instructions!&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated, thank you&lt;/p&gt;\n\n&lt;p&gt;(Images of the drive below)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xfrc2", "is_robot_indexable": true, "report_reasons": null, "author": "Just_Operation_1109", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xfrc2/quantum_80097601_lto_6_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xfrc2/quantum_80097601_lto_6_help/", "subreddit_subscribers": 685568, "created_utc": 1685620995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking to add another backup source to my current setup. Is there a particular LTO-5 unit that the sub finds is a decent value used? When I read through tape-related threads here, LTO-5 is recommended as the tapes are cheap enough to find out in the world.\n\nI'm not Linux-savvy, so something Windows friendly would be my preference (if that matters). If they are usually just plug n play like regular HDD into a motherboard or PCI-E / USB, that is great.\n\nI know that sometimes a used Enterprise-level solution can be more valuable than a new consumer-level device. I have an A/V case with rackmount hardware, so I could mount a rack unit if that's the best solution; just unsure if I need special adapters etc to connect to a standard ATX motherboard. Thanks!\n\nEDIT - looks like I'll probably need some sort of SAS-to-PCI-E adapter which I can research separately.", "author_fullname": "t2_50dz5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO-5 used unit - what do you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xhjbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685626288.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685625878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to add another backup source to my current setup. Is there a particular LTO-5 unit that the sub finds is a decent value used? When I read through tape-related threads here, LTO-5 is recommended as the tapes are cheap enough to find out in the world.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not Linux-savvy, so something Windows friendly would be my preference (if that matters). If they are usually just plug n play like regular HDD into a motherboard or PCI-E / USB, that is great.&lt;/p&gt;\n\n&lt;p&gt;I know that sometimes a used Enterprise-level solution can be more valuable than a new consumer-level device. I have an A/V case with rackmount hardware, so I could mount a rack unit if that&amp;#39;s the best solution; just unsure if I need special adapters etc to connect to a standard ATX motherboard. Thanks!&lt;/p&gt;\n\n&lt;p&gt;EDIT - looks like I&amp;#39;ll probably need some sort of SAS-to-PCI-E adapter which I can research separately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xhjbc", "is_robot_indexable": true, "report_reasons": null, "author": "orielbean", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xhjbc/lto5_used_unit_what_do_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xhjbc/lto5_used_unit_what_do_you_recommend/", "subreddit_subscribers": 685568, "created_utc": 1685625878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, this post is about a mobile game that's going to be made unavailable this July 4th. Named Qubetown, it was released in 2019 and made unavailable later that year before being rereleased as Fantasy Town in 2022. I really love this game and was devastated the first time it was taken offline. Does anyone know if there's a way to archive it? :(", "author_fullname": "t2_9ovbsh5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive this game?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xetqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685618168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, this post is about a mobile game that&amp;#39;s going to be made unavailable this July 4th. Named Qubetown, it was released in 2019 and made unavailable later that year before being rereleased as Fantasy Town in 2022. I really love this game and was devastated the first time it was taken offline. Does anyone know if there&amp;#39;s a way to archive it? :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xetqf", "is_robot_indexable": true, "report_reasons": null, "author": "-_109-_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xetqf/how_can_i_archive_this_game/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xetqf/how_can_i_archive_this_game/", "subreddit_subscribers": 685568, "created_utc": 1685618168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The title is self-explanatory, sorry if this is the wrong sub to ask this, but I do not know anywhere else on reddit where I could ask this.", "author_fullname": "t2_b9uquxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just uploaded 60 photos to Archive.org, but I wanted them to be in chronological order, they are all messy and I want to rearrange/organize them, is this possible? if so, how do I do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x2xtc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": "", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685578770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title is self-explanatory, sorry if this is the wrong sub to ask this, but I do not know anywhere else on reddit where I could ask this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13x2xtc", "is_robot_indexable": true, "report_reasons": null, "author": "wq1119", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13x2xtc/i_just_uploaded_60_photos_to_archiveorg_but_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13x2xtc/i_just_uploaded_60_photos_to_archiveorg_but_i/", "subreddit_subscribers": 685568, "created_utc": 1685578770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to mount 30 HDD's inside a couple gutted old towers I have.\n\nI was looking at buying a few of these: [10 Bay HDD Cage from Amazon](https://www.amazon.ca/yasu7-Stacking-Aluminum-Absorbing-Installation/dp/B09CR37C21/) or [16 Bay HDD Cage from Aliexpress](https://www.aliexpress.com/item/1005004460135377.html)\n\nSuggestions on the most economical way to do this?", "author_fullname": "t2_2vcbw7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "30 HDD's inside one or two gutted computer towers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wzred", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685572845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685571004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to mount 30 HDD&amp;#39;s inside a couple gutted old towers I have.&lt;/p&gt;\n\n&lt;p&gt;I was looking at buying a few of these: &lt;a href=\"https://www.amazon.ca/yasu7-Stacking-Aluminum-Absorbing-Installation/dp/B09CR37C21/\"&gt;10 Bay HDD Cage from Amazon&lt;/a&gt; or &lt;a href=\"https://www.aliexpress.com/item/1005004460135377.html\"&gt;16 Bay HDD Cage from Aliexpress&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Suggestions on the most economical way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13wzred", "is_robot_indexable": true, "report_reasons": null, "author": "solbergren", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13wzred/30_hdds_inside_one_or_two_gutted_computer_towers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13wzred/30_hdds_inside_one_or_two_gutted_computer_towers/", "subreddit_subscribers": 685568, "created_utc": 1685571004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Before I go though a very tedious project of manually cleaning up every folder of my audiobooks does anyone know of a program that will generate new folders with correct naming, clean up the metadata and put a copy of the cover art in the folder with it?", "author_fullname": "t2_zm65u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Audiobook - File sorting / Cover Art / Metadata updating", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xnksc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685640126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before I go though a very tedious project of manually cleaning up every folder of my audiobooks does anyone know of a program that will generate new folders with correct naming, clean up the metadata and put a copy of the cover art in the folder with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xnksc", "is_robot_indexable": true, "report_reasons": null, "author": "patricthomas", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xnksc/audiobook_file_sorting_cover_art_metadata_updating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xnksc/audiobook_file_sorting_cover_art_metadata_updating/", "subreddit_subscribers": 685568, "created_utc": 1685640126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have a 10% off coupon for WD that i will not be using. anyone who wants it can use it while it lasts\n\n XTRA10-LD2N-SFFK-5CWS-FKF2", "author_fullname": "t2_1swadf0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10% off WD store - first come first served", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xn131", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685638883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have a 10% off coupon for WD that i will not be using. anyone who wants it can use it while it lasts&lt;/p&gt;\n\n&lt;p&gt;XTRA10-LD2N-SFFK-5CWS-FKF2&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xn131", "is_robot_indexable": true, "report_reasons": null, "author": "wallacebrf", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xn131/10_off_wd_store_first_come_first_served/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xn131/10_off_wd_store_first_come_first_served/", "subreddit_subscribers": 685568, "created_utc": 1685638883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are WD official website purchases of multiple internal hard drives still being shipped poorly protected?\n\nIt looks like there were posts from a year ago where they are not in styrofoam and/or good clamshells. It seems single drives have no issue (from a six month ago post)\n\nWas curious because there's a deal on a pair of WD Red Pro 18TB's at the moment. These would be my first try having drives shipped to me...", "author_fullname": "t2_kaw77", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital shipping packaging?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xkmh5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685633512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are WD official website purchases of multiple internal hard drives still being shipped poorly protected?&lt;/p&gt;\n\n&lt;p&gt;It looks like there were posts from a year ago where they are not in styrofoam and/or good clamshells. It seems single drives have no issue (from a six month ago post)&lt;/p&gt;\n\n&lt;p&gt;Was curious because there&amp;#39;s a deal on a pair of WD Red Pro 18TB&amp;#39;s at the moment. These would be my first try having drives shipped to me...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xkmh5", "is_robot_indexable": true, "report_reasons": null, "author": "detracts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xkmh5/western_digital_shipping_packaging/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xkmh5/western_digital_shipping_packaging/", "subreddit_subscribers": 685568, "created_utc": 1685633512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to write a scraper for a website, but I am encountering two issues.\n\n**The main issue**\n\nThe scraper works successfully  without proxies enabled, and can achieve a rate of 800 requests per second. When proxies are enabled, this rate drops to \\~10.\n\nI am writing code in Java (as it's a language I'm familiar with). The code runs one producer thread that creates tasks, and multiple consumer threads, which process tasks asynchronously with a limit on co-currency.\n\nMy issue is that when making these requests, it seems as if not all proxies in the database are utilized properly.\n\nFor each proxy in the database, I hold the following information:\n\n`connection_string, usage_count, success_count, failed_count, fail_streak, cooldown_until, last_used, status`\n\nTo select proxies from the database, I do\n\n`String query = \"SELECT id, connection_string, usage_count, success_count, failed_count, fail_streak, cooldown_until \" +\"FROM test_proxy \" +\"WHERE (cooldown_until IS NULL OR NOW() &gt; cooldown_until) \" +\"ORDER BY CASE WHEN usage_count = 0 THEN 1 ELSE success_count / usage_count END DESC, last_used ASC \" +\"LIMIT 150\";`\n\nI load the proxies into memory, and then run an update on the database every second using batch, and reload the data. This prevents a huge amount of requests from having to be made to the database. To fetch a particular proxy, I do the following:\n\nI load the proxies into memory, and then run an update on the database every second using batch, and reload the data. This prevents a huge amount of requests from having to be made to the database. To fetch a particular proxy, I do the following\n\n        public Proxy getNewProxy() {\n            synchronized (proxies) {\n                if(proxies.size() == 0){\n                    return null;\n                }\n    \n                Random random = new Random();\n                int randomIndex = random.nextInt(proxies.size());\n                Proxy proxy = proxies.get(randomIndex);\n    \n                return proxy;\n            }\n        }\n\nWhen a request fails/succeeds, the following occurs\n\n    public void onSuccess(){\n            this.usageCount.incrementAndGet();\n            this.successCount.incrementAndGet();\n            this.failStreak.set(0);\n            this.cooldownUntil.set(System.currentTimeMillis());\n    }\n\nthis.usageCount.incrementAndGet(); this.successCount.incrementAndGet(); this.failStreak.set(0); this.cooldownUntil.set(System.currentTimeMillis()); }\n\n    public void onFailure() {\n            this.usageCount.incrementAndGet();\n            this.failedCount.incrementAndGet();\n            this.failStreak.incrementAndGet();\n    \n            int baseCooldownTime = 1000;\n            double exponentialFactor = 1.5;\n            long cooldownTime = baseCooldownTime * (long) Math.pow(exponentialFactor, failStreak.get() - 1);\n            long cooldownUntil = System.currentTimeMillis() + cooldownTime;\n            // TODO: check new cooldownuntil time is not more than 1 hour\n    \n            //System.out.println(\"back off time = \" + (cooldownTime / 1000));\n    \n            if(cooldownUntil &gt; this.cooldownUntil.get()){\n                this.cooldownUntil.set(System.currentTimeMillis() + cooldownTime);\n            }\n    }\n\nThe code only seems to use 50 of the proxies within the first 10 minutes, and only achieves a rate of \\~10 requests per second.\n\nI have been stuck on this issue for 2 months. I need a better strategy picking proxies, in order to optimize the amount of potential requests that can be made every second.\n\nCurrently I rank all proxies by success, and last used, then limit to the top 50, and select a random proxy.\n\nIf you have any suggestions on a better method, other than round-robin, please let me know, as I'm struggling a little!", "author_fullname": "t2_e0ksma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing the best proxy to use from a large list", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xhcnp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685625402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to write a scraper for a website, but I am encountering two issues.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The main issue&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The scraper works successfully  without proxies enabled, and can achieve a rate of 800 requests per second. When proxies are enabled, this rate drops to ~10.&lt;/p&gt;\n\n&lt;p&gt;I am writing code in Java (as it&amp;#39;s a language I&amp;#39;m familiar with). The code runs one producer thread that creates tasks, and multiple consumer threads, which process tasks asynchronously with a limit on co-currency.&lt;/p&gt;\n\n&lt;p&gt;My issue is that when making these requests, it seems as if not all proxies in the database are utilized properly.&lt;/p&gt;\n\n&lt;p&gt;For each proxy in the database, I hold the following information:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;connection_string, usage_count, success_count, failed_count, fail_streak, cooldown_until, last_used, status&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;To select proxies from the database, I do&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;String query = &amp;quot;SELECT id, connection_string, usage_count, success_count, failed_count, fail_streak, cooldown_until &amp;quot; +&amp;quot;FROM test_proxy &amp;quot; +&amp;quot;WHERE (cooldown_until IS NULL OR NOW() &amp;gt; cooldown_until) &amp;quot; +&amp;quot;ORDER BY CASE WHEN usage_count = 0 THEN 1 ELSE success_count / usage_count END DESC, last_used ASC &amp;quot; +&amp;quot;LIMIT 150&amp;quot;;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I load the proxies into memory, and then run an update on the database every second using batch, and reload the data. This prevents a huge amount of requests from having to be made to the database. To fetch a particular proxy, I do the following:&lt;/p&gt;\n\n&lt;p&gt;I load the proxies into memory, and then run an update on the database every second using batch, and reload the data. This prevents a huge amount of requests from having to be made to the database. To fetch a particular proxy, I do the following&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    public Proxy getNewProxy() {\n        synchronized (proxies) {\n            if(proxies.size() == 0){\n                return null;\n            }\n\n            Random random = new Random();\n            int randomIndex = random.nextInt(proxies.size());\n            Proxy proxy = proxies.get(randomIndex);\n\n            return proxy;\n        }\n    }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When a request fails/succeeds, the following occurs&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;public void onSuccess(){\n        this.usageCount.incrementAndGet();\n        this.successCount.incrementAndGet();\n        this.failStreak.set(0);\n        this.cooldownUntil.set(System.currentTimeMillis());\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;this.usageCount.incrementAndGet(); this.successCount.incrementAndGet(); this.failStreak.set(0); this.cooldownUntil.set(System.currentTimeMillis()); }&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;public void onFailure() {\n        this.usageCount.incrementAndGet();\n        this.failedCount.incrementAndGet();\n        this.failStreak.incrementAndGet();\n\n        int baseCooldownTime = 1000;\n        double exponentialFactor = 1.5;\n        long cooldownTime = baseCooldownTime * (long) Math.pow(exponentialFactor, failStreak.get() - 1);\n        long cooldownUntil = System.currentTimeMillis() + cooldownTime;\n        // TODO: check new cooldownuntil time is not more than 1 hour\n\n        //System.out.println(&amp;quot;back off time = &amp;quot; + (cooldownTime / 1000));\n\n        if(cooldownUntil &amp;gt; this.cooldownUntil.get()){\n            this.cooldownUntil.set(System.currentTimeMillis() + cooldownTime);\n        }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The code only seems to use 50 of the proxies within the first 10 minutes, and only achieves a rate of ~10 requests per second.&lt;/p&gt;\n\n&lt;p&gt;I have been stuck on this issue for 2 months. I need a better strategy picking proxies, in order to optimize the amount of potential requests that can be made every second.&lt;/p&gt;\n\n&lt;p&gt;Currently I rank all proxies by success, and last used, then limit to the top 50, and select a random proxy.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions on a better method, other than round-robin, please let me know, as I&amp;#39;m struggling a little!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xhcnp", "is_robot_indexable": true, "report_reasons": null, "author": "JakeN9", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xhcnp/choosing_the_best_proxy_to_use_from_a_large_list/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xhcnp/choosing_the_best_proxy_to_use_from_a_large_list/", "subreddit_subscribers": 685568, "created_utc": 1685625402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi fellow hoarders.  \nI took a look at the wiki but couldn't find what I needed. I'm looking for an android app/method to be able to organise the file structure of my photos, and move any not in the right place. The propose structure would be something like:  \n:Images/Year/Month/file.extension.  \n\n\nAn essential feature for me would be to automatically move and organise the whatsapp photos received as right now their convoluted location doesn't get backed up by Onedrive.  \n\n\nThanks", "author_fullname": "t2_6cr2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photo (file management) organiser for Samsung/Android", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xcflo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685609848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow hoarders.&lt;br/&gt;\nI took a look at the wiki but couldn&amp;#39;t find what I needed. I&amp;#39;m looking for an android app/method to be able to organise the file structure of my photos, and move any not in the right place. The propose structure would be something like:&lt;br/&gt;\n:Images/Year/Month/file.extension.  &lt;/p&gt;\n\n&lt;p&gt;An essential feature for me would be to automatically move and organise the whatsapp photos received as right now their convoluted location doesn&amp;#39;t get backed up by Onedrive.  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xcflo", "is_robot_indexable": true, "report_reasons": null, "author": "JiggaRob", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xcflo/photo_file_management_organiser_for_samsungandroid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xcflo/photo_file_management_organiser_for_samsungandroid/", "subreddit_subscribers": 685568, "created_utc": 1685609848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\u2026and not in a good way.\n\nI\u2019ve owned a lot of USB-powered portable hard drives over the years. They\u2019re just so damn convenient. Recently I had to get a new one, so I went to a local store. I usually go with WD or Seagate, but they only had 1 and 2 TB, while the highest capacity (4TB) were all Toshiba. So I figured I\u2019ll give them a shot. \n\nI put about 300 MB of photos on it as a test, it finished quickly, all intact. I set it up to copy about 50 GB. It started at 33MB/s, so I walk away, leaving it to do its thing for a bit. Later I come back and am shocked: the transfer speed was down to 1 MB/s. 3 hours remaining. \n\nThat long to copy 50GB? WTF? So I try copying the same files to my equally sized and only a few months old WD Elements portable, and it finishes in *a few minutes*. \n\nI try an experiment. I copied &gt;1TB of data to the WD. It finishes in about 5 hours. I copy the same exact data to the Toshiba, and end up having to leave it overnight. In the morning, the data is less than half copied (but still actively copying) and it says *52 hours remaining*.\n\nWTF is going on here? I thought the formatting must be messed up, so I format the thing. A few times, a few filesystems. Nothing changes. It starts off fine and then drops like a rock. \n\nSo I take it back and exchange for another Toshiba. Guess what, it has the same exact problem. So I return it, again, and just get a WD from Walmart. What do you know, it performs fine and dandy.\n\nSomething is very wrong here. I\u2019m aware of the difference between CMR and SMR, but I\u2019m 99% certain the WDs are also SMR, so that doesn\u2019t explain the massive difference in speed. \n\nWhat the hell, Toshiba? Imagine how long it would take to actually fill the thing with 4TB. How can they even sell something that\u2019s this bad at its only job?", "author_fullname": "t2_tggommtv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba portable drives have me in awe\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xbdj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685606027.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685605754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\u2026and not in a good way.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve owned a lot of USB-powered portable hard drives over the years. They\u2019re just so damn convenient. Recently I had to get a new one, so I went to a local store. I usually go with WD or Seagate, but they only had 1 and 2 TB, while the highest capacity (4TB) were all Toshiba. So I figured I\u2019ll give them a shot. &lt;/p&gt;\n\n&lt;p&gt;I put about 300 MB of photos on it as a test, it finished quickly, all intact. I set it up to copy about 50 GB. It started at 33MB/s, so I walk away, leaving it to do its thing for a bit. Later I come back and am shocked: the transfer speed was down to 1 MB/s. 3 hours remaining. &lt;/p&gt;\n\n&lt;p&gt;That long to copy 50GB? WTF? So I try copying the same files to my equally sized and only a few months old WD Elements portable, and it finishes in &lt;em&gt;a few minutes&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;I try an experiment. I copied &amp;gt;1TB of data to the WD. It finishes in about 5 hours. I copy the same exact data to the Toshiba, and end up having to leave it overnight. In the morning, the data is less than half copied (but still actively copying) and it says &lt;em&gt;52 hours remaining&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;WTF is going on here? I thought the formatting must be messed up, so I format the thing. A few times, a few filesystems. Nothing changes. It starts off fine and then drops like a rock. &lt;/p&gt;\n\n&lt;p&gt;So I take it back and exchange for another Toshiba. Guess what, it has the same exact problem. So I return it, again, and just get a WD from Walmart. What do you know, it performs fine and dandy.&lt;/p&gt;\n\n&lt;p&gt;Something is very wrong here. I\u2019m aware of the difference between CMR and SMR, but I\u2019m 99% certain the WDs are also SMR, so that doesn\u2019t explain the massive difference in speed. &lt;/p&gt;\n\n&lt;p&gt;What the hell, Toshiba? Imagine how long it would take to actually fill the thing with 4TB. How can they even sell something that\u2019s this bad at its only job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13xbdj2", "is_robot_indexable": true, "report_reasons": null, "author": "bobisnotmyuncIe", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xbdj2/toshiba_portable_drives_have_me_in_awe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xbdj2/toshiba_portable_drives_have_me_in_awe/", "subreddit_subscribers": 685568, "created_utc": 1685605754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've purchased LTO 6 drive recently. The drive is connected to a NAS I built by myself because it was the only computer with free PCIe slot for installing a SAS card.\n\nLTFS looks simpler to use, but it does not seem to support encryption. Not sure if it's fast enough with large number of small files.\n\nParchive supports checksum verification of data, though [its Wikipedia article states that most implementations do not support Unicode.](https://en.wikipedia.org/wiki/Parchive#Par2) Parchive itself does not support encryption. Not sure it could be directly used with devices like tape drives (which lack random access and only does sequential access). \n\nOr, do everybody write their own script with set of CLI tools ([like described in this article?](https://www.reddit.com/r/DataHoarder/comments/sdy9hf/lto_tape_data_storage_for_linux_nerds/))", "author_fullname": "t2_13pr7xbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What CLI tool do you use archiving files with LTO tape drives on Linux? I want one with encryption and data corruption detection, and is simple to use.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xaffv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685602104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve purchased LTO 6 drive recently. The drive is connected to a NAS I built by myself because it was the only computer with free PCIe slot for installing a SAS card.&lt;/p&gt;\n\n&lt;p&gt;LTFS looks simpler to use, but it does not seem to support encryption. Not sure if it&amp;#39;s fast enough with large number of small files.&lt;/p&gt;\n\n&lt;p&gt;Parchive supports checksum verification of data, though &lt;a href=\"https://en.wikipedia.org/wiki/Parchive#Par2\"&gt;its Wikipedia article states that most implementations do not support Unicode.&lt;/a&gt; Parchive itself does not support encryption. Not sure it could be directly used with devices like tape drives (which lack random access and only does sequential access). &lt;/p&gt;\n\n&lt;p&gt;Or, do everybody write their own script with set of CLI tools (&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/sdy9hf/lto_tape_data_storage_for_linux_nerds/\"&gt;like described in this article?&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xaffv", "is_robot_indexable": true, "report_reasons": null, "author": "vroad_x", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xaffv/what_cli_tool_do_you_use_archiving_files_with_lto/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xaffv/what_cli_tool_do_you_use_archiving_files_with_lto/", "subreddit_subscribers": 685568, "created_utc": 1685602104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This may be a very specific/niche problem, but I'm currently sharing my NAS with a friend who is currently overseas for studies, and he's reported a significant amount of lag when he's using the windows file explorer to access the SMB share when connected to my Tailscale network. As I understand it, SMB really does not like high latency, as each packet sent would need an acknowledgement before the subsequent packet is sent, thus causing a huge slowdown when the latency is high. My question is if this can be alleviated/overcome.", "author_fullname": "t2_zd7uf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tailscale SMB share access lagging/crashing windows file explorer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wyvhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685568979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This may be a very specific/niche problem, but I&amp;#39;m currently sharing my NAS with a friend who is currently overseas for studies, and he&amp;#39;s reported a significant amount of lag when he&amp;#39;s using the windows file explorer to access the SMB share when connected to my Tailscale network. As I understand it, SMB really does not like high latency, as each packet sent would need an acknowledgement before the subsequent packet is sent, thus causing a huge slowdown when the latency is high. My question is if this can be alleviated/overcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13wyvhl", "is_robot_indexable": true, "report_reasons": null, "author": "sp00kylucas", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13wyvhl/tailscale_smb_share_access_laggingcrashing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13wyvhl/tailscale_smb_share_access_laggingcrashing/", "subreddit_subscribers": 685568, "created_utc": 1685568979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\n**Question:** I came across one forum post saying that having more than one file system on one drive is asking for trouble. Is this true or am I going to be fine with my following plan?\n\nSo I'm planning on getting an external SSD(Samsung T7) to mainly use with my Mac to store footage and do video editing off it. But I do want to occasionally use this same drive with my PC. So I'd like to split the drive into two partitions, one would have the APFS format and the second one NTFS, because from what I've read, exFAT is unreliable and I'll use the Paragon software if I ever need to write to the NTFS partition from my Mac.\n\nEDIT: The reason I want to have the NTFS partition instead of using the APFS plugin on my PC is because I will occasionally connect this drive to the TV and also other Windows PCs.", "author_fullname": "t2_da7en", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about having APFS and NTFS on the same drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xea2j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685616719.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685616412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; I came across one forum post saying that having more than one file system on one drive is asking for trouble. Is this true or am I going to be fine with my following plan?&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m planning on getting an external SSD(Samsung T7) to mainly use with my Mac to store footage and do video editing off it. But I do want to occasionally use this same drive with my PC. So I&amp;#39;d like to split the drive into two partitions, one would have the APFS format and the second one NTFS, because from what I&amp;#39;ve read, exFAT is unreliable and I&amp;#39;ll use the Paragon software if I ever need to write to the NTFS partition from my Mac.&lt;/p&gt;\n\n&lt;p&gt;EDIT: The reason I want to have the NTFS partition instead of using the APFS plugin on my PC is because I will occasionally connect this drive to the TV and also other Windows PCs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13xea2j", "is_robot_indexable": true, "report_reasons": null, "author": "kkuznecovv", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13xea2j/question_about_having_apfs_and_ntfs_on_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13xea2j/question_about_having_apfs_and_ntfs_on_the_same/", "subreddit_subscribers": 685568, "created_utc": 1685616412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any .mso files they'd be willing to provide samples of? Looking to compare with the ones I have for format analysis. Thanks in advance", "author_fullname": "t2_13ju19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ActiveMime/Microsoft Office Macro Reference file (.MSO)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x94an", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685597208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any .mso files they&amp;#39;d be willing to provide samples of? Looking to compare with the ones I have for format analysis. Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13x94an", "is_robot_indexable": true, "report_reasons": null, "author": "IDaresayADisgrace", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13x94an/activemimemicrosoft_office_macro_reference_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13x94an/activemimemicrosoft_office_macro_reference_file/", "subreddit_subscribers": 685568, "created_utc": 1685597208.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}