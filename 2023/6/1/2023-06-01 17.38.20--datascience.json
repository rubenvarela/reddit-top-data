{"kind": "Listing", "data": {"after": "t3_13wvlzr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\"If you want to be a good data scientist, you should spend \\~49% of your time developing your statistical intuition (i.e. how to ask good questions of the data), and \\~49% of your time on domain knowledge (improving overall understanding of your field). Only \\~2% on methods per se.\"\n\nNate said this back in 2019, but has repeated it in various ways since. What do you think?", "author_fullname": "t2_oa3ngk2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you agree with this Nate Silver quote?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xc0zt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 183, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 183, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685608277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;If you want to be a good data scientist, you should spend ~49% of your time developing your statistical intuition (i.e. how to ask good questions of the data), and ~49% of your time on domain knowledge (improving overall understanding of your field). Only ~2% on methods per se.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Nate said this back in 2019, but has repeated it in various ways since. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xc0zt", "is_robot_indexable": true, "report_reasons": null, "author": "chickenparmo", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xc0zt/do_you_agree_with_this_nate_silver_quote/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xc0zt/do_you_agree_with_this_nate_silver_quote/", "subreddit_subscribers": 915116, "created_utc": 1685608277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6cptvbsw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "AI Basketball Referee Trained on 3000+ Images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nz0j7lzu3b3b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=945ee62cfa6a179ced0057ffc57ee0482bc14153"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b5e3944f481c1f6302ce18a152a52f2ad93c459"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=620736d6a019f43d3b94717f4abed614e4083ff4"}, {"y": 361, "x": 640, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17a89b4cde3c4d647cbb1a21795dc6d0829da0a8"}, {"y": 541, "x": 960, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1361c2c0a26a6dc501db264468a3e82fec5cd7e8"}, {"y": 609, "x": 1080, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59d7a86406f8c7d9e3bbe0339e158755aff441fb"}], "s": {"y": 1706, "x": 3024, "u": "https://preview.redd.it/nz0j7lzu3b3b1.png?width=3024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=84fd7e17df924ad05b4f0de5a6b7fcd9d6bc039f"}, "id": "nz0j7lzu3b3b1"}, "elpboovn3b3b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89e9ec3dc945416ed8775bc5ebd89a6aad5f34ea"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e6cd2098e59bf6536e8343850876a92358d450d"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbfa6d6b28e433e98c4601ae44c1af5b67595460"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa25dbd2cf00476567803ef9fe48dc540699f380"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d221f1e3946153c84bd505a5831030cadb3e302"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5a41760560a12834757c908760ac499f24c6083"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/elpboovn3b3b1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=058d2421525edc384537e03c91241bc6a64a9523"}, "id": "elpboovn3b3b1"}, "f8ejubs54b3b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 59, "x": 108, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03e27469304d60cca4cb8acac45217694f9b3c25"}, {"y": 119, "x": 216, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a20389ae407ec50f7198f9b984a0bf8198cd81d"}, {"y": 177, "x": 320, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05a7e53f83f3f49b8e1b9612642ecd025d905c20"}, {"y": 354, "x": 640, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6bff864483656cddb9524f3f7ad16f7cafc836f"}, {"y": 532, "x": 960, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64e57d9c79b78fa047bf33f07405b523513deb1b"}, {"y": 598, "x": 1080, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40362142505a6944c376ffa10de27a5e294342bc"}], "s": {"y": 1676, "x": 3024, "u": "https://preview.redd.it/f8ejubs54b3b1.png?width=3024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e184775674445579809504bb6c8f0e8e78599d3e"}, "id": "f8ejubs54b3b1"}}, "name": "t3_13x44iq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 101, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "I created version 2.0 of my AI Basketball Referee. I trained a custom machine-learning model with over 3000 images. ", "outbound_url": "https://youtu.be/VZgXUBi_wkM", "media_id": "f8ejubs54b3b1", "id": 282219390}, {"caption": "Tracks When Ball Is Held", "outbound_url": "https://youtu.be/VZgXUBi_wkM", "media_id": "nz0j7lzu3b3b1", "id": 282219391}, {"caption": "I created version 2.0 of my AI Basketball Referee. I trained a custom machine-learning model with over 3000 images. ", "outbound_url": "https://youtu.be/VZgXUBi_wkM", "media_id": "elpboovn3b3b1", "id": 282219392}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/djRVsBQGHpAs3VkV9F7MqU7NnaoqUYrP3isSXuJ_TLY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685581878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/13x44iq", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "13x44iq", "is_robot_indexable": true, "report_reasons": null, "author": "_ayushp_", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x44iq/ai_basketball_referee_trained_on_3000_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/VZgXUBi_wkM", "subreddit_subscribers": 915116, "created_utc": 1685581878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is the most well-known American data scientist and what field he or she is expert in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x684c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685587822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x684c", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x684c/who_is_the_most_wellknown_american_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x684c/who_is_the_most_wellknown_american_data_scientist/", "subreddit_subscribers": 915116, "created_utc": 1685587822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was scrolling through this sub yesterday and saw a couple of posts related to what i recently went through - lay offs and freelancing. so thought i'd create a separate detailed post on how i got started freelancing and why not get back into FTE (if interested, see related post back in Jan just after getting laid off- [https://www.reddit.com/r/datascience/comments/10ivzyj/my\\_ds\\_experience\\_at\\_amazon/](https://www.reddit.com/r/datascience/comments/10ivzyj/my_ds_experience_at_amazon/)).\n\nAnyway, after my last FT job at Amazon, and having the luxury of not needing to jump back into the job market immediately, I had to choose between getting back to stable employment or exploring few things i had wanted to try out for a while now- freelancing and learning web development.\n\nEven with FTE, I had tried working on side projects on evenings/weekends after regular work hours, but with Amazon, \"regular work hours\" is a blurry line. and my projects never really got anywhere. January was also the time when chatGPT was getting popular and I had been playing around with chat-with-your-data apps using the openai LLMs. So on a whim, even before deciding anything, I created an Upwork profile. Mostly, I wanted to prove to myself that i could make money if i needed to without selling away all my time to a company.\n\nI reached out to a couple of folks on Upwork who needed help with AI chatbots, and to my surprise, within a couple of weeks, i had my first freelancing gig and soon after (thanks to the upwork algorithm), started getting jobs in my inbox. So much so that I could select what jobs i wanted to work on. Just last week, I declined a $10k contract offer just for the first phase as the client had been dragging their feet since March with \"approvals\" and the scope was unclear. I had to remind myself that i didn't want to get into another long contract which would effectively be full time employment.\n\nSince Feb, I have made $15k on Upwork without really 'applying' for any of them (all inbound requests), while being highly selective on how much time i freelance and what kind of work i want to do. I know $15k is nothing to brag about compared to a salary, but I share this as someone who 4 months back, thought freelancing was a non-option for me. To the person who asked about this yesterday, it's very doable.\n\nSo what have I been doing with the rest of my time? Spending time with my now 6-month son, traveling, and learning web development. Work-wise, I wanted to reconnect with fellow data scientists, so tried running a data science mentoring/mock interview group here but that never really took off ([https://www.reddit.com/r/datascience/comments/10uy2qi/starting\\_a\\_personalized\\_mentorship\\_group\\_for\\_data/](https://www.reddit.com/r/datascience/comments/10uy2qi/starting_a_personalized_mentorship_group_for_data/)).  So instead, I combined it with my other interest to learn web development and have built a data science mock interview app - [rightjoin.co](https://rightjoin.co). here is a short blurb-\n\n* get mock interviewed with an AI hiring manager for any company/job post/topic of choice. Warm up for your upcoming interview with questions tailored to the job posting/topic.\n* you can upload your resume and have your AI persona answer questions for you. so you get to observe how your chatGPT-version would answer questions.\n* get feedback on each response to the interviewer questions\n\nIts currently a \"phone-screen\" level interview, but i plan adding other types of interview rounds if people find this useful. And its free. please try out and let me know what you think, especially if you have an upcoming interview. here's a screenshot:\n\n[tailored mock interview by an imaginary hiring manager \\(https:\\/\\/rightjoin.co\\/\\)](https://preview.redd.it/hzycr666rc3b1.png?width=2158&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d56a4bb08b55a124e0fe447017fdc1eade3d39c0)\n\nFor me, it's been fun dabbling with web development (django, htmx), keeping up with AI wave, having the freedom to spend time with family when i feel like, and learn things that interest me. I know this may not be sustainable, but I do plan to ramp up freelancing later this year if needed to stress test that option, and only in the worst case, jump back into the job market.\n\nI understand, these options may not be viable for others, but if you do find yourself having to make additional income with freelancing or want to try out solopreneurship, it's possible. Obviously there is risk involved but also ways to manage that risk until your build your portfolio a little. the AI wave has made this easier than otherwise, but as a data scientist, why wouldn't you jump on this wave?\n\nThats it, hope this was useful for a few here and please connect if interested :)", "author_fullname": "t2_4m1ivn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My experience transitioning from full-time to freelancing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hzycr666rc3b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86067ac822ba3ce9bd87d56948bd45fca248ed64"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d6ba3aec51e2bb0d58c5b6b422cf078b1272465"}, {"y": 187, "x": 320, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=925e9a000c77b48d0c0799546563c2e787079053"}, {"y": 374, "x": 640, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9490aa59cd6133f7cfc70d3fb0ee62bc564ab01b"}, {"y": 561, "x": 960, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d28a38172ea630c63a6e4fe9ac1f2efe205957ee"}, {"y": 631, "x": 1080, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adb7e00c4106ede5507137585d58564017e8b8a3"}], "s": {"y": 1262, "x": 2158, "u": "https://preview.redd.it/hzycr666rc3b1.png?width=2158&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d56a4bb08b55a124e0fe447017fdc1eade3d39c0"}, "id": "hzycr666rc3b1"}}, "name": "t3_13xabtx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IMNZeyq0v7OIQhZDiV2QvV7WHqI_zoBgluNtITjYVqc.jpg", "edited": 1685606974.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685601703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was scrolling through this sub yesterday and saw a couple of posts related to what i recently went through - lay offs and freelancing. so thought i&amp;#39;d create a separate detailed post on how i got started freelancing and why not get back into FTE (if interested, see related post back in Jan just after getting laid off- &lt;a href=\"https://www.reddit.com/r/datascience/comments/10ivzyj/my_ds_experience_at_amazon/\"&gt;https://www.reddit.com/r/datascience/comments/10ivzyj/my_ds_experience_at_amazon/&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;Anyway, after my last FT job at Amazon, and having the luxury of not needing to jump back into the job market immediately, I had to choose between getting back to stable employment or exploring few things i had wanted to try out for a while now- freelancing and learning web development.&lt;/p&gt;\n\n&lt;p&gt;Even with FTE, I had tried working on side projects on evenings/weekends after regular work hours, but with Amazon, &amp;quot;regular work hours&amp;quot; is a blurry line. and my projects never really got anywhere. January was also the time when chatGPT was getting popular and I had been playing around with chat-with-your-data apps using the openai LLMs. So on a whim, even before deciding anything, I created an Upwork profile. Mostly, I wanted to prove to myself that i could make money if i needed to without selling away all my time to a company.&lt;/p&gt;\n\n&lt;p&gt;I reached out to a couple of folks on Upwork who needed help with AI chatbots, and to my surprise, within a couple of weeks, i had my first freelancing gig and soon after (thanks to the upwork algorithm), started getting jobs in my inbox. So much so that I could select what jobs i wanted to work on. Just last week, I declined a $10k contract offer just for the first phase as the client had been dragging their feet since March with &amp;quot;approvals&amp;quot; and the scope was unclear. I had to remind myself that i didn&amp;#39;t want to get into another long contract which would effectively be full time employment.&lt;/p&gt;\n\n&lt;p&gt;Since Feb, I have made $15k on Upwork without really &amp;#39;applying&amp;#39; for any of them (all inbound requests), while being highly selective on how much time i freelance and what kind of work i want to do. I know $15k is nothing to brag about compared to a salary, but I share this as someone who 4 months back, thought freelancing was a non-option for me. To the person who asked about this yesterday, it&amp;#39;s very doable.&lt;/p&gt;\n\n&lt;p&gt;So what have I been doing with the rest of my time? Spending time with my now 6-month son, traveling, and learning web development. Work-wise, I wanted to reconnect with fellow data scientists, so tried running a data science mentoring/mock interview group here but that never really took off (&lt;a href=\"https://www.reddit.com/r/datascience/comments/10uy2qi/starting_a_personalized_mentorship_group_for_data/\"&gt;https://www.reddit.com/r/datascience/comments/10uy2qi/starting_a_personalized_mentorship_group_for_data/&lt;/a&gt;).  So instead, I combined it with my other interest to learn web development and have built a data science mock interview app - &lt;a href=\"https://rightjoin.co\"&gt;rightjoin.co&lt;/a&gt;. here is a short blurb-&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;get mock interviewed with an AI hiring manager for any company/job post/topic of choice. Warm up for your upcoming interview with questions tailored to the job posting/topic.&lt;/li&gt;\n&lt;li&gt;you can upload your resume and have your AI persona answer questions for you. so you get to observe how your chatGPT-version would answer questions.&lt;/li&gt;\n&lt;li&gt;get feedback on each response to the interviewer questions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Its currently a &amp;quot;phone-screen&amp;quot; level interview, but i plan adding other types of interview rounds if people find this useful. And its free. please try out and let me know what you think, especially if you have an upcoming interview. here&amp;#39;s a screenshot:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hzycr666rc3b1.png?width=2158&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d56a4bb08b55a124e0fe447017fdc1eade3d39c0\"&gt;tailored mock interview by an imaginary hiring manager (https://rightjoin.co/)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For me, it&amp;#39;s been fun dabbling with web development (django, htmx), keeping up with AI wave, having the freedom to spend time with family when i feel like, and learn things that interest me. I know this may not be sustainable, but I do plan to ramp up freelancing later this year if needed to stress test that option, and only in the worst case, jump back into the job market.&lt;/p&gt;\n\n&lt;p&gt;I understand, these options may not be viable for others, but if you do find yourself having to make additional income with freelancing or want to try out solopreneurship, it&amp;#39;s possible. Obviously there is risk involved but also ways to manage that risk until your build your portfolio a little. the AI wave has made this easier than otherwise, but as a data scientist, why wouldn&amp;#39;t you jump on this wave?&lt;/p&gt;\n\n&lt;p&gt;Thats it, hope this was useful for a few here and please connect if interested :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xabtx", "is_robot_indexable": true, "report_reasons": null, "author": "sang89", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xabtx/my_experience_transitioning_from_fulltime_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xabtx/my_experience_transitioning_from_fulltime_to/", "subreddit_subscribers": 915116, "created_utc": 1685601703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand before one can apply Arima or Sarima for a time series, one needs to make the non stationary time series into stationary.\n\nBut making it stationary also means removing the trends and seasonality. Then how can these techniques fully capture the time series' properties? Would they be more predictive if there are components in their model that capture the trend and seasonality?\n\nSecond question, Sarima has a seasonal component, is it still necessary to make a job stationary time series stationary before running Sarima?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused why we need to make non stationary time series stationary before applying Arima or Sarima", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x08tq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685572125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand before one can apply Arima or Sarima for a time series, one needs to make the non stationary time series into stationary.&lt;/p&gt;\n\n&lt;p&gt;But making it stationary also means removing the trends and seasonality. Then how can these techniques fully capture the time series&amp;#39; properties? Would they be more predictive if there are components in their model that capture the trend and seasonality?&lt;/p&gt;\n\n&lt;p&gt;Second question, Sarima has a seasonal component, is it still necessary to make a job stationary time series stationary before running Sarima?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x08tq", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x08tq/confused_why_we_need_to_make_non_stationary_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x08tq/confused_why_we_need_to_make_non_stationary_time/", "subreddit_subscribers": 915116, "created_utc": 1685572125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say I have a variables such as transaction day part (time of day customer makes purchases) and product groups (products they buy). The silhouette score is low when I perform the initial cluster, but greatly improves when I add weights to the variables (post standardizing) putting more emphasis on day part than products. \n\nThe results look pretty good. For example, we have two afternoon clusters (our busiest time). One cluster, the customers purchase more grocery products, the other cluster purchase more clothing.\n\nThis is over simplified, but you get the point.\n\nIs it ok to add weights to variables? I googled and saw a few others ask this questions, and so far everyone has said it\u2019s ok. But I didn\u2019t see any papers about it, so I wanted to check here to get everyone\u2019s thoughts.\n\nThanks.", "author_fullname": "t2_fjll57b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to add weights to variables in a kmeans?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x1x1n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685576165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say I have a variables such as transaction day part (time of day customer makes purchases) and product groups (products they buy). The silhouette score is low when I perform the initial cluster, but greatly improves when I add weights to the variables (post standardizing) putting more emphasis on day part than products. &lt;/p&gt;\n\n&lt;p&gt;The results look pretty good. For example, we have two afternoon clusters (our busiest time). One cluster, the customers purchase more grocery products, the other cluster purchase more clothing.&lt;/p&gt;\n\n&lt;p&gt;This is over simplified, but you get the point.&lt;/p&gt;\n\n&lt;p&gt;Is it ok to add weights to variables? I googled and saw a few others ask this questions, and so far everyone has said it\u2019s ok. But I didn\u2019t see any papers about it, so I wanted to check here to get everyone\u2019s thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x1x1n", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Resort-4196", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x1x1n/is_it_ok_to_add_weights_to_variables_in_a_kmeans/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x1x1n/is_it_ok_to_add_weights_to_variables_in_a_kmeans/", "subreddit_subscribers": 915116, "created_utc": 1685576165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[deleted]", "author_fullname": "t2_7ci7himt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Boss wants me to pass along my work for project completion by someone else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wsull", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685627877.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685554944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wsull", "is_robot_indexable": true, "report_reasons": null, "author": "njtw-1122", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wsull/boss_wants_me_to_pass_along_my_work_for_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wsull/boss_wants_me_to_pass_along_my_work_for_project/", "subreddit_subscribers": 915116, "created_utc": 1685554944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m just finished my junior year and am now in my final summer before graduation- with no internship. \n\ni feel like I\u2019m doing nothing\u2026because I am and so I don\u2019t want to waste this summer just because I didn\u2019t get an internship. \n\nWhat should I do? I know some people do projects, but how do I do that? Where do I go and how do I start? \n\nI know there are also a lot of data science boot camps- which are the most helpful and which do employers like to see? (And preferably very cheap or free) \n\nAny other suggestions?", "author_fullname": "t2_vojufwj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No internship- what should I do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wtfis", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685556331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m just finished my junior year and am now in my final summer before graduation- with no internship. &lt;/p&gt;\n\n&lt;p&gt;i feel like I\u2019m doing nothing\u2026because I am and so I don\u2019t want to waste this summer just because I didn\u2019t get an internship. &lt;/p&gt;\n\n&lt;p&gt;What should I do? I know some people do projects, but how do I do that? Where do I go and how do I start? &lt;/p&gt;\n\n&lt;p&gt;I know there are also a lot of data science boot camps- which are the most helpful and which do employers like to see? (And preferably very cheap or free) &lt;/p&gt;\n\n&lt;p&gt;Any other suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wtfis", "is_robot_indexable": true, "report_reasons": null, "author": "comfy_cozy_35", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wtfis/no_internship_what_should_i_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wtfis/no_internship_what_should_i_do/", "subreddit_subscribers": 915116, "created_utc": 1685556331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "perhaps the term outliers isnt appropriate here\n\nwhat i did is calculated the shap value for each feature, then :\n\n\\- i took the feature with highest importance\n\n\\- i took the index of each value with negative shap in this feature\n\n\\- i recreated dataset with removing these indexes\n\nsince a negative shap means a datapoint is contributing negatively to the model, i removed it\n\nmy f1score increased from 70% to 90 % ( the data was imbalanced )\n\nis this a good implementation of shap?\n\nbecause its mostly used for model interpretation but i used it for different purpose\n\nthanks for advice", "author_fullname": "t2_a8ditcldc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using shap values for removing outliers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ww38i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685562625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;perhaps the term outliers isnt appropriate here&lt;/p&gt;\n\n&lt;p&gt;what i did is calculated the shap value for each feature, then :&lt;/p&gt;\n\n&lt;p&gt;- i took the feature with highest importance&lt;/p&gt;\n\n&lt;p&gt;- i took the index of each value with negative shap in this feature&lt;/p&gt;\n\n&lt;p&gt;- i recreated dataset with removing these indexes&lt;/p&gt;\n\n&lt;p&gt;since a negative shap means a datapoint is contributing negatively to the model, i removed it&lt;/p&gt;\n\n&lt;p&gt;my f1score increased from 70% to 90 % ( the data was imbalanced )&lt;/p&gt;\n\n&lt;p&gt;is this a good implementation of shap?&lt;/p&gt;\n\n&lt;p&gt;because its mostly used for model interpretation but i used it for different purpose&lt;/p&gt;\n\n&lt;p&gt;thanks for advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ww38i", "is_robot_indexable": true, "report_reasons": null, "author": "qhelspil", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13ww38i/using_shap_values_for_removing_outliers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13ww38i/using_shap_values_for_removing_outliers/", "subreddit_subscribers": 915116, "created_utc": 1685562625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nI'm a researcher at a university and I have a project planned on urban movement and accessibility.\n\nCurrently, I'm in the planning stage of the work and need to figure out a data collection method. I am thinking of an app that allows participants of the study to eaisly share their daily movement (something like Google Maps Timeline) with us to analyse. I couldn't find any useful solutions, so hoping someone here can possibly help out with a recommendation.\n\nIdeally, the app will be able to log location, the route of movement, and time of day data of events.\n\nThanks in advance!", "author_fullname": "t2_nc9e2zv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "App Recommendations for Movement Tracking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x9lim", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685598949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a researcher at a university and I have a project planned on urban movement and accessibility.&lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m in the planning stage of the work and need to figure out a data collection method. I am thinking of an app that allows participants of the study to eaisly share their daily movement (something like Google Maps Timeline) with us to analyse. I couldn&amp;#39;t find any useful solutions, so hoping someone here can possibly help out with a recommendation.&lt;/p&gt;\n\n&lt;p&gt;Ideally, the app will be able to log location, the route of movement, and time of day data of events.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x9lim", "is_robot_indexable": true, "report_reasons": null, "author": "ruinartsocialist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x9lim/app_recommendations_for_movement_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x9lim/app_recommendations_for_movement_tracking/", "subreddit_subscribers": 915116, "created_utc": 1685598949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello... I want to pursue my graduate studies in a field related to Data Science. I've been working and learning in this field for about a year or two and now that I have obtained my bachelor's degree in Mathematics, I aim to deepen my knowledge. In terms of practical tools, I'm pretty fine. I'm pretty good at Python, SQL, Tableau, etc. There is a specific major in maths called Optimization. I want to know whether it's a good choice or not. Is it related to Machine Learning and Data Science? Do you recommend it?\nThank you so much for your help.", "author_fullname": "t2_9a8a04ke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mathematical Optimization and Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xjdmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685630566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello... I want to pursue my graduate studies in a field related to Data Science. I&amp;#39;ve been working and learning in this field for about a year or two and now that I have obtained my bachelor&amp;#39;s degree in Mathematics, I aim to deepen my knowledge. In terms of practical tools, I&amp;#39;m pretty fine. I&amp;#39;m pretty good at Python, SQL, Tableau, etc. There is a specific major in maths called Optimization. I want to know whether it&amp;#39;s a good choice or not. Is it related to Machine Learning and Data Science? Do you recommend it?\nThank you so much for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xjdmx", "is_robot_indexable": true, "report_reasons": null, "author": "Black-EyedRaven", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xjdmx/mathematical_optimization_and_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xjdmx/mathematical_optimization_and_data_science/", "subreddit_subscribers": 915116, "created_utc": 1685630566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sometimes when exploring what feature impact a target variable, I\u2019ve found it helpful to train a model (random Forrest for example) then look at feature importance and or Shapley values. Is this bad practice?", "author_fullname": "t2_bcbozi6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone train models just to gain insight on relationship between features and target variable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xhapb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685625260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes when exploring what feature impact a target variable, I\u2019ve found it helpful to train a model (random Forrest for example) then look at feature importance and or Shapley values. Is this bad practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xhapb", "is_robot_indexable": true, "report_reasons": null, "author": "sizable_data", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xhapb/does_anyone_train_models_just_to_gain_insight_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xhapb/does_anyone_train_models_just_to_gain_insight_on/", "subreddit_subscribers": 915116, "created_utc": 1685625260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I have a dataset covering the sales of products in a collection of grocery stores on a weekly basis over roughly 3 years. I'm looking at hundreds of individual products, and I'm interested in getting a sense of whatever seasonal effects are going on (some of these are really obvious, like some products selling worse at Christmas and vice versa). Where I'm looking to get to ultimately is some notion of a product's base sales in the absence of seasonal effects (and the absence of other factors such as price changes, etc.). \n\nI've tried a few time series decomposition-based approaches coming from the likes of statsmodels.tsa, facebook's prophet, etc., and had some success with pulling out what look to be seasonal coefficients, but there are a few issues I'm running into:\n\n- There are a lot of products to look at, and not all of them have complete data; some are new to the market, some had supply issues for a number of weeks due to covid or other factors. I've looked into grouping products together to smooth some of this out, assuming for example that similar products experience similar seasonal effects, but I'm not sure that it's sufficient to just sum up the sales of a group and treat that as a meaningful time series. \n\nShould I be grouping things at all, should I look at each individually, or should I be treating the whole dataset as a system and somehow look at all products together?\n\n- Some approaches are very conservative with what I get as seasonal coefficients - fb Prophet in particular consistently underestimates the effect that holidays have, even on toy data that's constant for the whole year and spikes to the same level at Christmases. I'm assuming that this is an artifact of the curve fitting it's doing, and I've had some success with using a model with a holiday indicator variable, but it's such a regular pattern especially on the toy data that I was hoping it would be picked up by univariate analysis.\n\n- I'm not entirely clear on how to interpret/apply the results. With prophet models I get weekly coefficients expressed as percentages from multiplicative models, which I'm taking to mean that the sales I'm seeing are my \"base\" sales +/- X%. Does this seem reasonable? I haven't been able to dig up much on deseasonalisation in general.\n\nIf anyone has any thoughts on what I could try or any ideas for where to look/read I'd love to hear them, or if I'm doing anything glaringly wrong I'd really appreciate the feedback.", "author_fullname": "t2_6wpol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having trouble deseasonalising multiple parallel time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xgs4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685623900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have a dataset covering the sales of products in a collection of grocery stores on a weekly basis over roughly 3 years. I&amp;#39;m looking at hundreds of individual products, and I&amp;#39;m interested in getting a sense of whatever seasonal effects are going on (some of these are really obvious, like some products selling worse at Christmas and vice versa). Where I&amp;#39;m looking to get to ultimately is some notion of a product&amp;#39;s base sales in the absence of seasonal effects (and the absence of other factors such as price changes, etc.). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried a few time series decomposition-based approaches coming from the likes of statsmodels.tsa, facebook&amp;#39;s prophet, etc., and had some success with pulling out what look to be seasonal coefficients, but there are a few issues I&amp;#39;m running into:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There are a lot of products to look at, and not all of them have complete data; some are new to the market, some had supply issues for a number of weeks due to covid or other factors. I&amp;#39;ve looked into grouping products together to smooth some of this out, assuming for example that similar products experience similar seasonal effects, but I&amp;#39;m not sure that it&amp;#39;s sufficient to just sum up the sales of a group and treat that as a meaningful time series. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Should I be grouping things at all, should I look at each individually, or should I be treating the whole dataset as a system and somehow look at all products together?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Some approaches are very conservative with what I get as seasonal coefficients - fb Prophet in particular consistently underestimates the effect that holidays have, even on toy data that&amp;#39;s constant for the whole year and spikes to the same level at Christmases. I&amp;#39;m assuming that this is an artifact of the curve fitting it&amp;#39;s doing, and I&amp;#39;ve had some success with using a model with a holiday indicator variable, but it&amp;#39;s such a regular pattern especially on the toy data that I was hoping it would be picked up by univariate analysis.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m not entirely clear on how to interpret/apply the results. With prophet models I get weekly coefficients expressed as percentages from multiplicative models, which I&amp;#39;m taking to mean that the sales I&amp;#39;m seeing are my &amp;quot;base&amp;quot; sales +/- X%. Does this seem reasonable? I haven&amp;#39;t been able to dig up much on deseasonalisation in general.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If anyone has any thoughts on what I could try or any ideas for where to look/read I&amp;#39;d love to hear them, or if I&amp;#39;m doing anything glaringly wrong I&amp;#39;d really appreciate the feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xgs4p", "is_robot_indexable": true, "report_reasons": null, "author": "InflationSquare", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xgs4p/having_trouble_deseasonalising_multiple_parallel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xgs4p/having_trouble_deseasonalising_multiple_parallel/", "subreddit_subscribers": 915116, "created_utc": 1685623900.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hundreds of millions of observations, with 30 or so columns. \n\nFirst step is to reduce dimensionality to 3 (t-SNE). \n\nSecond step is to map/plot. I am most familiar with Python and will try Vaex when I get back to the office, at the end of the summer. In the meantime I'd like to read and learn about tools and techniques. I'd want to render 3D plots that can be rotated. Specify the color of dots that belong to a given class. Learn to create \"exploding\" plots (start with aggregates, then explode to show individual components).\n\nWell, you probably can see the picture. \n\nSuggestions?", "author_fullname": "t2_3854xj3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are good resources to assist in large scale 3Dvisualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xe04n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685615475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hundreds of millions of observations, with 30 or so columns. &lt;/p&gt;\n\n&lt;p&gt;First step is to reduce dimensionality to 3 (t-SNE). &lt;/p&gt;\n\n&lt;p&gt;Second step is to map/plot. I am most familiar with Python and will try Vaex when I get back to the office, at the end of the summer. In the meantime I&amp;#39;d like to read and learn about tools and techniques. I&amp;#39;d want to render 3D plots that can be rotated. Specify the color of dots that belong to a given class. Learn to create &amp;quot;exploding&amp;quot; plots (start with aggregates, then explode to show individual components).&lt;/p&gt;\n\n&lt;p&gt;Well, you probably can see the picture. &lt;/p&gt;\n\n&lt;p&gt;Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xe04n", "is_robot_indexable": true, "report_reasons": null, "author": "-gauvins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xe04n/what_are_good_resources_to_assist_in_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xe04n/what_are_good_resources_to_assist_in_large_scale/", "subreddit_subscribers": 915116, "created_utc": 1685615475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am curently working on time series forecasting with different ML and deep Learning models . All the ressources i've found stoped at train, testing and validating the model but never on forecasting actual future values.\n\nFor example with ANN i've created a Train and test set based on one unique feature. Using feature engineering to create features based on the target (the lags, hours and minutes without entering too much into details)  and the unique feature as the target. The model works just fine on the train and test set ,but Now that i have to predict the future i'm stuck . I'm suposed to feed my model something for it to be able to make predictions but i don't know how i'm supose to do it.\n\nSorry if the question sounds a bit silly for some of you but i'm just starting.", "author_fullname": "t2_ccp5jozq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicting the future : time series forecasting with ML and DL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xil8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685628583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curently working on time series forecasting with different ML and deep Learning models . All the ressources i&amp;#39;ve found stoped at train, testing and validating the model but never on forecasting actual future values.&lt;/p&gt;\n\n&lt;p&gt;For example with ANN i&amp;#39;ve created a Train and test set based on one unique feature. Using feature engineering to create features based on the target (the lags, hours and minutes without entering too much into details)  and the unique feature as the target. The model works just fine on the train and test set ,but Now that i have to predict the future i&amp;#39;m stuck . I&amp;#39;m suposed to feed my model something for it to be able to make predictions but i don&amp;#39;t know how i&amp;#39;m supose to do it.&lt;/p&gt;\n\n&lt;p&gt;Sorry if the question sounds a bit silly for some of you but i&amp;#39;m just starting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xil8l", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic_Local_9115", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xil8l/predicting_the_future_time_series_forecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xil8l/predicting_the_future_time_series_forecasting/", "subreddit_subscribers": 915116, "created_utc": 1685628583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! \ud83d\udc4b\n\nAt the [Data-Centric AI Community](https://github.com/Data-Centric-AI-Community), we're going through a small community project on synthetic data, using [ydata-synthetic](https://github.com/ydataai/ydata-synthetic). The instructions are given on a weekly basis and we meet to discuss our findings. \n\nWe want to encourage everyone to showcase their projects, by writing a short piece on LinkedIn, Towards Data Science, other Medium publications or simply by adding it to the portfolio on GitHub and sharing it with us!\n\nOur team is always available to discuss the results with you, and you can use it with your own dataset instead of the datasets provided.\n\nWhen you finish the project, we'll be happy to send you a very special [holopin](https://www.holopin.io) badge for you to showcase in your GitHub profile :) Can you do it until the end of the month? \ud83d\ude01", "author_fullname": "t2_tqj6pej3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synthetic Data Challenge (complete a simple project, add it to your portfolio, and win a badge!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xial0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685627853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;At the &lt;a href=\"https://github.com/Data-Centric-AI-Community\"&gt;Data-Centric AI Community&lt;/a&gt;, we&amp;#39;re going through a small community project on synthetic data, using &lt;a href=\"https://github.com/ydataai/ydata-synthetic\"&gt;ydata-synthetic&lt;/a&gt;. The instructions are given on a weekly basis and we meet to discuss our findings. &lt;/p&gt;\n\n&lt;p&gt;We want to encourage everyone to showcase their projects, by writing a short piece on LinkedIn, Towards Data Science, other Medium publications or simply by adding it to the portfolio on GitHub and sharing it with us!&lt;/p&gt;\n\n&lt;p&gt;Our team is always available to discuss the results with you, and you can use it with your own dataset instead of the datasets provided.&lt;/p&gt;\n\n&lt;p&gt;When you finish the project, we&amp;#39;ll be happy to send you a very special &lt;a href=\"https://www.holopin.io\"&gt;holopin&lt;/a&gt; badge for you to showcase in your GitHub profile :) Can you do it until the end of the month? \ud83d\ude01&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-yNYBZQan_bX_ib0hicVZh-oZA2toK6FAL_z7Nnyu3Q.jpg?auto=webp&amp;v=enabled&amp;s=4a8ae58999e123a6c3ccde16e97c0016c7083971", "width": 280, "height": 280}, "resolutions": [{"url": "https://external-preview.redd.it/-yNYBZQan_bX_ib0hicVZh-oZA2toK6FAL_z7Nnyu3Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b238931b4e856d220b174fefa496be8e4bb3b95", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-yNYBZQan_bX_ib0hicVZh-oZA2toK6FAL_z7Nnyu3Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4f44ed72251cd37f48d1109c478adb1b6185083", "width": 216, "height": 216}], "variants": {}, "id": "43igTEeQeSnSP0hUUJBkzeC39HdmW4XR0Q23ue_1R20"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xial0", "is_robot_indexable": true, "report_reasons": null, "author": "SeaEngineering9034", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xial0/synthetic_data_challenge_complete_a_simple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xial0/synthetic_data_challenge_complete_a_simple/", "subreddit_subscribers": 915116, "created_utc": 1685627853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently getting my bachelors in stats &amp; computer science and will likely go for an MS in statistics afterwards. I'm pretty decent with software, so I've built targeted crawlers and have a lot of data I'm passionate about for projects. I am very school/career oriented and do wish to be as good as I can be at what I do.\n\nThere's a lot of stuff I've learnt in school, like basic data cleaning &amp; visualisation, that is done so much easier using GPT and its plugins. Rather than fiddling around with ggplot in R, I can use Tableau or Noteable with GPT and get the same results in a fraction of the time. I've got a decent idea of using R or pandas to navigate a data frame, but I can now achieve the same results in natural language in, again, a fraction of the time. I can get GPT to interpret, rename, standardise and clean my data set in 30 seconds.\n\nI can see the value in understanding how things work, but is it actually worth reinventing the wheel? My two concerns would be that my skills may atrophy and that when this suddenly doesn't work for a complex enough problem, I'll be stumped.", "author_fullname": "t2_2tftq9c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To what extent should you reinvent the wheel while learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xes1h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685618019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently getting my bachelors in stats &amp;amp; computer science and will likely go for an MS in statistics afterwards. I&amp;#39;m pretty decent with software, so I&amp;#39;ve built targeted crawlers and have a lot of data I&amp;#39;m passionate about for projects. I am very school/career oriented and do wish to be as good as I can be at what I do.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of stuff I&amp;#39;ve learnt in school, like basic data cleaning &amp;amp; visualisation, that is done so much easier using GPT and its plugins. Rather than fiddling around with ggplot in R, I can use Tableau or Noteable with GPT and get the same results in a fraction of the time. I&amp;#39;ve got a decent idea of using R or pandas to navigate a data frame, but I can now achieve the same results in natural language in, again, a fraction of the time. I can get GPT to interpret, rename, standardise and clean my data set in 30 seconds.&lt;/p&gt;\n\n&lt;p&gt;I can see the value in understanding how things work, but is it actually worth reinventing the wheel? My two concerns would be that my skills may atrophy and that when this suddenly doesn&amp;#39;t work for a complex enough problem, I&amp;#39;ll be stumped.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xes1h", "is_robot_indexable": true, "report_reasons": null, "author": "levaaa_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xes1h/to_what_extent_should_you_reinvent_the_wheel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xes1h/to_what_extent_should_you_reinvent_the_wheel/", "subreddit_subscribers": 915116, "created_utc": 1685618019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Pretty much the title I m final year data Science Student and want to work on new data science projects to gain more experience.\n\nWhere can I find them? Any sources or leads would be really appreciated!", "author_fullname": "t2_usmthp9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I find data science projects to gain more experience.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xecau", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685616624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title I m final year data Science Student and want to work on new data science projects to gain more experience.&lt;/p&gt;\n\n&lt;p&gt;Where can I find them? Any sources or leads would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xecau", "is_robot_indexable": true, "report_reasons": null, "author": "1st_human", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xecau/where_can_i_find_data_science_projects_to_gain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xecau/where_can_i_find_data_science_projects_to_gain/", "subreddit_subscribers": 915116, "created_utc": 1685616624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Test Data Generator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xdyp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_nzubmnn", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "aws", "selftext": "Please check my open source AWS Glue test data generator under aws-samples repository [https://github.com/aws-samples/aws-glue-test-data-generator](https://github.com/aws-samples/aws-glue-test-data-generator)", "author_fullname": "t2_nzubmnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Test Data Generator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wtzcd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "data analytics", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685557679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please check my open source AWS Glue test data generator under aws-samples repository &lt;a href=\"https://github.com/aws-samples/aws-glue-test-data-generator\"&gt;https://github.com/aws-samples/aws-glue-test-data-generator&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?auto=webp&amp;v=enabled&amp;s=2dd94f956b6f06e29510adf23a454a2abf42cb1f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39534ae830646054804b097a7f90ef915f6d4f2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95cabbc0b715cdee8b1396d4196ddb168e217a99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb08a5b4cae1046be6d69cf9a10619cf2925dde4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f42da7929e9b06f5dce82ad0c8ffdef2e7251b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9c1c4d5dd82fda0c3dc6444c859632b9e56194", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d568da4c3b9331327502f8338c0bd7203c0950df", "width": 1080, "height": 540}], "variants": {}, "id": "zVFtZ_jawPVzqOq2YRn7nwlwbYFSj23cWLHXo1eqCwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3fbb2226-250a-11eb-850a-0eeeb4e6614f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13wtzcd", "is_robot_indexable": true, "report_reasons": null, "author": "mbishbeashy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "subreddit_subscribers": 237963, "created_utc": 1685557679.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685615340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?auto=webp&amp;v=enabled&amp;s=2dd94f956b6f06e29510adf23a454a2abf42cb1f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39534ae830646054804b097a7f90ef915f6d4f2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95cabbc0b715cdee8b1396d4196ddb168e217a99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb08a5b4cae1046be6d69cf9a10619cf2925dde4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f42da7929e9b06f5dce82ad0c8ffdef2e7251b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9c1c4d5dd82fda0c3dc6444c859632b9e56194", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d568da4c3b9331327502f8338c0bd7203c0950df", "width": 1080, "height": 540}], "variants": {}, "id": "zVFtZ_jawPVzqOq2YRn7nwlwbYFSj23cWLHXo1eqCwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xdyp1", "is_robot_indexable": true, "report_reasons": null, "author": "mbishbeashy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13wtzcd", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xdyp1/aws_glue_test_data_generator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "subreddit_subscribers": 915116, "created_utc": 1685615340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently got an offer for Amazon as Business analyst intern. Initially I was aiming for Business intelligence engineer intern but at the end only had interviews on BA intern role.\n\nI also had previous experience as a data science intern at another big company.\nSince I heard BA intern in Amazon isn't referred as a technical role, do you guys still recommend me in going? Then try to change into BIE if possible once I got in?\nOr perhaps I should apply again with BIE roles?\n\nI really want to stay in Data science/engineer related field so I'm really struggling on how to make optimal decisions on this.\n\nThanks for reading through!", "author_fullname": "t2_cgtrg91kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I go for Business Analyst Intern at Amazon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xd4xn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685612438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got an offer for Amazon as Business analyst intern. Initially I was aiming for Business intelligence engineer intern but at the end only had interviews on BA intern role.&lt;/p&gt;\n\n&lt;p&gt;I also had previous experience as a data science intern at another big company.\nSince I heard BA intern in Amazon isn&amp;#39;t referred as a technical role, do you guys still recommend me in going? Then try to change into BIE if possible once I got in?\nOr perhaps I should apply again with BIE roles?&lt;/p&gt;\n\n&lt;p&gt;I really want to stay in Data science/engineer related field so I&amp;#39;m really struggling on how to make optimal decisions on this.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading through!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xd4xn", "is_robot_indexable": true, "report_reasons": null, "author": "BerryIceCream1114", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xd4xn/should_i_go_for_business_analyst_intern_at_amazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xd4xn/should_i_go_for_business_analyst_intern_at_amazon/", "subreddit_subscribers": 915116, "created_utc": 1685612438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello! as the title says, i will be entering premed but i have plans of shifting to statistics because i eventually want to work in data science instead of medicine. i'd like to hear your opinions about this (like if you think i'm making the right move in terms of program choice for data science or not).\n\n&amp;#x200B;\n\nbtw i've looked into the school's statistics program and they have subjects like python and i can take a minor in data science if i apply during second year", "author_fullname": "t2_16xuktd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "incoming biology major who wants to shift to statistics because of data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xc6qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685608899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello! as the title says, i will be entering premed but i have plans of shifting to statistics because i eventually want to work in data science instead of medicine. i&amp;#39;d like to hear your opinions about this (like if you think i&amp;#39;m making the right move in terms of program choice for data science or not).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;btw i&amp;#39;ve looked into the school&amp;#39;s statistics program and they have subjects like python and i can take a minor in data science if i apply during second year&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xc6qn", "is_robot_indexable": true, "report_reasons": null, "author": "Bottle_101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xc6qn/incoming_biology_major_who_wants_to_shift_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xc6qn/incoming_biology_major_who_wants_to_shift_to/", "subreddit_subscribers": 915116, "created_utc": 1685608899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, does anyone know of a visualization platform that does a better job than power bi or tableau? There are typical calculations, metrics, and graphs that I use such as: seasonality graphs (x axis: months, legend: days), year on year, month-on-month, rolling averages, year-to-date, etc. would be nice to be able to do such things easily rather than having to add things to the base data or creating new fields / columns. Thank you", "author_fullname": "t2_3auev6d0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Something better than power bi or tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x8t0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685596099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, does anyone know of a visualization platform that does a better job than power bi or tableau? There are typical calculations, metrics, and graphs that I use such as: seasonality graphs (x axis: months, legend: days), year on year, month-on-month, rolling averages, year-to-date, etc. would be nice to be able to do such things easily rather than having to add things to the base data or creating new fields / columns. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x8t0g", "is_robot_indexable": true, "report_reasons": null, "author": "alphamangocat", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x8t0g/something_better_than_power_bi_or_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x8t0g/something_better_than_power_bi_or_tableau/", "subreddit_subscribers": 915116, "created_utc": 1685596099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have an engineering degree in computer science and data science plus a specialised master in computer science. I live in Paris (France) so things might be different than in the US. I did 2 internships as a data scientist but after graduating I was hired by a consulting company to work as a\u2026 technical support analyst.\n\nMy job is basically to enter data in a tool, verify if accounts should be merged, etc by taking requests from the users through an ITSM tool. This is honestly boring but the client company is using me as a free data analyst and making me do many others things (without getting paid for it of course) that are much more interesting. I had the opportunity to participate to an innovation contest and my data science solution got attention from the top management of the company (CEO and VP or a large group). \n\nI feel like I am currently wasting my time but I cannot find any data science position. Recently the client offered to give me a data project manager position that has nothing to do with data science. Should I leave my consulting company for them ? I fear this will not help me land a data science position one day but it is still better than my current job. However they told me I will be in charge of making projects like the one I did for the innovation contest. So aside from my data project manager activities I might be able to make data science using the data of the platform I will be responsible of. The problem is my consulting company does  not seem to try to find a suitable mission for me so I might stay forever on this boring position. What should I do ?", "author_fullname": "t2_cdfyaxay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I quit my job for a new one I am offered ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13x2vux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685578927.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685578626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an engineering degree in computer science and data science plus a specialised master in computer science. I live in Paris (France) so things might be different than in the US. I did 2 internships as a data scientist but after graduating I was hired by a consulting company to work as a\u2026 technical support analyst.&lt;/p&gt;\n\n&lt;p&gt;My job is basically to enter data in a tool, verify if accounts should be merged, etc by taking requests from the users through an ITSM tool. This is honestly boring but the client company is using me as a free data analyst and making me do many others things (without getting paid for it of course) that are much more interesting. I had the opportunity to participate to an innovation contest and my data science solution got attention from the top management of the company (CEO and VP or a large group). &lt;/p&gt;\n\n&lt;p&gt;I feel like I am currently wasting my time but I cannot find any data science position. Recently the client offered to give me a data project manager position that has nothing to do with data science. Should I leave my consulting company for them ? I fear this will not help me land a data science position one day but it is still better than my current job. However they told me I will be in charge of making projects like the one I did for the innovation contest. So aside from my data project manager activities I might be able to make data science using the data of the platform I will be responsible of. The problem is my consulting company does  not seem to try to find a suitable mission for me so I might stay forever on this boring position. What should I do ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13x2vux", "is_robot_indexable": true, "report_reasons": null, "author": "SuccessfulWeb992", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13x2vux/should_i_quit_my_job_for_a_new_one_i_am_offered/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13x2vux/should_i_quit_my_job_for_a_new_one_i_am_offered/", "subreddit_subscribers": 915116, "created_utc": 1685578626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been informed that projects include, Markeing Mix Modeling and using machine learning. How should I prepare for this?", "author_fullname": "t2_47f0qg1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should I be expected to know / expect to do in a data science internship for a marketing company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wvpz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685561753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been informed that projects include, Markeing Mix Modeling and using machine learning. How should I prepare for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wvpz0", "is_robot_indexable": true, "report_reasons": null, "author": "IcyTitle1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wvpz0/what_should_i_be_expected_to_know_expect_to_do_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wvpz0/what_should_i_be_expected_to_know_expect_to_do_in/", "subreddit_subscribers": 915116, "created_utc": 1685561753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say you'd like to analyze behavior of users of an e-commerce shop. There are millions of daily active users. Given the compute power at hand, you have two options (or may be more?). First is to  take a small time period, say a week, and base your analysis on this one week for all users. Second is to take a much longer period, say a year, but choosing a smaller number of users. I understand that there are pros and cons to each method. But I would like to know what are the things that you take into account when making a choice.", "author_fullname": "t2_4oockqg5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Subsampling: small time period or sparse sampling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wvlzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685561492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say you&amp;#39;d like to analyze behavior of users of an e-commerce shop. There are millions of daily active users. Given the compute power at hand, you have two options (or may be more?). First is to  take a small time period, say a week, and base your analysis on this one week for all users. Second is to take a much longer period, say a year, but choosing a smaller number of users. I understand that there are pros and cons to each method. But I would like to know what are the things that you take into account when making a choice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13wvlzr", "is_robot_indexable": true, "report_reasons": null, "author": "furioncruz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13wvlzr/subsampling_small_time_period_or_sparse_sampling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13wvlzr/subsampling_small_time_period_or_sparse_sampling/", "subreddit_subscribers": 915116, "created_utc": 1685561492.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}