{"kind": "Listing", "data": {"after": "t3_144z8n7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm applying for some hiring processes for a machine learning engineer role.\n\nWhen I have the interview, I always try to ask:\n\n\\- How many senior MLE/DS do you have?\n\n\\- Which business problems do you want to solve?\n\n\\- How many models do you currently have in production?\n\n\\- What's the level of MLOps your company is at today?", "author_fullname": "t2_w7ap5hsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find red flags in the interview for machine learning engineer (or data science) role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1455mm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 125, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 125, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686318157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m applying for some hiring processes for a machine learning engineer role.&lt;/p&gt;\n\n&lt;p&gt;When I have the interview, I always try to ask:&lt;/p&gt;\n\n&lt;p&gt;- How many senior MLE/DS do you have?&lt;/p&gt;\n\n&lt;p&gt;- Which business problems do you want to solve?&lt;/p&gt;\n\n&lt;p&gt;- How many models do you currently have in production?&lt;/p&gt;\n\n&lt;p&gt;- What&amp;#39;s the level of MLOps your company is at today?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1455mm2", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Standard175", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1455mm2/how_to_find_red_flags_in_the_interview_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1455mm2/how_to_find_red_flags_in_the_interview_for/", "subreddit_subscribers": 921631, "created_utc": 1686318157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently aspiring to work in data analytics. I have a huge passion for it and I won\u2019t be giving up.\n\nBut I somehow ended on that subreddit and geez has it caused massive anxiety. So called \u201cdata scientists\u201d and \u201cengineers\u201d predicting AI to cause mass unemployment.\n\nI wanted to ask actual professionals in a dedicated subreddit, do you all believe that AI will perhaps not eliminate jobs, but significantly reduce open positions, at leasts for DAs?", "author_fullname": "t2_4soo46eq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone ever taken a look at the singularity subreddit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_144skm3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686277236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently aspiring to work in data analytics. I have a huge passion for it and I won\u2019t be giving up.&lt;/p&gt;\n\n&lt;p&gt;But I somehow ended on that subreddit and geez has it caused massive anxiety. So called \u201cdata scientists\u201d and \u201cengineers\u201d predicting AI to cause mass unemployment.&lt;/p&gt;\n\n&lt;p&gt;I wanted to ask actual professionals in a dedicated subreddit, do you all believe that AI will perhaps not eliminate jobs, but significantly reduce open positions, at leasts for DAs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "144skm3", "is_robot_indexable": true, "report_reasons": null, "author": "cam171811", "discussion_type": null, "num_comments": 113, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/144skm3/has_anyone_ever_taken_a_look_at_the_singularity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/144skm3/has_anyone_ever_taken_a_look_at_the_singularity/", "subreddit_subscribers": 921631, "created_utc": 1686277236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this is odd to post here - I completed 11 out of 12 courses for my MSDS at Northwestern and just felt like the program was extremely lackluster. The required courses in management rather than the technicals. It was 55k and it would have been obvious to transfer quickly to OMSA or the newer programs.The landscape looked different when I was applying for programs, and I was initially skeptical of entirely MOOC based programs. However, I ended up just watching YT videos as my lectures anyway.\n\nI would just like to warn others when deciding whether or not to go back to school. I\u2019m still taking time to patch up on knowledge that I felt like I did not gain via the program. Although with that being said, that would be the case with any masters program. I am almost considering not even doing the last capstone just because I know that there are other things that I would rather learn.\n\nI literally just have the capstone left but I am almost considering just letting it go", "author_fullname": "t2_35qsk3el", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Off my chest: No need for costly masters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145fo6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686356525.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686342059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is odd to post here - I completed 11 out of 12 courses for my MSDS at Northwestern and just felt like the program was extremely lackluster. The required courses in management rather than the technicals. It was 55k and it would have been obvious to transfer quickly to OMSA or the newer programs.The landscape looked different when I was applying for programs, and I was initially skeptical of entirely MOOC based programs. However, I ended up just watching YT videos as my lectures anyway.&lt;/p&gt;\n\n&lt;p&gt;I would just like to warn others when deciding whether or not to go back to school. I\u2019m still taking time to patch up on knowledge that I felt like I did not gain via the program. Although with that being said, that would be the case with any masters program. I am almost considering not even doing the last capstone just because I know that there are other things that I would rather learn.&lt;/p&gt;\n\n&lt;p&gt;I literally just have the capstone left but I am almost considering just letting it go&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145fo6w", "is_robot_indexable": true, "report_reasons": null, "author": "peachyjiang", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145fo6w/off_my_chest_no_need_for_costly_masters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145fo6w/off_my_chest_no_need_for_costly_masters/", "subreddit_subscribers": 921631, "created_utc": 1686342059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Teaching DataViz to kids via Board Games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_145d7r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_51o3wf0o", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/85BRd3d4PsXPnzvB0yCnfyt467HKEfL53NuS5MbknEU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataisbeautiful", "selftext": "", "author_fullname": "t2_51o3wf0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Teaching DataViz to kids via Board Games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataisbeautiful", "hidden": false, "pwls": 6, "link_flair_css_class": "oc", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_144gxzk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "1c7d62a6-099d-11e7-9b3c-0ee50bfd7a4c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OC", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/85BRd3d4PsXPnzvB0yCnfyt467HKEfL53NuS5MbknEU.jpg", "edited": false, "author_flair_css_class": "ocmaker", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1686248807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bxaaztw87u4b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?auto=webp&amp;v=enabled&amp;s=496ac0bb9575ca95229257a777fd1ce94900f593", "width": 720, "height": 540}, "resolutions": [{"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11d643590fc8f6d02c76e0865c2f60a1b6d596e3", "width": 108, "height": 81}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=615653e24d163ceb024b6456c7a7f67b1ec01130", "width": 216, "height": 162}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4e4a4953c341c8ba247a233877864ee4c3aa356", "width": 320, "height": 240}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4b9c83630fdc1ec7e0ea1a5febd8ba3b81987a9", "width": 640, "height": 480}], "variants": {}, "id": "nPqUNFFdipGnezYZE44prAzG_4rtsYukP-D_eWwmj08"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OC: 11", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2tk95", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "144gxzk", "is_robot_indexable": true, "report_reasons": null, "author": "DataVizzdom", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataisbeautiful/comments/144gxzk/oc_teaching_dataviz_to_kids_via_board_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bxaaztw87u4b1.jpg", "subreddit_subscribers": 19642075, "created_utc": 1686248807.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1686336122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bxaaztw87u4b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?auto=webp&amp;v=enabled&amp;s=496ac0bb9575ca95229257a777fd1ce94900f593", "width": 720, "height": 540}, "resolutions": [{"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11d643590fc8f6d02c76e0865c2f60a1b6d596e3", "width": 108, "height": 81}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=615653e24d163ceb024b6456c7a7f67b1ec01130", "width": 216, "height": 162}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4e4a4953c341c8ba247a233877864ee4c3aa356", "width": 320, "height": 240}, {"url": "https://preview.redd.it/bxaaztw87u4b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4b9c83630fdc1ec7e0ea1a5febd8ba3b81987a9", "width": 640, "height": 480}], "variants": {}, "id": "nPqUNFFdipGnezYZE44prAzG_4rtsYukP-D_eWwmj08"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145d7r5", "is_robot_indexable": true, "report_reasons": null, "author": "DataVizzdom", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_144gxzk", "author_flair_text_color": null, "permalink": "/r/datascience/comments/145d7r5/oc_teaching_dataviz_to_kids_via_board_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bxaaztw87u4b1.jpg", "subreddit_subscribers": 921631, "created_utc": 1686336122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used chatGPT to create a comprehensive list of 99 projects taking one from a beginner to expert level in Data Science.\n\nThese projects cover both key ML techniques and underappreciated technical skills, from basic code structuring to advanced deep learning.\n\nAs I progress, I'll be sharing my work here for us to discuss, learn, and grow together.\n\nCurious? Want to start your own journey? Here's the prompt I used:\n\n\"I am interested in {insert\\_topic\\_here}. List data science projects from beginner to expert that include AI or generative AI. Use a table format with columns - Name, Topic, Difficulty, Data Science/ML Technique, and a Description.\"\n\nMy first project is a recipe recommendation model. I'm focusing on Github repository setup, version control best practices, and project planning.\n\nStay tuned for more updates and happy learning!", "author_fullname": "t2_qyfyulzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embarking on a Journey of 99 Data Science Projects - From Beginner to Expert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145c4ap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686333520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used chatGPT to create a comprehensive list of 99 projects taking one from a beginner to expert level in Data Science.&lt;/p&gt;\n\n&lt;p&gt;These projects cover both key ML techniques and underappreciated technical skills, from basic code structuring to advanced deep learning.&lt;/p&gt;\n\n&lt;p&gt;As I progress, I&amp;#39;ll be sharing my work here for us to discuss, learn, and grow together.&lt;/p&gt;\n\n&lt;p&gt;Curious? Want to start your own journey? Here&amp;#39;s the prompt I used:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;I am interested in {insert_topic_here}. List data science projects from beginner to expert that include AI or generative AI. Use a table format with columns - Name, Topic, Difficulty, Data Science/ML Technique, and a Description.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;My first project is a recipe recommendation model. I&amp;#39;m focusing on Github repository setup, version control best practices, and project planning.&lt;/p&gt;\n\n&lt;p&gt;Stay tuned for more updates and happy learning!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145c4ap", "is_robot_indexable": true, "report_reasons": null, "author": "Front_Newspaper3600", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145c4ap/embarking_on_a_journey_of_99_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145c4ap/embarking_on_a_journey_of_99_data_science/", "subreddit_subscribers": 921631, "created_utc": 1686333520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there specific skills? Or is it just the same as everywhere else?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist who are good at office politics, how did you increase your political skill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145kh8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686353823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there specific skills? Or is it just the same as everywhere else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145kh8b", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145kh8b/data_scientist_who_are_good_at_office_politics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145kh8b/data_scientist_who_are_good_at_office_politics/", "subreddit_subscribers": 921631, "created_utc": 1686353823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing SlimPajama-627B: the largest extensively deduplicated, multi-corpora, open-source dataset for training large language models.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145gqcx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_voqxwypq", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LanguageTechnology", "selftext": "SlimPajama cleans and deduplicates RedPajama-1T, reducing the total token count and file size by 50%. It's half the size and trains twice as fast!\n\nIt\u2019s the highest quality dataset when training to 600B tokens and, when upsampled, performs equal or better than RedPajama.  It was no mean feat to deduplicate data on this scale \u2013 existing tools do not scale to a trillion tokens. We built a custom parallel data pre-processing pipeline and are sharing the code open source with the community.\n\nWe\u2019d like to thank our partner Opentensor for supporting this project. And credit goes to Together Compute and the entire team that created the RedPajama dataset!\n\n&amp;#x200B;\n\n* SlimPajama dataset - [https://huggingface.co/datasets/cerebras/SlimPajama-627B](https://huggingface.co/datasets/cerebras/SlimPajama-627B)\n* Libraries for data pre-processing - [https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data\\_processing/slimpajama](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data_processing/slimpajama)\n* Read our blog - [https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama](https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama)", "author_fullname": "t2_voqxwypq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing SlimPajama-627B: the largest extensively deduplicated, multi-corpora, open-source dataset for training large language models.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LanguageTechnology", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145gowe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686356247.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686344467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LanguageTechnology", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SlimPajama cleans and deduplicates RedPajama-1T, reducing the total token count and file size by 50%. It&amp;#39;s half the size and trains twice as fast!&lt;/p&gt;\n\n&lt;p&gt;It\u2019s the highest quality dataset when training to 600B tokens and, when upsampled, performs equal or better than RedPajama.  It was no mean feat to deduplicate data on this scale \u2013 existing tools do not scale to a trillion tokens. We built a custom parallel data pre-processing pipeline and are sharing the code open source with the community.&lt;/p&gt;\n\n&lt;p&gt;We\u2019d like to thank our partner Opentensor for supporting this project. And credit goes to Together Compute and the entire team that created the RedPajama dataset!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SlimPajama dataset - &lt;a href=\"https://huggingface.co/datasets/cerebras/SlimPajama-627B\"&gt;https://huggingface.co/datasets/cerebras/SlimPajama-627B&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Libraries for data pre-processing - &lt;a href=\"https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data_processing/slimpajama\"&gt;https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data_processing/slimpajama&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Read our blog - &lt;a href=\"https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama\"&gt;https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?auto=webp&amp;v=enabled&amp;s=a583c96a3aca547884f7609054ef900ea6e1b937", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ffa89dc772d5b0c5c209fe190156897d3bf3ab93", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e4f4987b044c263bd6abf9f14b3897f11eceedb", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=292e53558b985987a9004fa3c28fa47da1c1f2b9", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ccb4c70274741ca419e6fa85f5a4ed3c30f3cf2", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8328eb49c040bcae227faa60bf28f84f705cc4a0", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aae668a15dd053f27c3c00579ccf95137d96a1c", "width": 1080, "height": 583}], "variants": {}, "id": "qZu7xwSlcLKCNhCBJSU5hdBnG2HpXv6XxLw_0LnqVnA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rkr2", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145gowe", "is_robot_indexable": true, "report_reasons": null, "author": "CS-fan-101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/LanguageTechnology/comments/145gowe/introducing_slimpajama627b_the_largest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/LanguageTechnology/comments/145gowe/introducing_slimpajama627b_the_largest/", "subreddit_subscribers": 42634, "created_utc": 1686344467.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1686344549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.LanguageTechnology", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/LanguageTechnology/comments/145gowe/introducing_slimpajama627b_the_largest/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?auto=webp&amp;v=enabled&amp;s=a583c96a3aca547884f7609054ef900ea6e1b937", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ffa89dc772d5b0c5c209fe190156897d3bf3ab93", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e4f4987b044c263bd6abf9f14b3897f11eceedb", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=292e53558b985987a9004fa3c28fa47da1c1f2b9", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ccb4c70274741ca419e6fa85f5a4ed3c30f3cf2", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8328eb49c040bcae227faa60bf28f84f705cc4a0", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/e1NAAte95XVh6EVzu0k_0u2uONi5Ztr5_Gn6Gwul7Lk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6aae668a15dd053f27c3c00579ccf95137d96a1c", "width": 1080, "height": 583}], "variants": {}, "id": "qZu7xwSlcLKCNhCBJSU5hdBnG2HpXv6XxLw_0LnqVnA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145gqcx", "is_robot_indexable": true, "report_reasons": null, "author": "CS-fan-101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_145gowe", "author_flair_text_color": null, "permalink": "/r/datascience/comments/145gqcx/introducing_slimpajama627b_the_largest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/LanguageTechnology/comments/145gowe/introducing_slimpajama627b_the_largest/", "subreddit_subscribers": 921631, "created_utc": 1686344549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The way edtech Industry is booming right now makes me wonder about various applications of data science in this field. Anyone working in/with this industry, can you please share some insights what problems you faced, how you solved/tackled it, and what are the problems you are still facing?", "author_fullname": "t2_3wr0pzmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Edtech Industry Challenges", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1452gmm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686309411.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The way edtech Industry is booming right now makes me wonder about various applications of data science in this field. Anyone working in/with this industry, can you please share some insights what problems you faced, how you solved/tackled it, and what are the problems you are still facing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1452gmm", "is_robot_indexable": true, "report_reasons": null, "author": "sARUcasm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1452gmm/edtech_industry_challenges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1452gmm/edtech_industry_challenges/", "subreddit_subscribers": 921631, "created_utc": 1686309411.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone have experience interviewing at cruise? Specifically looking for experience with the live python coding piece. I have plenty of experience, just looking for resources or level of difficulty so I can study properly. Gracias fam!", "author_fullname": "t2_9d3tunn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cruise python technical interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145goxl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686344469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience interviewing at cruise? Specifically looking for experience with the live python coding piece. I have plenty of experience, just looking for resources or level of difficulty so I can study properly. Gracias fam!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145goxl", "is_robot_indexable": true, "report_reasons": null, "author": "IllPoem4426", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145goxl/cruise_python_technical_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145goxl/cruise_python_technical_interview/", "subreddit_subscribers": 921631, "created_utc": 1686344469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering if there was a good way to simulate sales data (like for a retail store or a restaurant) that could be analyzed for how time of day/season/etc affects what is sold\n\n(Alternatively, are there any companies that happen to share this info online? I assume not but worth a shot haha)", "author_fullname": "t2_bxa84d34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simulating sales data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145fptb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686342168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if there was a good way to simulate sales data (like for a retail store or a restaurant) that could be analyzed for how time of day/season/etc affects what is sold&lt;/p&gt;\n\n&lt;p&gt;(Alternatively, are there any companies that happen to share this info online? I assume not but worth a shot haha)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145fptb", "is_robot_indexable": true, "report_reasons": null, "author": "_new_name_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145fptb/simulating_sales_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145fptb/simulating_sales_data/", "subreddit_subscribers": 921631, "created_utc": 1686342168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello Xgboost gurus,\n\nDoes label encoding categorical features affect xgboost in anyway? My fear is that it would introduce some ordinality in the data and affect predictions. \n\nThe documentation suggests this and for categories with very high cardinality they suggest using techniques like Hash encoding.", "author_fullname": "t2_9atv3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Label Encoding for categorical columns - xgboost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145d04o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686335618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Xgboost gurus,&lt;/p&gt;\n\n&lt;p&gt;Does label encoding categorical features affect xgboost in anyway? My fear is that it would introduce some ordinality in the data and affect predictions. &lt;/p&gt;\n\n&lt;p&gt;The documentation suggests this and for categories with very high cardinality they suggest using techniques like Hash encoding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145d04o", "is_robot_indexable": true, "report_reasons": null, "author": "longgamma", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145d04o/label_encoding_for_categorical_columns_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145d04o/label_encoding_for_categorical_columns_xgboost/", "subreddit_subscribers": 921631, "created_utc": 1686335618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I found the model weight to a machine learning problem in the tar file but I need it in an h5 file format. What do I do? I only use TensorFlow. I'm unfamiliar with Pytorch, but the person wrote their model in Pytorch. Thanks for any help in advance.", "author_fullname": "t2_n76zm04c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tar file to h5 file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_145lz0q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686357883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found the model weight to a machine learning problem in the tar file but I need it in an h5 file format. What do I do? I only use TensorFlow. I&amp;#39;m unfamiliar with Pytorch, but the person wrote their model in Pytorch. Thanks for any help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145lz0q", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy-Currency-8127", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145lz0q/tar_file_to_h5_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145lz0q/tar_file_to_h5_file/", "subreddit_subscribers": 921631, "created_utc": 1686357883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have an interview coming up for a jr level position, can anyone recommend some resources to freshen up on basic probability theory / statistical methods?", "author_fullname": "t2_6htadx20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic probability theory resource", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145iahj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686348266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have an interview coming up for a jr level position, can anyone recommend some resources to freshen up on basic probability theory / statistical methods?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145iahj", "is_robot_indexable": true, "report_reasons": null, "author": "jannsbababa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145iahj/basic_probability_theory_resource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145iahj/basic_probability_theory_resource/", "subreddit_subscribers": 921631, "created_utc": 1686348266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is anyone able to comment if there are any red flags for [AIcore](https://www.theaicore.com/course)?", "author_fullname": "t2_7bl8nnsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AICore course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145ghzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686344003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone able to comment if there are any red flags for &lt;a href=\"https://www.theaicore.com/course\"&gt;AIcore&lt;/a&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?auto=webp&amp;v=enabled&amp;s=3ab8f6c55f8169f099c9cc9308a087aa25858e89", "width": 1240, "height": 610}, "resolutions": [{"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1095eb71deeaa13cf7603a78c86e3034295dfb61", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d17b8525e3bba5f66e42686a9abecf3dfb7bc824", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd7ae13ce5fa5bb9a1a6f83a91bc0531078aaa0d", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=910665178816e0b0b4d7ea9b5835b312c727f276", "width": 640, "height": 314}, {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24cede66d8db04c693ebaa4ba77319ff422a363b", "width": 960, "height": 472}, {"url": "https://external-preview.redd.it/T5PjxVtJ5fLnVD-lien7olOz1fn0VjRvL2C1E3GWp24.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1aa45b409bf9b4efc388c93ba78e100520da238b", "width": 1080, "height": 531}], "variants": {}, "id": "qBElg6l4Bmzpo_AONeuGwPp4lJLqCIF5bvY1xq4O4h8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145ghzi", "is_robot_indexable": true, "report_reasons": null, "author": "Q7893", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145ghzi/aicore_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145ghzi/aicore_course/", "subreddit_subscribers": 921631, "created_utc": 1686344003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ajskcqg7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitHub - H4NM/Groppy: Facilitating regex creation and deploying custom grok patterns in an ELK environment \ud83e\udd8c\ud83d\udcdc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_145gd6z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ye34yg6kbY7LbF7SF6nWRaiqYevZUoJaQ-qiRvUiqQQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686343690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/H4NM/Groppy", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?auto=webp&amp;v=enabled&amp;s=47a883acbbc6cfcb1ad03b617ff5d6148b9c03b4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=137f09c0b56404e7391a3e00960672e44546f560", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2192a1761052879ed3d684097620f0c931bfa269", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0284861e9739b5324448a15e56c9d35e9cb8a51", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2b106400924e31522dc736e5ac00dc2df536aca", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=343d458647e02212080ae14aaca929dcf05e0cd8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/H8Z38UsjEOniTS-CeIOYGPT41km18oxXPhS3_RoKovA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57cf8c00930eaa4468530c17c02e73206f7da4fa", "width": 1080, "height": 540}], "variants": {}, "id": "sXOGV_7LAGwkwaJUdEH5X0q6us7QJfYTKogbfMSh8EM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "145gd6z", "is_robot_indexable": true, "report_reasons": null, "author": "73637269707420", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145gd6z/github_h4nmgroppy_facilitating_regex_creation_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/H4NM/Groppy", "subreddit_subscribers": 921631, "created_utc": 1686343690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate data extraction using custom trained AI models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145b16s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_32tnavmg", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_UBIAI", "selftext": " \n\nIf you're a financial professional and you're tired of manual data entry from bank statements, we highly recommend reading this article on how to automate data extraction using custom trained AI models. \ud83d\udc47\n\nData is growing at an unprecedented rate, and automating data extraction is crucial for maintaining efficiency and accuracy in financial transactions. With manual data entry becoming increasingly inefficient, the use of AI technology has become a game-changer. \ud83d\udcaa\ud83d\udcbb\n\nIn this article, you'll learn how to automate data extraction from bank statements using custom trained AI models and automated table extraction. It also covers the process of table extraction, training AI models for information extraction, and creating custom workflows with the new AI Builder. \u2699\ufe0f\ud83d\udca1\n\nSo if you want to increase efficiency in handling bank statements, don't miss out on the transformative potential of AI technology in the financial industry. Read the full article here: \\[[https://walidamamou.medium.com/how-to-automate-data-extraction-from-bank-statements-572c0147654](https://walidamamou.medium.com/how-to-automate-data-extraction-from-bank-statements-572c0147654) \\] \ud83d\udcda\ud83d\udd17\n\n\\#FinancialAutomation #DataExtractionSolutions #AIinFinance #StreamlineProcesses #EfficientBanking #AutomatedWorkflows #TechInFinance #DigitalTransformation #FinancialProductivity #AIAdvancements", "author_fullname": "t2_32tnavmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate data extraction using custom trained AI models", "link_flair_richtext": [], "subreddit_name_prefixed": "u/UBIAI", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ww4zy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685562740.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re a financial professional and you&amp;#39;re tired of manual data entry from bank statements, we highly recommend reading this article on how to automate data extraction using custom trained AI models. \ud83d\udc47&lt;/p&gt;\n\n&lt;p&gt;Data is growing at an unprecedented rate, and automating data extraction is crucial for maintaining efficiency and accuracy in financial transactions. With manual data entry becoming increasingly inefficient, the use of AI technology has become a game-changer. \ud83d\udcaa\ud83d\udcbb&lt;/p&gt;\n\n&lt;p&gt;In this article, you&amp;#39;ll learn how to automate data extraction from bank statements using custom trained AI models and automated table extraction. It also covers the process of table extraction, training AI models for information extraction, and creating custom workflows with the new AI Builder. \u2699\ufe0f\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;So if you want to increase efficiency in handling bank statements, don&amp;#39;t miss out on the transformative potential of AI technology in the financial industry. Read the full article here: [&lt;a href=\"https://walidamamou.medium.com/how-to-automate-data-extraction-from-bank-statements-572c0147654\"&gt;https://walidamamou.medium.com/how-to-automate-data-extraction-from-bank-statements-572c0147654&lt;/a&gt; ] \ud83d\udcda\ud83d\udd17&lt;/p&gt;\n\n&lt;p&gt;#FinancialAutomation #DataExtractionSolutions #AIinFinance #StreamlineProcesses #EfficientBanking #AutomatedWorkflows #TechInFinance #DigitalTransformation #FinancialProductivity #AIAdvancements&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?auto=webp&amp;v=enabled&amp;s=9f0d6ddd7478695375bd3e670b58144bfd56e75a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b81999850d1b44619eaedec121806f9f984356b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b79cee30d0c2e1b0fdfeef6e84be55399188215e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6de3eb168e3bfa0ebea944d7c6afda05bf8e0494", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a422eaaa6dc866c8dc0244218508d07d080e1cb9", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72893e6a4300e60cca9c9bca7319be28290cea22", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab102a533234a4e1fe8f1a05986296ad9c037cfb", "width": 1080, "height": 720}], "variants": {}, "id": "7P_tY0x1uaRvOwBIKSy9n_H5V6Onw1hTKj1Xb5EaQnc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2lnnxo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13ww4zy", "is_robot_indexable": true, "report_reasons": null, "author": "UBIAI", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_UBIAI/comments/13ww4zy/how_to_automate_data_extraction_using_custom/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_UBIAI/comments/13ww4zy/how_to_automate_data_extraction_using_custom/", "subreddit_subscribers": 0, "created_utc": 1685562740.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1686330909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.UBIAI", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/user/UBIAI/comments/13ww4zy/how_to_automate_data_extraction_using_custom/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?auto=webp&amp;v=enabled&amp;s=9f0d6ddd7478695375bd3e670b58144bfd56e75a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b81999850d1b44619eaedec121806f9f984356b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b79cee30d0c2e1b0fdfeef6e84be55399188215e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6de3eb168e3bfa0ebea944d7c6afda05bf8e0494", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a422eaaa6dc866c8dc0244218508d07d080e1cb9", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72893e6a4300e60cca9c9bca7319be28290cea22", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/kJkEQfF7QKjFU8jyLMMNK0klvtl-h7ATXPmHGXDHW4k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab102a533234a4e1fe8f1a05986296ad9c037cfb", "width": 1080, "height": 720}], "variants": {}, "id": "7P_tY0x1uaRvOwBIKSy9n_H5V6Onw1hTKj1Xb5EaQnc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145b16s", "is_robot_indexable": true, "report_reasons": null, "author": "UBIAI", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13ww4zy", "author_flair_text_color": null, "permalink": "/r/datascience/comments/145b16s/how_to_automate_data_extraction_using_custom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/user/UBIAI/comments/13ww4zy/how_to_automate_data_extraction_using_custom/", "subreddit_subscribers": 921631, "created_utc": 1686330909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I upgraded my Golang code today to support combine queries such as Filter and GroupBy. Based on the benchmarking I did on May 30, 23, I was able to reduce the total processing time from 144s to 30s. However, I know that if I split the 300 million-row file into 3,000 files with 100,000 rows each, the fastest time I recorded for DuckDB is only 22s while a single 300 million-row file takes 65s.\n\nDuckDB recorded this 22s is potentially faster than Peaks, but Peaks has not yet to upgrade its streaming engine to support many files scenario. This is my next exercise how to outperform DuckDB again.\n\n[Revised Benchmarking @ Jun 9, 23](https://youtu.be/ctxX1O1-OKk)  \n[Original Benchmarking @ May 30, 23](https://youtu.be/zVR77B2bDR0)", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combine Filter and GroupBy in Single Function() Can Reduce Memory Usage Fundamentally", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1458knr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686325214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I upgraded my Golang code today to support combine queries such as Filter and GroupBy. Based on the benchmarking I did on May 30, 23, I was able to reduce the total processing time from 144s to 30s. However, I know that if I split the 300 million-row file into 3,000 files with 100,000 rows each, the fastest time I recorded for DuckDB is only 22s while a single 300 million-row file takes 65s.&lt;/p&gt;\n\n&lt;p&gt;DuckDB recorded this 22s is potentially faster than Peaks, but Peaks has not yet to upgrade its streaming engine to support many files scenario. This is my next exercise how to outperform DuckDB again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/ctxX1O1-OKk\"&gt;Revised Benchmarking @ Jun 9, 23&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://youtu.be/zVR77B2bDR0\"&gt;Original Benchmarking @ May 30, 23&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0Fuz1LgdO4GauHWZAao_U7v96oaD4x7346yC8vglnOA.jpg?auto=webp&amp;v=enabled&amp;s=0d90056a1583923896a2af6d2f42f965ef3f8bf7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/0Fuz1LgdO4GauHWZAao_U7v96oaD4x7346yC8vglnOA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4595a9e7c2328680ed3a5cd6dfa5fa556007f473", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/0Fuz1LgdO4GauHWZAao_U7v96oaD4x7346yC8vglnOA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=898781fef57ad85631369e4dc0337b930ad80ff9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/0Fuz1LgdO4GauHWZAao_U7v96oaD4x7346yC8vglnOA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b9835729c66f4ddebce5fff7db62f6506b529b5", "width": 320, "height": 240}], "variants": {}, "id": "GIFcGnhNsYS_byBMSvPaJXHVEwAseb-bM62KpvnvFvY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1458knr", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1458knr/combine_filter_and_groupby_in_single_function_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1458knr/combine_filter_and_groupby_in_single_function_can/", "subreddit_subscribers": 921631, "created_utc": 1686325214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI hope you're all having a great day! I have a few questions regarding a potential career transition to a Data Analyst role, and I would appreciate your insights and advice.  \n\n\n**Background**: Currently working as a Project Coordinator/HR Coordinator, I'm drawn to the idea of being able to gather and process data on a topic of interest, deriving meaningful conclusions and answers to questions. I'm considering a self-learning journey to transition into a Data Analyst role. I am a middle age man and have to take this decision seriously to avoid negative consequences. However, I am not happy with my current situation, hence I am looking for a career change. \n\n**Concern**:  I must admit that I lack confidence in my math + stats skills. While I did reasonably well in school, I haven't pursued math outside of the classroom and my degree is not science-related. I do not remember anything either, hence I will need to study any necessary knowledge from scratch.\n\n**Question** 1: How much math knowledge is required for a Data Analyst role compared to a Data Scientist role? What specific areas of math should I focus on for data analysis?\n\n**Question** 2: Given my background, is it realistic for me to self-study on weekends and successfully make a long-term transition? My aim is not just to land an entry-level job, but to establish a fulfilling career. I'm aware that learning SQL, Excel at an advanced level, and PowerBI would be essential for entry-level positions and I feel confident in that. I want to know how my math concerns play into that long-term. \n\n**Question** 3: Is it common for individuals to work as Data Analysts exclusively in the long term? I'm curious about the career prospects and potential earning growth for someone who prefers to stay in a Data Analyst role rather than pursuing more math-heavy positions within the field. I would not like to invest time and effort to become an analyst just to find out I need to change careers 5 years later due to limited earning potential. I want to stick to the analyst role for two reasons: math and the fact that from all my research analysts do what interests me (gather and processing data to answers questions to support decision makers). \n\n  \nI genuinely appreciate your time in reading my post and would be grateful for any advice or insights you can provide. Thank you in advance, and I'm looking forward to your responses!", "author_fullname": "t2_vlvj3cxu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Change - Seeking Advice &amp; can you be Data Analyst period, no progression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1453uib", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686313545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all having a great day! I have a few questions regarding a potential career transition to a Data Analyst role, and I would appreciate your insights and advice.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;: Currently working as a Project Coordinator/HR Coordinator, I&amp;#39;m drawn to the idea of being able to gather and process data on a topic of interest, deriving meaningful conclusions and answers to questions. I&amp;#39;m considering a self-learning journey to transition into a Data Analyst role. I am a middle age man and have to take this decision seriously to avoid negative consequences. However, I am not happy with my current situation, hence I am looking for a career change. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Concern&lt;/strong&gt;:  I must admit that I lack confidence in my math + stats skills. While I did reasonably well in school, I haven&amp;#39;t pursued math outside of the classroom and my degree is not science-related. I do not remember anything either, hence I will need to study any necessary knowledge from scratch.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt; 1: How much math knowledge is required for a Data Analyst role compared to a Data Scientist role? What specific areas of math should I focus on for data analysis?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt; 2: Given my background, is it realistic for me to self-study on weekends and successfully make a long-term transition? My aim is not just to land an entry-level job, but to establish a fulfilling career. I&amp;#39;m aware that learning SQL, Excel at an advanced level, and PowerBI would be essential for entry-level positions and I feel confident in that. I want to know how my math concerns play into that long-term. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt; 3: Is it common for individuals to work as Data Analysts exclusively in the long term? I&amp;#39;m curious about the career prospects and potential earning growth for someone who prefers to stay in a Data Analyst role rather than pursuing more math-heavy positions within the field. I would not like to invest time and effort to become an analyst just to find out I need to change careers 5 years later due to limited earning potential. I want to stick to the analyst role for two reasons: math and the fact that from all my research analysts do what interests me (gather and processing data to answers questions to support decision makers). &lt;/p&gt;\n\n&lt;p&gt;I genuinely appreciate your time in reading my post and would be grateful for any advice or insights you can provide. Thank you in advance, and I&amp;#39;m looking forward to your responses!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1453uib", "is_robot_indexable": true, "report_reasons": null, "author": "Monkey_Junkie_No1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1453uib/career_change_seeking_advice_can_you_be_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1453uib/career_change_seeking_advice_can_you_be_data/", "subreddit_subscribers": 921631, "created_utc": 1686313545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello\n\nI'm working on a chatbot that needs to answer questions based on a knowledge base. The chatbot should not answer questions that are not in the knowledge base. \n\nI was thinking of achieving this using ChatGPT and was trying to control the output of ChatGPT using prompting techniques. I have tried the following prompt but it seems it doesn't completely do what I want. Any advice/experience on how to achieve this?\n\n    You should answer questions based on the following facts. If the question is not related to the fact just say \"I don't know\".\n    \n    facts:\n    1. ...\n    2. ...\n    3. ...\n    end", "author_fullname": "t2_4so001i6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to limit answers of ChatGPT to a knowledge base", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1451s1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686307249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a chatbot that needs to answer questions based on a knowledge base. The chatbot should not answer questions that are not in the knowledge base. &lt;/p&gt;\n\n&lt;p&gt;I was thinking of achieving this using ChatGPT and was trying to control the output of ChatGPT using prompting techniques. I have tried the following prompt but it seems it doesn&amp;#39;t completely do what I want. Any advice/experience on how to achieve this?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;You should answer questions based on the following facts. If the question is not related to the fact just say &amp;quot;I don&amp;#39;t know&amp;quot;.\n\nfacts:\n1. ...\n2. ...\n3. ...\nend\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1451s1d", "is_robot_indexable": true, "report_reasons": null, "author": "engmrgh", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1451s1d/how_to_limit_answers_of_chatgpt_to_a_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1451s1d/how_to_limit_answers_of_chatgpt_to_a_knowledge/", "subreddit_subscribers": 921631, "created_utc": 1686307249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Consider support teams as Fraud Team or BI team in an org VS primary team or money making team as acquisition. Above are just examples, you can elaborate based on experience in either teams.\nWhich one pays more?\nJob hopping is easier for which team member?\nLayoffs affect ____ team more?\nWhich one would you prefer to be a part of and why?", "author_fullname": "t2_a0h39pj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Primary vs Support team. Which is better for career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145etjq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686339974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consider support teams as Fraud Team or BI team in an org VS primary team or money making team as acquisition. Above are just examples, you can elaborate based on experience in either teams.\nWhich one pays more?\nJob hopping is easier for which team member?\nLayoffs affect ____ team more?\nWhich one would you prefer to be a part of and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145etjq", "is_robot_indexable": true, "report_reasons": null, "author": "wealthyinvestor999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145etjq/primary_vs_support_team_which_is_better_for_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145etjq/primary_vs_support_team_which_is_better_for_career/", "subreddit_subscribers": 921631, "created_utc": 1686339974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A syllabus and lectures from a UPenn course: https://uncertaintyclass.com/\n\n\"Overview: In this course we will study modern techniques in machine learning, statistics, and computer science for estimating the uncertainty of black box forecasts. This includes conformal prediction, calibration and multi-calibration, outcome indistinguishability, and recent techniques for producing worst-case empirical coverage guarantees without any distributional assumptions. Along the way we will explore applications of these techniques to problems of domain adaptation and their use in solving downstream optimization problems, economics and mechanism design, and algorithmic fairness.\"", "author_fullname": "t2_c7y1n44w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uncertain: Modern Topics in Uncertainty Estimation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145eoy6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686339656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A syllabus and lectures from a UPenn course: &lt;a href=\"https://uncertaintyclass.com/\"&gt;https://uncertaintyclass.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Overview: In this course we will study modern techniques in machine learning, statistics, and computer science for estimating the uncertainty of black box forecasts. This includes conformal prediction, calibration and multi-calibration, outcome indistinguishability, and recent techniques for producing worst-case empirical coverage guarantees without any distributional assumptions. Along the way we will explore applications of these techniques to problems of domain adaptation and their use in solving downstream optimization problems, economics and mechanism design, and algorithmic fairness.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?auto=webp&amp;v=enabled&amp;s=9b10b3fa7998fb3a65776fe1739de5c9c452352e", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d110b55f89cbea8166a98e7eba65ed8675a3be1e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4273b5389343259b6c97cfab62541cbc942b7fbc", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55efffd1849d82ff5601bc02d41ce6aaa2df2782", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efaa17f4d31c6f09cdd3949f5ae68b5da12852b9", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/N30YfHDNHkKv4R6BzxhQBObEQYBN9o5mUJ2JujFrTzo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c20f5a00502c29933fa067fc3dac6ff03874aae7", "width": 960, "height": 960}], "variants": {}, "id": "IyZEpR08Kb7edR1cqVqnz-Om5yEwEXZNGv7LIYV3du4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145eoy6", "is_robot_indexable": true, "report_reasons": null, "author": "bikeskata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145eoy6/uncertain_modern_topics_in_uncertainty_estimation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145eoy6/uncertain_modern_topics_in_uncertainty_estimation/", "subreddit_subscribers": 921631, "created_utc": 1686339656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Original post: [https://www.reddit.com/r/datascience/comments/14582x8/got\\_this\\_question\\_as\\_part\\_of\\_uchicago\\_dsi/](https://www.reddit.com/r/datascience/comments/14582x8/got_this_question_as_part_of_uchicago_dsi/)\n\nGot this take home assignment:\n\nhttps://preview.redd.it/o5skl71ql15b1.png?width=480&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8dd48f375ca63dfda466972891d8d3d3ab014442\n\nThey said this should not take more than evening to complete. That might be true if you are cramming out code without thinking of design and don't have any question. The first inconsistency is where they ask you to imagine that the processes will be running on two separate machines, but want you to write code such that both processes are running on a single machine. I have a feeling they are going to come back to me and say that we wanted to have your code run on a distributed setting, but it did not, so you're rejected.\n\nThe second inconsistency IMO is in their definition of \"robust\". I am not sure if they mean that if a worker process fails in the middle of processing a file we want the living process to take up processing that file. If your assumption is just that the second process failing should not affect the first process, and they half processed file should be ignored, then they will come back to you and say that we wanted the living process to take over the processing of the failed file by the first process. This is impossible without adding another hierarchy to the process structure, but the way they are running the code does not allow for that to happen. And if I am to \"imagine\" that these processes are started independently on separate machines, I need the two processes to communicate periodically.\n\nI am not sure if I am overthinking the assignment or it is just poorly designed, but overall when I asked the engineer who designed this assignment questions, he seemed irritated.\n\nI am looking for some thoughts or opinions on this. There is no need to worry about giving away answers as I have already submitted the assignment and did not sign an NDA.\n\n&amp;#x200B;\n\nHere is my solution if you are interested:\n\n[https://gist.github.com/RoySRC/cc1c13849b5f6702da8e1727d1ca7821](https://gist.github.com/RoySRC/cc1c13849b5f6702da8e1727d1ca7821)\n\n[https://gist.github.com/RoySRC/7859249ab81d8255d644286437b03c21](https://gist.github.com/RoySRC/7859249ab81d8255d644286437b03c21)", "author_fullname": "t2_pwqjrkq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UChicago DSI Interview Take Home Assignment [Repost]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"o5skl71ql15b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 210, "x": 108, "u": "https://preview.redd.it/o5skl71ql15b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a239a9353dec63579bfacee0e6cae6666c1b4ffd"}, {"y": 421, "x": 216, "u": "https://preview.redd.it/o5skl71ql15b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81f1f07b46a4ae460bd5c373057ca80a2db54ee2"}, {"y": 624, "x": 320, "u": "https://preview.redd.it/o5skl71ql15b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d998db25edb7de3d16227d3a542de9c1ddd8b473"}], "s": {"y": 936, "x": 480, "u": "https://preview.redd.it/o5skl71ql15b1.png?width=480&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8dd48f375ca63dfda466972891d8d3d3ab014442"}, "id": "o5skl71ql15b1"}}, "name": "t3_145e5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SPqO5pFwnPY-FwJNl0Ldu4AlJqQTStUjTi2Y-NZGGXE.jpg", "edited": 1686342228.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1686338372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Original post: &lt;a href=\"https://www.reddit.com/r/datascience/comments/14582x8/got_this_question_as_part_of_uchicago_dsi/\"&gt;https://www.reddit.com/r/datascience/comments/14582x8/got_this_question_as_part_of_uchicago_dsi/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Got this take home assignment:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/o5skl71ql15b1.png?width=480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8dd48f375ca63dfda466972891d8d3d3ab014442\"&gt;https://preview.redd.it/o5skl71ql15b1.png?width=480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8dd48f375ca63dfda466972891d8d3d3ab014442&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They said this should not take more than evening to complete. That might be true if you are cramming out code without thinking of design and don&amp;#39;t have any question. The first inconsistency is where they ask you to imagine that the processes will be running on two separate machines, but want you to write code such that both processes are running on a single machine. I have a feeling they are going to come back to me and say that we wanted to have your code run on a distributed setting, but it did not, so you&amp;#39;re rejected.&lt;/p&gt;\n\n&lt;p&gt;The second inconsistency IMO is in their definition of &amp;quot;robust&amp;quot;. I am not sure if they mean that if a worker process fails in the middle of processing a file we want the living process to take up processing that file. If your assumption is just that the second process failing should not affect the first process, and they half processed file should be ignored, then they will come back to you and say that we wanted the living process to take over the processing of the failed file by the first process. This is impossible without adding another hierarchy to the process structure, but the way they are running the code does not allow for that to happen. And if I am to &amp;quot;imagine&amp;quot; that these processes are started independently on separate machines, I need the two processes to communicate periodically.&lt;/p&gt;\n\n&lt;p&gt;I am not sure if I am overthinking the assignment or it is just poorly designed, but overall when I asked the engineer who designed this assignment questions, he seemed irritated.&lt;/p&gt;\n\n&lt;p&gt;I am looking for some thoughts or opinions on this. There is no need to worry about giving away answers as I have already submitted the assignment and did not sign an NDA.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is my solution if you are interested:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gist.github.com/RoySRC/cc1c13849b5f6702da8e1727d1ca7821\"&gt;https://gist.github.com/RoySRC/cc1c13849b5f6702da8e1727d1ca7821&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gist.github.com/RoySRC/7859249ab81d8255d644286437b03c21\"&gt;https://gist.github.com/RoySRC/7859249ab81d8255d644286437b03c21&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&amp;v=enabled&amp;s=71a0c0d89dff6da89bceba27fe1c91bcf534185e", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=861a79178e2b1526b1d25e6f6024914f88255496", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4bb6ee491fe5bcd46e3f3931d54224ce794c00f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f3a516b3685246445a086721a600beada5d2696", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dba5835846d436768bb69d07e885dd9a8857cf16", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d36a205248a1e4685635ac78ef3c46e2dfcba5e7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc0368c25d57483c435e40bc8a848d6c3fa75df3", "width": 1080, "height": 540}], "variants": {}, "id": "OAXSl8SY6T3JK9MGQyKxkoYbqZ71HQRYXLeB8CV0NXg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "145e5mc", "is_robot_indexable": true, "report_reasons": null, "author": "Designer_Ad_2327", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145e5mc/uchicago_dsi_interview_take_home_assignment_repost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145e5mc/uchicago_dsi_interview_take_home_assignment_repost/", "subreddit_subscribers": 921631, "created_utc": 1686338372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a class project to showcase any data source in a dashboard and looking for your insights about which data is interesting in diagram format relevant for people life\u2019s and not old.", "author_fullname": "t2_8duxmbhz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Inspiring Suggestions for Captivating Datasources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145aghg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686329579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a class project to showcase any data source in a dashboard and looking for your insights about which data is interesting in diagram format relevant for people life\u2019s and not old.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145aghg", "is_robot_indexable": true, "report_reasons": null, "author": "Barqawiz_Coder", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145aghg/seeking_inspiring_suggestions_for_captivating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145aghg/seeking_inspiring_suggestions_for_captivating/", "subreddit_subscribers": 921631, "created_utc": 1686329579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHey guys! I published a video on my YT highlighting the recent trends in game playing AI research with LLMs and how Reinforcement Learning could benefit or be affected by it. \n\nI tried to explain recent papers like SPRING and Voyager which are straight-up LLM-based (GPT-4 and ChatGPT) methods that play open-world survival games like Minecraft and Crafter, through some really neat prompting and chain-of-thought techniques. I also cover LLM-assisted RL methods like ELLM, DESP, and Read and Reap Rewards that help train RL Agents efficiently by addressing many common issues with RL training, namely sparse rewards and sample efficiency.\n\nI tried to stay at a level that most people interested in the topic could take something away from watching it. I\u2019m a small Youtuber, so I appreciate any feedback I can get here!\n\nLeaving a link here in case anyone is interested!  \n [https://youtu.be/cXfnNoMgCio](https://youtu.be/cXfnNoMgCio)\n\nIf the above doesn\u2019t work, try:\n\n[https://m.youtube.com/watch?v=cXfnNoMgCio&amp;feature=youtu.be](https://m.youtube.com/watch?v=cXfnNoMgCio&amp;feature=youtu.be)", "author_fullname": "t2_matylxao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing RL and LLMs for Game Playing AI (A video)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14570de", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686321525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys! I published a video on my YT highlighting the recent trends in game playing AI research with LLMs and how Reinforcement Learning could benefit or be affected by it. &lt;/p&gt;\n\n&lt;p&gt;I tried to explain recent papers like SPRING and Voyager which are straight-up LLM-based (GPT-4 and ChatGPT) methods that play open-world survival games like Minecraft and Crafter, through some really neat prompting and chain-of-thought techniques. I also cover LLM-assisted RL methods like ELLM, DESP, and Read and Reap Rewards that help train RL Agents efficiently by addressing many common issues with RL training, namely sparse rewards and sample efficiency.&lt;/p&gt;\n\n&lt;p&gt;I tried to stay at a level that most people interested in the topic could take something away from watching it. I\u2019m a small Youtuber, so I appreciate any feedback I can get here!&lt;/p&gt;\n\n&lt;p&gt;Leaving a link here in case anyone is interested!&lt;br/&gt;\n &lt;a href=\"https://youtu.be/cXfnNoMgCio\"&gt;https://youtu.be/cXfnNoMgCio&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If the above doesn\u2019t work, try:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.youtube.com/watch?v=cXfnNoMgCio&amp;amp;feature=youtu.be\"&gt;https://m.youtube.com/watch?v=cXfnNoMgCio&amp;amp;feature=youtu.be&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/agDFv2SlRhIwIzj8ONmEfzuZ-0rzm3GFa4uUm-vkB9s.jpg?auto=webp&amp;v=enabled&amp;s=7b8af65df013b34526d0578c31b61a2d548df923", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/agDFv2SlRhIwIzj8ONmEfzuZ-0rzm3GFa4uUm-vkB9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=413412d163bdfd2d7b04761fd42f326f40cb9eb5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/agDFv2SlRhIwIzj8ONmEfzuZ-0rzm3GFa4uUm-vkB9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce67b7966ab298bace9dc7398489e650bfb58125", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/agDFv2SlRhIwIzj8ONmEfzuZ-0rzm3GFa4uUm-vkB9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29f02efdab61fac18d8c3d04c6aa1d1eef2d2a1c", "width": 320, "height": 240}], "variants": {}, "id": "4vQl83x5leoT6BymNoxoekZklHp-8ZmwIMbFfBzUNaI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14570de", "is_robot_indexable": true, "report_reasons": null, "author": "AvvYaa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14570de/comparing_rl_and_llms_for_game_playing_ai_a_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14570de/comparing_rl_and_llms_for_game_playing_ai_a_video/", "subreddit_subscribers": 921631, "created_utc": 1686321525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI've been lurking this sub the last weeks since I'm interested to make a career switch into data science. Right now I'm working as a data architect but I feel like doing more fieldwork. I saw a job post on Linkedin for a data scientist to help gather data on (environmental) field trips. and that caught my attention.   \nNow I was wondering how common it is for data scientist to do field work and carreer path you took to land that job.   \nThanks!", "author_fullname": "t2_770mmqxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fieldwork in datascience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_144z8n7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686298542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been lurking this sub the last weeks since I&amp;#39;m interested to make a career switch into data science. Right now I&amp;#39;m working as a data architect but I feel like doing more fieldwork. I saw a job post on Linkedin for a data scientist to help gather data on (environmental) field trips. and that caught my attention.&lt;br/&gt;\nNow I was wondering how common it is for data scientist to do field work and carreer path you took to land that job.&lt;br/&gt;\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "144z8n7", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableParticular7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/144z8n7/fieldwork_in_datascience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/144z8n7/fieldwork_in_datascience/", "subreddit_subscribers": 921631, "created_utc": 1686298542.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}