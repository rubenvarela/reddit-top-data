{"kind": "Listing", "data": {"after": "t3_1464ed0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there specific skills? Or is it just the same as everywhere else?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist who are good at office politics, how did you increase your political skill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145kh8b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 201, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 201, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686353823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there specific skills? Or is it just the same as everywhere else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145kh8b", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 118, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145kh8b/data_scientist_who_are_good_at_office_politics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145kh8b/data_scientist_who_are_good_at_office_politics/", "subreddit_subscribers": 922139, "created_utc": 1686353823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have come to problems that I have solved in SQL (postgress) but doing the analysis in R or even Python would be easier.\n\nI needed from a zip code the geometry column twice:1 for the orgin source and 1 for the destination.  There would be no easy solution in SQL other use a nested query or use left join twice. Where as in R mapvalues(collum\\_to\\_transforn, zipcode, geometry) is sufficient. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\nOr you want to calculate the avg use per zipcode per day but\n\nusing the global maximum and minimum date to calculate the number of  days and not the days between per zipcode, as the first time using it was e.g. in February but available since January.\n\nThis can be done with SQL but  R makes lives easier again.\n\n&amp;#x200B;\n\nSo when do you use SQL for data manipulation and when another language. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_67cz0s3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL or programming language. When to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145syvc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686379865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have come to problems that I have solved in SQL (postgress) but doing the analysis in R or even Python would be easier.&lt;/p&gt;\n\n&lt;p&gt;I needed from a zip code the geometry column twice:1 for the orgin source and 1 for the destination.  There would be no easy solution in SQL other use a nested query or use left join twice. Where as in R mapvalues(collum_to_transforn, zipcode, geometry) is sufficient. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or you want to calculate the avg use per zipcode per day but&lt;/p&gt;\n\n&lt;p&gt;using the global maximum and minimum date to calculate the number of  days and not the days between per zipcode, as the first time using it was e.g. in February but available since January.&lt;/p&gt;\n\n&lt;p&gt;This can be done with SQL but  R makes lives easier again.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So when do you use SQL for data manipulation and when another language. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145syvc", "is_robot_indexable": true, "report_reasons": null, "author": "TywinASOIAF", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145syvc/sql_or_programming_language_when_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145syvc/sql_or_programming_language_when_to_use/", "subreddit_subscribers": 922139, "created_utc": 1686379865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for advice about pursuing a sabbatical in the Fall. I've been working in data analytics, strategy and operations management for the last 10 years, and am in a very senior role in my company but I am BURNT OUT. I'm wrestling with the decision to simply step back for a few months (3-6) and go explore something new, whether that's in a related field (AI, machine learning, BI development) or really branch out and just pursue another interest. I'm curious to hear if anyone here in this thread has pulled off such a maneuver, what they did, and how they landed when they decided their \"break\" was over. I'm looking for ideas on what I could go do and also advice from anyone who has done it before. Thanks!\n\nEDIT: just want to emphasize - I\u2019m really curious what people here did for their sabbatical. Folks in data science - did you do something related?", "author_fullname": "t2_zt9il", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone here completed a sabbatical recently?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146858c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686431233.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686423597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for advice about pursuing a sabbatical in the Fall. I&amp;#39;ve been working in data analytics, strategy and operations management for the last 10 years, and am in a very senior role in my company but I am BURNT OUT. I&amp;#39;m wrestling with the decision to simply step back for a few months (3-6) and go explore something new, whether that&amp;#39;s in a related field (AI, machine learning, BI development) or really branch out and just pursue another interest. I&amp;#39;m curious to hear if anyone here in this thread has pulled off such a maneuver, what they did, and how they landed when they decided their &amp;quot;break&amp;quot; was over. I&amp;#39;m looking for ideas on what I could go do and also advice from anyone who has done it before. Thanks!&lt;/p&gt;\n\n&lt;p&gt;EDIT: just want to emphasize - I\u2019m really curious what people here did for their sabbatical. Folks in data science - did you do something related?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "146858c", "is_robot_indexable": true, "report_reasons": null, "author": "varSkubalon", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/146858c/has_anyone_here_completed_a_sabbatical_recently/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/146858c/has_anyone_here_completed_a_sabbatical_recently/", "subreddit_subscribers": 922139, "created_utc": 1686423597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For each feature, how do go about finding the best transformations?  \n\n\nCurrently what I do is I look at a scatter graph of my feature vs the target and trial various different functions as lines of best fit to see which has the best R-Squared and go with that. I know there are various weakness to this approach however, not to mention it's time consuming, at least how I do it.  \n\n\nWhat methods do you have find better transformation or to find them faster/more effeciently?", "author_fullname": "t2_1055bs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you find the best Transformations? (Linear Regression)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1460ek4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686403978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For each feature, how do go about finding the best transformations?  &lt;/p&gt;\n\n&lt;p&gt;Currently what I do is I look at a scatter graph of my feature vs the target and trial various different functions as lines of best fit to see which has the best R-Squared and go with that. I know there are various weakness to this approach however, not to mention it&amp;#39;s time consuming, at least how I do it.  &lt;/p&gt;\n\n&lt;p&gt;What methods do you have find better transformation or to find them faster/more effeciently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1460ek4", "is_robot_indexable": true, "report_reasons": null, "author": "Gef_1_Man_Army", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1460ek4/how_do_you_find_the_best_transformations_linear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1460ek4/how_do_you_find_the_best_transformations_linear/", "subreddit_subscribers": 922139, "created_utc": 1686403978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys!\n\nWe are hosting another Live event for our ML community.. you're all welcome to join =)\n\nTime: This Sunday at 1PM UTC+0 / 9AM EST / 7AM CST\n\nThe topic is: \"Machine Learning Implementation on the Insurance/Finance Industry\"\n\nThe Speaker: Cornellius Yudha Wijaya ([https://www.linkedin.com/in/cornellius-yudha-wijaya/](https://www.linkedin.com/in/cornellius-yudha-wijaya/))\n\n&amp;#x200B;\n\nIf you want the event on your Calendar and also to hear about future events you can signup here:\n\n[https://forms.gle/zTiezLukGRhiLQ4DA](https://forms.gle/zTiezLukGRhiLQ4DA)\n\n&amp;#x200B;\n\nIf you prefer not to share any info - I get it... you can simply join here when it starts:\n\n[https://meet.google.com/mcm-gxrd-prb](https://meet.google.com/mcm-gxrd-prb)", "author_fullname": "t2_8lm3cr0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Live Event - \"Machine Learning Implementation on the Insurance/Finance Industry\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1464x32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686415476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys!&lt;/p&gt;\n\n&lt;p&gt;We are hosting another Live event for our ML community.. you&amp;#39;re all welcome to join =)&lt;/p&gt;\n\n&lt;p&gt;Time: This Sunday at 1PM UTC+0 / 9AM EST / 7AM CST&lt;/p&gt;\n\n&lt;p&gt;The topic is: &amp;quot;Machine Learning Implementation on the Insurance/Finance Industry&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The Speaker: Cornellius Yudha Wijaya (&lt;a href=\"https://www.linkedin.com/in/cornellius-yudha-wijaya/\"&gt;https://www.linkedin.com/in/cornellius-yudha-wijaya/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you want the event on your Calendar and also to hear about future events you can signup here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forms.gle/zTiezLukGRhiLQ4DA\"&gt;https://forms.gle/zTiezLukGRhiLQ4DA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you prefer not to share any info - I get it... you can simply join here when it starts:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://meet.google.com/mcm-gxrd-prb\"&gt;https://meet.google.com/mcm-gxrd-prb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1464x32", "is_robot_indexable": true, "report_reasons": null, "author": "__god_bless_you_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1464x32/live_event_machine_learning_implementation_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1464x32/live_event_machine_learning_implementation_on_the/", "subreddit_subscribers": 922139, "created_utc": 1686415476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any one working on smart manufacturing? What are your use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145q3z8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686370304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145q3z8", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145q3z8/any_one_working_on_smart_manufacturing_what_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145q3z8/any_one_working_on_smart_manufacturing_what_are/", "subreddit_subscribers": 922139, "created_utc": 1686370304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'll use a API service to provide me with a bunch of website urls then use python beautiful soup to extract the actual text content the pile up all the content from about 30 web pages and send it to a python script that extracts keywords.\n\nBut it's slow. How can I find the bottle necks? Or is there a way to speed this up using another language like R or Java?\n\nQuite new to this so I do not know how to run tests etc.\n\nI just want to mention the the API is really fast and I'm sure is not causing any latency issue.\n\n**Update**: ok so I decided to try concurrent.futures and it improved the performance on my script which was taking around 20 seconds to 6 seconds. So this works very well!", "author_fullname": "t2_r3147swk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm using python to scrape web page content and extract keywords, how can I make it faster to process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145vvsx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686430467.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686389983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll use a API service to provide me with a bunch of website urls then use python beautiful soup to extract the actual text content the pile up all the content from about 30 web pages and send it to a python script that extracts keywords.&lt;/p&gt;\n\n&lt;p&gt;But it&amp;#39;s slow. How can I find the bottle necks? Or is there a way to speed this up using another language like R or Java?&lt;/p&gt;\n\n&lt;p&gt;Quite new to this so I do not know how to run tests etc.&lt;/p&gt;\n\n&lt;p&gt;I just want to mention the the API is really fast and I&amp;#39;m sure is not causing any latency issue.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: ok so I decided to try concurrent.futures and it improved the performance on my script which was taking around 20 seconds to 6 seconds. So this works very well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145vvsx", "is_robot_indexable": true, "report_reasons": null, "author": "flipsnapnet", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145vvsx/im_using_python_to_scrape_web_page_content_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145vvsx/im_using_python_to_scrape_web_page_content_and/", "subreddit_subscribers": 922139, "created_utc": 1686389983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a beginner and I am stuck in this program. \n\nWhen I use model.fit() the program says \u2018InvalidArgumentError\u2019\n\nI tried many ways to solve the problem.\n\n[https://www.kaggle.com/code/raghavdecoded/infosys-agropy](https://www.kaggle.com/code/raghavdecoded/infosys-agropy)", "author_fullname": "t2_rlkg9ceg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Plant Disease Identification using DenseNet201", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1461l5m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686410693.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686407016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a beginner and I am stuck in this program. &lt;/p&gt;\n\n&lt;p&gt;When I use model.fit() the program says \u2018InvalidArgumentError\u2019&lt;/p&gt;\n\n&lt;p&gt;I tried many ways to solve the problem.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kaggle.com/code/raghavdecoded/infosys-agropy\"&gt;https://www.kaggle.com/code/raghavdecoded/infosys-agropy&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uOl0zx6CKFscwZpm-VzUbN7G5fPVilXvzxsHD2hXZIg.jpg?auto=webp&amp;v=enabled&amp;s=cf506407538bb3c2c6ab5eabbb232e5ab21766cd", "width": 100, "height": 100}, "resolutions": [], "variants": {}, "id": "XdcBgGBtA9rRL9U_i8ErY-agZXiiCqClRnMacYcZRZY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1461l5m", "is_robot_indexable": true, "report_reasons": null, "author": "supreme-raghav", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1461l5m/plant_disease_identification_using_densenet201/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1461l5m/plant_disease_identification_using_densenet201/", "subreddit_subscribers": 922139, "created_utc": 1686407016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "  That\u2019s the second time in a week I am about to apply for a job (in LinkedIn or welcometothejungle) and something happens so I can\u2019t send my application. I was wondering if I can send it to someone in the company and explain (and prove) the site was not working.\n\n  Would be a email what my curriculum, portfolio and a \u201cI tried to apply through X and it was not working well\u2026\u201d. But for who? Is that ok if I send to the company mainly email?", "author_fullname": "t2_c9tg75x0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To who in a company can I send a prospective email?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146a42p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686428630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That\u2019s the second time in a week I am about to apply for a job (in LinkedIn or welcometothejungle) and something happens so I can\u2019t send my application. I was wondering if I can send it to someone in the company and explain (and prove) the site was not working.&lt;/p&gt;\n\n&lt;p&gt;Would be a email what my curriculum, portfolio and a \u201cI tried to apply through X and it was not working well\u2026\u201d. But for who? Is that ok if I send to the company mainly email?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "146a42p", "is_robot_indexable": true, "report_reasons": null, "author": "attmonteiro", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/146a42p/to_who_in_a_company_can_i_send_a_prospective_email/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/146a42p/to_who_in_a_company_can_i_send_a_prospective_email/", "subreddit_subscribers": 922139, "created_utc": 1686428630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing FeatureEng: A Community for Feature Engineering Enthusiasts!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145oag6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_cvej3qatd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "FeatureEng", "selftext": "Hey everyone, I am Gxav. I used to be very active on Kaggle [https://www.kaggle.com/xavierconort](https://www.kaggle.com/xavierconort) and I owe my Kaggle GrandMaster title to feature engineering. Building skills in feature engineering is an ongoing journey and I am really missing my Kaggle days where I could learn new tricks from my fellow Kagglers.\n\nI started the FeatureEng community because I couldn't find any communities specifically focused on feature engineering, which I believe deserves its own dedicated space. I hope this community will be a place where you and I will find our new sources of inspiration!\n\nCheers,\n\nGxav", "author_fullname": "t2_cvej3qatd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing FeatureEng: A Community for Feature Engineering Enthusiasts!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/FeatureEng", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145nb4g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686361712.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I am Gxav. I used to be very active on Kaggle &lt;a href=\"https://www.kaggle.com/xavierconort\"&gt;https://www.kaggle.com/xavierconort&lt;/a&gt; and I owe my Kaggle GrandMaster title to feature engineering. Building skills in feature engineering is an ongoing journey and I am really missing my Kaggle days where I could learn new tricks from my fellow Kagglers.&lt;/p&gt;\n\n&lt;p&gt;I started the FeatureEng community because I couldn&amp;#39;t find any communities specifically focused on feature engineering, which I believe deserves its own dedicated space. I hope this community will be a place where you and I will find our new sources of inspiration!&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;Gxav&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_8kc7h0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145nb4g", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/FeatureEng/comments/145nb4g/introducing_featureeng_a_community_for_feature/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/FeatureEng/comments/145nb4g/introducing_featureeng_a_community_for_feature/", "subreddit_subscribers": 23, "created_utc": 1686361712.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1686364639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/FeatureEng/comments/145nb4g/introducing_featureeng_a_community_for_feature/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145oag6", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_145nb4g", "author_flair_text_color": null, "permalink": "/r/datascience/comments/145oag6/introducing_featureeng_a_community_for_feature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/FeatureEng/comments/145nb4g/introducing_featureeng_a_community_for_feature/", "subreddit_subscribers": 922139, "created_utc": 1686364639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Things that I will be using in the near future(~5years)\n1. Tests of association (parametric and non parametric), tests of normality (very often)\n2. Regression analysis (not building models just for analysis)\n3. Survival analysis\n\nPrediction models, neural networks, deeplearning...etc are something I may or may not take up in the future like beyond 7yrs.\n\nEdit: To make things more clear, I am a medical student going into doing clinical practice and research. I will be needing data analysis and basic machine learning experience. And I have to learn in the limited amount of time.", "author_fullname": "t2_6lvuczf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am currently in the stage where I have to decide one language to properly learn. R or Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_146cfly", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686437217.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686434458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Things that I will be using in the near future(~5years)\n1. Tests of association (parametric and non parametric), tests of normality (very often)\n2. Regression analysis (not building models just for analysis)\n3. Survival analysis&lt;/p&gt;\n\n&lt;p&gt;Prediction models, neural networks, deeplearning...etc are something I may or may not take up in the future like beyond 7yrs.&lt;/p&gt;\n\n&lt;p&gt;Edit: To make things more clear, I am a medical student going into doing clinical practice and research. I will be needing data analysis and basic machine learning experience. And I have to learn in the limited amount of time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "146cfly", "is_robot_indexable": true, "report_reasons": null, "author": "RexFury101", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/146cfly/i_am_currently_in_the_stage_where_i_have_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/146cfly/i_am_currently_in_the_stage_where_i_have_to/", "subreddit_subscribers": 922139, "created_utc": 1686434458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What\u2019s the main differences and which would be more lucrative to have?", "author_fullname": "t2_cpr2fma81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters of Data Analytics versus Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146bb7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686431670.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the main differences and which would be more lucrative to have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "146bb7r", "is_robot_indexable": true, "report_reasons": null, "author": "Spirited_Drawing_411", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/146bb7r/masters_of_data_analytics_versus_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/146bb7r/masters_of_data_analytics_versus_data_science/", "subreddit_subscribers": 922139, "created_utc": 1686431670.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a rookie recent student of Data Science and got assigned homework: to predict and create a Propensity Score for clients of a bank on how likely they are to acquire a debit card. I have three tables basically: client bio data (age, gender, state), monthly snapshots of the client (debt, wealth, investments, how many debit cards, how many credit cards)(some clients have a whole year of information, other have less), and all the transactions of the banks per client (some clients have no transactions). \n\n&amp;#x200B;\n\nI know I might be asking for a lot, but I feel a bit lost as to how to merge these tables and then how to create the propensity score. Any help or suggestions are amazingly appreciated it. I hope it can be me helping some people from the subreddit in the future. \n\n&amp;#x200B;\n\nMany thanks in advance!", "author_fullname": "t2_ajss1yf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for a rookie doing his homework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146818n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686423309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a rookie recent student of Data Science and got assigned homework: to predict and create a Propensity Score for clients of a bank on how likely they are to acquire a debit card. I have three tables basically: client bio data (age, gender, state), monthly snapshots of the client (debt, wealth, investments, how many debit cards, how many credit cards)(some clients have a whole year of information, other have less), and all the transactions of the banks per client (some clients have no transactions). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know I might be asking for a lot, but I feel a bit lost as to how to merge these tables and then how to create the propensity score. Any help or suggestions are amazingly appreciated it. I hope it can be me helping some people from the subreddit in the future. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "146818n", "is_robot_indexable": true, "report_reasons": null, "author": "Marenx5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/146818n/suggestions_for_a_rookie_doing_his_homework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/146818n/suggestions_for_a_rookie_doing_his_homework/", "subreddit_subscribers": 922139, "created_utc": 1686423309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working with many data scientists in a large international enterprise, many of them have a PhD in fields such as physics, maths or computer science.\n\nRecently, I started wondering if there exists an unspoken glass ceiling for data scientists (or IT specialists in general) in many organisations for such individuals who are not overly keen on giving up actual hands-on data science work, or who are not overly keen on having lunches and coffees with more senior managers all the time. This might sound like a luxury problem to have, but once you are beyond your 40s and have a family, it's not so much fun to be put in front of an undisclosed choice to either not progress anymore significantly or be forced to become a manager and give up that which you are really good at. Obviously, one could argue that many data scientists, to progress further, need to learn how to be more outgoing, extrovert, present themselves etc. - but that's not what I'm referring to. I've seen brilliant people leave the company because there was just not a lot more possible for the positions they were in.\n\nSo, does there exist a glass ceiling for specialist roles such as data scientists?\n\nWhat are your observations?", "author_fullname": "t2_l5gzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glass ceiling for data science careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1467419", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686420967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with many data scientists in a large international enterprise, many of them have a PhD in fields such as physics, maths or computer science.&lt;/p&gt;\n\n&lt;p&gt;Recently, I started wondering if there exists an unspoken glass ceiling for data scientists (or IT specialists in general) in many organisations for such individuals who are not overly keen on giving up actual hands-on data science work, or who are not overly keen on having lunches and coffees with more senior managers all the time. This might sound like a luxury problem to have, but once you are beyond your 40s and have a family, it&amp;#39;s not so much fun to be put in front of an undisclosed choice to either not progress anymore significantly or be forced to become a manager and give up that which you are really good at. Obviously, one could argue that many data scientists, to progress further, need to learn how to be more outgoing, extrovert, present themselves etc. - but that&amp;#39;s not what I&amp;#39;m referring to. I&amp;#39;ve seen brilliant people leave the company because there was just not a lot more possible for the positions they were in.&lt;/p&gt;\n\n&lt;p&gt;So, does there exist a glass ceiling for specialist roles such as data scientists?&lt;/p&gt;\n\n&lt;p&gt;What are your observations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1467419", "is_robot_indexable": true, "report_reasons": null, "author": "fabkosta", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1467419/glass_ceiling_for_data_science_careers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1467419/glass_ceiling_for_data_science_careers/", "subreddit_subscribers": 922139, "created_utc": 1686420967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI'm currently a senior data analysts at a Fortune 50.\n\nI'm nearing completion of a MSc in Comp Sci with a Concentration in ML (OMSCS).\n\nI'm wanting to do a 2nd MSc degree because I really love learning in a structured environment outside of work.\n\nI have two options:\n\n(1) TAMU Masters in Statistics\n\n(2) UT Austin Masters in AI\n\nBoth of these programs look very interesting to me, and my work will cover the tuition in full.\n\nMy long term goal is to eventually get into an AI researcher role, but my short-term goal is to get into an AI Engineer/ML Engineer role.\n\nWhich program would be better for my career progression?\n\nI realize that another masters is technically not *ideal* because I can simply do more personal projects to boost my marketability (but I don't care about that lol).", "author_fullname": "t2_k5hos", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decision on Which Masters to Do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1466w7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686420810.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686420416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a senior data analysts at a Fortune 50.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m nearing completion of a MSc in Comp Sci with a Concentration in ML (OMSCS).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wanting to do a 2nd MSc degree because I really love learning in a structured environment outside of work.&lt;/p&gt;\n\n&lt;p&gt;I have two options:&lt;/p&gt;\n\n&lt;p&gt;(1) TAMU Masters in Statistics&lt;/p&gt;\n\n&lt;p&gt;(2) UT Austin Masters in AI&lt;/p&gt;\n\n&lt;p&gt;Both of these programs look very interesting to me, and my work will cover the tuition in full.&lt;/p&gt;\n\n&lt;p&gt;My long term goal is to eventually get into an AI researcher role, but my short-term goal is to get into an AI Engineer/ML Engineer role.&lt;/p&gt;\n\n&lt;p&gt;Which program would be better for my career progression?&lt;/p&gt;\n\n&lt;p&gt;I realize that another masters is technically not &lt;em&gt;ideal&lt;/em&gt; because I can simply do more personal projects to boost my marketability (but I don&amp;#39;t care about that lol).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1466w7d", "is_robot_indexable": true, "report_reasons": null, "author": "Delpen9", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1466w7d/decision_on_which_masters_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1466w7d/decision_on_which_masters_to_do/", "subreddit_subscribers": 922139, "created_utc": 1686420416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Recently, I conducted research and developed an exploratory data and sentiment analysis from Reddit in the r/movies subreddit. It took me several hours, but I believe the results are good!  \n\nPlease check out my notebook on Kaggle (link: [https://www.kaggle.com/code/curiel/r-movies-eda-sa](https://www.kaggle.com/code/curiel/r-movies-eda-sa)) and consider upvoting, analyzing, and providing feedback. All comments are welcome \ud83d\udc9c.  \n\nI compared how the posts and comments are organized based on tags, hour, and sentiment. It's beneficial because we can observe the sentiment of the post authors through tags and their corresponding comments, and analyze potential correlations.  \n\nIf you find this interesting, please consider sharing or linking it! Your support would be greatly appreciated and will help make this notebook accessible to a wider audience \ud83d\udc9c.  \n\n&amp;#x200B;\n\nDataset used: [https://www.kaggle.com/datasets/curiel/rmovies-posts-and-comments](https://www.kaggle.com/datasets/curiel/rmovies-posts-and-comments) \n\nScript that feeds and updates the dataset: [https://www.kaggle.com/code/curiel/update-r-movies-dataset](https://www.kaggle.com/code/curiel/update-r-movies-dataset)", "author_fullname": "t2_86qi4nrq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploratory Data and Sentiment Analysis of r/movies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1462i6f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686409387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, I conducted research and developed an exploratory data and sentiment analysis from Reddit in the &lt;a href=\"/r/movies\"&gt;r/movies&lt;/a&gt; subreddit. It took me several hours, but I believe the results are good!  &lt;/p&gt;\n\n&lt;p&gt;Please check out my notebook on Kaggle (link: &lt;a href=\"https://www.kaggle.com/code/curiel/r-movies-eda-sa\"&gt;https://www.kaggle.com/code/curiel/r-movies-eda-sa&lt;/a&gt;) and consider upvoting, analyzing, and providing feedback. All comments are welcome \ud83d\udc9c.  &lt;/p&gt;\n\n&lt;p&gt;I compared how the posts and comments are organized based on tags, hour, and sentiment. It&amp;#39;s beneficial because we can observe the sentiment of the post authors through tags and their corresponding comments, and analyze potential correlations.  &lt;/p&gt;\n\n&lt;p&gt;If you find this interesting, please consider sharing or linking it! Your support would be greatly appreciated and will help make this notebook accessible to a wider audience \ud83d\udc9c.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dataset used: &lt;a href=\"https://www.kaggle.com/datasets/curiel/rmovies-posts-and-comments\"&gt;https://www.kaggle.com/datasets/curiel/rmovies-posts-and-comments&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Script that feeds and updates the dataset: &lt;a href=\"https://www.kaggle.com/code/curiel/update-r-movies-dataset\"&gt;https://www.kaggle.com/code/curiel/update-r-movies-dataset&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bAF3nu34sqx9JiQ8p2IC1qpunRvsj1lY6gdZCTglVR4.jpg?auto=webp&amp;v=enabled&amp;s=f9a4ebbdf25c141e393ac0f5de16dfb5de3c35e8", "width": 100, "height": 100}, "resolutions": [], "variants": {}, "id": "nf-qTd7Cm4Nu8vE8A8JoHkZUwetTZo9OzjS48fKRCdo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1462i6f", "is_robot_indexable": true, "report_reasons": null, "author": "data-dreamr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1462i6f/exploratory_data_and_sentiment_analysis_of_rmovies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1462i6f/exploratory_data_and_sentiment_analysis_of_rmovies/", "subreddit_subscribers": 922139, "created_utc": 1686409387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This encoding system claim that it can state all IPA symbols and its pronounciation in a Binary format \n\nPhonBinary Encoding System V6\n\n- Analyzes each sound into its featural components to translate into binary. \n- Features are encoded using a variable number of bits based on the number of possibilities for each feature.\n- Enables representation of the full IPA  to use in various NLP applications. \n- Includes all manners of articulation, secondary articulations, prosodic features, airstream mechanisms and vowel qualities.\n\nSound Analysis:  \n\n- The first step involves analyzing each sound into its featural components. \n- Full understanding of the IPA and phonetic terminology required.\n\nConsonants:\n- Produced by modifying airstream with articulators. \n- Factors: airstream mechanism (3 bits), manner of articulation (5 bits), place of articulation (6 bits), phonation (4 bits), coarticulation (5 bits).\n\nAirstream mechanism (3 bits):\n- Pulmonic egressive: 000 \n- Pulmonic ingressive: 001\n- Glottalic egressive: 010\n- Glottalic ingressive: 011\n- Lingual-glottalic: 100\n- Velaric: 101 \n\nManner of articulation (5 bits):\n- Plosive: 00000   \n- Nasal: 00001\n- Trill: 00010\n- Tap: 00011\n- Fricative: 00100\n- Approximant: 00101\n- Lateral approximant: 00110\n- Flap: 00111\n- Affricate: 01000 \n- Clitic: 01001  \n- Implosive  01010\n- Ejective: 01011\n- Click: 01100\n\nPlace of articulation (6 bits): \n- Bilabial: 000000 \n- Labiodental: 000001\n- Interdental: 000010\n- Alveolar: 000011 \n- Postalveolar: 000100\n- Retroflex: 000101\n- Palatal: 000110\n- Velar: 000111 \n- Uvular: 001000\n- Pharyngeal: 001001  \n- Glottal: 001010 \n- Epiglottal: 001011\n- Labial-palatal: 001100\n- Labial-velar: 001101 \n- Labial-uvular: 001110\n- Velar-pharyngeal: 001111\n- Velar-uvular: 010000  \n- Velar-epilaryngeal: 010001\n- Uvular-pharyngeal : 010010\n\nPhonation (4 bits):\n- Voiceless: 0000\n- Voiced: 0001   \n- Creaky: 0010 \n- Breathy: 0011\n- Slack: 0100\n- Stiff: 0101\n- Creaky voiced: 0110\n- Whispered: 0111   \n- Harsh: 1000 \n- Laryngealized : 1001\n- Closed glottis: 1010\n- Velaric aspiration: 1011\n\nVowels:\n- Produced by shaping airstream resonated through oral and nasal cavities. \n- Factors: height (4 bits), backness (4 bits), roundness (4 bits), nasalization (2 bits), length (3 bits). \n\nHeight (4 bits):\n- Close: 0000\n- Near-close: 0001  \n- Close-mid: 0010  \n- Mid: 0011\n- Open-mid: 0100 \n- Near-open: 0101   \n- Open: 0110\n\nBackness(4 bits):\n- Front: 0000\n- Near-front: 0001\n- Central: 0010  \n- Near-back: 0011\n- Back: 0100 \n- Near-central: 0101\n\nRoundness (4 bits):\n- Unrounded: 0000  \n- Rounded: 0001\n- Compressed: 0010\n- Protruded: 0011\n- More rounded: 0100\n- Less rounded: 0101\n\nTenseness  (3 bits):\n- Extra-short: 000 \n- Short: 001\n- Long: 010  \n- Overlong: 011\n\nNasalization (2 bits):\n- Oral: 00\n- Nasal: 01\n- Nasalized: 10\n- Denasalized: 11\n\nSecondary articulations, prosodic features,  diacritics and delimiters will also be included with variable bit encoding. Morphological information  can be  added as an additional layer of information.\n\nDelimiters:\nMorpheme boundary (+)\nWord boundary (#)\nSyllable boundary (-)\nStress boundary (*)\nIntonation boundary ( ^ )\nProcess boundary (%)\n\nEncoding:\n\n- Analyze each sound into its featural components using the IPA chart and the feature values given in the question.\n- Arrange the features in a consistent order for consonants (airstream mechanism \u2192 manner \u2192 place \u2192 phonation \u2192 coarticulation)  and vowels (height \u2192 backness \u2192 roundness  \u2192 nasalization \u2192 length).\n- Concatenate the binary codes for each feature to form the binary code for each sound.\n- Concatenate the binary codes for each sound to form the binary code for each word.\n- Use delimiters to mark boundaries between words, syllables and morphemes.\n\nDecoding:\n\n- Use delimiters to identify boundaries between words, syllables and morphemes.\n- Split the binary code for each word into segments of variable length based on the number of bits for each feature.\n- Identify the feature values for each segment using the feature values given in the question.\n- Identify the sound corresponding to each segment using the IPA chart and the feature values.\n- Write the sounds using IPA symbols or orthographic symbols.\n\nExample:\n\n\"Hello World\"\n\nEncoding:\n\n- Analyze each sound into its featural components:\n\n  - /h/: pulmonic egressive, fricative, glottal, voiceless, no coarticulation\n  - /\u025b/: open-mid, front, unrounded, oral, short\n  - /l/: pulmonic egressive, lateral approximant, alveolar, voiced, no coarticulation\n  - /o\u028a/: close-mid, back, rounded, oral, long\n  - /w/: pulmonic egressive, approximant, labial-velar, voiced, no coarticulation\n  - /\u025c\u02d0/: mid, central, unrounded, oral, overlong\n  - /l/: pulmonic egressive, lateral approximant, alveolar, voiced, no coarticulation\n  - /d/: pulmonic egressive, plosive, alveolar, voiced, no coarticulation\n\n- Arrange the features in a consistent order and concatenate the binary codes for each feature:\n\n  - /h/: 000001000010100000000000\n  - /\u025b/: 010000000000000001\n  - /l/: 0000010110000110000100000\n  - /o\u028a/: 001001010001000010\n  - /w/: 0000010100111101000100000\n  - /\u025c\u02d0/: 001100010000000011\n  - /l/: 0000010110000110000100000\n  - /d/: 0000000000011001000100000\n\n- Concatenate the binary codes for each sound and use delimiters to mark boundaries:\n\n  - Hello: 000001000010100000000000#010000000000000001#-#0000010110000110000100000#001001010001000010#\n  - World: 0000010100111101000100000#-#001100010000000011#-#0000010110000110000100000#-#0000000000011001000100000#\n\nDecoding:\n\n- Identify the boundaries between words, syllables and morphemes using the delimiters:\n\n  - Hello: [h][\u025b]-[l][o\u028a]\n  - World: [w]-[\u025c\u02d0]-[l]-[d]\n\n- Divide the binary code for each word into chunks of bits corresponding to each feature:\n\n  - Hello: [3][5][6][4][5]-[4][4][4][2][3]-[3][5][6][4][5]-[4][4][4][2][3]\n    - [h]: [000] [00] [010] [1000] [00000]\n    - [\u025b]: [0100] [0000] [0000] [00] [001]\n    - [l]: [000] [01] [1000] [0110] [00010]\n    - [o\u028a]:[0010] [0100] [0100] [00] [010]\n  - World: [3][5][6][4][5]-[4][4][4][2][3]-[3][5][6][4][5]-[3][5][6][4][5]\n    - [w]: [000] [01] [0011] [1101] [00010]\n    - [\u025c\u02d0]:[0011] [0001] [0000] [00] [011]\n    - [l]: [000] [01] [1000] [0110] [00010]\n    - [d]: [000] [00] [0001] [1001] [00010]\n\n- Match each chunk of bits with the feature value given in the question:\n\n  - Hello:\n    - /h/: pulmonic egressive (000), fricative (00), glottal (010), voiceless (1000), no coarticulation (00000)\n    - /\u025b/: open-mid (0100), front (0000), unrounded (0000), oral (00), short (001)\n    - /l/: pulmonic egressive (000), lateral approximant (01), alveolar (1000), voiced (0110), no coarticulation (00010)\n    - /o\u028a/: close-mid (0010), back (0100), rounded (0100), oral (00), long (010)\n  - World:\n    - /w/: pulmonic egressive (000), approximant (01), labial-velar (0011), voiced (1101), no coarticulation (00010)\n    - /\u025c\u02d0/: mid (0011), central (0001), unrounded (0000), oral (00), overlong (011)\n    - /l/: pulmonic egressive (000), lateral approximant (01), alveolar (1000), voiced (0110), no coarticulation (00010)\n    - /d/: pulmonic egressive (000), plosive (00), alveolar (0001), voiced (1001), no coarticulation (00010)\n\n- Find the sound that corresponds to each combination of feature values using the IPA chart and the feature values:\n\n  - Hello: /h/ /\u025b/ /l/ /o\u028a/\n  - World: /w/ /\u025c\u02d0/ /l/ /d/\n\n- Write the sounds using IPA symbols or orthographic symbols:\n\n  - Hello: /h\u025blo\u028a/ or hello\n  - World: /w\u025c\u02d0ld/ or world", "author_fullname": "t2_d1l6mocox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Experimental Phonetics to Binary Encoding System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145y56v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686397622.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686397432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This encoding system claim that it can state all IPA symbols and its pronounciation in a Binary format &lt;/p&gt;\n\n&lt;p&gt;PhonBinary Encoding System V6&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Analyzes each sound into its featural components to translate into binary. &lt;/li&gt;\n&lt;li&gt;Features are encoded using a variable number of bits based on the number of possibilities for each feature.&lt;/li&gt;\n&lt;li&gt;Enables representation of the full IPA  to use in various NLP applications. &lt;/li&gt;\n&lt;li&gt;Includes all manners of articulation, secondary articulations, prosodic features, airstream mechanisms and vowel qualities.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Sound Analysis:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The first step involves analyzing each sound into its featural components. &lt;/li&gt;\n&lt;li&gt;Full understanding of the IPA and phonetic terminology required.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Consonants:\n- Produced by modifying airstream with articulators. \n- Factors: airstream mechanism (3 bits), manner of articulation (5 bits), place of articulation (6 bits), phonation (4 bits), coarticulation (5 bits).&lt;/p&gt;\n\n&lt;p&gt;Airstream mechanism (3 bits):\n- Pulmonic egressive: 000 \n- Pulmonic ingressive: 001\n- Glottalic egressive: 010\n- Glottalic ingressive: 011\n- Lingual-glottalic: 100\n- Velaric: 101 &lt;/p&gt;\n\n&lt;p&gt;Manner of articulation (5 bits):\n- Plosive: 00000&lt;br/&gt;\n- Nasal: 00001\n- Trill: 00010\n- Tap: 00011\n- Fricative: 00100\n- Approximant: 00101\n- Lateral approximant: 00110\n- Flap: 00111\n- Affricate: 01000 \n- Clitic: 01001&lt;br/&gt;\n- Implosive  01010\n- Ejective: 01011\n- Click: 01100&lt;/p&gt;\n\n&lt;p&gt;Place of articulation (6 bits): \n- Bilabial: 000000 \n- Labiodental: 000001\n- Interdental: 000010\n- Alveolar: 000011 \n- Postalveolar: 000100\n- Retroflex: 000101\n- Palatal: 000110\n- Velar: 000111 \n- Uvular: 001000\n- Pharyngeal: 001001&lt;br/&gt;\n- Glottal: 001010 \n- Epiglottal: 001011\n- Labial-palatal: 001100\n- Labial-velar: 001101 \n- Labial-uvular: 001110\n- Velar-pharyngeal: 001111\n- Velar-uvular: 010000&lt;br/&gt;\n- Velar-epilaryngeal: 010001\n- Uvular-pharyngeal : 010010&lt;/p&gt;\n\n&lt;p&gt;Phonation (4 bits):\n- Voiceless: 0000\n- Voiced: 0001&lt;br/&gt;\n- Creaky: 0010 \n- Breathy: 0011\n- Slack: 0100\n- Stiff: 0101\n- Creaky voiced: 0110\n- Whispered: 0111&lt;br/&gt;\n- Harsh: 1000 \n- Laryngealized : 1001\n- Closed glottis: 1010\n- Velaric aspiration: 1011&lt;/p&gt;\n\n&lt;p&gt;Vowels:\n- Produced by shaping airstream resonated through oral and nasal cavities. \n- Factors: height (4 bits), backness (4 bits), roundness (4 bits), nasalization (2 bits), length (3 bits). &lt;/p&gt;\n\n&lt;p&gt;Height (4 bits):\n- Close: 0000\n- Near-close: 0001&lt;br/&gt;\n- Close-mid: 0010&lt;br/&gt;\n- Mid: 0011\n- Open-mid: 0100 \n- Near-open: 0101&lt;br/&gt;\n- Open: 0110&lt;/p&gt;\n\n&lt;p&gt;Backness(4 bits):\n- Front: 0000\n- Near-front: 0001\n- Central: 0010&lt;br/&gt;\n- Near-back: 0011\n- Back: 0100 \n- Near-central: 0101&lt;/p&gt;\n\n&lt;p&gt;Roundness (4 bits):\n- Unrounded: 0000&lt;br/&gt;\n- Rounded: 0001\n- Compressed: 0010\n- Protruded: 0011\n- More rounded: 0100\n- Less rounded: 0101&lt;/p&gt;\n\n&lt;p&gt;Tenseness  (3 bits):\n- Extra-short: 000 \n- Short: 001\n- Long: 010&lt;br/&gt;\n- Overlong: 011&lt;/p&gt;\n\n&lt;p&gt;Nasalization (2 bits):\n- Oral: 00\n- Nasal: 01\n- Nasalized: 10\n- Denasalized: 11&lt;/p&gt;\n\n&lt;p&gt;Secondary articulations, prosodic features,  diacritics and delimiters will also be included with variable bit encoding. Morphological information  can be  added as an additional layer of information.&lt;/p&gt;\n\n&lt;p&gt;Delimiters:\nMorpheme boundary (+)\nWord boundary (#)\nSyllable boundary (-)\nStress boundary (*)\nIntonation boundary ( ^ )\nProcess boundary (%)&lt;/p&gt;\n\n&lt;p&gt;Encoding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Analyze each sound into its featural components using the IPA chart and the feature values given in the question.&lt;/li&gt;\n&lt;li&gt;Arrange the features in a consistent order for consonants (airstream mechanism \u2192 manner \u2192 place \u2192 phonation \u2192 coarticulation)  and vowels (height \u2192 backness \u2192 roundness  \u2192 nasalization \u2192 length).&lt;/li&gt;\n&lt;li&gt;Concatenate the binary codes for each feature to form the binary code for each sound.&lt;/li&gt;\n&lt;li&gt;Concatenate the binary codes for each sound to form the binary code for each word.&lt;/li&gt;\n&lt;li&gt;Use delimiters to mark boundaries between words, syllables and morphemes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Decoding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Use delimiters to identify boundaries between words, syllables and morphemes.&lt;/li&gt;\n&lt;li&gt;Split the binary code for each word into segments of variable length based on the number of bits for each feature.&lt;/li&gt;\n&lt;li&gt;Identify the feature values for each segment using the feature values given in the question.&lt;/li&gt;\n&lt;li&gt;Identify the sound corresponding to each segment using the IPA chart and the feature values.&lt;/li&gt;\n&lt;li&gt;Write the sounds using IPA symbols or orthographic symbols.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Hello World&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Encoding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Analyze each sound into its featural components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;/h/: pulmonic egressive, fricative, glottal, voiceless, no coarticulation&lt;/li&gt;\n&lt;li&gt;/\u025b/: open-mid, front, unrounded, oral, short&lt;/li&gt;\n&lt;li&gt;/l/: pulmonic egressive, lateral approximant, alveolar, voiced, no coarticulation&lt;/li&gt;\n&lt;li&gt;/o\u028a/: close-mid, back, rounded, oral, long&lt;/li&gt;\n&lt;li&gt;/w/: pulmonic egressive, approximant, labial-velar, voiced, no coarticulation&lt;/li&gt;\n&lt;li&gt;/\u025c\u02d0/: mid, central, unrounded, oral, overlong&lt;/li&gt;\n&lt;li&gt;/l/: pulmonic egressive, lateral approximant, alveolar, voiced, no coarticulation&lt;/li&gt;\n&lt;li&gt;/d/: pulmonic egressive, plosive, alveolar, voiced, no coarticulation&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Arrange the features in a consistent order and concatenate the binary codes for each feature:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;/h/: 000001000010100000000000&lt;/li&gt;\n&lt;li&gt;/\u025b/: 010000000000000001&lt;/li&gt;\n&lt;li&gt;/l/: 0000010110000110000100000&lt;/li&gt;\n&lt;li&gt;/o\u028a/: 001001010001000010&lt;/li&gt;\n&lt;li&gt;/w/: 0000010100111101000100000&lt;/li&gt;\n&lt;li&gt;/\u025c\u02d0/: 001100010000000011&lt;/li&gt;\n&lt;li&gt;/l/: 0000010110000110000100000&lt;/li&gt;\n&lt;li&gt;/d/: 0000000000011001000100000&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Concatenate the binary codes for each sound and use delimiters to mark boundaries:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello: 000001000010100000000000#010000000000000001#-#0000010110000110000100000#001001010001000010#&lt;/li&gt;\n&lt;li&gt;World: 0000010100111101000100000#-#001100010000000011#-#0000010110000110000100000#-#0000000000011001000100000#&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Decoding:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Identify the boundaries between words, syllables and morphemes using the delimiters:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello: [h][\u025b]-[l][o\u028a]&lt;/li&gt;\n&lt;li&gt;World: [w]-[\u025c\u02d0]-[l]-[d]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Divide the binary code for each word into chunks of bits corresponding to each feature:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello: [3][5][6][4][5]-[4][4][4][2][3]-[3][5][6][4][5]-[4][4][4][2][3]&lt;/li&gt;\n&lt;li&gt;[h]: [000] [00] [010] [1000] [00000]&lt;/li&gt;\n&lt;li&gt;[\u025b]: [0100] [0000] [0000] [00] [001]&lt;/li&gt;\n&lt;li&gt;[l]: [000] [01] [1000] [0110] [00010]&lt;/li&gt;\n&lt;li&gt;[o\u028a]:[0010] [0100] [0100] [00] [010]&lt;/li&gt;\n&lt;li&gt;World: [3][5][6][4][5]-[4][4][4][2][3]-[3][5][6][4][5]-[3][5][6][4][5]&lt;/li&gt;\n&lt;li&gt;[w]: [000] [01] [0011] [1101] [00010]&lt;/li&gt;\n&lt;li&gt;[\u025c\u02d0]:[0011] [0001] [0000] [00] [011]&lt;/li&gt;\n&lt;li&gt;[l]: [000] [01] [1000] [0110] [00010]&lt;/li&gt;\n&lt;li&gt;[d]: [000] [00] [0001] [1001] [00010]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Match each chunk of bits with the feature value given in the question:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello:&lt;/li&gt;\n&lt;li&gt;/h/: pulmonic egressive (000), fricative (00), glottal (010), voiceless (1000), no coarticulation (00000)&lt;/li&gt;\n&lt;li&gt;/\u025b/: open-mid (0100), front (0000), unrounded (0000), oral (00), short (001)&lt;/li&gt;\n&lt;li&gt;/l/: pulmonic egressive (000), lateral approximant (01), alveolar (1000), voiced (0110), no coarticulation (00010)&lt;/li&gt;\n&lt;li&gt;/o\u028a/: close-mid (0010), back (0100), rounded (0100), oral (00), long (010)&lt;/li&gt;\n&lt;li&gt;World:&lt;/li&gt;\n&lt;li&gt;/w/: pulmonic egressive (000), approximant (01), labial-velar (0011), voiced (1101), no coarticulation (00010)&lt;/li&gt;\n&lt;li&gt;/\u025c\u02d0/: mid (0011), central (0001), unrounded (0000), oral (00), overlong (011)&lt;/li&gt;\n&lt;li&gt;/l/: pulmonic egressive (000), lateral approximant (01), alveolar (1000), voiced (0110), no coarticulation (00010)&lt;/li&gt;\n&lt;li&gt;/d/: pulmonic egressive (000), plosive (00), alveolar (0001), voiced (1001), no coarticulation (00010)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Find the sound that corresponds to each combination of feature values using the IPA chart and the feature values:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello: /h/ /\u025b/ /l/ /o\u028a/&lt;/li&gt;\n&lt;li&gt;World: /w/ /\u025c\u02d0/ /l/ /d/&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Write the sounds using IPA symbols or orthographic symbols:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Hello: /h\u025blo\u028a/ or hello&lt;/li&gt;\n&lt;li&gt;World: /w\u025c\u02d0ld/ or world&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145y56v", "is_robot_indexable": true, "report_reasons": null, "author": "B-acccount", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145y56v/my_experimental_phonetics_to_binary_encoding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145y56v/my_experimental_phonetics_to_binary_encoding/", "subreddit_subscribers": 922139, "created_utc": 1686397432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I've been working on a business analytics degree with the hopes of getting an MBA afterwards. But now as I get closer to finishing my MSBA, I realized I really like the data science part better. So I'm think of going after an MS in Data Science, specifically for the machine learning and artificial intelligence aspect of it. Any tips for it? Money is not a factor.", "author_fullname": "t2_903k40ag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business analytics to data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145nmjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686362656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working on a business analytics degree with the hopes of getting an MBA afterwards. But now as I get closer to finishing my MSBA, I realized I really like the data science part better. So I&amp;#39;m think of going after an MS in Data Science, specifically for the machine learning and artificial intelligence aspect of it. Any tips for it? Money is not a factor.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145nmjv", "is_robot_indexable": true, "report_reasons": null, "author": "Impossible-Cry-495", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145nmjv/business_analytics_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145nmjv/business_analytics_to_data_science/", "subreddit_subscribers": 922139, "created_utc": 1686362656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I found the model weight to a machine learning problem in the tar file but I need it in an h5 file format. What do I do? I only use TensorFlow. I'm unfamiliar with Pytorch, but the person wrote their model in Pytorch. Thanks for any help in advance.", "author_fullname": "t2_n76zm04c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tar file to h5 file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145lz0q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686357883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found the model weight to a machine learning problem in the tar file but I need it in an h5 file format. What do I do? I only use TensorFlow. I&amp;#39;m unfamiliar with Pytorch, but the person wrote their model in Pytorch. Thanks for any help in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145lz0q", "is_robot_indexable": true, "report_reasons": null, "author": "Crazy-Currency-8127", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145lz0q/tar_file_to_h5_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145lz0q/tar_file_to_h5_file/", "subreddit_subscribers": 922139, "created_utc": 1686357883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI tools for Excel/Google Sheets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1465gt8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2u5c1o7i", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ChatGPT", "selftext": "While vanilla ChatGPT is powerful, it's just not quite there as a spreadsheet tool. However, I've noticed quite a few AI tools powered by GPT recently that integrate with Excel or Google Sheets so I've spent the better half of this week trying them out. Here's my rundown on several of what I thought were the most useful tools:\n\n# Coefficient - Google Sheets\n\nThis one is a free extension and it works as a Google Sheets Add-on. Essentially there's several prompts you can use to use ChatGPT within your spreadsheet itself- I've listed a few examples below:\n\n    // Generates text using GPT\n    =GPTX(prompt) \n    \n    // Generates table of values based on prompt and headers\n    =GPTX_TABLE(prompt, [header_row])\n    \n    // Classifies text according to given labels\n    =GPTX_CLASSIFY(text, labels)\n    \n    // Converts text into a specific text format\n    =GPTX_FORMAT(text, language)\n    \n    // Extracts info from text\n    =GPTX_EXTRACT(text, info_to_extract) \n\nAlong with the prompts/formulas, Coefficient can also generate formulas, pivot tables, and charts for you from natural language. For example I can ask it to create a pie chart that shows the distribution of my expenses, or pviot tables based on what information I want to organize/summarize.\n\n# Flowshot.ai - Google Sheets\n\nLike Coefficient, you can use GPT inside your spreadsheet however it also allows you to autocomplete/fill cells using AI, without needing to use formulas. It also allows you to train custom AI models using your own spreadsheet data and use it for the autocomplete feature or deploy it with Zapier or API. This one is also an add-on for Google Sheets and you get 100k characters for free.\n\n# SheetAI - Google Sheets\n\nAlternative to Coefficient for using GPT inside your spreadsheet. Available as Google Sheets add-on and you get 50 free generations a month, however you have to use your own OpenAI API key.\n\n# GPT for Sheets and Docs\n\nAnother great alternative to Coefficient. Note this one works with Google Docs as well as a writing co-pilot. It's a free add-on however you do have to use your own API key like SheetAI.\n\n# AskCSV - CSV and TSV files\n\nA free web app you can use to chat with your dataset and gain insights/analysis. As a very simple example, if I had a dataset of survey results with educational attainment and income, I could ask the chatbot to plot something where it compares the Income by Education and tell me insights about this. It will also give you questions and ideas to explore your data further. It's available as a web app and you get 5 generations a day for free. ***According to their website*** the data storage and analysis is only done on your browser and not sent to a server.\n\n# Zia - Zoho Sheet\n\nZia comes with Zoho Sheet and is basically an AI assistant for your data. You can use it to generate charts, pivot tables, and use it for data analysis questions. Works as a web and mobile app however you or your organization needs to be on a WorkDrive plan to use it.\n\n# Excelformulabot - Excel &amp; Google Sheets\n\nExcellent formula generator that does VBA, Regex, and Google Apps scripts as well. You could use ChatGPT to do this however it makes generating formulas a lot faster since they have preset prompts and you don't have to switch tabs. It's available as a web app as well as Excel &amp; Google Sheets add-on. It's a paid service but you get a limited number of generations for free each month.\n\n# Ajelix - Excel &amp; Google Sheets\n\nThis one is like Excelformulabot on steroids- except it can also generate entire Excel spreadsheets based on your description. Works both as a web app and plugin for Sheets &amp; Excel and has a free plan with limited generations.\n\n# Arcwise - Google Sheets\n\nGreat overall AI assistant for Google sheets. Like Excelformulabot and Ajelix, it functions as a formula copilot however it has a simple built in function to clean/extract data. However what really set it apart for me is its ability to answer questions regarding a spreadsheet. For example, you can ask it to explain outputs and calculation interdependencies. This one is a free Chrome extension.\n\nDon't want to sound like a broken record- but use these tools with sensitive data at your own risk. If your using this for work obviously be smart about it.\n\n\\---\n\n**P.S. If you liked this,** I've created a [free directory](https://aiscout.net/) with over 1000 AI tools listed for almost any use case. It's updated daily and there's also a GPT-powered chatbot to help you find AI tools for your needs. Feel free to check it out if there's something specific you are looking for.", "author_fullname": "t2_a12an6q01", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Tools to use GPT with Excel/Google Sheets", "link_flair_richtext": [{"e": "text", "t": "Resources "}], "subreddit_name_prefixed": "r/ChatGPT", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1459tt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1136, "total_awards_received": 4, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resources ", "can_mod_post": false, "score": 1136, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686328111.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ChatGPT", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While vanilla ChatGPT is powerful, it&amp;#39;s just not quite there as a spreadsheet tool. However, I&amp;#39;ve noticed quite a few AI tools powered by GPT recently that integrate with Excel or Google Sheets so I&amp;#39;ve spent the better half of this week trying them out. Here&amp;#39;s my rundown on several of what I thought were the most useful tools:&lt;/p&gt;\n\n&lt;h1&gt;Coefficient - Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;This one is a free extension and it works as a Google Sheets Add-on. Essentially there&amp;#39;s several prompts you can use to use ChatGPT within your spreadsheet itself- I&amp;#39;ve listed a few examples below:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;// Generates text using GPT\n=GPTX(prompt) \n\n// Generates table of values based on prompt and headers\n=GPTX_TABLE(prompt, [header_row])\n\n// Classifies text according to given labels\n=GPTX_CLASSIFY(text, labels)\n\n// Converts text into a specific text format\n=GPTX_FORMAT(text, language)\n\n// Extracts info from text\n=GPTX_EXTRACT(text, info_to_extract) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Along with the prompts/formulas, Coefficient can also generate formulas, pivot tables, and charts for you from natural language. For example I can ask it to create a pie chart that shows the distribution of my expenses, or pviot tables based on what information I want to organize/summarize.&lt;/p&gt;\n\n&lt;h1&gt;Flowshot.ai - Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;Like Coefficient, you can use GPT inside your spreadsheet however it also allows you to autocomplete/fill cells using AI, without needing to use formulas. It also allows you to train custom AI models using your own spreadsheet data and use it for the autocomplete feature or deploy it with Zapier or API. This one is also an add-on for Google Sheets and you get 100k characters for free.&lt;/p&gt;\n\n&lt;h1&gt;SheetAI - Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;Alternative to Coefficient for using GPT inside your spreadsheet. Available as Google Sheets add-on and you get 50 free generations a month, however you have to use your own OpenAI API key.&lt;/p&gt;\n\n&lt;h1&gt;GPT for Sheets and Docs&lt;/h1&gt;\n\n&lt;p&gt;Another great alternative to Coefficient. Note this one works with Google Docs as well as a writing co-pilot. It&amp;#39;s a free add-on however you do have to use your own API key like SheetAI.&lt;/p&gt;\n\n&lt;h1&gt;AskCSV - CSV and TSV files&lt;/h1&gt;\n\n&lt;p&gt;A free web app you can use to chat with your dataset and gain insights/analysis. As a very simple example, if I had a dataset of survey results with educational attainment and income, I could ask the chatbot to plot something where it compares the Income by Education and tell me insights about this. It will also give you questions and ideas to explore your data further. It&amp;#39;s available as a web app and you get 5 generations a day for free. &lt;strong&gt;&lt;em&gt;According to their website&lt;/em&gt;&lt;/strong&gt; the data storage and analysis is only done on your browser and not sent to a server.&lt;/p&gt;\n\n&lt;h1&gt;Zia - Zoho Sheet&lt;/h1&gt;\n\n&lt;p&gt;Zia comes with Zoho Sheet and is basically an AI assistant for your data. You can use it to generate charts, pivot tables, and use it for data analysis questions. Works as a web and mobile app however you or your organization needs to be on a WorkDrive plan to use it.&lt;/p&gt;\n\n&lt;h1&gt;Excelformulabot - Excel &amp;amp; Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;Excellent formula generator that does VBA, Regex, and Google Apps scripts as well. You could use ChatGPT to do this however it makes generating formulas a lot faster since they have preset prompts and you don&amp;#39;t have to switch tabs. It&amp;#39;s available as a web app as well as Excel &amp;amp; Google Sheets add-on. It&amp;#39;s a paid service but you get a limited number of generations for free each month.&lt;/p&gt;\n\n&lt;h1&gt;Ajelix - Excel &amp;amp; Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;This one is like Excelformulabot on steroids- except it can also generate entire Excel spreadsheets based on your description. Works both as a web app and plugin for Sheets &amp;amp; Excel and has a free plan with limited generations.&lt;/p&gt;\n\n&lt;h1&gt;Arcwise - Google Sheets&lt;/h1&gt;\n\n&lt;p&gt;Great overall AI assistant for Google sheets. Like Excelformulabot and Ajelix, it functions as a formula copilot however it has a simple built in function to clean/extract data. However what really set it apart for me is its ability to answer questions regarding a spreadsheet. For example, you can ask it to explain outputs and calculation interdependencies. This one is a free Chrome extension.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t want to sound like a broken record- but use these tools with sensitive data at your own risk. If your using this for work obviously be smart about it.&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. If you liked this,&lt;/strong&gt; I&amp;#39;ve created a &lt;a href=\"https://aiscout.net/\"&gt;free directory&lt;/a&gt; with over 1000 AI tools listed for almost any use case. It&amp;#39;s updated daily and there&amp;#39;s also a GPT-powered chatbot to help you find AI tools for your needs. Feel free to check it out if there&amp;#39;s something specific you are looking for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?auto=webp&amp;v=enabled&amp;s=04cdf591f6815ce8deb90a3e4ffae7ba454d249e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20000c576ef7c106e8e5cc3b02b566ec45759e35", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=868b10488dddd77106d6ee0bbc4bb6499de1a64f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=270984fa58d1a57a90df9ff788cf753e41cc8a1a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0baa55f84564a184a3acdd93672bf7aff92a3b60", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efaeb9e2f744d1f2c4359b05590e6ca40b001291", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cec84d601c33a898248e8ca14254c973370514b1", "width": 1080, "height": 607}], "variants": {}, "id": "A-eQ3J32nUFfJaKEDoNNYiT2VDRppiycWWRtZ-chcq0"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_a67d649d-5aa5-407e-a98b-32fd9e3a9696", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "The more you know... Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Today I Learned", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=c670b7d7bc99c03bffde92706ad5ceeda12658f3", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=63a498673bd4a518a031783179a767cc4135d5f5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8802df47965bd66370b72ac3cb7639e9eae92ae", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=fc40ae1c1a18193f190da70a2748d0a48c17a5a9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=77ba4d8e862ca183dd8c09e002fd123a6b2f52f5", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=c670b7d7bc99c03bffde92706ad5ceeda12658f3", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=63a498673bd4a518a031783179a767cc4135d5f5", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8802df47965bd66370b72ac3cb7639e9eae92ae", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=fc40ae1c1a18193f190da70a2748d0a48c17a5a9", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=77ba4d8e862ca183dd8c09e002fd123a6b2f52f5", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=25880d00e4283ff6a3851b64c83fea465c3fac48", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=67fae0c2af26488b9d70cb7afe877086707cf1d1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=3033c6583809a27b998883b7c56c158102cb0420", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=cccb48d7518eaba72894a7ac4214bb70c7120793", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=4101e0eff424bbd818195853387db358bec74ed0", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "c8a7075c-9962-11ed-86d0-b2c48b46bf22", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_7hqomg", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#373c3f", "id": "1459tt1", "is_robot_indexable": true, "report_reasons": null, "author": "AI_Scout_Official", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ChatGPT/comments/1459tt1/tools_to_use_gpt_with_excelgoogle_sheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/ChatGPT/comments/1459tt1/tools_to_use_gpt_with_excelgoogle_sheets/", "subreddit_subscribers": 2010597, "created_utc": 1686328111.0, "num_crossposts": 5, "media": null, "is_video": false}], "created": 1686416830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.ChatGPT", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/ChatGPT/comments/1459tt1/tools_to_use_gpt_with_excelgoogle_sheets/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?auto=webp&amp;v=enabled&amp;s=04cdf591f6815ce8deb90a3e4ffae7ba454d249e", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20000c576ef7c106e8e5cc3b02b566ec45759e35", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=868b10488dddd77106d6ee0bbc4bb6499de1a64f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=270984fa58d1a57a90df9ff788cf753e41cc8a1a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0baa55f84564a184a3acdd93672bf7aff92a3b60", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efaeb9e2f744d1f2c4359b05590e6ca40b001291", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/blYDgdvS6ArVk1sdgBtW4GHJScIzVRYSiWku_qVF7Gw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cec84d601c33a898248e8ca14254c973370514b1", "width": 1080, "height": 607}], "variants": {}, "id": "A-eQ3J32nUFfJaKEDoNNYiT2VDRppiycWWRtZ-chcq0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1465gt8", "is_robot_indexable": true, "report_reasons": null, "author": "safwanadnan19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1459tt1", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1465gt8/ai_tools_for_excelgoogle_sheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/ChatGPT/comments/1459tt1/tools_to_use_gpt_with_excelgoogle_sheets/", "subreddit_subscribers": 922139, "created_utc": 1686416830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a23h93a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the 2023 raises and bonuses thread up yet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14627hr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686408566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14627hr", "is_robot_indexable": true, "report_reasons": null, "author": "BlackPlasmaX", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14627hr/is_the_2023_raises_and_bonuses_thread_up_yet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14627hr/is_the_2023_raises_and_bonuses_thread_up_yet/", "subreddit_subscribers": 922139, "created_utc": 1686408566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I graduated from a more lax business-oriented data science degree a few years back and then worked in the industry. But the work, like many of you report, was mostly BI, politics, BS, power-points, some old ML models, some data engineering, etc. Not much time spent with real ML problems or research. Haven't read the latest papers, haven't even touched PyTorch or Tensorfow in over 2y. I feel like I am super behind everything and want to get back in the game. I need urgent advice on how to become more aware of current trends and how to do some practical work that I can show off. I am under the impression that I can learn model architectures but really I can't hope to cheaply train or tune anything by myself. So I was thinking, what do most people actually do to execute some DIY ML projects? Do you use model weights and embeddings from platforms like HuggingFace? How do you stay up to date with the news? What would you recommend I do a few hours a week for someone who knows stuff but not really?   ", "author_fullname": "t2_genrcwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get up to Data with SOTA DL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145tdqk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686381239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated from a more lax business-oriented data science degree a few years back and then worked in the industry. But the work, like many of you report, was mostly BI, politics, BS, power-points, some old ML models, some data engineering, etc. Not much time spent with real ML problems or research. Haven&amp;#39;t read the latest papers, haven&amp;#39;t even touched PyTorch or Tensorfow in over 2y. I feel like I am super behind everything and want to get back in the game. I need urgent advice on how to become more aware of current trends and how to do some practical work that I can show off. I am under the impression that I can learn model architectures but really I can&amp;#39;t hope to cheaply train or tune anything by myself. So I was thinking, what do most people actually do to execute some DIY ML projects? Do you use model weights and embeddings from platforms like HuggingFace? How do you stay up to date with the news? What would you recommend I do a few hours a week for someone who knows stuff but not really?   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145tdqk", "is_robot_indexable": true, "report_reasons": null, "author": "nacho_biznis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145tdqk/get_up_to_data_with_sota_dl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145tdqk/get_up_to_data_with_sota_dl/", "subreddit_subscribers": 922139, "created_utc": 1686381239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've just completed my first year in bachelor's data science, but I haven't worked on a real world data, so I haven't seen how I do practically without guidance can you guys telle where I can get data for practice and also what to do with it.", "author_fullname": "t2_flfng4ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real world data practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145qzgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686373210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just completed my first year in bachelor&amp;#39;s data science, but I haven&amp;#39;t worked on a real world data, so I haven&amp;#39;t seen how I do practically without guidance can you guys telle where I can get data for practice and also what to do with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145qzgm", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky-Top3782", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145qzgm/real_world_data_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145qzgm/real_world_data_practice/", "subreddit_subscribers": 922139, "created_utc": 1686373210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If you were asked to pick how you wanted to be interviewed for a DS/ML role knowing that other candidates were given the same option what steps would you pick?", "author_fullname": "t2_5bfewy53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview - Pick Your Own Adventure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_145odga", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686364892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were asked to pick how you wanted to be interviewed for a DS/ML role knowing that other candidates were given the same option what steps would you pick?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "145odga", "is_robot_indexable": true, "report_reasons": null, "author": "hownottopetacat", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/145odga/interview_pick_your_own_adventure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/145odga/interview_pick_your_own_adventure/", "subreddit_subscribers": 922139, "created_utc": 1686364892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Check it out.   \n[The Data Trend](https://twitter.com/The_Data_Trend)", "author_fullname": "t2_b0yxowhs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found this Twitter page for Data Science and Machine Learning news, memes and updates.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1464ed0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686414183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check it out.&lt;br/&gt;\n&lt;a href=\"https://twitter.com/The_Data_Trend\"&gt;The Data Trend&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mweMiAud3dRpl_1hGIw-ngmTx1YtB_XjmdNPdcUdy_U.jpg?auto=webp&amp;v=enabled&amp;s=b317b757dd20c1540a217fbc014b11be74d9ce21", "width": 48, "height": 48}, "resolutions": [], "variants": {}, "id": "Ppn8lQdRHSLk2n7yFevfF4XxKFit9zpleSrj5_PJxTo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1464ed0", "is_robot_indexable": true, "report_reasons": null, "author": "Roomour5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1464ed0/found_this_twitter_page_for_data_science_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1464ed0/found_this_twitter_page_for_data_science_and/", "subreddit_subscribers": 922139, "created_utc": 1686414183.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}