{"kind": "Listing", "data": {"after": "t3_14l4o9f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am having interviews to hire someone who will work for me. I interviewed two people so far. Neither of them answered on questions:\n\n&amp;#x200B;\n\n1. OLAP and OLTP systems\n2. Star Schema vs. Cube\n3. ETL vs. ELT\n4. Window function SQL question\n\n&amp;#x200B;\n\nIt is a position for 3+ years in data analytics, business intelligence, or a related field and I didn't expect to get the full extent of complete answers. Am I asking too difficult questions? or am I becoming out of touch and those aren't relevant anymore?\n\n&amp;#x200B;\n\nEdit: I didn't really make it clear what the role is for. The role is BI Engineer, but the candidates that the head hunter sent to our HR manager happened to have a data analyst background. ", "author_fullname": "t2_oxibh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these terms irrelevant in the industry anymore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kra4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687953754.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687903985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having interviews to hire someone who will work for me. I interviewed two people so far. Neither of them answered on questions:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;OLAP and OLTP systems&lt;/li&gt;\n&lt;li&gt;Star Schema vs. Cube&lt;/li&gt;\n&lt;li&gt;ETL vs. ELT&lt;/li&gt;\n&lt;li&gt;Window function SQL question&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It is a position for 3+ years in data analytics, business intelligence, or a related field and I didn&amp;#39;t expect to get the full extent of complete answers. Am I asking too difficult questions? or am I becoming out of touch and those aren&amp;#39;t relevant anymore?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I didn&amp;#39;t really make it clear what the role is for. The role is BI Engineer, but the candidates that the head hunter sent to our HR manager happened to have a data analyst background. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14kra4i", "is_robot_indexable": true, "report_reasons": null, "author": "Bloodylime", "discussion_type": null, "num_comments": 92, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kra4i/are_these_terms_irrelevant_in_the_industry_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kra4i/are_these_terms_irrelevant_in_the_industry_anymore/", "subreddit_subscribers": 112787, "created_utc": 1687903985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3kxbd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake and NVIDIA partner to let businesses use their own data to build custom AIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14khz2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "#46d160", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/atjVKtqBAcuD2hYMHyOhp0zO0Tqz6CaM0EYTqNChE5c.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687882530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "siliconangle.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://siliconangle.com/2023/06/26/snowflake-nvidia-partner-let-businesses-use-data-build-custom-ais/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?auto=webp&amp;v=enabled&amp;s=1694c0da80a7280adde7a6cd11f9f5e63ab094d8", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4ac16fb05afde3a6d8b66c5c0c333864754cc25", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d39af5ace4b1d59bb35ad166beec028ce0a9f2f0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=050033972ecb64ddbdc27bbfb180bc1d4763130a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=252e51196f6cd50870736335ffbd9c47e9d6514f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9c82f2e77d09bd2cd458af93e4bdc19d4253919", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ai3OkLm6AS8nBk3M6GTInbP4bBnSJqVUId4bMsOrQ4A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=500b029ebae340277138106ae1d316dde6443b1e", "width": 1080, "height": 607}], "variants": {}, "id": "ThGtxO58yFnUlZH49TLbpinGxphltYTSu9rYVOyFbhE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "honorary mod | Snowflake", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14khz2i", "is_robot_indexable": true, "report_reasons": null, "author": "fhoffa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/14khz2i/snowflake_and_nvidia_partner_to_let_businesses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://siliconangle.com/2023/06/26/snowflake-nvidia-partner-let-businesses-use-data-build-custom-ais/", "subreddit_subscribers": 112787, "created_utc": 1687882530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking about the future of data engineering and what kind of learning path I would suggest to someone breaking into the industry.\n\nDatabricks + Snowflake seems to be providing a ton of value by giving us a platform to focus on data engineering (instead of configuration, connecting tools, etc.). \n\nHowever, I don't see adoption at the holy-grail big data FAANG companies. From looking at their job descriptions, these companies are still using tools within the Hadoop ecosystem. \n\nThis makes me wonder if it is the small number of \"big data\" companies keeping the Hadoop ecosystem alive as the industry tries to move forward and simplify. Or why haven't they also adopted platforms like Databricks or Snowflake. I get these tools would be costly given the vast amounts of data, but I would imagine that there would also be a ton of savings on engineer hours. \n\nIs the future of DE platforms like Databricks? Do we only care about the Hadoop-ecosystem because of a few large companies who haven't figured out how to adopt these platforms in a cost-effective way?\n\n&amp;#x200B;", "author_fullname": "t2_7iitruic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform Adoption and FAANG Companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ksgkm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687906844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking about the future of data engineering and what kind of learning path I would suggest to someone breaking into the industry.&lt;/p&gt;\n\n&lt;p&gt;Databricks + Snowflake seems to be providing a ton of value by giving us a platform to focus on data engineering (instead of configuration, connecting tools, etc.). &lt;/p&gt;\n\n&lt;p&gt;However, I don&amp;#39;t see adoption at the holy-grail big data FAANG companies. From looking at their job descriptions, these companies are still using tools within the Hadoop ecosystem. &lt;/p&gt;\n\n&lt;p&gt;This makes me wonder if it is the small number of &amp;quot;big data&amp;quot; companies keeping the Hadoop ecosystem alive as the industry tries to move forward and simplify. Or why haven&amp;#39;t they also adopted platforms like Databricks or Snowflake. I get these tools would be costly given the vast amounts of data, but I would imagine that there would also be a ton of savings on engineer hours. &lt;/p&gt;\n\n&lt;p&gt;Is the future of DE platforms like Databricks? Do we only care about the Hadoop-ecosystem because of a few large companies who haven&amp;#39;t figured out how to adopt these platforms in a cost-effective way?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ksgkm", "is_robot_indexable": true, "report_reasons": null, "author": "jduran9987", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ksgkm/data_platform_adoption_and_faang_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ksgkm/data_platform_adoption_and_faang_companies/", "subreddit_subscribers": 112787, "created_utc": 1687906844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you guys implementing the medallion architecture in unity catalog. \n\nWe currently have a dev and prod workspace with bronze, silver, gold catalogs in each. We also have external tables, and externally managed tables. \n\nI am the one architecting our databricks environment but have not found good documentation on the medallion architecture within unity catalog. Any advice is much appreciated!", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you implement the medallion pattern in databricks unity catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ku3ae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687910930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you guys implementing the medallion architecture in unity catalog. &lt;/p&gt;\n\n&lt;p&gt;We currently have a dev and prod workspace with bronze, silver, gold catalogs in each. We also have external tables, and externally managed tables. &lt;/p&gt;\n\n&lt;p&gt;I am the one architecting our databricks environment but have not found good documentation on the medallion architecture within unity catalog. Any advice is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ku3ae", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ku3ae/how_do_you_implement_the_medallion_pattern_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ku3ae/how_do_you_implement_the_medallion_pattern_in/", "subreddit_subscribers": 112787, "created_utc": 1687910930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those of you that work on or maintain a feature store, I'm curious how its managed.\n\n&amp;#x200B;\n\nAssuming you have centralized infrastructure for the store, do you have one core team that is developing and contributing features? Or do you allow the domain experts to create the feature pipelines and contribute the data to the store?\n\n&amp;#x200B;\n\nFor a large feature store, I am thinking it makes the most sense to have a central team manage the infrastructure of the store and act as gatekeepers to determine what does and doesn't get into the feature store. Then, develop contracts with the business teams who can create the features and contribute them into the store following the contract.\n\n&amp;#x200B;\n\nHow does your company manage it?", "author_fullname": "t2_7b45m4y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company manage feature stores?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kl55h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687889724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those of you that work on or maintain a feature store, I&amp;#39;m curious how its managed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Assuming you have centralized infrastructure for the store, do you have one core team that is developing and contributing features? Or do you allow the domain experts to create the feature pipelines and contribute the data to the store?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For a large feature store, I am thinking it makes the most sense to have a central team manage the infrastructure of the store and act as gatekeepers to determine what does and doesn&amp;#39;t get into the feature store. Then, develop contracts with the business teams who can create the features and contribute them into the store following the contract.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How does your company manage it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kl55h", "is_robot_indexable": true, "report_reasons": null, "author": "fithrowaway379", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kl55h/how_does_your_company_manage_feature_stores/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kl55h/how_does_your_company_manage_feature_stores/", "subreddit_subscribers": 112787, "created_utc": 1687889724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, I am annoyed.\n\nFour or five years ago, we signed up with Periscope Data for BI. Their package included some basic ELT &amp; warehousing infrastructure using Fivetran and Redshift. It was convenient (but not necessarily cost effective) to have our entire data stack managed by a single vendor, for a single price.\n\nFast forward a year and Periscope gets bought by Sisense. Sisense agreed to continue managing our whole stack, but each time we renewed our contract, they seemed more and more confused by the relationship with the other vendors, didn\u2019t know how Fivetran was supposed to get paid, stuff like that.\n\nSo this year, I see that Fivetran is now offering a free plan for customers who use less than 500K monthly active rows (MAR). We were just over that amount, and I saw an opportunity to lower our costs by reducing our usage. I checked in with Sisense and Fivetran to make sure I was thinking correctly - get under 500K MAR, and drop down to the free tier. Cut out the Fivetran portion of our spend.\n\nNow, just a couple days before we have to renew our contract with Sisense, they\u2019re telling me that *even though I have optimized our ELT process to get into Fivetran\u2019s free tier*, our bill to Sisense is *not going to decrease at all* and will actually go up the usual 5%.\n\nWhat a joke. In what world is a business - especially a small biz like ours (&lt;50 employees) going to pay *more* for the vendor to do *less*? If I can optimize our ELT, I\u2019ll bet I can optimize our BI as well, and Sisense can go pound sand.\n\nIs this the norm for vendors in the analytics space? Does anyone have any suggestions for more cost-effective BI solutions? I was playing around with Looker Studio today\u2026query times were pretty long for a dataset that only has about 200,000 records\u2026I have a call with Mode next week. Less than $5,000 a month would be good\u2026less than $2,500 a month would be even better.\n\n*Edit - 500K MAR, not 500. Sorry. Shouldn\u2019t post when tired.*", "author_fullname": "t2_b76ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran and Sisense: I am annoyed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kx9l2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687947241.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687919702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I am annoyed.&lt;/p&gt;\n\n&lt;p&gt;Four or five years ago, we signed up with Periscope Data for BI. Their package included some basic ELT &amp;amp; warehousing infrastructure using Fivetran and Redshift. It was convenient (but not necessarily cost effective) to have our entire data stack managed by a single vendor, for a single price.&lt;/p&gt;\n\n&lt;p&gt;Fast forward a year and Periscope gets bought by Sisense. Sisense agreed to continue managing our whole stack, but each time we renewed our contract, they seemed more and more confused by the relationship with the other vendors, didn\u2019t know how Fivetran was supposed to get paid, stuff like that.&lt;/p&gt;\n\n&lt;p&gt;So this year, I see that Fivetran is now offering a free plan for customers who use less than 500K monthly active rows (MAR). We were just over that amount, and I saw an opportunity to lower our costs by reducing our usage. I checked in with Sisense and Fivetran to make sure I was thinking correctly - get under 500K MAR, and drop down to the free tier. Cut out the Fivetran portion of our spend.&lt;/p&gt;\n\n&lt;p&gt;Now, just a couple days before we have to renew our contract with Sisense, they\u2019re telling me that &lt;em&gt;even though I have optimized our ELT process to get into Fivetran\u2019s free tier&lt;/em&gt;, our bill to Sisense is &lt;em&gt;not going to decrease at all&lt;/em&gt; and will actually go up the usual 5%.&lt;/p&gt;\n\n&lt;p&gt;What a joke. In what world is a business - especially a small biz like ours (&amp;lt;50 employees) going to pay &lt;em&gt;more&lt;/em&gt; for the vendor to do &lt;em&gt;less&lt;/em&gt;? If I can optimize our ELT, I\u2019ll bet I can optimize our BI as well, and Sisense can go pound sand.&lt;/p&gt;\n\n&lt;p&gt;Is this the norm for vendors in the analytics space? Does anyone have any suggestions for more cost-effective BI solutions? I was playing around with Looker Studio today\u2026query times were pretty long for a dataset that only has about 200,000 records\u2026I have a call with Mode next week. Less than $5,000 a month would be good\u2026less than $2,500 a month would be even better.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit - 500K MAR, not 500. Sorry. Shouldn\u2019t post when tired.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kx9l2", "is_robot_indexable": true, "report_reasons": null, "author": "Batspocky", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kx9l2/fivetran_and_sisense_i_am_annoyed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kx9l2/fivetran_and_sisense_i_am_annoyed/", "subreddit_subscribers": 112787, "created_utc": 1687919702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. \n\nI\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?", "author_fullname": "t2_5ah07udc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How complex is the coding in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2se5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687937371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2se5", "is_robot_indexable": true, "report_reasons": null, "author": "jimharbaughthrowaway", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "subreddit_subscribers": 112787, "created_utc": 1687937371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer with 3+ years of full time work experience in India and 1 year of experience in a full time internship in US.\n\nI have good skills in SQL, Python, ETL, Data warehousing, GCP, Snowflake and databricks. \n\nI have been applying for jobs for past 3 months now, but still not getting any calls. I have tried applying to jobs via LinkedIn/indeed, connecting with my ex managers and employers, cold emailing Hiring Managers etc.\n\nWhat am I doing wrong. What else can I do to get a job in this market", "author_fullname": "t2_7tah61j5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a job in this market??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kyy12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687924578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer with 3+ years of full time work experience in India and 1 year of experience in a full time internship in US.&lt;/p&gt;\n\n&lt;p&gt;I have good skills in SQL, Python, ETL, Data warehousing, GCP, Snowflake and databricks. &lt;/p&gt;\n\n&lt;p&gt;I have been applying for jobs for past 3 months now, but still not getting any calls. I have tried applying to jobs via LinkedIn/indeed, connecting with my ex managers and employers, cold emailing Hiring Managers etc.&lt;/p&gt;\n\n&lt;p&gt;What am I doing wrong. What else can I do to get a job in this market&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14kyy12", "is_robot_indexable": true, "report_reasons": null, "author": "Test_Known", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kyy12/how_to_get_a_job_in_this_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kyy12/how_to_get_a_job_in_this_market/", "subreddit_subscribers": 112787, "created_utc": 1687924578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cp1afbpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook data transfers declared illegal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14l4vx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W8uGyrlvQygFg_rRgAMqXpeLJ3YONTEx29NRiIgY6kE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687944975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "simpleanalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?auto=webp&amp;v=enabled&amp;s=4656d7a82bd341b62c92ae3ea737313ccf033fa4", "width": 1000, "height": 523}, "resolutions": [{"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3c3430786c5f80cb771c67a3759036191424d61", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef490707114127b18201183b737925a2d1aef3b6", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ebeae41cc50014b4dbda964f13017329b909e27", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e206fdb52dc4d73d477ec0cd93963175a4eac4d7", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bd40816e9cd524436e774f464dfcd8ac7d71c26", "width": 960, "height": 502}], "variants": {}, "id": "p4LUfDlJMgUcV_dAFYAKR_AN31ciT_2jgZfllIkmSX4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14l4vx6", "is_robot_indexable": true, "report_reasons": null, "author": "nulovyk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l4vx6/facebook_data_transfers_declared_illegal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "subreddit_subscribers": 112787, "created_utc": 1687944975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analyst/junior engineer.\n\nI\u2019ve built one pipeline using snowflake as a storage solution.\n\nShould I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).", "author_fullname": "t2_602r7p43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake or Databicks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l5wfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687948330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analyst/junior engineer.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve built one pipeline using snowflake as a storage solution.&lt;/p&gt;\n\n&lt;p&gt;Should I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l5wfj", "is_robot_indexable": true, "report_reasons": null, "author": "rolledthrough7578", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "subreddit_subscribers": 112787, "created_utc": 1687948330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen two scenarios of this topic.\n\n1. Ephemeral Landing Zone -&gt; append in Bronze as parquet -&gt; **Validate new/modified records** \\-&gt; Merge in Silver\n2. Ephemeral Landing Zone -&gt; **Validate new/modified records** \\-&gt; append in bronze as parquet-&gt; merge in silver\n\nThe argument for method #1 is that we just care about getting data into bronze as fast as possible and we don't care about the quality, structure, or validity of the data when appending to the bronze table. Only when we want to merge those new/changed records in silver, we should apply data contract validation.\n\nI understand that reasoning, but I feel like method #2 is better, no? why not validate with the contracts BEFORE appending to bronze? This way I am only appending validated data into bronze, which can just be merged into silver with no worries.\n\nWhat is your approach to data validation &amp; quality checks in your pipeline?\n\nAs always, thanks! :)", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to validate data / apply contracts in a data lake pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14knfzj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687895247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen two scenarios of this topic.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ephemeral Landing Zone -&amp;gt; append in Bronze as parquet -&amp;gt; &lt;strong&gt;Validate new/modified records&lt;/strong&gt; -&amp;gt; Merge in Silver&lt;/li&gt;\n&lt;li&gt;Ephemeral Landing Zone -&amp;gt; &lt;strong&gt;Validate new/modified records&lt;/strong&gt; -&amp;gt; append in bronze as parquet-&amp;gt; merge in silver&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The argument for method #1 is that we just care about getting data into bronze as fast as possible and we don&amp;#39;t care about the quality, structure, or validity of the data when appending to the bronze table. Only when we want to merge those new/changed records in silver, we should apply data contract validation.&lt;/p&gt;\n\n&lt;p&gt;I understand that reasoning, but I feel like method #2 is better, no? why not validate with the contracts BEFORE appending to bronze? This way I am only appending validated data into bronze, which can just be merged into silver with no worries.&lt;/p&gt;\n\n&lt;p&gt;What is your approach to data validation &amp;amp; quality checks in your pipeline?&lt;/p&gt;\n\n&lt;p&gt;As always, thanks! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14knfzj", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14knfzj/when_to_validate_data_apply_contracts_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14knfzj/when_to_validate_data_apply_contracts_in_a_data/", "subreddit_subscribers": 112787, "created_utc": 1687895247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. \n\nI created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he's being used as a reference). \n\nAfter that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it's always something talked about but as soon as you try to say something such as \"We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?\n\n...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?", "author_fullname": "t2_nw770", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else really frustrated with the additional responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l93wo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1687958109.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687957762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. &lt;/p&gt;\n\n&lt;p&gt;I created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he&amp;#39;s being used as a reference). &lt;/p&gt;\n\n&lt;p&gt;After that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it&amp;#39;s always something talked about but as soon as you try to say something such as &amp;quot;We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?&lt;/p&gt;\n\n&lt;p&gt;...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l93wo", "is_robot_indexable": true, "report_reasons": null, "author": "PeacefullyFighting", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "subreddit_subscribers": 112787, "created_utc": 1687957762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Databricks Data across Tenant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2esp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687935987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2esp", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "subreddit_subscribers": 112787, "created_utc": 1687935987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm attending the Databricks Data &amp; AI Summit in SF this year and I was shocked to find out that Salt n Pepa are performing at the big Data Party at Chase Party.\n\nJust curious, does anyone know if the Snowflake Summit in Vegas also have a similar performance? Looking to see who had the better accommodations/performers haha", "author_fullname": "t2_3x6pwgqwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and Snowflake Summit Performers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ktxs1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687910539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m attending the Databricks Data &amp;amp; AI Summit in SF this year and I was shocked to find out that Salt n Pepa are performing at the big Data Party at Chase Party.&lt;/p&gt;\n\n&lt;p&gt;Just curious, does anyone know if the Snowflake Summit in Vegas also have a similar performance? Looking to see who had the better accommodations/performers haha&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ktxs1", "is_robot_indexable": true, "report_reasons": null, "author": "nerdistheword88", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ktxs1/databricks_and_snowflake_summit_performers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ktxs1/databricks_and_snowflake_summit_performers/", "subreddit_subscribers": 112787, "created_utc": 1687910539.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're switching from on-prem to Synapse. \n\nOur current build stored procs, are getting switched over to Spark SQL notebooks.  Some of these build procs are truncate and inserts. \n\nDelta retains the history though -it's a soft delete, until vacuum is run anyway.  If say, a Delta file is getting truncate and insert every night:\n\n  * Is that an OK practice?\n  * What does that look like in the Delta file?  Say a 1,000 row table on Day 1, is then truncated and inserted, and no data changed. Is that now a 2,000 row table, with 1,000 'active' rows and 1,000 soft deleted ones?", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truncating Delta Tables - is that wise? (Ignorant Q)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kte7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687909158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re switching from on-prem to Synapse. &lt;/p&gt;\n\n&lt;p&gt;Our current build stored procs, are getting switched over to Spark SQL notebooks.  Some of these build procs are truncate and inserts. &lt;/p&gt;\n\n&lt;p&gt;Delta retains the history though -it&amp;#39;s a soft delete, until vacuum is run anyway.  If say, a Delta file is getting truncate and insert every night:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is that an OK practice?&lt;/li&gt;\n&lt;li&gt;What does that look like in the Delta file?  Say a 1,000 row table on Day 1, is then truncated and inserted, and no data changed. Is that now a 2,000 row table, with 1,000 &amp;#39;active&amp;#39; rows and 1,000 soft deleted ones?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14kte7b", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kte7b/truncating_delta_tables_is_that_wise_ignorant_q/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kte7b/truncating_delta_tables_is_that_wise_ignorant_q/", "subreddit_subscribers": 112787, "created_utc": 1687909158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm second guessing my understanding here: if pyspark is used to read a table from a remote DB (with something like J/ODBC connections) and some transformation is done to the data, is the compute used to perform that transformation sourced from the database servers storing the data or from the executor nodes?  Does the answer change if it is a local spark session instead of a cluster, or if the transformation is provided purely as a sql query?", "author_fullname": "t2_15slf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does computation occur with Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kplh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687900292.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687900072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m second guessing my understanding here: if pyspark is used to read a table from a remote DB (with something like J/ODBC connections) and some transformation is done to the data, is the compute used to perform that transformation sourced from the database servers storing the data or from the executor nodes?  Does the answer change if it is a local spark session instead of a cluster, or if the transformation is provided purely as a sql query?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kplh3", "is_robot_indexable": true, "report_reasons": null, "author": "JustAnotherMortalMan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kplh3/where_does_computation_occur_with_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kplh3/where_does_computation_occur_with_spark/", "subreddit_subscribers": 112787, "created_utc": 1687900072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I've been facing a challenge at my job recently and could use a product recommendation. I'm the only data engineer at a small startup, and I spend a lot of my time preparing and formatting reports for our executives. Our execs aren't technical, so they can only view data in the form of a filterable spreadsheet. We use Airtable for this, and it works decently, but has serious issues. Firstly, it has a max table size of 100k records, so some requests that exceed that are impossible for us to send in one report. It also doesn't have live querying capabilities for quick iteration if the original spec wasn't 100%.\n\nI'd love to hear recommendations for data visualization tools that are flexible to use, can connect to and query from standard data warehouses (we use BigQuery mostly), and most importantly can produce reports that are filterable by the end user. Most of what we want to display is aggregate, filterable stats and rollups on user activity, where we have \\~20 million activity data points across \\~500k users.   \n\n\nSo far we've looked into Mode and Tableau, but with mode being acquired (yesterday) we're skeptical, and Tableau at least at first doesn't look very user-friendly to non-technical users. Open to considering both of these though.", "author_fullname": "t2_2l99cuqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for User-Friendly data visualization tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kogbl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687897546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve been facing a challenge at my job recently and could use a product recommendation. I&amp;#39;m the only data engineer at a small startup, and I spend a lot of my time preparing and formatting reports for our executives. Our execs aren&amp;#39;t technical, so they can only view data in the form of a filterable spreadsheet. We use Airtable for this, and it works decently, but has serious issues. Firstly, it has a max table size of 100k records, so some requests that exceed that are impossible for us to send in one report. It also doesn&amp;#39;t have live querying capabilities for quick iteration if the original spec wasn&amp;#39;t 100%.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear recommendations for data visualization tools that are flexible to use, can connect to and query from standard data warehouses (we use BigQuery mostly), and most importantly can produce reports that are filterable by the end user. Most of what we want to display is aggregate, filterable stats and rollups on user activity, where we have ~20 million activity data points across ~500k users.   &lt;/p&gt;\n\n&lt;p&gt;So far we&amp;#39;ve looked into Mode and Tableau, but with mode being acquired (yesterday) we&amp;#39;re skeptical, and Tableau at least at first doesn&amp;#39;t look very user-friendly to non-technical users. Open to considering both of these though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14kogbl", "is_robot_indexable": true, "report_reasons": null, "author": "chas_jk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kogbl/recommendations_for_userfriendly_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kogbl/recommendations_for_userfriendly_data/", "subreddit_subscribers": 112787, "created_utc": 1687897546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working in a small research team. I am thinking about how to streamline and modernize our data  processes. \n\nRight now, we have various people collecting research data on various paper forms. These are all then scanned and entered into a database by an admin. This isn't the worst part - the 'database' was designed by an in house IT team a few years ago. It's terrible, it's not even a research database but rather some crude business analytics tool called Diver. (I asked IT last week if I could analyse and compare two very obvious groups in the database, and they said no, it wasn't built that way (!) but I could export two different Excel spreadsheets if I wanted and merge them manually. I nearly cried.)\n\nI am meeting someone from IT tomorrow to discuss options. Basically I have an opportunity to drive us to streamline and modernize the whole setup. \n\nI want something that will allow front-end entry of data into specially designed forms (perhaps on tablets carried by frontline staff). This will then automatically update one central repository of data. On the other end I want us to be able to slice, dice, analyse and extract the data in an easy fashion. I also want the ability to dynamically build dashboards that update with team progress automatically. (As it stands one admin spends a week with Diver to generate a quarterly report on team progress). \n\nI am just trying to get a feel for my various options. \n\nOption 1: The university I'm in uses Redcap. This is the default for academic research, and it's pretty good. I'll investigate but I am unsure if it has all of the functionality I'm looking for. \n\nOption 2: The university I'm in also subscribes to O365, which means they have a good working relationship with their local Microsoft Partner. I'm wondering if it would be worth asking this vendor to design a database solution from scratch for us, e.g. using Microsoft Forms for direct data entry into a central data repository, which we can then layer analytics tools on top of. For example I presume we could have PowerBI dashboards which update automatically with our progress, if we have good data going in? There would also presumably be the opportunity to automate other processes we haven't even thought about. \n\nThanks for answers in advance. The data we're generating is golden but it's all siloed, and very difficult to extract/analyse, so in essence it's useless in its current form. I need to try and build a solid data pipeline that will pay dividends for the next 10 years+, and I'd love any advice/comments/suggestions. \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_viysurrq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions for research data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14klgt0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687890459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working in a small research team. I am thinking about how to streamline and modernize our data  processes. &lt;/p&gt;\n\n&lt;p&gt;Right now, we have various people collecting research data on various paper forms. These are all then scanned and entered into a database by an admin. This isn&amp;#39;t the worst part - the &amp;#39;database&amp;#39; was designed by an in house IT team a few years ago. It&amp;#39;s terrible, it&amp;#39;s not even a research database but rather some crude business analytics tool called Diver. (I asked IT last week if I could analyse and compare two very obvious groups in the database, and they said no, it wasn&amp;#39;t built that way (!) but I could export two different Excel spreadsheets if I wanted and merge them manually. I nearly cried.)&lt;/p&gt;\n\n&lt;p&gt;I am meeting someone from IT tomorrow to discuss options. Basically I have an opportunity to drive us to streamline and modernize the whole setup. &lt;/p&gt;\n\n&lt;p&gt;I want something that will allow front-end entry of data into specially designed forms (perhaps on tablets carried by frontline staff). This will then automatically update one central repository of data. On the other end I want us to be able to slice, dice, analyse and extract the data in an easy fashion. I also want the ability to dynamically build dashboards that update with team progress automatically. (As it stands one admin spends a week with Diver to generate a quarterly report on team progress). &lt;/p&gt;\n\n&lt;p&gt;I am just trying to get a feel for my various options. &lt;/p&gt;\n\n&lt;p&gt;Option 1: The university I&amp;#39;m in uses Redcap. This is the default for academic research, and it&amp;#39;s pretty good. I&amp;#39;ll investigate but I am unsure if it has all of the functionality I&amp;#39;m looking for. &lt;/p&gt;\n\n&lt;p&gt;Option 2: The university I&amp;#39;m in also subscribes to O365, which means they have a good working relationship with their local Microsoft Partner. I&amp;#39;m wondering if it would be worth asking this vendor to design a database solution from scratch for us, e.g. using Microsoft Forms for direct data entry into a central data repository, which we can then layer analytics tools on top of. For example I presume we could have PowerBI dashboards which update automatically with our progress, if we have good data going in? There would also presumably be the opportunity to automate other processes we haven&amp;#39;t even thought about. &lt;/p&gt;\n\n&lt;p&gt;Thanks for answers in advance. The data we&amp;#39;re generating is golden but it&amp;#39;s all siloed, and very difficult to extract/analyse, so in essence it&amp;#39;s useless in its current form. I need to try and build a solid data pipeline that will pay dividends for the next 10 years+, and I&amp;#39;d love any advice/comments/suggestions. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14klgt0", "is_robot_indexable": true, "report_reasons": null, "author": "nobblessobligee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14klgt0/suggestions_for_research_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14klgt0/suggestions_for_research_data/", "subreddit_subscribers": 112787, "created_utc": 1687890459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_268wbuql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Tech Digest #2: Building Airbnb\u2019s Next Generation Data Management Platform, Building Etsy\u2019s Search by Image Feature, GPT-4 + Streaming Data = Real-Time Generative AI, and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_14ki254", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P4j6V8_dpcfElDyZ7PFbZLjsQbgB3dV4D7StXaOFFro.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687882728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigtechdigest.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigtechdigest.substack.com/p/big-tech-digest-2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/r3j1pJ5gWadngqdz9jV9NknBuvafSBaUumpf00WdpCk.jpg?auto=webp&amp;v=enabled&amp;s=0f0dd02779000bdb817a53992464d0baea24146a", "width": 890, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/r3j1pJ5gWadngqdz9jV9NknBuvafSBaUumpf00WdpCk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ccf6ea99fb5e2659c8fbc21d06ddb184b51449b", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/r3j1pJ5gWadngqdz9jV9NknBuvafSBaUumpf00WdpCk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1169ad642964aae605819b4cad0eaf5fb4bf0c7e", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/r3j1pJ5gWadngqdz9jV9NknBuvafSBaUumpf00WdpCk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6673c3ce906dd8194c2ceab4f79db5ea842f4c49", "width": 320, "height": 215}, {"url": "https://external-preview.redd.it/r3j1pJ5gWadngqdz9jV9NknBuvafSBaUumpf00WdpCk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90999e1176d1161d7f04dd53e751af8f1ed2183c", "width": 640, "height": 431}], "variants": {}, "id": "XiUlx3gzRzy_cjCWI4Vw-iuommEZd_UYAdhmYC1LaZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ki254", "is_robot_indexable": true, "report_reasons": null, "author": "av818", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ki254/big_tech_digest_2_building_airbnbs_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigtechdigest.substack.com/p/big-tech-digest-2", "subreddit_subscribers": 112787, "created_utc": 1687882728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing some research about the challenges of creating and using behavioral customer data. Wanted to ask the group what are some of the challenges you're finding collecting and using behavioral customer data? What are your preferred tools, sources, targets for this type of data?\n\n&amp;#x200B;", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using behavioral customer data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kgls3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687879285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing some research about the challenges of creating and using behavioral customer data. Wanted to ask the group what are some of the challenges you&amp;#39;re finding collecting and using behavioral customer data? What are your preferred tools, sources, targets for this type of data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kgls3", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kgls3/using_behavioral_customer_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kgls3/using_behavioral_customer_data/", "subreddit_subscribers": 112787, "created_utc": 1687879285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good evening Gentleman and Ladies.\n\nI have an Internship that starts July 10th, this will be my first job ever.\n\nI want to get a head start.\n\n* Internship will involve **Reltio a master data maangement platform.**\n* I will be **learning to manage records**\n* With s**ql I will be managing/creating burn down list**\n* **Writing querys to target certain records.**\n\nMy questions are:\n\n1. What SQL Commands/Functions should I be really trying to Master to do this task?\n2. I don't know much about IT too be honest, what are some basic things I should know about to not look clueless.\n3. How can I get good at using Reltio?\n\nTo those who took the time to answer, thank you.", "author_fullname": "t2_htrki4x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reltio and SQL for my first job ever.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14lb7i0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687962987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening Gentleman and Ladies.&lt;/p&gt;\n\n&lt;p&gt;I have an Internship that starts July 10th, this will be my first job ever.&lt;/p&gt;\n\n&lt;p&gt;I want to get a head start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Internship will involve &lt;strong&gt;Reltio a master data maangement platform.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I will be &lt;strong&gt;learning to manage records&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;With s&lt;strong&gt;ql I will be managing/creating burn down list&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Writing querys to target certain records.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What SQL Commands/Functions should I be really trying to Master to do this task?&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know much about IT too be honest, what are some basic things I should know about to not look clueless.&lt;/li&gt;\n&lt;li&gt;How can I get good at using Reltio?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To those who took the time to answer, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lb7i0", "is_robot_indexable": true, "report_reasons": null, "author": "TophKatara", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "subreddit_subscribers": 112787, "created_utc": 1687962987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Have We Learned From Using Pandas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_14lb1yh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8FKZDFYpkLaPvVN2lPub80U2vVbRXhAaA9wt3u52QO4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687962625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/gooddata-developers/what-have-we-learned-from-using-pandas-78b513cd58e0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?auto=webp&amp;v=enabled&amp;s=dc2e4f6011b7ebec2424db038aecc27561341e54", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da6d397d7d496d0b37043bd05911f547a2cbcadf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74c222bf26a4f7eb6b612c443e87cb6088b2402c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1035a3c07df7f6a68794e267d22eb56791ef3193", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47703850ef1cb25ca8138c94420c0a4c96f3fbdb", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7030fd9423aa211a4e2ab28d48ac982e44bd287a", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/k04ryb3NDrz4SHpw1zysbMKZDvqPI-ldQKUOIffQPHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83e08f3dd3e215d290ea67e33839f3af5c5976fa", "width": 1080, "height": 565}], "variants": {}, "id": "wHJachZtYKHNpqZZHJT5iGa-Bj-H2aI67v3vvQ8kxeI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lb1yh", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb1yh/what_have_we_learned_from_using_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/gooddata-developers/what-have-we-learned-from-using-pandas-78b513cd58e0", "subreddit_subscribers": 112787, "created_utc": 1687962625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vd2d51zd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc49 New Awesome Polars release! What's new in the world of Polars in June 2023 ? Let's find out! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_14la4y2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gqtPViRGBsKIrIJLyK_hSIjXArCufvNmUE135m4TIC8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687960389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?auto=webp&amp;v=enabled&amp;s=112b9d316153e774ab88765bc9f581c2b6a33feb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bae859fbf853259a52562afce9f36c9c5ea37068", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44f2d000933928749cf1e76e290388c1a64f2b88", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c578d631f51a640c097e9893cee238f3a997c41", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1e8119a50a2d6aae203727ecbf3e07a742106bc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28f9c60e425f5a482c13ef5ccf8c62c99277514f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c612bd2f8f22ab035d6fe28c1f79ae276f57be6a", "width": 1080, "height": 540}], "variants": {}, "id": "JLi9UEo1JLI2HplShAk-3FlVXxlreLI_Mw3YPTU9RTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14la4y2", "is_robot_indexable": true, "report_reasons": null, "author": "damiendotta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14la4y2/new_awesome_polars_release_whats_new_in_the_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "subreddit_subscribers": 112787, "created_utc": 1687960389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "any experiences with this topic?\n\nthings to consider, approaches to modeling the data once it's extracted etc.\n\nThings that you've tried or seen working.\n\nA generic description from Chatty G on what im referring to:\n\n&amp;#x200B;\n\n&gt;In a data engineering context, \"point in time\" refers to a specific moment or snapshot of data. It represents a specific timestamp or a specific version of a dataset. It is often used to indicate when a particular event or action occurred or to capture the state of data at a specific instance.  \n&gt;  \n&gt;In data engineering, managing data at different points in time is crucial for various purposes, such as tracking changes, auditing, analysis, and maintaining data integrity. By capturing data at different points in time, data engineers can analyze historical trends, perform comparisons, and ensure data consistency across different systems and processes.\n\n&amp;#x200B;\n\nbonus points if you've worked on these topics using dbt, that's my main data transform engine.\n\nfull transparency: am looking into productizing this type of data modeling exercise, making it easier to achieve without making the queries super inefficient/costly. looking to understand the topic better.\n\n&amp;#x200B;\n\nthanks in advance y'all \ud83d\ude4f\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fcayybrmpq8b1.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5198e1b0a56c23f848d4fee65d5c579dea1c6cb1", "author_fullname": "t2_rsfh63ed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "historical data and \"point in time\" data modeling techniques, advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fcayybrmpq8b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 120, "x": 108, "u": "https://preview.redd.it/fcayybrmpq8b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7021cc7bd407e268e8ed63ee960f8ac2b3f4892f"}, {"y": 241, "x": 216, "u": "https://preview.redd.it/fcayybrmpq8b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e63d2d24b2d148790b778950af840bb7fac4f81e"}, {"y": 357, "x": 320, "u": "https://preview.redd.it/fcayybrmpq8b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9285ccf01b3d4f348e18daa8ec2a7fe2384ec538"}], "s": {"y": 559, "x": 500, "u": "https://preview.redd.it/fcayybrmpq8b1.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5198e1b0a56c23f848d4fee65d5c579dea1c6cb1"}, "id": "fcayybrmpq8b1"}}, "name": "t3_14l6e0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5dBGFRaKmO-tAKBtnfcV8e_XZn15Exdoc8oGb5ezmnI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687949925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;any experiences with this topic?&lt;/p&gt;\n\n&lt;p&gt;things to consider, approaches to modeling the data once it&amp;#39;s extracted etc.&lt;/p&gt;\n\n&lt;p&gt;Things that you&amp;#39;ve tried or seen working.&lt;/p&gt;\n\n&lt;p&gt;A generic description from Chatty G on what im referring to:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;In a data engineering context, &amp;quot;point in time&amp;quot; refers to a specific moment or snapshot of data. It represents a specific timestamp or a specific version of a dataset. It is often used to indicate when a particular event or action occurred or to capture the state of data at a specific instance.  &lt;/p&gt;\n\n&lt;p&gt;In data engineering, managing data at different points in time is crucial for various purposes, such as tracking changes, auditing, analysis, and maintaining data integrity. By capturing data at different points in time, data engineers can analyze historical trends, perform comparisons, and ensure data consistency across different systems and processes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;bonus points if you&amp;#39;ve worked on these topics using dbt, that&amp;#39;s my main data transform engine.&lt;/p&gt;\n\n&lt;p&gt;full transparency: am looking into productizing this type of data modeling exercise, making it easier to achieve without making the queries super inefficient/costly. looking to understand the topic better.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance y&amp;#39;all \ud83d\ude4f&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fcayybrmpq8b1.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5198e1b0a56c23f848d4fee65d5c579dea1c6cb1\"&gt;https://preview.redd.it/fcayybrmpq8b1.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=5198e1b0a56c23f848d4fee65d5c579dea1c6cb1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l6e0c", "is_robot_indexable": true, "report_reasons": null, "author": "thesnappingdog", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l6e0c/historical_data_and_point_in_time_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l6e0c/historical_data_and_point_in_time_data_modeling/", "subreddit_subscribers": 112787, "created_utc": 1687949925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cbmhjy2x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jacobson's Rank", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l4o9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1687944201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "denvaar.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://denvaar.github.io/posts/jacobsons_rank.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14l4o9f", "is_robot_indexable": true, "report_reasons": null, "author": "qunatrimonix", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l4o9f/jacobsons_rank/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://denvaar.github.io/posts/jacobsons_rank.html", "subreddit_subscribers": 112787, "created_utc": 1687944201.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}