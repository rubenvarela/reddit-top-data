{"kind": "Listing", "data": {"after": "t3_14kogbl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am having interviews to hire someone who will work for me. I interviewed two people so far. Neither of them answered on questions:\n\n&amp;#x200B;\n\n1. OLAP and OLTP systems\n2. Star Schema vs. Cube\n3. ETL vs. ELT\n4. Window function SQL question\n\n&amp;#x200B;\n\nIt is a position for 3+ years in data analytics, business intelligence, or a related field and I didn't expect to get the full extent of complete answers. Am I asking too difficult questions? or am I becoming out of touch and those aren't relevant anymore?\n\n&amp;#x200B;\n\nEdit: I didn't really make it clear what the role is for. The role is BI Engineer, but the candidates that the head hunter sent to our HR manager happened to have a data analyst background. ", "author_fullname": "t2_oxibh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these terms irrelevant in the industry anymore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kra4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687953754.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687903985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having interviews to hire someone who will work for me. I interviewed two people so far. Neither of them answered on questions:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;OLAP and OLTP systems&lt;/li&gt;\n&lt;li&gt;Star Schema vs. Cube&lt;/li&gt;\n&lt;li&gt;ETL vs. ELT&lt;/li&gt;\n&lt;li&gt;Window function SQL question&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It is a position for 3+ years in data analytics, business intelligence, or a related field and I didn&amp;#39;t expect to get the full extent of complete answers. Am I asking too difficult questions? or am I becoming out of touch and those aren&amp;#39;t relevant anymore?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I didn&amp;#39;t really make it clear what the role is for. The role is BI Engineer, but the candidates that the head hunter sent to our HR manager happened to have a data analyst background. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14kra4i", "is_robot_indexable": true, "report_reasons": null, "author": "Bloodylime", "discussion_type": null, "num_comments": 99, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kra4i/are_these_terms_irrelevant_in_the_industry_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kra4i/are_these_terms_irrelevant_in_the_industry_anymore/", "subreddit_subscribers": 112823, "created_utc": 1687903985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking about the future of data engineering and what kind of learning path I would suggest to someone breaking into the industry.\n\nDatabricks + Snowflake seems to be providing a ton of value by giving us a platform to focus on data engineering (instead of configuration, connecting tools, etc.). \n\nHowever, I don't see adoption at the holy-grail big data FAANG companies. From looking at their job descriptions, these companies are still using tools within the Hadoop ecosystem. \n\nThis makes me wonder if it is the small number of \"big data\" companies keeping the Hadoop ecosystem alive as the industry tries to move forward and simplify. Or why haven't they also adopted platforms like Databricks or Snowflake. I get these tools would be costly given the vast amounts of data, but I would imagine that there would also be a ton of savings on engineer hours. \n\nIs the future of DE platforms like Databricks? Do we only care about the Hadoop-ecosystem because of a few large companies who haven't figured out how to adopt these platforms in a cost-effective way?\n\n&amp;#x200B;", "author_fullname": "t2_7iitruic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform Adoption and FAANG Companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ksgkm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687906844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking about the future of data engineering and what kind of learning path I would suggest to someone breaking into the industry.&lt;/p&gt;\n\n&lt;p&gt;Databricks + Snowflake seems to be providing a ton of value by giving us a platform to focus on data engineering (instead of configuration, connecting tools, etc.). &lt;/p&gt;\n\n&lt;p&gt;However, I don&amp;#39;t see adoption at the holy-grail big data FAANG companies. From looking at their job descriptions, these companies are still using tools within the Hadoop ecosystem. &lt;/p&gt;\n\n&lt;p&gt;This makes me wonder if it is the small number of &amp;quot;big data&amp;quot; companies keeping the Hadoop ecosystem alive as the industry tries to move forward and simplify. Or why haven&amp;#39;t they also adopted platforms like Databricks or Snowflake. I get these tools would be costly given the vast amounts of data, but I would imagine that there would also be a ton of savings on engineer hours. &lt;/p&gt;\n\n&lt;p&gt;Is the future of DE platforms like Databricks? Do we only care about the Hadoop-ecosystem because of a few large companies who haven&amp;#39;t figured out how to adopt these platforms in a cost-effective way?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ksgkm", "is_robot_indexable": true, "report_reasons": null, "author": "jduran9987", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ksgkm/data_platform_adoption_and_faang_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ksgkm/data_platform_adoption_and_faang_companies/", "subreddit_subscribers": 112823, "created_utc": 1687906844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cp1afbpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook data transfers declared illegal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14l4vx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W8uGyrlvQygFg_rRgAMqXpeLJ3YONTEx29NRiIgY6kE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687944975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "simpleanalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?auto=webp&amp;v=enabled&amp;s=4656d7a82bd341b62c92ae3ea737313ccf033fa4", "width": 1000, "height": 523}, "resolutions": [{"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3c3430786c5f80cb771c67a3759036191424d61", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef490707114127b18201183b737925a2d1aef3b6", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ebeae41cc50014b4dbda964f13017329b909e27", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e206fdb52dc4d73d477ec0cd93963175a4eac4d7", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bd40816e9cd524436e774f464dfcd8ac7d71c26", "width": 960, "height": 502}], "variants": {}, "id": "p4LUfDlJMgUcV_dAFYAKR_AN31ciT_2jgZfllIkmSX4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14l4vx6", "is_robot_indexable": true, "report_reasons": null, "author": "nulovyk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l4vx6/facebook_data_transfers_declared_illegal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "subreddit_subscribers": 112823, "created_utc": 1687944975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you guys implementing the medallion architecture in unity catalog. \n\nWe currently have a dev and prod workspace with bronze, silver, gold catalogs in each. We also have external tables, and externally managed tables. \n\nI am the one architecting our databricks environment but have not found good documentation on the medallion architecture within unity catalog. Any advice is much appreciated!", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you implement the medallion pattern in databricks unity catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ku3ae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687910930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you guys implementing the medallion architecture in unity catalog. &lt;/p&gt;\n\n&lt;p&gt;We currently have a dev and prod workspace with bronze, silver, gold catalogs in each. We also have external tables, and externally managed tables. &lt;/p&gt;\n\n&lt;p&gt;I am the one architecting our databricks environment but have not found good documentation on the medallion architecture within unity catalog. Any advice is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ku3ae", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ku3ae/how_do_you_implement_the_medallion_pattern_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ku3ae/how_do_you_implement_the_medallion_pattern_in/", "subreddit_subscribers": 112823, "created_utc": 1687910930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. \n\nI\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?", "author_fullname": "t2_5ah07udc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How complex is the coding in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2se5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687937371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2se5", "is_robot_indexable": true, "report_reasons": null, "author": "jimharbaughthrowaway", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "subreddit_subscribers": 112823, "created_utc": 1687937371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. \n\n&amp;nbsp;\n\n**Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?** For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. \n\n&amp;nbsp;\n\nThanks!", "author_fullname": "t2_bf1rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Weather/Geospatial data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcyxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687967137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?&lt;/strong&gt; For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lcyxr", "is_robot_indexable": true, "report_reasons": null, "author": "gbromley", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "subreddit_subscribers": 112823, "created_utc": 1687967137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.\n\nMy life just got more interesting.", "author_fullname": "t2_713dpi97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 3.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfqfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.&lt;/p&gt;\n\n&lt;p&gt;My life just got more interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lfqfu", "is_robot_indexable": true, "report_reasons": null, "author": "rexicusmaximus", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lfqfu/delta_lake_30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lfqfu/delta_lake_30/", "subreddit_subscribers": 112823, "created_utc": 1687973614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title says, I am annoyed.\n\nFour or five years ago, we signed up with Periscope Data for BI. Their package included some basic ELT &amp; warehousing infrastructure using Fivetran and Redshift. It was convenient (but not necessarily cost effective) to have our entire data stack managed by a single vendor, for a single price.\n\nFast forward a year and Periscope gets bought by Sisense. Sisense agreed to continue managing our whole stack, but each time we renewed our contract, they seemed more and more confused by the relationship with the other vendors, didn\u2019t know how Fivetran was supposed to get paid, stuff like that.\n\nSo this year, I see that Fivetran is now offering a free plan for customers who use less than 500K monthly active rows (MAR). We were just over that amount, and I saw an opportunity to lower our costs by reducing our usage. I checked in with Sisense and Fivetran to make sure I was thinking correctly - get under 500K MAR, and drop down to the free tier. Cut out the Fivetran portion of our spend.\n\nNow, just a couple days before we have to renew our contract with Sisense, they\u2019re telling me that *even though I have optimized our ELT process to get into Fivetran\u2019s free tier*, our bill to Sisense is *not going to decrease at all* and will actually go up the usual 5%.\n\nWhat a joke. In what world is a business - especially a small biz like ours (&lt;50 employees) going to pay *more* for the vendor to do *less*? If I can optimize our ELT, I\u2019ll bet I can optimize our BI as well, and Sisense can go pound sand.\n\nIs this the norm for vendors in the analytics space? Does anyone have any suggestions for more cost-effective BI solutions? I was playing around with Looker Studio today\u2026query times were pretty long for a dataset that only has about 200,000 records\u2026I have a call with Mode next week. Less than $5,000 a month would be good\u2026less than $2,500 a month would be even better.\n\n*Edit - 500K MAR, not 500. Sorry. Shouldn\u2019t post when tired.*", "author_fullname": "t2_b76ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran and Sisense: I am annoyed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kx9l2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687947241.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687919702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says, I am annoyed.&lt;/p&gt;\n\n&lt;p&gt;Four or five years ago, we signed up with Periscope Data for BI. Their package included some basic ELT &amp;amp; warehousing infrastructure using Fivetran and Redshift. It was convenient (but not necessarily cost effective) to have our entire data stack managed by a single vendor, for a single price.&lt;/p&gt;\n\n&lt;p&gt;Fast forward a year and Periscope gets bought by Sisense. Sisense agreed to continue managing our whole stack, but each time we renewed our contract, they seemed more and more confused by the relationship with the other vendors, didn\u2019t know how Fivetran was supposed to get paid, stuff like that.&lt;/p&gt;\n\n&lt;p&gt;So this year, I see that Fivetran is now offering a free plan for customers who use less than 500K monthly active rows (MAR). We were just over that amount, and I saw an opportunity to lower our costs by reducing our usage. I checked in with Sisense and Fivetran to make sure I was thinking correctly - get under 500K MAR, and drop down to the free tier. Cut out the Fivetran portion of our spend.&lt;/p&gt;\n\n&lt;p&gt;Now, just a couple days before we have to renew our contract with Sisense, they\u2019re telling me that &lt;em&gt;even though I have optimized our ELT process to get into Fivetran\u2019s free tier&lt;/em&gt;, our bill to Sisense is &lt;em&gt;not going to decrease at all&lt;/em&gt; and will actually go up the usual 5%.&lt;/p&gt;\n\n&lt;p&gt;What a joke. In what world is a business - especially a small biz like ours (&amp;lt;50 employees) going to pay &lt;em&gt;more&lt;/em&gt; for the vendor to do &lt;em&gt;less&lt;/em&gt;? If I can optimize our ELT, I\u2019ll bet I can optimize our BI as well, and Sisense can go pound sand.&lt;/p&gt;\n\n&lt;p&gt;Is this the norm for vendors in the analytics space? Does anyone have any suggestions for more cost-effective BI solutions? I was playing around with Looker Studio today\u2026query times were pretty long for a dataset that only has about 200,000 records\u2026I have a call with Mode next week. Less than $5,000 a month would be good\u2026less than $2,500 a month would be even better.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit - 500K MAR, not 500. Sorry. Shouldn\u2019t post when tired.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kx9l2", "is_robot_indexable": true, "report_reasons": null, "author": "Batspocky", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kx9l2/fivetran_and_sisense_i_am_annoyed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kx9l2/fivetran_and_sisense_i_am_annoyed/", "subreddit_subscribers": 112823, "created_utc": 1687919702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data engineer with 3+ years of full time work experience in India and 1 year of experience in a full time internship in US.\n\nI have good skills in SQL, Python, ETL, Data warehousing, GCP, Snowflake and databricks. \n\nI have been applying for jobs for past 3 months now, but still not getting any calls. I have tried applying to jobs via LinkedIn/indeed, connecting with my ex managers and employers, cold emailing Hiring Managers etc.\n\nWhat am I doing wrong. What else can I do to get a job in this market", "author_fullname": "t2_7tah61j5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a job in this market??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kyy12", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687924578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data engineer with 3+ years of full time work experience in India and 1 year of experience in a full time internship in US.&lt;/p&gt;\n\n&lt;p&gt;I have good skills in SQL, Python, ETL, Data warehousing, GCP, Snowflake and databricks. &lt;/p&gt;\n\n&lt;p&gt;I have been applying for jobs for past 3 months now, but still not getting any calls. I have tried applying to jobs via LinkedIn/indeed, connecting with my ex managers and employers, cold emailing Hiring Managers etc.&lt;/p&gt;\n\n&lt;p&gt;What am I doing wrong. What else can I do to get a job in this market&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14kyy12", "is_robot_indexable": true, "report_reasons": null, "author": "Test_Known", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kyy12/how_to_get_a_job_in_this_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kyy12/how_to_get_a_job_in_this_market/", "subreddit_subscribers": 112823, "created_utc": 1687924578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vd2d51zd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc49 New Awesome Polars release! What's new in the world of Polars in June 2023 ? Let's find out! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14la4y2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gqtPViRGBsKIrIJLyK_hSIjXArCufvNmUE135m4TIC8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687960389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?auto=webp&amp;v=enabled&amp;s=112b9d316153e774ab88765bc9f581c2b6a33feb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bae859fbf853259a52562afce9f36c9c5ea37068", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44f2d000933928749cf1e76e290388c1a64f2b88", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c578d631f51a640c097e9893cee238f3a997c41", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1e8119a50a2d6aae203727ecbf3e07a742106bc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28f9c60e425f5a482c13ef5ccf8c62c99277514f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c612bd2f8f22ab035d6fe28c1f79ae276f57be6a", "width": 1080, "height": 540}], "variants": {}, "id": "JLi9UEo1JLI2HplShAk-3FlVXxlreLI_Mw3YPTU9RTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14la4y2", "is_robot_indexable": true, "report_reasons": null, "author": "damiendotta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14la4y2/new_awesome_polars_release_whats_new_in_the_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "subreddit_subscribers": 112823, "created_utc": 1687960389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LakehouseIQ: Your new AI overlord", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcl25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Cj0uZCvWJ3ImvXy1b7VYd5DorYe54LBpuERUqXRoGs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687966222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?auto=webp&amp;v=enabled&amp;s=54c85608339efd7fc98d82c6e5b6c9037d5411f2", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49591bac210c847aac0bde7034427b597fa95e23", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2abb0c0cf8bf149f255a6877f21eeedfcf1d7fba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5964f5ea655f0c082865c46c6b9b9bcdb6bf5d10", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08d9fdd05bddec589e96728cffd91c20aa02822a", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cff40cf2a10d7a4505e1a08f0230f717c73a797e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2da1bbe17bc855612237efc1fa8f4b062fea442d", "width": 1080, "height": 565}], "variants": {}, "id": "1WPTbdrGWkjPjVPTtLKBuew_V3jfMV5ZAV1IKBysEkc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcl25", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcl25/lakehouseiq_your_new_ai_overlord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "subreddit_subscribers": 112823, "created_utc": 1687966222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks releases SDK for GoLang", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfo8e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1kJyYWMqkdbCvtL5fjI7i_X7Y3MAIZKdnWR1Z3VPd6w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687973468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databricks/databricks-sdk-go", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?auto=webp&amp;v=enabled&amp;s=e1c8f2a696d48140997018ac21f0b8cb74ec1d61", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bac44c441432f7a904027de58f94c82910fb8a72", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5761212a1b753cf2ae42160ce90945c64d03678a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87516ed969e0ac51911914b206689094cd75b19b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dec257a8ba48c0ff28f22f8e5e91e8cfbcb1d56c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb0bc72c7bb47eff8cc109b0d1a4874ec277203a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JMqn2srL1JOqcCZAVoHgeIkW5PVrxjclM6eMct7eoFM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb64c32779b2f53ea20beb94ccfd00dffd140659", "width": 1080, "height": 540}], "variants": {}, "id": "M8Rn_CsBpMQdSTLg5nr44Fdx0IMUNx6c059e86piFDw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14lfo8e", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lfo8e/databricks_releases_sdk_for_golang/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databricks/databricks-sdk-go", "subreddit_subscribers": 112823, "created_utc": 1687973468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Graphs in Rust. Yikes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcciw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w7A3n7NOh83dDxukY5zsnG72JmKkQ6tJdlFr7s_UiSA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687965666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?auto=webp&amp;v=enabled&amp;s=fda8c60d7a50945b57821af3599a39dd7a2311ce", "width": 1030, "height": 511}, "resolutions": [{"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e978f0e26b5253388ce5d2e091ddf9f8c72248a", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34a8c0dea0a4814284917b3628a2034aa3f221bd", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9e3586c3d359d92ef4ad3fdc9dc31e8a122f49a", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1fbdee8fa2883d6a099972a972e6c3fb586299f", "width": 640, "height": 317}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4546983493885ca9ff0ddea1e30868c4ca32b779", "width": 960, "height": 476}], "variants": {}, "id": "sB9wqRwDtNXITSnlZBdxKU18Nhco9x0ZHuKL_Jn4Y_s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcciw", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcciw/exploring_graphs_in_rust_yikes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "subreddit_subscribers": 112823, "created_utc": 1687965666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks releases official SDK for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14leo16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/T4Cm8TpuEbsjx0eN9z_Sxuq9ad6WD_ct5CZcJr74BF4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687971083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databricks/databricks-sdk-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?auto=webp&amp;v=enabled&amp;s=acc4f5041fcaf40d949a2e4cd847bc08fcb005a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adf867fe2bcae051621aeba4736112dbc20c72f0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57141edffce8ca6d2acbb15a7b65388ad21e2056", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfef8eca6f82325f924314d9d07cdf8e6cd3b9ff", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feeb38a5a98bbef277fc0c31b6606bc79483fd91", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb4920be5ece8ef16eaf4b82c39c87fa81b0fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb059ae1542e2484e120ecd8e83f3351fc15ec07", "width": 1080, "height": 540}], "variants": {}, "id": "6IBNQF9cmQiIH3ZxOSSypIOoNLMuRKd750KVDHEoZxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14leo16", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14leo16/databricks_releases_official_sdk_for_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databricks/databricks-sdk-py", "subreddit_subscribers": 112823, "created_utc": 1687971083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am wondering how reddit stores the registration IP address of deleted accounts? Is the IP directly linked to the deleted account? In such a way that if someone were to get it, they would know identity of a reddit user? Or is it anonymized in such a way that it cannot be linked to any specific account?\n\nI am also wondering if the username gets anonymized in the database aswell or only on the reddit website?", "author_fullname": "t2_ecx0hpbo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does reddit store the registration IP address of deleted accounts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lb4hm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687962789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering how reddit stores the registration IP address of deleted accounts? Is the IP directly linked to the deleted account? In such a way that if someone were to get it, they would know identity of a reddit user? Or is it anonymized in such a way that it cannot be linked to any specific account?&lt;/p&gt;\n\n&lt;p&gt;I am also wondering if the username gets anonymized in the database aswell or only on the reddit website?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lb4hm", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable-Dirt-1289", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb4hm/how_does_reddit_store_the_registration_ip_address/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lb4hm/how_does_reddit_store_the_registration_ip_address/", "subreddit_subscribers": 112823, "created_utc": 1687962789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're switching from on-prem to Synapse. \n\nOur current build stored procs, are getting switched over to Spark SQL notebooks.  Some of these build procs are truncate and inserts. \n\nDelta retains the history though -it's a soft delete, until vacuum is run anyway.  If say, a Delta file is getting truncate and insert every night:\n\n  * Is that an OK practice?\n  * What does that look like in the Delta file?  Say a 1,000 row table on Day 1, is then truncated and inserted, and no data changed. Is that now a 2,000 row table, with 1,000 'active' rows and 1,000 soft deleted ones?", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truncating Delta Tables - is that wise? (Ignorant Q)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kte7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687909158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re switching from on-prem to Synapse. &lt;/p&gt;\n\n&lt;p&gt;Our current build stored procs, are getting switched over to Spark SQL notebooks.  Some of these build procs are truncate and inserts. &lt;/p&gt;\n\n&lt;p&gt;Delta retains the history though -it&amp;#39;s a soft delete, until vacuum is run anyway.  If say, a Delta file is getting truncate and insert every night:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is that an OK practice?&lt;/li&gt;\n&lt;li&gt;What does that look like in the Delta file?  Say a 1,000 row table on Day 1, is then truncated and inserted, and no data changed. Is that now a 2,000 row table, with 1,000 &amp;#39;active&amp;#39; rows and 1,000 soft deleted ones?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14kte7b", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kte7b/truncating_delta_tables_is_that_wise_ignorant_q/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kte7b/truncating_delta_tables_is_that_wise_ignorant_q/", "subreddit_subscribers": 112823, "created_utc": 1687909158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen two scenarios of this topic.\n\n1. Ephemeral Landing Zone -&gt; append in Bronze as parquet -&gt; **Validate new/modified records** \\-&gt; Merge in Silver\n2. Ephemeral Landing Zone -&gt; **Validate new/modified records** \\-&gt; append in bronze as parquet-&gt; merge in silver\n\nThe argument for method #1 is that we just care about getting data into bronze as fast as possible and we don't care about the quality, structure, or validity of the data when appending to the bronze table. Only when we want to merge those new/changed records in silver, we should apply data contract validation.\n\nI understand that reasoning, but I feel like method #2 is better, no? why not validate with the contracts BEFORE appending to bronze? This way I am only appending validated data into bronze, which can just be merged into silver with no worries.\n\nWhat is your approach to data validation &amp; quality checks in your pipeline?\n\nAs always, thanks! :)", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to validate data / apply contracts in a data lake pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14knfzj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687895247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen two scenarios of this topic.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ephemeral Landing Zone -&amp;gt; append in Bronze as parquet -&amp;gt; &lt;strong&gt;Validate new/modified records&lt;/strong&gt; -&amp;gt; Merge in Silver&lt;/li&gt;\n&lt;li&gt;Ephemeral Landing Zone -&amp;gt; &lt;strong&gt;Validate new/modified records&lt;/strong&gt; -&amp;gt; append in bronze as parquet-&amp;gt; merge in silver&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The argument for method #1 is that we just care about getting data into bronze as fast as possible and we don&amp;#39;t care about the quality, structure, or validity of the data when appending to the bronze table. Only when we want to merge those new/changed records in silver, we should apply data contract validation.&lt;/p&gt;\n\n&lt;p&gt;I understand that reasoning, but I feel like method #2 is better, no? why not validate with the contracts BEFORE appending to bronze? This way I am only appending validated data into bronze, which can just be merged into silver with no worries.&lt;/p&gt;\n\n&lt;p&gt;What is your approach to data validation &amp;amp; quality checks in your pipeline?&lt;/p&gt;\n\n&lt;p&gt;As always, thanks! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14knfzj", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14knfzj/when_to_validate_data_apply_contracts_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14knfzj/when_to_validate_data_apply_contracts_in_a_data/", "subreddit_subscribers": 112823, "created_utc": 1687895247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename\n\nI have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)\n\nThis is working, it is not able read the value of parameter.\n\nCan anyone help me with the solution.", "author_fullname": "t2_jrlp2tiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF parameters in SQL query -Urgent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14letcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687971436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename&lt;/p&gt;\n\n&lt;p&gt;I have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)&lt;/p&gt;\n\n&lt;p&gt;This is working, it is not able read the value of parameter.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with the solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14letcn", "is_robot_indexable": true, "report_reasons": null, "author": "ProcedureScared2970", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "subreddit_subscribers": 112823, "created_utc": 1687971436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been studying and working toward a career transition in data engineering.  I'm not ready yet, but I have passed the Microsoft DE exam (and the DBA one), and I've been working in Azure to create demos.  \n\nMy mentor has described me as \"internship ready\" though I don't have access to internships, as all (so far) have required that only current CS-related college students apply.  I completed my bachelors years ago in social sciences, and I had lots of sporadic IT skills/training, but little of it is formal classes.\n\nNext step is to accelerate/focus the process, which means some formal training.  My best options are these:\n\n\\- an offer of a data science masters degree (FREE) at an honors college, inc paid internship  \n\\- a bootcamp style 6 month graduate program ($10K) remote through a university/Springboard  \n\n\nMy question: If my goal remains DE, would be it normal (or not) to see a data science master's degree on a job application for a data engineer?", "author_fullname": "t2_lu0npiks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would a data science masters degree be useful for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lc985", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687965441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been studying and working toward a career transition in data engineering.  I&amp;#39;m not ready yet, but I have passed the Microsoft DE exam (and the DBA one), and I&amp;#39;ve been working in Azure to create demos.  &lt;/p&gt;\n\n&lt;p&gt;My mentor has described me as &amp;quot;internship ready&amp;quot; though I don&amp;#39;t have access to internships, as all (so far) have required that only current CS-related college students apply.  I completed my bachelors years ago in social sciences, and I had lots of sporadic IT skills/training, but little of it is formal classes.&lt;/p&gt;\n\n&lt;p&gt;Next step is to accelerate/focus the process, which means some formal training.  My best options are these:&lt;/p&gt;\n\n&lt;p&gt;- an offer of a data science masters degree (FREE) at an honors college, inc paid internship&lt;br/&gt;\n- a bootcamp style 6 month graduate program ($10K) remote through a university/Springboard  &lt;/p&gt;\n\n&lt;p&gt;My question: If my goal remains DE, would be it normal (or not) to see a data science master&amp;#39;s degree on a job application for a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14lc985", "is_robot_indexable": true, "report_reasons": null, "author": "prillo7991", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lc985/would_a_data_science_masters_degree_be_useful_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lc985/would_a_data_science_masters_degree_be_useful_for/", "subreddit_subscribers": 112823, "created_utc": 1687965441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good evening Gentleman and Ladies.\n\nI have an Internship that starts July 10th, this will be my first job ever.\n\nI want to get a head start.\n\n* Internship will involve **Reltio a master data maangement platform.**\n* I will be **learning to manage records**\n* With s**ql I will be managing/creating burn down list**\n* **Writing querys to target certain records.**\n\nMy questions are:\n\n1. What SQL Commands/Functions should I be really trying to Master to do this task?\n2. I don't know much about IT too be honest, what are some basic things I should know about to not look clueless.\n3. How can I get good at using Reltio?\n\nTo those who took the time to answer, thank you.", "author_fullname": "t2_htrki4x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reltio and SQL for my first job ever.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lb7i0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687962987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening Gentleman and Ladies.&lt;/p&gt;\n\n&lt;p&gt;I have an Internship that starts July 10th, this will be my first job ever.&lt;/p&gt;\n\n&lt;p&gt;I want to get a head start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Internship will involve &lt;strong&gt;Reltio a master data maangement platform.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I will be &lt;strong&gt;learning to manage records&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;With s&lt;strong&gt;ql I will be managing/creating burn down list&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Writing querys to target certain records.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What SQL Commands/Functions should I be really trying to Master to do this task?&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know much about IT too be honest, what are some basic things I should know about to not look clueless.&lt;/li&gt;\n&lt;li&gt;How can I get good at using Reltio?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To those who took the time to answer, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lb7i0", "is_robot_indexable": true, "report_reasons": null, "author": "TophKatara", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "subreddit_subscribers": 112823, "created_utc": 1687962987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. \n\nI created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he's being used as a reference). \n\nAfter that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it's always something talked about but as soon as you try to say something such as \"We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?\n\n...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?", "author_fullname": "t2_nw770", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else really frustrated with the additional responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l93wo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1687958109.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687957762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. &lt;/p&gt;\n\n&lt;p&gt;I created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he&amp;#39;s being used as a reference). &lt;/p&gt;\n\n&lt;p&gt;After that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it&amp;#39;s always something talked about but as soon as you try to say something such as &amp;quot;We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?&lt;/p&gt;\n\n&lt;p&gt;...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l93wo", "is_robot_indexable": true, "report_reasons": null, "author": "PeacefullyFighting", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "subreddit_subscribers": 112823, "created_utc": 1687957762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analyst/junior engineer.\n\nI\u2019ve built one pipeline using snowflake as a storage solution.\n\nShould I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).", "author_fullname": "t2_602r7p43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake or Databicks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l5wfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687948330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analyst/junior engineer.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve built one pipeline using snowflake as a storage solution.&lt;/p&gt;\n\n&lt;p&gt;Should I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l5wfj", "is_robot_indexable": true, "report_reasons": null, "author": "rolledthrough7578", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "subreddit_subscribers": 112823, "created_utc": 1687948330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Databricks Data across Tenant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2esp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687935987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2esp", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "subreddit_subscribers": 112823, "created_utc": 1687935987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm second guessing my understanding here: if pyspark is used to read a table from a remote DB (with something like J/ODBC connections) and some transformation is done to the data, is the compute used to perform that transformation sourced from the database servers storing the data or from the executor nodes?  Does the answer change if it is a local spark session instead of a cluster, or if the transformation is provided purely as a sql query?", "author_fullname": "t2_15slf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does computation occur with Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kplh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687900292.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687900072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m second guessing my understanding here: if pyspark is used to read a table from a remote DB (with something like J/ODBC connections) and some transformation is done to the data, is the compute used to perform that transformation sourced from the database servers storing the data or from the executor nodes?  Does the answer change if it is a local spark session instead of a cluster, or if the transformation is provided purely as a sql query?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kplh3", "is_robot_indexable": true, "report_reasons": null, "author": "JustAnotherMortalMan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kplh3/where_does_computation_occur_with_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kplh3/where_does_computation_occur_with_spark/", "subreddit_subscribers": 112823, "created_utc": 1687900072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I've been facing a challenge at my job recently and could use a product recommendation. I'm the only data engineer at a small startup, and I spend a lot of my time preparing and formatting reports for our executives. Our execs aren't technical, so they can only view data in the form of a filterable spreadsheet. We use Airtable for this, and it works decently, but has serious issues. Firstly, it has a max table size of 100k records, so some requests that exceed that are impossible for us to send in one report. It also doesn't have live querying capabilities for quick iteration if the original spec wasn't 100%.\n\nI'd love to hear recommendations for data visualization tools that are flexible to use, can connect to and query from standard data warehouses (we use BigQuery mostly), and most importantly can produce reports that are filterable by the end user. Most of what we want to display is aggregate, filterable stats and rollups on user activity, where we have \\~20 million activity data points across \\~500k users.   \n\n\nSo far we've looked into Mode and Tableau, but with mode being acquired (yesterday) we're skeptical, and Tableau at least at first doesn't look very user-friendly to non-technical users. Open to considering both of these though.", "author_fullname": "t2_2l99cuqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for User-Friendly data visualization tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kogbl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687897546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve been facing a challenge at my job recently and could use a product recommendation. I&amp;#39;m the only data engineer at a small startup, and I spend a lot of my time preparing and formatting reports for our executives. Our execs aren&amp;#39;t technical, so they can only view data in the form of a filterable spreadsheet. We use Airtable for this, and it works decently, but has serious issues. Firstly, it has a max table size of 100k records, so some requests that exceed that are impossible for us to send in one report. It also doesn&amp;#39;t have live querying capabilities for quick iteration if the original spec wasn&amp;#39;t 100%.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear recommendations for data visualization tools that are flexible to use, can connect to and query from standard data warehouses (we use BigQuery mostly), and most importantly can produce reports that are filterable by the end user. Most of what we want to display is aggregate, filterable stats and rollups on user activity, where we have ~20 million activity data points across ~500k users.   &lt;/p&gt;\n\n&lt;p&gt;So far we&amp;#39;ve looked into Mode and Tableau, but with mode being acquired (yesterday) we&amp;#39;re skeptical, and Tableau at least at first doesn&amp;#39;t look very user-friendly to non-technical users. Open to considering both of these though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14kogbl", "is_robot_indexable": true, "report_reasons": null, "author": "chas_jk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kogbl/recommendations_for_userfriendly_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kogbl/recommendations_for_userfriendly_data/", "subreddit_subscribers": 112823, "created_utc": 1687897546.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}