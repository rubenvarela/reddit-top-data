{"kind": "Listing", "data": {"after": "t3_141bww4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Don't Let Reddit Kill 3rd Party Apps!\n\n#What's going on?\n\nA recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app **permanently inaccessible** to users.\n\nOn May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from [Apollo](https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/) to [Reddit is Fun](https://www.reddit.com/r/redditisfun/comments/13wxepd/rif_dev_here_reddits_api_changes_will_likely_kill/) to [Narwhal](https://www.reddit.com/r/getnarwhal/comments/13wv038/reddit_have_quoted_the_apollo_devs_a_ridiculous/jmdqtyt/) to [BaconReader](https://www.reddit.com/r/baconreader/comments/13wveb2/reddit_api_changes_and_baconreader/).\n\nEven if you're not a mobile user and don't use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface [](/ajwtf \"and everything that goes with it!\").\n\nThis isn't only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.\n\n#What's the plan? \n\nOn June 12th, [many subreddits](https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/) will be going dark to protest this policy. Some will return after 48 hours: others will go away *permanently* unless the issue is adequately addressed, since many moderators aren't able to put in the work they do with the poor tools available through the official app. This isn't something any of us do lightly: we do what we do because *we love Reddit*, and we truly believe this change will make it impossible to keep doing what we love.\n\nThe two-day blackout isn't the *goal*, and it isn't the end. Should things reach the 14th with no sign of Reddit choosing to fix what they've broken, we'll use the community and buzz we've built between then and now as a tool for further action.\n\nWhat can *you* do?\n\n1. **Complain.** Message the mods of /r/reddit.com, who are the admins of the site: message /u/reddit: submit a [support request](https://support.reddithelp.com/hc/en-us/requests/new): comment in relevant threads on /r/reddit, such as [this one](https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/.), leave a negative review on their official iOS or Android app- and sign your username in support to this post.\n\n2. **Spread the word.** Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at /r/ModCoord.\n\n3. **Boycott *and* spread the word...to Reddit's competition!** Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite *non*-Reddit platform of choice and make some noise in support!\n\n4. **Don't be a jerk.** As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible.\n\n**Further reading**\n\nhttps://www.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/\n\nhttps://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/\n\nhttps://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/\n\nhttps://www.reddit.com/r/SubredditDrama/comments/1404hwj/mods_of_rblind_reveal_that_removing_3rd_party/\n\nhttps://www.reddit.com/r/redditdev/comments/13wsiks/api_update_enterprise_level_tier_for_large_scale/jmolrhn/?context=3\n\nedit: [Open Letter regarding API pricing](https://www.reddit.com/r/ModCoord/comments/13xh1e7/an_open_letter_on_the_state_of_affairs_regarding/)\n\n[View Poll](https://www.reddit.com/poll/140xtxu)", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the DE community want to join the Reddit protest?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140xtxu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "#46d160", "subreddit_type": "public", "ups": 154, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 154, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685928833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t Let Reddit Kill 3rd Party Apps!&lt;/p&gt;\n\n&lt;h1&gt;What&amp;#39;s going on?&lt;/h1&gt;\n\n&lt;p&gt;A recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app &lt;strong&gt;permanently inaccessible&lt;/strong&gt; to users.&lt;/p&gt;\n\n&lt;p&gt;On May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from &lt;a href=\"https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/\"&gt;Apollo&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/redditisfun/comments/13wxepd/rif_dev_here_reddits_api_changes_will_likely_kill/\"&gt;Reddit is Fun&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/getnarwhal/comments/13wv038/reddit_have_quoted_the_apollo_devs_a_ridiculous/jmdqtyt/\"&gt;Narwhal&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/baconreader/comments/13wveb2/reddit_api_changes_and_baconreader/\"&gt;BaconReader&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Even if you&amp;#39;re not a mobile user and don&amp;#39;t use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface &lt;a href=\"/ajwtf\" title=\"and everything that goes with it!\"&gt;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.&lt;/p&gt;\n\n&lt;h1&gt;What&amp;#39;s the plan?&lt;/h1&gt;\n\n&lt;p&gt;On June 12th, &lt;a href=\"https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/\"&gt;many subreddits&lt;/a&gt; will be going dark to protest this policy. Some will return after 48 hours: others will go away &lt;em&gt;permanently&lt;/em&gt; unless the issue is adequately addressed, since many moderators aren&amp;#39;t able to put in the work they do with the poor tools available through the official app. This isn&amp;#39;t something any of us do lightly: we do what we do because &lt;em&gt;we love Reddit&lt;/em&gt;, and we truly believe this change will make it impossible to keep doing what we love.&lt;/p&gt;\n\n&lt;p&gt;The two-day blackout isn&amp;#39;t the &lt;em&gt;goal&lt;/em&gt;, and it isn&amp;#39;t the end. Should things reach the 14th with no sign of Reddit choosing to fix what they&amp;#39;ve broken, we&amp;#39;ll use the community and buzz we&amp;#39;ve built between then and now as a tool for further action.&lt;/p&gt;\n\n&lt;p&gt;What can &lt;em&gt;you&lt;/em&gt; do?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Complain.&lt;/strong&gt; Message the mods of &lt;a href=\"/r/reddit.com\"&gt;/r/reddit.com&lt;/a&gt;, who are the admins of the site: message &lt;a href=\"/u/reddit\"&gt;/u/reddit&lt;/a&gt;: submit a &lt;a href=\"https://support.reddithelp.com/hc/en-us/requests/new\"&gt;support request&lt;/a&gt;: comment in relevant threads on &lt;a href=\"/r/reddit\"&gt;/r/reddit&lt;/a&gt;, such as &lt;a href=\"https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/.\"&gt;this one&lt;/a&gt;, leave a negative review on their official iOS or Android app- and sign your username in support to this post.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Spread the word.&lt;/strong&gt; Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at &lt;a href=\"/r/ModCoord\"&gt;/r/ModCoord&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Boycott &lt;em&gt;and&lt;/em&gt; spread the word...to Reddit&amp;#39;s competition!&lt;/strong&gt; Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite &lt;em&gt;non&lt;/em&gt;-Reddit platform of choice and make some noise in support!&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Don&amp;#39;t be a jerk.&lt;/strong&gt; As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Further reading&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/\"&gt;https://www.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/\"&gt;https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/\"&gt;https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/SubredditDrama/comments/1404hwj/mods_of_rblind_reveal_that_removing_3rd_party/\"&gt;https://www.reddit.com/r/SubredditDrama/comments/1404hwj/mods_of_rblind_reveal_that_removing_3rd_party/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/redditdev/comments/13wsiks/api_update_enterprise_level_tier_for_large_scale/jmolrhn/?context=3\"&gt;https://www.reddit.com/r/redditdev/comments/13wsiks/api_update_enterprise_level_tier_for_large_scale/jmolrhn/?context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit: &lt;a href=\"https://www.reddit.com/r/ModCoord/comments/13xh1e7/an_open_letter_on_the_state_of_affairs_regarding/\"&gt;Open Letter regarding API pricing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/140xtxu\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": "moderator", "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "140xtxu", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 42, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1686360833597, "options": [{"text": "Join the protest", "id": "23340610"}, {"text": "Don\u2019t join the protest", "id": "23340611"}, {"text": "Other: tell us in the comments!", "id": "23340612"}, {"text": "I just want to see the results", "id": "23340613"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 1461, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/140xtxu/does_the_de_community_want_to_join_the_reddit/", "parent_whitelist_status": "all_ads", "stickied": true, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/140xtxu/does_the_de_community_want_to_join_the_reddit/", "subreddit_subscribers": 109026, "created_utc": 1685928833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much title.\n\nPython and SQL are must-know-to-survive languages. Besides that, everything else's value seems dubious at best.\n\nThe next three on the list of importance would be Scala, Java and R. But like I said, the value of learning any of those three is very questionable.\n\nC/C++ could be considered for writing python extension, and Go and Rust for their future potential.\n\nWhat do you thing about this whole situation?", "author_fullname": "t2_13cgzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In DE, is there a language that is actually worth learning besides Python and SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140y77y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685929648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much title.&lt;/p&gt;\n\n&lt;p&gt;Python and SQL are must-know-to-survive languages. Besides that, everything else&amp;#39;s value seems dubious at best.&lt;/p&gt;\n\n&lt;p&gt;The next three on the list of importance would be Scala, Java and R. But like I said, the value of learning any of those three is very questionable.&lt;/p&gt;\n\n&lt;p&gt;C/C++ could be considered for writing python extension, and Go and Rust for their future potential.&lt;/p&gt;\n\n&lt;p&gt;What do you thing about this whole situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "140y77y", "is_robot_indexable": true, "report_reasons": null, "author": "Altrooke", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140y77y/in_de_is_there_a_language_that_is_actually_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140y77y/in_de_is_there_a_language_that_is_actually_worth/", "subreddit_subscribers": 109026, "created_utc": 1685929648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologize if this question has been asked countless times. As a newly hired DE I was advised by my Supervisor to improve my SQL knowledge from a 5 to 8/10 and be more versed in BigQuery and GCP\n\nMy previous experience as a Software Developer didn't provide difficult database tasks, so my SQL skills are limited to the basic CRUD and creation of schema and tables. \n\nGoing back to my question, how do I proceed from here? I checked the links in the faq but I still feel lost.", "author_fullname": "t2_c58xvng2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get better in SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1415jdb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685948603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologize if this question has been asked countless times. As a newly hired DE I was advised by my Supervisor to improve my SQL knowledge from a 5 to 8/10 and be more versed in BigQuery and GCP&lt;/p&gt;\n\n&lt;p&gt;My previous experience as a Software Developer didn&amp;#39;t provide difficult database tasks, so my SQL skills are limited to the basic CRUD and creation of schema and tables. &lt;/p&gt;\n\n&lt;p&gt;Going back to my question, how do I proceed from here? I checked the links in the faq but I still feel lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1415jdb", "is_robot_indexable": true, "report_reasons": null, "author": "dehydratedcatnip", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1415jdb/how_do_i_get_better_in_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1415jdb/how_do_i_get_better_in_sql/", "subreddit_subscribers": 109026, "created_utc": 1685948603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_aqzwz9ec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta 2.3 - huge update for Change data feed users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_140nh3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-_JKjejvDLsMH1sCmDK5t9rz54NSPyYsQuqiRo9rae0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685906835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/codex/delta-lake-game-changing-update-to-productionize-change-data-feed-f1bf469a3f15", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?auto=webp&amp;v=enabled&amp;s=496fa08858a47ec4b788c7fb48e86a9a26484206", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65a7171388777dd5abbd23759b0024982ab3ab88", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d60beb4e6e9df9c4e595648998e3d1b5c8d368f", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84b2d8865f8cdef763f1b287fc22d67d48fe1388", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4308ea234a30b4f08f7a8d18c207684e31ae2202", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=759a7c895442ea6fc3b32205fa28f14bff23152f", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/XTs9s466ld_MB0sU25wvWNXDDr0RpAfL9gbA-KrwAzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b51df8daf2d67961b69f0ecbdb2dbb9a03f023e", "width": 1080, "height": 720}], "variants": {}, "id": "65zyPz3pDYUNargtMV3K-4yh3XGkxez_1HyAOqZEqwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "140nh3n", "is_robot_indexable": true, "report_reasons": null, "author": "Sensitive-Noise-3261", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140nh3n/delta_23_huge_update_for_change_data_feed_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/codex/delta-lake-game-changing-update-to-productionize-change-data-feed-f1bf469a3f15", "subreddit_subscribers": 109026, "created_utc": 1685906835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not only am I getting mountains of emails from vendors, but now emails from leadership and department heads who are apt to respond to a flashy vendor email.\n\nI\u2019m skeptical of most of these products to say the least. But it\u2019s not always bad to have the business seeing more value to data.\n\nBut I\u2019m curious how others are tempering expectations as well as a general outlook on utilizing these technologies?\n\nMy thoughts are it\u2019s doubtful any business has a well proven product with GPT being so new, and it\u2019s the same buzzwords all over again but with AI replacing RPA.", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is everyone handling the wave of Chat GPT-based software products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141ijx5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685979661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not only am I getting mountains of emails from vendors, but now emails from leadership and department heads who are apt to respond to a flashy vendor email.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m skeptical of most of these products to say the least. But it\u2019s not always bad to have the business seeing more value to data.&lt;/p&gt;\n\n&lt;p&gt;But I\u2019m curious how others are tempering expectations as well as a general outlook on utilizing these technologies?&lt;/p&gt;\n\n&lt;p&gt;My thoughts are it\u2019s doubtful any business has a well proven product with GPT being so new, and it\u2019s the same buzzwords all over again but with AI replacing RPA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "141ijx5", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141ijx5/how_is_everyone_handling_the_wave_of_chat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141ijx5/how_is_everyone_handling_the_wave_of_chat/", "subreddit_subscribers": 109026, "created_utc": 1685979661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seeing alot of news around Doris and it's performance benchmarks.\n\n\nSo, is it the next big thing to pocket?", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Doris the next big thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141eswm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685972153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeing alot of news around Doris and it&amp;#39;s performance benchmarks.&lt;/p&gt;\n\n&lt;p&gt;So, is it the next big thing to pocket?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "141eswm", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141eswm/is_apache_doris_the_next_big_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141eswm/is_apache_doris_the_next_big_thing/", "subreddit_subscribers": 109026, "created_utc": 1685972153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am modeling a postgres database and I'm wondering about filling via several sources ( other databases, CSV, txt, user etc... ). There's potentially a lot of data to extract and transform before integrating it into my database. The only purpose of this database is to feed applications, not analysis, just simple SQL request. Is it therefore correct to create a data pipeline or to say that the preparation process is a pipeline although the database is not a datawarehouse?\n\nThank you.", "author_fullname": "t2_q95335vn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Probably a stupid question... Can a pipeline be used to fill an OLTP database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1416a3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685951228.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685950661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am modeling a postgres database and I&amp;#39;m wondering about filling via several sources ( other databases, CSV, txt, user etc... ). There&amp;#39;s potentially a lot of data to extract and transform before integrating it into my database. The only purpose of this database is to feed applications, not analysis, just simple SQL request. Is it therefore correct to create a data pipeline or to say that the preparation process is a pipeline although the database is not a datawarehouse?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1416a3t", "is_robot_indexable": true, "report_reasons": null, "author": "Aquilae2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1416a3t/probably_a_stupid_question_can_a_pipeline_be_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1416a3t/probably_a_stupid_question_can_a_pipeline_be_used/", "subreddit_subscribers": 109026, "created_utc": 1685950661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a database set up like so:\n\n    1. Campaign table references:\n       - None\n    \n    2. AdGroup table references:\n       - `Campaign` table via the `campaign_id` foreign key.\n    \n    3. AdGroupAd table references:\n       - `AdGroup` table via the `ad_group_id` foreign key.\n\nIn reality, there's several more tables with many more relationships. So inserting data has become quite nuanced. For example, if I insert a new \\`AdGroupAd\\` record, I must first make sure that it has a corresponding \\`AdGroup\\`. By extension, I must make sure there's also a corresponding \\`Campaign\\`. This gets a little overwhelming after awhile.\n\nI was thinking, I can create a table called \\`LoadingZone\\` where I can insert the entire raw data--which looks like this:\n\n    [\n        {\n            \"campaign\": \"international_stuff\",\n            \"ad_group\": \"regional_1\",\n            \"ad\": \"blue\"\n        },\n        {\n            \"campaign\": \"international_stuff\",\n            \"ad_group\": \"regional_2\",\n            \"ad\": \"blue\"\n        },\n        {\n            \"campaign\": \"local_stuff\",\n            \"ad_group\": \"holiday_special\",\n            \"ad\": \"ice_cream\"\n        }\n    ]\n\nIn theory, my \"LoadingZone\" table will have a trigger before insert. The trigger will iterate through each row in there and try inserting everything to their respective table (in the correct order) with \\`ON CONFLICT IGNORE\\`.\n\nAlternatively, I can make code that does this from outside the database, and expect errors to arise if a conflict ever occurs.\n\nWhich way is better?  \n\n\nEdit: No replies yet, but I think I'm going to go with the trigger approach. Because the database should ideally be more optimized at triaging data to tables than any Python code I write to do the same. Secondly, if there is an error in the middle of inserting hierarchy data to several tables... that sounds like a mess. With a trigger, I believe the entire hierarchy (multiple inserts) should either fail or pass. That sounds ideal to me.", "author_fullname": "t2_k648rah9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With a database containing hierarchical tables, is it better to have a simple insert design and let the database handle all the nuances of which table needs which data first?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141jg50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685987667.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685981434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a database set up like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;1. Campaign table references:\n   - None\n\n2. AdGroup table references:\n   - `Campaign` table via the `campaign_id` foreign key.\n\n3. AdGroupAd table references:\n   - `AdGroup` table via the `ad_group_id` foreign key.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In reality, there&amp;#39;s several more tables with many more relationships. So inserting data has become quite nuanced. For example, if I insert a new `AdGroupAd` record, I must first make sure that it has a corresponding `AdGroup`. By extension, I must make sure there&amp;#39;s also a corresponding `Campaign`. This gets a little overwhelming after awhile.&lt;/p&gt;\n\n&lt;p&gt;I was thinking, I can create a table called `LoadingZone` where I can insert the entire raw data--which looks like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[\n    {\n        &amp;quot;campaign&amp;quot;: &amp;quot;international_stuff&amp;quot;,\n        &amp;quot;ad_group&amp;quot;: &amp;quot;regional_1&amp;quot;,\n        &amp;quot;ad&amp;quot;: &amp;quot;blue&amp;quot;\n    },\n    {\n        &amp;quot;campaign&amp;quot;: &amp;quot;international_stuff&amp;quot;,\n        &amp;quot;ad_group&amp;quot;: &amp;quot;regional_2&amp;quot;,\n        &amp;quot;ad&amp;quot;: &amp;quot;blue&amp;quot;\n    },\n    {\n        &amp;quot;campaign&amp;quot;: &amp;quot;local_stuff&amp;quot;,\n        &amp;quot;ad_group&amp;quot;: &amp;quot;holiday_special&amp;quot;,\n        &amp;quot;ad&amp;quot;: &amp;quot;ice_cream&amp;quot;\n    }\n]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In theory, my &amp;quot;LoadingZone&amp;quot; table will have a trigger before insert. The trigger will iterate through each row in there and try inserting everything to their respective table (in the correct order) with `ON CONFLICT IGNORE`.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, I can make code that does this from outside the database, and expect errors to arise if a conflict ever occurs.&lt;/p&gt;\n\n&lt;p&gt;Which way is better?  &lt;/p&gt;\n\n&lt;p&gt;Edit: No replies yet, but I think I&amp;#39;m going to go with the trigger approach. Because the database should ideally be more optimized at triaging data to tables than any Python code I write to do the same. Secondly, if there is an error in the middle of inserting hierarchy data to several tables... that sounds like a mess. With a trigger, I believe the entire hierarchy (multiple inserts) should either fail or pass. That sounds ideal to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141jg50", "is_robot_indexable": true, "report_reasons": null, "author": "MrChadWood", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141jg50/with_a_database_containing_hierarchical_tables_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141jg50/with_a_database_containing_hierarchical_tables_is/", "subreddit_subscribers": 109026, "created_utc": 1685981434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've done dp-203, dp-900 and az-900 but felt it wasn't sufficient. After getting those, I now work using SQL Server, T-SQL, SSMS and SSIS in Visual Studio. \n\nI really want to do DE in Azure and have been getting job interviews and doing well but my Azure technology experience let's me down a little. \n\nI find it MUCH better learning on the job with projects and a little guidance but don't have the privilege. \n\nIve tried learning more through YouTube but most are just basic explanations or basic \"copy this table into azure\" and nothing juicy enough for me to get some good experience and ideas. \n\nI've tried doing some solo projects but without the knowledge I tend to bugger something up and no idea how to fix it. \n\nDoes anyone have any good resources to help be get good with learning ADF, data warehousing, modelling and a little Power BI? \n\nHope this makes sense!\n\nThanks!", "author_fullname": "t2_6o5h731v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help getting DE experience in Azure stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141h76i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685976997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve done dp-203, dp-900 and az-900 but felt it wasn&amp;#39;t sufficient. After getting those, I now work using SQL Server, T-SQL, SSMS and SSIS in Visual Studio. &lt;/p&gt;\n\n&lt;p&gt;I really want to do DE in Azure and have been getting job interviews and doing well but my Azure technology experience let&amp;#39;s me down a little. &lt;/p&gt;\n\n&lt;p&gt;I find it MUCH better learning on the job with projects and a little guidance but don&amp;#39;t have the privilege. &lt;/p&gt;\n\n&lt;p&gt;Ive tried learning more through YouTube but most are just basic explanations or basic &amp;quot;copy this table into azure&amp;quot; and nothing juicy enough for me to get some good experience and ideas. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried doing some solo projects but without the knowledge I tend to bugger something up and no idea how to fix it. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any good resources to help be get good with learning ADF, data warehousing, modelling and a little Power BI? &lt;/p&gt;\n\n&lt;p&gt;Hope this makes sense!&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141h76i", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous6156", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141h76i/help_getting_de_experience_in_azure_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141h76i/help_getting_de_experience_in_azure_stack/", "subreddit_subscribers": 109026, "created_utc": 1685976997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for some advice here. There is lots to be found on automating the load of a Data Vault warehouse, with hubs, links &amp; satellites. But unless you want a transactional system driven (as opposed to domain driven) warehouse, there needs to be some form of modelling in the staging area prior to ingestion. \n\nExample: our Salesforce Account table holds leads, customers, companies, stores etc. and each of these would arguably sit in a different hub. An automated solution will just build off the source, which means the source (staging area) would need these modelled out into different tables - account_lead; account_customer; account_store etc.\n\nOur raw data sits in Snowflake, replicated there by FiveTran. Prior to ingesting into DV, what would your tool of choice be to load your staging tables?\n\n- basic sql;\n- dbt;\n- SQLMesh;\n- something else?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Staging area before data vault", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141bqzf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685965221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some advice here. There is lots to be found on automating the load of a Data Vault warehouse, with hubs, links &amp;amp; satellites. But unless you want a transactional system driven (as opposed to domain driven) warehouse, there needs to be some form of modelling in the staging area prior to ingestion. &lt;/p&gt;\n\n&lt;p&gt;Example: our Salesforce Account table holds leads, customers, companies, stores etc. and each of these would arguably sit in a different hub. An automated solution will just build off the source, which means the source (staging area) would need these modelled out into different tables - account_lead; account_customer; account_store etc.&lt;/p&gt;\n\n&lt;p&gt;Our raw data sits in Snowflake, replicated there by FiveTran. Prior to ingesting into DV, what would your tool of choice be to load your staging tables?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;basic sql;&lt;/li&gt;\n&lt;li&gt;dbt;&lt;/li&gt;\n&lt;li&gt;SQLMesh;&lt;/li&gt;\n&lt;li&gt;something else?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141bqzf", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141bqzf/staging_area_before_data_vault/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141bqzf/staging_area_before_data_vault/", "subreddit_subscribers": 109026, "created_utc": 1685965221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  I have a DW/Datalake setup on AWS S3 with Delta format.\n  My data consumers get access to the data via:\n- athena - via glue catalog/ manifest backed\n- redshift - external tables\n- Databricks sql endpoint/notebooks\n\nI am trying to wrap my head around how to monitor Data Access and audit it? \n I do have redshift setup with saml and i can consume the redshift internals.\n Athena i can use cloudwatch and cloudtrail, but will cost me an arm and a leg.\n\n What do i do about Databricks ? How can i persist thehitory of runned queries? \n\nThx", "author_fullname": "t2_nxu067bi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake - Data Access Audit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1418y5z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685958055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a DW/Datalake setup on AWS S3 with Delta format.\n  My data consumers get access to the data via:\n- athena - via glue catalog/ manifest backed\n- redshift - external tables\n- Databricks sql endpoint/notebooks&lt;/p&gt;\n\n&lt;p&gt;I am trying to wrap my head around how to monitor Data Access and audit it? \n I do have redshift setup with saml and i can consume the redshift internals.\n Athena i can use cloudwatch and cloudtrail, but will cost me an arm and a leg.&lt;/p&gt;\n\n&lt;p&gt;What do i do about Databricks ? How can i persist thehitory of runned queries? &lt;/p&gt;\n\n&lt;p&gt;Thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1418y5z", "is_robot_indexable": true, "report_reasons": null, "author": "InsightByte", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1418y5z/datalake_data_access_audit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1418y5z/datalake_data_access_audit/", "subreddit_subscribers": 109026, "created_utc": 1685958055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, My organization is working on our first dbt project. We are Azure partners and I am figuring out how to deploy dbt in Azure infrastructure. Right now we have two options under consideration:\n\n1: Install dbt on a VM and schedule from ADF.\n\n2: Install dbt on Azure Container Instances after dockerizing and schedule from ADF. \n\n&amp;#x200B;\n\nWhich option do you advice ?. If there is a better alternative, please advice on it.", "author_fullname": "t2_o78u2p44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt deployment in Docker or VM ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1418rxw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685957562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, My organization is working on our first dbt project. We are Azure partners and I am figuring out how to deploy dbt in Azure infrastructure. Right now we have two options under consideration:&lt;/p&gt;\n\n&lt;p&gt;1: Install dbt on a VM and schedule from ADF.&lt;/p&gt;\n\n&lt;p&gt;2: Install dbt on Azure Container Instances after dockerizing and schedule from ADF. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Which option do you advice ?. If there is a better alternative, please advice on it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1418rxw", "is_robot_indexable": true, "report_reasons": null, "author": "SignificanceNo136", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1418rxw/dbt_deployment_in_docker_or_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1418rxw/dbt_deployment_in_docker_or_vm/", "subreddit_subscribers": 109026, "created_utc": 1685957562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, fellow data enthusiasts! \ud83d\udc4b\n\nWe just launched the alpha release of [Sherloq](https://sherloqdata.io/?utm_source=redditl&amp;utm_medium=post&amp;utm_campaign=data_page) \ud83e\udd29 With this free Chrome extension, you can effortlessly save your SQL queries from any web editor you use, organize it in a folder and keep your KPI calculations aligned with your teammates. No more lost queries! It also offers a snippet tool with convenient keyboard shortcuts for repetitive code. Whether you're a data scientist or a developer, Sherloq empowers you to stay organized and efficient.\n\nWe know the struggle of organizing and managing your SQL queries scattered across various platforms like Slack or notes. That's why we're excited to introduce our collaborative data platform that designed to solve this headache!\n\n&amp;#x200B;\n\n[Here is an example of a saved SQL snippet injected with a keyboard shortcut t code edit](https://i.redd.it/uhz6ec3up54b1.gif)\n\n&amp;#x200B;\n\nWe're constantly working on enhancing Sherloq's features and usability. And we want you to be a part of it! Join us for the [alpha release and try out Sherloq for free](https://chrome.google.com/webstore/detail/sherloq-save-share-simpli/kjndilccgkemibeimjdefmjkhfddobfk). Explore our cool features and let us know your feedback or feature requests. Your input will help shape the platform and make it even more powerful!", "author_fullname": "t2_vgo9vaei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sherloq: Chrome extension for query management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 17, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uhz6ec3up54b1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/uhz6ec3up54b1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=2421174a67d48580a7e2bbdb3ea5b8a1bd7365d3"}, {"y": 139, "x": 216, "u": "https://preview.redd.it/uhz6ec3up54b1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3ebc2f3b88ba013eefaf9510f8aaf64593873398"}, {"y": 206, "x": 320, "u": "https://preview.redd.it/uhz6ec3up54b1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=8112e6763498acc65c322aefdf2ccabea3bed35f"}], "s": {"y": 388, "gif": "https://i.redd.it/uhz6ec3up54b1.gif", "mp4": "https://preview.redd.it/uhz6ec3up54b1.gif?format=mp4&amp;v=enabled&amp;s=8ef4dd7473e0889f83d51f7c8281d3c56e3acef6", "x": 600}, "id": "uhz6ec3up54b1"}}, "name": "t3_1416wy0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HkDpKsZnvP7_a8s_jXIuL34m-kSy77e7K-IAMhWnW1Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1685952341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, fellow data enthusiasts! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;We just launched the alpha release of &lt;a href=\"https://sherloqdata.io/?utm_source=redditl&amp;amp;utm_medium=post&amp;amp;utm_campaign=data_page\"&gt;Sherloq&lt;/a&gt; \ud83e\udd29 With this free Chrome extension, you can effortlessly save your SQL queries from any web editor you use, organize it in a folder and keep your KPI calculations aligned with your teammates. No more lost queries! It also offers a snippet tool with convenient keyboard shortcuts for repetitive code. Whether you&amp;#39;re a data scientist or a developer, Sherloq empowers you to stay organized and efficient.&lt;/p&gt;\n\n&lt;p&gt;We know the struggle of organizing and managing your SQL queries scattered across various platforms like Slack or notes. That&amp;#39;s why we&amp;#39;re excited to introduce our collaborative data platform that designed to solve this headache!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/uhz6ec3up54b1.gif\"&gt;Here is an example of a saved SQL snippet injected with a keyboard shortcut t code edit&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re constantly working on enhancing Sherloq&amp;#39;s features and usability. And we want you to be a part of it! Join us for the &lt;a href=\"https://chrome.google.com/webstore/detail/sherloq-save-share-simpli/kjndilccgkemibeimjdefmjkhfddobfk\"&gt;alpha release and try out Sherloq for free&lt;/a&gt;. Explore our cool features and let us know your feedback or feature requests. Your input will help shape the platform and make it even more powerful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?auto=webp&amp;v=enabled&amp;s=a6ddbe5ebc94895fcc16642562572ba1cfbf4a27", "width": 1024, "height": 131}, "resolutions": [{"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a21afc50ed0b4f2a167730c1f0690e39818af994", "width": 108, "height": 13}, {"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5262580a59e0d01dd1ab8f24234f0921d5bed6be", "width": 216, "height": 27}, {"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ff6b5e6278956b2b095f3768e649f5a29a3a510", "width": 320, "height": 40}, {"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bea029fd1205c3f80b838c3b333f01f2ce39f85a", "width": 640, "height": 81}, {"url": "https://external-preview.redd.it/mYUPF3GbHOtlFa6UY8QuXuhwaWJPNu0ouFkcdj9h6W4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b35941c2de2b4191f2d234aeca6084f9c3c5e5cd", "width": 960, "height": 122}], "variants": {}, "id": "WIejn18f-7pW7brSGEj-Lt7qSAGVJ5ofhiDCuH9gKco"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1416wy0", "is_robot_indexable": true, "report_reasons": null, "author": "hellosherloq1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1416wy0/sherloq_chrome_extension_for_query_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1416wy0/sherloq_chrome_extension_for_query_management/", "subreddit_subscribers": 109026, "created_utc": 1685952341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pardon me for this unclear use case. I wanted to know if we can make SFTP even more secure by using some kind of multifactor authentication in the form of SSH keys or certificates? I believe it's not necessary to do so as SFTP implies that everything is encrypted and secured over the network but is there any caveat to this?", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SFTP with some kind of multifactor auth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1411xjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685938847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pardon me for this unclear use case. I wanted to know if we can make SFTP even more secure by using some kind of multifactor authentication in the form of SSH keys or certificates? I believe it&amp;#39;s not necessary to do so as SFTP implies that everything is encrypted and secured over the network but is there any caveat to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1411xjn", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1411xjn/sftp_with_some_kind_of_multifactor_auth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1411xjn/sftp_with_some_kind_of_multifactor_auth/", "subreddit_subscribers": 109026, "created_utc": 1685938847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data teams ticket takers or decision makers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_141mm5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kpT-5cEDFtmFInhplih-1oOkSQD5NNJ3F57ni9_g0iM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685987733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/data-ticket-takers-vs-decision-makers-a6cf957b507a?source=friends_link&amp;sk=8e7d47f140ed3f52fb28c20afbaef857", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?auto=webp&amp;v=enabled&amp;s=4bb49ecea64a7f1202f6feca5180cf599a787581", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c37175c432cbcfcfe8a8137b16e632f4277ae695", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f74ae6673c837d75931c755e99a0195512544ad", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0fcfc0e5f281cbf54e60f111b9561bbbca7f4ba4", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d49462121ab79fe5e96a0c9f9d787e5924b2146c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e07e5cc45eeb9d189ed12770abf052b30581f1dc", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/c29SdWi1xl771_I4NksyuZnqWj4C4BddpjnDTo6MKE8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=143ac4f8ddf1b3360a7fda0604683595d20dd195", "width": 1080, "height": 607}], "variants": {}, "id": "Uoz-O1WeN4siWLyEn-9XyIVY3xbQocAz9iebFjC37C4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "141mm5c", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141mm5c/are_data_teams_ticket_takers_or_decision_makers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/data-ticket-takers-vs-decision-makers-a6cf957b507a?source=friends_link&amp;sk=8e7d47f140ed3f52fb28c20afbaef857", "subreddit_subscribers": 109026, "created_utc": 1685987733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious how others document their data architecture. I wonder if there are any standards around this or if there is a lot of variance.  Would be great if you could include what types of diagrams and sections you would see along with how this presented to new employees or stakeholders.\n\nFor me, I'm built 2 data architectures as the a lone wolf data engineer.  My current documentation includes \n\n* An architecture diagram that shows all the cloud technologies and connections between them.\n* Brief descriptions of the phases like 'Data Ingestion', 'Orchestration', 'Reporting'.  \n\nThis documentation is mostly for my own reference and truth be told I'm wondering what else I should be including.", "author_fullname": "t2_5065w9mg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you or your company document your data architecture? What is typically included in the documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_141lrjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685986040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious how others document their data architecture. I wonder if there are any standards around this or if there is a lot of variance.  Would be great if you could include what types of diagrams and sections you would see along with how this presented to new employees or stakeholders.&lt;/p&gt;\n\n&lt;p&gt;For me, I&amp;#39;m built 2 data architectures as the a lone wolf data engineer.  My current documentation includes &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An architecture diagram that shows all the cloud technologies and connections between them.&lt;/li&gt;\n&lt;li&gt;Brief descriptions of the phases like &amp;#39;Data Ingestion&amp;#39;, &amp;#39;Orchestration&amp;#39;, &amp;#39;Reporting&amp;#39;.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This documentation is mostly for my own reference and truth be told I&amp;#39;m wondering what else I should be including.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "141lrjm", "is_robot_indexable": true, "report_reasons": null, "author": "kvotheTHEinquisitor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141lrjm/how_do_you_or_your_company_document_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141lrjm/how_do_you_or_your_company_document_your_data/", "subreddit_subscribers": 109026, "created_utc": 1685986040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I relatively often see people referring that they do the E(t)L of ELT with basic Python and the T with SQL.  \nWhat is your approach to the EL in Python?\n\nI am recent graduate in data science and after my internship got a full time position in a non-tech company (football/soccer club) with no data infrastructure, and no employees with a computer or data science background.  \nMy thoughts would be to built api wrappers in Python, which is already done as I have used them for apps and reports through my internship, and then use pandas (or polars) to do the (t) from .json to dataframes/tables. Do the insert, update and delete using sqlalchemy and schedule the scripts using cron on a physical machine in the office (i.e. my old windows computer).  \nIt is a very basic and fragile setup, but on a limited budget, it is to my knowledge, a good way to start and then convince the organization to invest more resources and me learning in tools and migrate to dagster, Airflow, dbt etc.\n\nWhat are your suggestions of how to do the EL in Python for very basic usage, and how do you approach the E(t)L with Python (custom api wrappers, pandas, sqlachemy, json objects, cron)?  \nWould love to see some examples if possible :)", "author_fullname": "t2_226yoed5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do the \"basic\" EL in Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141ib4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685979180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I relatively often see people referring that they do the E(t)L of ELT with basic Python and the T with SQL.&lt;br/&gt;\nWhat is your approach to the EL in Python?&lt;/p&gt;\n\n&lt;p&gt;I am recent graduate in data science and after my internship got a full time position in a non-tech company (football/soccer club) with no data infrastructure, and no employees with a computer or data science background.&lt;br/&gt;\nMy thoughts would be to built api wrappers in Python, which is already done as I have used them for apps and reports through my internship, and then use pandas (or polars) to do the (t) from .json to dataframes/tables. Do the insert, update and delete using sqlalchemy and schedule the scripts using cron on a physical machine in the office (i.e. my old windows computer).&lt;br/&gt;\nIt is a very basic and fragile setup, but on a limited budget, it is to my knowledge, a good way to start and then convince the organization to invest more resources and me learning in tools and migrate to dagster, Airflow, dbt etc.&lt;/p&gt;\n\n&lt;p&gt;What are your suggestions of how to do the EL in Python for very basic usage, and how do you approach the E(t)L with Python (custom api wrappers, pandas, sqlachemy, json objects, cron)?&lt;br/&gt;\nWould love to see some examples if possible :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141ib4n", "is_robot_indexable": true, "report_reasons": null, "author": "C_Ronsholt", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141ib4n/how_to_do_the_basic_el_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141ib4n/how_to_do_the_basic_el_in_python/", "subreddit_subscribers": 109026, "created_utc": 1685979180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So as the title states, I\u2019m currently a data analyst who wants to switch to DE. I\u2019ve realized at my current job I\u2019m way more into building things than analyzing, the issue is my current work place ONLY uses excel. I\u2019ve tried to have them budge, they won\u2019t. So I\u2019ve done everything I can to automate spreadsheets via PowerQuery. I\u2019m considering learning VBA for automation as well but I\u2019m unsure if it\u2019s worth while. \n\nWith that, my only other technical skills are some novice python, and sql. For python the most complex thing I\u2019ve built is a dnd character generator, but it scrapes random names from fantasy name generator. For SQL I can do basic querying, but outside of that I don\u2019t know much. \n\nThe issue I\u2019m having is I come here and see a bunch of terms and tools thrown around that I know nothing about. Just for examples sake, I see airflow being talked about often, but I have no clue what airflow is for, what it does, and where it\u2019s fits into data engineering. I also worry, that while I have some python and SQL knowledge, I don\u2019t know what I actually need to know. I\u2019ve never worked with SQL outside of my own home PC so I have no clue how it looks in a professional environment. \n\nI\u2019m not sure if I\u2019m explaining my issue well, but in short, I feel like I have a lot of gaps in what I need to know for data engineering. My current workplace isn\u2019t conductive to my learning really, but I can\u2019t really get a DE job to learn without the prerequisite DE knowledge. Any pointers in the direction I should look would be greatly appreciated", "author_fullname": "t2_49nguj2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m a DA who wants to learn DE but there\u2019s a lot of gaps I don\u2019t know how to fill", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141i57o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685978858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as the title states, I\u2019m currently a data analyst who wants to switch to DE. I\u2019ve realized at my current job I\u2019m way more into building things than analyzing, the issue is my current work place ONLY uses excel. I\u2019ve tried to have them budge, they won\u2019t. So I\u2019ve done everything I can to automate spreadsheets via PowerQuery. I\u2019m considering learning VBA for automation as well but I\u2019m unsure if it\u2019s worth while. &lt;/p&gt;\n\n&lt;p&gt;With that, my only other technical skills are some novice python, and sql. For python the most complex thing I\u2019ve built is a dnd character generator, but it scrapes random names from fantasy name generator. For SQL I can do basic querying, but outside of that I don\u2019t know much. &lt;/p&gt;\n\n&lt;p&gt;The issue I\u2019m having is I come here and see a bunch of terms and tools thrown around that I know nothing about. Just for examples sake, I see airflow being talked about often, but I have no clue what airflow is for, what it does, and where it\u2019s fits into data engineering. I also worry, that while I have some python and SQL knowledge, I don\u2019t know what I actually need to know. I\u2019ve never worked with SQL outside of my own home PC so I have no clue how it looks in a professional environment. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure if I\u2019m explaining my issue well, but in short, I feel like I have a lot of gaps in what I need to know for data engineering. My current workplace isn\u2019t conductive to my learning really, but I can\u2019t really get a DE job to learn without the prerequisite DE knowledge. Any pointers in the direction I should look would be greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141i57o", "is_robot_indexable": true, "report_reasons": null, "author": "Hillsand0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141i57o/im_a_da_who_wants_to_learn_de_but_theres_a_lot_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141i57o/im_a_da_who_wants_to_learn_de_but_theres_a_lot_of/", "subreddit_subscribers": 109026, "created_utc": 1685978858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI need couple of advices regarding career.\n\nCurrently I'm working in a bank as developer (Oracle technologies) and I have good experience with data analysis, ETL and BI (also some experience in Microsoft technologies)\nNow I'm planning to switch to real data engineering path. Knowing Python, I'm currently learning Pandas and other libraries and I have my eye on AWS and GCP.\n\nNow, my questions are:\n- What's the easiest way to find remote job,  and get into field professionaly? Also part-time option would be the best, so I could continue with the current job while obtaining experience with data engineering until I'm fully ready to switch jobs.\n\n- I have registered small company here in my country and I would like to use it for data engineering jobs. Is it easier / harder to get hired / payed as b2b? Should I mention this option to recruiters (I'm from Bosnia and Herzegovina, EU - if that makes any difference)\n\nAlso, any other advices about this would be appreciated.\n\nThanks in advance!", "author_fullname": "t2_swnotw4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching career to data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141i3gu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685978762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I need couple of advices regarding career.&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m working in a bank as developer (Oracle technologies) and I have good experience with data analysis, ETL and BI (also some experience in Microsoft technologies)\nNow I&amp;#39;m planning to switch to real data engineering path. Knowing Python, I&amp;#39;m currently learning Pandas and other libraries and I have my eye on AWS and GCP.&lt;/p&gt;\n\n&lt;p&gt;Now, my questions are:\n- What&amp;#39;s the easiest way to find remote job,  and get into field professionaly? Also part-time option would be the best, so I could continue with the current job while obtaining experience with data engineering until I&amp;#39;m fully ready to switch jobs.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I have registered small company here in my country and I would like to use it for data engineering jobs. Is it easier / harder to get hired / payed as b2b? Should I mention this option to recruiters (I&amp;#39;m from Bosnia and Herzegovina, EU - if that makes any difference)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also, any other advices about this would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "141i3gu", "is_robot_indexable": true, "report_reasons": null, "author": "Doza071", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141i3gu/switching_career_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141i3gu/switching_career_to_data_engineer/", "subreddit_subscribers": 109026, "created_utc": 1685978762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello fellow DE,\n\nI've been working on a project that uses AWS Lambdas written in Python, which get triggered upon the arrival of a file in an S3 bucket, and then proceed to write to a MySQL RDS database.\n\nI'm looking for ways to effectively perform integration tests on this workflow. I already wrote unit test that I can run locally and in my Github CI/CD pipeline.\n\nHere are some of the specific areas where I'd appreciate some guidance:\n\n1. **Mocking AWS Services**: What are the best practices to mock AWS services, specifically S3, Lambda, and MySQL RDS? I have come across some tools like moto  \n and localstack, but I'm unsure about their pros and cons, and whether there are better alternatives. Should I even mock my infra for integration test?\n2. **Data Persistence**: With the writing process to a MySQL RDS database, how can I ensure the data is correctly written and also reset the state for each test?\n\nI'm open to any tools, libraries, or best practices that could make my integration testing process more efficient and effective. Any examples or guides would be especially helpful.\n\nThank you in advance for your valuable inputs!", "author_fullname": "t2_gmwe0m1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Integration Testing for AWS Lambdas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1417dae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685953640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DE,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a project that uses AWS Lambdas written in Python, which get triggered upon the arrival of a file in an S3 bucket, and then proceed to write to a MySQL RDS database.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for ways to effectively perform integration tests on this workflow. I already wrote unit test that I can run locally and in my Github CI/CD pipeline.&lt;/p&gt;\n\n&lt;p&gt;Here are some of the specific areas where I&amp;#39;d appreciate some guidance:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Mocking AWS Services&lt;/strong&gt;: What are the best practices to mock AWS services, specifically S3, Lambda, and MySQL RDS? I have come across some tools like moto&lt;br/&gt;\nand localstack, but I&amp;#39;m unsure about their pros and cons, and whether there are better alternatives. Should I even mock my infra for integration test?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Persistence&lt;/strong&gt;: With the writing process to a MySQL RDS database, how can I ensure the data is correctly written and also reset the state for each test?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m open to any tools, libraries, or best practices that could make my integration testing process more efficient and effective. Any examples or guides would be especially helpful.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your valuable inputs!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1417dae", "is_robot_indexable": true, "report_reasons": null, "author": "baguetteFeuille", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1417dae/integration_testing_for_aws_lambdas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1417dae/integration_testing_for_aws_lambdas/", "subreddit_subscribers": 109026, "created_utc": 1685953640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been working in data science for about 4 years. I\u2019m switching to DE and slowly starting to apply for jobs. \n\nI know if I go in DS, I can land a senior DS positon. Realistically, could I land a senior DE job or will need to aim for DE given my background was mainly DS.", "author_fullname": "t2_t4jv8qi9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science to data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_141lm26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685985733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working in data science for about 4 years. I\u2019m switching to DE and slowly starting to apply for jobs. &lt;/p&gt;\n\n&lt;p&gt;I know if I go in DS, I can land a senior DS positon. Realistically, could I land a senior DE job or will need to aim for DE given my background was mainly DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "141lm26", "is_robot_indexable": true, "report_reasons": null, "author": "NoStrang3rDang3r", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141lm26/data_science_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141lm26/data_science_to_data_engineer/", "subreddit_subscribers": 109026, "created_utc": 1685985733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nI'm a master student in Computer science finishing in 20 days, who thought for a long time i wanted to be a data scientist, which many of my courses reflect. But have since figured out data engineering seems more like me.\n\nHow would you recommend that i learn to become a data engineer? Are there any courses that you would recommend? I have also worked with some of the tools used as a data engineer so would it make more sense more me to just learn what I'm missing and in that case which tools should i go about learning?", "author_fullname": "t2_3nlbcxry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Computer science major wanting to work as a data engineer! Any advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141je4p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685981323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a master student in Computer science finishing in 20 days, who thought for a long time i wanted to be a data scientist, which many of my courses reflect. But have since figured out data engineering seems more like me.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend that i learn to become a data engineer? Are there any courses that you would recommend? I have also worked with some of the tools used as a data engineer so would it make more sense more me to just learn what I&amp;#39;m missing and in that case which tools should i go about learning?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141je4p", "is_robot_indexable": true, "report_reasons": null, "author": "Run-Unusual", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141je4p/computer_science_major_wanting_to_work_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141je4p/computer_science_major_wanting_to_work_as_a_data/", "subreddit_subscribers": 109026, "created_utc": 1685981323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with Stress, Anxiety, and Hardship in the Workplace - For Data Teams.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_141goay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oW2ST2TqJh8lwUnOU7z_uPNio5HJuUT1-8T4kZEtJGU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685975962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/dealing-with-stress-anxiety-and-hardship", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?auto=webp&amp;v=enabled&amp;s=99414398c70bd3631b59ba8ac60fae8cb3c69ca4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4793c125b4ed7daf2542151156cffb135801b63a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f156d5ca38d969003d42eb37cccafd04c2e1c09", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=53fb1a728fa17f641cfb1638c6c9b8bc0bd6d86d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3776a5aaaa38f5a96bea915d2dfd7e78842045a2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=270b84fa85f88739e0f81ec4bb2c04d426d74af9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1Y7lxIaCpednikHFqFth7tEilJrtWdz4_q4UQUvdWus.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3489454e18359fdaf3e767c5ac7d03f8303f5bce", "width": 1080, "height": 540}], "variants": {}, "id": "2KFxKuutbxGF5hKkkkpCRiynNtuLX_DvDGRncEwMZwA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "141goay", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141goay/dealing_with_stress_anxiety_and_hardship_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/dealing-with-stress-anxiety-and-hardship", "subreddit_subscribers": 109026, "created_utc": 1685975962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors! \ud83d\udc4b\n\nAs a new intern exploring the fascinating world of ETL (Extract, Transform, Load), I'm seeking guidance on setting up a robust ETL pipeline using Amazon Web Services (AWS) to facilitate ML model training. Specifically, I have a MySQL RDS database as the data source and intend to generate structured output on S3, which will be utilized for training OCR (Optical Character Recognition) and LLM (Language Model) models.\n\nMy ultimate goal is to build an end-to-end pipeline that seamlessly extracts data from MySQL RDS, performs necessary transformations, and loads the transformed data into an S3 bucket. This structured data will then serve as the training dataset for ML models like OCR and LLM.\n\nAdditionally, I'm considering incorporating Kafka or AWS SQS into the pipeline for efficient data processing and message queuing, ensuring the smooth flow of data throughout the system.\n\nGiven my limited experience in ETL, I'm particularly interested in leveraging the capabilities of AWS services to simplify the process. Services like AWS Glue and AWS Lambda have caught my attention, but I'm unsure about how to integrate them effectively into the pipeline.\n\nHere's a summary of what I aim to accomplish:\n\n1. **Data Source**: MySQL RDS - Extracting data from a MySQL RDS database.\n2. **Transformation**: Applying necessary transformations, cleansing, and enrichment to the data; would be made clear to me later once I finalize the architecture\n3. **Structured Output**: Storing the transformed data in a structured format on an S3 bucket to serve as the training dataset for ML models (OCR, LLM)\n\nIf any experienced individuals have insights, tips, or step-by-step guidance on setting up this ETL pipeline using Amazon services such as AWS Glue, AWS Lambda, or any other relevant AWS services, I would greatly appreciate your valuable input!\n\nMoreover, if you have specific advice or best practices for training ML models like OCR and LLM using the structured data in S3, I would be thrilled to hear about them.\n\nI'm eager to delve into the world of ETL and AWS, and your assistance will play a vital role in helping me kickstart this project.\n\nThank you in advance for your support and guidance! \ud83d\ude4f\n\n*Note: This post is from a new intern who is eager to learn about ETL, AWS services, and ML model training. Constructive advice, insights, and best practices are most welcome.*", "author_fullname": "t2_8q14n8jy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up an ETL Pipeline with MySQL RDS, S3, Kafka, and SQS using AWS Services (Help Needed for ML Model Training)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141d21a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685968283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;As a new intern exploring the fascinating world of ETL (Extract, Transform, Load), I&amp;#39;m seeking guidance on setting up a robust ETL pipeline using Amazon Web Services (AWS) to facilitate ML model training. Specifically, I have a MySQL RDS database as the data source and intend to generate structured output on S3, which will be utilized for training OCR (Optical Character Recognition) and LLM (Language Model) models.&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to build an end-to-end pipeline that seamlessly extracts data from MySQL RDS, performs necessary transformations, and loads the transformed data into an S3 bucket. This structured data will then serve as the training dataset for ML models like OCR and LLM.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I&amp;#39;m considering incorporating Kafka or AWS SQS into the pipeline for efficient data processing and message queuing, ensuring the smooth flow of data throughout the system.&lt;/p&gt;\n\n&lt;p&gt;Given my limited experience in ETL, I&amp;#39;m particularly interested in leveraging the capabilities of AWS services to simplify the process. Services like AWS Glue and AWS Lambda have caught my attention, but I&amp;#39;m unsure about how to integrate them effectively into the pipeline.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a summary of what I aim to accomplish:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Data Source&lt;/strong&gt;: MySQL RDS - Extracting data from a MySQL RDS database.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Transformation&lt;/strong&gt;: Applying necessary transformations, cleansing, and enrichment to the data; would be made clear to me later once I finalize the architecture&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Structured Output&lt;/strong&gt;: Storing the transformed data in a structured format on an S3 bucket to serve as the training dataset for ML models (OCR, LLM)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If any experienced individuals have insights, tips, or step-by-step guidance on setting up this ETL pipeline using Amazon services such as AWS Glue, AWS Lambda, or any other relevant AWS services, I would greatly appreciate your valuable input!&lt;/p&gt;\n\n&lt;p&gt;Moreover, if you have specific advice or best practices for training ML models like OCR and LLM using the structured data in S3, I would be thrilled to hear about them.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m eager to delve into the world of ETL and AWS, and your assistance will play a vital role in helping me kickstart this project.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your support and guidance! \ud83d\ude4f&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Note: This post is from a new intern who is eager to learn about ETL, AWS services, and ML model training. Constructive advice, insights, and best practices are most welcome.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "141d21a", "is_robot_indexable": true, "report_reasons": null, "author": "SiddharthAnand_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141d21a/setting_up_an_etl_pipeline_with_mysql_rds_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141d21a/setting_up_an_etl_pipeline_with_mysql_rds_s3/", "subreddit_subscribers": 109026, "created_utc": 1685968283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been invited to do a technical assessment on hackajob for a data engineer role. I\u2019ve done one before and was wondering if anyone else had done these before. Do they change each time or are they the same?\n\nI recently did one handling an Pok\u00e9dex api. It\u2019d be great to know if others have had other experiences and what you needed to do?", "author_fullname": "t2_a1zpmnvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer hackajob test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141bww4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685965612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been invited to do a technical assessment on hackajob for a data engineer role. I\u2019ve done one before and was wondering if anyone else had done these before. Do they change each time or are they the same?&lt;/p&gt;\n\n&lt;p&gt;I recently did one handling an Pok\u00e9dex api. It\u2019d be great to know if others have had other experiences and what you needed to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "141bww4", "is_robot_indexable": true, "report_reasons": null, "author": "dmiller2104", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/141bww4/data_engineer_hackajob_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/141bww4/data_engineer_hackajob_test/", "subreddit_subscribers": 109026, "created_utc": 1685965612.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}