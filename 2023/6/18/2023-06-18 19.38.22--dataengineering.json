{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_n79165dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stack Overflow Will Charge AI Giants for Training Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ckwyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1687096020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "wired.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ckwyq", "is_robot_indexable": true, "report_reasons": null, "author": "wagfrydue", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ckwyq/stack_overflow_will_charge_ai_giants_for_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.wired.com/story/stack-overflow-will-charge-ai-giants-for-training-data/", "subreddit_subscribers": 111072, "created_utc": 1687096020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This post was mistakenly removed as it was thought to be a res ume review but actually it\u2019s a question of when is it considered reasonable to include a technology on your resume? \n\nBackground(last paragraph is main point):\n\nI\u2019ve been working on a data pipeline project for a little over 2 months now and I\u2019ve been learning and using tools like Spark, Nifi, and Airflow for it. \n\nI typically read up on the fundamentals of each too before figuring out how and why to use them in the project. Each tool plays a pretty major role in the project itself. Looking to include Kafka too but doing Kafka with python isn\u2019t as easy\n\nWhat I wonder is if once you\u2019ve gotten to this point, using the tool in your project, if you are okay to put said tool on your res ume, even if you aren\u2019t necessarily an expert, but rather you have experience using it in your own work. How do you typically get it on your res ume in a way that doesn\u2019t imply you\u2019re an expert?", "author_fullname": "t2_55fytx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When do you \u201cknow\u201d a technology enough to mention it when you apply to a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14c68nt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687047704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post was mistakenly removed as it was thought to be a res ume review but actually it\u2019s a question of when is it considered reasonable to include a technology on your resume? &lt;/p&gt;\n\n&lt;p&gt;Background(last paragraph is main point):&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working on a data pipeline project for a little over 2 months now and I\u2019ve been learning and using tools like Spark, Nifi, and Airflow for it. &lt;/p&gt;\n\n&lt;p&gt;I typically read up on the fundamentals of each too before figuring out how and why to use them in the project. Each tool plays a pretty major role in the project itself. Looking to include Kafka too but doing Kafka with python isn\u2019t as easy&lt;/p&gt;\n\n&lt;p&gt;What I wonder is if once you\u2019ve gotten to this point, using the tool in your project, if you are okay to put said tool on your res ume, even if you aren\u2019t necessarily an expert, but rather you have experience using it in your own work. How do you typically get it on your res ume in a way that doesn\u2019t imply you\u2019re an expert?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14c68nt", "is_robot_indexable": true, "report_reasons": null, "author": "ToothPickLegs", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14c68nt/when_do_you_know_a_technology_enough_to_mention/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14c68nt/when_do_you_know_a_technology_enough_to_mention/", "subreddit_subscribers": 111072, "created_utc": 1687047704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm currently working on developing a data quality strategy for my organization and would love to hear your opinions and insights on this topic.  \n\n\nWhat data quality strategies have you implemented in your organization?\n\nHow do you identify and handle data anomalies or discrepancies?\n\nHow do you involve stakeholders in data quality initiatives?\n\nHow do you measure and monitor data quality over time?\n\n Please share your experiences, challenges, and successes related to data quality.  \n\nTechstack , AWS , Glue , DBT.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's Your Data Quality Strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14cdr4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687072020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on developing a data quality strategy for my organization and would love to hear your opinions and insights on this topic.  &lt;/p&gt;\n\n&lt;p&gt;What data quality strategies have you implemented in your organization?&lt;/p&gt;\n\n&lt;p&gt;How do you identify and handle data anomalies or discrepancies?&lt;/p&gt;\n\n&lt;p&gt;How do you involve stakeholders in data quality initiatives?&lt;/p&gt;\n\n&lt;p&gt;How do you measure and monitor data quality over time?&lt;/p&gt;\n\n&lt;p&gt;Please share your experiences, challenges, and successes related to data quality.  &lt;/p&gt;\n\n&lt;p&gt;Techstack , AWS , Glue , DBT.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14cdr4i", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14cdr4i/whats_your_data_quality_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14cdr4i/whats_your_data_quality_strategy/", "subreddit_subscribers": 111072, "created_utc": 1687072020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to query a SQL db, perform some transformations and upload the resultant df to a another SQL db. \n\nThis task seems like a very basic/elementary DE task but I am struggling to find resources on how to go about it. \n\nMy main struggles are with aligning my schema with that of my SQL table\u2019s. Also, it seems my only way to upsert data is to do it record by record \u2014 is there not a more streamlined way to go about it?", "author_fullname": "t2_2l4y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas to SQL DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14c18dh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687034653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to query a SQL db, perform some transformations and upload the resultant df to a another SQL db. &lt;/p&gt;\n\n&lt;p&gt;This task seems like a very basic/elementary DE task but I am struggling to find resources on how to go about it. &lt;/p&gt;\n\n&lt;p&gt;My main struggles are with aligning my schema with that of my SQL table\u2019s. Also, it seems my only way to upsert data is to do it record by record \u2014 is there not a more streamlined way to go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14c18dh", "is_robot_indexable": true, "report_reasons": null, "author": "5678", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14c18dh/pandas_to_sql_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14c18dh/pandas_to_sql_db/", "subreddit_subscribers": 111072, "created_utc": 1687034653.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, guys, i apologize if this sounds silly.\n\nI've been working as a software engineer for one year now. Recently, my team was assigned the task of migrating a project that involves hundreds of big clients to a new platform we built.\n\nDuring the past month, I made contributions to the team by suggesting the use of Airflow to handle a large number of script files we had. I worked with SRE to set up the AWS infrastructure, wrote DAGs myself, and documented the process for the team and future teams who will inherit and maintain the project.\n\nMost of the tasks revolve around fetching and transforming data from various API calls, transforming the data, and storing the results in a cache for dynamic retrieval. Using pure python for data &lt;1mb.\n\nOnce the migration project is complete, our team will be disbanded, and we will be reassigned to different teams.\n\nI was recommended to join the data engineering team because of my use of Airflow, and I accepted the offer because it seems like a fun opportunity.\n\nHowever, I can't help but feel scared. The job entails building numerous pipelines using Snowflake and Spark, attending meetings to gather requirements etc. Lots of database stuff..\n\nI am not qualified for this.\n\nWhen I took a look at the team's repositories, I noticed there is a lot of complex SQL involved. Frankly, I struggle with writing anything beyond a basic SELECT statement, and I get nervous whenever I have to manually update something in a database.\n\nThe team has been treating me as their peer during the meetings, despite their 10+ years of experience and some holding a PhD.\n\nI am doing my best to learn as much until as i can until them, using the DE wiki. Unfortunately the workload is big and time is limited right now.\n\nI am expected to start working directly on live projects in a few months I'm quite worried about disappointing them as i do not have experience in this field.\n\nAny tips? This feels like a great opportunity for someone with no degree for my career and do not want to mess it up.\n\nThanks!", "author_fullname": "t2_k85y8a6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internal switch to DE.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14cjk1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687092423.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687092217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, guys, i apologize if this sounds silly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as a software engineer for one year now. Recently, my team was assigned the task of migrating a project that involves hundreds of big clients to a new platform we built.&lt;/p&gt;\n\n&lt;p&gt;During the past month, I made contributions to the team by suggesting the use of Airflow to handle a large number of script files we had. I worked with SRE to set up the AWS infrastructure, wrote DAGs myself, and documented the process for the team and future teams who will inherit and maintain the project.&lt;/p&gt;\n\n&lt;p&gt;Most of the tasks revolve around fetching and transforming data from various API calls, transforming the data, and storing the results in a cache for dynamic retrieval. Using pure python for data &amp;lt;1mb.&lt;/p&gt;\n\n&lt;p&gt;Once the migration project is complete, our team will be disbanded, and we will be reassigned to different teams.&lt;/p&gt;\n\n&lt;p&gt;I was recommended to join the data engineering team because of my use of Airflow, and I accepted the offer because it seems like a fun opportunity.&lt;/p&gt;\n\n&lt;p&gt;However, I can&amp;#39;t help but feel scared. The job entails building numerous pipelines using Snowflake and Spark, attending meetings to gather requirements etc. Lots of database stuff..&lt;/p&gt;\n\n&lt;p&gt;I am not qualified for this.&lt;/p&gt;\n\n&lt;p&gt;When I took a look at the team&amp;#39;s repositories, I noticed there is a lot of complex SQL involved. Frankly, I struggle with writing anything beyond a basic SELECT statement, and I get nervous whenever I have to manually update something in a database.&lt;/p&gt;\n\n&lt;p&gt;The team has been treating me as their peer during the meetings, despite their 10+ years of experience and some holding a PhD.&lt;/p&gt;\n\n&lt;p&gt;I am doing my best to learn as much until as i can until them, using the DE wiki. Unfortunately the workload is big and time is limited right now.&lt;/p&gt;\n\n&lt;p&gt;I am expected to start working directly on live projects in a few months I&amp;#39;m quite worried about disappointing them as i do not have experience in this field.&lt;/p&gt;\n\n&lt;p&gt;Any tips? This feels like a great opportunity for someone with no degree for my career and do not want to mess it up.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14cjk1i", "is_robot_indexable": true, "report_reasons": null, "author": "DeadInMyCar", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14cjk1i/internal_switch_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14cjk1i/internal_switch_to_de/", "subreddit_subscribers": 111072, "created_utc": 1687092217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**TL;DR an engineer on our team is proposing to move our EL infrastructure to MuleSoft, but it doesn\u2019t seem like the best approach from a DE perspective. Seems like writing pure Python would be preferred in our case.**\n\nTo make a long story short, our company got stuck with a contract for MuleSoft as part of our Salesforce implementation. Our warehouse will be feeding analytics and master data to Salesforce via reverse ETL.\n\nBecause of this, one of our engineers is pushing to build out all of our API endpoints as Mule app wrappers around our source/target APIs. He has discussed taking a microservices approach to the extract and load workloads of our ELT pipelines. For example, having a single application that handles the ingestion of any flat file into our warehouse.\n\nI am a bit apprehensive about this approach. MuleSoft seems great for IT systems integration and an approach geared more toward software development, but I feel like we are quickly going to be caught up in over-engineering for our pipelines. To be honest, they are not all that complex. Workloads are pretty small, and in terms of querying APIs, there really only seems to be a need for one pipeline per source as we just need to get the data into the warehouse for transform workloads.\n\nSome of the source APIs also seem to be purpose-built for record-to-record integration, as opposed to batch jobs suitable for ETL/ELT. There are other options I don\u2019t think the team is exploring because APIs are seen as preferential even when an ODBC driver might be more suitable for data engineering (as opposed to SWE).\n\nFurthermore, entirety of our data engineering team really only writes in Python, while MuleSoft really only has extensibility in Java. It\u2019s making me a bit apprehensive about our future and I talked to my manager about having a discussion with our VP about broader strategy around our infrastructure.\n\nI was hoping some fellow engineers here could lend some advice on general architectural setup in this scenario.", "author_fullname": "t2_ehi5h2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your data org handle API management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14c4z0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687044098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR an engineer on our team is proposing to move our EL infrastructure to MuleSoft, but it doesn\u2019t seem like the best approach from a DE perspective. Seems like writing pure Python would be preferred in our case.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;To make a long story short, our company got stuck with a contract for MuleSoft as part of our Salesforce implementation. Our warehouse will be feeding analytics and master data to Salesforce via reverse ETL.&lt;/p&gt;\n\n&lt;p&gt;Because of this, one of our engineers is pushing to build out all of our API endpoints as Mule app wrappers around our source/target APIs. He has discussed taking a microservices approach to the extract and load workloads of our ELT pipelines. For example, having a single application that handles the ingestion of any flat file into our warehouse.&lt;/p&gt;\n\n&lt;p&gt;I am a bit apprehensive about this approach. MuleSoft seems great for IT systems integration and an approach geared more toward software development, but I feel like we are quickly going to be caught up in over-engineering for our pipelines. To be honest, they are not all that complex. Workloads are pretty small, and in terms of querying APIs, there really only seems to be a need for one pipeline per source as we just need to get the data into the warehouse for transform workloads.&lt;/p&gt;\n\n&lt;p&gt;Some of the source APIs also seem to be purpose-built for record-to-record integration, as opposed to batch jobs suitable for ETL/ELT. There are other options I don\u2019t think the team is exploring because APIs are seen as preferential even when an ODBC driver might be more suitable for data engineering (as opposed to SWE).&lt;/p&gt;\n\n&lt;p&gt;Furthermore, entirety of our data engineering team really only writes in Python, while MuleSoft really only has extensibility in Java. It\u2019s making me a bit apprehensive about our future and I talked to my manager about having a discussion with our VP about broader strategy around our infrastructure.&lt;/p&gt;\n\n&lt;p&gt;I was hoping some fellow engineers here could lend some advice on general architectural setup in this scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data &amp; Analytics Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14c4z0s", "is_robot_indexable": true, "report_reasons": null, "author": "BlurryEcho", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14c4z0s/how_does_your_data_org_handle_api_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14c4z0s/how_does_your_data_org_handle_api_management/", "subreddit_subscribers": 111072, "created_utc": 1687044098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am used to seeing targets exceeded or met as a good thing. But what happens when exceeding target is a negative thing? Would you use a different term instead of target?\n\nFor some context, the data I'm dealing with is event types and target values are currently set at Prior Year count of events less X%.\n\nPrior year count less X% can be exceeded, but if it does it's not a good thing.", "author_fullname": "t2_sie27959", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What term to use instead of \"target\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14cbmb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687074870.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687064830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am used to seeing targets exceeded or met as a good thing. But what happens when exceeding target is a negative thing? Would you use a different term instead of target?&lt;/p&gt;\n\n&lt;p&gt;For some context, the data I&amp;#39;m dealing with is event types and target values are currently set at Prior Year count of events less X%.&lt;/p&gt;\n\n&lt;p&gt;Prior year count less X% can be exceeded, but if it does it&amp;#39;s not a good thing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14cbmb5", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Chapter959", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14cbmb5/what_term_to_use_instead_of_target/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14cbmb5/what_term_to_use_instead_of_target/", "subreddit_subscribers": 111072, "created_utc": 1687064830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why should you use external tables ? instead of Datawarehouse", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of External Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ckvut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687095934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why should you use external tables ? instead of Datawarehouse&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ckvut", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ckvut/benefits_of_external_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ckvut/benefits_of_external_tables/", "subreddit_subscribers": 111072, "created_utc": 1687095934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_n79165dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The State of Data Engineering 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_14ch7sl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LH5YJQKRpKS-jACYzeroLPz77UqjXCRAw6kijl83z_w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687084498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/the-state-of-data-engineering-2023/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3LxL4Ls4C_fSycZBEFjfiqbvqkspUuiUa_MBUuXM5jg.jpg?auto=webp&amp;v=enabled&amp;s=202c273d84870d3622f9c7a09efcd8cfc9de556e", "width": 525, "height": 450}, "resolutions": [{"url": "https://external-preview.redd.it/3LxL4Ls4C_fSycZBEFjfiqbvqkspUuiUa_MBUuXM5jg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc32e81c50b463082a20dafd9c29fe660248b71e", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/3LxL4Ls4C_fSycZBEFjfiqbvqkspUuiUa_MBUuXM5jg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4276d0af8312a85fc0f2af59faaef3c63019d5f8", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/3LxL4Ls4C_fSycZBEFjfiqbvqkspUuiUa_MBUuXM5jg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f5a86c2ef15c1b5371c45ba13378fee3c168fcb", "width": 320, "height": 274}], "variants": {}, "id": "xpTW-m5_MtaimMuBNvYrgMV4lZGUc19QGYCIc3hzvUw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ch7sl", "is_robot_indexable": true, "report_reasons": null, "author": "wagfrydue", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ch7sl/the_state_of_data_engineering_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/the-state-of-data-engineering-2023/", "subreddit_subscribers": 111072, "created_utc": 1687084498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking into reverse ETL to send data from Snowflake to a CRM\u2026 any recommendations?  Any bear traps I should avoid?", "author_fullname": "t2_5gzu4ur4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse ETL recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14c8m1k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687055016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking into reverse ETL to send data from Snowflake to a CRM\u2026 any recommendations?  Any bear traps I should avoid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14c8m1k", "is_robot_indexable": true, "report_reasons": null, "author": "bluezebra42", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14c8m1k/reverse_etl_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14c8m1k/reverse_etl_recommendations/", "subreddit_subscribers": 111072, "created_utc": 1687055016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a spark data frame that has some reconciliation data and this data frame only gets created if reconciliation fails. \n\nWhen this spark data frame does get created in data bricks, I need to send the data in it as logs to azure application insights from data bricks. \n\nWhat\u2019s confusing me is that there seems to be two libraries, \u201copen census\u201d and \u201copen telemetry\u201d, Open Telemetry is supposed to be the newest one but seems it\u2019s still on Beta? The Microsoft documentation isn\u2019t clear on that.\n\nSo my question is which library do i need to use? Also some python code examples of how to do this would be much appreciated.\n\nThank You.", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which library to use to write Data from a Spark Data Frame to Azure Application Insights from data bricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14c3tei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687041109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a spark data frame that has some reconciliation data and this data frame only gets created if reconciliation fails. &lt;/p&gt;\n\n&lt;p&gt;When this spark data frame does get created in data bricks, I need to send the data in it as logs to azure application insights from data bricks. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s confusing me is that there seems to be two libraries, \u201copen census\u201d and \u201copen telemetry\u201d, Open Telemetry is supposed to be the newest one but seems it\u2019s still on Beta? The Microsoft documentation isn\u2019t clear on that.&lt;/p&gt;\n\n&lt;p&gt;So my question is which library do i need to use? Also some python code examples of how to do this would be much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank You.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14c3tei", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14c3tei/which_library_to_use_to_write_data_from_a_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14c3tei/which_library_to_use_to_write_data_from_a_spark/", "subreddit_subscribers": 111072, "created_utc": 1687041109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I use Azure DataFactorys and Synapse Workspaces for data processing. \n\nWhat is the best way to set up jobs for this?\n\nThe triggers for the ADFs are not adequate as I have jobs that are allowed to run in parallel and others that are dependent on each other. \n\nRecently Apache Airflow can be used, but that is not a solution. \n\nI use currently the ProcFWK ([https://mrpaulandrew.github.io/procfwk/](https://mrpaulandrew.github.io/procfwk/)), but this is not a long-term solution for me. \n\nHow do you guys do something like this?  \n\n\nThanks in advance. ", "author_fullname": "t2_3x5koiy5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to orchestrate Azure ADFs and Synapse Pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14cd5rp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687070002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I use Azure DataFactorys and Synapse Workspaces for data processing. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to set up jobs for this?&lt;/p&gt;\n\n&lt;p&gt;The triggers for the ADFs are not adequate as I have jobs that are allowed to run in parallel and others that are dependent on each other. &lt;/p&gt;\n\n&lt;p&gt;Recently Apache Airflow can be used, but that is not a solution. &lt;/p&gt;\n\n&lt;p&gt;I use currently the ProcFWK (&lt;a href=\"https://mrpaulandrew.github.io/procfwk/\"&gt;https://mrpaulandrew.github.io/procfwk/&lt;/a&gt;), but this is not a long-term solution for me. &lt;/p&gt;\n\n&lt;p&gt;How do you guys do something like this?  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14cd5rp", "is_robot_indexable": true, "report_reasons": null, "author": "RedHatBerry", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14cd5rp/how_to_orchestrate_azure_adfs_and_synapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14cd5rp/how_to_orchestrate_azure_adfs_and_synapse/", "subreddit_subscribers": 111072, "created_utc": 1687070002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We recently spoke with a consultant to help us with data engineering work and we were quoted 200/hr. This is using mostly a Databricks/ADF stack. I\u2019m curious what the market rate would be for consulting help.", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market rate for consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14chc3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687084917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We recently spoke with a consultant to help us with data engineering work and we were quoted 200/hr. This is using mostly a Databricks/ADF stack. I\u2019m curious what the market rate would be for consulting help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14chc3i", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14chc3i/market_rate_for_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14chc3i/market_rate_for_consulting/", "subreddit_subscribers": 111072, "created_utc": 1687084917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently started my first job .\n\nFor now my role is to mapping company database from varies system which include excel , on prem sql server , own , design, , and maintained by different departments, some database not normalised/cleaned. \n\n\nTrying to have a physical ER diagram but stuck by  different structures (multi attribute structures vs flattened structure which i posted another post in r/SQL) \n\nSeeking for advices for the tools(what diagram/type of documentation/tools would be good for the job?)\n\nER models (lost of database information)?\nConceptual ERD?\nPhysical ERD?(cannot due with structure differences with not normalised database)", "author_fullname": "t2_1wtbi6tw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Look for advice ]for choice of tools/diagram for mapping database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14cf4tq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687076932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently started my first job .&lt;/p&gt;\n\n&lt;p&gt;For now my role is to mapping company database from varies system which include excel , on prem sql server , own , design, , and maintained by different departments, some database not normalised/cleaned. &lt;/p&gt;\n\n&lt;p&gt;Trying to have a physical ER diagram but stuck by  different structures (multi attribute structures vs flattened structure which i posted another post in &lt;a href=\"/r/SQL\"&gt;r/SQL&lt;/a&gt;) &lt;/p&gt;\n\n&lt;p&gt;Seeking for advices for the tools(what diagram/type of documentation/tools would be good for the job?)&lt;/p&gt;\n\n&lt;p&gt;ER models (lost of database information)?\nConceptual ERD?\nPhysical ERD?(cannot due with structure differences with not normalised database)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14cf4tq", "is_robot_indexable": true, "report_reasons": null, "author": "gffyhgffh45655", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14cf4tq/look_for_advice_for_choice_of_toolsdiagram_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14cf4tq/look_for_advice_for_choice_of_toolsdiagram_for/", "subreddit_subscribers": 111072, "created_utc": 1687076932.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}