{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. \n\nI want to ensure I have a long career.", "author_fullname": "t2_5bpuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some books that had an impact on your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5aks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685688434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. &lt;/p&gt;\n\n&lt;p&gt;I want to ensure I have a long career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13y5aks", "is_robot_indexable": true, "report_reasons": null, "author": "cheanerman", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "subreddit_subscribers": 108578, "created_utc": 1685688434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to build out a data model for a pet project that I want to be able to run on my laptop (8GB RAM). The data is shaped in such a way that I can have one 4-byte INT key link just about everything together that I need to. It's not necessarily a star schema, but for the purposes of the question you can think of it that way without much loss of generality. The central table is around \\~15M rows and the other tables are in that order of magnitude as well.\n\nI really like DuckDB and it was a logical choice for the project, but at the moment it doesn't have a good way of leveraging predictability when performing full-table joins (it also uses a lot of memory on joins when you're grabbing a wide set of columns from the tables, which is a problem for my case). Ideally I'd have something like Redshift's distkeys and sortkeys, where the data from the different tables would already be collocated by the join key. A standard PK/FK constraint would also work if declaring them actually sped up full-table joins.\n\nAny suggestions? Clickhouse seems like it might be a good fit, but I'm not sure how well it would handle the low-memory part specifically.", "author_fullname": "t2_3rnvqshi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good open-source analytics DB for fast, low-memory joins on predictable keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xxcmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685663922.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685663531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to build out a data model for a pet project that I want to be able to run on my laptop (8GB RAM). The data is shaped in such a way that I can have one 4-byte INT key link just about everything together that I need to. It&amp;#39;s not necessarily a star schema, but for the purposes of the question you can think of it that way without much loss of generality. The central table is around ~15M rows and the other tables are in that order of magnitude as well.&lt;/p&gt;\n\n&lt;p&gt;I really like DuckDB and it was a logical choice for the project, but at the moment it doesn&amp;#39;t have a good way of leveraging predictability when performing full-table joins (it also uses a lot of memory on joins when you&amp;#39;re grabbing a wide set of columns from the tables, which is a problem for my case). Ideally I&amp;#39;d have something like Redshift&amp;#39;s distkeys and sortkeys, where the data from the different tables would already be collocated by the join key. A standard PK/FK constraint would also work if declaring them actually sped up full-table joins.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? Clickhouse seems like it might be a good fit, but I&amp;#39;m not sure how well it would handle the low-memory part specifically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13xxcmq", "is_robot_indexable": true, "report_reasons": null, "author": "PaginatedSalmon", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xxcmq/good_opensource_analytics_db_for_fast_lowmemory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xxcmq/good_opensource_analytics_db_for_fast_lowmemory/", "subreddit_subscribers": 108578, "created_utc": 1685663531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data vault learning resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8vg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8vg5", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "subreddit_subscribers": 108578, "created_utc": 1685701550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! Just wanted to say I\u2019m not a coder nor programmer, recently started a sales role in a SasS company (Sales are the worst I know, oh well).\n\nWe have a lot of inbound leads, however, cold outreach is just about as it sounds - COLD. So I\u2019m really trying to understand if I\u2019m not finding the right audience, or if a data modeling tool (conceptual/physical/logical modeling) is useless to most of you?", "author_fullname": "t2_3rwynq3m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y0e1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685672094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! Just wanted to say I\u2019m not a coder nor programmer, recently started a sales role in a SasS company (Sales are the worst I know, oh well).&lt;/p&gt;\n\n&lt;p&gt;We have a lot of inbound leads, however, cold outreach is just about as it sounds - COLD. So I\u2019m really trying to understand if I\u2019m not finding the right audience, or if a data modeling tool (conceptual/physical/logical modeling) is useless to most of you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y0e1o", "is_robot_indexable": true, "report_reasons": null, "author": "S0urScream", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y0e1o/data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y0e1o/data_modeling_tool/", "subreddit_subscribers": 108578, "created_utc": 1685672094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have a system where a lot of data arrives in a pleasant, standard format (let's say there are \\~100 standard forms) but a lot of data arrives in Excel or text files with some descriptive header, many rows of CSV content, some more descriptive cruft, another set of CSV content, etc.\n\n\"Get the users to fix the data\" isn't a viable response given our pricing model.\n\nI'm starting to write some tools to allow users to provide processing instructions, such as \n\n* split an Excel doc into multiple sheets\n* split the file at some user provided content (e.g. \"Report #2 xyz\")\n* skip n header rows (easy) and n footer rows (less easy)\n* date format\n* the usual delimiter, character quoting stuff\n\nAll of this is achievable with some code, but this isn't a new or unique problem so there must be some options already available out there. Right?", "author_fullname": "t2_rmmatfaw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tooling for messy ingestions (e.g. excel, non-tabular text files, etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xzejs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685669224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a system where a lot of data arrives in a pleasant, standard format (let&amp;#39;s say there are ~100 standard forms) but a lot of data arrives in Excel or text files with some descriptive header, many rows of CSV content, some more descriptive cruft, another set of CSV content, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Get the users to fix the data&amp;quot; isn&amp;#39;t a viable response given our pricing model.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m starting to write some tools to allow users to provide processing instructions, such as &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;split an Excel doc into multiple sheets&lt;/li&gt;\n&lt;li&gt;split the file at some user provided content (e.g. &amp;quot;Report #2 xyz&amp;quot;)&lt;/li&gt;\n&lt;li&gt;skip n header rows (easy) and n footer rows (less easy)&lt;/li&gt;\n&lt;li&gt;date format&lt;/li&gt;\n&lt;li&gt;the usual delimiter, character quoting stuff&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All of this is achievable with some code, but this isn&amp;#39;t a new or unique problem so there must be some options already available out there. Right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13xzejs", "is_robot_indexable": true, "report_reasons": null, "author": "realitydevice", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xzejs/tooling_for_messy_ingestions_eg_excel_nontabular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xzejs/tooling_for_messy_ingestions_eg_excel_nontabular/", "subreddit_subscribers": 108578, "created_utc": 1685669224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have always been intrigued and slowly been falling inlove with the extensive capabilities of what Data Engineers can do in the industry. \n\nMy portfolio, I have been working as DMA in the Data Governance for 9 years. My job mainly consist of implementing data cleaning cycle to my company,  Generating metrics on my team\u2019s output monthly to check work efficiency. Not even sure if considered a technical skill but I\u2019m using powershell and automating tools to do the dirty work in migrating bulk data (terabytes). Not so fun at all.\n\nI have 0 interest in coding but since I\u2019ve been really into Data Engineering. Recently I\u2019ve been self studying, buying udemy bootcamps courses for Python and SQL. Also I\u2019ve been using our friendly neighborhood Youtube and Google as additional resources.\n\nKnowing how crucial and important data is in the industry. I\u2019m really considering in transitioning to this role due to its high demand,  high value and the skillset to acquire in this role is no joke. I can see that it takes continous dedication to upskill and pure love for data to be considered a good DE.\nOf course would also have to consider the bigger pay for this role as well.\n\nWill this be worth the jump?\n\nAny tips or advise would be highly appreciated!\n\n\n\nTLDR: I\u2019m emotionally fatigued with my current role, how can I find hope in transitioning to Data Engineer?", "author_fullname": "t2_p2kttfgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Shift from Data Management Analyst to Data Engineer a good idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xqwrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685647837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have always been intrigued and slowly been falling inlove with the extensive capabilities of what Data Engineers can do in the industry. &lt;/p&gt;\n\n&lt;p&gt;My portfolio, I have been working as DMA in the Data Governance for 9 years. My job mainly consist of implementing data cleaning cycle to my company,  Generating metrics on my team\u2019s output monthly to check work efficiency. Not even sure if considered a technical skill but I\u2019m using powershell and automating tools to do the dirty work in migrating bulk data (terabytes). Not so fun at all.&lt;/p&gt;\n\n&lt;p&gt;I have 0 interest in coding but since I\u2019ve been really into Data Engineering. Recently I\u2019ve been self studying, buying udemy bootcamps courses for Python and SQL. Also I\u2019ve been using our friendly neighborhood Youtube and Google as additional resources.&lt;/p&gt;\n\n&lt;p&gt;Knowing how crucial and important data is in the industry. I\u2019m really considering in transitioning to this role due to its high demand,  high value and the skillset to acquire in this role is no joke. I can see that it takes continous dedication to upskill and pure love for data to be considered a good DE.\nOf course would also have to consider the bigger pay for this role as well.&lt;/p&gt;\n\n&lt;p&gt;Will this be worth the jump?&lt;/p&gt;\n\n&lt;p&gt;Any tips or advise would be highly appreciated!&lt;/p&gt;\n\n&lt;p&gt;TLDR: I\u2019m emotionally fatigued with my current role, how can I find hope in transitioning to Data Engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13xqwrx", "is_robot_indexable": true, "report_reasons": null, "author": "SheeshKebabPls", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xqwrx/career_shift_from_data_management_analyst_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xqwrx/career_shift_from_data_management_analyst_to_data/", "subreddit_subscribers": 108578, "created_utc": 1685647837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to update records on Delta live tables with the incoming stream? \n\nBusiness case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. \n\nI have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.", "author_fullname": "t2_feq227wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Upsert on Delta Live Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5nvm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685689773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to update records on Delta live tables with the incoming stream? &lt;/p&gt;\n\n&lt;p&gt;Business case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. &lt;/p&gt;\n\n&lt;p&gt;I have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y5nvm", "is_robot_indexable": true, "report_reasons": null, "author": "qki_machine", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "subreddit_subscribers": 108578, "created_utc": 1685689773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Redditors!\n\nI thought this community might find it very useful that Databricks has partnered with [Cleanlab](https://cleanlab.ai/) to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.\n\nA big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.\n\nTo highlight what's possible with this new integration, their recent [blog](https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio) shows how LLMs (Large Language Models) trained on Databricks data can be **boosted in test accuracy (by over 30%) using Cleanlab Studio** to train ML models on an improved text dataset. \n\nYou only need a couple of lines of code too:\n\n    cleanlab_studio.upload_dataset(dataset)\n    dataset_fixed = cleanlab_studio.apply_corrections(id, dataset)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks users can now automatically correct data and improve ML models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yhf6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685723424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors!&lt;/p&gt;\n\n&lt;p&gt;I thought this community might find it very useful that Databricks has partnered with &lt;a href=\"https://cleanlab.ai/\"&gt;Cleanlab&lt;/a&gt; to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.&lt;/p&gt;\n\n&lt;p&gt;A big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.&lt;/p&gt;\n\n&lt;p&gt;To highlight what&amp;#39;s possible with this new integration, their recent &lt;a href=\"https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio\"&gt;blog&lt;/a&gt; shows how LLMs (Large Language Models) trained on Databricks data can be &lt;strong&gt;boosted in test accuracy (by over 30%) using Cleanlab Studio&lt;/strong&gt; to train ML models on an improved text dataset. &lt;/p&gt;\n\n&lt;p&gt;You only need a couple of lines of code too:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;cleanlab_studio.upload_dataset(dataset)\ndataset_fixed = cleanlab_studio.apply_corrections(id, dataset)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?auto=webp&amp;v=enabled&amp;s=4fa344feec1203c5a3c8037ff4dc262b8199993c", "width": 1272, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=497bb037271a9f730fba0c9762fccfd03bc83854", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e9a92773876a44dff24033bb28bfcac23cc6be9", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d8289065076165108742e1f06e1eba13b2ba27e", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=860eca71c83a330feea1f4e293c3767498138aec", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29a33bb3ca9ee068da332d2221827e16765a2a4a", "width": 960, "height": 517}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bd1c44daed0be645a75f28344e835d728418327", "width": 1080, "height": 582}], "variants": {}, "id": "ZToDd-YI1Es8iCGrsYQ-wSRxT7XW4KUdV7ki6pqFGdE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13yhf6e", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "subreddit_subscribers": 108578, "created_utc": 1685723424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What work did you do as interns/junior-level DEs and how did it change as you progressed?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question for all data engineers:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yelms", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685716828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What work did you do as interns/junior-level DEs and how did it change as you progressed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13yelms", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "subreddit_subscribers": 108578, "created_utc": 1685716828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm struggling to find a service that at least gives me more that 80 cities in the UK. \n\nWhat I'm looking for is this type of data:\n\n&amp;#x200B;\n\n|country|region|district/city|longitude|latitude|\n|:-|:-|:-|:-|:-|\n|England|North West|Liverpool|\\-29.09|34.00|\n\nLong and Lat are wrong, just place holder data.   \n\n\nSeems a lot of places I've been looking only have like 300 locations or even 80.   \n\n\nAnyone found a good free API for this at all?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone got any information on how to retrieve all longitude and latitude data for each city in the UK (including Scotland, Wales, Northern Ireland)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8g9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685700107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to find a service that at least gives me more that 80 cities in the UK. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is this type of data:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;country&lt;/th&gt;\n&lt;th align=\"left\"&gt;region&lt;/th&gt;\n&lt;th align=\"left\"&gt;district/city&lt;/th&gt;\n&lt;th align=\"left\"&gt;longitude&lt;/th&gt;\n&lt;th align=\"left\"&gt;latitude&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;England&lt;/td&gt;\n&lt;td align=\"left\"&gt;North West&lt;/td&gt;\n&lt;td align=\"left\"&gt;Liverpool&lt;/td&gt;\n&lt;td align=\"left\"&gt;-29.09&lt;/td&gt;\n&lt;td align=\"left\"&gt;34.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Long and Lat are wrong, just place holder data.   &lt;/p&gt;\n\n&lt;p&gt;Seems a lot of places I&amp;#39;ve been looking only have like 300 locations or even 80.   &lt;/p&gt;\n\n&lt;p&gt;Anyone found a good free API for this at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8g9g", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "subreddit_subscribers": 108578, "created_utc": 1685700107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, DE here with around 1 YoE. Been chilling on my current job rn and I've been looking to upskill/learn in the meantime. Current exp is with GCP (BigQuery), Airflow, Python, Docker, and some fullstack (Vue/Flask).\n\nI'm from a non-CS degree so I've been thinking of either learning more CS fundamentals or just focusing on DE tools in general. Problem is that I am also a bit overwhelmed at the choices and tools/languages I can learn (Somewhat inspired by [this post](https://www.reddit.com/r/dataengineering/comments/12x895j/getting_overwhelmed_by_wide_and_everchanging_tech/)). Would appreciate any insight on the different options i'm looking into, thanks!  \n\n\n1. Implement DE projects/Learn new tools to further build github portfolio  \n\\- Trying DE Zoomcamp  \n\\- Read documentation on new tools (Scala/Prefect/MS Azure/Kafka/K8s/MLFlow) and work on implementing a project covering some of the tools.  \n\\- Contribute to open source projects/tools\n2. Strengthen CS fundamentals  \n\\- Watch lectures ([CMU lectures](https://www.youtube.com/watch?v=LWS8LEQAUVc&amp;list=PLSE8ODhjZXjYzlLMbX3cR0sxWnRM7CLFn) seem like an interesting start)  \n\\- Leetcode  \n\\- Advent of Code  \n\\- Read books (DDIA, DE fundamentals, Data Quality fundamentals, etc.)", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsure which way to move forward", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y3l4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685682323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, DE here with around 1 YoE. Been chilling on my current job rn and I&amp;#39;ve been looking to upskill/learn in the meantime. Current exp is with GCP (BigQuery), Airflow, Python, Docker, and some fullstack (Vue/Flask).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a non-CS degree so I&amp;#39;ve been thinking of either learning more CS fundamentals or just focusing on DE tools in general. Problem is that I am also a bit overwhelmed at the choices and tools/languages I can learn (Somewhat inspired by &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12x895j/getting_overwhelmed_by_wide_and_everchanging_tech/\"&gt;this post&lt;/a&gt;). Would appreciate any insight on the different options i&amp;#39;m looking into, thanks!  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Implement DE projects/Learn new tools to further build github portfolio&lt;br/&gt;\n- Trying DE Zoomcamp&lt;br/&gt;\n- Read documentation on new tools (Scala/Prefect/MS Azure/Kafka/K8s/MLFlow) and work on implementing a project covering some of the tools.&lt;br/&gt;\n- Contribute to open source projects/tools&lt;/li&gt;\n&lt;li&gt;Strengthen CS fundamentals&lt;br/&gt;\n- Watch lectures (&lt;a href=\"https://www.youtube.com/watch?v=LWS8LEQAUVc&amp;amp;list=PLSE8ODhjZXjYzlLMbX3cR0sxWnRM7CLFn\"&gt;CMU lectures&lt;/a&gt; seem like an interesting start)&lt;br/&gt;\n- Leetcode&lt;br/&gt;\n- Advent of Code&lt;br/&gt;\n- Read books (DDIA, DE fundamentals, Data Quality fundamentals, etc.)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?auto=webp&amp;v=enabled&amp;s=8d8b8c47fd8dfcdb4e02dacb36d29a388df017fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e9d66b26f4882c4244a7f41710779a43b6cb525", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38a8bcd47e423b5db9f81a5814edacf641e49ce5", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efbefd9ab914cbb0cf7af94095436120ca48cd51", "width": 320, "height": 240}], "variants": {}, "id": "VAulGrQIgrZNrLvYNArFduNfHDflJBIDC4XEkzG8oCE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13y3l4q", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y3l4q/unsure_which_way_to_move_forward/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y3l4q/unsure_which_way_to_move_forward/", "subreddit_subscribers": 108578, "created_utc": 1685682323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding Pipelines For Generative AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13xzpt2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/H7VGUc9R5gFecU5Ez20Voch7M-JUlDQ0FW_iAoTLGzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685670118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytewax.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bytewax.io/blog/embedding-pipelines-for-generative-ai", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?auto=webp&amp;v=enabled&amp;s=508e36832dcdeb2bc9f42531a3224e7c5f9e6cfc", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2221d29d33827fb9c45a1bd9a811e44475b47a7", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=442f4ea278032bdda0e13616933e73c99662a6fd", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa994bb2165b79bc75a9a548cd1f0d1425ee6e87", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c21bb53529abd65816f0b2935254605f4fa330e2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d47c4f7c1122199e5f3b9214633846d5d289578b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2ed7d5bf7eba7af3c8eb8ac8fa0c65c8d7be082", "width": 1080, "height": 607}], "variants": {}, "id": "aZU66TyrS3pTtx2nstLcKFQ6BhqRUJp3xVigMlCxRJg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13xzpt2", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xzpt2/embedding_pipelines_for_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bytewax.io/blog/embedding-pipelines-for-generative-ai", "subreddit_subscribers": 108578, "created_utc": 1685670118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, thanks for passing by.  \nI'm working on a project where we need (among other things) to geographically enrich ingested data in NRT.  \nThe currently implemented architecture is simply as follows:  \nEvents -&gt; kafka -&gt; spark streaming -&gt; kafka  \n\nThe spark job is is concerned with:  \n1. Reading decoding avro data packets from a kafka topic\n2. joining packets with customer data read from Hbase  \n3. calling a reverse geocoding service (written by some folks here) for geographical enrichment for each packet. \n4. Writing data back to another kafka topic  \n\nAs of now, the reverse geocoder is a single instance REST service which loads the whole 80+ gb OSM map in memory, and i really have the feeling this is by no means the correct way to implement it (although i do not have experience with geographical data) and I'm therefore looking to find a better, more robust way to accomplish this requirement.  \n\nIs there a commonly agreed upon way to do this? The map data is obviously static, so the solution needs to be optimized for fast data retrieval (key-based). I'd like to get rid of the rest service altogether and to store this map (which will soon include other countries hence will be bigger than 80gb) in some data store.  \n\nThe first solution that i came up with was to store the map in Hbase, since it's what we already use for customer data and also because it would unify our data enrichment process, but somehow CA colleagues say that \"it would overload Hbase and negatively impact performance\". Are they just being lazy or mine is actually a bad idea? (I feel like enhancement proposals are not very welcome here, but yet i try). \nIs there any other technology that would be fit for the task? Postgres, Elasticsearch? Alternatively, is keeping these big ass maps in memory a good idea? \n\nJust for info, we are talking about 1000 to 2000 msg/s and no, we cannot use external geocoding services. Also manually implementing sharding, load balancing, replication and automatic fallbacks is a lot of unnecessary work to me.\n\nThanks a lot for taking the time to read this.  \n\nEdit: i'd add that while the msg rate is around 1000-2000 /s we process them in micro-batches every 30 seconds.", "author_fullname": "t2_3xvidrz9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing a Reverse Geocoding service for data enrichment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xsrft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685652572.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685652159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, thanks for passing by.&lt;br/&gt;\nI&amp;#39;m working on a project where we need (among other things) to geographically enrich ingested data in NRT.&lt;br/&gt;\nThe currently implemented architecture is simply as follows:&lt;br/&gt;\nEvents -&amp;gt; kafka -&amp;gt; spark streaming -&amp;gt; kafka  &lt;/p&gt;\n\n&lt;p&gt;The spark job is is concerned with:&lt;br/&gt;\n1. Reading decoding avro data packets from a kafka topic\n2. joining packets with customer data read from Hbase&lt;br/&gt;\n3. calling a reverse geocoding service (written by some folks here) for geographical enrichment for each packet. \n4. Writing data back to another kafka topic  &lt;/p&gt;\n\n&lt;p&gt;As of now, the reverse geocoder is a single instance REST service which loads the whole 80+ gb OSM map in memory, and i really have the feeling this is by no means the correct way to implement it (although i do not have experience with geographical data) and I&amp;#39;m therefore looking to find a better, more robust way to accomplish this requirement.  &lt;/p&gt;\n\n&lt;p&gt;Is there a commonly agreed upon way to do this? The map data is obviously static, so the solution needs to be optimized for fast data retrieval (key-based). I&amp;#39;d like to get rid of the rest service altogether and to store this map (which will soon include other countries hence will be bigger than 80gb) in some data store.  &lt;/p&gt;\n\n&lt;p&gt;The first solution that i came up with was to store the map in Hbase, since it&amp;#39;s what we already use for customer data and also because it would unify our data enrichment process, but somehow CA colleagues say that &amp;quot;it would overload Hbase and negatively impact performance&amp;quot;. Are they just being lazy or mine is actually a bad idea? (I feel like enhancement proposals are not very welcome here, but yet i try). \nIs there any other technology that would be fit for the task? Postgres, Elasticsearch? Alternatively, is keeping these big ass maps in memory a good idea? &lt;/p&gt;\n\n&lt;p&gt;Just for info, we are talking about 1000 to 2000 msg/s and no, we cannot use external geocoding services. Also manually implementing sharding, load balancing, replication and automatic fallbacks is a lot of unnecessary work to me.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for taking the time to read this.  &lt;/p&gt;\n\n&lt;p&gt;Edit: i&amp;#39;d add that while the msg rate is around 1000-2000 /s we process them in micro-batches every 30 seconds.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13xsrft", "is_robot_indexable": true, "report_reasons": null, "author": "RAT-000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xsrft/implementing_a_reverse_geocoding_service_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xsrft/implementing_a_reverse_geocoding_service_for_data/", "subreddit_subscribers": 108578, "created_utc": 1685652159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am looking for a sample database with interesting business data to analyze.\n\nIt shouldn't be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).\n\nIt can be a sample of accounting entries, or an insurance company database, any industry, actually.\n\nI will use this DB for demo dashboards and teaching analytics and data engineering.  \nThanks", "author_fullname": "t2_924si4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sample dataset/database with business data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y93cq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685702285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a sample database with interesting business data to analyze.&lt;/p&gt;\n\n&lt;p&gt;It shouldn&amp;#39;t be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).&lt;/p&gt;\n\n&lt;p&gt;It can be a sample of accounting entries, or an insurance company database, any industry, actually.&lt;/p&gt;\n\n&lt;p&gt;I will use this DB for demo dashboards and teaching analytics and data engineering.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y93cq", "is_robot_indexable": true, "report_reasons": null, "author": "mshparber", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "subreddit_subscribers": 108578, "created_utc": 1685702285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:\n\n- modularity\n- Logging/Error Handling\n- Tests/Data Validation Tests\n- Few dependencies in addition to pandas/polars\n- no prefect/airflow/dagster\n- bonus is simplistic data flow tracking\n\nExemplary use case: e.g. simple etl pipeline running on databricks\n\nInterested in seeing various approaches to the most basic form of etl pipeline in python.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimal Python ETL-pipeline-template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8pu2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;modularity&lt;/li&gt;\n&lt;li&gt;Logging/Error Handling&lt;/li&gt;\n&lt;li&gt;Tests/Data Validation Tests&lt;/li&gt;\n&lt;li&gt;Few dependencies in addition to pandas/polars&lt;/li&gt;\n&lt;li&gt;no prefect/airflow/dagster&lt;/li&gt;\n&lt;li&gt;bonus is simplistic data flow tracking&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Exemplary use case: e.g. simple etl pipeline running on databricks&lt;/p&gt;\n\n&lt;p&gt;Interested in seeing various approaches to the most basic form of etl pipeline in python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8pu2", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "subreddit_subscribers": 108578, "created_utc": 1685701014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Alright so let me give a bit of a background:\n\nI\u2019ve been working as a software consultant for 1.5yr which means 50% of my job is working directly with our clients, understanding their business needs and figuring out the technical requirements. \n\nThe other 50% goes like this:\n\n-\tWriting large SQL queries for ad hoc reports used in business analytics/intelligence\n-\tWriting backend code in C# and VB.Net (legacy codebase) for ETL operations (typically used for populating our data warehouse), for batch updates of databases (we receive bulk data from various government agencies), creating streams to automate various file jobs, as well as application side data\n-\tOptimizing SQL queries (some queries involve joining several tables with hundreds of millions of rows each), indexing tables, creating new tables, etc\n\nTypical tools I use are SSMS and Visual Studio. Nothing fancy. \n\nI\u2019m also doing a masters in computer and information technology at University of Pennsylvania. I\u2019ve taken data structures, algorithms, machine learning courses and currently studying big data analytics. So I\u2019m proficient with Java and Python (as well as data science tools like pandas, scikitlearn) and currently learning Spark and Hadoop in the big data course. \n\nUPenn also partnered with AWS and offered us a project opportunity to set up EC2, S3, RDS. I just received my cloud practitioner certificate. \n\nWhat are my chances that I break in to the data engineering field given I don\u2019t use any popular cloud or recent data engineering technology? All job listings I\u2019ve looked at requires 3+ years of Azure, GCP, AWS, Databricks, Snowflake etc. \n\nI\u2019m open to learning these technologies on my own but due to my companies old tech stack I wouldn\u2019t be professionally using them. At best at a personal portfolio/project level.", "author_fullname": "t2_a0n6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How likely that I can transition from software consultancy to data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xoqv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685644629.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685642773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright so let me give a bit of a background:&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working as a software consultant for 1.5yr which means 50% of my job is working directly with our clients, understanding their business needs and figuring out the technical requirements. &lt;/p&gt;\n\n&lt;p&gt;The other 50% goes like this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;  Writing large SQL queries for ad hoc reports used in business analytics/intelligence&lt;/li&gt;\n&lt;li&gt;  Writing backend code in C# and VB.Net (legacy codebase) for ETL operations (typically used for populating our data warehouse), for batch updates of databases (we receive bulk data from various government agencies), creating streams to automate various file jobs, as well as application side data&lt;/li&gt;\n&lt;li&gt;  Optimizing SQL queries (some queries involve joining several tables with hundreds of millions of rows each), indexing tables, creating new tables, etc&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Typical tools I use are SSMS and Visual Studio. Nothing fancy. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m also doing a masters in computer and information technology at University of Pennsylvania. I\u2019ve taken data structures, algorithms, machine learning courses and currently studying big data analytics. So I\u2019m proficient with Java and Python (as well as data science tools like pandas, scikitlearn) and currently learning Spark and Hadoop in the big data course. &lt;/p&gt;\n\n&lt;p&gt;UPenn also partnered with AWS and offered us a project opportunity to set up EC2, S3, RDS. I just received my cloud practitioner certificate. &lt;/p&gt;\n\n&lt;p&gt;What are my chances that I break in to the data engineering field given I don\u2019t use any popular cloud or recent data engineering technology? All job listings I\u2019ve looked at requires 3+ years of Azure, GCP, AWS, Databricks, Snowflake etc. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m open to learning these technologies on my own but due to my companies old tech stack I wouldn\u2019t be professionally using them. At best at a personal portfolio/project level.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13xoqv2", "is_robot_indexable": true, "report_reasons": null, "author": "Soknardalr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xoqv2/how_likely_that_i_can_transition_from_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xoqv2/how_likely_that_i_can_transition_from_software/", "subreddit_subscribers": 108578, "created_utc": 1685642773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance", "author_fullname": "t2_7r5xenrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering conference in Canada (anywhere)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygpe4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685721746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ygpe4", "is_robot_indexable": true, "report_reasons": null, "author": "Heavy_End_2971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "subreddit_subscribers": 108578, "created_utc": 1685721746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of NoSQL Databases: Deep Dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygmj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tbjolvjcd4pFGYwrUy21pTO8xhj6HfhJnXoILsY07vY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685721582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?auto=webp&amp;v=enabled&amp;s=30a10ec625bb545da69ce94ff3eaecf423192ffb", "width": 2400, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cb781c8024b80019cbb4d8671b9ac82ce55239a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3019c8983a64031de7cc3d528cc1a4082b979ce3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c14465cc9cf34e73a9dfcd9cee8f25a2024ac4f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=855bc3dfe0b174024f1952f236e466bf3704d9aa", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e348a1a0827d26c78592ce17c4f91f62d1984ae2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21faf68b901e2ba8bc3816beedccedea6c06e79f", "width": 1080, "height": 540}], "variants": {}, "id": "M2IsBpOmOWUv3ZenklBzRFx5hxz60Ew2I2gjTGE5GCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13ygmj4", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygmj4/types_of_nosql_databases_deep_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "subreddit_subscribers": 108578, "created_utc": 1685721582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the \"frameworkisation\" of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.\n\nWhat would have been your primary choice of framework for this kind of project in Python?", "author_fullname": "t2_flv2knd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream processing framework for a new project in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yftqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685719716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the &amp;quot;frameworkisation&amp;quot; of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.&lt;/p&gt;\n\n&lt;p&gt;What would have been your primary choice of framework for this kind of project in Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yftqn", "is_robot_indexable": true, "report_reasons": null, "author": "Hashrann", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "subreddit_subscribers": 108578, "created_utc": 1685719716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.\n\nAs they're migrating to the cloud I'm wondering how to best represent those one to many relationships in OBT ?\nObviously I'm thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?", "author_fullname": "t2_4v8mesko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you create one to many relationships in OBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yc68h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685710964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.&lt;/p&gt;\n\n&lt;p&gt;As they&amp;#39;re migrating to the cloud I&amp;#39;m wondering how to best represent those one to many relationships in OBT ?\nObviously I&amp;#39;m thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yc68h", "is_robot_indexable": true, "report_reasons": null, "author": "_thetrue_SpaceTofu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "subreddit_subscribers": 108578, "created_utc": 1685710964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,   \n\n\nI know that Fivetran has functionality that enables the creation of Custom Connectors e.g. instructions here: [https://www.biztory.com/blog/building-your-own-custom-connector-for-fivetran-part-ii](https://www.biztory.com/blog/building-your-own-custom-connector-for-fivetran-part-ii)  \n\n\nBut does anybody know what their protocol is for the creation of Native connectors? For example if a native connector doesn't exist for your data source - can you request for one to be built and what is the likelihood of that happening?   \n\n\nThanks", "author_fullname": "t2_gmutm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creation of native connectors with FiveTran", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xw7re", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685660529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,   &lt;/p&gt;\n\n&lt;p&gt;I know that Fivetran has functionality that enables the creation of Custom Connectors e.g. instructions here: &lt;a href=\"https://www.biztory.com/blog/building-your-own-custom-connector-for-fivetran-part-ii\"&gt;https://www.biztory.com/blog/building-your-own-custom-connector-for-fivetran-part-ii&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;But does anybody know what their protocol is for the creation of Native connectors? For example if a native connector doesn&amp;#39;t exist for your data source - can you request for one to be built and what is the likelihood of that happening?   &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13xw7re", "is_robot_indexable": true, "report_reasons": null, "author": "CyberVoyeur", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xw7re/creation_of_native_connectors_with_fivetran/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xw7re/creation_of_native_connectors_with_fivetran/", "subreddit_subscribers": 108578, "created_utc": 1685660529.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}