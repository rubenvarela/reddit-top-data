{"kind": "Listing", "data": {"after": "t3_13y2bgq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand that the market condition is awful but 500+ rejects is crazy. I'd appreciate if someone could provide insights on what I'm doing wrong.\n\nEdit: Im applying for Internships / Co-ops at the moment.\n\nhttps://preview.redd.it/jna118vbah3b1.png?width=1698&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73697849b3b222c34e5430074c0938cca282cbaa", "author_fullname": "t2_129bsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What am I doing wrong? No interviews after 6 months of applying and 500+ applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jna118vbah3b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/jna118vbah3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d478be48aea5d6519d8205569ec1967789f543a"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/jna118vbah3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6835448a09c98168001648f8d64961bcb49ab592"}, {"y": 413, "x": 320, "u": "https://preview.redd.it/jna118vbah3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6790e14d5576c472bb2a4f823f5bcef8bb855a06"}, {"y": 827, "x": 640, "u": "https://preview.redd.it/jna118vbah3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46136d792892f1ccf3e508d5f11bd06dbb2ef104"}, {"y": 1241, "x": 960, "u": "https://preview.redd.it/jna118vbah3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6579149849b2a621a441451ff217b029353df3fa"}, {"y": 1396, "x": 1080, "u": "https://preview.redd.it/jna118vbah3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=752473126a6c88db93684de295024b4d14a6878c"}], "s": {"y": 2196, "x": 1698, "u": "https://preview.redd.it/jna118vbah3b1.png?width=1698&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73697849b3b222c34e5430074c0938cca282cbaa"}, "id": "jna118vbah3b1"}}, "name": "t3_13xuleb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 140, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 140, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TrNwdUGzpOvl8HBPCEibLBxsgKopt5rRN7ZGUPKIY1c.jpg", "edited": 1685659265.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685656557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that the market condition is awful but 500+ rejects is crazy. I&amp;#39;d appreciate if someone could provide insights on what I&amp;#39;m doing wrong.&lt;/p&gt;\n\n&lt;p&gt;Edit: Im applying for Internships / Co-ops at the moment.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jna118vbah3b1.png?width=1698&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=73697849b3b222c34e5430074c0938cca282cbaa\"&gt;https://preview.redd.it/jna118vbah3b1.png?width=1698&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=73697849b3b222c34e5430074c0938cca282cbaa&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xuleb", "is_robot_indexable": true, "report_reasons": null, "author": "Tam27_", "discussion_type": null, "num_comments": 87, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xuleb/what_am_i_doing_wrong_no_interviews_after_6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xuleb/what_am_i_doing_wrong_no_interviews_after_6/", "subreddit_subscribers": 915713, "created_utc": 1685656557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lrllrd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What python library you are using for interactive visualisation?(other than plotly)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y0wwg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685673636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y0wwg", "is_robot_indexable": true, "report_reasons": null, "author": "vishal-vora", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y0wwg/what_python_library_you_are_using_for_interactive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y0wwg/what_python_library_you_are_using_for_interactive/", "subreddit_subscribers": 915713, "created_utc": 1685673636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Elements of statistical learning? Rethinking? What do we have that's as ubiquitous as those few, and all the others? What are the must read books in our field?", "author_fullname": "t2_15v03egd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Engineers have \"Designing Data Intensive Applications\" and \"Clean Code\" and \"The Pragmatic Programmer\". What do we have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xyx0g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685668258.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685667810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Elements of statistical learning? Rethinking? What do we have that&amp;#39;s as ubiquitous as those few, and all the others? What are the must read books in our field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xyx0g", "is_robot_indexable": true, "report_reasons": null, "author": "eipi-10", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xyx0g/engineers_have_designing_data_intensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xyx0g/engineers_have_designing_data_intensive/", "subreddit_subscribers": 915713, "created_utc": 1685667810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have set a goal to create a complete project portfolio by the end of the year.\n\nDo you think this is important to get a machine learning / data science job?", "author_fullname": "t2_w7ap5hsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do recruiters really care about portfolio projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xusrz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685657041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have set a goal to create a complete project portfolio by the end of the year.&lt;/p&gt;\n\n&lt;p&gt;Do you think this is important to get a machine learning / data science job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xusrz", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Standard175", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xusrz/do_recruiters_really_care_about_portfolio_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xusrz/do_recruiters_really_care_about_portfolio_projects/", "subreddit_subscribers": 915713, "created_utc": 1685657041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sometimes when exploring what feature impact a target variable, I\u2019ve found it helpful to train a model (random Forrest for example) then look at feature importance and or Shapley values. Is this bad practice?", "author_fullname": "t2_bcbozi6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone train models just to gain insight on relationship between features and target variable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xhapb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685625260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes when exploring what feature impact a target variable, I\u2019ve found it helpful to train a model (random Forrest for example) then look at feature importance and or Shapley values. Is this bad practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xhapb", "is_robot_indexable": true, "report_reasons": null, "author": "sizable_data", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xhapb/does_anyone_train_models_just_to_gain_insight_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xhapb/does_anyone_train_models_just_to_gain_insight_on/", "subreddit_subscribers": 915713, "created_utc": 1685625260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say you are working on spam email detection. You build a classification model (e.g, LightGBM) after carefully evaluating 100 samples in the test set.\n\nThe model scores\n\n    Accuracy: 60%\n    Precision: 85%\n    Recall: 46%\n    F1: 60%\n\nHow do you explain these numbers to business users?\n\nAre those 4 metrics enough to measure model performance? What metrics would you add to ensure that your model is undoubtedly good?", "author_fullname": "t2_8x390zk24", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you explain classification metrics to business users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xxrvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685664635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say you are working on spam email detection. You build a classification model (e.g, LightGBM) after carefully evaluating 100 samples in the test set.&lt;/p&gt;\n\n&lt;p&gt;The model scores&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Accuracy: 60%\nPrecision: 85%\nRecall: 46%\nF1: 60%\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How do you explain these numbers to business users?&lt;/p&gt;\n\n&lt;p&gt;Are those 4 metrics enough to measure model performance? What metrics would you add to ensure that your model is undoubtedly good?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xxrvk", "is_robot_indexable": true, "report_reasons": null, "author": "sapporonight", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xxrvk/how_do_you_explain_classification_metrics_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xxrvk/how_do_you_explain_classification_metrics_to/", "subreddit_subscribers": 915713, "created_utc": 1685664635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After almost 5 years spent in research (I have a MSc in Physics)  I was just annoyed to use my time in order to produce results that would eventually end up in a research paper to be forgotten after a few months: I didn't see any purpose in that. That's why in 2019 I moved to the industry by applying as Data Scientist to a large corporation. I really hoped the industry would give me more practical applications of my knowledge; I was wrong.\n\nSince I joined the company I've been bouncing back and forth between different projects where I would have plenty of meetings discussing general stuff, without ever going into the details. Every time we were getting to something concrete it was said that I shouldn't do any development, as this is the task of subcontractors. Even when I managed to build some products that I think were pretty cool, after just a few months the same products ended up forgotten into a drawer because were built with already outdated requirements (a management issue). \n\nNowadays I just spend my days working on personal projects as the tasks that I'm assigned to are fairly easy and don't require me too much time. Plus, I'm working on stuff that I'm pretty sure nobody will ever use. Why do I know that? I could be literally gone for days and almost nobody would realize. I shouldn't really complain as I'm not working many hours and payed more than enough, but being constantly without motivation is definitely not good...\n\nIn the end I'd just like to be useful and to build something that I know will serve a purpose. Is it really hard to do that in big companies? Is there anyone in the same position as me?", "author_fullname": "t2_z7t46j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does working in a large corporation ever get less depressing and more interesting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y6m9f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685693454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After almost 5 years spent in research (I have a MSc in Physics)  I was just annoyed to use my time in order to produce results that would eventually end up in a research paper to be forgotten after a few months: I didn&amp;#39;t see any purpose in that. That&amp;#39;s why in 2019 I moved to the industry by applying as Data Scientist to a large corporation. I really hoped the industry would give me more practical applications of my knowledge; I was wrong.&lt;/p&gt;\n\n&lt;p&gt;Since I joined the company I&amp;#39;ve been bouncing back and forth between different projects where I would have plenty of meetings discussing general stuff, without ever going into the details. Every time we were getting to something concrete it was said that I shouldn&amp;#39;t do any development, as this is the task of subcontractors. Even when I managed to build some products that I think were pretty cool, after just a few months the same products ended up forgotten into a drawer because were built with already outdated requirements (a management issue). &lt;/p&gt;\n\n&lt;p&gt;Nowadays I just spend my days working on personal projects as the tasks that I&amp;#39;m assigned to are fairly easy and don&amp;#39;t require me too much time. Plus, I&amp;#39;m working on stuff that I&amp;#39;m pretty sure nobody will ever use. Why do I know that? I could be literally gone for days and almost nobody would realize. I shouldn&amp;#39;t really complain as I&amp;#39;m not working many hours and payed more than enough, but being constantly without motivation is definitely not good...&lt;/p&gt;\n\n&lt;p&gt;In the end I&amp;#39;d just like to be useful and to build something that I know will serve a purpose. Is it really hard to do that in big companies? Is there anyone in the same position as me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y6m9f", "is_robot_indexable": true, "report_reasons": null, "author": "OutrageousExternal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y6m9f/does_working_in_a_large_corporation_ever_get_less/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y6m9f/does_working_in_a_large_corporation_ever_get_less/", "subreddit_subscribers": 915713, "created_utc": 1685693454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When would banding be beneficial? Would it be where the data is too granular and the general trend is being lost in the noise (pdp plot too noisy).\n\nI understand that we can use the min child weight hyper parameter to reduce the noise in the data but I\u2019m unsure whether banding would improve the model performance. I\u2019m also rerunning and comparing banding vs unbanding but it would help to hear other people\u2019s experience", "author_fullname": "t2_afzfamz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Xgboost: Banding continuous variables vs keeping raw data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xtsp3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685654609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When would banding be beneficial? Would it be where the data is too granular and the general trend is being lost in the noise (pdp plot too noisy).&lt;/p&gt;\n\n&lt;p&gt;I understand that we can use the min child weight hyper parameter to reduce the noise in the data but I\u2019m unsure whether banding would improve the model performance. I\u2019m also rerunning and comparing banding vs unbanding but it would help to hear other people\u2019s experience&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xtsp3", "is_robot_indexable": true, "report_reasons": null, "author": "fuzzy_plums", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xtsp3/xgboost_banding_continuous_variables_vs_keeping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xtsp3/xgboost_banding_continuous_variables_vs_keeping/", "subreddit_subscribers": 915713, "created_utc": 1685654609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greeting everyone!\n\nI am new to data science, I am an undergraduate trying to . I am trying to clean two columns of my data set. The data is unstructured. The first data column deals with month, day, and year, but the entries not all follow a specific format. For example, one entry is 2005, another is c2005, \\[2005\\], 20050510, 2005-05-10, 2005 or 2006, 05/10/2005, (c) 2005, May 2005, May 10, 2005, 2005 (5th ed), etc. I want to know how I would clean and format the data. The second data column deals with names like publishers Jack Jack, Jack-Jack, jack jack, alex llc, james inc., etc. The data is in excel, but I am using Rstudio. I am trying to get a list of names that match a specific year. I ask for advice or suggestion or feedback on how to clean the data. If you have any questions, please comment! I think this is a great opportunity to handle unstructured data and i am really excited!\n\n&amp;#x200B;\n\nMy Estimated Approach\n\n1. Is to correct the first column's formatting in Excel, I will sort by the year. If they have a month listed, I will sort by month. If they have a day listed, I will sort by day. If they only have year, I will only sort the data by year.\n2. Correct the second column's formatting in Excel, I am unsure of how arrange the data. I want to get a list of all the names of the publishers. Then, find and replace the input to a specific form. \n3. Using Rstudio, I will write a program that will output a list of names along with the product item that are in a specific year.", "author_fullname": "t2_6npgrd5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance for Cleaning Unstructured Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xr3mq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685648279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greeting everyone!&lt;/p&gt;\n\n&lt;p&gt;I am new to data science, I am an undergraduate trying to . I am trying to clean two columns of my data set. The data is unstructured. The first data column deals with month, day, and year, but the entries not all follow a specific format. For example, one entry is 2005, another is c2005, [2005], 20050510, 2005-05-10, 2005 or 2006, 05/10/2005, (c) 2005, May 2005, May 10, 2005, 2005 (5th ed), etc. I want to know how I would clean and format the data. The second data column deals with names like publishers Jack Jack, Jack-Jack, jack jack, alex llc, james inc., etc. The data is in excel, but I am using Rstudio. I am trying to get a list of names that match a specific year. I ask for advice or suggestion or feedback on how to clean the data. If you have any questions, please comment! I think this is a great opportunity to handle unstructured data and i am really excited!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My Estimated Approach&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is to correct the first column&amp;#39;s formatting in Excel, I will sort by the year. If they have a month listed, I will sort by month. If they have a day listed, I will sort by day. If they only have year, I will only sort the data by year.&lt;/li&gt;\n&lt;li&gt;Correct the second column&amp;#39;s formatting in Excel, I am unsure of how arrange the data. I want to get a list of all the names of the publishers. Then, find and replace the input to a specific form. &lt;/li&gt;\n&lt;li&gt;Using Rstudio, I will write a program that will output a list of names along with the product item that are in a specific year.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xr3mq", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Ad_5697", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xr3mq/guidance_for_cleaning_unstructured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xr3mq/guidance_for_cleaning_unstructured_data/", "subreddit_subscribers": 915713, "created_utc": 1685648279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What level should a data analyst be at re: stats?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xos3y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_my91pdoi", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataanalysis", "selftext": "Obviously, data scientists need to have in-depth knowledge of statistics. I am trying to get an idea of what is really demanded of data analysts re: statistics, especially in Canada? \n\n1) Solid working knowledge of descriptive stats\n\n2) Solid working knowledge of inferential stats (e.g., regression, p-values etc.,)\n\n3) Even more advanced knowledge?", "author_fullname": "t2_my91pdoi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What level should a data analyst be at re: stats?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataanalysis", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xoqdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685642742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataanalysis", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Obviously, data scientists need to have in-depth knowledge of statistics. I am trying to get an idea of what is really demanded of data analysts re: statistics, especially in Canada? &lt;/p&gt;\n\n&lt;p&gt;1) Solid working knowledge of descriptive stats&lt;/p&gt;\n\n&lt;p&gt;2) Solid working knowledge of inferential stats (e.g., regression, p-values etc.,)&lt;/p&gt;\n\n&lt;p&gt;3) Even more advanced knowledge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32t3c", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xoqdo", "is_robot_indexable": true, "report_reasons": null, "author": "Will_Tomos_Edwards", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataanalysis/comments/13xoqdo/what_level_should_a_data_analyst_be_at_re_stats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataanalysis/comments/13xoqdo/what_level_should_a_data_analyst_be_at_re_stats/", "subreddit_subscribers": 57045, "created_utc": 1685642742.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685642853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataanalysis", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataanalysis/comments/13xoqdo/what_level_should_a_data_analyst_be_at_re_stats/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xos3y", "is_robot_indexable": true, "report_reasons": null, "author": "Will_Tomos_Edwards", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13xoqdo", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xos3y/what_level_should_a_data_analyst_be_at_re_stats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataanalysis/comments/13xoqdo/what_level_should_a_data_analyst_be_at_re_stats/", "subreddit_subscribers": 915713, "created_utc": 1685642853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all,\n\nBeen posting here a bit and getting great insight.\n\nGenerally newer to data science and analytics.\n\nWe ran an experiment and metrics showed something like this:\n\nOverall: impressions per user is up 3%\n\nUS users: down 0.5%\n\nNon-US users: down 3%\n\nMajority users are US users (maybe \\~75%)\n\nI've read articles and threads on Simpsons Paradox, but\n\n1) If I understand simpsons paradox correctly, this can apply here correct? Meaning that this result can theoretically be accurate (that our subgroups show a decline in a metric but overall shows an increase)\n\n2) Is there a way to try to verify that this is a paradox? I've comb through my code multiple times and things appear to be correct.", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Simpsons Paradox and how to validate it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xnttv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685640708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Been posting here a bit and getting great insight.&lt;/p&gt;\n\n&lt;p&gt;Generally newer to data science and analytics.&lt;/p&gt;\n\n&lt;p&gt;We ran an experiment and metrics showed something like this:&lt;/p&gt;\n\n&lt;p&gt;Overall: impressions per user is up 3%&lt;/p&gt;\n\n&lt;p&gt;US users: down 0.5%&lt;/p&gt;\n\n&lt;p&gt;Non-US users: down 3%&lt;/p&gt;\n\n&lt;p&gt;Majority users are US users (maybe ~75%)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read articles and threads on Simpsons Paradox, but&lt;/p&gt;\n\n&lt;p&gt;1) If I understand simpsons paradox correctly, this can apply here correct? Meaning that this result can theoretically be accurate (that our subgroups show a decline in a metric but overall shows an increase)&lt;/p&gt;\n\n&lt;p&gt;2) Is there a way to try to verify that this is a paradox? I&amp;#39;ve comb through my code multiple times and things appear to be correct.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xnttv", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xnttv/understanding_simpsons_paradox_and_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xnttv/understanding_simpsons_paradox_and_how_to/", "subreddit_subscribers": 915713, "created_utc": 1685640708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I have a dataset covering the sales of products in a collection of grocery stores on a weekly basis over roughly 3 years. I'm looking at hundreds of individual products, and I'm interested in getting a sense of whatever seasonal effects are going on (some of these are really obvious, like some products selling worse at Christmas and vice versa). Where I'm looking to get to ultimately is some notion of a product's base sales in the absence of seasonal effects (and the absence of other factors such as price changes, etc.). \n\nI've tried a few time series decomposition-based approaches coming from the likes of statsmodels.tsa, facebook's prophet, etc., and had some success with pulling out what look to be seasonal coefficients, but there are a few issues I'm running into:\n\n- There are a lot of products to look at, and not all of them have complete data; some are new to the market, some had supply issues for a number of weeks due to covid or other factors. I've looked into grouping products together to smooth some of this out, assuming for example that similar products experience similar seasonal effects, but I'm not sure that it's sufficient to just sum up the sales of a group and treat that as a meaningful time series. \n\nShould I be grouping things at all, should I look at each individually, or should I be treating the whole dataset as a system and somehow look at all products together?\n\n- Some approaches are very conservative with what I get as seasonal coefficients - fb Prophet in particular consistently underestimates the effect that holidays have, even on toy data that's constant for the whole year and spikes to the same level at Christmases. I'm assuming that this is an artifact of the curve fitting it's doing, and I've had some success with using a model with a holiday indicator variable, but it's such a regular pattern especially on the toy data that I was hoping it would be picked up by univariate analysis.\n\n- I'm not entirely clear on how to interpret/apply the results. With prophet models I get weekly coefficients expressed as percentages from multiplicative models, which I'm taking to mean that the sales I'm seeing are my \"base\" sales +/- X%. Does this seem reasonable? I haven't been able to dig up much on deseasonalisation in general.\n\nIf anyone has any thoughts on what I could try or any ideas for where to look/read I'd love to hear them, or if I'm doing anything glaringly wrong I'd really appreciate the feedback.", "author_fullname": "t2_6wpol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having trouble deseasonalising multiple parallel time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xgs4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685623900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have a dataset covering the sales of products in a collection of grocery stores on a weekly basis over roughly 3 years. I&amp;#39;m looking at hundreds of individual products, and I&amp;#39;m interested in getting a sense of whatever seasonal effects are going on (some of these are really obvious, like some products selling worse at Christmas and vice versa). Where I&amp;#39;m looking to get to ultimately is some notion of a product&amp;#39;s base sales in the absence of seasonal effects (and the absence of other factors such as price changes, etc.). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried a few time series decomposition-based approaches coming from the likes of statsmodels.tsa, facebook&amp;#39;s prophet, etc., and had some success with pulling out what look to be seasonal coefficients, but there are a few issues I&amp;#39;m running into:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;There are a lot of products to look at, and not all of them have complete data; some are new to the market, some had supply issues for a number of weeks due to covid or other factors. I&amp;#39;ve looked into grouping products together to smooth some of this out, assuming for example that similar products experience similar seasonal effects, but I&amp;#39;m not sure that it&amp;#39;s sufficient to just sum up the sales of a group and treat that as a meaningful time series. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Should I be grouping things at all, should I look at each individually, or should I be treating the whole dataset as a system and somehow look at all products together?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Some approaches are very conservative with what I get as seasonal coefficients - fb Prophet in particular consistently underestimates the effect that holidays have, even on toy data that&amp;#39;s constant for the whole year and spikes to the same level at Christmases. I&amp;#39;m assuming that this is an artifact of the curve fitting it&amp;#39;s doing, and I&amp;#39;ve had some success with using a model with a holiday indicator variable, but it&amp;#39;s such a regular pattern especially on the toy data that I was hoping it would be picked up by univariate analysis.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I&amp;#39;m not entirely clear on how to interpret/apply the results. With prophet models I get weekly coefficients expressed as percentages from multiplicative models, which I&amp;#39;m taking to mean that the sales I&amp;#39;m seeing are my &amp;quot;base&amp;quot; sales +/- X%. Does this seem reasonable? I haven&amp;#39;t been able to dig up much on deseasonalisation in general.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If anyone has any thoughts on what I could try or any ideas for where to look/read I&amp;#39;d love to hear them, or if I&amp;#39;m doing anything glaringly wrong I&amp;#39;d really appreciate the feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xgs4p", "is_robot_indexable": true, "report_reasons": null, "author": "InflationSquare", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xgs4p/having_trouble_deseasonalising_multiple_parallel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xgs4p/having_trouble_deseasonalising_multiple_parallel/", "subreddit_subscribers": 915713, "created_utc": 1685623900.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hundreds of millions of observations, with 30 or so columns. \n\nFirst step is to reduce dimensionality to 3 (t-SNE). \n\nSecond step is to map/plot. I am most familiar with Python and will try Vaex when I get back to the office, at the end of the summer. In the meantime I'd like to read and learn about tools and techniques. I'd want to render 3D plots that can be rotated. Specify the color of dots that belong to a given class. Learn to create \"exploding\" plots (start with aggregates, then explode to show individual components).\n\nWell, you probably can see the picture. \n\nSuggestions?", "author_fullname": "t2_3854xj3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are good resources to assist in large scale 3Dvisualization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xe04n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685615475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hundreds of millions of observations, with 30 or so columns. &lt;/p&gt;\n\n&lt;p&gt;First step is to reduce dimensionality to 3 (t-SNE). &lt;/p&gt;\n\n&lt;p&gt;Second step is to map/plot. I am most familiar with Python and will try Vaex when I get back to the office, at the end of the summer. In the meantime I&amp;#39;d like to read and learn about tools and techniques. I&amp;#39;d want to render 3D plots that can be rotated. Specify the color of dots that belong to a given class. Learn to create &amp;quot;exploding&amp;quot; plots (start with aggregates, then explode to show individual components).&lt;/p&gt;\n\n&lt;p&gt;Well, you probably can see the picture. &lt;/p&gt;\n\n&lt;p&gt;Suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xe04n", "is_robot_indexable": true, "report_reasons": null, "author": "-gauvins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xe04n/what_are_good_resources_to_assist_in_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xe04n/what_are_good_resources_to_assist_in_large_scale/", "subreddit_subscribers": 915713, "created_utc": 1685615475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently got a take-home assignment for a job before interviewing with someone. The assignment was quite difficult in my opinion: 1) it was a very domain-specific task (predict protein binding affinity from sequences, which I didn't have experience in); 2) the dataset was large (millions of pairs); 3) the distribution of the labels were narrow as the binding affinity was low in most cases.\n\nI was given a week to build a ML model to *accurately* make predictions. I spent almost all my free time in the week but none of my models worked. Submitted what I had in the end but had no hopes for moving forward for obvious reasons.\n\nGiven the assignment itself, and the fact that this was even before speaking to anyone in the company,  I felt the assignment was used for free ideas/initial exploration of a big project. Or I am just incompetent? As someone who is desperate enough, I have no choice but to finish those assignments, but feel really burnout for the time-demanding ones.\n\n**TL;DR**\n\nHow to tell if a take-home assignment is used to harvest free ideas/labour? What would you do in this case?", "author_fullname": "t2_axl6v1qoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Take-home assignments: test or free ideas/labour? How to tell the difference?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13y7yzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685698439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got a take-home assignment for a job before interviewing with someone. The assignment was quite difficult in my opinion: 1) it was a very domain-specific task (predict protein binding affinity from sequences, which I didn&amp;#39;t have experience in); 2) the dataset was large (millions of pairs); 3) the distribution of the labels were narrow as the binding affinity was low in most cases.&lt;/p&gt;\n\n&lt;p&gt;I was given a week to build a ML model to &lt;em&gt;accurately&lt;/em&gt; make predictions. I spent almost all my free time in the week but none of my models worked. Submitted what I had in the end but had no hopes for moving forward for obvious reasons.&lt;/p&gt;\n\n&lt;p&gt;Given the assignment itself, and the fact that this was even before speaking to anyone in the company,  I felt the assignment was used for free ideas/initial exploration of a big project. Or I am just incompetent? As someone who is desperate enough, I have no choice but to finish those assignments, but feel really burnout for the time-demanding ones.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How to tell if a take-home assignment is used to harvest free ideas/labour? What would you do in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y7yzu", "is_robot_indexable": true, "report_reasons": null, "author": "SevereCheetah1939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y7yzu/takehome_assignments_test_or_free_ideaslabour_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y7yzu/takehome_assignments_test_or_free_ideaslabour_how/", "subreddit_subscribers": 915713, "created_utc": 1685698439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good evening fellow nerds....lol.\n\n\nWhat are some recommended training to learn typescript? Paid or unpaid doesn't matter. \n\nI am trying to expand my knowledge base for work so I can use some typescript capabilities. I see different online trainings but wanted to hear from you all.", "author_fullname": "t2_qp5mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Typescript Training Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xym55", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685666969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening fellow nerds....lol.&lt;/p&gt;\n\n&lt;p&gt;What are some recommended training to learn typescript? Paid or unpaid doesn&amp;#39;t matter. &lt;/p&gt;\n\n&lt;p&gt;I am trying to expand my knowledge base for work so I can use some typescript capabilities. I see different online trainings but wanted to hear from you all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xym55", "is_robot_indexable": true, "report_reasons": null, "author": "Yourteararedelicious", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xym55/typescript_training_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xym55/typescript_training_recommendations/", "subreddit_subscribers": 915713, "created_utc": 1685666969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to learn SQL, do I have to buy software for it? The google course is sort of a guide, but I\u00b4m a hands on kind of learner.", "author_fullname": "t2_agqkoks8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning SQL tools and tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xvme5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685659045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to learn SQL, do I have to buy software for it? The google course is sort of a guide, but I\u00b4m a hands on kind of learner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xvme5", "is_robot_indexable": true, "report_reasons": null, "author": "Clashoftwo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xvme5/learning_sql_tools_and_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xvme5/learning_sql_tools_and_tips/", "subreddit_subscribers": 915713, "created_utc": 1685659045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking for ideas about designing a recommender system to recommend college courses in a traditional on-campus courses. \n\nWorking with recommender sys for first time so have been studying about it for a while now. It seems unless there are hundreds/thousands of products/contents and some ranking from users, building a recommender system doesn't make much sense. We offer mostly traditional on-campus courses (contents) so we don't have a ton of courses to choose from unlike some online universities. And there's no rating from students (users). We could use course GPA as a proxy for rating. \n\nBut it doesn't seem to me like a good case for commonly used recommender system models e.g. Collab filtering, matrix factorization etc. \n\nRather implementing a simple ranking based on some kind of historic course grade stats maybe would be a good idea? Another possibility that I see is using the course features along with student related features as predictor and course grades as target to build a predictive model. Then using it to predict course grades and rank the courses based on the predicted grades. \n\nAny thoughts on any of these ideas or any new ideas/tips?", "author_fullname": "t2_viwwhp0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommender system ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xtwvt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685654894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for ideas about designing a recommender system to recommend college courses in a traditional on-campus courses. &lt;/p&gt;\n\n&lt;p&gt;Working with recommender sys for first time so have been studying about it for a while now. It seems unless there are hundreds/thousands of products/contents and some ranking from users, building a recommender system doesn&amp;#39;t make much sense. We offer mostly traditional on-campus courses (contents) so we don&amp;#39;t have a ton of courses to choose from unlike some online universities. And there&amp;#39;s no rating from students (users). We could use course GPA as a proxy for rating. &lt;/p&gt;\n\n&lt;p&gt;But it doesn&amp;#39;t seem to me like a good case for commonly used recommender system models e.g. Collab filtering, matrix factorization etc. &lt;/p&gt;\n\n&lt;p&gt;Rather implementing a simple ranking based on some kind of historic course grade stats maybe would be a good idea? Another possibility that I see is using the course features along with student related features as predictor and course grades as target to build a predictive model. Then using it to predict course grades and rank the courses based on the predicted grades. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts on any of these ideas or any new ideas/tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xtwvt", "is_robot_indexable": true, "report_reasons": null, "author": "Abject-Bumblebee4881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xtwvt/recommender_system_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xtwvt/recommender_system_ideas/", "subreddit_subscribers": 915713, "created_utc": 1685654894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intelligent document extraction for logistics and supply chain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xp98u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_q9v3kbiq", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "nlp_knowledge_sharing", "selftext": "In the article, we provide an easy-to-follow tutorial that empowers you to train and host custom AI models for logistics documents, even if you're not an AI expert or have coding skills. \n\nThe tutorial focuses on training a Named Entity Recognition (NER) model tailored for the logistics domain with over 110 labels. We demonstrate how to label and train the model using your own dataset, saving valuable time and simplifying the model training process \ud83d\ude80 \n\nAdditionally, we guide you through deploying your custom model using the AI Builder tool (https//builder.ubiai.tools), enabling seamless document processing and efficient data extraction within your business workflow.\n\n\ud83d\udd25Read the full article here [ https://walidamamou.medium.com/intelligent-document-extraction-for-logistics-and-supply-chain-75f3dbc461f9 ] and discover how you can train and host custom AI models for logistics documents without needing to be an AI expert or possess coding skills.\n\n#SupplyChainManagement #Logistics #AIModels #DocumentProcessing #DataExtraction #FutureTechnology #MustRead", "author_fullname": "t2_q9v3kbiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intelligent document extraction for logistics and supply chain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/nlp_knowledge_sharing", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xp6tw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685643818.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.nlp_knowledge_sharing", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the article, we provide an easy-to-follow tutorial that empowers you to train and host custom AI models for logistics documents, even if you&amp;#39;re not an AI expert or have coding skills. &lt;/p&gt;\n\n&lt;p&gt;The tutorial focuses on training a Named Entity Recognition (NER) model tailored for the logistics domain with over 110 labels. We demonstrate how to label and train the model using your own dataset, saving valuable time and simplifying the model training process \ud83d\ude80 &lt;/p&gt;\n\n&lt;p&gt;Additionally, we guide you through deploying your custom model using the AI Builder tool (https//builder.ubiai.tools), enabling seamless document processing and efficient data extraction within your business workflow.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd25Read the full article here [ &lt;a href=\"https://walidamamou.medium.com/intelligent-document-extraction-for-logistics-and-supply-chain-75f3dbc461f9\"&gt;https://walidamamou.medium.com/intelligent-document-extraction-for-logistics-and-supply-chain-75f3dbc461f9&lt;/a&gt; ] and discover how you can train and host custom AI models for logistics documents without needing to be an AI expert or possess coding skills.&lt;/p&gt;\n\n&lt;h1&gt;SupplyChainManagement #Logistics #AIModels #DocumentProcessing #DataExtraction #FutureTechnology #MustRead&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?auto=webp&amp;v=enabled&amp;s=880bdf34811e74b3b13b8e1357e2cf474e414459", "width": 1200, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ddb7665820df8097f9c1073d96c407f1054f195", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0dde54713a949a9a0857d90127deabe7dd593246", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aea313056e1d7897f0df2f87e1619b73e77269fa", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ba7b6081862bbccb07afaab5151865b65529dcc", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa3dd15d9543863c44f99af80c89b8c5c739a580", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c2dd3fef612461352b923d19a4bd367ec7dfa9d", "width": 1080, "height": 617}], "variants": {}, "id": "hW91nlJSsQ9VxPs55XGLzGr1XXwDRjOmb6xoBFSxdMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ulgo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xp6tw", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/nlp_knowledge_sharing/comments/13xp6tw/intelligent_document_extraction_for_logistics_and/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/nlp_knowledge_sharing/comments/13xp6tw/intelligent_document_extraction_for_logistics_and/", "subreddit_subscribers": 1913, "created_utc": 1685643818.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1685643975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.nlp_knowledge_sharing", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/nlp_knowledge_sharing/comments/13xp6tw/intelligent_document_extraction_for_logistics_and/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?auto=webp&amp;v=enabled&amp;s=880bdf34811e74b3b13b8e1357e2cf474e414459", "width": 1200, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ddb7665820df8097f9c1073d96c407f1054f195", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0dde54713a949a9a0857d90127deabe7dd593246", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aea313056e1d7897f0df2f87e1619b73e77269fa", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ba7b6081862bbccb07afaab5151865b65529dcc", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa3dd15d9543863c44f99af80c89b8c5c739a580", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/-Qrukh-zG5iyyKs56eAVtePGGLy5eERIslk_Z7Qx6cM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c2dd3fef612461352b923d19a4bd367ec7dfa9d", "width": 1080, "height": 617}], "variants": {}, "id": "hW91nlJSsQ9VxPs55XGLzGr1XXwDRjOmb6xoBFSxdMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xp98u", "is_robot_indexable": true, "report_reasons": null, "author": "Harvy_thomson87", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13xp6tw", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xp98u/intelligent_document_extraction_for_logistics_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/nlp_knowledge_sharing/comments/13xp6tw/intelligent_document_extraction_for_logistics_and/", "subreddit_subscribers": 915713, "created_utc": 1685643975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently getting my bachelors in stats &amp; computer science and will likely go for an MS in statistics afterwards. I'm pretty decent with software, so I've built targeted crawlers and have a lot of data I'm passionate about for projects. I am very school/career oriented and do wish to be as good as I can be at what I do.\n\nThere's a lot of stuff I've learnt in school, like basic data cleaning &amp; visualisation, that is done so much easier using GPT and its plugins. Rather than fiddling around with ggplot in R, I can use Tableau or Noteable with GPT and get the same results in a fraction of the time. I've got a decent idea of using R or pandas to navigate a data frame, but I can now achieve the same results in natural language in, again, a fraction of the time. I can get GPT to interpret, rename, standardise and clean my data set in 30 seconds.\n\nI can see the value in understanding how things work, but is it actually worth reinventing the wheel? My two concerns would be that my skills may atrophy and that when this suddenly doesn't work for a complex enough problem, I'll be stumped.", "author_fullname": "t2_2tftq9c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To what extent should you reinvent the wheel while learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xes1h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685618019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently getting my bachelors in stats &amp;amp; computer science and will likely go for an MS in statistics afterwards. I&amp;#39;m pretty decent with software, so I&amp;#39;ve built targeted crawlers and have a lot of data I&amp;#39;m passionate about for projects. I am very school/career oriented and do wish to be as good as I can be at what I do.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of stuff I&amp;#39;ve learnt in school, like basic data cleaning &amp;amp; visualisation, that is done so much easier using GPT and its plugins. Rather than fiddling around with ggplot in R, I can use Tableau or Noteable with GPT and get the same results in a fraction of the time. I&amp;#39;ve got a decent idea of using R or pandas to navigate a data frame, but I can now achieve the same results in natural language in, again, a fraction of the time. I can get GPT to interpret, rename, standardise and clean my data set in 30 seconds.&lt;/p&gt;\n\n&lt;p&gt;I can see the value in understanding how things work, but is it actually worth reinventing the wheel? My two concerns would be that my skills may atrophy and that when this suddenly doesn&amp;#39;t work for a complex enough problem, I&amp;#39;ll be stumped.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xes1h", "is_robot_indexable": true, "report_reasons": null, "author": "levaaa_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xes1h/to_what_extent_should_you_reinvent_the_wheel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13xes1h/to_what_extent_should_you_reinvent_the_wheel/", "subreddit_subscribers": 915713, "created_utc": 1685618019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Test Data Generator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xdyp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_nzubmnn", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "aws", "selftext": "Please check my open source AWS Glue test data generator under aws-samples repository [https://github.com/aws-samples/aws-glue-test-data-generator](https://github.com/aws-samples/aws-glue-test-data-generator)", "author_fullname": "t2_nzubmnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue Test Data Generator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13wtzcd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "data analytics", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685557679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please check my open source AWS Glue test data generator under aws-samples repository &lt;a href=\"https://github.com/aws-samples/aws-glue-test-data-generator\"&gt;https://github.com/aws-samples/aws-glue-test-data-generator&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?auto=webp&amp;v=enabled&amp;s=2dd94f956b6f06e29510adf23a454a2abf42cb1f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39534ae830646054804b097a7f90ef915f6d4f2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95cabbc0b715cdee8b1396d4196ddb168e217a99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb08a5b4cae1046be6d69cf9a10619cf2925dde4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f42da7929e9b06f5dce82ad0c8ffdef2e7251b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9c1c4d5dd82fda0c3dc6444c859632b9e56194", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d568da4c3b9331327502f8338c0bd7203c0950df", "width": 1080, "height": 540}], "variants": {}, "id": "zVFtZ_jawPVzqOq2YRn7nwlwbYFSj23cWLHXo1eqCwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3fbb2226-250a-11eb-850a-0eeeb4e6614f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13wtzcd", "is_robot_indexable": true, "report_reasons": null, "author": "mbishbeashy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "subreddit_subscribers": 238021, "created_utc": 1685557679.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1685615340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?auto=webp&amp;v=enabled&amp;s=2dd94f956b6f06e29510adf23a454a2abf42cb1f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39534ae830646054804b097a7f90ef915f6d4f2e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95cabbc0b715cdee8b1396d4196ddb168e217a99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb08a5b4cae1046be6d69cf9a10619cf2925dde4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f42da7929e9b06f5dce82ad0c8ffdef2e7251b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9c1c4d5dd82fda0c3dc6444c859632b9e56194", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JOR1l1cxX5ilVmIw5l8SL8rrrXJjCdenOCPUWZm1e-M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d568da4c3b9331327502f8338c0bd7203c0950df", "width": 1080, "height": 540}], "variants": {}, "id": "zVFtZ_jawPVzqOq2YRn7nwlwbYFSj23cWLHXo1eqCwE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13xdyp1", "is_robot_indexable": true, "report_reasons": null, "author": "mbishbeashy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_13wtzcd", "author_flair_text_color": null, "permalink": "/r/datascience/comments/13xdyp1/aws_glue_test_data_generator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/aws/comments/13wtzcd/aws_glue_test_data_generator/", "subreddit_subscribers": 915713, "created_utc": 1685615340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there any way to combine multiple XGBOOST models to a single model such that all functions of xgb class / shap run on it like it's a single model\nPs- Thanks in advance", "author_fullname": "t2_cfq7ywht7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining multiple XGBOOST models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5jhq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685689337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any way to combine multiple XGBOOST models to a single model such that all functions of xgb class / shap run on it like it&amp;#39;s a single model\nPs- Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y5jhq", "is_robot_indexable": true, "report_reasons": null, "author": "hisoka_aly", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y5jhq/combining_multiple_xgboost_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y5jhq/combining_multiple_xgboost_models/", "subreddit_subscribers": 915713, "created_utc": 1685689337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\n## Introduction \n\n[Data science trends in 2023](https://preview.redd.it/yrrap9oqyj3b1.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a9ccd0d5de1ebe65fcc10f335908a9b734bd07e8)\n\n**Data Science Trends** for 2023 are set to shape the future of data-driven decision-making. Thanks to the rapid progress of **Data Science and AI**, organisations may use cutting-edge technology and processes to derive useful insights from huge data sets. These themes cover a wide range of innovations, such as AI-driven analytics, automated [machine learning projects](https://blog.learnbay.co/top-5-machine-learning-projects-for-beginners-in-2023), augmented reality in data visualisation, improvements in natural language processing, and federated learning for improved privacy and cooperation.\n\nOrganisations can remain ahead of the curve and use the power of data science to drive innovation, improve operations, and gain a competitive edge by comprehending and embracing these trends. As these changes transform our use of data in 2023 and beyond, data professionals must stay current and adapt to them. \n\n## Data Science Trends for 2023\n\n### Artificial Intelligence\n\nData science will undergo a revolution in 2023 due to AI, opening up new possibilities. AI algorithms and approaches allow robots to mimic human intellect, allowing them to carry out complex operations and make independent judgements. There are several advantages to this combination of AI and data science. \n\nFirst, the pattern recognition skills of AI algorithms allow for discovering intricate links and patterns within enormous datasets that may be difficult for humans to notice. Second, as AI systems learn from previous data and produce trustworthy projections for future events, predictive modelling gets more accurate and precise. Additionally, AI-assisted automation of analytical procedures minimises human labour and accelerates data-driven insights, boosting productivity and efficiency. \n\nA better comprehension of data and the ability to make wise judgements that promote development and success are made possible by the synergy between AI and data science. **Data science in 2023** promises to open up new vistas in knowledge discovery and problem-solving, with AI at its core.\n\n### Machine Learning \n\nThe data science landscape and the **Data Science Trends** for 2023 are expected to be dominated by machine learning (ML), a subset of artificial intelligence (AI). Systems may learn from data and increase performance without explicit programming thanks to machine learning (ML) methods. By 2023, ML will be a fundamental component of Data Science thanks to its revolutionary impact on various Data Science applications, including fraud detection, predictive analytics, and recommendation systems. \n\n**Data science in 2023** will continue to advance due to developments in machine learning algorithms, deep learning architectures, and neural networks that will open up new opportunities for extracting knowledge from large-scale datasets. The constant advancement of ML approaches will encourage the creation of cutting-edge methods for handling data issues and enabling more precise forecasts and insights. In this data-driven era, organisations rely on ML-driven models to find important information, acquire a competitive edge, and make wise decisions. \n\nThe growing use and deployment of ML methods will characterise **Data Science Trends** in 2023. As ML algorithms advance, businesses and sectors will see ground-breaking improvements in data analysis, pattern identification, and predictive modelling. By 2023, data science will have revolutionised how businesses operate and generate value from their data assets by utilising ML developments to unleash the full potential of data and create disruptive transformations across industries.  \n\n### Augmented Reality \n\nIn 2023, Augmented Reality (AR) will become a game-changing technology in data science trends. By fusing the physical and digital worlds, augmented reality (AR) improves data scientists' view of and engagement with their surroundings, revolutionising **data science in 2023**. Augmented reality (AR), which offers immersive and interactive experiences, might transform data visualisation and analysis. \n\nIts applications also include collaborative analytics, data exploration, and visualisation, allowing users to make data-driven choices more naturally and interestingly. \n\nData scientists may seamlessly integrate data into the actual world by using AR to overlay data points, charts, and graphs onto the real-world environment. Data scientists have a strong tool at their disposal in the form of augmented reality (AR), according to the trends in **data science in 2023**, which paves the way for novel data analysis and decision-making methods.\n\n### Natural Language Processing (NLP)\n\nAccording to data science trends, Natural Language Processing (NLP) will play a significant part in defining **data science in 2023**. NLP aims to make it possible for computers to comprehend, translate, and create natural language, revolutionising how we interact with textual data. In 2023, the area of NLP will continue to advance thanks to developments in chatbot creation, sentiment analysis, and language translation. \n\nNLP techniques like text mining, sentiment analysis, and named entity identification will be essential to gain useful insights from unstructured data sources like social media, customer reviews, and text documents. Organisations may extract valuable information from these enormous textual resources using NLP in Data Science, allowing data-driven decision-making and competitive advantage in 2023.\n\nImproved natural language processing promotes innovation. A shift in how organisations extract knowledge from the textual domain in Data Science will result from the continuous development of NLP approaches and algorithms.\n\n### Federated Learning \n\nFederated Learning stands out in the landscape of **Data Science Trends** as a disruptive strategy tackling data privacy and security issues in **Data Science in 2023**. Federated learning enables models to be trained locally on distant data sources. It is becoming more popular as businesses seek ways to collaborate and get insights without jeopardising sensitive data. \n\nFederated learning under this decentralised paradigm assures privacy compliance while utilising the combined wisdom of several datasets to produce improved models and more precise predictions. Federated learning will revolutionise **data science in 2023** thanks to its capacity to protect data privacy and promote collaborative research.\n\nOrganisations can use dispersed data's potential without the requirement for centralised data transmission or storage, promoting innovation and advancing the industry. Federated learning offers a privacy-preserving method for releasing the full potential of dispersed data resources in 2023 and beyond, and it is a critical enabler in the changing landscape of **data science trends**.\n\n## Importance of Data Science in 2023\n\n**Data science trends** are crucial for businesses using data-driven decision-making to achieve a competitive advantage. Utilising the main **Data Science Trends** of AI, ML, AR, NLP, and federated learning will be essential for gaining insightful information, streamlining procedures, and fostering creativity across sectors. You can hone your skills and knowledge by taking [online certification courses](https://course.learnbay.co/). Data scientists, who will be at the forefront of **data science in 2023**, will be essential in converting raw data into information organisations can use to stay adaptable and make wise strategic decisions.\n\n* **Competitive Edge**: By utilising the potential of AI, ML, AR, NLP, and federated learning, **Data Science Trends** give businesses a competitive edge. Businesses may extract priceless insights, spot patterns, and make data-driven choices that provide them with a major competitive edge in 2023 by adopting these cutting-edge technologies in data science.\n* **Actionable Insights**: Data scientists, who will play a major role in **data science in 2023**, are skilled at sifting through large databases for significant patterns, trends, and correlations. They give businesses useful insights through data analysis and interpretation that help them make strategic decisions, streamline procedures, and expand their operations. \n* **Agility and Adaptability**: Organisations need to be flexible and adaptive in the **Data Science Trends** landscape 2023, given its fast evolution. Thanks to data science, businesses can analyse real-time data, spot new patterns, and react quickly to shifting market conditions. Organisations can make data-driven choices because of their agility, which keeps them one step ahead of the competition and in line with their strategic objectives.\n* **Enhanced Customer Experience**: Organisations may thoroughly grasp client preferences, behaviour, and demands thanks to **data science trends**. Businesses may personalise experiences, conduct targeted marketing efforts, and increase overall customer happiness by using consumer data with AI, ML, NLP, and AR. This improved customer experience encourages retention, growth, and customer loyalty. \n* **Innovation and Optimization**: By revealing hidden patterns and insights that result in ground-breaking solutions, 2023's **data science trends** will help to drive innovation. Organisations may stimulate innovation, maximise profitability, and maintain their competitive edge in a data-driven world by optimising processes, enhancing efficiency, and spotting possibilities for cost reductions. \n\nAs businesses strive to use the potential of AI, ML, AR, NLP, and federated learning for competitive advantage, actionable insights, agility, improved customer experiences, and innovation, data science is of utmost significance. Businesses that want to succeed in the data-driven world in 2023 must embrace data science not merely out of necessity but also out of strategic necessity. \n\n## How Can You Make A Career in Data Science in 2023? \n\nThere are various crucial things to consider in 2023 for people who want to work in the data science area. First and foremost, it's crucial to build a solid foundation in arithmetic, statistics, and programming languages like Python and R. Your knowledge and abilities can also be improved by enrolling in appropriate educational programmes, online courses, and certifications. Learnbay\u2019s [**data science course**](https://course.learnbay.co/data-science-certification-courses?utm_source=google&amp;utm_medium=ds_%5Bag_1%5D_lb&amp;utm_campaign=search_ads_learnbay.co&amp;utm_id=16975880767&amp;utm_term=data_science&amp;utm_term=learnbay%20data%20science%20course&amp;utm_campaign=Search+Ads+Learnbay.co&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=6881325803&amp;hsa_cam=16975880767&amp;hsa_grp=136176468216&amp;hsa_ad=636562695815&amp;hsa_src=g&amp;hsa_tgt=kwd-920798089135&amp;hsa_kw=learnbay%20data%20science%20course&amp;hsa_mt=p&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=Cj0KCQjw4NujBhC5ARIsAF4Iv6cEddG8Zj1ARtSL3kSHWovEqQG0Rx7hPYOnPOJLV2SYww8VFHEhqNgaAtgpEALw_wcB) will help you stand out among the rest. It focuses on domain specialisation. \n\nParticipation in data science contests and practical experience with real-world data projects may improve your portfolio. Finally, ensuring your abilities are current and in demand requires continuously studying new trends, technologies, and procedures. \n\n## The Bottom Line\n\nThe data science environment is being formed as we set off on the trip of 2023 with important developments, including AI, ML, AR, NLP, and federated learning. These developments are pushing the limits of what is feasible in data analysis and decision-making, fueling ground-breaking innovations. For businesses and data, professionals who want to fully utilise data science in the years to come, embracing and comprehending these trends is essential. \n\nBusinesses may gain a competitive edge, stimulate innovation, and make wise decisions based on data-driven insights by keeping up with the newest advancements and adopting these disruptive technologies into their plans. The capacity to adapt and take advantage of these trends will be a crucial difference in this quickly expanding area. It will help practitioners succeed and realise the full potential of data science in the dynamic and data-centric era of 2023 and beyond.", "author_fullname": "t2_thvgxi49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top Data Science Trends for 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yrrap9oqyj3b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/yrrap9oqyj3b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99f1b38fb6b58d88e7b647f88b98bd7580802cf7"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/yrrap9oqyj3b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab58f2d31599556f8d4c0007afce20707157b95d"}], "s": {"y": 168, "x": 300, "u": "https://preview.redd.it/yrrap9oqyj3b1.jpg?width=300&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a9ccd0d5de1ebe65fcc10f335908a9b734bd07e8"}, "id": "yrrap9oqyj3b1"}}, "name": "t3_13y5g9h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/QS-S-u4PrlSr1I_Ty3ZGEzQ0T0xjDtW6D2wkJgTOj00.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685689029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yrrap9oqyj3b1.jpg?width=300&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a9ccd0d5de1ebe65fcc10f335908a9b734bd07e8\"&gt;Data science trends in 2023&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Science Trends&lt;/strong&gt; for 2023 are set to shape the future of data-driven decision-making. Thanks to the rapid progress of &lt;strong&gt;Data Science and AI&lt;/strong&gt;, organisations may use cutting-edge technology and processes to derive useful insights from huge data sets. These themes cover a wide range of innovations, such as AI-driven analytics, automated &lt;a href=\"https://blog.learnbay.co/top-5-machine-learning-projects-for-beginners-in-2023\"&gt;machine learning projects&lt;/a&gt;, augmented reality in data visualisation, improvements in natural language processing, and federated learning for improved privacy and cooperation.&lt;/p&gt;\n\n&lt;p&gt;Organisations can remain ahead of the curve and use the power of data science to drive innovation, improve operations, and gain a competitive edge by comprehending and embracing these trends. As these changes transform our use of data in 2023 and beyond, data professionals must stay current and adapt to them. &lt;/p&gt;\n\n&lt;h2&gt;Data Science Trends for 2023&lt;/h2&gt;\n\n&lt;h3&gt;Artificial Intelligence&lt;/h3&gt;\n\n&lt;p&gt;Data science will undergo a revolution in 2023 due to AI, opening up new possibilities. AI algorithms and approaches allow robots to mimic human intellect, allowing them to carry out complex operations and make independent judgements. There are several advantages to this combination of AI and data science. &lt;/p&gt;\n\n&lt;p&gt;First, the pattern recognition skills of AI algorithms allow for discovering intricate links and patterns within enormous datasets that may be difficult for humans to notice. Second, as AI systems learn from previous data and produce trustworthy projections for future events, predictive modelling gets more accurate and precise. Additionally, AI-assisted automation of analytical procedures minimises human labour and accelerates data-driven insights, boosting productivity and efficiency. &lt;/p&gt;\n\n&lt;p&gt;A better comprehension of data and the ability to make wise judgements that promote development and success are made possible by the synergy between AI and data science. &lt;strong&gt;Data science in 2023&lt;/strong&gt; promises to open up new vistas in knowledge discovery and problem-solving, with AI at its core.&lt;/p&gt;\n\n&lt;h3&gt;Machine Learning&lt;/h3&gt;\n\n&lt;p&gt;The data science landscape and the &lt;strong&gt;Data Science Trends&lt;/strong&gt; for 2023 are expected to be dominated by machine learning (ML), a subset of artificial intelligence (AI). Systems may learn from data and increase performance without explicit programming thanks to machine learning (ML) methods. By 2023, ML will be a fundamental component of Data Science thanks to its revolutionary impact on various Data Science applications, including fraud detection, predictive analytics, and recommendation systems. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data science in 2023&lt;/strong&gt; will continue to advance due to developments in machine learning algorithms, deep learning architectures, and neural networks that will open up new opportunities for extracting knowledge from large-scale datasets. The constant advancement of ML approaches will encourage the creation of cutting-edge methods for handling data issues and enabling more precise forecasts and insights. In this data-driven era, organisations rely on ML-driven models to find important information, acquire a competitive edge, and make wise decisions. &lt;/p&gt;\n\n&lt;p&gt;The growing use and deployment of ML methods will characterise &lt;strong&gt;Data Science Trends&lt;/strong&gt; in 2023. As ML algorithms advance, businesses and sectors will see ground-breaking improvements in data analysis, pattern identification, and predictive modelling. By 2023, data science will have revolutionised how businesses operate and generate value from their data assets by utilising ML developments to unleash the full potential of data and create disruptive transformations across industries.  &lt;/p&gt;\n\n&lt;h3&gt;Augmented Reality&lt;/h3&gt;\n\n&lt;p&gt;In 2023, Augmented Reality (AR) will become a game-changing technology in data science trends. By fusing the physical and digital worlds, augmented reality (AR) improves data scientists&amp;#39; view of and engagement with their surroundings, revolutionising &lt;strong&gt;data science in 2023&lt;/strong&gt;. Augmented reality (AR), which offers immersive and interactive experiences, might transform data visualisation and analysis. &lt;/p&gt;\n\n&lt;p&gt;Its applications also include collaborative analytics, data exploration, and visualisation, allowing users to make data-driven choices more naturally and interestingly. &lt;/p&gt;\n\n&lt;p&gt;Data scientists may seamlessly integrate data into the actual world by using AR to overlay data points, charts, and graphs onto the real-world environment. Data scientists have a strong tool at their disposal in the form of augmented reality (AR), according to the trends in &lt;strong&gt;data science in 2023&lt;/strong&gt;, which paves the way for novel data analysis and decision-making methods.&lt;/p&gt;\n\n&lt;h3&gt;Natural Language Processing (NLP)&lt;/h3&gt;\n\n&lt;p&gt;According to data science trends, Natural Language Processing (NLP) will play a significant part in defining &lt;strong&gt;data science in 2023&lt;/strong&gt;. NLP aims to make it possible for computers to comprehend, translate, and create natural language, revolutionising how we interact with textual data. In 2023, the area of NLP will continue to advance thanks to developments in chatbot creation, sentiment analysis, and language translation. &lt;/p&gt;\n\n&lt;p&gt;NLP techniques like text mining, sentiment analysis, and named entity identification will be essential to gain useful insights from unstructured data sources like social media, customer reviews, and text documents. Organisations may extract valuable information from these enormous textual resources using NLP in Data Science, allowing data-driven decision-making and competitive advantage in 2023.&lt;/p&gt;\n\n&lt;p&gt;Improved natural language processing promotes innovation. A shift in how organisations extract knowledge from the textual domain in Data Science will result from the continuous development of NLP approaches and algorithms.&lt;/p&gt;\n\n&lt;h3&gt;Federated Learning&lt;/h3&gt;\n\n&lt;p&gt;Federated Learning stands out in the landscape of &lt;strong&gt;Data Science Trends&lt;/strong&gt; as a disruptive strategy tackling data privacy and security issues in &lt;strong&gt;Data Science in 2023&lt;/strong&gt;. Federated learning enables models to be trained locally on distant data sources. It is becoming more popular as businesses seek ways to collaborate and get insights without jeopardising sensitive data. &lt;/p&gt;\n\n&lt;p&gt;Federated learning under this decentralised paradigm assures privacy compliance while utilising the combined wisdom of several datasets to produce improved models and more precise predictions. Federated learning will revolutionise &lt;strong&gt;data science in 2023&lt;/strong&gt; thanks to its capacity to protect data privacy and promote collaborative research.&lt;/p&gt;\n\n&lt;p&gt;Organisations can use dispersed data&amp;#39;s potential without the requirement for centralised data transmission or storage, promoting innovation and advancing the industry. Federated learning offers a privacy-preserving method for releasing the full potential of dispersed data resources in 2023 and beyond, and it is a critical enabler in the changing landscape of &lt;strong&gt;data science trends&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h2&gt;Importance of Data Science in 2023&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;Data science trends&lt;/strong&gt; are crucial for businesses using data-driven decision-making to achieve a competitive advantage. Utilising the main &lt;strong&gt;Data Science Trends&lt;/strong&gt; of AI, ML, AR, NLP, and federated learning will be essential for gaining insightful information, streamlining procedures, and fostering creativity across sectors. You can hone your skills and knowledge by taking &lt;a href=\"https://course.learnbay.co/\"&gt;online certification courses&lt;/a&gt;. Data scientists, who will be at the forefront of &lt;strong&gt;data science in 2023&lt;/strong&gt;, will be essential in converting raw data into information organisations can use to stay adaptable and make wise strategic decisions.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Competitive Edge&lt;/strong&gt;: By utilising the potential of AI, ML, AR, NLP, and federated learning, &lt;strong&gt;Data Science Trends&lt;/strong&gt; give businesses a competitive edge. Businesses may extract priceless insights, spot patterns, and make data-driven choices that provide them with a major competitive edge in 2023 by adopting these cutting-edge technologies in data science.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Actionable Insights&lt;/strong&gt;: Data scientists, who will play a major role in &lt;strong&gt;data science in 2023&lt;/strong&gt;, are skilled at sifting through large databases for significant patterns, trends, and correlations. They give businesses useful insights through data analysis and interpretation that help them make strategic decisions, streamline procedures, and expand their operations. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Agility and Adaptability&lt;/strong&gt;: Organisations need to be flexible and adaptive in the &lt;strong&gt;Data Science Trends&lt;/strong&gt; landscape 2023, given its fast evolution. Thanks to data science, businesses can analyse real-time data, spot new patterns, and react quickly to shifting market conditions. Organisations can make data-driven choices because of their agility, which keeps them one step ahead of the competition and in line with their strategic objectives.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enhanced Customer Experience&lt;/strong&gt;: Organisations may thoroughly grasp client preferences, behaviour, and demands thanks to &lt;strong&gt;data science trends&lt;/strong&gt;. Businesses may personalise experiences, conduct targeted marketing efforts, and increase overall customer happiness by using consumer data with AI, ML, NLP, and AR. This improved customer experience encourages retention, growth, and customer loyalty. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Innovation and Optimization&lt;/strong&gt;: By revealing hidden patterns and insights that result in ground-breaking solutions, 2023&amp;#39;s &lt;strong&gt;data science trends&lt;/strong&gt; will help to drive innovation. Organisations may stimulate innovation, maximise profitability, and maintain their competitive edge in a data-driven world by optimising processes, enhancing efficiency, and spotting possibilities for cost reductions. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As businesses strive to use the potential of AI, ML, AR, NLP, and federated learning for competitive advantage, actionable insights, agility, improved customer experiences, and innovation, data science is of utmost significance. Businesses that want to succeed in the data-driven world in 2023 must embrace data science not merely out of necessity but also out of strategic necessity. &lt;/p&gt;\n\n&lt;h2&gt;How Can You Make A Career in Data Science in 2023?&lt;/h2&gt;\n\n&lt;p&gt;There are various crucial things to consider in 2023 for people who want to work in the data science area. First and foremost, it&amp;#39;s crucial to build a solid foundation in arithmetic, statistics, and programming languages like Python and R. Your knowledge and abilities can also be improved by enrolling in appropriate educational programmes, online courses, and certifications. Learnbay\u2019s &lt;a href=\"https://course.learnbay.co/data-science-certification-courses?utm_source=google&amp;amp;utm_medium=ds_%5Bag_1%5D_lb&amp;amp;utm_campaign=search_ads_learnbay.co&amp;amp;utm_id=16975880767&amp;amp;utm_term=data_science&amp;amp;utm_term=learnbay%20data%20science%20course&amp;amp;utm_campaign=Search+Ads+Learnbay.co&amp;amp;utm_source=adwords&amp;amp;utm_medium=ppc&amp;amp;hsa_acc=6881325803&amp;amp;hsa_cam=16975880767&amp;amp;hsa_grp=136176468216&amp;amp;hsa_ad=636562695815&amp;amp;hsa_src=g&amp;amp;hsa_tgt=kwd-920798089135&amp;amp;hsa_kw=learnbay%20data%20science%20course&amp;amp;hsa_mt=p&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gclid=Cj0KCQjw4NujBhC5ARIsAF4Iv6cEddG8Zj1ARtSL3kSHWovEqQG0Rx7hPYOnPOJLV2SYww8VFHEhqNgaAtgpEALw_wcB\"&gt;&lt;strong&gt;data science course&lt;/strong&gt;&lt;/a&gt; will help you stand out among the rest. It focuses on domain specialisation. &lt;/p&gt;\n\n&lt;p&gt;Participation in data science contests and practical experience with real-world data projects may improve your portfolio. Finally, ensuring your abilities are current and in demand requires continuously studying new trends, technologies, and procedures. &lt;/p&gt;\n\n&lt;h2&gt;The Bottom Line&lt;/h2&gt;\n\n&lt;p&gt;The data science environment is being formed as we set off on the trip of 2023 with important developments, including AI, ML, AR, NLP, and federated learning. These developments are pushing the limits of what is feasible in data analysis and decision-making, fueling ground-breaking innovations. For businesses and data, professionals who want to fully utilise data science in the years to come, embracing and comprehending these trends is essential. &lt;/p&gt;\n\n&lt;p&gt;Businesses may gain a competitive edge, stimulate innovation, and make wise decisions based on data-driven insights by keeping up with the newest advancements and adopting these disruptive technologies into their plans. The capacity to adapt and take advantage of these trends will be a crucial difference in this quickly expanding area. It will help practitioners succeed and realise the full potential of data science in the dynamic and data-centric era of 2023 and beyond.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y5g9h", "is_robot_indexable": true, "report_reasons": null, "author": "mallikmallu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y5g9h/top_data_science_trends_for_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y5g9h/top_data_science_trends_for_2023/", "subreddit_subscribers": 915713, "created_utc": 1685689029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey experienced folks of this sub. I\u2019m a senior DS who will be starting to apply to open positions and I\u2019m looking for resources that can help provide a refresher from basics to advanced DS concepts. Something similar to a crash course but for the technically inclined that isn\u2019t too detailed. \n\nA course/study guide that sort of covers basic stats, ML algorithms, deploying, monitoring. I know this won\u2019t be a single course. So I\u2019m looking for your help to collect resources and that can potentially be shared with interested folks.", "author_fullname": "t2_fj708osq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for a quick refresher", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y59kh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685688325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey experienced folks of this sub. I\u2019m a senior DS who will be starting to apply to open positions and I\u2019m looking for resources that can help provide a refresher from basics to advanced DS concepts. Something similar to a crash course but for the technically inclined that isn\u2019t too detailed. &lt;/p&gt;\n\n&lt;p&gt;A course/study guide that sort of covers basic stats, ML algorithms, deploying, monitoring. I know this won\u2019t be a single course. So I\u2019m looking for your help to collect resources and that can potentially be shared with interested folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y59kh", "is_robot_indexable": true, "report_reasons": null, "author": "nottoohotwheels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y59kh/resources_for_a_quick_refresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y59kh/resources_for_a_quick_refresher/", "subreddit_subscribers": 915713, "created_utc": 1685688325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a 2nd year student Bsc Data Science and Business Intelligence , recently our faculty told us to get some online courses done through sites like Coursera and Udemy to make our profile stronger but I am really confused what course should I get done as there are many . So can someone recommend me some courses that would help me learn and also for my profile", "author_fullname": "t2_flfng4ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am pursuing Bachelors in Data Science , Need help with online courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y2f5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685678406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a 2nd year student Bsc Data Science and Business Intelligence , recently our faculty told us to get some online courses done through sites like Coursera and Udemy to make our profile stronger but I am really confused what course should I get done as there are many . So can someone recommend me some courses that would help me learn and also for my profile&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y2f5v", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky-Top3782", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y2f5v/i_am_pursuing_bachelors_in_data_science_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y2f5v/i_am_pursuing_bachelors_in_data_science_need_help/", "subreddit_subscribers": 915713, "created_utc": 1685678406.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m an incoming MS student in statistics, and my university\u2019s winter break is over a month long. I was wondering if there is such a thing as \u201cwinternships\u201d or winter interns for this month between semesters? Is this a possibility? Would you guys hire an intern for a month?", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Winternships?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y2bgq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685678063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an incoming MS student in statistics, and my university\u2019s winter break is over a month long. I was wondering if there is such a thing as \u201cwinternships\u201d or winter interns for this month between semesters? Is this a possibility? Would you guys hire an intern for a month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "13y2bgq", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/13y2bgq/winternships/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/13y2bgq/winternships/", "subreddit_subscribers": 915713, "created_utc": 1685678063.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}