{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. \n\nI want to ensure I have a long career.", "author_fullname": "t2_5bpuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some books that had an impact on your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5aks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685688434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. &lt;/p&gt;\n\n&lt;p&gt;I want to ensure I have a long career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13y5aks", "is_robot_indexable": true, "report_reasons": null, "author": "cheanerman", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "subreddit_subscribers": 108605, "created_utc": 1685688434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to build out a data model for a pet project that I want to be able to run on my laptop (8GB RAM). The data is shaped in such a way that I can have one 4-byte INT key link just about everything together that I need to. It's not necessarily a star schema, but for the purposes of the question you can think of it that way without much loss of generality. The central table is around \\~15M rows and the other tables are in that order of magnitude as well.\n\nI really like DuckDB and it was a logical choice for the project, but at the moment it doesn't have a good way of leveraging predictability when performing full-table joins (it also uses a lot of memory on joins when you're grabbing a wide set of columns from the tables, which is a problem for my case). Ideally I'd have something like Redshift's distkeys and sortkeys, where the data from the different tables would already be collocated by the join key. A standard PK/FK constraint would also work if declaring them actually sped up full-table joins.\n\nAny suggestions? Clickhouse seems like it might be a good fit, but I'm not sure how well it would handle the low-memory part specifically.", "author_fullname": "t2_3rnvqshi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good open-source analytics DB for fast, low-memory joins on predictable keys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xxcmq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685663922.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685663531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to build out a data model for a pet project that I want to be able to run on my laptop (8GB RAM). The data is shaped in such a way that I can have one 4-byte INT key link just about everything together that I need to. It&amp;#39;s not necessarily a star schema, but for the purposes of the question you can think of it that way without much loss of generality. The central table is around ~15M rows and the other tables are in that order of magnitude as well.&lt;/p&gt;\n\n&lt;p&gt;I really like DuckDB and it was a logical choice for the project, but at the moment it doesn&amp;#39;t have a good way of leveraging predictability when performing full-table joins (it also uses a lot of memory on joins when you&amp;#39;re grabbing a wide set of columns from the tables, which is a problem for my case). Ideally I&amp;#39;d have something like Redshift&amp;#39;s distkeys and sortkeys, where the data from the different tables would already be collocated by the join key. A standard PK/FK constraint would also work if declaring them actually sped up full-table joins.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions? Clickhouse seems like it might be a good fit, but I&amp;#39;m not sure how well it would handle the low-memory part specifically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13xxcmq", "is_robot_indexable": true, "report_reasons": null, "author": "PaginatedSalmon", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xxcmq/good_opensource_analytics_db_for_fast_lowmemory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xxcmq/good_opensource_analytics_db_for_fast_lowmemory/", "subreddit_subscribers": 108605, "created_utc": 1685663531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data vault learning resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8vg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8vg5", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "subreddit_subscribers": 108605, "created_utc": 1685701550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have a system where a lot of data arrives in a pleasant, standard format (let's say there are \\~100 standard forms) but a lot of data arrives in Excel or text files with some descriptive header, many rows of CSV content, some more descriptive cruft, another set of CSV content, etc.\n\n\"Get the users to fix the data\" isn't a viable response given our pricing model.\n\nI'm starting to write some tools to allow users to provide processing instructions, such as \n\n* split an Excel doc into multiple sheets\n* split the file at some user provided content (e.g. \"Report #2 xyz\")\n* skip n header rows (easy) and n footer rows (less easy)\n* date format\n* the usual delimiter, character quoting stuff\n\nAll of this is achievable with some code, but this isn't a new or unique problem so there must be some options already available out there. Right?", "author_fullname": "t2_rmmatfaw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tooling for messy ingestions (e.g. excel, non-tabular text files, etc)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13xzejs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685669224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a system where a lot of data arrives in a pleasant, standard format (let&amp;#39;s say there are ~100 standard forms) but a lot of data arrives in Excel or text files with some descriptive header, many rows of CSV content, some more descriptive cruft, another set of CSV content, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Get the users to fix the data&amp;quot; isn&amp;#39;t a viable response given our pricing model.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m starting to write some tools to allow users to provide processing instructions, such as &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;split an Excel doc into multiple sheets&lt;/li&gt;\n&lt;li&gt;split the file at some user provided content (e.g. &amp;quot;Report #2 xyz&amp;quot;)&lt;/li&gt;\n&lt;li&gt;skip n header rows (easy) and n footer rows (less easy)&lt;/li&gt;\n&lt;li&gt;date format&lt;/li&gt;\n&lt;li&gt;the usual delimiter, character quoting stuff&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All of this is achievable with some code, but this isn&amp;#39;t a new or unique problem so there must be some options already available out there. Right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13xzejs", "is_robot_indexable": true, "report_reasons": null, "author": "realitydevice", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xzejs/tooling_for_messy_ingestions_eg_excel_nontabular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13xzejs/tooling_for_messy_ingestions_eg_excel_nontabular/", "subreddit_subscribers": 108605, "created_utc": 1685669224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all! Just wanted to say I\u2019m not a coder nor programmer, recently started a sales role in a SasS company (Sales are the worst I know, oh well).\n\nWe have a lot of inbound leads, however, cold outreach is just about as it sounds - COLD. So I\u2019m really trying to understand if I\u2019m not finding the right audience, or if a data modeling tool (conceptual/physical/logical modeling) is useless to most of you?", "author_fullname": "t2_3rwynq3m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y0e1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685672094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! Just wanted to say I\u2019m not a coder nor programmer, recently started a sales role in a SasS company (Sales are the worst I know, oh well).&lt;/p&gt;\n\n&lt;p&gt;We have a lot of inbound leads, however, cold outreach is just about as it sounds - COLD. So I\u2019m really trying to understand if I\u2019m not finding the right audience, or if a data modeling tool (conceptual/physical/logical modeling) is useless to most of you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y0e1o", "is_robot_indexable": true, "report_reasons": null, "author": "S0urScream", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y0e1o/data_modeling_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y0e1o/data_modeling_tool/", "subreddit_subscribers": 108605, "created_utc": 1685672094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to update records on Delta live tables with the incoming stream? \n\nBusiness case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. \n\nI have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.", "author_fullname": "t2_feq227wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Upsert on Delta Live Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5nvm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685689773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to update records on Delta live tables with the incoming stream? &lt;/p&gt;\n\n&lt;p&gt;Business case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. &lt;/p&gt;\n\n&lt;p&gt;I have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y5nvm", "is_robot_indexable": true, "report_reasons": null, "author": "qki_machine", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "subreddit_subscribers": 108605, "created_utc": 1685689773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm struggling to find a service that at least gives me more that 80 cities in the UK. \n\nWhat I'm looking for is this type of data:\n\n&amp;#x200B;\n\n|country|region|district/city|longitude|latitude|\n|:-|:-|:-|:-|:-|\n|England|North West|Liverpool|\\-29.09|34.00|\n\nLong and Lat are wrong, just place holder data.   \n\n\nSeems a lot of places I've been looking only have like 300 locations or even 80.   \n\n\nAnyone found a good free API for this at all?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone got any information on how to retrieve all longitude and latitude data for each city in the UK (including Scotland, Wales, Northern Ireland)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8g9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685700107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to find a service that at least gives me more that 80 cities in the UK. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is this type of data:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;country&lt;/th&gt;\n&lt;th align=\"left\"&gt;region&lt;/th&gt;\n&lt;th align=\"left\"&gt;district/city&lt;/th&gt;\n&lt;th align=\"left\"&gt;longitude&lt;/th&gt;\n&lt;th align=\"left\"&gt;latitude&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;England&lt;/td&gt;\n&lt;td align=\"left\"&gt;North West&lt;/td&gt;\n&lt;td align=\"left\"&gt;Liverpool&lt;/td&gt;\n&lt;td align=\"left\"&gt;-29.09&lt;/td&gt;\n&lt;td align=\"left\"&gt;34.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Long and Lat are wrong, just place holder data.   &lt;/p&gt;\n\n&lt;p&gt;Seems a lot of places I&amp;#39;ve been looking only have like 300 locations or even 80.   &lt;/p&gt;\n\n&lt;p&gt;Anyone found a good free API for this at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8g9g", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "subreddit_subscribers": 108605, "created_utc": 1685700107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, DE here with around 1 YoE. Been chilling on my current job rn and I've been looking to upskill/learn in the meantime. Current exp is with GCP (BigQuery), Airflow, Python, Docker, and some fullstack (Vue/Flask).\n\nI'm from a non-CS degree so I've been thinking of either learning more CS fundamentals or just focusing on DE tools in general. Problem is that I am also a bit overwhelmed at the choices and tools/languages I can learn (Somewhat inspired by [this post](https://www.reddit.com/r/dataengineering/comments/12x895j/getting_overwhelmed_by_wide_and_everchanging_tech/)). Would appreciate any insight on the different options i'm looking into, thanks!  \n\n\n1. Implement DE projects/Learn new tools to further build github portfolio  \n\\- Trying DE Zoomcamp  \n\\- Read documentation on new tools (Scala/Prefect/MS Azure/Kafka/K8s/MLFlow) and work on implementing a project covering some of the tools.  \n\\- Contribute to open source projects/tools\n2. Strengthen CS fundamentals  \n\\- Watch lectures ([CMU lectures](https://www.youtube.com/watch?v=LWS8LEQAUVc&amp;list=PLSE8ODhjZXjYzlLMbX3cR0sxWnRM7CLFn) seem like an interesting start)  \n\\- Leetcode  \n\\- Advent of Code  \n\\- Read books (DDIA, DE fundamentals, Data Quality fundamentals, etc.)", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unsure which way to move forward", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y3l4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685682323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, DE here with around 1 YoE. Been chilling on my current job rn and I&amp;#39;ve been looking to upskill/learn in the meantime. Current exp is with GCP (BigQuery), Airflow, Python, Docker, and some fullstack (Vue/Flask).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from a non-CS degree so I&amp;#39;ve been thinking of either learning more CS fundamentals or just focusing on DE tools in general. Problem is that I am also a bit overwhelmed at the choices and tools/languages I can learn (Somewhat inspired by &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/12x895j/getting_overwhelmed_by_wide_and_everchanging_tech/\"&gt;this post&lt;/a&gt;). Would appreciate any insight on the different options i&amp;#39;m looking into, thanks!  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Implement DE projects/Learn new tools to further build github portfolio&lt;br/&gt;\n- Trying DE Zoomcamp&lt;br/&gt;\n- Read documentation on new tools (Scala/Prefect/MS Azure/Kafka/K8s/MLFlow) and work on implementing a project covering some of the tools.&lt;br/&gt;\n- Contribute to open source projects/tools&lt;/li&gt;\n&lt;li&gt;Strengthen CS fundamentals&lt;br/&gt;\n- Watch lectures (&lt;a href=\"https://www.youtube.com/watch?v=LWS8LEQAUVc&amp;amp;list=PLSE8ODhjZXjYzlLMbX3cR0sxWnRM7CLFn\"&gt;CMU lectures&lt;/a&gt; seem like an interesting start)&lt;br/&gt;\n- Leetcode&lt;br/&gt;\n- Advent of Code&lt;br/&gt;\n- Read books (DDIA, DE fundamentals, Data Quality fundamentals, etc.)&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?auto=webp&amp;v=enabled&amp;s=8d8b8c47fd8dfcdb4e02dacb36d29a388df017fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e9d66b26f4882c4244a7f41710779a43b6cb525", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38a8bcd47e423b5db9f81a5814edacf641e49ce5", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Z2jqAmXQLa05RR0HUf49fYzqieuG8CsKsAS_KeUB0uQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efbefd9ab914cbb0cf7af94095436120ca48cd51", "width": 320, "height": 240}], "variants": {}, "id": "VAulGrQIgrZNrLvYNArFduNfHDflJBIDC4XEkzG8oCE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13y3l4q", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y3l4q/unsure_which_way_to_move_forward/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y3l4q/unsure_which_way_to_move_forward/", "subreddit_subscribers": 108605, "created_utc": 1685682323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What work did you do as interns/junior-level DEs and how did it change as you progressed?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question for all data engineers:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yelms", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685716828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What work did you do as interns/junior-level DEs and how did it change as you progressed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13yelms", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "subreddit_subscribers": 108605, "created_utc": 1685716828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Embedding Pipelines For Generative AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_13xzpt2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/H7VGUc9R5gFecU5Ez20Voch7M-JUlDQ0FW_iAoTLGzI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685670118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytewax.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bytewax.io/blog/embedding-pipelines-for-generative-ai", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?auto=webp&amp;v=enabled&amp;s=508e36832dcdeb2bc9f42531a3224e7c5f9e6cfc", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2221d29d33827fb9c45a1bd9a811e44475b47a7", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=442f4ea278032bdda0e13616933e73c99662a6fd", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa994bb2165b79bc75a9a548cd1f0d1425ee6e87", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c21bb53529abd65816f0b2935254605f4fa330e2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d47c4f7c1122199e5f3b9214633846d5d289578b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/L5YMBKz240JSZtVKLof0hBtrdtcN9SZdn6JrDNu6LdE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a2ed7d5bf7eba7af3c8eb8ac8fa0c65c8d7be082", "width": 1080, "height": 607}], "variants": {}, "id": "aZU66TyrS3pTtx2nstLcKFQ6BhqRUJp3xVigMlCxRJg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13xzpt2", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13xzpt2/embedding_pipelines_for_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bytewax.io/blog/embedding-pipelines-for-generative-ai", "subreddit_subscribers": 108605, "created_utc": 1685670118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am looking for a sample database with interesting business data to analyze.\n\nIt shouldn't be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).\n\nIt can be a sample of accounting entries, or an insurance company database, any industry, actually.\n\nI will use this DB for demo dashboards and teaching analytics and data engineering.  \nThanks", "author_fullname": "t2_924si4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sample dataset/database with business data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y93cq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685702285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a sample database with interesting business data to analyze.&lt;/p&gt;\n\n&lt;p&gt;It shouldn&amp;#39;t be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).&lt;/p&gt;\n\n&lt;p&gt;It can be a sample of accounting entries, or an insurance company database, any industry, actually.&lt;/p&gt;\n\n&lt;p&gt;I will use this DB for demo dashboards and teaching analytics and data engineering.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y93cq", "is_robot_indexable": true, "report_reasons": null, "author": "mshparber", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "subreddit_subscribers": 108605, "created_utc": 1685702285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:\n\n- modularity\n- Logging/Error Handling\n- Tests/Data Validation Tests\n- Few dependencies in addition to pandas/polars\n- no prefect/airflow/dagster\n- bonus is simplistic data flow tracking\n\nExemplary use case: e.g. simple etl pipeline running on databricks\n\nInterested in seeing various approaches to the most basic form of etl pipeline in python.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimal Python ETL-pipeline-template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8pu2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;modularity&lt;/li&gt;\n&lt;li&gt;Logging/Error Handling&lt;/li&gt;\n&lt;li&gt;Tests/Data Validation Tests&lt;/li&gt;\n&lt;li&gt;Few dependencies in addition to pandas/polars&lt;/li&gt;\n&lt;li&gt;no prefect/airflow/dagster&lt;/li&gt;\n&lt;li&gt;bonus is simplistic data flow tracking&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Exemplary use case: e.g. simple etl pipeline running on databricks&lt;/p&gt;\n\n&lt;p&gt;Interested in seeing various approaches to the most basic form of etl pipeline in python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8pu2", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "subreddit_subscribers": 108605, "created_utc": 1685701014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's is the community's take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?\n\nI should add I don't like story points for DE work so if you don't use them, what is your approach?", "author_fullname": "t2_puuzgu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Story point norms in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13yr4ph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685744842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685743759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s is the community&amp;#39;s take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?&lt;/p&gt;\n\n&lt;p&gt;I should add I don&amp;#39;t like story points for DE work so if you don&amp;#39;t use them, what is your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yr4ph", "is_robot_indexable": true, "report_reasons": null, "author": "getafterit123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "subreddit_subscribers": 108605, "created_utc": 1685743759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I am migrating code to Databricks/pyspark, which requires reading a bunch of Snowflake tables and views. Then a bunch of joins and such. \n\nIt generally works but some statements are not finishing with larger tables. I tried to troubleshoot one like this: \n\nsome\\_query = \"select \\~50 columns from Snowflake view with 1400 columns and 235m rows\"\n\ndf = spark.read.format(\"snowflake\").options(\\*\\*sfOptions).option(\"query\", some\\_query).load()\n\ndf.explain()\n\nAnd it's been going for 50 minutes now. Is it normal?\n\nSomeone suggested I go to Snowflake and look at Query History. That helps, but sometimes I don't even see the query there, so I don't know what's going on. \n\nI went to the cluster and just clicking around, like the Spark UI tab &gt; Executors, and the \"Active tasks\" is  0. So is it doing anything?? Driver logs don't show errors. \n\nWould love some tips on how to confirm what a query is doing. Thanks.", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking tips to troubleshoot Databricks queries of large Snowflake tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ymkox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685734584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I am migrating code to Databricks/pyspark, which requires reading a bunch of Snowflake tables and views. Then a bunch of joins and such. &lt;/p&gt;\n\n&lt;p&gt;It generally works but some statements are not finishing with larger tables. I tried to troubleshoot one like this: &lt;/p&gt;\n\n&lt;p&gt;some_query = &amp;quot;select ~50 columns from Snowflake view with 1400 columns and 235m rows&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;df = spark.read.format(&amp;quot;snowflake&amp;quot;).options(**sfOptions).option(&amp;quot;query&amp;quot;, some_query).load()&lt;/p&gt;\n\n&lt;p&gt;df.explain()&lt;/p&gt;\n\n&lt;p&gt;And it&amp;#39;s been going for 50 minutes now. Is it normal?&lt;/p&gt;\n\n&lt;p&gt;Someone suggested I go to Snowflake and look at Query History. That helps, but sometimes I don&amp;#39;t even see the query there, so I don&amp;#39;t know what&amp;#39;s going on. &lt;/p&gt;\n\n&lt;p&gt;I went to the cluster and just clicking around, like the Spark UI tab &amp;gt; Executors, and the &amp;quot;Active tasks&amp;quot; is  0. So is it doing anything?? Driver logs don&amp;#39;t show errors. &lt;/p&gt;\n\n&lt;p&gt;Would love some tips on how to confirm what a query is doing. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ymkox", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ymkox/seeking_tips_to_troubleshoot_databricks_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ymkox/seeking_tips_to_troubleshoot_databricks_queries/", "subreddit_subscribers": 108605, "created_utc": 1685734584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. I currently work in research in the field of crypto/web 3. (Glorified way to say that I write on crypto topics for my employer.)\n\nI'm considering learning Dune (formerly called Dune Analytics) since it helps extract onchain data better and is a valuable skill that pays well. \n\nIs there anyone here who has dabbled with Dune and is sufficiently proficient in it?  Or were you able to land projects/jobs because you know your way around it? Would love to get in touch with you for some help and guidance.", "author_fullname": "t2_qj1xoq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Dune wizards here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ylfgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685732240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I currently work in research in the field of crypto/web 3. (Glorified way to say that I write on crypto topics for my employer.)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering learning Dune (formerly called Dune Analytics) since it helps extract onchain data better and is a valuable skill that pays well. &lt;/p&gt;\n\n&lt;p&gt;Is there anyone here who has dabbled with Dune and is sufficiently proficient in it?  Or were you able to land projects/jobs because you know your way around it? Would love to get in touch with you for some help and guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ylfgz", "is_robot_indexable": true, "report_reasons": null, "author": "heeguunte", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ylfgz/any_dune_wizards_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ylfgz/any_dune_wizards_here/", "subreddit_subscribers": 108605, "created_utc": 1685732240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Redditors!\n\nI thought this community might find it very useful that Databricks has partnered with [Cleanlab](https://cleanlab.ai/) to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.\n\nA big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.\n\nTo highlight what's possible with this new integration, their recent [blog](https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio) shows how LLMs (Large Language Models) trained on Databricks data can be **boosted in test accuracy (by over 30%) using Cleanlab Studio** to train ML models on an improved text dataset. \n\nYou only need a couple of lines of code too:\n\n    cleanlab_studio.upload_dataset(dataset)\n    dataset_fixed = cleanlab_studio.apply_corrections(id, dataset)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks users can now automatically correct data and improve ML models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yhf6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685723424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors!&lt;/p&gt;\n\n&lt;p&gt;I thought this community might find it very useful that Databricks has partnered with &lt;a href=\"https://cleanlab.ai/\"&gt;Cleanlab&lt;/a&gt; to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.&lt;/p&gt;\n\n&lt;p&gt;A big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.&lt;/p&gt;\n\n&lt;p&gt;To highlight what&amp;#39;s possible with this new integration, their recent &lt;a href=\"https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio\"&gt;blog&lt;/a&gt; shows how LLMs (Large Language Models) trained on Databricks data can be &lt;strong&gt;boosted in test accuracy (by over 30%) using Cleanlab Studio&lt;/strong&gt; to train ML models on an improved text dataset. &lt;/p&gt;\n\n&lt;p&gt;You only need a couple of lines of code too:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;cleanlab_studio.upload_dataset(dataset)\ndataset_fixed = cleanlab_studio.apply_corrections(id, dataset)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?auto=webp&amp;v=enabled&amp;s=4fa344feec1203c5a3c8037ff4dc262b8199993c", "width": 1272, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=497bb037271a9f730fba0c9762fccfd03bc83854", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e9a92773876a44dff24033bb28bfcac23cc6be9", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d8289065076165108742e1f06e1eba13b2ba27e", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=860eca71c83a330feea1f4e293c3767498138aec", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29a33bb3ca9ee068da332d2221827e16765a2a4a", "width": 960, "height": 517}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bd1c44daed0be645a75f28344e835d728418327", "width": 1080, "height": 582}], "variants": {}, "id": "ZToDd-YI1Es8iCGrsYQ-wSRxT7XW4KUdV7ki6pqFGdE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13yhf6e", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "subreddit_subscribers": 108605, "created_utc": 1685723424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance", "author_fullname": "t2_7r5xenrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering conference in Canada (anywhere)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygpe4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685721746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ygpe4", "is_robot_indexable": true, "report_reasons": null, "author": "Heavy_End_2971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "subreddit_subscribers": 108605, "created_utc": 1685721746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of NoSQL Databases: Deep Dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygmj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tbjolvjcd4pFGYwrUy21pTO8xhj6HfhJnXoILsY07vY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685721582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?auto=webp&amp;v=enabled&amp;s=30a10ec625bb545da69ce94ff3eaecf423192ffb", "width": 2400, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cb781c8024b80019cbb4d8671b9ac82ce55239a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3019c8983a64031de7cc3d528cc1a4082b979ce3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c14465cc9cf34e73a9dfcd9cee8f25a2024ac4f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=855bc3dfe0b174024f1952f236e466bf3704d9aa", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e348a1a0827d26c78592ce17c4f91f62d1984ae2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21faf68b901e2ba8bc3816beedccedea6c06e79f", "width": 1080, "height": 540}], "variants": {}, "id": "M2IsBpOmOWUv3ZenklBzRFx5hxz60Ew2I2gjTGE5GCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13ygmj4", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygmj4/types_of_nosql_databases_deep_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "subreddit_subscribers": 108605, "created_utc": 1685721582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the \"frameworkisation\" of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.\n\nWhat would have been your primary choice of framework for this kind of project in Python?", "author_fullname": "t2_flv2knd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream processing framework for a new project in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yftqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685719716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the &amp;quot;frameworkisation&amp;quot; of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.&lt;/p&gt;\n\n&lt;p&gt;What would have been your primary choice of framework for this kind of project in Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yftqn", "is_robot_indexable": true, "report_reasons": null, "author": "Hashrann", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "subreddit_subscribers": 108605, "created_utc": 1685719716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.\n\nAs they're migrating to the cloud I'm wondering how to best represent those one to many relationships in OBT ?\nObviously I'm thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?", "author_fullname": "t2_4v8mesko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you create one to many relationships in OBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yc68h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685710964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.&lt;/p&gt;\n\n&lt;p&gt;As they&amp;#39;re migrating to the cloud I&amp;#39;m wondering how to best represent those one to many relationships in OBT ?\nObviously I&amp;#39;m thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yc68h", "is_robot_indexable": true, "report_reasons": null, "author": "_thetrue_SpaceTofu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "subreddit_subscribers": 108605, "created_utc": 1685710964.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}