{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What data catalog is your company currently using? What do you like about it and hate about it? What tool would you replace your current data catalog with if you could make the decision? \n\n\nStart from me:\n\nETL - Informatica power center\n\nData Catalog - Excel Spreadsheet (I know..)", "author_fullname": "t2_cjk2xje6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your favorite data catalog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hhvtr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687576433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What data catalog is your company currently using? What do you like about it and hate about it? What tool would you replace your current data catalog with if you could make the decision? &lt;/p&gt;\n\n&lt;p&gt;Start from me:&lt;/p&gt;\n\n&lt;p&gt;ETL - Informatica power center&lt;/p&gt;\n\n&lt;p&gt;Data Catalog - Excel Spreadsheet (I know..)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hhvtr", "is_robot_indexable": true, "report_reasons": null, "author": "highlifeed", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hhvtr/what_is_your_favorite_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hhvtr/what_is_your_favorite_data_catalog/", "subreddit_subscribers": 112026, "created_utc": 1687576433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Disclaimer:** My background is in Statistics and ML -- so I admittedly have little experience in creating/architecting pipelines.\n\nI am working on a personal project that scrapes auction results and my goal is to create a live pricing model. Up to this point the work has been \"ad-hoc\" and collection is manually triggered. However, I feel pretty satisfied with the initial scraped outputs (\\~4K auctions) and I want to begin the steps towards standardizing the scraping workflow with an automated and scheduled pipeline. My very open ended question is -- **what are the best routes for scaling up this type of workflow?**\n\nHere are some additional details:\n\n1. Only a select few pages from the entire website are scraped. These pages are independent from one another and as a result, I imagine that scaling horizontally with multiple VMs or Containers doing one page/scrape-job would be efficient.\n2. All past and historical auctions are viewable. This means that *initial* scraping is a bit expensive -- it involves crawling *all* historical auctions and scraping the results from each one. However after this first initial scrape -- ideally any subsequent scrapes would only crawl the most recently closed auctions and **update and add** to the previous scrape (at most I expect 3-5 auction results added).\n3. The scraped data are dumped into individual CSV files at the moment (a file for each page/product that is scraped). I am not certain but I foresee this may be an unsuitable format if I'd like to be able to update the data. In that case -- would I likely need to set up a DB? I guess the problem I am foreseeing is how can the scraper \"know\" which auctions are \"new\" versus which have already been scraped.\n\n**Potential Idea:**\n\n1. Use GitHub Actions to automate scraping on a cron schedule. However does this scale \"horizontally\" if I'd like to have several scrapers running different jobs in parallel?\n\nTIA for any inputs! I am also curious what platforms and tools people think would be most appropriate for this type of project as well (AWS, GCP, Azure)", "author_fullname": "t2_tzg6wdez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Scale and Automate Webscraping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hdpg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687570779.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687564323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; My background is in Statistics and ML -- so I admittedly have little experience in creating/architecting pipelines.&lt;/p&gt;\n\n&lt;p&gt;I am working on a personal project that scrapes auction results and my goal is to create a live pricing model. Up to this point the work has been &amp;quot;ad-hoc&amp;quot; and collection is manually triggered. However, I feel pretty satisfied with the initial scraped outputs (~4K auctions) and I want to begin the steps towards standardizing the scraping workflow with an automated and scheduled pipeline. My very open ended question is -- &lt;strong&gt;what are the best routes for scaling up this type of workflow?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Here are some additional details:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Only a select few pages from the entire website are scraped. These pages are independent from one another and as a result, I imagine that scaling horizontally with multiple VMs or Containers doing one page/scrape-job would be efficient.&lt;/li&gt;\n&lt;li&gt;All past and historical auctions are viewable. This means that &lt;em&gt;initial&lt;/em&gt; scraping is a bit expensive -- it involves crawling &lt;em&gt;all&lt;/em&gt; historical auctions and scraping the results from each one. However after this first initial scrape -- ideally any subsequent scrapes would only crawl the most recently closed auctions and &lt;strong&gt;update and add&lt;/strong&gt; to the previous scrape (at most I expect 3-5 auction results added).&lt;/li&gt;\n&lt;li&gt;The scraped data are dumped into individual CSV files at the moment (a file for each page/product that is scraped). I am not certain but I foresee this may be an unsuitable format if I&amp;#39;d like to be able to update the data. In that case -- would I likely need to set up a DB? I guess the problem I am foreseeing is how can the scraper &amp;quot;know&amp;quot; which auctions are &amp;quot;new&amp;quot; versus which have already been scraped.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Potential Idea:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use GitHub Actions to automate scraping on a cron schedule. However does this scale &amp;quot;horizontally&amp;quot; if I&amp;#39;d like to have several scrapers running different jobs in parallel?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;TIA for any inputs! I am also curious what platforms and tools people think would be most appropriate for this type of project as well (AWS, GCP, Azure)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hdpg4", "is_robot_indexable": true, "report_reasons": null, "author": "divergingLoss", "discussion_type": null, "num_comments": 13, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hdpg4/how_to_scale_and_automate_webscraping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hdpg4/how_to_scale_and_automate_webscraping/", "subreddit_subscribers": 112026, "created_utc": 1687564323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, so I've been self studying and lately, got a 3 month subscription on datacamp and I decided to take the opportunity to get a deeper look into data engineering. They seem to have a variety of courses, but I'm not exactly sure which to take and in what order. I know that they have a data engineering track thing, but I don't think it's enough and it seems to be missing many concepts that I've seen from some youtube roadmaps. So, I was hoping that some of you, whether you're a data engineer or someone who tried these courses before, would be able to help me learn in the appropriate order without missing some key concepts. Your help would be really appreciated. \n\nThis is the link to the courses\n\n[https://www.datacamp.com/data-courses/data-engineering-courses](https://www.datacamp.com/data-courses/data-engineering-courses)", "author_fullname": "t2_hvy9bzsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datacamp data engineering courses roadmap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h2sgr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687537265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so I&amp;#39;ve been self studying and lately, got a 3 month subscription on datacamp and I decided to take the opportunity to get a deeper look into data engineering. They seem to have a variety of courses, but I&amp;#39;m not exactly sure which to take and in what order. I know that they have a data engineering track thing, but I don&amp;#39;t think it&amp;#39;s enough and it seems to be missing many concepts that I&amp;#39;ve seen from some youtube roadmaps. So, I was hoping that some of you, whether you&amp;#39;re a data engineer or someone who tried these courses before, would be able to help me learn in the appropriate order without missing some key concepts. Your help would be really appreciated. &lt;/p&gt;\n\n&lt;p&gt;This is the link to the courses&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/data-courses/data-engineering-courses\"&gt;https://www.datacamp.com/data-courses/data-engineering-courses&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?auto=webp&amp;v=enabled&amp;s=7b98d550c0803837fe3d4a013e7e5abb715007f7", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1dbf4ded87a8d9eb65d6bb061303f2d920d52874", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ab1761e5190e30d94122d78ccc62ab846e9fc8f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c3d569d7a6e0f4fc4668e309315f4c167244de2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96f1e8442b3aef432d6d858d01a816c55f3d2de2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a7f3557b0d56d8c6ba51af4c56a5b1ebcae12a4", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/S2wmkVS2noOwqJFkqAOgzW276TRr-Xz0PKLEA3MuIy4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bec3b8ad604fa4b316ba9ff30f524357eaaa72e", "width": 1080, "height": 567}], "variants": {}, "id": "ljwW312xt1z1t0ZiTa9rJsrX-p4IHiPkBQDDxV5w3Wo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14h2sgr", "is_robot_indexable": true, "report_reasons": null, "author": "IamHoussem", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14h2sgr/datacamp_data_engineering_courses_roadmap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14h2sgr/datacamp_data_engineering_courses_roadmap/", "subreddit_subscribers": 112026, "created_utc": 1687537265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, currently I have 1 year of experience as a data engineer in the data warehouse team of 12 people. My work is mostly doing ELT, data modeling and data warehousing stuffs with T-SQL, SSIS and Control-M. Work can be fun sometimes but a bit stale because of the outdated tech stack. ( Edit: I mean the SSIS and control-M part)\n\nI was spreading my resume around to try and get some jobs that will have me working with Spark or newer tech. Recently I got an offer from a bank for an SQL developer type of work, basically doing same ELT and performance tuning work in Oracle, but will also have to do some querying to create Power-BI reports as requested from business. I can feel that this job can be quite boring, but the salary bump is quite huge and the benefit is very good. If anyone have experience with such roles before, can you give me some review on the career climb there?", "author_fullname": "t2_h33ht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is the career perspective for an SQL developer in a bank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hkgkm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687595846.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687584710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, currently I have 1 year of experience as a data engineer in the data warehouse team of 12 people. My work is mostly doing ELT, data modeling and data warehousing stuffs with T-SQL, SSIS and Control-M. Work can be fun sometimes but a bit stale because of the outdated tech stack. ( Edit: I mean the SSIS and control-M part)&lt;/p&gt;\n\n&lt;p&gt;I was spreading my resume around to try and get some jobs that will have me working with Spark or newer tech. Recently I got an offer from a bank for an SQL developer type of work, basically doing same ELT and performance tuning work in Oracle, but will also have to do some querying to create Power-BI reports as requested from business. I can feel that this job can be quite boring, but the salary bump is quite huge and the benefit is very good. If anyone have experience with such roles before, can you give me some review on the career climb there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14hkgkm", "is_robot_indexable": true, "report_reasons": null, "author": "toidaylabach", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hkgkm/how_is_the_career_perspective_for_an_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hkgkm/how_is_the_career_perspective_for_an_sql/", "subreddit_subscribers": 112026, "created_utc": 1687584710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a Data Science company where we had a discussion regarding what should be the best layer for this use case:\n\nWe want to create an analytics dashboard in Power BI. Let's imagine we are digesting data from an on-premise/cloud SQL Server Database. That data will be ingested in batch once a day, and that data may be updated, so we must import past data (not only the new one) since old data may be updated. We are imagining the following layer model:\n\n- Bronze: Raw data in parquet format with a DATE/TABLE folder structure\n- Silver: Delta tables that will be upserted from the bronze data (using the merge statement, so inserting new values and updating old ones that have been modified). These tables are transactional, so are not optimal for being used in Power BI directly.\n- Gold: Star shema model of the transactional tables, optimized for Power BI ingestion.\n\nThe main doubt is:\n- If, in the future, I decide to pre-join tables of the star schema to make digestion on Power BI easier (for example, join tableA and tableB to create tableAB, so Power BI engine don't have to do that job), I saw the Gold Layer as the appropriate layer to store that table, but since the star schema is already there, I don't know if that would be messy and get into a bad practice. \n\nA solution would be to actually store the star schema in the Silver layer, and leave the Gold layer initially empty. When a case as described appear, store the tableAB in that layer.\n\nI don't really know what would be the best practice in this use case scenario.", "author_fullname": "t2_nt1xl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should be the right layer for normalized data in a Data Lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hale0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687556321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a Data Science company where we had a discussion regarding what should be the best layer for this use case:&lt;/p&gt;\n\n&lt;p&gt;We want to create an analytics dashboard in Power BI. Let&amp;#39;s imagine we are digesting data from an on-premise/cloud SQL Server Database. That data will be ingested in batch once a day, and that data may be updated, so we must import past data (not only the new one) since old data may be updated. We are imagining the following layer model:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Bronze: Raw data in parquet format with a DATE/TABLE folder structure&lt;/li&gt;\n&lt;li&gt;Silver: Delta tables that will be upserted from the bronze data (using the merge statement, so inserting new values and updating old ones that have been modified). These tables are transactional, so are not optimal for being used in Power BI directly.&lt;/li&gt;\n&lt;li&gt;Gold: Star shema model of the transactional tables, optimized for Power BI ingestion.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main doubt is:\n- If, in the future, I decide to pre-join tables of the star schema to make digestion on Power BI easier (for example, join tableA and tableB to create tableAB, so Power BI engine don&amp;#39;t have to do that job), I saw the Gold Layer as the appropriate layer to store that table, but since the star schema is already there, I don&amp;#39;t know if that would be messy and get into a bad practice. &lt;/p&gt;\n\n&lt;p&gt;A solution would be to actually store the star schema in the Silver layer, and leave the Gold layer initially empty. When a case as described appear, store the tableAB in that layer.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really know what would be the best practice in this use case scenario.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hale0", "is_robot_indexable": true, "report_reasons": null, "author": "marcos249", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hale0/what_should_be_the_right_layer_for_normalized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hale0/what_should_be_the_right_layer_for_normalized/", "subreddit_subscribers": 112026, "created_utc": 1687556321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on building a DLT in databricks. In the bronze (raw) layer, I'm loading Parquet files into a table using autoloader. This is a streaming table.. \n\nNext I need to build the silver layer where I want to load the latest data into a dataframe and perform some operations before inserting it into a silver table. \n\nHow can I achieve this? Creating materialized view is not an option because I do not want to load the entire table or apply where cause.", "author_fullname": "t2_2z97f1a4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you work with streaming data in databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hhuvh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687576348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on building a DLT in databricks. In the bronze (raw) layer, I&amp;#39;m loading Parquet files into a table using autoloader. This is a streaming table.. &lt;/p&gt;\n\n&lt;p&gt;Next I need to build the silver layer where I want to load the latest data into a dataframe and perform some operations before inserting it into a silver table. &lt;/p&gt;\n\n&lt;p&gt;How can I achieve this? Creating materialized view is not an option because I do not want to load the entire table or apply where cause.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14hhuvh", "is_robot_indexable": true, "report_reasons": null, "author": "charliebrown3011", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hhuvh/how_do_you_work_with_streaming_data_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hhuvh/how_do_you_work_with_streaming_data_in_databricks/", "subreddit_subscribers": 112026, "created_utc": 1687576348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hope this article could help anyone struggling with Helm charts and Spark operator.\n\nAs i have finished writing a series of tutorials about manipulating Spark on Kubernetes for begginers.I've found only old exemples not working well, added to changes in version, this makes Spark operator tricky to use even for a simple exemple.Here is the tutorial  \n[https://medium.com/@SaphE/deploying-apache-spark-on-kubernetes-using-helm-charts-simplified-cluster-management-and-ee5e4f2264fd](https://medium.com/@SaphE/deploying-apache-spark-on-kubernetes-using-helm-charts-simplified-cluster-management-and-ee5e4f2264fd)  \n\n\nPeace", "author_fullname": "t2_ae4tw1pnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy Spark on kubernetes using spark operator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hdshn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687564553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this article could help anyone struggling with Helm charts and Spark operator.&lt;/p&gt;\n\n&lt;p&gt;As i have finished writing a series of tutorials about manipulating Spark on Kubernetes for begginers.I&amp;#39;ve found only old exemples not working well, added to changes in version, this makes Spark operator tricky to use even for a simple exemple.Here is the tutorial&lt;br/&gt;\n&lt;a href=\"https://medium.com/@SaphE/deploying-apache-spark-on-kubernetes-using-helm-charts-simplified-cluster-management-and-ee5e4f2264fd\"&gt;https://medium.com/@SaphE/deploying-apache-spark-on-kubernetes-using-helm-charts-simplified-cluster-management-and-ee5e4f2264fd&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Peace&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?auto=webp&amp;v=enabled&amp;s=6cb27f16e4b39771d9ec229f7a0d639823f44263", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31f330f50053b5df405ec0bb66809b86a509ad09", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86d8800124f03f07ed923620c964b15aa6c75c90", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9a6b614464dcc01f53161cfc18dad2d4981ac65", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9853dc192df755ea1eeb18d316a3f0dd265f63a1", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b2076caf0afbe06b9f91b6c02420c42d7fceffb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/6YNTiRolKDmgoAaO3Rtb6LtXklCdHHJanIXZIFKwevA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc7a32edf4a4feaed51f86f5749bfc018fd2def3", "width": 1080, "height": 607}], "variants": {}, "id": "_JrtXfbRg-zigPtfgE5-pxqxVwXpZzVRPSDGes3EzEo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14hdshn", "is_robot_indexable": true, "report_reasons": null, "author": "PhysicalTomorrow2098", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hdshn/deploy_spark_on_kubernetes_using_spark_operator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hdshn/deploy_spark_on_kubernetes_using_spark_operator/", "subreddit_subscribers": 112026, "created_utc": 1687564553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://link.medium.com/WPFVsjPnTAb", "author_fullname": "t2_ons03791", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How correctly use BigQuery LAST_VALUE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hsshd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687612421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://link.medium.com/WPFVsjPnTAb\"&gt;https://link.medium.com/WPFVsjPnTAb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?auto=webp&amp;v=enabled&amp;s=536fd612c98bf904f01321972c9c4c9e9aed3679", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=197dfc7226864a217dee1314ff3b2fc47729fb49", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bcd05289efb1370b44625c08fa6b5f14cfac025", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73df50f7a975e846cc08686b5dba9114dc106f2a", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b245bb293d370d9b61541418ecc4c645d4467d24", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c9638ecc8ade8c70666b412c5fa705c484fb261", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/6aUupUk918CpOyg-9LVBdqNFm70pSQ6KWWamDe4aj0E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4235aa5ae4b3ab545ea8b5cac0660c6635c6421", "width": 1080, "height": 720}], "variants": {}, "id": "krnsupjGWUP4JTG8hjk0-l3wnq4PYHQ_Bcl0X--gQGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14hsshd", "is_robot_indexable": true, "report_reasons": null, "author": "pacolocopepito", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hsshd/how_correctly_use_bigquery_last_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hsshd/how_correctly_use_bigquery_last_value/", "subreddit_subscribers": 112026, "created_utc": 1687612421.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior programmer/IT for a sme and even tho they describe themselves as high tech, they use a very inadequate ERP for what they're doing and they ended up telling the entire tech departement that we where going to directly edit the data from the erp's database with built in house api and software instead of changing erp. My supervisor and I have been saying that A using third party software to edit a paid software database without having the rights (A long time ago my supervisor found the super user admin creds for the database in a decompiled dll) is illegal and B is immoral yet they do not care, am I wrong for thinkibg that or no?", "author_fullname": "t2_qmmqdk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questionnability of my work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hsb67", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687611106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior programmer/IT for a sme and even tho they describe themselves as high tech, they use a very inadequate ERP for what they&amp;#39;re doing and they ended up telling the entire tech departement that we where going to directly edit the data from the erp&amp;#39;s database with built in house api and software instead of changing erp. My supervisor and I have been saying that A using third party software to edit a paid software database without having the rights (A long time ago my supervisor found the super user admin creds for the database in a decompiled dll) is illegal and B is immoral yet they do not care, am I wrong for thinkibg that or no?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hsb67", "is_robot_indexable": true, "report_reasons": null, "author": "Psychot75", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hsb67/questionnability_of_my_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hsb67/questionnability_of_my_work/", "subreddit_subscribers": 112026, "created_utc": 1687611106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to become a valuable data engineer \u00b7 Start Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_14htepc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xmSRc36JDepxnnSW94bZtAB3-p9ZRZKGLzkMIbLf6EY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687614129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "startdataengineering.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.startdataengineering.com/post/valuable-de-guide", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WIL_sRHCRWvCB5kxy6RAuyv3u8m6s8OgchKVm5loFTQ.jpg?auto=webp&amp;v=enabled&amp;s=d59126c82ed597d698dd8db0f8360c57fa77dfa6", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/WIL_sRHCRWvCB5kxy6RAuyv3u8m6s8OgchKVm5loFTQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b26397e7df8d1eb0b841ff2750e871238caa05b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/WIL_sRHCRWvCB5kxy6RAuyv3u8m6s8OgchKVm5loFTQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfd3d6ffbbf6800d559a555a81a25704b59caad2", "width": 216, "height": 216}], "variants": {}, "id": "bUxb81ct5axPonw-tInRep3zNJeyvp9SsKOACIqnnXE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14htepc", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14htepc/how_to_become_a_valuable_data_engineer_start_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.startdataengineering.com/post/valuable-de-guide", "subreddit_subscribers": 112026, "created_utc": 1687614129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beyond Data Pipelines: How Data Engineers Drive Data Culture and Empower Users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": true, "name": "t3_14htd3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JYdIHN8NLgqtgSU-Qu1cnL494kWVZzIDlyhEuq4YoXw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687614018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@timwebster85/beyond-data-pipelines-how-data-engineers-drive-data-culture-and-empower-users-953abc5418ac", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?auto=webp&amp;v=enabled&amp;s=2db3937e2e30cee22f3bfc35cb60844aadbc3a05", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41ac506bfd55a414fc515768825b0d921da5e8b3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1562a26a9d617589d73c6bdb250dd8e26237407", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bd4bcf7382a0b961c38ba1c0989f94993db2030", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be24ab8a5d040b82783b2f18ef54173f0dc6bc6b", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=235eff03e0e67b53cc3e3daee0bba9fd24ad9428", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/Q3J4QrOkI4L6bz5oNYKDKn4Dgrz00NmGeKtPQDkVgaI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cabb6f83b3d85e22b8fd1e95d1d4f9dfe2f8fc41", "width": 1080, "height": 720}], "variants": {}, "id": "cdk-PyrXUpo4d4_G-YO7ZKV3YQFKpl6wmvnYkljBNKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14htd3b", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14htd3b/beyond_data_pipelines_how_data_engineers_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@timwebster85/beyond-data-pipelines-how-data-engineers-drive-data-culture-and-empower-users-953abc5418ac", "subreddit_subscribers": 112026, "created_utc": 1687614018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, in data science, there are frameworks for reproducible data science projects like CRISP-DM.\n\n&amp;#x200B;\n\nIs there something similar in data engineering?  The goal here is to build a data pipeline fueling a front end and then use it to scale to a company level", "author_fullname": "t2_dymj0eb7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Frameworks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ht15i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687613082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, in data science, there are frameworks for reproducible data science projects like CRISP-DM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there something similar in data engineering?  The goal here is to build a data pipeline fueling a front end and then use it to scale to a company level&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ht15i", "is_robot_indexable": true, "report_reasons": null, "author": "Small_Wash3822", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ht15i/data_engineering_frameworks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ht15i/data_engineering_frameworks/", "subreddit_subscribers": 112026, "created_utc": 1687613082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1bnhotlu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Landscape in the AI-Driven World", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_14hntwr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/giMJN3EB5dWdz7RV539Innr7f5EkZb87cAX5dEzpeK0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687596636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kdnuggets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kdnuggets.com/2023/05/data-engineering-landscape-aidriven-world.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?auto=webp&amp;v=enabled&amp;s=d4c3726eefa7f0158bd41a2413cc0503d74780e0", "width": 1024, "height": 763}, "resolutions": [{"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=281a6404ce3eaa59d0ab6b7f199a79b1e32e5d66", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07a312e52954a328c614fc9f4ca6c1f649a7510c", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39028bbcec532d3f61458d5a65540aef7953236b", "width": 320, "height": 238}, {"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24a68e3c5a8c8d972306af253ecd826a8fa84cc4", "width": 640, "height": 476}, {"url": "https://external-preview.redd.it/N9eh_3ub3nVZtTlEmjxwnk-p4ZGnqe54Tu4mFtcb1WM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65548e2679206a9ef11d5f761d44a1e5586890e6", "width": 960, "height": 715}], "variants": {}, "id": "JIcX4P_4yiNYwPlTFXovy3k9ZX7-RbFRzBBpCFve4pg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14hntwr", "is_robot_indexable": true, "report_reasons": null, "author": "skj8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hntwr/data_engineering_landscape_in_the_aidriven_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kdnuggets.com/2023/05/data-engineering-landscape-aidriven-world.html", "subreddit_subscribers": 112026, "created_utc": 1687596636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm currently working on an internship project to build a proof of concept (POC) for a data warehouse on Azure Synapse. I have a few basic doubts that I couldn't find answers to, so I'm reaching out to the community for help.\n\nI'm planning to use Synapse Spark pools and Delta tables in Spark instead of Databricks. I've learned about the three-layered architecture and intend to implement it. However, I'm confused about the purpose of each layer. I have specific questions regarding each layer:\n\nBronze: Is this layer primarily used for dumping full load files and other updates? Or do we have external tables on top of the data lake where we update the tables with the files we bring into the data lake? Does this layer consist only of ADLS (Azure Data Lake Storage), or does it include ADLS along with some Delta or external tables that require updates?\n\nSilver: If we use Bronze only for storing files, my understanding is that the Silver layer will be more or less an exact replica of the OLTP (Online Transaction Processing) system, with some cleaning steps. What confuses me is that after implementing two layers, are we essentially creating a replica of the source system? If Bronze is used for both storing files and creating a replica of the source system, what is the significant difference between Bronze and Silver?\n\nGold: I've heard that regardless of the technology or tools we use, dimensional modeling is key to making BI (Business Intelligence) work more effectively. Is this the layer where we have our Kimball-style dimensionally modeled data?  \n\n\nThank you!", "author_fullname": "t2_v1vre9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help on Implementing Medallion Architecture in Synapse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hhcjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687574829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on an internship project to build a proof of concept (POC) for a data warehouse on Azure Synapse. I have a few basic doubts that I couldn&amp;#39;t find answers to, so I&amp;#39;m reaching out to the community for help.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to use Synapse Spark pools and Delta tables in Spark instead of Databricks. I&amp;#39;ve learned about the three-layered architecture and intend to implement it. However, I&amp;#39;m confused about the purpose of each layer. I have specific questions regarding each layer:&lt;/p&gt;\n\n&lt;p&gt;Bronze: Is this layer primarily used for dumping full load files and other updates? Or do we have external tables on top of the data lake where we update the tables with the files we bring into the data lake? Does this layer consist only of ADLS (Azure Data Lake Storage), or does it include ADLS along with some Delta or external tables that require updates?&lt;/p&gt;\n\n&lt;p&gt;Silver: If we use Bronze only for storing files, my understanding is that the Silver layer will be more or less an exact replica of the OLTP (Online Transaction Processing) system, with some cleaning steps. What confuses me is that after implementing two layers, are we essentially creating a replica of the source system? If Bronze is used for both storing files and creating a replica of the source system, what is the significant difference between Bronze and Silver?&lt;/p&gt;\n\n&lt;p&gt;Gold: I&amp;#39;ve heard that regardless of the technology or tools we use, dimensional modeling is key to making BI (Business Intelligence) work more effectively. Is this the layer where we have our Kimball-style dimensionally modeled data?  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14hhcjn", "is_robot_indexable": true, "report_reasons": null, "author": "sach_mess10", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hhcjn/help_on_implementing_medallion_architecture_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hhcjn/help_on_implementing_medallion_architecture_in/", "subreddit_subscribers": 112026, "created_utc": 1687574829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " **Build Datawarehouse with dbt using Kimball dimensional model | dbt models | Custom Schema | Macros** \n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\n**Transform and materialize tables with dbt**\n\n[**https://www.youtube.com/watch?v=cK617PcokS0**](https://www.youtube.com/watch?v=cK617PcokS0)\n\nTopics covered:\n\n* dbt\n* Transform and materialize tables\n* ETL\n* [dbt setup](https://www.youtube.com/watch?v=gH1w4OIgXj4&amp;t)\n\nTech Stack: **Airbyte**, **dbt, Postgres, SQL, SQL Server**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a Star Schema with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14htd1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687614016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Build Datawarehouse with dbt using Kimball dimensional model | dbt models | Custom Schema | Macros&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Transform and materialize tables with dbt&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=cK617PcokS0\"&gt;&lt;strong&gt;https://www.youtube.com/watch?v=cK617PcokS0&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;dbt&lt;/li&gt;\n&lt;li&gt;Transform and materialize tables&lt;/li&gt;\n&lt;li&gt;ETL&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=gH1w4OIgXj4&amp;amp;t\"&gt;dbt setup&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Airbyte&lt;/strong&gt;, &lt;strong&gt;dbt, Postgres, SQL, SQL Server&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DWgRPH8IOs0GckCAYma-l8zQ8aGfgHGCNajszIFE7Ug.jpg?auto=webp&amp;v=enabled&amp;s=010d6a42a7e98d4bc6595a37fe55d08ae70e5085", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/DWgRPH8IOs0GckCAYma-l8zQ8aGfgHGCNajszIFE7Ug.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8136d5da161e30574b4a0a21a23ce1fbfcb52fe5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DWgRPH8IOs0GckCAYma-l8zQ8aGfgHGCNajszIFE7Ug.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=909f1e97eaa7a8c2e1037b7083a2a190efe49e2b", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/DWgRPH8IOs0GckCAYma-l8zQ8aGfgHGCNajszIFE7Ug.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5156389e1823a1240b832ffea3dcb564102183bb", "width": 320, "height": 240}], "variants": {}, "id": "wAQa0K9mEULn2pqOlmlm18DtPdjxIJlqR-vxOyO0MXs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14htd1x", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14htd1x/build_a_star_schema_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14htd1x/build_a_star_schema_with_dbt/", "subreddit_subscribers": 112026, "created_utc": 1687614016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey , does anyone know of any roadmap to become an SME in Databricks.", "author_fullname": "t2_97hotvbcw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hsq4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687612250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey , does anyone know of any roadmap to become an SME in Databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hsq4x", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable_Tour_5897", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hsq4x/career_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hsq4x/career_opportunities/", "subreddit_subscribers": 112026, "created_utc": 1687612250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "EDIT\n\nThanks so much for all of the comments so far. Learned sth new today that DEs have the option to use a lot of GUI-driven tools to maintain their workflows &amp; effectively doing less coding as a result. Tbh no shame in that as long as things work as intended, but, still, just color me surprised. \n\nAnws, more feedback/comment is always welcome!\n\n\n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\n\n\nTLDR\n\nI'm a DA/DS first &amp; foremost w/ limited knowledge in DE. \n\nA coworker who previously worked in a global consulting firm *as a DE*, who's supposed to be a DE seems to not have any working knowledge coding skills. Only seems to know basic SQL, close to no Python but tbf to the guy, does have mad Power BI visualization &amp; dashboarding skills... \n\nJust found the whole thing very strange. I kinda get not being a Python wiz cos I can kinda justify doing DE w/ only SQL but the DEs I've worked w/ apparently can code in Python pretty well... Given Airflow, PySpark etc. as pretty popular tools for DE needs.\n\nY'all finding it sus too right? Or am I too harsh on him?\n\n\n\n\n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\nRecently got a new gig at a small shop as a DA but implied that the role will involve some DE responsibilities. Tbf I kinda set myself up here cos I've been mainly DA/DS but rly wanted to get up close &amp; personal w/ data at a lower level so this role is perfect.\n\nThe company apparently also recently hired another person (let's call him Joe) w/ the same kind of work setup/expectations but Joe has DE experience. Joe previously worked at a global consulting firm but he just immigrated &amp; that's why he needed to start small so to speak. If I namedrop the consulting firm name, chances are u know. When I learned of this, I was ecstatic. I'll be working closely w/ Joe anws &amp; I can't wait to learn DE stuffs from him.\n\nAt first things went well. He appeared to know his stuff cos he had a way of explaining them all conceptually. The technical terms &amp; buzzwords, even introduced me to some of the tools/platforms I wasn't aware of or expanded the usages I wasn't aware of for some tools I know previously.\n\nBut that's the extent of that... Just in words. So far what Joe has been doing are writing some very basic SQL queries &amp; mucking around in PowerBI almost all the time. And no, Joe didn't even seem to understand Power Query M &amp; DAX as he just connected his data model to prod server, query a bunch of data as is &amp; display them. But I gotta give it to him, the visuals are pretty to look at.\n\nCan't overstate how dissapointed I was... Not to mention I walked over to Joe's desk one time to discuss abt sth &amp; on his 2nd screen there's a YouTube tutorial that displays glaringly \"What is Matplotlib\", which prolly means he doesn't know Python as well. But props to Joe he's actually doing sth to expand his skillset.\n\nI didn't mean to be derisive, Joe's a cool dude as a person but I'm genuinely confused as to how a DE in a global consulting firm appeared to be so detached from actual code. Did he just get lucky/exaggerate his technical skills? \n\nOn another note, I think I can imagine a world where DEs don't rly need Python &amp; can get by just w/ SQL but given the increasing usage of tools on the cloud and/or as a service for DE needs, hiring someone w/ very limitied coding skills seems to only make life difficult.\n\nAny comment/feedback is greatly appreciated. I just feel off throughout the whole thing so far.", "author_fullname": "t2_lp3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coworker described as DE but nvr seemed to code anything?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14hi03a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687614160.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687576799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;EDIT&lt;/p&gt;\n\n&lt;p&gt;Thanks so much for all of the comments so far. Learned sth new today that DEs have the option to use a lot of GUI-driven tools to maintain their workflows &amp;amp; effectively doing less coding as a result. Tbh no shame in that as long as things work as intended, but, still, just color me surprised. &lt;/p&gt;\n\n&lt;p&gt;Anws, more feedback/comment is always welcome!&lt;/p&gt;\n\n&lt;p&gt;\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;TLDR&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a DA/DS first &amp;amp; foremost w/ limited knowledge in DE. &lt;/p&gt;\n\n&lt;p&gt;A coworker who previously worked in a global consulting firm &lt;em&gt;as a DE&lt;/em&gt;, who&amp;#39;s supposed to be a DE seems to not have any working knowledge coding skills. Only seems to know basic SQL, close to no Python but tbf to the guy, does have mad Power BI visualization &amp;amp; dashboarding skills... &lt;/p&gt;\n\n&lt;p&gt;Just found the whole thing very strange. I kinda get not being a Python wiz cos I can kinda justify doing DE w/ only SQL but the DEs I&amp;#39;ve worked w/ apparently can code in Python pretty well... Given Airflow, PySpark etc. as pretty popular tools for DE needs.&lt;/p&gt;\n\n&lt;p&gt;Y&amp;#39;all finding it sus too right? Or am I too harsh on him?&lt;/p&gt;\n\n&lt;p&gt;\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014&lt;/p&gt;\n\n&lt;p&gt;Recently got a new gig at a small shop as a DA but implied that the role will involve some DE responsibilities. Tbf I kinda set myself up here cos I&amp;#39;ve been mainly DA/DS but rly wanted to get up close &amp;amp; personal w/ data at a lower level so this role is perfect.&lt;/p&gt;\n\n&lt;p&gt;The company apparently also recently hired another person (let&amp;#39;s call him Joe) w/ the same kind of work setup/expectations but Joe has DE experience. Joe previously worked at a global consulting firm but he just immigrated &amp;amp; that&amp;#39;s why he needed to start small so to speak. If I namedrop the consulting firm name, chances are u know. When I learned of this, I was ecstatic. I&amp;#39;ll be working closely w/ Joe anws &amp;amp; I can&amp;#39;t wait to learn DE stuffs from him.&lt;/p&gt;\n\n&lt;p&gt;At first things went well. He appeared to know his stuff cos he had a way of explaining them all conceptually. The technical terms &amp;amp; buzzwords, even introduced me to some of the tools/platforms I wasn&amp;#39;t aware of or expanded the usages I wasn&amp;#39;t aware of for some tools I know previously.&lt;/p&gt;\n\n&lt;p&gt;But that&amp;#39;s the extent of that... Just in words. So far what Joe has been doing are writing some very basic SQL queries &amp;amp; mucking around in PowerBI almost all the time. And no, Joe didn&amp;#39;t even seem to understand Power Query M &amp;amp; DAX as he just connected his data model to prod server, query a bunch of data as is &amp;amp; display them. But I gotta give it to him, the visuals are pretty to look at.&lt;/p&gt;\n\n&lt;p&gt;Can&amp;#39;t overstate how dissapointed I was... Not to mention I walked over to Joe&amp;#39;s desk one time to discuss abt sth &amp;amp; on his 2nd screen there&amp;#39;s a YouTube tutorial that displays glaringly &amp;quot;What is Matplotlib&amp;quot;, which prolly means he doesn&amp;#39;t know Python as well. But props to Joe he&amp;#39;s actually doing sth to expand his skillset.&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t mean to be derisive, Joe&amp;#39;s a cool dude as a person but I&amp;#39;m genuinely confused as to how a DE in a global consulting firm appeared to be so detached from actual code. Did he just get lucky/exaggerate his technical skills? &lt;/p&gt;\n\n&lt;p&gt;On another note, I think I can imagine a world where DEs don&amp;#39;t rly need Python &amp;amp; can get by just w/ SQL but given the increasing usage of tools on the cloud and/or as a service for DE needs, hiring someone w/ very limitied coding skills seems to only make life difficult.&lt;/p&gt;\n\n&lt;p&gt;Any comment/feedback is greatly appreciated. I just feel off throughout the whole thing so far.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14hi03a", "is_robot_indexable": true, "report_reasons": null, "author": "YsrYsl", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14hi03a/coworker_described_as_de_but_nvr_seemed_to_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14hi03a/coworker_described_as_de_but_nvr_seemed_to_code/", "subreddit_subscribers": 112026, "created_utc": 1687576799.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}