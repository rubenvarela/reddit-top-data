{"kind": "Listing", "data": {"after": "t3_1436qx7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": " Reddit user [/u/TheArstaInventor](https://www.reddit.com/u/TheArstaInventor/) was recently banned from Reddit, alongside a subreddit they created [r/LemmyMigration](https://www.reddit.com/r/LemmyMigration/) which was promoting Lemmy.   \n\n\nLemmy is a self-hosted social link sharing and discussion platform, offering an alternative experience to Reddit. Considering recent issues with Reddit API changes, and the impending hemorrhage to Reddit's userbase, this is a sign they're panicking.\n\nThe account and subreddit have since been reinstated, but this doesn't look good for Reddit.\n\n[Full Story Here](https://www.videogamer.com/news/reddit-ban-subreddit-user-for-alternative-platforms/)", "author_fullname": "t2_323wrsms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit temporarily ban subreddit and user advertising rival self-hosted platform (Lemmy)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143diuj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 743, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 743, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686145007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Reddit user &lt;a href=\"https://www.reddit.com/u/TheArstaInventor/\"&gt;/u/TheArstaInventor&lt;/a&gt; was recently banned from Reddit, alongside a subreddit they created &lt;a href=\"https://www.reddit.com/r/LemmyMigration/\"&gt;r/LemmyMigration&lt;/a&gt; which was promoting Lemmy.   &lt;/p&gt;\n\n&lt;p&gt;Lemmy is a self-hosted social link sharing and discussion platform, offering an alternative experience to Reddit. Considering recent issues with Reddit API changes, and the impending hemorrhage to Reddit&amp;#39;s userbase, this is a sign they&amp;#39;re panicking.&lt;/p&gt;\n\n&lt;p&gt;The account and subreddit have since been reinstated, but this doesn&amp;#39;t look good for Reddit.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.videogamer.com/news/reddit-ban-subreddit-user-for-alternative-platforms/\"&gt;Full Story Here&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?auto=webp&amp;v=enabled&amp;s=b8eefb80e051ba5398a798c3a229f32db754c076", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0561d12bc98eb5f1b8d0d944a5c060c864ab8623", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9df6672753cabfd8d6415b81932b4e9cdb47ddd8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef98ae9ad8c8655be51f274feff1b59ef96d0243", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a0d880e3969f6248f2c83387e65a8f196c8c24f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef106070d31ec92bfaac7be0f6ef9be04a758ff8", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/PzuqbMn9alFK81jaXqH63dvBafiuAetLc-MBF0oPzoo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3baf5840512a29988e474a7940626d2606c072fd", "width": 1080, "height": 607}], "variants": {}, "id": "Gm61LbO2xeYFv46HtomUc2iJNR9HfwuX54_1zHApFg0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143diuj", "is_robot_indexable": true, "report_reasons": null, "author": "aDogWithoutABone", "discussion_type": null, "num_comments": 145, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143diuj/reddit_temporarily_ban_subreddit_and_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143diuj/reddit_temporarily_ban_subreddit_and_user/", "subreddit_subscribers": 253033, "created_utc": 1686145007.0, "num_crossposts": 5, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "[https://github.com/go-skynet/LocalAI](https://github.com/go-skynet/LocalAI) Updates!  \n\n\n\ud83d\ude80\ud83d\udd25 Exciting news! LocalAI v1.18.0 is here with a stellar release packed full of new features, bug fixes, and updates! \ud83c\udf89\ud83d\udd25\n\nA huge shoutout to the amazing community for their invaluable help in making this a fantastic community-driven release! Thank you for your support and make the community grow! \ud83d\ude4c\n\n# What is LocalAI?\n\nLocalAI is the OpenAI compatible API that lets you run AI models locally on your own CPU! \ud83d\udcbb Data never leaves your machine! No need for  expensive cloud services or GPUs, LocalAI uses llama.cpp and ggml to power your AI projects! \ud83e\udd99\n\n# What's new?\n\nThis LocalAI release is plenty of new features, bugfixes and updates!  Thanks to the community for the help, this was a great community  release!\n\nWe now support a vast variety of models, while being backward  compatible with prior quantization formats, this new release allows  still to load older formats and new [k-quants](https://github.com/ggerganov/llama.cpp/pull/1684)!\n\n# New features\n\n* \u2728 Added support for falcon\\-based model families (7b)  ( [mudler](https://github.com/mudler) )\n* \u2728 Experimental support for Metal Apple Silicon GPU - ( [mudler](https://github.com/mudler) and thanks to u/Soleblaze for testing! ). See the [build section](https://localai.io/basics/build/#Acceleration).\n* \u2728 Support for token stream in the /v1/completions endpoint ( [samm81](https://github.com/samm81) )\n* \u2728 Added huggingface backend ( [Evilfreelancer](https://github.com/EvilFreelancer) )\n* \ud83d\udcf7 Stablediffusion now can output 2048x2048 images size with esrgan! ( [mudler](https://github.com/mudler) )\n\n# Container images\n\n* \ud83d\udc0b CUDA container images (arm64, x86\\_64) ( [sebastien-prudhomme](https://github.com/sebastien-prudhomme) )\n* \ud83d\udc0b FFmpeg container images (arm64, x86\\_64) ( [mudler](https://github.com/mudler) )\n\n# Dependencies updates\n\n* \ud83c\udd99 Bloomz has been updated to the latest ggml changes, including new quantization format ( [mudler](https://github.com/mudler) )\n* \ud83c\udd99 RWKV has been updated to the new quantization format( [mudler](https://github.com/mudler) )\n* \ud83c\udd99 [k-quants](https://github.com/ggerganov/llama.cpp/pull/1684) format support for the llama  \n models ( [mudler](https://github.com/mudler) )\n* \ud83c\udd99 gpt4all has been updated, incorporating upstream changes allowing  to load older models, and with different CPU instruction set (AVX only,  AVX2) from the same binary! ( [mudler](https://github.com/mudler) )\n\n# Generic\n\n* \ud83d\udc27 Fully Linux static binary releases ( [mudler](https://github.com/mudler) )\n* \ud83d\udcf7 Stablediffusion has been enabled on container images by default ( [mudler](https://github.com/mudler) ) Note: You can disable container image rebuilds with REBUILD=false\n\n# Examples\n\n* \ud83d\udca1 [AutoGPT](https://github.com/go-skynet/LocalAI/tree/master/examples/autoGPT) example ( [mudler](https://github.com/mudler) )\n* \ud83d\udca1 [PrivateGPT](https://github.com/go-skynet/LocalAI/tree/master/examples/privateGPT) example ( [mudler](https://github.com/mudler) )\n* \ud83d\udca1 [Flowise](https://github.com/go-skynet/LocalAI/tree/master/examples/flowise) example ( [mudler](https://github.com/mudler) )\n\nTwo new projects offer now direct integration with LocalAI!\n\n* [Flowise](https://github.com/FlowiseAI/Flowise/pull/123)\n* [Mods](https://github.com/charmbracelet/mods)\n\n[Full release changelog](https://github.com/go-skynet/LocalAI/releases/tag/v1.18.0)\n\n&amp;#x200B;\n\nThank you for your support, and happy hacking!", "author_fullname": "t2_g0k1wu3i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LocalAI v1.18.0 release!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142uqn4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 211, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 211, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686088947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/go-skynet/LocalAI\"&gt;https://github.com/go-skynet/LocalAI&lt;/a&gt; Updates!  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\ude80\ud83d\udd25 Exciting news! LocalAI v1.18.0 is here with a stellar release packed full of new features, bug fixes, and updates! \ud83c\udf89\ud83d\udd25&lt;/p&gt;\n\n&lt;p&gt;A huge shoutout to the amazing community for their invaluable help in making this a fantastic community-driven release! Thank you for your support and make the community grow! \ud83d\ude4c&lt;/p&gt;\n\n&lt;h1&gt;What is LocalAI?&lt;/h1&gt;\n\n&lt;p&gt;LocalAI is the OpenAI compatible API that lets you run AI models locally on your own CPU! \ud83d\udcbb Data never leaves your machine! No need for  expensive cloud services or GPUs, LocalAI uses llama.cpp and ggml to power your AI projects! \ud83e\udd99&lt;/p&gt;\n\n&lt;h1&gt;What&amp;#39;s new?&lt;/h1&gt;\n\n&lt;p&gt;This LocalAI release is plenty of new features, bugfixes and updates!  Thanks to the community for the help, this was a great community  release!&lt;/p&gt;\n\n&lt;p&gt;We now support a vast variety of models, while being backward  compatible with prior quantization formats, this new release allows  still to load older formats and new &lt;a href=\"https://github.com/ggerganov/llama.cpp/pull/1684\"&gt;k-quants&lt;/a&gt;!&lt;/p&gt;\n\n&lt;h1&gt;New features&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u2728 Added support for falcon-based model families (7b)  ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\u2728 Experimental support for Metal Apple Silicon GPU - ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; and thanks to &lt;a href=\"/u/Soleblaze\"&gt;u/Soleblaze&lt;/a&gt; for testing! ). See the &lt;a href=\"https://localai.io/basics/build/#Acceleration\"&gt;build section&lt;/a&gt;.&lt;/li&gt;\n&lt;li&gt;\u2728 Support for token stream in the /v1/completions endpoint ( &lt;a href=\"https://github.com/samm81\"&gt;samm81&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\u2728 Added huggingface backend ( &lt;a href=\"https://github.com/EvilFreelancer\"&gt;Evilfreelancer&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83d\udcf7 Stablediffusion now can output 2048x2048 images size with esrgan! ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Container images&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\ud83d\udc0b CUDA container images (arm64, x86_64) ( &lt;a href=\"https://github.com/sebastien-prudhomme\"&gt;sebastien-prudhomme&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83d\udc0b FFmpeg container images (arm64, x86_64) ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Dependencies updates&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\ud83c\udd99 Bloomz has been updated to the latest ggml changes, including new quantization format ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83c\udd99 RWKV has been updated to the new quantization format( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83c\udd99 &lt;a href=\"https://github.com/ggerganov/llama.cpp/pull/1684\"&gt;k-quants&lt;/a&gt; format support for the llama&lt;br/&gt;\nmodels ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83c\udd99 gpt4all has been updated, incorporating upstream changes allowing  to load older models, and with different CPU instruction set (AVX only,  AVX2) from the same binary! ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Generic&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\ud83d\udc27 Fully Linux static binary releases ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83d\udcf7 Stablediffusion has been enabled on container images by default ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; ) Note: You can disable container image rebuilds with REBUILD=false&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Examples&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\ud83d\udca1 &lt;a href=\"https://github.com/go-skynet/LocalAI/tree/master/examples/autoGPT\"&gt;AutoGPT&lt;/a&gt; example ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83d\udca1 &lt;a href=\"https://github.com/go-skynet/LocalAI/tree/master/examples/privateGPT\"&gt;PrivateGPT&lt;/a&gt; example ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;li&gt;\ud83d\udca1 &lt;a href=\"https://github.com/go-skynet/LocalAI/tree/master/examples/flowise\"&gt;Flowise&lt;/a&gt; example ( &lt;a href=\"https://github.com/mudler\"&gt;mudler&lt;/a&gt; )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Two new projects offer now direct integration with LocalAI!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/FlowiseAI/Flowise/pull/123\"&gt;Flowise&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/charmbracelet/mods\"&gt;Mods&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/go-skynet/LocalAI/releases/tag/v1.18.0\"&gt;Full release changelog&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your support, and happy hacking!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?auto=webp&amp;v=enabled&amp;s=bcd7bfb38ec1002e85e94f43bdde96894e011ee0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e74c80851be11fbaac70d5ef4c7c041cb072cfe", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50a79e603293a769cf09363306b8016912b06d99", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=312657372ed13380b99edf291142005c14d26fd7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26146a544279201554cdb69b8d83e35c44198250", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4fe2e79ab45dbc8bf28f94f51badca13d204890", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/QmsDfC5XJiVbqIq9J1VFfmejf_JVzPR_bB62-qUPGzo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ca227fe8d3f49d8578394b9e54561190ad7c8cc", "width": 1080, "height": 540}], "variants": {}, "id": "s-3Py4QBMcmGZhK82kMFFBqMbm--Iv0cn5Z_tIUNgqM"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 325, "id": "award_2bc47247-b107-44a8-a78c-613da21869ff", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Rocket_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Rocket_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Rocket_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Rocket_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Rocket_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Rocket_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Boldly go where we haven't been in a long, long time.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "To The Stars", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=06f2d039483185440c5e566f72737a920237569b", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=d0ecc136d90892f44d543d59e829c16e5fb88e47", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=62b08d35d1a520218ef92eba8201ac610dce24d7", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=380d1eeb5fe919116bbafe61b1aa5a82e83d59c2", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=28263127cf796e9c53e91fb0a750106e59ac67c0", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 512, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/1sof6d93g9e51_ToTheStars.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142uqn4", "is_robot_indexable": true, "report_reasons": null, "author": "mudler_it", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142uqn4/localai_v1180_release/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142uqn4/localai_v1180_release/", "subreddit_subscribers": 253033, "created_utc": 1686088947.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey folks,\n\nToday we are launching OpenObserve. An open source Elasticsearch/Splunk/Datadog alternative written in rust and vue that is super easy to get started with and has 140x lower storage cost. It offers logs, metrics, traces, dashboards, alerts, functions (run aws lambda like functions during ingestion and query to enrich, redact, transform, normalize and whatever else you want to do. Think redacting email IDs from logs, adding geolocation based on IP address, etc). You can do all of this from the UI; no messing up with configuration files.\n\nOpenObserve can use local disk for storage in single node mode or s3/gc/minio/azure blob or any s3 compatible store in HA mode.\n\nWe found that setting up observability often involved setting up 4 different tools (grafana for dashboarding, elasticsearch/loki/etc for logs, jaeger for tracing, thanos, cortex etc for metics) and its not simple to do these things.\n\nHere is a blog on why we built OpenObserve - [https://openobserve.ai/blog/launching-openobserve](https://openobserve.ai/blog/launching-openobserve).\n\nWe are in early days and would love to get feedback and suggestions.\n\nHere is the github page. [https://github.com/openobserve/openobserve](https://github.com/openobserve/openobserve)\n\nYou can run it in your raspberry pi and in a 300 node cluster ingesting a petabyte of data per day.", "author_fullname": "t2_7bsgws6q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenObserve: Open source Elasticsearch alternative in Rust for logs. 140x lower storage cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1435zxl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 165, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 165, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686121257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;Today we are launching OpenObserve. An open source Elasticsearch/Splunk/Datadog alternative written in rust and vue that is super easy to get started with and has 140x lower storage cost. It offers logs, metrics, traces, dashboards, alerts, functions (run aws lambda like functions during ingestion and query to enrich, redact, transform, normalize and whatever else you want to do. Think redacting email IDs from logs, adding geolocation based on IP address, etc). You can do all of this from the UI; no messing up with configuration files.&lt;/p&gt;\n\n&lt;p&gt;OpenObserve can use local disk for storage in single node mode or s3/gc/minio/azure blob or any s3 compatible store in HA mode.&lt;/p&gt;\n\n&lt;p&gt;We found that setting up observability often involved setting up 4 different tools (grafana for dashboarding, elasticsearch/loki/etc for logs, jaeger for tracing, thanos, cortex etc for metics) and its not simple to do these things.&lt;/p&gt;\n\n&lt;p&gt;Here is a blog on why we built OpenObserve - &lt;a href=\"https://openobserve.ai/blog/launching-openobserve\"&gt;https://openobserve.ai/blog/launching-openobserve&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We are in early days and would love to get feedback and suggestions.&lt;/p&gt;\n\n&lt;p&gt;Here is the github page. &lt;a href=\"https://github.com/openobserve/openobserve\"&gt;https://github.com/openobserve/openobserve&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You can run it in your raspberry pi and in a 300 node cluster ingesting a petabyte of data per day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?auto=webp&amp;v=enabled&amp;s=7af5d4a7c0c23b43d6468eed6a9865232ffa57c1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86d33bedec1eedc64b24099befee2610e36c1a80", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=586642648cb9af20ea78deb9cde7d79077e2e0d0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cdf2de17fd1043b683e41e84fe5fb28c2f0659c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1383d36d9feeafc549b1450e47c1f89b407d8bd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488da2967b97a31c9c5be251dbb1a1075bb3d933", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Adh2OFRbF0Mpp2vtvO-d6SqX0hIHPqWjaucS2EG-16w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baa4f68a31fa7a7db0ae4647c7ea0236f6f85d6f", "width": 1080, "height": 567}], "variants": {}, "id": "4otMKjAedw7YCHVFlFfFjck6QDT82noeIjZFvL9idEA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1435zxl", "is_robot_indexable": true, "report_reasons": null, "author": "the_ml_guy", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1435zxl/openobserve_open_source_elasticsearch_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1435zxl/openobserve_open_source_elasticsearch_alternative/", "subreddit_subscribers": 253033, "created_utc": 1686121257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I don't know if this where already posted or if this is the right subreddit to post but here is my idea:\n\nReddit 2.0 because reddit changing its API Policies and becoming more interested in their investors then in thier community.\n\n**Reddit 2.0**\n\n1. Use the Reddit Archive of Archiv Team from r/DataHoarder to create an easily accessible database where everyone can go select a subreddit and download the files required to spin up a Lemmy instance to host this subreddit on their server.\n2. Maybe create some sort of community funding system where people get paid when hosting subreddits and where the payout gets calculated on how many users this instance has. And if the server that hosts a high-demand subreddit (on lemmy) goes down a hosting fund gets created that pays the people re-spinning up this subreddit to get it re-online faster\n3. Some other communities like r/webdev could be asked to create a better Reddit-style Lemmy frontpage and r/Frontend could be asked to create a more normie appealing frontend (design) for Lemmy.\n\n&amp;#x200B;\n\n**How to maybe moderate the platform**\n\nReddit already moderates its platform only through bots and moderators working in their free time. It would need a system to convert the already existing moderators from Reddit to Lemmy.\n\n&amp;#x200B;\n\n**community fund**\n\n* Some sort of premium subscription like pay $2,99/Month to use the full platform.\n* A Advertisement System where Advertises pay directly into the fund to place ads on the platform (without tracking of course)\n* For the Crypto Bros: LemmyCoin or Reddit2.0Coin where you mine it by hosting an instance.\n\n&amp;#x200B;\n\nI know this idea has its problems like Lemmy having its problems, would this find a community-wide adaptation, and and and. And I know its hard to get the community to work together but maybe a group of people could be found making this a reality. Or is it just me and the idea of creating a social media page like Reddit but it is more decentralized and community driven would be great.\n\nWould this be a good Idea would appreciate feedback for this.", "author_fullname": "t2_dvw71m6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Community Effort to Create Reddit 2.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142t8tw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686085545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if this where already posted or if this is the right subreddit to post but here is my idea:&lt;/p&gt;\n\n&lt;p&gt;Reddit 2.0 because reddit changing its API Policies and becoming more interested in their investors then in thier community.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Reddit 2.0&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use the Reddit Archive of Archiv Team from &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; to create an easily accessible database where everyone can go select a subreddit and download the files required to spin up a Lemmy instance to host this subreddit on their server.&lt;/li&gt;\n&lt;li&gt;Maybe create some sort of community funding system where people get paid when hosting subreddits and where the payout gets calculated on how many users this instance has. And if the server that hosts a high-demand subreddit (on lemmy) goes down a hosting fund gets created that pays the people re-spinning up this subreddit to get it re-online faster&lt;/li&gt;\n&lt;li&gt;Some other communities like &lt;a href=\"/r/webdev\"&gt;r/webdev&lt;/a&gt; could be asked to create a better Reddit-style Lemmy frontpage and &lt;a href=\"/r/Frontend\"&gt;r/Frontend&lt;/a&gt; could be asked to create a more normie appealing frontend (design) for Lemmy.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How to maybe moderate the platform&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Reddit already moderates its platform only through bots and moderators working in their free time. It would need a system to convert the already existing moderators from Reddit to Lemmy.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;community fund&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some sort of premium subscription like pay $2,99/Month to use the full platform.&lt;/li&gt;\n&lt;li&gt;A Advertisement System where Advertises pay directly into the fund to place ads on the platform (without tracking of course)&lt;/li&gt;\n&lt;li&gt;For the Crypto Bros: LemmyCoin or Reddit2.0Coin where you mine it by hosting an instance.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know this idea has its problems like Lemmy having its problems, would this find a community-wide adaptation, and and and. And I know its hard to get the community to work together but maybe a group of people could be found making this a reality. Or is it just me and the idea of creating a social media page like Reddit but it is more decentralized and community driven would be great.&lt;/p&gt;\n\n&lt;p&gt;Would this be a good Idea would appreciate feedback for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142t8tw", "is_robot_indexable": true, "report_reasons": null, "author": "BikaenDerAndereAcc", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142t8tw/community_effort_to_create_reddit_20/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142t8tw/community_effort_to_create_reddit_20/", "subreddit_subscribers": 253033, "created_utc": 1686085545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm currently using trello to keep a bunch of stuff organised. But I'm wanting to organise a little more and I'm having a hard time choosing the best application for my use case.\n\nWhat I'm looking for:\nA lot of similar features to trello.\nUnlimited boards and unlimited workspaces.\nAllows the collaboration between a few members.\nKanban.\n\nBasically I'm looking for the closest thing to trello that allows me to have more boards within my workspaces without paying etc.\n\nI've looked at leantime and focalboard but I'm having trouble knowing if they have the features I want. I forgot to also mention I'm looking to run this on a raspberry pi 4. I've had leantime run in there before with no issues, I was looking for another feature at the time though and couldn't find it.\n\nAny help would be greatly appreciated. I'm honestly really stuck and lost with this.\n~Blood", "author_fullname": "t2_atzwj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trello Alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142vwm6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686091709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently using trello to keep a bunch of stuff organised. But I&amp;#39;m wanting to organise a little more and I&amp;#39;m having a hard time choosing the best application for my use case.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for:\nA lot of similar features to trello.\nUnlimited boards and unlimited workspaces.\nAllows the collaboration between a few members.\nKanban.&lt;/p&gt;\n\n&lt;p&gt;Basically I&amp;#39;m looking for the closest thing to trello that allows me to have more boards within my workspaces without paying etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at leantime and focalboard but I&amp;#39;m having trouble knowing if they have the features I want. I forgot to also mention I&amp;#39;m looking to run this on a raspberry pi 4. I&amp;#39;ve had leantime run in there before with no issues, I was looking for another feature at the time though and couldn&amp;#39;t find it.&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated. I&amp;#39;m honestly really stuck and lost with this.\n~Blood&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142vwm6", "is_robot_indexable": true, "report_reasons": null, "author": "bloodshotpico", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142vwm6/trello_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142vwm6/trello_alternative/", "subreddit_subscribers": 253033, "created_utc": 1686091709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "So in lieu of Reddit's recent API changes, it seems people will want to have ways to dump their data and move elsewhere if the announced pricing plan isn't adjusted. Since I wanted to dump my own Reddit messages, I came up with a script that makes this possible.\n\nReddit's new chat infrastructure is based on Matrix, allowing us to use standard Matrix clients to access the message history.\n\nAs I used Golang for this, I used the Mautrix client, and came up with the following:\n\n    func FetchMessages(client *mautrix.Client, roomID id.RoomID, callback func(messages []*event.Event)) error {\n    \tr, err := client.CreateFilter(mautrix.NewDefaultSyncer().FilterJSON)\n    \n    \tif err != nil {\n    \t\treturn err\n    \t}\n    \n    \tresp, err := client.SyncRequest(0, \"\", r.FilterID, true, event.PresenceOnline, context.TODO())\n    \n    \tif err != nil {\n    \t\treturn err\n    \t}\n    \n    \tvar room *mautrix.SyncJoinedRoom\n    \n    \tfor id, r := range resp.Rooms.Join {\n    \t\tif id == roomID {\n    \t\t\troom = r\n    \t\t\tbreak\n    \t\t}\n    \t}\n    \n    \tvar messages []*event.Event\n    \n    \tfor _, m := range room.Timeline.Events {\n    \t\tif m.Type == event.EventMessage {\n    \t\t\tmessages = append(messages, m)\n    \t\t}\n    \t}\n    \n    \tcallback(messages)\n    \n    \tend := room.Timeline.PrevBatch\n    \n    \tfor {\n    \t\tif end == \"\" {\n    \t\t\tbreak\n    \t\t}\n    \n    \t\tvar messages []*event.Event\n    \n    \t\tmsgs, err := client.Messages(roomID, end, \"\", mautrix.DirectionBackward, &amp;mautrix.FilterPart{}, 100)\n    \n    \t\tif err != nil {\n    \t\t\tlog.Fatalf(err.Error())\n    \t\t}\n    \n    \t\tmessages = append(messages, msgs.Chunk...)\n    \t\tcallback(messages)\n    \n    \t\tend = msgs.End\n    \n    \t\tif len(messages) == 0 {\n    \t\t\tcontinue\n    \t\t}\n    \t}\n    \n    \treturn nil\n    }\n\nThis method will fetch all the messages from a given room ID, and call the `callback()` function in batches. From there you can use the events to dump as JSON, store in a DB, or anything else. \n\nTo create the Mautrix client and `roomID` argument, the following snippet can be used:\n\n    client, err := mautrix.NewClient(\"https://matrix.redditspace.com/\", id.NewUserID(\"t2_&lt;userID&gt;\", \"reddit.com\"), \"&lt;redditAccessToken\"\")\n    roomID := id.RoomID(\"&lt;roomID&gt;\")\n\nTo fill out the above variables, you'll need to use your browser's network tab to inspect requests and get the IDs and access token. For that head to Reddit's chat at [https://chat.reddit.com](https://chat.reddit.com) and reload the window with the network tab open. \n\n**User ID**\n\nYour user ID is visible in the request to [https://matrix.redditspace.com/\\_matrix/client/r0/login](https://matrix.redditspace.com/_matrix/client/r0/login). It will be part of the response as `user_id`.\n\n**Room ID**\n\nThe room ID will be part of the URL when you select a chat room. Simply copy the entire path after [https://chat.reddit.com/room](https://chat.reddit.com/room) and URL decode it.\n\n**Access Token**\n\nYour access token will be included in all requests after the login. I used the request to /filter and copy the value from the `Authorization` header without \"Bearer \".\n\nNow, depending on what you want to do with the messages you'll want to write your own parsing and mapping logic, as well as saving, but a fairly straightforward `main()` method to save all the messages in JSON can look like this:\n\n    package main\n    \n    type Message struct {\n        Source      string    `bson:\"source\"`\n        ChatID      string    `bson:\"chat_id\"`\n        Author      string    `bson:\"author\"`\n        Timestamp   time.Time `bson:\"timestamp\"`\n        SourceID    string    `bson:\"source_id\"`\n        Body        string    `bson:\"body\"`\n        Attachments []string  `bson:\"attachments\"`\n    }\n    \n    func parseMsg(message *event.Event, roomId id.RoomID) *model.Message {\n    \tts := time.Unix(message.Timestamp, 0)\n    \n    \tmsg := &amp;model.Message{\n    \t\tSource:    \"reddit\",\n    \t\tChatID:    roomId.String(),\n    \t\tAuthor:    message.Sender.String(),\n    \t\tTimestamp: ts,\n    \t\tSourceID:  message.ID.String(),\n    \t}\n    \n    \tswitch message.Content.Raw[\"msgtype\"] {\n    \tcase \"m.text\":\n    \t\tif message.Content.Raw[\"body\"] == nil {\n    \t\t\tfmt.Println(\"Empty message body:\", message.Content.Raw)\n    \t\t\treturn nil\n    \t\t} else {\n    \t\t\tmsg.Body = message.Content.Raw[\"body\"].(string)\n    \t\t}\n    \tcase \"m.image\":\n    \t\tmsg.Attachments = []string{\n    \t\t\tmessage.Content.Raw[\"url\"].(string),\n    \t\t}\n    \tcase nil:\n    \t\tif message.Content.Raw[\"m.relates_to\"] != nil &amp;&amp; message.Content.Raw[\"m.relates_to\"].(map[string]interface{})[\"rel_type\"] == \"com.reddit.potentially_toxic\" {\n    \t\t} else {\n    \t\t\tfmt.Println(\"No message type:\", message.Content.Raw)\n    \t\t}\n    \t\treturn nil\n    \tdefault:\n    \t\tfmt.Println(\"Unknown message type:\", message.Content.Raw)\n    \t}\n    \n    \treturn msg\n    }\n    \n    func main() {\n        var allMessages []*Message\n        \n        err = reddit.FetchMessages(client, roomId, func(messages []*event.Event) {\n            for _, msg := range messages {\n                m := parseMsg(msg, roomId)\n                if m == nil {\n                    continue\n                }\n                messages = append(messages, m)\n            }\n        }\n    \n        if err != nil {\n            log.Fatalf(err.Error())\n        }\n    \n        file, _ := json.MarshalIndent(allMessages, \"\", \" \")\n        _ = os.WriteFile(\"events.json\", file, 0644)\n    }\n\nHappy dumping!", "author_fullname": "t2_9w1ryk11p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created some Go scripts to dump Reddit chats!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "chatsystem", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143bl09", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Chat System", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686140052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So in lieu of Reddit&amp;#39;s recent API changes, it seems people will want to have ways to dump their data and move elsewhere if the announced pricing plan isn&amp;#39;t adjusted. Since I wanted to dump my own Reddit messages, I came up with a script that makes this possible.&lt;/p&gt;\n\n&lt;p&gt;Reddit&amp;#39;s new chat infrastructure is based on Matrix, allowing us to use standard Matrix clients to access the message history.&lt;/p&gt;\n\n&lt;p&gt;As I used Golang for this, I used the Mautrix client, and came up with the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;func FetchMessages(client *mautrix.Client, roomID id.RoomID, callback func(messages []*event.Event)) error {\n    r, err := client.CreateFilter(mautrix.NewDefaultSyncer().FilterJSON)\n\n    if err != nil {\n        return err\n    }\n\n    resp, err := client.SyncRequest(0, &amp;quot;&amp;quot;, r.FilterID, true, event.PresenceOnline, context.TODO())\n\n    if err != nil {\n        return err\n    }\n\n    var room *mautrix.SyncJoinedRoom\n\n    for id, r := range resp.Rooms.Join {\n        if id == roomID {\n            room = r\n            break\n        }\n    }\n\n    var messages []*event.Event\n\n    for _, m := range room.Timeline.Events {\n        if m.Type == event.EventMessage {\n            messages = append(messages, m)\n        }\n    }\n\n    callback(messages)\n\n    end := room.Timeline.PrevBatch\n\n    for {\n        if end == &amp;quot;&amp;quot; {\n            break\n        }\n\n        var messages []*event.Event\n\n        msgs, err := client.Messages(roomID, end, &amp;quot;&amp;quot;, mautrix.DirectionBackward, &amp;amp;mautrix.FilterPart{}, 100)\n\n        if err != nil {\n            log.Fatalf(err.Error())\n        }\n\n        messages = append(messages, msgs.Chunk...)\n        callback(messages)\n\n        end = msgs.End\n\n        if len(messages) == 0 {\n            continue\n        }\n    }\n\n    return nil\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This method will fetch all the messages from a given room ID, and call the &lt;code&gt;callback()&lt;/code&gt; function in batches. From there you can use the events to dump as JSON, store in a DB, or anything else. &lt;/p&gt;\n\n&lt;p&gt;To create the Mautrix client and &lt;code&gt;roomID&lt;/code&gt; argument, the following snippet can be used:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;client, err := mautrix.NewClient(&amp;quot;https://matrix.redditspace.com/&amp;quot;, id.NewUserID(&amp;quot;t2_&amp;lt;userID&amp;gt;&amp;quot;, &amp;quot;reddit.com&amp;quot;), &amp;quot;&amp;lt;redditAccessToken&amp;quot;&amp;quot;)\nroomID := id.RoomID(&amp;quot;&amp;lt;roomID&amp;gt;&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To fill out the above variables, you&amp;#39;ll need to use your browser&amp;#39;s network tab to inspect requests and get the IDs and access token. For that head to Reddit&amp;#39;s chat at &lt;a href=\"https://chat.reddit.com\"&gt;https://chat.reddit.com&lt;/a&gt; and reload the window with the network tab open. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;User ID&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Your user ID is visible in the request to &lt;a href=\"https://matrix.redditspace.com/_matrix/client/r0/login\"&gt;https://matrix.redditspace.com/_matrix/client/r0/login&lt;/a&gt;. It will be part of the response as &lt;code&gt;user_id&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Room ID&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The room ID will be part of the URL when you select a chat room. Simply copy the entire path after &lt;a href=\"https://chat.reddit.com/room\"&gt;https://chat.reddit.com/room&lt;/a&gt; and URL decode it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Access Token&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Your access token will be included in all requests after the login. I used the request to /filter and copy the value from the &lt;code&gt;Authorization&lt;/code&gt; header without &amp;quot;Bearer &amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Now, depending on what you want to do with the messages you&amp;#39;ll want to write your own parsing and mapping logic, as well as saving, but a fairly straightforward &lt;code&gt;main()&lt;/code&gt; method to save all the messages in JSON can look like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;package main\n\ntype Message struct {\n    Source      string    `bson:&amp;quot;source&amp;quot;`\n    ChatID      string    `bson:&amp;quot;chat_id&amp;quot;`\n    Author      string    `bson:&amp;quot;author&amp;quot;`\n    Timestamp   time.Time `bson:&amp;quot;timestamp&amp;quot;`\n    SourceID    string    `bson:&amp;quot;source_id&amp;quot;`\n    Body        string    `bson:&amp;quot;body&amp;quot;`\n    Attachments []string  `bson:&amp;quot;attachments&amp;quot;`\n}\n\nfunc parseMsg(message *event.Event, roomId id.RoomID) *model.Message {\n    ts := time.Unix(message.Timestamp, 0)\n\n    msg := &amp;amp;model.Message{\n        Source:    &amp;quot;reddit&amp;quot;,\n        ChatID:    roomId.String(),\n        Author:    message.Sender.String(),\n        Timestamp: ts,\n        SourceID:  message.ID.String(),\n    }\n\n    switch message.Content.Raw[&amp;quot;msgtype&amp;quot;] {\n    case &amp;quot;m.text&amp;quot;:\n        if message.Content.Raw[&amp;quot;body&amp;quot;] == nil {\n            fmt.Println(&amp;quot;Empty message body:&amp;quot;, message.Content.Raw)\n            return nil\n        } else {\n            msg.Body = message.Content.Raw[&amp;quot;body&amp;quot;].(string)\n        }\n    case &amp;quot;m.image&amp;quot;:\n        msg.Attachments = []string{\n            message.Content.Raw[&amp;quot;url&amp;quot;].(string),\n        }\n    case nil:\n        if message.Content.Raw[&amp;quot;m.relates_to&amp;quot;] != nil &amp;amp;&amp;amp; message.Content.Raw[&amp;quot;m.relates_to&amp;quot;].(map[string]interface{})[&amp;quot;rel_type&amp;quot;] == &amp;quot;com.reddit.potentially_toxic&amp;quot; {\n        } else {\n            fmt.Println(&amp;quot;No message type:&amp;quot;, message.Content.Raw)\n        }\n        return nil\n    default:\n        fmt.Println(&amp;quot;Unknown message type:&amp;quot;, message.Content.Raw)\n    }\n\n    return msg\n}\n\nfunc main() {\n    var allMessages []*Message\n\n    err = reddit.FetchMessages(client, roomId, func(messages []*event.Event) {\n        for _, msg := range messages {\n            m := parseMsg(msg, roomId)\n            if m == nil {\n                continue\n            }\n            messages = append(messages, m)\n        }\n    }\n\n    if err != nil {\n        log.Fatalf(err.Error())\n    }\n\n    file, _ := json.MarshalIndent(allMessages, &amp;quot;&amp;quot;, &amp;quot; &amp;quot;)\n    _ = os.WriteFile(&amp;quot;events.json&amp;quot;, file, 0644)\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Happy dumping!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0d52d76a-7e68-11e9-977c-0eabae61418e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143bl09", "is_robot_indexable": true, "report_reasons": null, "author": "Dan6erbond2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143bl09/i_created_some_go_scripts_to_dump_reddit_chats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143bl09/i_created_some_go_scripts_to_dump_reddit_chats/", "subreddit_subscribers": 253033, "created_utc": 1686140052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I hope reddit can forgive the click-baity title. I am trying something new\n\nOntime is an application for managing rundowns and stage timers. The first version was released slightly over a year ago.\n\nSince, we have learned about the application and how users interact with Ontime and have prepared a new version\n\nV2 is a great technical achievement, mainly focused on preparing architecture to enable us to expand. Unfortunately, technical achievements do not present themselves to regular users, but we still have a good list of features and improvements:\n\n* Complete **redesign of editors** and views focusing on adding more power and friendlier UX\n* New, **cleaner styling** system with a focus on dark schemes\n* New **integrations engine** for enabling Ontime to share its data with other software (focusing on OSC)\n* Friendly **view configurations**\n* Comprehensive **companion module**\n* **Improved playback** mode\n* Timer **automations**\n* ... Several small UX and UI improvements requested by users\n* ... and lots more\n\nv2 has been beta testing for nearly half a year and is now a stable release.\n\n&amp;#x200B;\n\nOntime is [available for Mac, Windows, Linux](https://github.com/cpvalente/ontime/releases/tag/v2.0.0), and a [docker image](https://hub.docker.com/r/getontime/ontime).\n\nPlease visit [the website](https://www.getontime.no/) or see the [documentation in GitBook](https://ontime.gitbook.io/v2/). You are also welcome to check in on our development and participate with bug reports and feature requests on [Github](https://github.com/cpvalente/ontime)\n\nOntime always was and will remain free.", "author_fullname": "t2_dny19tii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ontime v2: rundown and time manager is now free", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142ro1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686081900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope reddit can forgive the click-baity title. I am trying something new&lt;/p&gt;\n\n&lt;p&gt;Ontime is an application for managing rundowns and stage timers. The first version was released slightly over a year ago.&lt;/p&gt;\n\n&lt;p&gt;Since, we have learned about the application and how users interact with Ontime and have prepared a new version&lt;/p&gt;\n\n&lt;p&gt;V2 is a great technical achievement, mainly focused on preparing architecture to enable us to expand. Unfortunately, technical achievements do not present themselves to regular users, but we still have a good list of features and improvements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Complete &lt;strong&gt;redesign of editors&lt;/strong&gt; and views focusing on adding more power and friendlier UX&lt;/li&gt;\n&lt;li&gt;New, &lt;strong&gt;cleaner styling&lt;/strong&gt; system with a focus on dark schemes&lt;/li&gt;\n&lt;li&gt;New &lt;strong&gt;integrations engine&lt;/strong&gt; for enabling Ontime to share its data with other software (focusing on OSC)&lt;/li&gt;\n&lt;li&gt;Friendly &lt;strong&gt;view configurations&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Comprehensive &lt;strong&gt;companion module&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Improved playback&lt;/strong&gt; mode&lt;/li&gt;\n&lt;li&gt;Timer &lt;strong&gt;automations&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;... Several small UX and UI improvements requested by users&lt;/li&gt;\n&lt;li&gt;... and lots more&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;v2 has been beta testing for nearly half a year and is now a stable release.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ontime is &lt;a href=\"https://github.com/cpvalente/ontime/releases/tag/v2.0.0\"&gt;available for Mac, Windows, Linux&lt;/a&gt;, and a &lt;a href=\"https://hub.docker.com/r/getontime/ontime\"&gt;docker image&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Please visit &lt;a href=\"https://www.getontime.no/\"&gt;the website&lt;/a&gt; or see the &lt;a href=\"https://ontime.gitbook.io/v2/\"&gt;documentation in GitBook&lt;/a&gt;. You are also welcome to check in on our development and participate with bug reports and feature requests on &lt;a href=\"https://github.com/cpvalente/ontime\"&gt;Github&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ontime always was and will remain free.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?auto=webp&amp;v=enabled&amp;s=ced5d1c828969cbc11f300d34e2be4d5f1fdebfc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a256953e3907e070d84b8bc7d5772ec0958b92c2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=707a48d69a3b1c68b99b7109fa49b318761b761f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61fd1afcdb3c99899a60253f574bb9ab23202ff7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe8e3efa89f29acd962d4a45d87cc4f5ebde8a0e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99a02f32d41b8215076d6997d6679858b13bf9bc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/_PAdhr0f3c6lQ0xzAI3xLu7qI1vDsBKpJR03JRv_0-0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eadb251364569404b6999af9dc2954a790922955", "width": 1080, "height": 540}], "variants": {}, "id": "h1-JFeAGzTqAb7X3Mrkg-Sh26vLs7v1vF5qUL-3F9w0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142ro1f", "is_robot_indexable": true, "report_reasons": null, "author": "somedevstuff", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142ro1f/ontime_v2_rundown_and_time_manager_is_now_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142ro1f/ontime_v2_rundown_and_time_manager_is_now_free/", "subreddit_subscribers": 253033, "created_utc": 1686081900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm never clear on what counts as self promotion, so I won't include the link until someone tells I can. Besides that, I haven't run it anywhere but my own server so there are probably bugs.\n\nI made a web-based photo gallery for my home photos and I would like it if some people would help test it and share feedback.\n\nKey features: \n \n * It handles 200,000+ images and videos well, showing them all in a date-sorted scrolling wall of thumbnails, which you can click to view full sized. \n * \"Rewind\" button to show all photos taken on today's date in past years\n * Jump-to-date calendar popup to navigate your large photo library\n * Shows photo locations on a map, clicking on the map takes you to the photo\n * Can toggle map filter mode so that only photos on the current map view are shown in the scrollable area. \n * Reads tags from metadata and lets you filter photos by tags\n * Generates streamable copies of your videos so you can watch them all in the browser\n * Basic username and password protection\n * Progressive Web App so you can put an icon on your home page and it will cache thumbnails and resources\n * Lastly, it should be easy to set up\n\nThe code is a bit old-school. Written in PHP and JavaScript. It needs ffmpeg for video thumbnails and either vipsthumbnail, imagemagic or gd for image thumbnails.\n\nIt's 100% open source and I don't (and won't) have a business around it. I just put a lot of work in to it, think it's kind of cool and would love to get some feedback.", "author_fullname": "t2_k2sbwvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a few testers for a self-hosted image gallery project (free &amp; open source, of course)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143ajs9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686137094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m never clear on what counts as self promotion, so I won&amp;#39;t include the link until someone tells I can. Besides that, I haven&amp;#39;t run it anywhere but my own server so there are probably bugs.&lt;/p&gt;\n\n&lt;p&gt;I made a web-based photo gallery for my home photos and I would like it if some people would help test it and share feedback.&lt;/p&gt;\n\n&lt;p&gt;Key features: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It handles 200,000+ images and videos well, showing them all in a date-sorted scrolling wall of thumbnails, which you can click to view full sized. &lt;/li&gt;\n&lt;li&gt;&amp;quot;Rewind&amp;quot; button to show all photos taken on today&amp;#39;s date in past years&lt;/li&gt;\n&lt;li&gt;Jump-to-date calendar popup to navigate your large photo library&lt;/li&gt;\n&lt;li&gt;Shows photo locations on a map, clicking on the map takes you to the photo&lt;/li&gt;\n&lt;li&gt;Can toggle map filter mode so that only photos on the current map view are shown in the scrollable area. &lt;/li&gt;\n&lt;li&gt;Reads tags from metadata and lets you filter photos by tags&lt;/li&gt;\n&lt;li&gt;Generates streamable copies of your videos so you can watch them all in the browser&lt;/li&gt;\n&lt;li&gt;Basic username and password protection&lt;/li&gt;\n&lt;li&gt;Progressive Web App so you can put an icon on your home page and it will cache thumbnails and resources&lt;/li&gt;\n&lt;li&gt;Lastly, it should be easy to set up&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The code is a bit old-school. Written in PHP and JavaScript. It needs ffmpeg for video thumbnails and either vipsthumbnail, imagemagic or gd for image thumbnails.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s 100% open source and I don&amp;#39;t (and won&amp;#39;t) have a business around it. I just put a lot of work in to it, think it&amp;#39;s kind of cool and would love to get some feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143ajs9", "is_robot_indexable": true, "report_reasons": null, "author": "cspybbq", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143ajs9/looking_for_a_few_testers_for_a_selfhosted_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143ajs9/looking_for_a_few_testers_for_a_selfhosted_image/", "subreddit_subscribers": 253033, "created_utc": 1686137094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "after mullvad got rid of port forwarding, would it still be feasible to use qbittorent and prowlarr to hide my ip?", "author_fullname": "t2_4qrzevb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "mullvad and qbittorent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1432gqu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686109753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;after mullvad got rid of port forwarding, would it still be feasible to use qbittorent and prowlarr to hide my ip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1432gqu", "is_robot_indexable": true, "report_reasons": null, "author": "eldaniay", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1432gqu/mullvad_and_qbittorent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1432gqu/mullvad_and_qbittorent/", "subreddit_subscribers": 253033, "created_utc": 1686109753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi all,\n\nIn the past I've leaned heavily on Consul and DNSMasq for my service discovery and resolution, and I've also used PiHole as a stop-gap when I don't need auto-discovery, however I have a new project I'm working on and I'd love to be able to add DNS functionality \"out of the box\", but with service discovery in the same way that Traefik reads the docker socket.\n\nI've looked at CoreDNS, and that seems to do what I want for k8s and etcd, but I'm running neither of those things for this project as it is based on the [Balena.io](https://Balena.io) platform and docker-compose, meaning that I do not have access to the underlying physical host (a raspberry pi in this case).\n\nIn my head, the idea is that I feed this DNS resolver the domain (for example [`mydomain.com`](https://mydomain.com), and it then reads the docker socket and serves up records in the format &lt;container\\_name&gt;.mydomain.com based on the value it reads from Docker (in the same way that Consul does for Nomad or using [https://medium.com/@david.curran3/microservices-running-with-docker-and-consul-for-service-discovery-3c6d05b8030b](https://medium.com/@david.curran3/microservices-running-with-docker-and-consul-for-service-discovery-3c6d05b8030b))\n\nThe thing is, Consul feels like overkill for this particular application, so I'm hoping there's something else out there I can use!", "author_fullname": "t2_y0tbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightweight DNS Server that can be run in a docker container and also allows for service discovery of other containers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142stoi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686089480.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686084569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;In the past I&amp;#39;ve leaned heavily on Consul and DNSMasq for my service discovery and resolution, and I&amp;#39;ve also used PiHole as a stop-gap when I don&amp;#39;t need auto-discovery, however I have a new project I&amp;#39;m working on and I&amp;#39;d love to be able to add DNS functionality &amp;quot;out of the box&amp;quot;, but with service discovery in the same way that Traefik reads the docker socket.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked at CoreDNS, and that seems to do what I want for k8s and etcd, but I&amp;#39;m running neither of those things for this project as it is based on the &lt;a href=\"https://Balena.io\"&gt;Balena.io&lt;/a&gt; platform and docker-compose, meaning that I do not have access to the underlying physical host (a raspberry pi in this case).&lt;/p&gt;\n\n&lt;p&gt;In my head, the idea is that I feed this DNS resolver the domain (for example &lt;a href=\"https://mydomain.com\"&gt;&lt;code&gt;mydomain.com&lt;/code&gt;&lt;/a&gt;, and it then reads the docker socket and serves up records in the format &amp;lt;container\\_name&amp;gt;.mydomain.com based on the value it reads from Docker (in the same way that Consul does for Nomad or using &lt;a href=\"https://medium.com/@david.curran3/microservices-running-with-docker-and-consul-for-service-discovery-3c6d05b8030b\"&gt;https://medium.com/@david.curran3/microservices-running-with-docker-and-consul-for-service-discovery-3c6d05b8030b&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;The thing is, Consul feels like overkill for this particular application, so I&amp;#39;m hoping there&amp;#39;s something else out there I can use!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142stoi", "is_robot_indexable": true, "report_reasons": null, "author": "TheProffalken", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142stoi/lightweight_dns_server_that_can_be_run_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142stoi/lightweight_dns_server_that_can_be_run_in_a/", "subreddit_subscribers": 253033, "created_utc": 1686084569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi, I have the following task on my desk: I want to backup my emails (with attachments) in an automated fashion. As of now I am using gmail using the web interface via browser.\n\nOfficial google backups are quite cumbersome to deal with. I read that the easiest way to keep a copy is to have a mail client (like thunderbird) and keep a backup of it. I tested thunderbird and it works fine (it can really mirror gmail via IMAP and you can import/export the backups).\n\nHowever, I want something similar that can run on my server. In particular, I am looking for:\n\n* something that can pull changes automatically every N-hours (not when opening the app)\n* something that can be self-contained in a docker that run on a headless server\n* has a web interface (like zimbra/roundcube/...) just to check if everything is working. However, this is not mandatory, but just nice to have.\n\nAny recommended workflow here?", "author_fullname": "t2_9mioauuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking for suggestions: selfhosted server based mirror of gmail for backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1438gam", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686130241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have the following task on my desk: I want to backup my emails (with attachments) in an automated fashion. As of now I am using gmail using the web interface via browser.&lt;/p&gt;\n\n&lt;p&gt;Official google backups are quite cumbersome to deal with. I read that the easiest way to keep a copy is to have a mail client (like thunderbird) and keep a backup of it. I tested thunderbird and it works fine (it can really mirror gmail via IMAP and you can import/export the backups).&lt;/p&gt;\n\n&lt;p&gt;However, I want something similar that can run on my server. In particular, I am looking for:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;something that can pull changes automatically every N-hours (not when opening the app)&lt;/li&gt;\n&lt;li&gt;something that can be self-contained in a docker that run on a headless server&lt;/li&gt;\n&lt;li&gt;has a web interface (like zimbra/roundcube/...) just to check if everything is working. However, this is not mandatory, but just nice to have.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any recommended workflow here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1438gam", "is_robot_indexable": true, "report_reasons": null, "author": "-elmuz-", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1438gam/asking_for_suggestions_selfhosted_server_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1438gam/asking_for_suggestions_selfhosted_server_based/", "subreddit_subscribers": 253033, "created_utc": 1686130241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey everyone,  \ni recently created my Paperless instance and so far it works \"okay\" ;)  \n\n\nI have 2 Problems:  \n1. If i scan multiple Documents with Barcodes on each document, Paperless didnt split the PDF file.  \nThe Barcodes get recognised\n\nIn the Log the Barcode with Code128 are the ones from my Sticker.  \n\n\n    [2023-05-25 14:55:03,087] [INFO] [paperless.management.consumer] Adding /usr/src/paperless/consume/Gewerbe/Eingangs_Rechnung/20230525_134142.pdf to the task queue.\n    [2023-05-25 14:55:03,094] [INFO] [paperless.management.consumer] Adding /usr/src/paperless/consume/20230525_134142.pdf to the task queue.\n    [2023-05-25 14:55:07,891] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,004] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,165] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: 23E00517929\n    [2023-05-25 14:55:08,166] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00009\n    [2023-05-25 14:55:08,166] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,290] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: 23E00517929\n    [2023-05-25 14:55:08,291] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00009\n    [2023-05-25 14:55:08,291] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,331] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,458] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,522] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00010\n    [2023-05-25 14:55:08,523] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,648] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00010\n    [2023-05-25 14:55:08,649] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,668] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,796] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,849] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00011\n    [2023-05-25 14:55:08,850] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:08,989] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00011\n    [2023-05-25 14:55:08,989] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,014] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,136] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,196] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,306] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,338] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,441] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: VL0088449\n    [2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00012\n    [2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: VL0088449\n    [2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00012\n    [2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,689] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,779] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: BCD\n    002\n    1\n    SCT\n    \n    RG119608\n    [2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: RG119608\n    [2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00013\n    [2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: BCD\n    002\n    1\n    SCT\n    \n    RG119608\n    [2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: RG119608\n    [2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00013\n    [2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,091] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,166] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,257] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,326] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n    [2023-05-25 14:55:10,456] [INFO] [paperless.consumer] Consuming 20230525_134142.pdf\n    [2023-05-25 14:55:10,460] [DEBUG] [paperless.consumer] Detected mime type: application/pdf\n    [2023-05-25 14:55:10,462] [DEBUG] [paperless.consumer] Parser: RasterisedDocumentParser\n    [2023-05-25 14:55:10,464] [DEBUG] [paperless.consumer] Parsing 20230525_134142.pdf...\n    [2023-05-25 14:55:10,531] [INFO] [paperless.consumer] Consuming 20230525_134142.pdf\n    [2023-05-25 14:55:10,535] [DEBUG] [paperless.consumer] Detected mime type: application/pdf\n    [2023-05-25 14:55:10,536] [DEBUG] [paperless.consumer] Parser: RasterisedDocumentParser\n    [2023-05-25 14:55:10,539] [DEBUG] [paperless.consumer] Parsing 20230525_134142.pdf...\n    [2023-05-25 14:55:10,573] [DEBUG] [paperless.parsing.tesseract] Calling OCRmyPDF with args: {'input_file': PosixPath('/tmp/paperless/paperless-ngxzbpeluif/20230525_134142.pdf'), 'output_file': PosixPath('/tmp/paperless/paperless-1wqpexro/archive.pdf'), 'use_threads': True, 'jobs': '2', 'language': 'eng', 'output_type': 'pdfa', 'progress_bar': False, 'skip_text': True, 'clean': True, 'deskew': True, 'rotate_pages': True, 'rotate_pages_threshold': 12.0, 'sidecar': PosixPath('/tmp/paperless/paperless-1wqpexro/sidecar.txt')}\n    [2023-05-25 14:55:10,627] [DEBUG] [paperless.parsing.tesseract] Calling OCRmyPDF with args: {'input_file': PosixPath('/tmp/paperless/paperless-ngxu8thnhgd/20230525_134142.pdf'), 'output_file': PosixPath('/tmp/paperless/paperless-djjj8xny/archive.pdf'), 'use_threads': True, 'jobs': '2', 'language': 'eng', 'output_type': 'pdfa', 'progress_bar': False, 'skip_text': True, 'clean': True, 'deskew': True, 'rotate_pages': True, 'rotate_pages_threshold': 12.0, 'sidecar': PosixPath('/tmp/paperless/paperless-djjj8xny/sidecar.txt')}\n    [2023-05-25 14:56:11,255] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:11,267] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:11,273] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:11,277] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:59,398] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:59,433] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:59,442] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:56:59,455] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:57:07,981] [DEBUG] [paperless.parsing.tesseract] Using text from sidecar file\n    [2023-05-25 14:57:07,982] [DEBUG] [paperless.consumer] Generating thumbnail for 20230525_134142.pdf...\n    [2023-05-25 14:57:07,986] [DEBUG] [paperless.parsing] Execute: convert -density 300 -scale 500x5000&gt; -alpha remove -strip -auto-orient /tmp/paperless/paperless-djjj8xny/archive.pdf[0] /tmp/paperless/paperless-djjj8xny/convert.webp\n    [2023-05-25 14:57:08,009] [DEBUG] [paperless.parsing.tesseract] Using text from sidecar file\n    [2023-05-25 14:57:08,011] [DEBUG] [paperless.consumer] Generating thumbnail for 20230525_134142.pdf...\n    [2023-05-25 14:57:08,014] [DEBUG] [paperless.parsing] Execute: convert -density 300 -scale 500x5000&gt; -alpha remove -strip -auto-orient /tmp/paperless/paperless-1wqpexro/archive.pdf[0] /tmp/paperless/paperless-1wqpexro/convert.webp\n    [2023-05-25 14:57:09,952] [DEBUG] [paperless.consumer] Saving record to database\n    [2023-05-25 14:57:09,952] [DEBUG] [paperless.consumer] Creation date from st_mtime: 2023-05-25 14:55:10.529478+02:00\n    [2023-05-25 14:57:09,968] [DEBUG] [paperless.consumer] Saving record to database\n    [2023-05-25 14:57:09,968] [DEBUG] [paperless.consumer] Creation date from st_mtime: 2023-05-25 14:55:10.457478+02:00\n    [2023-05-25 14:57:10,125] [INFO] [paperless.handlers] Assigning document type Eingangs Rechnungen to 2023-05-25 20230525_134142\n    [2023-05-25 14:57:10,143] [INFO] [paperless.handlers] Tagging \"2023-05-25 20230525_134142\" with \"Gewerbe\"\n    [2023-05-25 14:57:10,161] [INFO] [paperless.handlers] Assigning storage path Gewerbe_Eingangsrechnung to 2023-05-25 20230525_134142\n    [2023-05-25 14:57:10,223] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:57:10,236] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n    [2023-05-25 14:57:10,238] [DEBUG] [paperless.consumer] Deleting file /tmp/paperless/paperless-ngxu8thnhgd/20230525_134142.pdf\n    [2023-05-25 14:57:10,241] [DEBUG] [paperless.parsing.tesseract] Deleting directory /tmp/paperless/paperless-djjj8xny\n    [2023-05-25 14:57:10,242] [INFO] [paperless.consumer] Document 2023-05-25 20230525_134142 consumption finished\n\nDid you know what i am doing wrong?  \n\n\nAnd my second \"Problem\" in that case i was thinking that Paperless put the Barcode ID in the Document ID automatically?  \nOr does it need more \"Training\" data to know that it should do that?  \n\n\nThanks for your Help ;)", "author_fullname": "t2_4vwsum16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paperless-ngx (Docker) Barcode problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "business", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1436e8p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Business Tools", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686122658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;br/&gt;\ni recently created my Paperless instance and so far it works &amp;quot;okay&amp;quot; ;)  &lt;/p&gt;\n\n&lt;p&gt;I have 2 Problems:&lt;br/&gt;\n1. If i scan multiple Documents with Barcodes on each document, Paperless didnt split the PDF file.&lt;br/&gt;\nThe Barcodes get recognised&lt;/p&gt;\n\n&lt;p&gt;In the Log the Barcode with Code128 are the ones from my Sticker.  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[2023-05-25 14:55:03,087] [INFO] [paperless.management.consumer] Adding /usr/src/paperless/consume/Gewerbe/Eingangs_Rechnung/20230525_134142.pdf to the task queue.\n[2023-05-25 14:55:03,094] [INFO] [paperless.management.consumer] Adding /usr/src/paperless/consume/20230525_134142.pdf to the task queue.\n[2023-05-25 14:55:07,891] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,004] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,165] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: 23E00517929\n[2023-05-25 14:55:08,166] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00009\n[2023-05-25 14:55:08,166] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,290] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: 23E00517929\n[2023-05-25 14:55:08,291] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00009\n[2023-05-25 14:55:08,291] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,331] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,458] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,522] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00010\n[2023-05-25 14:55:08,523] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,648] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00010\n[2023-05-25 14:55:08,649] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,668] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,796] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,849] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00011\n[2023-05-25 14:55:08,850] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:08,989] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00011\n[2023-05-25 14:55:08,989] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,014] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,136] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,196] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,306] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,338] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,441] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: VL0088449\n[2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00012\n[2023-05-25 14:55:09,533] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: VL0088449\n[2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00012\n[2023-05-25 14:55:09,629] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,689] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,779] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: BCD\n002\n1\nSCT\n\nRG119608\n[2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: RG119608\n[2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00013\n[2023-05-25 14:55:09,941] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type QRCODE found: BCD\n002\n1\nSCT\n\nRG119608\n[2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type CODE39 found: RG119608\n[2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Barcode of type CODE128 found: 00013\n[2023-05-25 14:55:10,021] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,091] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,166] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,257] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,326] [DEBUG] [paperless.barcodes] Scanning for barcodes using PYZBAR\n[2023-05-25 14:55:10,456] [INFO] [paperless.consumer] Consuming 20230525_134142.pdf\n[2023-05-25 14:55:10,460] [DEBUG] [paperless.consumer] Detected mime type: application/pdf\n[2023-05-25 14:55:10,462] [DEBUG] [paperless.consumer] Parser: RasterisedDocumentParser\n[2023-05-25 14:55:10,464] [DEBUG] [paperless.consumer] Parsing 20230525_134142.pdf...\n[2023-05-25 14:55:10,531] [INFO] [paperless.consumer] Consuming 20230525_134142.pdf\n[2023-05-25 14:55:10,535] [DEBUG] [paperless.consumer] Detected mime type: application/pdf\n[2023-05-25 14:55:10,536] [DEBUG] [paperless.consumer] Parser: RasterisedDocumentParser\n[2023-05-25 14:55:10,539] [DEBUG] [paperless.consumer] Parsing 20230525_134142.pdf...\n[2023-05-25 14:55:10,573] [DEBUG] [paperless.parsing.tesseract] Calling OCRmyPDF with args: {&amp;#39;input_file&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-ngxzbpeluif/20230525_134142.pdf&amp;#39;), &amp;#39;output_file&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-1wqpexro/archive.pdf&amp;#39;), &amp;#39;use_threads&amp;#39;: True, &amp;#39;jobs&amp;#39;: &amp;#39;2&amp;#39;, &amp;#39;language&amp;#39;: &amp;#39;eng&amp;#39;, &amp;#39;output_type&amp;#39;: &amp;#39;pdfa&amp;#39;, &amp;#39;progress_bar&amp;#39;: False, &amp;#39;skip_text&amp;#39;: True, &amp;#39;clean&amp;#39;: True, &amp;#39;deskew&amp;#39;: True, &amp;#39;rotate_pages&amp;#39;: True, &amp;#39;rotate_pages_threshold&amp;#39;: 12.0, &amp;#39;sidecar&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-1wqpexro/sidecar.txt&amp;#39;)}\n[2023-05-25 14:55:10,627] [DEBUG] [paperless.parsing.tesseract] Calling OCRmyPDF with args: {&amp;#39;input_file&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-ngxu8thnhgd/20230525_134142.pdf&amp;#39;), &amp;#39;output_file&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-djjj8xny/archive.pdf&amp;#39;), &amp;#39;use_threads&amp;#39;: True, &amp;#39;jobs&amp;#39;: &amp;#39;2&amp;#39;, &amp;#39;language&amp;#39;: &amp;#39;eng&amp;#39;, &amp;#39;output_type&amp;#39;: &amp;#39;pdfa&amp;#39;, &amp;#39;progress_bar&amp;#39;: False, &amp;#39;skip_text&amp;#39;: True, &amp;#39;clean&amp;#39;: True, &amp;#39;deskew&amp;#39;: True, &amp;#39;rotate_pages&amp;#39;: True, &amp;#39;rotate_pages_threshold&amp;#39;: 12.0, &amp;#39;sidecar&amp;#39;: PosixPath(&amp;#39;/tmp/paperless/paperless-djjj8xny/sidecar.txt&amp;#39;)}\n[2023-05-25 14:56:11,255] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:11,267] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:11,273] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:11,277] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:59,398] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:59,433] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:59,442] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:56:59,455] [DEBUG] [paperless.filehandling] Document has storage_path 4 (Default/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:57:07,981] [DEBUG] [paperless.parsing.tesseract] Using text from sidecar file\n[2023-05-25 14:57:07,982] [DEBUG] [paperless.consumer] Generating thumbnail for 20230525_134142.pdf...\n[2023-05-25 14:57:07,986] [DEBUG] [paperless.parsing] Execute: convert -density 300 -scale 500x5000&amp;gt; -alpha remove -strip -auto-orient /tmp/paperless/paperless-djjj8xny/archive.pdf[0] /tmp/paperless/paperless-djjj8xny/convert.webp\n[2023-05-25 14:57:08,009] [DEBUG] [paperless.parsing.tesseract] Using text from sidecar file\n[2023-05-25 14:57:08,011] [DEBUG] [paperless.consumer] Generating thumbnail for 20230525_134142.pdf...\n[2023-05-25 14:57:08,014] [DEBUG] [paperless.parsing] Execute: convert -density 300 -scale 500x5000&amp;gt; -alpha remove -strip -auto-orient /tmp/paperless/paperless-1wqpexro/archive.pdf[0] /tmp/paperless/paperless-1wqpexro/convert.webp\n[2023-05-25 14:57:09,952] [DEBUG] [paperless.consumer] Saving record to database\n[2023-05-25 14:57:09,952] [DEBUG] [paperless.consumer] Creation date from st_mtime: 2023-05-25 14:55:10.529478+02:00\n[2023-05-25 14:57:09,968] [DEBUG] [paperless.consumer] Saving record to database\n[2023-05-25 14:57:09,968] [DEBUG] [paperless.consumer] Creation date from st_mtime: 2023-05-25 14:55:10.457478+02:00\n[2023-05-25 14:57:10,125] [INFO] [paperless.handlers] Assigning document type Eingangs Rechnungen to 2023-05-25 20230525_134142\n[2023-05-25 14:57:10,143] [INFO] [paperless.handlers] Tagging &amp;quot;2023-05-25 20230525_134142&amp;quot; with &amp;quot;Gewerbe&amp;quot;\n[2023-05-25 14:57:10,161] [INFO] [paperless.handlers] Assigning storage path Gewerbe_Eingangsrechnung to 2023-05-25 20230525_134142\n[2023-05-25 14:57:10,223] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:57:10,236] [DEBUG] [paperless.filehandling] Document has storage_path 2 (Gewerbe_Eingangsrechnung/{correspondent}/{created_year}/{asn}-{title}) set\n[2023-05-25 14:57:10,238] [DEBUG] [paperless.consumer] Deleting file /tmp/paperless/paperless-ngxu8thnhgd/20230525_134142.pdf\n[2023-05-25 14:57:10,241] [DEBUG] [paperless.parsing.tesseract] Deleting directory /tmp/paperless/paperless-djjj8xny\n[2023-05-25 14:57:10,242] [INFO] [paperless.consumer] Document 2023-05-25 20230525_134142 consumption finished\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Did you know what i am doing wrong?  &lt;/p&gt;\n\n&lt;p&gt;And my second &amp;quot;Problem&amp;quot; in that case i was thinking that Paperless put the Barcode ID in the Document ID automatically?&lt;br/&gt;\nOr does it need more &amp;quot;Training&amp;quot; data to know that it should do that?  &lt;/p&gt;\n\n&lt;p&gt;Thanks for your Help ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0ac01dca-53ce-11ed-9fce-c6cd629e2d85", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1436e8p", "is_robot_indexable": true, "report_reasons": null, "author": "Heartbeats_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1436e8p/paperlessngx_docker_barcode_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1436e8p/paperlessngx_docker_barcode_problems/", "subreddit_subscribers": 253033, "created_utc": 1686122658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Looking for a good self hosted ticketing system that has:\n\n- Knowledge base before user can submit a ticket\n- Customizable ticketing submission page\n- And of course user friendly and reliable", "author_fullname": "t2_l4ihi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best self hosted docker ticketing systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142xkpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686096018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a good self hosted ticketing system that has:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Knowledge base before user can submit a ticket&lt;/li&gt;\n&lt;li&gt;Customizable ticketing submission page&lt;/li&gt;\n&lt;li&gt;And of course user friendly and reliable&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "142xkpx", "is_robot_indexable": true, "report_reasons": null, "author": "amcco1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/142xkpx/best_self_hosted_docker_ticketing_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/142xkpx/best_self_hosted_docker_ticketing_systems/", "subreddit_subscribers": 253033, "created_utc": 1686096018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am not a developer and I have tried the alternatives, but I've been looking for a simple paste-bin like app though that wasn't super complicated to set up but also supported syntax highlighting and more than just text files. I've tried some, but I really wanted a simple clean interface for me alone.\n\nCode here: [https://github.com/skibare87/postit](https://github.com/skibare87/postit)\n\nPostIt! is a simple paste manager that allows for text to be pasted in and saved to the filename selected. It also supports arbitrary file upload with the upload file button.\n\nThe editor supports syntax highlighting. All saved files appear at the bottom. Clicking on the file will download it. Right clicking will present a menu that will allow you to load the file back into the editor or delete the file from the server.\n\nIf a file already exists, the UI will ask for confirmation before overwriting.\n\nTo run:\n\n&gt;docker run -v ./files:/files -p 8080:80 skibare87/postit:latest\n\n&amp;#x200B;\n\n[Example Post It!](https://preview.redd.it/ufajgvq03n4b1.png?width=1504&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=341fa2ed9408b037af47f7d80755bd4b5597345f)\n\nNOTE: It is recommended to host this behind a reverse proxy with https support. Also, adding authentication is important if this is publicly available. There are **no** restrictions on file size or content, so use at your own risk.", "author_fullname": "t2_8s1uh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PostIt! Paste Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ufajgvq03n4b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecca045a1d81066dec2f3a2f5c00272095fdd0f4"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21a36f4ca7ba53dd4f70f9b85a0ef6c9ffb95e03"}, {"y": 254, "x": 320, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57f49ffdcf9f41e20b242750e99454da2c50f567"}, {"y": 508, "x": 640, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d28ef00b2980fa6d4f90485cb799612d064411be"}, {"y": 762, "x": 960, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cc563a2dfd9430bc87afafdbd1241a36e3851ef"}, {"y": 857, "x": 1080, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e774f867d5ebae8cfe5cd2bd62a0e6291e999f2"}], "s": {"y": 1194, "x": 1504, "u": "https://preview.redd.it/ufajgvq03n4b1.png?width=1504&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=341fa2ed9408b037af47f7d80755bd4b5597345f"}, "id": "ufajgvq03n4b1"}}, "name": "t3_143hpl9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nbDc1ax9pfqwps1CAOuy043ZhdIO7DEJGuKMACFGaBw.jpg", "edited": 1686162597.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686154973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a developer and I have tried the alternatives, but I&amp;#39;ve been looking for a simple paste-bin like app though that wasn&amp;#39;t super complicated to set up but also supported syntax highlighting and more than just text files. I&amp;#39;ve tried some, but I really wanted a simple clean interface for me alone.&lt;/p&gt;\n\n&lt;p&gt;Code here: &lt;a href=\"https://github.com/skibare87/postit\"&gt;https://github.com/skibare87/postit&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;PostIt! is a simple paste manager that allows for text to be pasted in and saved to the filename selected. It also supports arbitrary file upload with the upload file button.&lt;/p&gt;\n\n&lt;p&gt;The editor supports syntax highlighting. All saved files appear at the bottom. Clicking on the file will download it. Right clicking will present a menu that will allow you to load the file back into the editor or delete the file from the server.&lt;/p&gt;\n\n&lt;p&gt;If a file already exists, the UI will ask for confirmation before overwriting.&lt;/p&gt;\n\n&lt;p&gt;To run:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;docker run -v ./files:/files -p 8080:80 skibare87/postit:latest&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ufajgvq03n4b1.png?width=1504&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=341fa2ed9408b037af47f7d80755bd4b5597345f\"&gt;Example Post It!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;NOTE: It is recommended to host this behind a reverse proxy with https support. Also, adding authentication is important if this is publicly available. There are &lt;strong&gt;no&lt;/strong&gt; restrictions on file size or content, so use at your own risk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?auto=webp&amp;v=enabled&amp;s=f012a97f539dab29af98b4667a24354f21fd24a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9a4cbd14e79efbd2d09c538d13033293cd2588d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fce78c53d634c42e8bd12fa72da055fbcbb7ad25", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6608e690f5519df0e358445b2afe7cc55486975", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1ec374d72d132117e56c8702971bcb92a2d987", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57a65c8d55e45770e224047097926ca7a1c854e6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Xhe20Sbq9o6eEtkOlD3VuWYbYsiiuAoQiEmSeyIXsDs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fb9d08da5468b7bd7148ac94a6b420c95f45ff7", "width": 1080, "height": 540}], "variants": {}, "id": "n4AAY0I80BPwKPdyI3QUQjrHcSyPe5H53FvMy2LVMqw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143hpl9", "is_robot_indexable": true, "report_reasons": null, "author": "skibare87", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143hpl9/postit_paste_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143hpl9/postit_paste_manager/", "subreddit_subscribers": 253033, "created_utc": 1686154973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "TL;DR Latest version of Docker seems to be incompatible with LXC on Proxmox, and I need help to set up Docker, Compose, and Portainer on versions that do work in an LXC.\n\nI'm using Proxmox and I have an Ubuntu server 22.04.2 LXC. Following Docker's own install guides like [this one](https://docs.docker.com/engine/install/ubuntu/) as well as other guides like [this one](https://docs.fuga.cloud/how-to-install-portainer-docker-ui-manager-on-ubuntu-20.04-18.04-16.04) run into errors. Here is the error from trying a docker hello-world\n\n`sudo docker run hello-world`\n\n`docker: Error response from daemon: AppArmor enabled on system but the docker-default profile could not be loaded: running \\`/usr/sbin/apparmor\\_parser apparmor\\_parser -Kr /var/lib/docker/tmp/docker-default1024565780\\` failed with output: apparmor\\_parser: Unable to replace \"docker-default\".  Permission denied; attempted to load a profile while confined?\\`\n\n&amp;#x200B;\n\n`error: exit status 243.`\n\n`ERRO[0000] error waiting for container:`\n\nI have been chasing a rabbit hole of errors for a while, and bug posts like [this one](https://github.com/moby/moby/pull/44902) and [this one](https://github.com/moby/moby/issues/44900) as well as other posts [like this one](https://forum.proxmox.com/threads/priviledge-container-disabling-apparmor-does-not-work.122168/) have led me to believe that the problem I'm facing is that my LXC does not support Apparmor because as an LXC, it is using the kernel from the host OS (Proxmox) and the team behind one of the docker packages is trying to force Apparmor because of safety concerns. This seems to have come up at Docker v. 23, and was somehow sorted out for subsequent 23.x versions (apparently by making Apparmor no longer required, at least for the time being), but the latest install version is now 24.0.2 and the errors related to Apparmor are back. I'm all for safety, and if there's some way to get Apparmor actually working in Proxmox so that my LXC container can use it, that'd be great. But if not, I need a way to go back to an older version of docker, I guess.\n\nI don't know very much about installing packages that are older than the latest apt versions, so I can't figure out how to just install older versions of docker and related packages like portainer. That's why I'm asking here for help. Is there a CT Template somewhere (from a reputable source) that includes docker, compose, and portainer? Or could someone point me at a guide or even just the console command to install the working (older) versions of docker and its related packages? I can't just use latest because it seems that the problems are with the latest versions.\n\nThanks, and I hope this also helps anyone else who is banging their heads against the wall trying to get Docker to work in an LXC container in Portainer, and following guides that used to work no longer works because of these Apparmor errors.", "author_fullname": "t2_5jpmatk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for LXC-friendly Docker install instructions for use with Compose and Portainer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1436ekf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686122691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR Latest version of Docker seems to be incompatible with LXC on Proxmox, and I need help to set up Docker, Compose, and Portainer on versions that do work in an LXC.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Proxmox and I have an Ubuntu server 22.04.2 LXC. Following Docker&amp;#39;s own install guides like &lt;a href=\"https://docs.docker.com/engine/install/ubuntu/\"&gt;this one&lt;/a&gt; as well as other guides like &lt;a href=\"https://docs.fuga.cloud/how-to-install-portainer-docker-ui-manager-on-ubuntu-20.04-18.04-16.04\"&gt;this one&lt;/a&gt; run into errors. Here is the error from trying a docker hello-world&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;sudo docker run hello-world&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;docker: Error response from daemon: AppArmor enabled on system but the docker-default profile could not be loaded: running \\&lt;/code&gt;/usr/sbin/apparmor_parser apparmor_parser -Kr /var/lib/docker/tmp/docker-default1024565780` failed with output: apparmor_parser: Unable to replace &amp;quot;docker-default&amp;quot;.  Permission denied; attempted to load a profile while confined?`&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;error: exit status 243.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ERRO[0000] error waiting for container:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I have been chasing a rabbit hole of errors for a while, and bug posts like &lt;a href=\"https://github.com/moby/moby/pull/44902\"&gt;this one&lt;/a&gt; and &lt;a href=\"https://github.com/moby/moby/issues/44900\"&gt;this one&lt;/a&gt; as well as other posts &lt;a href=\"https://forum.proxmox.com/threads/priviledge-container-disabling-apparmor-does-not-work.122168/\"&gt;like this one&lt;/a&gt; have led me to believe that the problem I&amp;#39;m facing is that my LXC does not support Apparmor because as an LXC, it is using the kernel from the host OS (Proxmox) and the team behind one of the docker packages is trying to force Apparmor because of safety concerns. This seems to have come up at Docker v. 23, and was somehow sorted out for subsequent 23.x versions (apparently by making Apparmor no longer required, at least for the time being), but the latest install version is now 24.0.2 and the errors related to Apparmor are back. I&amp;#39;m all for safety, and if there&amp;#39;s some way to get Apparmor actually working in Proxmox so that my LXC container can use it, that&amp;#39;d be great. But if not, I need a way to go back to an older version of docker, I guess.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know very much about installing packages that are older than the latest apt versions, so I can&amp;#39;t figure out how to just install older versions of docker and related packages like portainer. That&amp;#39;s why I&amp;#39;m asking here for help. Is there a CT Template somewhere (from a reputable source) that includes docker, compose, and portainer? Or could someone point me at a guide or even just the console command to install the working (older) versions of docker and its related packages? I can&amp;#39;t just use latest because it seems that the problems are with the latest versions.&lt;/p&gt;\n\n&lt;p&gt;Thanks, and I hope this also helps anyone else who is banging their heads against the wall trying to get Docker to work in an LXC container in Portainer, and following guides that used to work no longer works because of these Apparmor errors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1436ekf", "is_robot_indexable": true, "report_reasons": null, "author": "ResearchTLDR", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1436ekf/looking_for_lxcfriendly_docker_install/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1436ekf/looking_for_lxcfriendly_docker_install/", "subreddit_subscribers": 253033, "created_utc": 1686122691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_7q1bce91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discourse people are seeking feedback on ActivityPub Implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_143jhhk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qABCSDfBFcOuNmhPtiKkJ0-v43VbSJ_vigKCIBQLYqA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686159126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "socialhub.activitypub.rocks", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://socialhub.activitypub.rocks/t/adding-federation-support-to-discourse/2966/7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/msR6u55Wb86P0ae7ZuJwWBL-BcjrrlidBo8Y8TA0YEs.jpg?auto=webp&amp;v=enabled&amp;s=ab24c5ddf8fea0854a88c5dca82cd8d110dbc680", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/msR6u55Wb86P0ae7ZuJwWBL-BcjrrlidBo8Y8TA0YEs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d1064ee804c3b8df336dce8e3954595fb8aa953d", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/msR6u55Wb86P0ae7ZuJwWBL-BcjrrlidBo8Y8TA0YEs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e6f798733409ac00c8312860d8db09a51d288fb", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/msR6u55Wb86P0ae7ZuJwWBL-BcjrrlidBo8Y8TA0YEs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b4ff8bb2aded9e1eba6994f87dbd45ade14da7d", "width": 320, "height": 320}], "variants": {}, "id": "XpHSqUx4eA4-2hD8IQku15kljP6HrTzsLdik-4IeT9I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "143jhhk", "is_robot_indexable": true, "report_reasons": null, "author": "ex_06", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143jhhk/discourse_people_are_seeking_feedback_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://socialhub.activitypub.rocks/t/adding-federation-support-to-discourse/2966/7", "subreddit_subscribers": 253033, "created_utc": 1686159126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I've got Invidious working via Docker, but some of the configuration options through config.yml don't seem to be taking effect.\n\nI copied ./config/config.example.yml to ./config/config.yml and restarted the container, but it doesn't look like anything changed.  Do I have it in the wrong place, or do I need to adjust something else?\n\n**SOLVED**\n\n**This poorly documented, but the config.yml file seems to do nothing at all for docker.  You have to add them all through environmental variables.**", "author_fullname": "t2_3kutd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Invidious (docker) config path?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143hs3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686159447.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686155143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got Invidious working via Docker, but some of the configuration options through config.yml don&amp;#39;t seem to be taking effect.&lt;/p&gt;\n\n&lt;p&gt;I copied ./config/config.example.yml to ./config/config.yml and restarted the container, but it doesn&amp;#39;t look like anything changed.  Do I have it in the wrong place, or do I need to adjust something else?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SOLVED&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This poorly documented, but the config.yml file seems to do nothing at all for docker.  You have to add them all through environmental variables.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143hs3u", "is_robot_indexable": true, "report_reasons": null, "author": "JeffR47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143hs3u/invidious_docker_config_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143hs3u/invidious_docker_config_path/", "subreddit_subscribers": 253033, "created_utc": 1686155143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi everyone, I hope you're doing well. I recently changed my isp and they're only providing ipv6 rather than ipv4. Can I continue self host using ipv6? Thank you.", "author_fullname": "t2_71rz1kxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I Self Host Using ipv6?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143hkpn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686154660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I hope you&amp;#39;re doing well. I recently changed my isp and they&amp;#39;re only providing ipv6 rather than ipv4. Can I continue self host using ipv6? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143hkpn", "is_robot_indexable": true, "report_reasons": null, "author": "Kaziopu123", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143hkpn/can_i_self_host_using_ipv6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143hkpn/can_i_self_host_using_ipv6/", "subreddit_subscribers": 253033, "created_utc": 1686154660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have a proxmox server running on a ssd and a 5tb raid where's the data directory located and stuff like that.\n\nI have a jellyfin server running on one container and nextcloud on another one. The video files are stored on /data/smb on the host machine and are shared to the jellyfin container. Nextcloud stores its files on /data/nextcloud but I can't copy or move them to another directory (eg. /data/smb). I tried to change the permission of the nextcloud files directory so the host machine can access but that didn't work.\n\nCan someone help me with that?", "author_fullname": "t2_vl9z9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proxmox copying files to another lxc container", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143bt4z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686140672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a proxmox server running on a ssd and a 5tb raid where&amp;#39;s the data directory located and stuff like that.&lt;/p&gt;\n\n&lt;p&gt;I have a jellyfin server running on one container and nextcloud on another one. The video files are stored on /data/smb on the host machine and are shared to the jellyfin container. Nextcloud stores its files on /data/nextcloud but I can&amp;#39;t copy or move them to another directory (eg. /data/smb). I tried to change the permission of the nextcloud files directory so the host machine can access but that didn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;Can someone help me with that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143bt4z", "is_robot_indexable": true, "report_reasons": null, "author": "FAKERHOCH10000", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143bt4z/proxmox_copying_files_to_another_lxc_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143bt4z/proxmox_copying_files_to_another_lxc_container/", "subreddit_subscribers": 253033, "created_utc": 1686140672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": " Hello everyone! \n\nI'm looking for a self-hosted application (free if possible) that will serve as a dashboard for administrators and users. The idea of the dashboard is as follows:\n\n* Users will be able to deploy WordPress and other CMS.\n* Configure the database.\n* Have an FTP account and similar features.\n\nThe main idea is that I have a ton of servers running in a large cluster, and I want to create hosting solutions for people who are willing to pay for it. It's pretty straightforward: people pay, and they get a web server to host their website!\n\nI believe everyone will understand what I want, so I won't explain further, I suppose! Anyway, if my explanation is unclear, please let me know. English isn't my first language, so maybe I'm not explaining myself very well!\n\nThank you to everyone who is willing to help! \n\n&amp;#x200B;\n\nHave a nice day!", "author_fullname": "t2_uc9dwrce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Admin &amp; client panel for web hosting solutions !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "Automation", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143ar4e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Automation", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686137691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a self-hosted application (free if possible) that will serve as a dashboard for administrators and users. The idea of the dashboard is as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Users will be able to deploy WordPress and other CMS.&lt;/li&gt;\n&lt;li&gt;Configure the database.&lt;/li&gt;\n&lt;li&gt;Have an FTP account and similar features.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The main idea is that I have a ton of servers running in a large cluster, and I want to create hosting solutions for people who are willing to pay for it. It&amp;#39;s pretty straightforward: people pay, and they get a web server to host their website!&lt;/p&gt;\n\n&lt;p&gt;I believe everyone will understand what I want, so I won&amp;#39;t explain further, I suppose! Anyway, if my explanation is unclear, please let me know. English isn&amp;#39;t my first language, so maybe I&amp;#39;m not explaining myself very well!&lt;/p&gt;\n\n&lt;p&gt;Thank you to everyone who is willing to help! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Have a nice day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "13cfcd28-7e68-11e9-8ad0-0edb644073ce", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143ar4e", "is_robot_indexable": true, "report_reasons": null, "author": "zamk-paw", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143ar4e/admin_client_panel_for_web_hosting_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143ar4e/admin_client_panel_for_web_hosting_solutions/", "subreddit_subscribers": 253033, "created_utc": 1686137691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Modelz LLM is an inference server that facilitates the utilization of open-source large language models (LLMs), such as FastChat, LLaMA, and ChatGLM, on either **local or cloud-based** environments with **OpenAI compatible API**.\n\n&amp;#x200B;\n\n[https://github.com/tensorchord/modelz-llm](https://github.com/tensorchord/modelz-llm)", "author_fullname": "t2_ilf6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelz-LLM: Self-hosted OpenAI API server for open-source LLMs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1438ix8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686130501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Modelz LLM is an inference server that facilitates the utilization of open-source large language models (LLMs), such as FastChat, LLaMA, and ChatGLM, on either &lt;strong&gt;local or cloud-based&lt;/strong&gt; environments with &lt;strong&gt;OpenAI compatible API&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/tensorchord/modelz-llm\"&gt;https://github.com/tensorchord/modelz-llm&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?auto=webp&amp;v=enabled&amp;s=373a5ef545b2671e44545bed62421cc8fe0e9d7e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c2ebe04b164c70fcadc16bca6bec91b9e49b231", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=673df2f54ba05c19d51b1556a47f81fede149f3c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84d338fe01704f838e784e21c044f75736a4bba0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3efb07e61d65c421a598354e2504ccff415d46ab", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=416872f9c028e8b2d2e771344138f4ef53cca1e0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/kZAfMGGeWTJMJrAT_T01IWeWfMNbVwESo5Oyv99EsWQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91cb15ed6465f65ea33b300cb3ab134b4eb7c49c", "width": 1080, "height": 540}], "variants": {}, "id": "_biArIOsGILTg1zviydwznt0jzmt5J4n2cbmfLa6JgI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1438ix8", "is_robot_indexable": true, "report_reasons": null, "author": "gaocegege", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1438ix8/modelzllm_selfhosted_openai_api_server_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1438ix8/modelzllm_selfhosted_openai_api_server_for/", "subreddit_subscribers": 253033, "created_utc": 1686130501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm testing Tailscale here but it seems not enough for my needs\n\nI want to expose multiple services running locally on a machine. All of them use the same IP but changes the port. Like: 192.168.00.00:**1001**, 192.168.00.00:**1002**, 192.168.00.00:**1003**.....\n\n1001 to onwards\n\n\\---\n\nNeed to make it very \"automatic\" and simple  since I'll send some people to do it too.\n\n**So, something like just need to it one time and then all this ports are acessible, just changing the port at the end of the address.**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rj9x0k4jbk4b1.png?width=1050&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7d3dd15e340c130e321e0d71b2e8e6fae9871d28", "author_fullname": "t2_ic3g3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expose Multiple Localhost Online", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "vpn", "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rj9x0k4jbk4b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e37ace35d9edc8a3505ca333148ab86c341d0eaf"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f29a209cef2e43c7c5bf836b252b49df8573419"}, {"y": 148, "x": 320, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ba8749e63ce748333199b20174914ed49b12d05"}, {"y": 297, "x": 640, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bfd665b9fdcac3618ab2a9561151b4e20ea1a21"}, {"y": 446, "x": 960, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64f79ce5a9c83a51e4b12f12f4eebbd83f4f6527"}], "s": {"y": 488, "x": 1050, "u": "https://preview.redd.it/rj9x0k4jbk4b1.png?width=1050&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7d3dd15e340c130e321e0d71b2e8e6fae9871d28"}, "id": "rj9x0k4jbk4b1"}}, "name": "t3_143828t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "VPN", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cnUCsX14kRr0sv9cfAHKjiFhyjkUx1mG8wOlHmXP3Zs.jpg", "edited": 1686129113.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686128841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m testing Tailscale here but it seems not enough for my needs&lt;/p&gt;\n\n&lt;p&gt;I want to expose multiple services running locally on a machine. All of them use the same IP but changes the port. Like: 192.168.00.00:&lt;strong&gt;1001&lt;/strong&gt;, 192.168.00.00:&lt;strong&gt;1002&lt;/strong&gt;, 192.168.00.00:&lt;strong&gt;1003&lt;/strong&gt;.....&lt;/p&gt;\n\n&lt;p&gt;1001 to onwards&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Need to make it very &amp;quot;automatic&amp;quot; and simple  since I&amp;#39;ll send some people to do it too.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So, something like just need to it one time and then all this ports are acessible, just changing the port at the end of the address.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rj9x0k4jbk4b1.png?width=1050&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7d3dd15e340c130e321e0d71b2e8e6fae9871d28\"&gt;https://preview.redd.it/rj9x0k4jbk4b1.png?width=1050&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7d3dd15e340c130e321e0d71b2e8e6fae9871d28&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7e5c2d58-7e68-11e9-9418-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "143828t", "is_robot_indexable": true, "report_reasons": null, "author": "FelipeNS", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/143828t/expose_multiple_localhost_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/143828t/expose_multiple_localhost_online/", "subreddit_subscribers": 253033, "created_utc": 1686128841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I've searched the self-hosting fora for quite a while now to find an open-source and free (we're a non-profit self-managed daycare) tool for docker that helps me to\n\n- define a workflow (sequence of activities, possibly with conditional forks)\n- assign roles/users to individual activities\n- have notifications and dashboards (my assignments, all assignments overview, etc.)\n\nI tried several Kanban tools (Taiga, Openproject, Nextcloud Deck, ...) but they seemingly lack the definition of sequential dependencies. Camunda seems like an overkill.\n\nUse case: a document (or any object, really, could also be a phone call triggered workflow) must go through several process steps. Each process step is assigned to a different person. The process steps have interdependencies (2 after 1, 3 in parallel). Users should be notified via webhook or similar if they something to do.\n\nDoes anyone have a good proposal?\n\nEdit: Just checking out Vikunja\nEdit 2: Vikunja does let you define task dependencies, but only ad hoc, not as a template.", "author_fullname": "t2_5y85mh93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow / Taskflow / Process Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "Automation", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1437w22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Automation", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686134688.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686128239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve searched the self-hosting fora for quite a while now to find an open-source and free (we&amp;#39;re a non-profit self-managed daycare) tool for docker that helps me to&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;define a workflow (sequence of activities, possibly with conditional forks)&lt;/li&gt;\n&lt;li&gt;assign roles/users to individual activities&lt;/li&gt;\n&lt;li&gt;have notifications and dashboards (my assignments, all assignments overview, etc.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I tried several Kanban tools (Taiga, Openproject, Nextcloud Deck, ...) but they seemingly lack the definition of sequential dependencies. Camunda seems like an overkill.&lt;/p&gt;\n\n&lt;p&gt;Use case: a document (or any object, really, could also be a phone call triggered workflow) must go through several process steps. Each process step is assigned to a different person. The process steps have interdependencies (2 after 1, 3 in parallel). Users should be notified via webhook or similar if they something to do.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good proposal?&lt;/p&gt;\n\n&lt;p&gt;Edit: Just checking out Vikunja\nEdit 2: Vikunja does let you define task dependencies, but only ad hoc, not as a template.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "13cfcd28-7e68-11e9-8ad0-0edb644073ce", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1437w22", "is_robot_indexable": true, "report_reasons": null, "author": "schnillermann", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1437w22/workflow_taskflow_process_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1437w22/workflow_taskflow_process_tool/", "subreddit_subscribers": 253033, "created_utc": 1686128239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I\u2019m looking for a software for download hls or m3u8 with limit bandwidth, can you recommend something? \n\nI see a few but only bowser plug ins, not program with limit speed. \n\nThank you.", "author_fullname": "t2_5x8m1n0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HLS download with bandwidth limit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "cloudstorage", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1437109", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud Storage", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686125015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for a software for download hls or m3u8 with limit bandwidth, can you recommend something? &lt;/p&gt;\n\n&lt;p&gt;I see a few but only bowser plug ins, not program with limit speed. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bc5f6346-7e67-11e9-a0fe-0e631119683e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1437109", "is_robot_indexable": true, "report_reasons": null, "author": "dotinho", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1437109/hls_download_with_bandwidth_limit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1437109/hls_download_with_bandwidth_limit/", "subreddit_subscribers": 253033, "created_utc": 1686125015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi,\n\nIm looking for a way to have a system where authenticated users can upload a file that is automatically stored in a folder of my server. The reason for this is to allow multiple people to upload gave saves into the servers saves folder so that any of the few people i trust to make saves and maintain the server can upload a file without my help. I originally was looking for a client that would download files from discord to a set folder but havent found much. Any ideas/help would be appreciated thanks", "author_fullname": "t2_97up9a10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File upload/sharing system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1436qx7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686123980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Im looking for a way to have a system where authenticated users can upload a file that is automatically stored in a folder of my server. The reason for this is to allow multiple people to upload gave saves into the servers saves folder so that any of the few people i trust to make saves and maintain the server can upload a file without my help. I originally was looking for a client that would download files from discord to a set folder but havent found much. Any ideas/help would be appreciated thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1436qx7", "is_robot_indexable": true, "report_reasons": null, "author": "Commiccannon", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/1436qx7/file_uploadsharing_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/1436qx7/file_uploadsharing_system/", "subreddit_subscribers": 253033, "created_utc": 1686123980.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}