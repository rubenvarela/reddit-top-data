{"kind": "Listing", "data": {"after": "t3_1426hhj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_brkxjomi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019ve had the definition wrong this entire time\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 125, "top_awarded_type": null, "hide_score": false, "name": "t3_1420fjz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 496, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 496, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IFuK97ynhfsSPbLctWG4Nu9kNdsbn1tYITeoa2-9rxo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686017984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9uviprh35b4b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9uviprh35b4b1.jpg?auto=webp&amp;v=enabled&amp;s=b854077dd9f4cc89f247e44d63a04c45f3e13183", "width": 556, "height": 500}, "resolutions": [{"url": "https://preview.redd.it/9uviprh35b4b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc60879835dacd0fc93b0a0944ee45ce943074f", "width": 108, "height": 97}, {"url": "https://preview.redd.it/9uviprh35b4b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81a30ee8d32ecc13cb413e31f972976c6fae5ad9", "width": 216, "height": 194}, {"url": "https://preview.redd.it/9uviprh35b4b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fcfb0b91c224266641f631f8d29d0b65971bf9d", "width": 320, "height": 287}], "variants": {}, "id": "U3wE6gNxgunkDMWgxqPlc8ScfOmNpg9hno-IJl-hp7E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1420fjz", "is_robot_indexable": true, "report_reasons": null, "author": "Straight_House8628", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1420fjz/ive_had_the_definition_wrong_this_entire_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9uviprh35b4b1.jpg", "subreddit_subscribers": 109272, "created_utc": 1686017984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On paper, I have a great job.  It's at a great tech company that pays very well for my area, and I enjoy working with my colleagues.  I've also been there for more than 2.5 years.\n\n\n\n\nHowever, for almost a year at work now, my team's responsibilities have gotten less interesting to me.  When I started, the core of my responsibilities involved your usual data pipeline development and optimizing existing code.  However, data engineers were also given the opportunity to work on collaborative projects in the area of backend engineering and devops, which I often did.  I found all of my previous work very interesting.\n\n\n\n\nMy team is now at the point where our data pipelines just need the very occasional maintenance, so much of our responsibilities now involve advising stakeholders and attending meetings to provide various metrics.  I'm in meetings for a large part of my day, and the coding I do now is pretty repetitive.  Since my company hired a lot in 2021-2022, there is also less of an opportunity now to work between teams, and we lost a lot of the culture that encouraged working on projects between teams.\n\n\n\n\nI feel like I am at a great company with great coworkers, I just don't have the opportunity to grow as an engineer.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it unreasonable to want to find a new job only because my current work is not interesting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142fmvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686057059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On paper, I have a great job.  It&amp;#39;s at a great tech company that pays very well for my area, and I enjoy working with my colleagues.  I&amp;#39;ve also been there for more than 2.5 years.&lt;/p&gt;\n\n&lt;p&gt;However, for almost a year at work now, my team&amp;#39;s responsibilities have gotten less interesting to me.  When I started, the core of my responsibilities involved your usual data pipeline development and optimizing existing code.  However, data engineers were also given the opportunity to work on collaborative projects in the area of backend engineering and devops, which I often did.  I found all of my previous work very interesting.&lt;/p&gt;\n\n&lt;p&gt;My team is now at the point where our data pipelines just need the very occasional maintenance, so much of our responsibilities now involve advising stakeholders and attending meetings to provide various metrics.  I&amp;#39;m in meetings for a large part of my day, and the coding I do now is pretty repetitive.  Since my company hired a lot in 2021-2022, there is also less of an opportunity now to work between teams, and we lost a lot of the culture that encouraged working on projects between teams.&lt;/p&gt;\n\n&lt;p&gt;I feel like I am at a great company with great coworkers, I just don&amp;#39;t have the opportunity to grow as an engineer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142fmvl", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/142fmvl/is_it_unreasonable_to_want_to_find_a_new_job_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142fmvl/is_it_unreasonable_to_want_to_find_a_new_job_only/", "subreddit_subscribers": 109272, "created_utc": 1686057059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backfills in Data &amp; Machine Learning: A Primer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_142pvzv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cY9YAqmchEDvDN7MKJRCyRg2S15QsVLI2muUxBcZ5rs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686077853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/backfills-in-ml", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?auto=webp&amp;v=enabled&amp;s=4be0ce4eeaac7d4e33577ce23de9a3ec845f98fa", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dddc1c128bf06f3c4f1c97d2205c47b70e089659", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75fd6f93b598ecb352f3043d765d23efaa46c21c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=add58ccdb0ca6087ca1287080374257733c4c249", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a4849a00c4a14fd421297606b59638a6c2df7bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49e8248a72bbe10fd0fd967a7fb25991c81785fe", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/IQXE-E9nspj7HmxNyVCAFw3mqZhacj7cyoRWveMg6aY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b53957688a5061bddc29f0044cfa3e94c567e0e1", "width": 1080, "height": 567}], "variants": {}, "id": "Aa6Wm30sENcyJNse8PbIo81dnSMAEWTl17sCuqG_RIs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "142pvzv", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142pvzv/backfills_in_data_machine_learning_a_primer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/backfills-in-ml", "subreddit_subscribers": 109272, "created_utc": 1686077853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all\n\nNot sure if this is the right forum. I work in an industry service organisation that recently started moving its business and project data into Snowflake. The process of data ingestion is still new and being developed - a lot of the project data is Excel spreadsheets. \n\nAs a data analyst, I am finding Snowflake fast and easy to use, but a pathway to data documentation seems missing. Our organisation apparently has a plan for this but it's still in the planning stage. \n\nFor example, yesterday I came across sensor timestamp data that was stored \"No Time Zone\". I had no way to know what the time zone was. After asking around I was told the sensor generating the data uses UTC. However this information is not stored in Snowflake and I see no obvious way to store it there (even if I had permission to add documentation). Other columns also lack documentation, such as temperatures that could be in Celsius of Fahrenheit.\n\nI'm wondering how your company handles data documentation for data in something like Snowflake. Do you have a unified approach or tool? Do you store the documentation in the database itself?\n\nThanks!", "author_fullname": "t2_221frg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your company handle data documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142si63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686083836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;Not sure if this is the right forum. I work in an industry service organisation that recently started moving its business and project data into Snowflake. The process of data ingestion is still new and being developed - a lot of the project data is Excel spreadsheets. &lt;/p&gt;\n\n&lt;p&gt;As a data analyst, I am finding Snowflake fast and easy to use, but a pathway to data documentation seems missing. Our organisation apparently has a plan for this but it&amp;#39;s still in the planning stage. &lt;/p&gt;\n\n&lt;p&gt;For example, yesterday I came across sensor timestamp data that was stored &amp;quot;No Time Zone&amp;quot;. I had no way to know what the time zone was. After asking around I was told the sensor generating the data uses UTC. However this information is not stored in Snowflake and I see no obvious way to store it there (even if I had permission to add documentation). Other columns also lack documentation, such as temperatures that could be in Celsius of Fahrenheit.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering how your company handles data documentation for data in something like Snowflake. Do you have a unified approach or tool? Do you store the documentation in the database itself?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142si63", "is_robot_indexable": true, "report_reasons": null, "author": "si_wo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142si63/how_does_your_company_handle_data_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142si63/how_does_your_company_handle_data_documentation/", "subreddit_subscribers": 109272, "created_utc": 1686083836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is HUDI a template against delta lake? What is one thing that it solves that the current models dont? Most importantly, when should one think of implementing HUDI , i mean the actual used case ?\n\nThe documentation out on their site is pain to understand. Pardon me if this has been already discussed here but yes, an expert's perspective about HUDI would be highly appreciated.", "author_fullname": "t2_nyd96q0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm not understanding the purpose of HUDI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1426wgc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686035780.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686034648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is HUDI a template against delta lake? What is one thing that it solves that the current models dont? Most importantly, when should one think of implementing HUDI , i mean the actual used case ?&lt;/p&gt;\n\n&lt;p&gt;The documentation out on their site is pain to understand. Pardon me if this has been already discussed here but yes, an expert&amp;#39;s perspective about HUDI would be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1426wgc", "is_robot_indexable": true, "report_reasons": null, "author": "theaitribe", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1426wgc/im_not_understanding_the_purpose_of_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1426wgc/im_not_understanding_the_purpose_of_hudi/", "subreddit_subscribers": 109272, "created_utc": 1686034648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, I have user subscriptions. The status and attributes change over time (trial vs paid, expiration dates, active/inactive, primary focus... etc) and I receive daily snapshots of this information.\n\nfact_subscription is easy, it has all of the measures. Daily data.\n\ndim_subscription seems like it should be just the active state of the subscription attributes.  One row per subscription.\n\nI want to store the changing information, but really don't know what to call it.\n\n\nscd_subscription?\n\ntype2_subscription?\n\ndim_daily_subscription?\n\nWhat do you guys find is the cleanest way to keep up with these types of tables?", "author_fullname": "t2_ebaw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call your SCD/Type 2 tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142nu8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686073909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I have user subscriptions. The status and attributes change over time (trial vs paid, expiration dates, active/inactive, primary focus... etc) and I receive daily snapshots of this information.&lt;/p&gt;\n\n&lt;p&gt;fact_subscription is easy, it has all of the measures. Daily data.&lt;/p&gt;\n\n&lt;p&gt;dim_subscription seems like it should be just the active state of the subscription attributes.  One row per subscription.&lt;/p&gt;\n\n&lt;p&gt;I want to store the changing information, but really don&amp;#39;t know what to call it.&lt;/p&gt;\n\n&lt;p&gt;scd_subscription?&lt;/p&gt;\n\n&lt;p&gt;type2_subscription?&lt;/p&gt;\n\n&lt;p&gt;dim_daily_subscription?&lt;/p&gt;\n\n&lt;p&gt;What do you guys find is the cleanest way to keep up with these types of tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142nu8s", "is_robot_indexable": true, "report_reasons": null, "author": "sois", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142nu8s/what_do_you_call_your_scdtype_2_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142nu8s/what_do_you_call_your_scdtype_2_tables/", "subreddit_subscribers": 109272, "created_utc": 1686073909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are using the AWS ecosystem and currently dumping some big files in S3 and we want to transform those files and load them into MySQL (AWS - RDS).\n\nWe are currently considering using AWS Glue, but the documentation is a little confusing and the notebooks are not working for me. I am trying to create a remote development process connecting the S3 and glue to my local VSCode and use it to build and test code. This sounds like a complicated process for me. Is there a better approach that doesn't cost much?", "author_fullname": "t2_3yclh0lo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ETL workflow for doing transformations on data present in S3 and loading it to MySQL table.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14255vr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686029900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are using the AWS ecosystem and currently dumping some big files in S3 and we want to transform those files and load them into MySQL (AWS - RDS).&lt;/p&gt;\n\n&lt;p&gt;We are currently considering using AWS Glue, but the documentation is a little confusing and the notebooks are not working for me. I am trying to create a remote development process connecting the S3 and glue to my local VSCode and use it to build and test code. This sounds like a complicated process for me. Is there a better approach that doesn&amp;#39;t cost much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14255vr", "is_robot_indexable": true, "report_reasons": null, "author": "vishalw007", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14255vr/best_etl_workflow_for_doing_transformations_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14255vr/best_etl_workflow_for_doing_transformations_on/", "subreddit_subscribers": 109272, "created_utc": 1686029900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Yet another data orchestration post. I'm trying to decide on which tool to introduce into our data team to standardise data pipelines. Our team is pretty small- 2 Data Engineers and 1 Data Analyst. Our main data sources are from our customer databases and systems that load files into ADLS and 3rd party SaaS tools. We have various ways of ingesting data into SQL Server (legacy) and Snowflake, stored procedures, bespoke application that runs on Azure Function App, Snowpipe from blob. \n\nWe're on Azure, with Snowflake, and are introducing DBT into the mix, along with an orchestrator. Admittedly, I don't have too much experience working with an orchestration tool. Looking for one that doesn't require too much maintenance, is easy to manage, not too expensive and has good integrations with our stack.\n\nWe're currently evaluating Airflow, Prefect, Dagster\n\n* Airflow: Easy to build pipelines, Flexible, good integrations. I've heard it can be difficult to manage and is slightly outdated and bloated.\n* Prefect: Like Airflow but easy to manage. Free Prefect Cloud option looks appealing for our small team but not sure how soon we'd run into limitations which force license upgrades. \n* Dagster: Love the concept and can see how you can build really powerful, robust pipelines. Just a bit of a      learning curve. Good integrations.\n\nAnyone have any recommendations for our case? Thanks in advance!", "author_fullname": "t2_4di18tzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding on an Orchestrator: Airflow, Prefect &amp; Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142trzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686086754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yet another data orchestration post. I&amp;#39;m trying to decide on which tool to introduce into our data team to standardise data pipelines. Our team is pretty small- 2 Data Engineers and 1 Data Analyst. Our main data sources are from our customer databases and systems that load files into ADLS and 3rd party SaaS tools. We have various ways of ingesting data into SQL Server (legacy) and Snowflake, stored procedures, bespoke application that runs on Azure Function App, Snowpipe from blob. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on Azure, with Snowflake, and are introducing DBT into the mix, along with an orchestrator. Admittedly, I don&amp;#39;t have too much experience working with an orchestration tool. Looking for one that doesn&amp;#39;t require too much maintenance, is easy to manage, not too expensive and has good integrations with our stack.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently evaluating Airflow, Prefect, Dagster&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Airflow: Easy to build pipelines, Flexible, good integrations. I&amp;#39;ve heard it can be difficult to manage and is slightly outdated and bloated.&lt;/li&gt;\n&lt;li&gt;Prefect: Like Airflow but easy to manage. Free Prefect Cloud option looks appealing for our small team but not sure how soon we&amp;#39;d run into limitations which force license upgrades. &lt;/li&gt;\n&lt;li&gt;Dagster: Love the concept and can see how you can build really powerful, robust pipelines. Just a bit of a      learning curve. Good integrations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyone have any recommendations for our case? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142trzs", "is_robot_indexable": true, "report_reasons": null, "author": "TshirtJefferson", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142trzs/deciding_on_an_orchestrator_airflow_prefect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142trzs/deciding_on_an_orchestrator_airflow_prefect/", "subreddit_subscribers": 109272, "created_utc": 1686086754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here's the situation, our data team works on multiple different projects for different business units, and all regularly need some form of automation which we orchestrate through Airflow. Right now, we centralize deployment/hosting of Airflow DAGs on AWS MWAA, and we have a central Airflow repo that syncs to MWAA's backend S3 as a CICD.\n\nWhile this works, it means that whenever a developer is working on a project, they're split between two repos, the actual project repo &amp; the central Airflow repo. Ideally, we would want a situation where developers can work in a single repo per project (which means being able to include Airflow logic alongside their business logic), however, because MWAA can only use a single requirements.txt for workers, we'd likely end up with package conflicts between different projects, also it's not clear how we could make use of shared Airflow resources like custom operators?\n\nThe reason we don't want to decentralize MWAA as well is that we do want a central view of all DAGs across projects and MWAA is expensive (\\~$1,000 per month per env) and wasteful to setup for just one or two DAGs.", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to centralize Airflow deployment/hosting from decentralized repositories?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142oy7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686076006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s the situation, our data team works on multiple different projects for different business units, and all regularly need some form of automation which we orchestrate through Airflow. Right now, we centralize deployment/hosting of Airflow DAGs on AWS MWAA, and we have a central Airflow repo that syncs to MWAA&amp;#39;s backend S3 as a CICD.&lt;/p&gt;\n\n&lt;p&gt;While this works, it means that whenever a developer is working on a project, they&amp;#39;re split between two repos, the actual project repo &amp;amp; the central Airflow repo. Ideally, we would want a situation where developers can work in a single repo per project (which means being able to include Airflow logic alongside their business logic), however, because MWAA can only use a single requirements.txt for workers, we&amp;#39;d likely end up with package conflicts between different projects, also it&amp;#39;s not clear how we could make use of shared Airflow resources like custom operators?&lt;/p&gt;\n\n&lt;p&gt;The reason we don&amp;#39;t want to decentralize MWAA as well is that we do want a central view of all DAGs across projects and MWAA is expensive (~$1,000 per month per env) and wasteful to setup for just one or two DAGs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142oy7u", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142oy7u/how_to_centralize_airflow_deploymenthosting_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142oy7u/how_to_centralize_airflow_deploymenthosting_from/", "subreddit_subscribers": 109272, "created_utc": 1686076006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, so title really says all I currently have 6+ years of experience in DE. BS in CS and MS in Data Science. I have been applying for primarily DE jobs and SE jobs.\n\nI would say my rates are about for every 50 or so jobs applied I get about 5 or so first round/phone screenings. So, I am getting interviews but in those 5 first round/phone screenings 0-1 continue with me. Which is pretty annoying because I cannot seem to comprehend on how one can make a decision to not continue the process just from a 10-30 min phone call - without the ability to show my skill set in a technical manner. To me, considering my education and years of experience, that means other applicants must have at least an MS or PhD and many more years of experience than me?\n\nIs anybody else having troubles getting a job atm in the industry? Family/friends have been telling me the tech market is doing pretty bad atm is this true? My issue is that I am getting interviews so it almost makes me think otherwise like why would I be getting interviews if the market is in a bad place? Are companies just filling in quotas/reqs and interviewing people and not actually hiring/filling the roles?\n\nWhat are some other jobs somebody in DE can easily change to? I have been applying to data analyst related jobs recently, any other recommendations?\n\nI will likely post my resume another time to ask for some advice on changes I can make but just wanted to hear the thoughts of others.", "author_fullname": "t2_9vildhm3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recently laid off, getting interviews but not landing anything - thoughts on current state of job opportunities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142a3n1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686050888.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686043555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so title really says all I currently have 6+ years of experience in DE. BS in CS and MS in Data Science. I have been applying for primarily DE jobs and SE jobs.&lt;/p&gt;\n\n&lt;p&gt;I would say my rates are about for every 50 or so jobs applied I get about 5 or so first round/phone screenings. So, I am getting interviews but in those 5 first round/phone screenings 0-1 continue with me. Which is pretty annoying because I cannot seem to comprehend on how one can make a decision to not continue the process just from a 10-30 min phone call - without the ability to show my skill set in a technical manner. To me, considering my education and years of experience, that means other applicants must have at least an MS or PhD and many more years of experience than me?&lt;/p&gt;\n\n&lt;p&gt;Is anybody else having troubles getting a job atm in the industry? Family/friends have been telling me the tech market is doing pretty bad atm is this true? My issue is that I am getting interviews so it almost makes me think otherwise like why would I be getting interviews if the market is in a bad place? Are companies just filling in quotas/reqs and interviewing people and not actually hiring/filling the roles?&lt;/p&gt;\n\n&lt;p&gt;What are some other jobs somebody in DE can easily change to? I have been applying to data analyst related jobs recently, any other recommendations?&lt;/p&gt;\n\n&lt;p&gt;I will likely post my resume another time to ask for some advice on changes I can make but just wanted to hear the thoughts of others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "142a3n1", "is_robot_indexable": true, "report_reasons": null, "author": "ReasonableOpinion40", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142a3n1/recently_laid_off_getting_interviews_but_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142a3n1/recently_laid_off_getting_interviews_but_not/", "subreddit_subscribers": 109272, "created_utc": 1686043555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I don't understand it, on the resource group my user that's creating the access connector is the owner and I even added Databricks Resource Provider as an owner to the resource group too, I have no clue what else I can do to get the authorisation working, has anyone ran into this issue before?\n\nThanks everyone!", "author_fullname": "t2_56o0g58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Databricks User not authorized (403) error when creating Access Connector for Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142wlbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686093393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t understand it, on the resource group my user that&amp;#39;s creating the access connector is the owner and I even added Databricks Resource Provider as an owner to the resource group too, I have no clue what else I can do to get the authorisation working, has anyone ran into this issue before?&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142wlbp", "is_robot_indexable": true, "report_reasons": null, "author": "IG-55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142wlbp/azure_databricks_user_not_authorized_403_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142wlbp/azure_databricks_user_not_authorized_403_error/", "subreddit_subscribers": 109272, "created_utc": 1686093393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Blog] Modern Data Architecture: Data Lakes, Data Lakehouses and Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_142hvm3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p92sma0n5QT9bNqNV10xSWZOBqQ_BLs-vft5oV9UZ4U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686061770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/pulse/dremio-modern-data-architecture-lakes-lakehouses-mesh-alex-merced", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?auto=webp&amp;v=enabled&amp;s=69797846034b3ce8e4f0a8bb2bf679651b6032a8", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7cf650d471314bab7e6c637b4951db7927856d28", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab1ad6015da62b3b5a656a37e027014fa3e2b00d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a309836d3f9157cd2484e144026660ed34abeff", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c6089a0a8a2291a0e36c0e48d415f68ed761913", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d004a6260959d1e74589182881a7cab2ea84dd0d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/M0Mmxel-fRn_znsBGILJ2GSM2Eo1HMfm_foQym-Z8wc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9d94d3e8b7467079a6e2e0f216b4f12e593d010", "width": 1080, "height": 565}], "variants": {}, "id": "sam90P28s5CV067X6he2za03vQHZF4DA_RzyAIf2U1I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "142hvm3", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142hvm3/blog_modern_data_architecture_data_lakes_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/pulse/dremio-modern-data-architecture-lakes-lakehouses-mesh-alex-merced", "subreddit_subscribers": 109272, "created_utc": 1686061770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ok Reddit, help me figure out what I am. \n\nI\u2019ve got about 6 years of SQL experience, querying, inserting, deleting, and updating data in live production SSMS databases on a daily basis. \n\nI\u2019ve migrated data from one db to another with a matching schema with various methods, but the most streamlined of which included a Python script/program to retrieve the data from database(s) make any necessary manipulations with mapping files or utilizing pandas data frame merges, and inserting it into a new database. \n\nIt\u2019s as terrifying as it sounds. \n\nI\u2019ve been in a new role the last year that is far less technical and far more business, mostly using sql to build looker dashboards, and it\u2019s boring. I\u2019m hoping I can move into DE but my concern is my skills will fall short as I have almost no experience with big data/cloud infrastructure, and really have no clue how to bridge that gap. \n\nAny inputs on what kind of positions I could fit my current skill set into? My previous position seems fairly niche, and I can\u2019t seem to find something similar.", "author_fullname": "t2_fgr2zl76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m a data\u2026 wannabe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142wx4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686094249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok Reddit, help me figure out what I am. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got about 6 years of SQL experience, querying, inserting, deleting, and updating data in live production SSMS databases on a daily basis. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve migrated data from one db to another with a matching schema with various methods, but the most streamlined of which included a Python script/program to retrieve the data from database(s) make any necessary manipulations with mapping files or utilizing pandas data frame merges, and inserting it into a new database. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s as terrifying as it sounds. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been in a new role the last year that is far less technical and far more business, mostly using sql to build looker dashboards, and it\u2019s boring. I\u2019m hoping I can move into DE but my concern is my skills will fall short as I have almost no experience with big data/cloud infrastructure, and really have no clue how to bridge that gap. &lt;/p&gt;\n\n&lt;p&gt;Any inputs on what kind of positions I could fit my current skill set into? My previous position seems fairly niche, and I can\u2019t seem to find something similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "142wx4e", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway682749273", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142wx4e/im_a_data_wannabe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142wx4e/im_a_data_wannabe/", "subreddit_subscribers": 109272, "created_utc": 1686094249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs!\n\nI have my virtual onsite in 1-2 weeks for the Data Engineering role at Meta. I was wondering if anyone was also interviewing and would be interested in doing some Product Sense and Data Modeling mock interviews (we can both act as interviewers). If you are a Data Scientist or Product Manager who is also interviewing at Meta, feel free to also reach out. Let me know in a comment or DM.", "author_fullname": "t2_k349c07v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Partner for Meta Mock Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142sdcw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686083528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs!&lt;/p&gt;\n\n&lt;p&gt;I have my virtual onsite in 1-2 weeks for the Data Engineering role at Meta. I was wondering if anyone was also interviewing and would be interested in doing some Product Sense and Data Modeling mock interviews (we can both act as interviewers). If you are a Data Scientist or Product Manager who is also interviewing at Meta, feel free to also reach out. Let me know in a comment or DM.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "142sdcw", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent-Flight775", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142sdcw/partner_for_meta_mock_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142sdcw/partner_for_meta_mock_interview/", "subreddit_subscribers": 109272, "created_utc": 1686083528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone! :)  \n\n\nThat's my first time working on Google Cloud and I have to move data between buckets and from buckets to BigQuery.   \n\n\nI've extensive experience with Spark (on-prem Hadoop and Databricks) and no experience at all with Beam (powering Dataflow). Also, I'm not afraid of learning.  But, I'm indeed trying to reduce:  \n\\- cognitive load  \n\\- infra management  \n\\- cloud costs  \n\n\nSpark can follow a bucket for new files and has a connector to BigQuery. So I'll need:  \n\\- Dataproc  \n\\- Buckets for checkpointing\n\nBeam can follow a bucket for new files, so it should be the same as Spark. I suppose it needs some sort of checkpointing as well, or maybe it works better with new files notification to Pub/Sub?  \n\n\n**So, I'm trying to compare and get to a decision:**  \n1. How straightforward is it to use (and to monitor!) Dataflow vs Dataproc?  \n2. Is Dataflow worth the time spent learning Beam?  \n3. If my transformations are simple, maybe I should just go for new files notification to Pub/Sub and plain code using Google Storage read and BigQuery write APIs?  \n4. How to estimate cloud costs so I can compare them?  \n5. More considerations?  \n\n\nThank you :)", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataflow or Spark on Dataproc?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142l4u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686068280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone! :)  &lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s my first time working on Google Cloud and I have to move data between buckets and from buckets to BigQuery.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve extensive experience with Spark (on-prem Hadoop and Databricks) and no experience at all with Beam (powering Dataflow). Also, I&amp;#39;m not afraid of learning.  But, I&amp;#39;m indeed trying to reduce:&lt;br/&gt;\n- cognitive load&lt;br/&gt;\n- infra management&lt;br/&gt;\n- cloud costs  &lt;/p&gt;\n\n&lt;p&gt;Spark can follow a bucket for new files and has a connector to BigQuery. So I&amp;#39;ll need:&lt;br/&gt;\n- Dataproc&lt;br/&gt;\n- Buckets for checkpointing&lt;/p&gt;\n\n&lt;p&gt;Beam can follow a bucket for new files, so it should be the same as Spark. I suppose it needs some sort of checkpointing as well, or maybe it works better with new files notification to Pub/Sub?  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So, I&amp;#39;m trying to compare and get to a decision:&lt;/strong&gt;&lt;br/&gt;\n1. How straightforward is it to use (and to monitor!) Dataflow vs Dataproc?&lt;br/&gt;\n2. Is Dataflow worth the time spent learning Beam?&lt;br/&gt;\n3. If my transformations are simple, maybe I should just go for new files notification to Pub/Sub and plain code using Google Storage read and BigQuery write APIs?&lt;br/&gt;\n4. How to estimate cloud costs so I can compare them?&lt;br/&gt;\n5. More considerations?  &lt;/p&gt;\n\n&lt;p&gt;Thank you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142l4u8", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142l4u8/dataflow_or_spark_on_dataproc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142l4u8/dataflow_or_spark_on_dataproc/", "subreddit_subscribers": 109272, "created_utc": 1686068280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've been really looking forward to spark connect and finally being able to work in my local IDE as well. However, it seems to me that currently the delta library is not working with spark connect. However, in this [video](https://www.youtube.com/live/vTd3OqDzjuo?feature=share) the lead developer mentions the delta package specifically and that is possible using protobuf. Has someone made it work so far and what are your experiences with spark connect?", "author_fullname": "t2_bk0fqe9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark connect + Delta", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142fphr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686057215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been really looking forward to spark connect and finally being able to work in my local IDE as well. However, it seems to me that currently the delta library is not working with spark connect. However, in this &lt;a href=\"https://www.youtube.com/live/vTd3OqDzjuo?feature=share\"&gt;video&lt;/a&gt; the lead developer mentions the delta package specifically and that is possible using protobuf. Has someone made it work so far and what are your experiences with spark connect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?auto=webp&amp;v=enabled&amp;s=2d05cf1f77c1ab48b175910d05cf18e34f2d70f6", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac263a64861a0f0d0770aa07379ccd824a27bf8b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=530b0395e538a5b25103a7e93a7b5cac942009ab", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db96dfc1e20f3f895b6caa12fd4b9c4debb0c1d7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1663804cacf85d4bf7e1768ab7e491e8eed2c44f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5986f6f7dd6adcfbf015ec40b1d8783f07a778af", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/uuEDnN6MuTZ98hsAbub6IMBKG8EdIwZJ6foFWFNpZr4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35819345822a28c9077066d605e32da792ac236b", "width": 1080, "height": 607}], "variants": {}, "id": "fZjMsp4g602eFrlNRwRND3O_r9aeS5AIqnfKK3OsiBA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142fphr", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Bake_783", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142fphr/spark_connect_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142fphr/spark_connect_delta/", "subreddit_subscribers": 109272, "created_utc": 1686057215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nFirst of all, I thank God for being part of this amazing data community. Whether knowingly or unknowingly, this subreddit has helped me a lot.\n\nI'm planning to change jobs and target the position of a senior data engineer. Currently, I am a data engineer in my organization. I am also working on side projects with the goal of showcasing real impact on my CV and to potential employers.\n\nIn my current side project:\n\nI am extracting data from an API, transforming it using Spark, and loading it into PostgreSQL. The end product will be built on Streamlit.\n\nI am also working with Airflow as an orchestrator, although I have never worked with it before. Additionally, I am exploring Great Expectations.\n\nI have two questions:\n\n1) Does the above project look good for a candidate applying for a senior data engineer role?\n\n2) What factors should be considered when building a side project as a senior data engineer?\n\nPlease let me know if you have any suggestions or feedback. Thank you.", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side project as a senior data engineer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142768o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686035378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;First of all, I thank God for being part of this amazing data community. Whether knowingly or unknowingly, this subreddit has helped me a lot.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to change jobs and target the position of a senior data engineer. Currently, I am a data engineer in my organization. I am also working on side projects with the goal of showcasing real impact on my CV and to potential employers.&lt;/p&gt;\n\n&lt;p&gt;In my current side project:&lt;/p&gt;\n\n&lt;p&gt;I am extracting data from an API, transforming it using Spark, and loading it into PostgreSQL. The end product will be built on Streamlit.&lt;/p&gt;\n\n&lt;p&gt;I am also working with Airflow as an orchestrator, although I have never worked with it before. Additionally, I am exploring Great Expectations.&lt;/p&gt;\n\n&lt;p&gt;I have two questions:&lt;/p&gt;\n\n&lt;p&gt;1) Does the above project look good for a candidate applying for a senior data engineer role?&lt;/p&gt;\n\n&lt;p&gt;2) What factors should be considered when building a side project as a senior data engineer?&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you have any suggestions or feedback. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142768o", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142768o/side_project_as_a_senior_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142768o/side_project_as_a_senior_data_engineer/", "subreddit_subscribers": 109272, "created_utc": 1686035378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need advice on picking a cloud data storage/server (AWS, Azure, Google Cloud) to store roughly 50GB of data in parquet, csv, and pickle. I run python scripts hourly and daily to update them. Which service is faster/cheaper/reliable. I run batch scripts hourly and daily to update that data and then push to Salesforce, so the data flow is non-stop. I am thinking of storing the python scripts into the cloud to have the whole ETL process in cloud. Please give me advice. I am new to Cloud Engineering/Architecture", "author_fullname": "t2_ue7511np", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142wfjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686092994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need advice on picking a cloud data storage/server (AWS, Azure, Google Cloud) to store roughly 50GB of data in parquet, csv, and pickle. I run python scripts hourly and daily to update them. Which service is faster/cheaper/reliable. I run batch scripts hourly and daily to update that data and then push to Salesforce, so the data flow is non-stop. I am thinking of storing the python scripts into the cloud to have the whole ETL process in cloud. Please give me advice. I am new to Cloud Engineering/Architecture&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142wfjj", "is_robot_indexable": true, "report_reasons": null, "author": "datatulga", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142wfjj/i_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142wfjj/i_need_advice/", "subreddit_subscribers": 109272, "created_utc": 1686092994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Excuse my ignorance, this still is well before my time. Trying to learn as much as quick as possible.\n\nNeed to land mainframe data to raw S3 bucket. A couple of questions:\n\n1. Could Informatica be used to accomplish this? If not, what are other simple alternatives?\n2. I'm assuming it would be best practice to ingest this data in a more friendly format (e.g., JSON). Would there be a significant amount of effort required to do this?\n3. Any other general suggestions/resources/experiences would be greatly appreciated.", "author_fullname": "t2_1fco9rqs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting VSAM files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142sjv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686083949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excuse my ignorance, this still is well before my time. Trying to learn as much as quick as possible.&lt;/p&gt;\n\n&lt;p&gt;Need to land mainframe data to raw S3 bucket. A couple of questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Could Informatica be used to accomplish this? If not, what are other simple alternatives?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m assuming it would be best practice to ingest this data in a more friendly format (e.g., JSON). Would there be a significant amount of effort required to do this?&lt;/li&gt;\n&lt;li&gt;Any other general suggestions/resources/experiences would be greatly appreciated.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142sjv8", "is_robot_indexable": true, "report_reasons": null, "author": "gencoupethrowaway69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142sjv8/ingesting_vsam_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142sjv8/ingesting_vsam_files/", "subreddit_subscribers": 109272, "created_utc": 1686083949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any sites or programs catered to this?", "author_fullname": "t2_kggujlwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Volunteer opportunities for DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142pq4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686077475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any sites or programs catered to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "142pq4x", "is_robot_indexable": true, "report_reasons": null, "author": "kitkat_predict", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142pq4x/volunteer_opportunities_for_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142pq4x/volunteer_opportunities_for_de/", "subreddit_subscribers": 109272, "created_utc": 1686077475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you think having both of them together in a architecture is an added benefit ? Given that the lakehouse is not performant at some point ? \n\nIf you have both the components, then i wonder if i have to stick to medallion architecture, then all the marts are in DWH , i hope this will be a ideal solution", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse architecture + Data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142jtdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686065755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you think having both of them together in a architecture is an added benefit ? Given that the lakehouse is not performant at some point ? &lt;/p&gt;\n\n&lt;p&gt;If you have both the components, then i wonder if i have to stick to medallion architecture, then all the marts are in DWH , i hope this will be a ideal solution&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "142jtdu", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142jtdu/lakehouse_architecture_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142jtdu/lakehouse_architecture_data_warehouse/", "subreddit_subscribers": 109272, "created_utc": 1686065755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any ETL tools that extract data from SaaS platforms such as Salesforce and Hubspot in a streaming / CDC fashion? Running Fivetran in high frequency gets costly. Any other suggestions on how to get \u201crealtime\u201d data from these common Business SaaS tools. Use case is to do automation from these change events", "author_fullname": "t2_cmjwin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming ETL tools for SaaS products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142i57z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686062337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any ETL tools that extract data from SaaS platforms such as Salesforce and Hubspot in a streaming / CDC fashion? Running Fivetran in high frequency gets costly. Any other suggestions on how to get \u201crealtime\u201d data from these common Business SaaS tools. Use case is to do automation from these change events&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142i57z", "is_robot_indexable": true, "report_reasons": null, "author": "tiltaltti", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142i57z/streaming_etl_tools_for_saas_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142i57z/streaming_etl_tools_for_saas_products/", "subreddit_subscribers": 109272, "created_utc": 1686062337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently working as a Data Scientist in a small, relatively new Data Science team (&lt;10 data scientists) as part of a larger company (&lt;1000 employees). We've grown quickly in the last year and are noticing that we're severely lacking in data engineering skills. While my boss is trying his best to get us a proper data engineer, I have gotten sign-off to get some cross-training to tide us over. \n\nSince we're almost exclusively working with structured data, I want to focus on SQL databases (we're running MySQL at the moment) and data modeling, as that's where we'd probably get the most bang for our buck.  \nI do have some basic knowledge in SQL: I can do simple JOINs and have heard of keys and normalization, but beyond that, things get hazy fast.\n\nWhat's the best way for me to get a decent foundation? Is there a book I should absolutely read? A coursera/udemy course? A lecture I should attend in University? Some 5-day crash-course Bootcamp?\n\nIs there something that I should definitely learn that I don't yet know I should learn?\n\nThanks a lot for your insights!", "author_fullname": "t2_uda7ln5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross-Training from Data Scientist, how and what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142fqh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686057272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working as a Data Scientist in a small, relatively new Data Science team (&amp;lt;10 data scientists) as part of a larger company (&amp;lt;1000 employees). We&amp;#39;ve grown quickly in the last year and are noticing that we&amp;#39;re severely lacking in data engineering skills. While my boss is trying his best to get us a proper data engineer, I have gotten sign-off to get some cross-training to tide us over. &lt;/p&gt;\n\n&lt;p&gt;Since we&amp;#39;re almost exclusively working with structured data, I want to focus on SQL databases (we&amp;#39;re running MySQL at the moment) and data modeling, as that&amp;#39;s where we&amp;#39;d probably get the most bang for our buck.&lt;br/&gt;\nI do have some basic knowledge in SQL: I can do simple JOINs and have heard of keys and normalization, but beyond that, things get hazy fast.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way for me to get a decent foundation? Is there a book I should absolutely read? A coursera/udemy course? A lecture I should attend in University? Some 5-day crash-course Bootcamp?&lt;/p&gt;\n\n&lt;p&gt;Is there something that I should definitely learn that I don&amp;#39;t yet know I should learn?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "142fqh5", "is_robot_indexable": true, "report_reasons": null, "author": "invalidConsciousness", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142fqh5/crosstraining_from_data_scientist_how_and_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142fqh5/crosstraining_from_data_scientist_how_and_what/", "subreddit_subscribers": 109272, "created_utc": 1686057272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically wanna stream some data to bigquery from a database using rest api, how to?\nI know I cant stream it through rest api obviously so have to incrementally do it by applying filters etc.\n\nNow my question is how to do this? Using \ncloud functions?", "author_fullname": "t2_6g2a5pmw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to schedule load from database (no access) through REST API -&gt; bigquery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_142algz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686044882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically wanna stream some data to bigquery from a database using rest api, how to?\nI know I cant stream it through rest api obviously so have to incrementally do it by applying filters etc.&lt;/p&gt;\n\n&lt;p&gt;Now my question is how to do this? Using \ncloud functions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "142algz", "is_robot_indexable": true, "report_reasons": null, "author": "Entertainer-Subject", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/142algz/how_to_schedule_load_from_database_no_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/142algz/how_to_schedule_load_from_database_no_access/", "subreddit_subscribers": 109272, "created_utc": 1686044882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am willing to learn from stratch how to data modeling entities in an IoT context in order to map thoese entities in a relational database (or another paradigm of database if more suitable).\n\nLet me define the entities in their gerarchy:\n\n\\- Plants\n\n\\- Machines\n\n\\- Sensors\n\nThe sensors output data with different frenquencies. Should I have a table with all measures from a single machine resulting in a sparse table or should I have a table for each sensor containing the measurements? Where should I start about designing this?\n\nFeel free to source me references or books also, thanks!", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to data modeling in IoT context", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1426hhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686033496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am willing to learn from stratch how to data modeling entities in an IoT context in order to map thoese entities in a relational database (or another paradigm of database if more suitable).&lt;/p&gt;\n\n&lt;p&gt;Let me define the entities in their gerarchy:&lt;/p&gt;\n\n&lt;p&gt;- Plants&lt;/p&gt;\n\n&lt;p&gt;- Machines&lt;/p&gt;\n\n&lt;p&gt;- Sensors&lt;/p&gt;\n\n&lt;p&gt;The sensors output data with different frenquencies. Should I have a table with all measures from a single machine resulting in a sparse table or should I have a table for each sensor containing the measurements? Where should I start about designing this?&lt;/p&gt;\n\n&lt;p&gt;Feel free to source me references or books also, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1426hhj", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1426hhj/how_to_data_modeling_in_iot_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1426hhj/how_to_data_modeling_in_iot_context/", "subreddit_subscribers": 109272, "created_utc": 1686033496.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}