{"kind": "Listing", "data": {"after": "t3_149cwx3", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For the last 5 years or so I have been conducting impact evaluations in the development sector (mostly NGOs or research orgs) looking at impact of social programs on health, education and environment. This involves everything from collecting primary data, cleaning the data, data wrangling, conducting exploratory and causal analysis and data visualization.\n\nUltimately the insights generated by the analysis are very rarely taken up by those who can make the programs better and improve millions of lives (subjectively). The data teams are mostly under-resourced and aren't paid well. Those who have to implement the programs have little to no technical expertise and in most cases no will to make actual changes. \n\nMy hypothesis is that things might be better in for-profit companies where insights can help bring in more profit or atleast cut losses. I understand that this might be a - grass is greener on the other side - situation so want to understand if people face similar issues on the \"other side\". How often are you able to derive useful insights from the data at hand? How often are your recommendations used to make product related decisions? Are other stakeholders amenable to results that aren't favourable for the business?", "author_fullname": "t2_c37rfuyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the grass greener on the other side?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148ss5c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686699084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the last 5 years or so I have been conducting impact evaluations in the development sector (mostly NGOs or research orgs) looking at impact of social programs on health, education and environment. This involves everything from collecting primary data, cleaning the data, data wrangling, conducting exploratory and causal analysis and data visualization.&lt;/p&gt;\n\n&lt;p&gt;Ultimately the insights generated by the analysis are very rarely taken up by those who can make the programs better and improve millions of lives (subjectively). The data teams are mostly under-resourced and aren&amp;#39;t paid well. Those who have to implement the programs have little to no technical expertise and in most cases no will to make actual changes. &lt;/p&gt;\n\n&lt;p&gt;My hypothesis is that things might be better in for-profit companies where insights can help bring in more profit or atleast cut losses. I understand that this might be a - grass is greener on the other side - situation so want to understand if people face similar issues on the &amp;quot;other side&amp;quot;. How often are you able to derive useful insights from the data at hand? How often are your recommendations used to make product related decisions? Are other stakeholders amenable to results that aren&amp;#39;t favourable for the business?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148ss5c", "is_robot_indexable": true, "report_reasons": null, "author": "False-Apricot-2755", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148ss5c/is_the_grass_greener_on_the_other_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148ss5c/is_the_grass_greener_on_the_other_side/", "subreddit_subscribers": 924697, "created_utc": 1686699084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best algorithms and what are the purposes thag we can use Machine learning and deep learning algorithms in banking sector ?", "author_fullname": "t2_wasnzue9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science in banking sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148z8eg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686719771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best algorithms and what are the purposes thag we can use Machine learning and deep learning algorithms in banking sector ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148z8eg", "is_robot_indexable": true, "report_reasons": null, "author": "kavinda_uthsuka97", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148z8eg/data_science_in_banking_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148z8eg/data_science_in_banking_sector/", "subreddit_subscribers": 924697, "created_utc": 1686719771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?", "author_fullname": "t2_cqm8clcx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning form Data Scientist to Product Analyst.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1497dmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686747878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1497dmz", "is_robot_indexable": true, "report_reasons": null, "author": "Conscious-Rush-9646", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "subreddit_subscribers": 924697, "created_utc": 1686747878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Want to stay on top of all new data science research that is coming out. Does anyone have ways to find research papers (best ways to find them)? Just want to make sure I do not fall behind and find reading the papers pretty interesting.", "author_fullname": "t2_1yczo6px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping on top of Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148vsv6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686708528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to stay on top of all new data science research that is coming out. Does anyone have ways to find research papers (best ways to find them)? Just want to make sure I do not fall behind and find reading the papers pretty interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148vsv6", "is_robot_indexable": true, "report_reasons": null, "author": "v3rycrafty", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148vsv6/keeping_on_top_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148vsv6/keeping_on_top_of_data_science/", "subreddit_subscribers": 924697, "created_utc": 1686708528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "PyPOTS is the first (and so far the only) Python toolbox/library specifically designed for data mining and machine learning on partially-observed time series (POTS), namely, incomplete time series with missing values, A.K.A. irregularly-sampled time series, supporting tasks of imputation, classification, clustering, and forecasting on POTS datasets.\n\nFeedback and contributions are very welcome!\n\nWebsite: [https://pypots.com](https://pypots.com/)\n\nGitHub repo: [https://github.com/WenjieDu/PyPOTS](https://github.com/WenjieDu/PyPOTS)\n\nPaper link: [https://arxiv.org/abs/2305.18811](https://arxiv.org/abs/2305.18811)\n\nhttps://preview.redd.it/gstk0nutpz5b1.jpg?width=1801&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7b39cdb94d6fa0793de93d731f2573790c993715", "author_fullname": "t2_4iz6qtg8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We built PyPOTS, an open-source toolbox for data mining on partially-observed time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gstk0nutpz5b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 29, "x": 108, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=532453efb904fb0f9841b9450fa2e0aeb590b030"}, {"y": 59, "x": 216, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94e7a294a61899f9b10a4e87a0d71e34b372bc83"}, {"y": 88, "x": 320, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa151ac0ebc5a68f50625bcb126f349c516c882d"}, {"y": 177, "x": 640, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9753ea2d954169da7047b4f2bd7def16247650a"}, {"y": 265, "x": 960, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71ab9a6068a36bd4da317d7ea58ac9132e0ce982"}, {"y": 299, "x": 1080, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b7d5345fbdf025c7bd1972c3e5248010fe72e7c"}], "s": {"y": 499, "x": 1801, "u": "https://preview.redd.it/gstk0nutpz5b1.jpg?width=1801&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7b39cdb94d6fa0793de93d731f2573790c993715"}, "id": "gstk0nutpz5b1"}}, "name": "t3_1498sbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1F8QkZL_LhrzXDJuQ2HtmE0NdAhiFfIU06ZXNJNNnYo.jpg", "edited": 1686758456.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1686751537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PyPOTS is the first (and so far the only) Python toolbox/library specifically designed for data mining and machine learning on partially-observed time series (POTS), namely, incomplete time series with missing values, A.K.A. irregularly-sampled time series, supporting tasks of imputation, classification, clustering, and forecasting on POTS datasets.&lt;/p&gt;\n\n&lt;p&gt;Feedback and contributions are very welcome!&lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://pypots.com/\"&gt;https://pypots.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub repo: &lt;a href=\"https://github.com/WenjieDu/PyPOTS\"&gt;https://github.com/WenjieDu/PyPOTS&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Paper link: &lt;a href=\"https://arxiv.org/abs/2305.18811\"&gt;https://arxiv.org/abs/2305.18811&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gstk0nutpz5b1.jpg?width=1801&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7b39cdb94d6fa0793de93d731f2573790c993715\"&gt;https://preview.redd.it/gstk0nutpz5b1.jpg?width=1801&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7b39cdb94d6fa0793de93d731f2573790c993715&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?auto=webp&amp;v=enabled&amp;s=ae18da170d54a52f1073bf11f7d048c5a12962d0", "width": 1201, "height": 629}, "resolutions": [{"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a2a77f45b53751b494327fedd714b523034241a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d9f30536681c6d1fddf2c5126b80f631e11bce1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=567ae17fb9d2d4e40e09c033653354c1309eb75f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9aa92dc7e349ba3089543da32836081b782de01a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0725f3f4df1d6fcaea98ad8b82f200707595c63d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da6916df36b5d3142764d9a689159a70d4eec0eb", "width": 1080, "height": 565}], "variants": {}, "id": "Fpe5wYBZaVfZMk60KGAqRJN_j6Ixp5cTN5LGAeoHZGo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498sbg", "is_robot_indexable": true, "report_reasons": null, "author": "WenjayDu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498sbg/we_built_pypots_an_opensource_toolbox_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1498sbg/we_built_pypots_an_opensource_toolbox_for_data/", "subreddit_subscribers": 924697, "created_utc": 1686751537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth investing time in learning specialized Python frameworks for data science, such as TensorFlow or PyTorch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498nva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686751246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498nva", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "subreddit_subscribers": 924697, "created_utc": 1686751246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m at a small tech company based out of Toronto, but I work remotely from a LCOL city a few hours away. I do data migrations, a ton of SQL querying for customer requests, working with JSON files, a ton of Azure and occasionally I\u2019ll whip up some PowerBI dashboards for the company when they need something to look nice. I make $70k before bonuses and it\u2019s my first real job out of university (about 3 year of total experience since finishing undergrad). If I had to estimate my average hours spent working most weeks, I\u2019d say it\u2019s about 10. Only the first week of each month do I put in anywhere near a full 40 hours. \n\nI really couldn\u2019t ask for more with my job. I don\u2019t have dread on Sundays worrying about another work week. In fact, I\u2019m doing a full time MS in Data Science right now with how much free time I have. \n\nI\u2019ve recently been applying to other jobs with better titles and slightly higher salaries, but I can\u2019t get myself to leave my current one. I have solid knowledge of Python &amp; R, solid knowledge of analytics and relatively good knowledge of ML, but I don\u2019t have any opportunity to use it. As much as I want a more prestigious title/raise and some analytical work, I can\u2019t help but feel that it\u2019s not worth hating my job/life for a few hundred extra on my cheques you know?\n\nSo, I\u2019ve come to the conclusion that when I\u2019m done my masters in a couple months I\u2019m going to get a part time role on top of my current one. The problem is, I have no idea if they exist. \n\nSide note - I have my annual review next week. What would be something appropriate to bring up to him when talking about wanting to utilize my skill set? Furthermore, how do you suggest a change to a more prestigious title since I spend so much time writing custom queries and working on Azure?", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part-Time Roles: Do They Exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148vsm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686751662.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686708503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m at a small tech company based out of Toronto, but I work remotely from a LCOL city a few hours away. I do data migrations, a ton of SQL querying for customer requests, working with JSON files, a ton of Azure and occasionally I\u2019ll whip up some PowerBI dashboards for the company when they need something to look nice. I make $70k before bonuses and it\u2019s my first real job out of university (about 3 year of total experience since finishing undergrad). If I had to estimate my average hours spent working most weeks, I\u2019d say it\u2019s about 10. Only the first week of each month do I put in anywhere near a full 40 hours. &lt;/p&gt;\n\n&lt;p&gt;I really couldn\u2019t ask for more with my job. I don\u2019t have dread on Sundays worrying about another work week. In fact, I\u2019m doing a full time MS in Data Science right now with how much free time I have. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve recently been applying to other jobs with better titles and slightly higher salaries, but I can\u2019t get myself to leave my current one. I have solid knowledge of Python &amp;amp; R, solid knowledge of analytics and relatively good knowledge of ML, but I don\u2019t have any opportunity to use it. As much as I want a more prestigious title/raise and some analytical work, I can\u2019t help but feel that it\u2019s not worth hating my job/life for a few hundred extra on my cheques you know?&lt;/p&gt;\n\n&lt;p&gt;So, I\u2019ve come to the conclusion that when I\u2019m done my masters in a couple months I\u2019m going to get a part time role on top of my current one. The problem is, I have no idea if they exist. &lt;/p&gt;\n\n&lt;p&gt;Side note - I have my annual review next week. What would be something appropriate to bring up to him when talking about wanting to utilize my skill set? Furthermore, how do you suggest a change to a more prestigious title since I spend so much time writing custom queries and working on Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148vsm4", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148vsm4/parttime_roles_do_they_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148vsm4/parttime_roles_do_they_exist/", "subreddit_subscribers": 924697, "created_utc": 1686708503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, \n\nI am currently doing my masters degree in healthcare data science . There is another masters program i m interested in (neuro data science related) and would like to do it after i finish my current degree . I'm not sure i want to go for a phd or continue in research . So i am wondering if i should only consider a neuro data science career if i really want to do research ?", "author_fullname": "t2_dmd2i1wa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what possible careers in neuro data science outside of research ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148ogfc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686687168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;I am currently doing my masters degree in healthcare data science . There is another masters program i m interested in (neuro data science related) and would like to do it after i finish my current degree . I&amp;#39;m not sure i want to go for a phd or continue in research . So i am wondering if i should only consider a neuro data science career if i really want to do research ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148ogfc", "is_robot_indexable": true, "report_reasons": null, "author": "Lucky-Purple8629", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148ogfc/what_possible_careers_in_neuro_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148ogfc/what_possible_careers_in_neuro_data_science/", "subreddit_subscribers": 924697, "created_utc": 1686687168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. \n\nAs an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. \n\nIf there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. \n\nIf anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break the \u201cneed experience to get experience\u201d cycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149bakb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686757729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. &lt;/p&gt;\n\n&lt;p&gt;As an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. &lt;/p&gt;\n\n&lt;p&gt;If there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. &lt;/p&gt;\n\n&lt;p&gt;If anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149bakb", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "subreddit_subscribers": 924697, "created_utc": 1686757729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Could you please mention what are the best steps of feature engineering ?", "author_fullname": "t2_wasnzue9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the main steps for feature engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1495cyi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686741839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could you please mention what are the best steps of feature engineering ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1495cyi", "is_robot_indexable": true, "report_reasons": null, "author": "kavinda_uthsuka97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1495cyi/what_are_the_main_steps_for_feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1495cyi/what_are_the_main_steps_for_feature_engineering/", "subreddit_subscribers": 924697, "created_utc": 1686741839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. \n\nIs this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.", "author_fullname": "t2_5238n9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are extremely long take home assignments in interview processes the norm now, or am I unlucky?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149cj12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686762740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. &lt;/p&gt;\n\n&lt;p&gt;Is this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cj12", "is_robot_indexable": true, "report_reasons": null, "author": "ravidampatel", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "subreddit_subscribers": 924697, "created_utc": 1686760756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In Regression analysis, there are basically two hypothesis tests. T-Test and F-Tests.\n\nIn most books there is a big deal about the LINE assumptions of linear regression, but if I understand it right, the t test only needs normal distribution if the sample size is small. If I have a sufficiently large sample size, I would assume that we do not need normality of residuals in regression as the CLT kicks in?\n\nHow does that behave for the the F-Tests?\n\nHence in DS most sample sizes are large, can we just more or less skip the N in LINE? or is it a LIE?\n\n(Sorry)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nEdit:   \n\n\nI think when it comes to interpretation of transformations we still need the normality, assumption, as we apply the notion, that mean = median, which only holds for a at least symetric distribution of residuals.\n\nAnd I found this  \n\n\n[https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis](https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis)", "author_fullname": "t2_9jc8y5kx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Normality of residuals in linear regression for hypothesis tests.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1490r3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686727315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686725213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In Regression analysis, there are basically two hypothesis tests. T-Test and F-Tests.&lt;/p&gt;\n\n&lt;p&gt;In most books there is a big deal about the LINE assumptions of linear regression, but if I understand it right, the t test only needs normal distribution if the sample size is small. If I have a sufficiently large sample size, I would assume that we do not need normality of residuals in regression as the CLT kicks in?&lt;/p&gt;\n\n&lt;p&gt;How does that behave for the the F-Tests?&lt;/p&gt;\n\n&lt;p&gt;Hence in DS most sample sizes are large, can we just more or less skip the N in LINE? or is it a LIE?&lt;/p&gt;\n\n&lt;p&gt;(Sorry)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit:   &lt;/p&gt;\n\n&lt;p&gt;I think when it comes to interpretation of transformations we still need the normality, assumption, as we apply the notion, that mean = median, which only holds for a at least symetric distribution of residuals.&lt;/p&gt;\n\n&lt;p&gt;And I found this  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis\"&gt;https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?auto=webp&amp;v=enabled&amp;s=72c13130d870084d77eda19882d28124c486f818", "width": 576, "height": 384}, "resolutions": [{"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=058d21915c61f3473bff13f8f8f2c4f6d0b021b5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=add76eef4177ac69590f8a74cd0ab7673383effc", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8e1bf1d17da2da349262ce590a7413c77996bac", "width": 320, "height": 213}], "variants": {}, "id": "A1UkfvdVRRULPfpZqh4KtHTnbw5sv3j-itYfKqCA6V0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1490r3e", "is_robot_indexable": true, "report_reasons": null, "author": "dududu87", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1490r3e/normality_of_residuals_in_linear_regression_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1490r3e/normality_of_residuals_in_linear_regression_for/", "subreddit_subscribers": 924697, "created_utc": 1686725213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Have been getting calls from recruiters and this seems to be one of the common questions. I earn \ud83e\udd5c\ud83e\udd5c in my current job (Govt. Org) so can't use it as a reference point. Any suggestions would be much appreciated.\n\n[View Poll](https://www.reddit.com/poll/148nbnm)", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should be the expected base salary for a DS with ~5 YOE (remote role in the US)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148nbnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686684105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have been getting calls from recruiters and this seems to be one of the common questions. I earn \ud83e\udd5c\ud83e\udd5c in my current job (Govt. Org) so can&amp;#39;t use it as a reference point. Any suggestions would be much appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/148nbnm\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "148nbnm", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1686856905493, "options": [{"text": "&lt;120k", "id": "23458651"}, {"text": "121-150k", "id": "23458652"}, {"text": "151-180k", "id": "23458653"}, {"text": "181-200k", "id": "23458654"}, {"text": "201-220k", "id": "23458655"}, {"text": "220+", "id": "23458656"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 1380, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148nbnm/what_should_be_the_expected_base_salary_for_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/148nbnm/what_should_be_the_expected_base_salary_for_a_ds/", "subreddit_subscribers": 924697, "created_utc": 1686684105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanted to thank everyone for taking the time to read my thread. \n\nI'm almost 30 years old, and have been in the same career for 8 years. I'm a \"Data Scientist\" with a Bachelors degree in Mathematics &amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp; executives. I work for a major financial institution. \n\nHere's the problem : I feel so disconnected &amp; unpassionate about my job. It's partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp; those who are passionate about Data Science - I'm losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp; improve. This has really never been me. I was able to succeed in the mid to late 2010's being fresh out of school &amp; having an \"up to date\" skillset ... but I don't think I have the drive or desire to do what I have to do to keep up in the mid to late 2020's.  \n\nI feel like I fell into this career out of the start of my career, but now a few months away from 30 I'm questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don't know what it is I'm passionate about, but working as a data scientist in the financial sector for the next 25 years isn't it (or maybe being a data scientist at all). \n\nAt the same time, I don't want to start my career fresh at the age of 30. I think I'm a naturally analytical person, and want to be able to carry over some of the skills I've picked up from the last 8 years into a new role, that might bring more passion &amp; joy back into my job. \n\nSo, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don't want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?\n\nThanks, look forward to hearing some stories", "author_fullname": "t2_ahx89ryl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't want to be a Data Scientist Anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149ea3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686765001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to thank everyone for taking the time to read my thread. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m almost 30 years old, and have been in the same career for 8 years. I&amp;#39;m a &amp;quot;Data Scientist&amp;quot; with a Bachelors degree in Mathematics &amp;amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp;amp; executives. I work for a major financial institution. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the problem : I feel so disconnected &amp;amp; unpassionate about my job. It&amp;#39;s partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp;amp; those who are passionate about Data Science - I&amp;#39;m losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp;amp; improve. This has really never been me. I was able to succeed in the mid to late 2010&amp;#39;s being fresh out of school &amp;amp; having an &amp;quot;up to date&amp;quot; skillset ... but I don&amp;#39;t think I have the drive or desire to do what I have to do to keep up in the mid to late 2020&amp;#39;s.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I fell into this career out of the start of my career, but now a few months away from 30 I&amp;#39;m questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp;amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don&amp;#39;t know what it is I&amp;#39;m passionate about, but working as a data scientist in the financial sector for the next 25 years isn&amp;#39;t it (or maybe being a data scientist at all). &lt;/p&gt;\n\n&lt;p&gt;At the same time, I don&amp;#39;t want to start my career fresh at the age of 30. I think I&amp;#39;m a naturally analytical person, and want to be able to carry over some of the skills I&amp;#39;ve picked up from the last 8 years into a new role, that might bring more passion &amp;amp; joy back into my job. &lt;/p&gt;\n\n&lt;p&gt;So, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don&amp;#39;t want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?&lt;/p&gt;\n\n&lt;p&gt;Thanks, look forward to hearing some stories&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ea3x", "is_robot_indexable": true, "report_reasons": null, "author": "I_am_Howie_Dewitt", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "subreddit_subscribers": 924697, "created_utc": 1686765001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)", "author_fullname": "t2_a2ps3jf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on ETL tools like Azure Data Factory or AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149chge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149chge", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent-Bunch7505", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "subreddit_subscribers": 924697, "created_utc": 1686760645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Being a Data Analyst, I could notice the problem of accessibility of data for people. If you don't know how to do SQL, you are stuck and ultra dependent on your DA.\n\nSo I created Vazy, a solution whose goal is to solve this. With various AI models, we are able to bring to a real discussion between the user and our models.\n\nWe take care of getting the data, explain how we did it and accompany you in your research.\n\nIf you want to test our alpha, there is a link below.\n\nIf you have any feedback, don't hesitate.", "author_fullname": "t2_8vmalds1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've built a tool to make people discuss with their data and without SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ag4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686755624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Being a Data Analyst, I could notice the problem of accessibility of data for people. If you don&amp;#39;t know how to do SQL, you are stuck and ultra dependent on your DA.&lt;/p&gt;\n\n&lt;p&gt;So I created Vazy, a solution whose goal is to solve this. With various AI models, we are able to bring to a real discussion between the user and our models.&lt;/p&gt;\n\n&lt;p&gt;We take care of getting the data, explain how we did it and accompany you in your research.&lt;/p&gt;\n\n&lt;p&gt;If you want to test our alpha, there is a link below.&lt;/p&gt;\n\n&lt;p&gt;If you have any feedback, don&amp;#39;t hesitate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ag4p", "is_robot_indexable": true, "report_reasons": null, "author": "Miserness", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ag4p/ive_built_a_tool_to_make_people_discuss_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ag4p/ive_built_a_tool_to_make_people_discuss_with/", "subreddit_subscribers": 924697, "created_utc": 1686755624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498fdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_cvej3qatd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "FeatureEng", "selftext": "Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:\n\n1. A feature with high impact does not necessarily have a causal relationship with the target variable.\n2. The feature relationship learned by the model may not generalize well in the future.\n\nTo illustrate this, let's consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn't seen new timestamps before and doesn't know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.\n\nThis problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.\n\nI encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition's conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.\n\nTo address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here's what I did for the GE Flight Quest:\n\n1. Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.\n2. Then, I trained a second model to capture the residual effects specific to each airport.\n\nThis two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.\n\nI see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:\n\n1. Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.\n2. Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.\n\nHave you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?\n\nGxav", "author_fullname": "t2_cvej3qatd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/FeatureEng", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_147x9gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686602923.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A feature with high impact does not necessarily have a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;The feature relationship learned by the model may not generalize well in the future.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To illustrate this, let&amp;#39;s consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn&amp;#39;t seen new timestamps before and doesn&amp;#39;t know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.&lt;/p&gt;\n\n&lt;p&gt;This problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.&lt;/p&gt;\n\n&lt;p&gt;I encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition&amp;#39;s conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.&lt;/p&gt;\n\n&lt;p&gt;To address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here&amp;#39;s what I did for the GE Flight Quest:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.&lt;/li&gt;\n&lt;li&gt;Then, I trained a second model to capture the residual effects specific to each airport.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.&lt;/p&gt;\n\n&lt;p&gt;I see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Have you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?&lt;/p&gt;\n\n&lt;p&gt;Gxav&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_8kc7h0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "147x9gj", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 51, "created_utc": 1686602923.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1686750652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498fdy", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_147x9gj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498fdy/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 924697, "created_utc": 1686750652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I have a basic machine learning background and understand the \"traditional\" regression/classification models etc. and would like to get some solid knowledge on deep learning. I recently watched the MIT DL series on youtube, which is a good foundation, but I feel it lacks a lot of practicality. Additionally, a lot of the online courses are outdated and use obsolete versions of machine learning libraries.\n\nI'm looking for a relatively new/updated course on deep learning that will teach me the basics such as CNN, RNN, reinforcement learning, generative models etc. Preferably, there will be a good explanation on the maths behind these concepts and there will also be good practical examples/coding projects.", "author_fullname": "t2_4pjl2389", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the Best Online Deep Learning Course for 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1494bor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686738446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I have a basic machine learning background and understand the &amp;quot;traditional&amp;quot; regression/classification models etc. and would like to get some solid knowledge on deep learning. I recently watched the MIT DL series on youtube, which is a good foundation, but I feel it lacks a lot of practicality. Additionally, a lot of the online courses are outdated and use obsolete versions of machine learning libraries.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a relatively new/updated course on deep learning that will teach me the basics such as CNN, RNN, reinforcement learning, generative models etc. Preferably, there will be a good explanation on the maths behind these concepts and there will also be good practical examples/coding projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1494bor", "is_robot_indexable": true, "report_reasons": null, "author": "souvlaki_mix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1494bor/which_is_the_best_online_deep_learning_course_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1494bor/which_is_the_best_online_deep_learning_course_for/", "subreddit_subscribers": 924697, "created_utc": 1686738446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team builds and maintains a number of models and dashboards in addition to undertaking analytics projects for a large business. Normally with the teams we are structurally closer to we would build something for a team, have agreed scope and touch points through an engagement. As part of that we walk the team through use of the product etc.\nMany of our more sophisticated models were built as self scoped initiatives where we anticipated a need. Most of these have proven quite popular and a number of more removed business units know us for these products. \nHowever, we recently moved to a new division we previously did a fair amount of work for. This division has had significant turnover in the past few years. Despite spending a significant amount of time explaining these models to new hires(and their replacements) in these teams. There is persistent commentary that these teams don't have what they need and that they are not aware these products exist and don't have access. However these teams don't come and ask for information, first interaction is that complaint. \n\nNo other teams outside this division we work with act like this. They all come with questions or projects and we're generally well regarded. \n\nI think we have more than met what is required in explaning the use and existence of these products. And that it's not my role to make sure there is handover within other teams. Particularly as we don't know about turnover elsewhere. Am I wrong?\n\nWe've met with these teams to determine their priorities and directly ask what their needs are, what work may be upcoming etc, we direct them to resources and work with them as needed but I'm at a loss of what else I can do. \n\nFull disclosure I've tapered off these explanations as they were taking up too much time and impacting our availability and deliverables", "author_fullname": "t2_1pb50w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice: Who's responsible for keeping end users aware of a model and other data products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1492eu4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686731388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team builds and maintains a number of models and dashboards in addition to undertaking analytics projects for a large business. Normally with the teams we are structurally closer to we would build something for a team, have agreed scope and touch points through an engagement. As part of that we walk the team through use of the product etc.\nMany of our more sophisticated models were built as self scoped initiatives where we anticipated a need. Most of these have proven quite popular and a number of more removed business units know us for these products. \nHowever, we recently moved to a new division we previously did a fair amount of work for. This division has had significant turnover in the past few years. Despite spending a significant amount of time explaining these models to new hires(and their replacements) in these teams. There is persistent commentary that these teams don&amp;#39;t have what they need and that they are not aware these products exist and don&amp;#39;t have access. However these teams don&amp;#39;t come and ask for information, first interaction is that complaint. &lt;/p&gt;\n\n&lt;p&gt;No other teams outside this division we work with act like this. They all come with questions or projects and we&amp;#39;re generally well regarded. &lt;/p&gt;\n\n&lt;p&gt;I think we have more than met what is required in explaning the use and existence of these products. And that it&amp;#39;s not my role to make sure there is handover within other teams. Particularly as we don&amp;#39;t know about turnover elsewhere. Am I wrong?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve met with these teams to determine their priorities and directly ask what their needs are, what work may be upcoming etc, we direct them to resources and work with them as needed but I&amp;#39;m at a loss of what else I can do. &lt;/p&gt;\n\n&lt;p&gt;Full disclosure I&amp;#39;ve tapered off these explanations as they were taking up too much time and impacting our availability and deliverables&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1492eu4", "is_robot_indexable": true, "report_reasons": null, "author": "origami_knight", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1492eu4/advice_whos_responsible_for_keeping_end_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1492eu4/advice_whos_responsible_for_keeping_end_users/", "subreddit_subscribers": 924697, "created_utc": 1686731388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking to develop a model that will need to score about 5 million records every night. Pandas is obviously terrible for a dataset of this scope but I\u2019m not sure what the alternative would be. Spark NNs lack the customizability I need.", "author_fullname": "t2_gj1m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best way to score ~5 million records with a tensorflow neural network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148sofh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686698775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to develop a model that will need to score about 5 million records every night. Pandas is obviously terrible for a dataset of this scope but I\u2019m not sure what the alternative would be. Spark NNs lack the customizability I need.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148sofh", "is_robot_indexable": true, "report_reasons": null, "author": "JimBeanery", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148sofh/best_way_to_score_5_million_records_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148sofh/best_way_to_score_5_million_records_with_a/", "subreddit_subscribers": 924697, "created_utc": 1686698775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm the dba for a few on-prem SQL Server dbs that my company use for financials reporting and data science tasks. I'm trying to come up with a data catalog solution for these databases. They are about 1 TB each with 20-30 core tables related to transactions, customer ids, and pricing logic. We don't have new tables that often but it does happen.\n\nOur end goal is to have a better understanding of our data for analysts/scientists to use it and in case we need to give business clarification for what certain metrics mean. For example, we have a certain pricing calculation that is assigned to every customer, and is stored in a column called. I would like analysts to be able to easily look up which tables have this column, and read about what it actually means, easily.\n\nWe considered microsoft purview but it seems expensive for what we get, and I'm not sure it would even work with our on-prem databases. Has anyone done something like this before?\n\nWe currently have some of this info stored in some excel spreadsheets I made after pulling table/column schema data out. I wouldn't need everyone to be able to update the meta data for these table columns, just a few people in the no.\n\nTechnically I think I could make another table that is comprised of all the table/column names, and basic description, keyword, use cases. But I'm wondering if there is a solution that is a little bit more intiutive than this, without buying something expensive and unnecessary. Really, as minimal as possible, while still giving a base line catalot\n\nAny thoughts appreciated!", "author_fullname": "t2_ezn9dzzw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy data catalog solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149cwji", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686761691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m the dba for a few on-prem SQL Server dbs that my company use for financials reporting and data science tasks. I&amp;#39;m trying to come up with a data catalog solution for these databases. They are about 1 TB each with 20-30 core tables related to transactions, customer ids, and pricing logic. We don&amp;#39;t have new tables that often but it does happen.&lt;/p&gt;\n\n&lt;p&gt;Our end goal is to have a better understanding of our data for analysts/scientists to use it and in case we need to give business clarification for what certain metrics mean. For example, we have a certain pricing calculation that is assigned to every customer, and is stored in a column called. I would like analysts to be able to easily look up which tables have this column, and read about what it actually means, easily.&lt;/p&gt;\n\n&lt;p&gt;We considered microsoft purview but it seems expensive for what we get, and I&amp;#39;m not sure it would even work with our on-prem databases. Has anyone done something like this before?&lt;/p&gt;\n\n&lt;p&gt;We currently have some of this info stored in some excel spreadsheets I made after pulling table/column schema data out. I wouldn&amp;#39;t need everyone to be able to update the meta data for these table columns, just a few people in the no.&lt;/p&gt;\n\n&lt;p&gt;Technically I think I could make another table that is comprised of all the table/column names, and basic description, keyword, use cases. But I&amp;#39;m wondering if there is a solution that is a little bit more intiutive than this, without buying something expensive and unnecessary. Really, as minimal as possible, while still giving a base line catalot&lt;/p&gt;\n\n&lt;p&gt;Any thoughts appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cwji", "is_robot_indexable": true, "report_reasons": null, "author": "packetpupper", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cwji/easy_data_catalog_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cwji/easy_data_catalog_solutions/", "subreddit_subscribers": 924697, "created_utc": 1686761691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey folks,   \nLet's say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no \"relevant\" domain experience. \n\nWhat are your advices on having more chances to be given a chance?\n\nI heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.  \nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?", "author_fullname": "t2_s9fqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to increase chances for an interview when switching industries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149cvkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686761622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;br/&gt;\nLet&amp;#39;s say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no &amp;quot;relevant&amp;quot; domain experience. &lt;/p&gt;\n\n&lt;p&gt;What are your advices on having more chances to be given a chance?&lt;/p&gt;\n\n&lt;p&gt;I heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.&lt;br/&gt;\nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cvkw", "is_robot_indexable": true, "report_reasons": null, "author": "scriptosens", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "subreddit_subscribers": 924697, "created_utc": 1686761622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. \n\nWhat are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I've previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?", "author_fullname": "t2_9chfd9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Healthcare", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149amep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686756070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. &lt;/p&gt;\n\n&lt;p&gt;What are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I&amp;#39;ve previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149amep", "is_robot_indexable": true, "report_reasons": null, "author": "Statefan3778", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149amep/data_science_in_healthcare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149amep/data_science_in_healthcare/", "subreddit_subscribers": 924697, "created_utc": 1686756070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "According to the global skill report, Switzerland, Spain and Germany come out on top while the US ranks only far below with a 32% score in data-science. How are those ranks generated? Considering the dominant role of the US in the tech industry, shouldn't one expect it to rank higher?  \n\n\nLink:\n\n[https://www.coursera.org/skills-reports/global](https://www.coursera.org/skills-reports/global)", "author_fullname": "t2_3d4vknwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coursera Global Skill Report", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14991lt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686752201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;According to the global skill report, Switzerland, Spain and Germany come out on top while the US ranks only far below with a 32% score in data-science. How are those ranks generated? Considering the dominant role of the US in the tech industry, shouldn&amp;#39;t one expect it to rank higher?  &lt;/p&gt;\n\n&lt;p&gt;Link:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/skills-reports/global\"&gt;https://www.coursera.org/skills-reports/global&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?auto=webp&amp;v=enabled&amp;s=c97593ea23d3d2051b49ee0a560e2fd77a773c06", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65f7d0e9941291c84563eb219f4b536bcad17351", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93c4262061f093ff62d5fe8976ca11d6254af2da", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01eaadd440881b56801a7b518821ec86afe1c689", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dcfa6a5a3bf506a7d7166d41a98cc68881ea57c1", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d0c74ef524c065e8bc2ecfea464feae0b52365a", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/j5Ti117lg7MCY56FwTNX5c4xFqkO05516hLspFT1y10.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=355238ca57c25f6ae602d97dbc2e83a4cf55efc7", "width": 1080, "height": 565}], "variants": {}, "id": "ToiB8Bukx67CErSv8laxbM9MfgevAYptQJyu_o7VGnQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14991lt", "is_robot_indexable": true, "report_reasons": null, "author": "nyquant", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14991lt/coursera_global_skill_report/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14991lt/coursera_global_skill_report/", "subreddit_subscribers": 924697, "created_utc": 1686752201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hope I\u2019m posting in the right place, this sub seems large enough for me to get enough feedback. I am leaving some details deliberately vague so I don't get identified by colleagues, let me know if I need to give more info. \n\nJob title: Advertising Analytics Manager\nLocation: East Coast, US (not in NYC)\nPay: base $100k with an opportunity for up to $20k in bonuses\n\nI took this job with the impression that I would be reporting on the performance of a company\u2019s advertising campaigns, something I have a lot of experience with. While interviewing, it was described to me that this type of information was already being provided but they wanted someone specialized in it to lighten the load of the existing team. I was led to believe there was an existing structure and I\u2019d have plenty of support for data questions.\n\nTurns out the existing data is a bit of a shitshow and the job is WAY more technical than expected. I am expected to organize internal data and basically build up GA from scratch, plus deal with proprietary reporting systems and handle tagging (the IT department implements but I have to give them direction). The people who were handling projects before me shrug their shoulders when I ask questions. I\u2019m getting a ton of complex requests about the overall business (not marketing specific). I\u2019ve barely done any work I expected to do.\n\nI\u2019m not an idiot but I feel way over my head and that this job would have been better suited for a data engineer, not a marketing analyst. But\u2026 did I just luck out with prior jobs? I\u2019ve worked for both small and large companies and never had to do this level of work before. I\u2019m feeling bamboozled especially knowing how much more engineers get paid.\n\nAny insight is appreciated.", "author_fullname": "t2_8m73d0nki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis job: am I being paid enough for what is being required of me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149cwx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686761715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope I\u2019m posting in the right place, this sub seems large enough for me to get enough feedback. I am leaving some details deliberately vague so I don&amp;#39;t get identified by colleagues, let me know if I need to give more info. &lt;/p&gt;\n\n&lt;p&gt;Job title: Advertising Analytics Manager\nLocation: East Coast, US (not in NYC)\nPay: base $100k with an opportunity for up to $20k in bonuses&lt;/p&gt;\n\n&lt;p&gt;I took this job with the impression that I would be reporting on the performance of a company\u2019s advertising campaigns, something I have a lot of experience with. While interviewing, it was described to me that this type of information was already being provided but they wanted someone specialized in it to lighten the load of the existing team. I was led to believe there was an existing structure and I\u2019d have plenty of support for data questions.&lt;/p&gt;\n\n&lt;p&gt;Turns out the existing data is a bit of a shitshow and the job is WAY more technical than expected. I am expected to organize internal data and basically build up GA from scratch, plus deal with proprietary reporting systems and handle tagging (the IT department implements but I have to give them direction). The people who were handling projects before me shrug their shoulders when I ask questions. I\u2019m getting a ton of complex requests about the overall business (not marketing specific). I\u2019ve barely done any work I expected to do.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not an idiot but I feel way over my head and that this job would have been better suited for a data engineer, not a marketing analyst. But\u2026 did I just luck out with prior jobs? I\u2019ve worked for both small and large companies and never had to do this level of work before. I\u2019m feeling bamboozled especially knowing how much more engineers get paid.&lt;/p&gt;\n\n&lt;p&gt;Any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cwx3", "is_robot_indexable": true, "report_reasons": null, "author": "IGoNuts4DogButts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cwx3/data_analysis_job_am_i_being_paid_enough_for_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cwx3/data_analysis_job_am_i_being_paid_enough_for_what/", "subreddit_subscribers": 924697, "created_utc": 1686761715.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}