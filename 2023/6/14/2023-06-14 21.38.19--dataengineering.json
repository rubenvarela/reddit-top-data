{"kind": "Listing", "data": {"after": "t3_149igv5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just finished writing up a welcome gift for my newsletter, but I wanted to share at least the list of links here. \n\nFor comments on all the books &amp; articles, don't hesitate to subscribe to [https://www.finishslime.com/](https://www.finishslime.com/).  \n\n*FWIW: I have read all of these, and I did consider all of them very helpful for my data engineering skills! This is not a bogus collection of what others have shared.* \n\n# Books \n\n* [Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems](https://www.amazon.de/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321) \\- Martin Kleppmann\n* [Fundamentals of Data Engineering](https://www.amazon.de/-/en/Joe-Reis/dp/1098108302) \\- Reis &amp; Housley\n* [Data Science for Business](https://www.amazon.de/-/en/Foster-Provost/dp/1449361323/) \\- Provost &amp; Fawcett\n* [Big Data](https://www.amazon.de/-/en/Nathan-Marz/dp/1617290343): Principles and best practices of scalable realtime data systems - Nathan Marz\n* [Database Reliability Engineering](https://www.amazon.com/Database-Reliability-Engineering-Designing-Operating/dp/1491925949/): Designing and Operating Resilient Database Systems - Campbell Majors\n* [Storytelling with data](https://www.amazon.com/Storytelling-Data-Visualization-Business-Professionals/dp/1119002257) \\- Nussbaumer Knaflic\n* [Data Mesh](https://www.amazon.com/Data-Mesh-Delivering-Data-Driven-Value/dp/1492092398/) \\- Zhamak Dehghani\n\n# Articles from last year\n\n* [Stop aggregating away the signal in your data](https://stackoverflow.blog/2022/03/03/stop-aggregating-away-the-signal-in-your-data/%20)\u00a0\u2014 Zan Armstrong \n* [Data Mesh in practice](https://www.starburst.io/info/data-mesh-in-practice-ebook/%20)\u00a0\u2014 Max Schultze &amp; Arif Wider\n* [The future of the modern data stack](https://www.montecarlodata.com/the-future-of-the-modern-data-stack/)\u00a0\u2014 Barr Moses\n* [Reshaping data engineering](https://preset.io/blog/reshaping-data-engineering/)\u00a0\u2014 Maxime Beauchemin\n* [Emerging Architectures for modern data infrastructure](https://a16z.com/2020/10/15/emerging-architectures-for-modern-data-infrastructure/)\u00a0\u2014 Matt Bornstein, Jennifer Li, Martin Casado\n* [Dodging the data bottleneck, data mesh at starship](https://www.starship.xyz/medium_blog_posts/dodging-the-data-bottleneckdata-mesh-at-starship/)\u00a0\u2014 Taavi Pungas\n* [3 Level data lakes](https://youtu.be/4zLCUPNIV3M)\u00a0\u2014 Paul Singman\n* [Miro's journey to data monitoring](https://medium.com/miro-engineering/our-journey-to-data-engineering-monitoring-c14d6ff20351)\u00a0\u2014 Goncalo Costa, Ricardo Souza\n* [Photobox data platform](https://medium.com/photobox-technology-product-and-design/photobox-new-data-platform-da5d70296ba0)\u00a0\u2014 Stefan Solimito\n* [Talk on Functional Data Engineering](https://www.youtube.com/watch?v=4Spo2QRTz1k&amp;feature=youtu.be&amp;themeRefresh=1)\u00a0\u2014 Maxime Beauchemin\n\n# Overall great articles \n\n* [The Rise of the Data Engineer](https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603)\n* [The Modern Stack of ML Infrastructure](https://outerbounds.com/blog/the-modern-stack-of-ml-infrastructure/)\n* [The Downfall of the Data Engineer](https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b)\n* [How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html)\n* [Functional Data Engineering \u2014 a modern paradigm for batch data processing](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)\n* [Data Mesh Principles and Logical Architecture](https://martinfowler.com/articles/data-mesh-principles.html)\n* [The Future Of Business Intelligence Is Open Source](https://preset.io/blog/future-of-business-intelligence/)\n* [Tristan Handy on the changing face of the data stack](https://mixpanel.com/blog/tristan-handy-changing-data-stack/)\n* [The Future of the Data Engineer](https://preset.io/blog/the-future-of-the-data-engineer/)\n* [The Modern Data Stack: Past, Present, and Future](https://www.getdbt.com/blog/future-of-the-modern-data-stack/)\n* [The Case for Dataset-Centric Visualization](https://preset.io/blog/dataset-centric-visualization/)\n* [Building The Modern Data Team](https://databased.pedramnavid.com/p/modern-data-team)\n* [Introducing Entity-Centric Data Modeling for Analytics](https://preset.io/blog/introducing-entity-centric-data-modeling-for-analytics/)\n* [We Don't Need Data Scientists, We Need Data Engineers](https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/)\n* [How should our company structure our data team?](https://medium.com/super/how-should-our-company-structure-our-data-team-e71f6846024d)\n* [What makes a data analyst excellent?](https://towardsdatascience.com/what-makes-a-data-analyst-excellent-17ee4651c6db)\n* [Data Strategy: Good Data vs. Bad Data](https://towardsdatascience.com/data-strategy-good-data-vs-bad-data-d40f85d7ba4e)\n* [What Companies REALLY Want in an Analytics Engineer](https://medium.com/geekculture/what-companies-really-want-in-an-analytics-engineer-1ac03ff4494a)\n* [Stop using so many CTEs](https://hex.tech/blog/stop-using-so-many-ctes/)\n* [7 Antifragile Principles for a Successful Data Warehouse](https://blog.picnic.nl/7-antifragile-principles-for-a-successful-data-warehouse-574b655f0bc6)\n\nWhat about you? Got anything to add? I bet!", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A must-read data engineering collection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1491swe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 130, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 130, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686729121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just finished writing up a welcome gift for my newsletter, but I wanted to share at least the list of links here. &lt;/p&gt;\n\n&lt;p&gt;For comments on all the books &amp;amp; articles, don&amp;#39;t hesitate to subscribe to &lt;a href=\"https://www.finishslime.com/\"&gt;https://www.finishslime.com/&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;FWIW: I have read all of these, and I did consider all of them very helpful for my data engineering skills! This is not a bogus collection of what others have shared.&lt;/em&gt; &lt;/p&gt;\n\n&lt;h1&gt;Books&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.de/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321\"&gt;Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems&lt;/a&gt; - Martin Kleppmann&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.de/-/en/Joe-Reis/dp/1098108302\"&gt;Fundamentals of Data Engineering&lt;/a&gt; - Reis &amp;amp; Housley&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.de/-/en/Foster-Provost/dp/1449361323/\"&gt;Data Science for Business&lt;/a&gt; - Provost &amp;amp; Fawcett&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.de/-/en/Nathan-Marz/dp/1617290343\"&gt;Big Data&lt;/a&gt;: Principles and best practices of scalable realtime data systems - Nathan Marz&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.com/Database-Reliability-Engineering-Designing-Operating/dp/1491925949/\"&gt;Database Reliability Engineering&lt;/a&gt;: Designing and Operating Resilient Database Systems - Campbell Majors&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.com/Storytelling-Data-Visualization-Business-Professionals/dp/1119002257\"&gt;Storytelling with data&lt;/a&gt; - Nussbaumer Knaflic&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.amazon.com/Data-Mesh-Delivering-Data-Driven-Value/dp/1492092398/\"&gt;Data Mesh&lt;/a&gt; - Zhamak Dehghani&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Articles from last year&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://stackoverflow.blog/2022/03/03/stop-aggregating-away-the-signal-in-your-data/%20\"&gt;Stop aggregating away the signal in your data&lt;/a&gt;\u00a0\u2014 Zan Armstrong &lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.starburst.io/info/data-mesh-in-practice-ebook/%20\"&gt;Data Mesh in practice&lt;/a&gt;\u00a0\u2014 Max Schultze &amp;amp; Arif Wider&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.montecarlodata.com/the-future-of-the-modern-data-stack/\"&gt;The future of the modern data stack&lt;/a&gt;\u00a0\u2014 Barr Moses&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://preset.io/blog/reshaping-data-engineering/\"&gt;Reshaping data engineering&lt;/a&gt;\u00a0\u2014 Maxime Beauchemin&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://a16z.com/2020/10/15/emerging-architectures-for-modern-data-infrastructure/\"&gt;Emerging Architectures for modern data infrastructure&lt;/a&gt;\u00a0\u2014 Matt Bornstein, Jennifer Li, Martin Casado&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.starship.xyz/medium_blog_posts/dodging-the-data-bottleneckdata-mesh-at-starship/\"&gt;Dodging the data bottleneck, data mesh at starship&lt;/a&gt;\u00a0\u2014 Taavi Pungas&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://youtu.be/4zLCUPNIV3M\"&gt;3 Level data lakes&lt;/a&gt;\u00a0\u2014 Paul Singman&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://medium.com/miro-engineering/our-journey-to-data-engineering-monitoring-c14d6ff20351\"&gt;Miro&amp;#39;s journey to data monitoring&lt;/a&gt;\u00a0\u2014 Goncalo Costa, Ricardo Souza&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://medium.com/photobox-technology-product-and-design/photobox-new-data-platform-da5d70296ba0\"&gt;Photobox data platform&lt;/a&gt;\u00a0\u2014 Stefan Solimito&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=4Spo2QRTz1k&amp;amp;feature=youtu.be&amp;amp;themeRefresh=1\"&gt;Talk on Functional Data Engineering&lt;/a&gt;\u00a0\u2014 Maxime Beauchemin&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Overall great articles&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603\"&gt;The Rise of the Data Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://outerbounds.com/blog/the-modern-stack-of-ml-infrastructure/\"&gt;The Modern Stack of ML Infrastructure&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b\"&gt;The Downfall of the Data Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"&gt;How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a\"&gt;Functional Data Engineering \u2014 a modern paradigm for batch data processing&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://martinfowler.com/articles/data-mesh-principles.html\"&gt;Data Mesh Principles and Logical Architecture&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://preset.io/blog/future-of-business-intelligence/\"&gt;The Future Of Business Intelligence Is Open Source&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://mixpanel.com/blog/tristan-handy-changing-data-stack/\"&gt;Tristan Handy on the changing face of the data stack&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://preset.io/blog/the-future-of-the-data-engineer/\"&gt;The Future of the Data Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.getdbt.com/blog/future-of-the-modern-data-stack/\"&gt;The Modern Data Stack: Past, Present, and Future&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://preset.io/blog/dataset-centric-visualization/\"&gt;The Case for Dataset-Centric Visualization&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://databased.pedramnavid.com/p/modern-data-team\"&gt;Building The Modern Data Team&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://preset.io/blog/introducing-entity-centric-data-modeling-for-analytics/\"&gt;Introducing Entity-Centric Data Modeling for Analytics&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/\"&gt;We Don&amp;#39;t Need Data Scientists, We Need Data Engineers&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://medium.com/super/how-should-our-company-structure-our-data-team-e71f6846024d\"&gt;How should our company structure our data team?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://towardsdatascience.com/what-makes-a-data-analyst-excellent-17ee4651c6db\"&gt;What makes a data analyst excellent?&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://towardsdatascience.com/data-strategy-good-data-vs-bad-data-d40f85d7ba4e\"&gt;Data Strategy: Good Data vs. Bad Data&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://medium.com/geekculture/what-companies-really-want-in-an-analytics-engineer-1ac03ff4494a\"&gt;What Companies REALLY Want in an Analytics Engineer&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://hex.tech/blog/stop-using-so-many-ctes/\"&gt;Stop using so many CTEs&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://blog.picnic.nl/7-antifragile-principles-for-a-successful-data-warehouse-574b655f0bc6\"&gt;7 Antifragile Principles for a Successful Data Warehouse&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What about you? Got anything to add? I bet!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?auto=webp&amp;v=enabled&amp;s=17e9aa1e2e0c6b00394d4d00391a764723ba8c43", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeb9be75ee9df55f943d2c006f33b3b963351136", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa9a5bc601791e56ec1b4975e64f78534d863d8b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7076add5279a56322542289191d0f4b5b8ed56eb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f2360a39159e77cc834968666c8aa2292bab1f5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4111816dd29402a410d198172afc8a928aae1493", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/HE7dyElECq-kTgUzVIAdR4-AMYW0Oc-ceaGKSj8THrA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30ae2ad853ec907e86089a8d0d2c1ab934e54fff", "width": 1080, "height": 567}], "variants": {}, "id": "AfogqMslPrW_R5l3T-ydG_abd5Ry_EDHMH467eXBhUo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1491swe", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1491swe/a_mustread_data_engineering_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1491swe/a_mustread_data_engineering_collection/", "subreddit_subscribers": 110367, "created_utc": 1686729121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "That is all", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I missed you guys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1497ngt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686748613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That is all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1497ngt", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1497ngt/i_missed_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1497ngt/i_missed_you_guys/", "subreddit_subscribers": 110367, "created_utc": 1686748613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "On my quest to find a new job, I need your hilarious insights. What are some unmistakable signals or alarm bells that scream, \"Run for your life! The job is a horrendous nightmare or managed by Captain Chaos himself\"?\n\nEdit: Thanks for the responses. Definitely, many of these will help me make better judgments!", "author_fullname": "t2_s1imvbrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Red flags in job hunting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1490edf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686777355.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686723938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my quest to find a new job, I need your hilarious insights. What are some unmistakable signals or alarm bells that scream, &amp;quot;Run for your life! The job is a horrendous nightmare or managed by Captain Chaos himself&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks for the responses. Definitely, many of these will help me make better judgments!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1490edf", "is_robot_indexable": true, "report_reasons": null, "author": "AsideAwkward3789", "discussion_type": null, "num_comments": 97, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1490edf/red_flags_in_job_hunting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1490edf/red_flags_in_job_hunting/", "subreddit_subscribers": 110367, "created_utc": 1686723938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm a Data Engineer and I work mainly using Python and pySpark on Databricks. I noticed that 6 out of 10 most paid jobs in Data Engineering field are \"BigData Engineer with Scala\" and simmilar, often related with Azure and Databricks.\n\nSo to meet market expectations I want to learn Scala in context of Data Engineering. If there is a someone with job like I mentioned, I will take any advice on what to learn and how to learn Scala for Data Engineering.\n\nI'm asking for help because I dont want to be a Scala Developer, so maybe some experts can point me some directions what should I learn, and what shouldn't  :)", "author_fullname": "t2_mt2ra5ww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer with Scala?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1493oql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686736271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a Data Engineer and I work mainly using Python and pySpark on Databricks. I noticed that 6 out of 10 most paid jobs in Data Engineering field are &amp;quot;BigData Engineer with Scala&amp;quot; and simmilar, often related with Azure and Databricks.&lt;/p&gt;\n\n&lt;p&gt;So to meet market expectations I want to learn Scala in context of Data Engineering. If there is a someone with job like I mentioned, I will take any advice on what to learn and how to learn Scala for Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking for help because I dont want to be a Scala Developer, so maybe some experts can point me some directions what should I learn, and what shouldn&amp;#39;t  :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1493oql", "is_robot_indexable": true, "report_reasons": null, "author": "Logical-Media-344", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1493oql/data_engineer_with_scala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1493oql/data_engineer_with_scala/", "subreddit_subscribers": 110367, "created_utc": 1686736271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I keep finding I'm not getting interviews despite I think tons of experience and skills, and I wonder if I'm just doing something drastically wrong in my approach or framing, or something I take for granted as a strength is actually a major red flag.\n\nFor starters, I got pushed up quite quickly to a senior manager level position for reasons I think of knowledge, skill, outspokenness, and vision, but also, frankly, just due to the needs of the company to fill that role from a pool of mostly junior talent. Basically, I went from DE to senior DE to manager in only three years, with about two years of experience before that as a data scientist, so that's a total of ~6 years in data.\n\nI've always worked with Python and cloud platforms, mostly AWS but also GCP, and recently, I've become very familiar with Databricks. I do have a solid understanding of databases as well, but it could be considered cursory. \n\nIf I had to characterize my technical skill set distribution among roles, I would say I am at like 20% cloud engineer, 40% big data engineer (python, spark, distributed computing, databases, Airflow and other orchestration approaches, but also batch scripting, AWS lambdas, etc), 20% analyst/scientist still, 20% software engineering and CICD approaches.\n\nI've led a number of projects, and have pushed forward and solved a number of challenges to get projects delivered, so my work even before becoming a manager involved communicating across teams, divisions, and global entities of the same group company.\n\nAnd yet, I get no interviews. \n\nOn the one hand, I have few years, and maybe I also am doing a terrible job compressing my wide-ranging experiences into strictly relevant and focused messaging for the roles I apply to.\n\nOn the other hand, I wonder if my title doesn't read as seriously inflated (head of data engineering and a senior engineer) when viewed against the number of years, or maybe it's assumed I'm not on the ball technically enough as a partial people manager.\n\nI'm mainly going after non-managerial roles, in part because I feel I still have much to learn on the technical side, and I'd really like to deepen core skill sets with peer or even more senior mentorship. Maybe that is apparent and viewed as a serious weakness, and so I get passed on even though my demonstrable skills typically check all the boxes and more.\n\nTechnical weaknesses of mine would be in data modeling (never had to create and model a data store for a business unit from scratch; I'm trying to fill in the theory gap.by reading), optimizing non-distributed data stores for performance (I know the theory, but never had to do, but instead have optimized spark jobs and queries to good effect), and the lack of more experienced programmers to mentor me.\r\n\nI don't have any certifications, thinking experience and knowledge should speak loudly enough, but maybe that's needed to get initial attention?\n\nAny thoughts on what I'm doing wrong or could do better to put my best foot forward for mid-career DE roles?", "author_fullname": "t2_ejt24ok7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not getting interviews despite plentiful experience and skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1491j5j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686728102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I keep finding I&amp;#39;m not getting interviews despite I think tons of experience and skills, and I wonder if I&amp;#39;m just doing something drastically wrong in my approach or framing, or something I take for granted as a strength is actually a major red flag.&lt;/p&gt;\n\n&lt;p&gt;For starters, I got pushed up quite quickly to a senior manager level position for reasons I think of knowledge, skill, outspokenness, and vision, but also, frankly, just due to the needs of the company to fill that role from a pool of mostly junior talent. Basically, I went from DE to senior DE to manager in only three years, with about two years of experience before that as a data scientist, so that&amp;#39;s a total of ~6 years in data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve always worked with Python and cloud platforms, mostly AWS but also GCP, and recently, I&amp;#39;ve become very familiar with Databricks. I do have a solid understanding of databases as well, but it could be considered cursory. &lt;/p&gt;\n\n&lt;p&gt;If I had to characterize my technical skill set distribution among roles, I would say I am at like 20% cloud engineer, 40% big data engineer (python, spark, distributed computing, databases, Airflow and other orchestration approaches, but also batch scripting, AWS lambdas, etc), 20% analyst/scientist still, 20% software engineering and CICD approaches.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve led a number of projects, and have pushed forward and solved a number of challenges to get projects delivered, so my work even before becoming a manager involved communicating across teams, divisions, and global entities of the same group company.&lt;/p&gt;\n\n&lt;p&gt;And yet, I get no interviews. &lt;/p&gt;\n\n&lt;p&gt;On the one hand, I have few years, and maybe I also am doing a terrible job compressing my wide-ranging experiences into strictly relevant and focused messaging for the roles I apply to.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, I wonder if my title doesn&amp;#39;t read as seriously inflated (head of data engineering and a senior engineer) when viewed against the number of years, or maybe it&amp;#39;s assumed I&amp;#39;m not on the ball technically enough as a partial people manager.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m mainly going after non-managerial roles, in part because I feel I still have much to learn on the technical side, and I&amp;#39;d really like to deepen core skill sets with peer or even more senior mentorship. Maybe that is apparent and viewed as a serious weakness, and so I get passed on even though my demonstrable skills typically check all the boxes and more.&lt;/p&gt;\n\n&lt;p&gt;Technical weaknesses of mine would be in data modeling (never had to create and model a data store for a business unit from scratch; I&amp;#39;m trying to fill in the theory gap.by reading), optimizing non-distributed data stores for performance (I know the theory, but never had to do, but instead have optimized spark jobs and queries to good effect), and the lack of more experienced programmers to mentor me.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any certifications, thinking experience and knowledge should speak loudly enough, but maybe that&amp;#39;s needed to get initial attention?&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on what I&amp;#39;m doing wrong or could do better to put my best foot forward for mid-career DE roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1491j5j", "is_robot_indexable": true, "report_reasons": null, "author": "suterebaiiiii", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1491j5j/not_getting_interviews_despite_plentiful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1491j5j/not_getting_interviews_despite_plentiful/", "subreddit_subscribers": 110367, "created_utc": 1686728102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\n\n\nBefore, I saw several people who said that it was right to study while working, but I always thought that these people took the time to do some new mooc not very work-related. What I understood is that actually the best way to learn is to work on real work projects that use new knowledge, research and whatever else I need to develop myself, before I only studied tools and programming languages that I wouldn't even use in the work. I can even use moocs, but for projects that make sense and that I'm working on. Before, I was very tired of studying outside of work, sometimes even on the weekend and I didn't have the expected results, I believe that this way I can reach seniority at work. Do you also do something similar to this? I believe that dedicating work hours to the connection between work and study is much more valuable than simply taking an online course and not having daily practice with what you learned. I will no longer study after work hours, even to have a healthy balance in life.", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I think I finally understand the relationship between learning and work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1496ukf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686746400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before, I saw several people who said that it was right to study while working, but I always thought that these people took the time to do some new mooc not very work-related. What I understood is that actually the best way to learn is to work on real work projects that use new knowledge, research and whatever else I need to develop myself, before I only studied tools and programming languages that I wouldn&amp;#39;t even use in the work. I can even use moocs, but for projects that make sense and that I&amp;#39;m working on. Before, I was very tired of studying outside of work, sometimes even on the weekend and I didn&amp;#39;t have the expected results, I believe that this way I can reach seniority at work. Do you also do something similar to this? I believe that dedicating work hours to the connection between work and study is much more valuable than simply taking an online course and not having daily practice with what you learned. I will no longer study after work hours, even to have a healthy balance in life.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1496ukf", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1496ukf/i_think_i_finally_understand_the_relationship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1496ukf/i_think_i_finally_understand_the_relationship/", "subreddit_subscribers": 110367, "created_utc": 1686746400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Started a year ago with microsoft exams, started a minimum wage job doing DE and have been for 10 months and I've been offered an amazing job actually helping people and also exploring analytics/datascience and other stuff too. \n\nComplete DE freedom to engineer and explore and find ways to help people, bonus is its 1.5x my salary and offers senior level relatively quickly. \n\nI've always struggled and felt like an imposter but in such a short time I've come far and I can't wait to learn more. \n\nI suck at doing off job projects, I prefer having  data shoved in my face and told to fix or do something with it!\n\nHad a rough year but this has worked out amazingly and I'm thankful for everyone's support!\n\n(Sorry if it's slight brag)", "author_fullname": "t2_6o5h731v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 year since I started data engineer and I found the job of my dreams while you guys were gone \ud83d\ude2d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149fhb7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686767941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Started a year ago with microsoft exams, started a minimum wage job doing DE and have been for 10 months and I&amp;#39;ve been offered an amazing job actually helping people and also exploring analytics/datascience and other stuff too. &lt;/p&gt;\n\n&lt;p&gt;Complete DE freedom to engineer and explore and find ways to help people, bonus is its 1.5x my salary and offers senior level relatively quickly. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve always struggled and felt like an imposter but in such a short time I&amp;#39;ve come far and I can&amp;#39;t wait to learn more. &lt;/p&gt;\n\n&lt;p&gt;I suck at doing off job projects, I prefer having  data shoved in my face and told to fix or do something with it!&lt;/p&gt;\n\n&lt;p&gt;Had a rough year but this has worked out amazingly and I&amp;#39;m thankful for everyone&amp;#39;s support!&lt;/p&gt;\n\n&lt;p&gt;(Sorry if it&amp;#39;s slight brag)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "149fhb7", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous6156", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149fhb7/1_year_since_i_started_data_engineer_and_i_found/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149fhb7/1_year_since_i_started_data_engineer_and_i_found/", "subreddit_subscribers": 110367, "created_utc": 1686767941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help. I'm on the BI team at a large fortune 500 company with immature data pipelines for our analytics reporting and I am struggling. I have more of a tech background than data. Before I joined, reporting for my business domain has been outsourced to an offshore company that has produced unmaintainable/undocumented massive SQL queries with hardcoded conditions scattered/duplicated throughout subqueries and a mess of v1,v2,copy,test tables in production. Understanding the data flow takes hours of data archeology and I'm worried that others will think this a reflection of me rather than the messy structure.\n\nBusiness logic is littered throughout the entire reporting ecosystem (alteryx, stored procs, BI tool cubes, etc) and data ownership and knowledge is split across teams and team members (enterprise data architecture/offshore teams/business owners writing their own sql, etc). Domain reporting is siloed and we are all responsible for building our own data pipelines to our BI reporting tool for our specific domain stakeholders. My domain has the most stakeholders. Our team is not really supposed to be business owner facing but our intermediaries (the analysts) are doing their own thing running queries and building scrappy dashboards for their stakeholders with conversations between our teams mainly being \"how do I do x\" vs true collaboration. I'm consistently bogged down by incidents of things breaking and don't have time to focus on learning what I believe could be the solution to a lot of our problems (spoiler: dbt). The issues are glaringly obvious to me but I'm not always able to articulate my thoughts live (probably because idk what will sink in or make me sound stupid).\n\nThe offshore team that built everything is gone and it's now up to me to become the SME of this domain's data and reporting. I feel like I walked into a trap that will end with me being the face of failure and me pointing out these problems to my leadership comes off as excuses or complaining as this has been seemingly working up until now. (My anxiety about this is through the roof at this point and I've contemplated leaving before this happens).\n\nThe solution to me sounds like we need to scrap everything and model our pipelines correctly in a maintainable way with good documentation right in the code.\n\nHow do I convince my team/department that have been in this space much longer than I have that we need real change to something like dbt to help organize the mess and move forward? I feel like my inexperience and recent output struggles hurts my ability to impact positive change, especially when I basically have to tell the story of why the way the BI team/Analytics dept decided to operate led us to this. Do I continue to struggle and risk being fired or abandon ship for a more data-mature company? I now know want to become a data engineer or analytics engineer and rebuild everything but I can't get out from under the current situation and the stress is eating me alive. Nor do I have the DE hard skills/experience to get where I want to be yet if I were to leave for a similar role.\n\nAny advice at all is very appreciated. Thanks", "author_fullname": "t2_h4xz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help - how do I promote a better data culture when so new to the space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1499n97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686763445.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686753697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help. I&amp;#39;m on the BI team at a large fortune 500 company with immature data pipelines for our analytics reporting and I am struggling. I have more of a tech background than data. Before I joined, reporting for my business domain has been outsourced to an offshore company that has produced unmaintainable/undocumented massive SQL queries with hardcoded conditions scattered/duplicated throughout subqueries and a mess of v1,v2,copy,test tables in production. Understanding the data flow takes hours of data archeology and I&amp;#39;m worried that others will think this a reflection of me rather than the messy structure.&lt;/p&gt;\n\n&lt;p&gt;Business logic is littered throughout the entire reporting ecosystem (alteryx, stored procs, BI tool cubes, etc) and data ownership and knowledge is split across teams and team members (enterprise data architecture/offshore teams/business owners writing their own sql, etc). Domain reporting is siloed and we are all responsible for building our own data pipelines to our BI reporting tool for our specific domain stakeholders. My domain has the most stakeholders. Our team is not really supposed to be business owner facing but our intermediaries (the analysts) are doing their own thing running queries and building scrappy dashboards for their stakeholders with conversations between our teams mainly being &amp;quot;how do I do x&amp;quot; vs true collaboration. I&amp;#39;m consistently bogged down by incidents of things breaking and don&amp;#39;t have time to focus on learning what I believe could be the solution to a lot of our problems (spoiler: dbt). The issues are glaringly obvious to me but I&amp;#39;m not always able to articulate my thoughts live (probably because idk what will sink in or make me sound stupid).&lt;/p&gt;\n\n&lt;p&gt;The offshore team that built everything is gone and it&amp;#39;s now up to me to become the SME of this domain&amp;#39;s data and reporting. I feel like I walked into a trap that will end with me being the face of failure and me pointing out these problems to my leadership comes off as excuses or complaining as this has been seemingly working up until now. (My anxiety about this is through the roof at this point and I&amp;#39;ve contemplated leaving before this happens).&lt;/p&gt;\n\n&lt;p&gt;The solution to me sounds like we need to scrap everything and model our pipelines correctly in a maintainable way with good documentation right in the code.&lt;/p&gt;\n\n&lt;p&gt;How do I convince my team/department that have been in this space much longer than I have that we need real change to something like dbt to help organize the mess and move forward? I feel like my inexperience and recent output struggles hurts my ability to impact positive change, especially when I basically have to tell the story of why the way the BI team/Analytics dept decided to operate led us to this. Do I continue to struggle and risk being fired or abandon ship for a more data-mature company? I now know want to become a data engineer or analytics engineer and rebuild everything but I can&amp;#39;t get out from under the current situation and the stress is eating me alive. Nor do I have the DE hard skills/experience to get where I want to be yet if I were to leave for a similar role.&lt;/p&gt;\n\n&lt;p&gt;Any advice at all is very appreciated. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1499n97", "is_robot_indexable": true, "report_reasons": null, "author": "soorr", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499n97/help_how_do_i_promote_a_better_data_culture_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499n97/help_how_do_i_promote_a_better_data_culture_when/", "subreddit_subscribers": 110367, "created_utc": 1686753697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d8afn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Continuous Slack=&gt;ChatGPT=&gt;Google Sheets Pipeline using Estuary Flow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149h80m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1686772120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "estuary.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://estuary.dev/gpt-real-time-pipeline/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "149h80m", "is_robot_indexable": true, "report_reasons": null, "author": "johnnygraettinger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149h80m/a_continuous_slackchatgptgoogle_sheets_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://estuary.dev/gpt-real-time-pipeline/", "subreddit_subscribers": 110367, "created_utc": 1686772120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone. Just wanted to let you know that there\u2019s a 5 book bundle @ [Humble Bundle](https://www.humblebundle.com/books/popular-programming-languages-2023-oreilly-books?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_2_c_popularprogramminglanguages2023oreilly_bookbundle) going for 1\u20ac (or more if you want to donate to Code for America) that includes Scala Cookbook, Robust Python and more. There\u2019s also a 10 and 15 book bundle if you\u2019re interested in those books!\n\nOffer ends in 12 days, hope this helped you!", "author_fullname": "t2_9d8b8hr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Scala Cookbook (+ Robust Python &amp; more books) for 1\u20ac at Humble Bundle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149gppg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686770873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. Just wanted to let you know that there\u2019s a 5 book bundle @ &lt;a href=\"https://www.humblebundle.com/books/popular-programming-languages-2023-oreilly-books?hmb_source=&amp;amp;hmb_medium=product_tile&amp;amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_2_c_popularprogramminglanguages2023oreilly_bookbundle\"&gt;Humble Bundle&lt;/a&gt; going for 1\u20ac (or more if you want to donate to Code for America) that includes Scala Cookbook, Robust Python and more. There\u2019s also a 10 and 15 book bundle if you\u2019re interested in those books!&lt;/p&gt;\n\n&lt;p&gt;Offer ends in 12 days, hope this helped you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?auto=webp&amp;v=enabled&amp;s=145c5031dd9a76b3a193c59bb037b7f969636343", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff318a3e2d3d005fb2b97fba6815f8e46f0df195", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e533d028be1491f12d960c5d200ac7ab94084045", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdeb2123bb81cdeb7d8445bab1776ec7145007df", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e1fa92d72d541f6ea0ef6099d91cfc9c6cb4509", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42abec49d1559a82ba3501a0721124d8bac2044c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b179f527a048da516c574ee3436a15d9754f85b", "width": 1080, "height": 607}], "variants": {}, "id": "RyTlK6qn5A-hML7nwk6v7Ctu-pDz9VPLPbeDYzhPn4I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149gppg", "is_robot_indexable": true, "report_reasons": null, "author": "TauIsRC", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149gppg/psa_scala_cookbook_robust_python_more_books_for_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149gppg/psa_scala_cookbook_robust_python_more_books_for_1/", "subreddit_subscribers": 110367, "created_utc": 1686770873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to copy \\~50TB spread over millions of files. \n\n**Source**: Azure Data Lake Gen1\n\n**Destination**: Azure Data Lake Gen2\n\nUsing Azure Data Factory would be possible but there is a minimum cost per file and millions of files will quickly add up on the bill. So I'd like to avoid that. \n\nAre there any other tools out there available? \n\nI could write  python script myself and run it on a beefy VM in Azure. But adding retry functionality and keeping track of what's already been copied successfully so the script can be restarted will take some messing around to get right. It will be fun, but if there's something already developed that's probably faster. How would you parallelize the copying so many files could be copied simultaneously? I'm not read up on that detail currently.", "author_fullname": "t2_vcdigx7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Copy several TB between two Azure Data Lakes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1492cbc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686731107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to copy ~50TB spread over millions of files. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Source&lt;/strong&gt;: Azure Data Lake Gen1&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Destination&lt;/strong&gt;: Azure Data Lake Gen2&lt;/p&gt;\n\n&lt;p&gt;Using Azure Data Factory would be possible but there is a minimum cost per file and millions of files will quickly add up on the bill. So I&amp;#39;d like to avoid that. &lt;/p&gt;\n\n&lt;p&gt;Are there any other tools out there available? &lt;/p&gt;\n\n&lt;p&gt;I could write  python script myself and run it on a beefy VM in Azure. But adding retry functionality and keeping track of what&amp;#39;s already been copied successfully so the script can be restarted will take some messing around to get right. It will be fun, but if there&amp;#39;s something already developed that&amp;#39;s probably faster. How would you parallelize the copying so many files could be copied simultaneously? I&amp;#39;m not read up on that detail currently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1492cbc", "is_robot_indexable": true, "report_reasons": null, "author": "loudandclear11", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1492cbc/copy_several_tb_between_two_azure_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1492cbc/copy_several_tb_between_two_azure_data_lakes/", "subreddit_subscribers": 110367, "created_utc": 1686731107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious, whenever I look for examples and syntax, Apache has these one-liners like \"this is what it is and don't ask anymore questions\" lol.\n\n[https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row\\_number.html?highlight=row\\_number#pyspark.sql.functions.row\\_number](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number)\n\nCompared to Pandas docs, for example, which are more descriptive and useful. Thoughts?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why is Apache Pyspark documentation so...sparse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149g5zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686769576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious, whenever I look for examples and syntax, Apache has these one-liners like &amp;quot;this is what it is and don&amp;#39;t ask anymore questions&amp;quot; lol.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number\"&gt;https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Compared to Pandas docs, for example, which are more descriptive and useful. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149g5zk", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149g5zk/why_is_apache_pyspark_documentation_sosparse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149g5zk/why_is_apache_pyspark_documentation_sosparse/", "subreddit_subscribers": 110367, "created_utc": 1686769576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interested in learning KDB+ because getting into fund trading industry is always what I desire.\n\nI just realise so many investment bank trading teams and hedge funds are still using KDB+.\n\nIs there any learning material or beginner project for me to learn KDB+?\n\nThank you!", "author_fullname": "t2_txqvauef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone now learning KDB+?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149djon", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686763242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in learning KDB+ because getting into fund trading industry is always what I desire.&lt;/p&gt;\n\n&lt;p&gt;I just realise so many investment bank trading teams and hedge funds are still using KDB+.&lt;/p&gt;\n\n&lt;p&gt;Is there any learning material or beginner project for me to learn KDB+?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149djon", "is_robot_indexable": true, "report_reasons": null, "author": "Dice__R", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149djon/is_anyone_now_learning_kdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149djon/is_anyone_now_learning_kdb/", "subreddit_subscribers": 110367, "created_utc": 1686763242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Check out an E2E example of the beneof the new dagster DBT Integration in my blog post https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/", "author_fullname": "t2_8dvvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster DBT and OpenMetadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1499w55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686754275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out an E2E example of the beneof the new dagster DBT Integration in my blog post &lt;a href=\"https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/\"&gt;https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?auto=webp&amp;v=enabled&amp;s=aa32a37254e14adf3e475b1006064c87146e67e5", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d49440a898cd6eb78c5939cfe2480f33ac70d48", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=524221a933940f49dcb7659be8ffb496cb1bc1de", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29354e993b55adf8026761862b447fbf5c028285", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655bf1b2c7e35f378533d0b18ea04bad6a18830f", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea6342f16cde2177b5af1ed2ea83a69a739056ac", "width": 960, "height": 960}], "variants": {}, "id": "9XePCxBEEF3qzr3JG-bBuvoOQn1z5ZLCXspSZIlahwc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1499w55", "is_robot_indexable": true, "report_reasons": null, "author": "geoheil", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499w55/dagster_dbt_and_openmetadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499w55/dagster_dbt_and_openmetadata/", "subreddit_subscribers": 110367, "created_utc": 1686754275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A tech lead asked me to look into managing permissions and users on redshift for a ~100TB DB that around a dozen colleagues (data engineers, software engineers, data scientists, analysts) will be pulling pulling data from, creating new tables, running analysis, etc.  \n\nI am wondering what the general convention is here. Are you guys all just sharing admin credentials around the team (current practice in my team)? Do you have someone fulfill a DBA role that creates users inside of redshift, grants permissions, and sends them around to team members? Do you use [IAM roles to authenticate](https://docs.aws.amazon.com/redshift/latest/mgmt/generating-user-credentials.html)? \n\nElse, any good resources for role/user/permission management?", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Redshift Users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149c85c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686759999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A tech lead asked me to look into managing permissions and users on redshift for a ~100TB DB that around a dozen colleagues (data engineers, software engineers, data scientists, analysts) will be pulling pulling data from, creating new tables, running analysis, etc.  &lt;/p&gt;\n\n&lt;p&gt;I am wondering what the general convention is here. Are you guys all just sharing admin credentials around the team (current practice in my team)? Do you have someone fulfill a DBA role that creates users inside of redshift, grants permissions, and sends them around to team members? Do you use &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/generating-user-credentials.html\"&gt;IAM roles to authenticate&lt;/a&gt;? &lt;/p&gt;\n\n&lt;p&gt;Else, any good resources for role/user/permission management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149c85c", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149c85c/managing_redshift_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149c85c/managing_redshift_users/", "subreddit_subscribers": 110367, "created_utc": 1686759999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a scraper application that I want to run sporadically. The goal is to have a database for this but since it's really just a minor pet project/POC, I am totally not willing to use any managed SQL service because they are super expensive. But I do want a relational database. I was thinking I could just make use of SQLite? Has anyone done this before, can I just save the .db in cloud storage and use a connector?\n\nEdit: how about if I just use BigQuery. This data I have is not even 1GB, so it should be basically free, right?", "author_fullname": "t2_genrcwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap SQL in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149bpxt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686760151.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686758755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a scraper application that I want to run sporadically. The goal is to have a database for this but since it&amp;#39;s really just a minor pet project/POC, I am totally not willing to use any managed SQL service because they are super expensive. But I do want a relational database. I was thinking I could just make use of SQLite? Has anyone done this before, can I just save the .db in cloud storage and use a connector?&lt;/p&gt;\n\n&lt;p&gt;Edit: how about if I just use BigQuery. This data I have is not even 1GB, so it should be basically free, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149bpxt", "is_robot_indexable": true, "report_reasons": null, "author": "nacho_biznis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149bpxt/cheap_sql_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149bpxt/cheap_sql_in_gcp/", "subreddit_subscribers": 110367, "created_utc": 1686758755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone! I am looking for an in-depth explanations with examples of the different ETL (mostly T) services that GCP offers and when to use what, if anyone has a good resources (or don\u2019t mind writing it here) please share.\nLooking for when to use DataProc (lift and shift of Hadoop) VS Dataflow (for streaming) VS DataFusion (kind of basic version of Informatica/SSIS) VS SP in BigQuery (for ELT), I even worked in company where they are doing the T in Composer itself which is causing a hell of troubles and Composer Cluster is downtown more then up most of the times. Feel free to share the current architecture in your current company, real GCP projects are very limited on the internet. Appreciate everyone\u2019s help and time!", "author_fullname": "t2_6ot8pfmy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL - GCP Services !!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ar42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686756393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone! I am looking for an in-depth explanations with examples of the different ETL (mostly T) services that GCP offers and when to use what, if anyone has a good resources (or don\u2019t mind writing it here) please share.\nLooking for when to use DataProc (lift and shift of Hadoop) VS Dataflow (for streaming) VS DataFusion (kind of basic version of Informatica/SSIS) VS SP in BigQuery (for ELT), I even worked in company where they are doing the T in Composer itself which is causing a hell of troubles and Composer Cluster is downtown more then up most of the times. Feel free to share the current architecture in your current company, real GCP projects are very limited on the internet. Appreciate everyone\u2019s help and time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149ar42", "is_robot_indexable": true, "report_reasons": null, "author": "WeirdWorldDz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149ar42/etl_gcp_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149ar42/etl_gcp_services/", "subreddit_subscribers": 110367, "created_utc": 1686756393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, maybe a bit of a naive question. Our company traditionally uses Informatica as our ETL for a long time. \n\nOur team is looking for something a bit more UI friendly to do ETL or ELT. My question is can we use Fivetran to ingest from various sources (I know fivetran offers over 200+). Then use Fivetran to parse xml, json, etc into .csv for analytics ready? Or do we need a different tool? \n\nHow much volume fivetran can handle? What are the pros and cons?", "author_fullname": "t2_vlbvypwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Fivetran for ingestion and transforming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149ibrz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686774743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, maybe a bit of a naive question. Our company traditionally uses Informatica as our ETL for a long time. &lt;/p&gt;\n\n&lt;p&gt;Our team is looking for something a bit more UI friendly to do ETL or ELT. My question is can we use Fivetran to ingest from various sources (I know fivetran offers over 200+). Then use Fivetran to parse xml, json, etc into .csv for analytics ready? Or do we need a different tool? &lt;/p&gt;\n\n&lt;p&gt;How much volume fivetran can handle? What are the pros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149ibrz", "is_robot_indexable": true, "report_reasons": null, "author": "dataeng_328", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149ibrz/using_fivetran_for_ingestion_and_transforming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149ibrz/using_fivetran_for_ingestion_and_transforming/", "subreddit_subscribers": 110367, "created_utc": 1686774743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dx287f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RealTime Data Processing \u2014 Integrate Kafka with Flink To S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 60, "top_awarded_type": null, "hide_score": false, "name": "t3_149frg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0rNZqqABnXkq9772hY2W2QFNqsAIbiuu30fHFEb_t4Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686768621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.shellkode.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.shellkode.com/realtime-data-processing-integrate-kafka-with-flink-to-s3-2228783f09c5", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?auto=webp&amp;v=enabled&amp;s=c5710a999ebd59de89dc2127a8f4882be209eb14", "width": 1200, "height": 519}, "resolutions": [{"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7de175429ffd5893dbba2da14b8856c41b97d99f", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a671008823320022391899e7bec8a58e87f61878", "width": 216, "height": 93}, {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d557f51a61998afed8a2e97bc4f8526c6db1767", "width": 320, "height": 138}, {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36b6782f9c6ec76e4234d715fb4107cae0b40c02", "width": 640, "height": 276}, {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f1fa087b7cd39c5aa9f3a5b4db448f73e966356", "width": 960, "height": 415}, {"url": "https://external-preview.redd.it/3e6lTkeQFlqFJ3p6wjQH-0qxhBCWbDPE3KMShIEla6A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42cb17c9251f780247bbedc3b2277ff513da78ea", "width": 1080, "height": 467}], "variants": {}, "id": "6YpA0G1qMCMqzAuUkh2oDNYWeIPQfZb4FuhT5HMyEQo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "149frg5", "is_robot_indexable": true, "report_reasons": null, "author": "TheSqlAdmin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149frg5/realtime_data_processing_integrate_kafka_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.shellkode.com/realtime-data-processing-integrate-kafka-with-flink-to-s3-2228783f09c5", "subreddit_subscribers": 110367, "created_utc": 1686768621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_wdxkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AutoML pipeline for tabular data on VertexAI in Go", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_149f400", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QGu0lGGJreh9LtxJkH0TxAetigLL1cLkFkf7MwBnx9Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686767045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pgaleone.eu", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pgaleone.eu/golang/vertexai/2023/06/14/automl-pipeline-tabular-data-vertexai-go-golang/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?auto=webp&amp;v=enabled&amp;s=d895e20ca88cd59d8a539fcaff9533fc5c1e408e", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd161604dc7ce5a90a66effc72bbebe13a7324b0", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/Kif1VkEGmSAkH1AWLfl8hJIMYa-HyIuZz3dahqrOOzo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf4122d034eec0be3ad89d9b0a4e0682f8c6205d", "width": 216, "height": 216}], "variants": {}, "id": "QCb-J1Fr_047ebumrG01fT3ttdPG7-jWDogxAKgzMBQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "149f400", "is_robot_indexable": true, "report_reasons": null, "author": "pgaleone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149f400/automl_pipeline_for_tabular_data_on_vertexai_in_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pgaleone.eu/golang/vertexai/2023/06/14/automl-pipeline-tabular-data-vertexai-go-golang/", "subreddit_subscribers": 110367, "created_utc": 1686767045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a complete beginner in the Data Engineering field. I am planning to make a project to stream NYC Taxi data from a CSV file and display some analytics on a dashboard. I want to extract some features from the existing features in the csv file for which I am planning to use Spark.\n\nMy proposed pipeline is CSV -&gt; Kafka Producer -&gt; Take in the data using Spark Streaming -&gt; Elastic Search -&gt; Graphana/some other visualization tool that you can recommend?\n\nI am confused whether to do some data preprocessing and feature extraction before producing the data to the Kafka broker or after it is collected by spark I should perform manipulations on the batch of data which is consumed?", "author_fullname": "t2_9fupektn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query regarding feature extraction in data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149dhek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686763093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a complete beginner in the Data Engineering field. I am planning to make a project to stream NYC Taxi data from a CSV file and display some analytics on a dashboard. I want to extract some features from the existing features in the csv file for which I am planning to use Spark.&lt;/p&gt;\n\n&lt;p&gt;My proposed pipeline is CSV -&amp;gt; Kafka Producer -&amp;gt; Take in the data using Spark Streaming -&amp;gt; Elastic Search -&amp;gt; Graphana/some other visualization tool that you can recommend?&lt;/p&gt;\n\n&lt;p&gt;I am confused whether to do some data preprocessing and feature extraction before producing the data to the Kafka broker or after it is collected by spark I should perform manipulations on the batch of data which is consumed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149dhek", "is_robot_indexable": true, "report_reasons": null, "author": "Tis-is-the-way", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149dhek/query_regarding_feature_extraction_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149dhek/query_regarding_feature_extraction_in_data/", "subreddit_subscribers": 110367, "created_utc": 1686763093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Very interesting set of slides detailing different designs and the tradeoffs involved\n\nhttps://preview.redd.it/l2v2fc2hyz5b1.png?width=1517&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9dba68881943e655c73988be9e42a06ba8c72b60\n\nhttps://preview.redd.it/j8bdarbiyz5b1.png?width=1536&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f384cfb583518b2471d265a72c1d75b069b90897\n\n\ud83d\udcd4 Slides here: [**https://speakerdeck.com/stevenz3wu/streaming-from-apache-iceberg-qcon-ny-2023**](https://speakerdeck.com/stevenz3wu/streaming-from-apache-iceberg-qcon-ny-2023)", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[QCon NY] Streaming from Apache Iceberg - Building Low-Latency and Cost Effective Data Pipelines - Steven Wu @ Apple", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 81, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l2v2fc2hyz5b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ac236ab378b788b3c9dbeca5ecb5cd17e1a4852"}, {"y": 125, "x": 216, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c71b942f6b38097771aca459c1943ef2a02fc233"}, {"y": 185, "x": 320, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97ded9ef08ce918874bab09cadb809fa7f8fbd1b"}, {"y": 370, "x": 640, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9800f53c3b9997567bdb409d9414dc18c12c60b5"}, {"y": 555, "x": 960, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a4fad68cea7dd1b9bc1bc59ab15ff6d2718abcd"}, {"y": 625, "x": 1080, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9866a66cde47c85a0eb79e321d569fcc094567e8"}], "s": {"y": 878, "x": 1517, "u": "https://preview.redd.it/l2v2fc2hyz5b1.png?width=1517&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9dba68881943e655c73988be9e42a06ba8c72b60"}, "id": "l2v2fc2hyz5b1"}, "j8bdarbiyz5b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b2a0e8e54a1a47677e9c7c53cd79e54f3317a0a"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0873a190a792f3c09874318d01554cad9d24ea89"}, {"y": 184, "x": 320, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=946fca0cd56019db2a5043298e74f519268dab4a"}, {"y": 368, "x": 640, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e0da2da0cccc9fe1c7a495f791aa040709c31b4"}, {"y": 552, "x": 960, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97926af73dcec9419fc89bf8f21dfb6745e22647"}, {"y": 621, "x": 1080, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6512fbef0543b7caebc05d35d55e2e14bcb85cc"}], "s": {"y": 884, "x": 1536, "u": "https://preview.redd.it/j8bdarbiyz5b1.png?width=1536&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f384cfb583518b2471d265a72c1d75b069b90897"}, "id": "j8bdarbiyz5b1"}}, "name": "t3_1499x6x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_5zoRfMGIzvlS2hJimm9b_HwVAgJnq5t8xPfT0OmkQQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1686754341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Very interesting set of slides detailing different designs and the tradeoffs involved&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/l2v2fc2hyz5b1.png?width=1517&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9dba68881943e655c73988be9e42a06ba8c72b60\"&gt;https://preview.redd.it/l2v2fc2hyz5b1.png?width=1517&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9dba68881943e655c73988be9e42a06ba8c72b60&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j8bdarbiyz5b1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f384cfb583518b2471d265a72c1d75b069b90897\"&gt;https://preview.redd.it/j8bdarbiyz5b1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f384cfb583518b2471d265a72c1d75b069b90897&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcd4 Slides here: &lt;a href=\"https://speakerdeck.com/stevenz3wu/streaming-from-apache-iceberg-qcon-ny-2023\"&gt;&lt;strong&gt;https://speakerdeck.com/stevenz3wu/streaming-from-apache-iceberg-qcon-ny-2023&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?auto=webp&amp;v=enabled&amp;s=d349be3942dc1b09fed54c24349a59feebe46429", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58982277606d2980896bd493b2e035d6e995c0e0", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a584f68e175d215d2063a956119ac2aa9e4e1e2e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66ad741ef67ebba8da6c583ea42ea63a3c044366", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eac63f6d5cf62b236a5f1760a43550b249654dfd", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf910cc40dd31632b3bed7a5eec3b576c3df4c82", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/YjA9AvmGPtvGrvbN_-nXuiwEiNO-cfMV0Pw_5Gc0m-0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d31da5e785d8e3a59402f4e53bbb17b168a2597", "width": 1080, "height": 607}], "variants": {}, "id": "8pJEsGRff6q5C18lxQje3YApqH7YCkaMeXJ9HjvnzgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1499x6x", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499x6x/qcon_ny_streaming_from_apache_iceberg_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499x6x/qcon_ny_streaming_from_apache_iceberg_building/", "subreddit_subscribers": 110367, "created_utc": 1686754341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am fairly inexperienced in Azure I have been tasked with building a data warehouse for a client. We have all of their data in a Cosmos DB and transaction data in Postgres. \n\nMy first approach was to use ADF and Dataflows, but I find the drag and drop interface incredibly limiting, it doesn\u2019t work well with all datetypes or JSON records.\n\nI was thinking of integrating Python scripts in the pipelines, where I could make some custom functions that takes in a data frame as input written with Spark, but I can\u2019t really seem to figure out how to make something that would work dynamically for different source containers.\n\nI was also considering making a bunch of sequential SQL views, and then use stored procedures to do the transformation and validation, but I kind of feel like this defeats the purpose. Can anyone help me in the right direction ?", "author_fullname": "t2_8112m7hs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on building a DW in azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1499jir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686753453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am fairly inexperienced in Azure I have been tasked with building a data warehouse for a client. We have all of their data in a Cosmos DB and transaction data in Postgres. &lt;/p&gt;\n\n&lt;p&gt;My first approach was to use ADF and Dataflows, but I find the drag and drop interface incredibly limiting, it doesn\u2019t work well with all datetypes or JSON records.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of integrating Python scripts in the pipelines, where I could make some custom functions that takes in a data frame as input written with Spark, but I can\u2019t really seem to figure out how to make something that would work dynamically for different source containers.&lt;/p&gt;\n\n&lt;p&gt;I was also considering making a bunch of sequential SQL views, and then use stored procedures to do the transformation and validation, but I kind of feel like this defeats the purpose. Can anyone help me in the right direction ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1499jir", "is_robot_indexable": true, "report_reasons": null, "author": "Olafcitoo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499jir/looking_for_advice_on_building_a_dw_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499jir/looking_for_advice_on_building_a_dw_in_azure/", "subreddit_subscribers": 110367, "created_utc": 1686753453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI wanted to share my current situation and get some insights from you all. I work in a small startup with a team of no more than 15 people. I started as a Trainee Data Engineer, but there was no one available to train me, which has been one of the biggest professional challenges I've faced. Despite the lack of a dedicated Data Engineer on the team, I received support from my colleagues, data scientists, and developers. While it was initially daunting to learn everything on my own, it turned out to be a tremendous opportunity for professional growth (with a touch of anxiety, haha), and the management has been incredibly supportive.\n\nThat said, I recently received a promotion from Trainee Data Engineer to the lead engineer of the team, essentially continuing the work I've been doing but with a salary increase and more responsibility.\n\nThis brings me to something I've always wanted in my career\u2014working in a company that already has an established Data Engineering team, where I can learn from experienced professionals and, at some point, have the opportunity to be mentor by others seniors engineers, which I haven't had the chance yet. I've always relied on self-learning through trial and error and books.\n\nToday, I received confirmation that I passed a selection process for one of the largest finance companies in the country, where I would join as a Junior Data Engineer in an established team.\n\nGiven this situation, I'm strongly inclined to accept the offer. However, I would like to hear your thoughts on leaving my current company, where the management has placed a lot of trust in me, and where I have been responsible for end-to-end Data Engineering projects. Leaving abruptly would leave them in a tough spot.\n\nI'm considering ensuring that I complete all documentation for my current projects and providing a smooth transition process for the newly hired engineer or any replacements who may come in.\n\nI appreciate any insights or advice you can provide. Thank you!", "author_fullname": "t2_v87ay3j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Growth Dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498vss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686751787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I wanted to share my current situation and get some insights from you all. I work in a small startup with a team of no more than 15 people. I started as a Trainee Data Engineer, but there was no one available to train me, which has been one of the biggest professional challenges I&amp;#39;ve faced. Despite the lack of a dedicated Data Engineer on the team, I received support from my colleagues, data scientists, and developers. While it was initially daunting to learn everything on my own, it turned out to be a tremendous opportunity for professional growth (with a touch of anxiety, haha), and the management has been incredibly supportive.&lt;/p&gt;\n\n&lt;p&gt;That said, I recently received a promotion from Trainee Data Engineer to the lead engineer of the team, essentially continuing the work I&amp;#39;ve been doing but with a salary increase and more responsibility.&lt;/p&gt;\n\n&lt;p&gt;This brings me to something I&amp;#39;ve always wanted in my career\u2014working in a company that already has an established Data Engineering team, where I can learn from experienced professionals and, at some point, have the opportunity to be mentor by others seniors engineers, which I haven&amp;#39;t had the chance yet. I&amp;#39;ve always relied on self-learning through trial and error and books.&lt;/p&gt;\n\n&lt;p&gt;Today, I received confirmation that I passed a selection process for one of the largest finance companies in the country, where I would join as a Junior Data Engineer in an established team.&lt;/p&gt;\n\n&lt;p&gt;Given this situation, I&amp;#39;m strongly inclined to accept the offer. However, I would like to hear your thoughts on leaving my current company, where the management has placed a lot of trust in me, and where I have been responsible for end-to-end Data Engineering projects. Leaving abruptly would leave them in a tough spot.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering ensuring that I complete all documentation for my current projects and providing a smooth transition process for the newly hired engineer or any replacements who may come in.&lt;/p&gt;\n\n&lt;p&gt;I appreciate any insights or advice you can provide. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1498vss", "is_robot_indexable": true, "report_reasons": null, "author": "sensacaosensacional", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1498vss/career_growth_dilemma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1498vss/career_growth_dilemma/", "subreddit_subscribers": 110367, "created_utc": 1686751787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now our team is pretty old-school and everyone creates their own local dev environment using a `requirements.txt` file and a bootstrapping doc that outlines any other steps necessary to recreate prod.  We have images for our Airflow servers for easy redeployment, and we're considering containerizing these to use for local dev work.  This seems like a natural progression, and will reduce any room for issues or inconsistencies in setting up a dev environment.  For anyone who's done or considered this, what are your thoughts? And what best practices should we be following?", "author_fullname": "t2_22ksp1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here use a container (Docker or otherwise) as their development environment? What are the best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149igv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686775839.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686775092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now our team is pretty old-school and everyone creates their own local dev environment using a &lt;code&gt;requirements.txt&lt;/code&gt; file and a bootstrapping doc that outlines any other steps necessary to recreate prod.  We have images for our Airflow servers for easy redeployment, and we&amp;#39;re considering containerizing these to use for local dev work.  This seems like a natural progression, and will reduce any room for issues or inconsistencies in setting up a dev environment.  For anyone who&amp;#39;s done or considered this, what are your thoughts? And what best practices should we be following?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149igv5", "is_robot_indexable": true, "report_reasons": null, "author": "x1084", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149igv5/does_anyone_here_use_a_container_docker_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149igv5/does_anyone_here_use_a_container_docker_or/", "subreddit_subscribers": 110367, "created_utc": 1686775092.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}