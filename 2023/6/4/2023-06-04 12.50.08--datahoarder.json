{"kind": "Listing", "data": {"after": "t3_13zezl4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4htci70y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datahoarding Costs 1985", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13zdu6b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Eu12kKgeYPnhczko0I-fy5LwJWy4sNsi_P8hVPUWLHg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685800942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/xwr7v40z6t3b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/xwr7v40z6t3b1.jpg?auto=webp&amp;v=enabled&amp;s=e0b75c7d1903bb38aa0cdf85060a3ecd0f65f8b9", "width": 816, "height": 3168}, "resolutions": [{"url": "https://preview.redd.it/xwr7v40z6t3b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f460031da950ccc965536d2842e4774c0aa337ac", "width": 108, "height": 216}, {"url": "https://preview.redd.it/xwr7v40z6t3b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4515964b4f929f05a3f3f2b7a82a58a64522c41d", "width": 216, "height": 432}, {"url": "https://preview.redd.it/xwr7v40z6t3b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7552cb7d5d01865d836a2d908515f4cf38631f0", "width": 320, "height": 640}, {"url": "https://preview.redd.it/xwr7v40z6t3b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b232b6e58cac9c7d3379d869360b9b6484d5e0ac", "width": 640, "height": 1280}], "variants": {}, "id": "QY3kyKdFM3Wvzu6vrLn2uyKajB8gzDObJ9PkzC8X57c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13zdu6b", "is_robot_indexable": true, "report_reasons": null, "author": "titoCA321", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zdu6b/datahoarding_costs_1985/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/xwr7v40z6t3b1.jpg", "subreddit_subscribers": 686012, "created_utc": 1685800942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nWelcome to the Warhammer Collection,\n\nthis is the eight update (June 2023) we're doing on the WH lore and thanks to the feedback received we managed to archive:\n\n\\- an improved sorting  \n\\- added new released books  \n\\- replaced/deleted many non-retail\n\nALL the books have been renamed with Author's Name Surname - Book title (Series) for an easy search.\n\nThe retail tag means how the book was ripped\n\n\\[Retail\\] - Books that i have bought myself and i have removed the DRM thru calibre  \n(Retail) - Books shared by other users whom DRM has been remove correctly thru calibre  \n(retail) - Books shared by other users who purchased the books but not drm'ed correctly with calibre\n\nWith  this I'm hoping to give the reader a complete collection of WH books in  their best available format and somehow well sorted.\n\nIf  you enjoyed this and found some issues such as typos, bad  scans/conversions, misplaced books and pretty much anything please send  me a message.\n\nLastly a huge thanks goes to all the people that helped out with this project. Thank you!\n\n**Torrent**\n\nmagnet:?xt=urn:btih:cabb1b65ad56be929798de20109fdfb96c6f540b", "author_fullname": "t2_nmbmr98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warhammer Universe Collection [Updated June 2023]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zwspv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Warhammer Collection", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685842564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to the Warhammer Collection,&lt;/p&gt;\n\n&lt;p&gt;this is the eight update (June 2023) we&amp;#39;re doing on the WH lore and thanks to the feedback received we managed to archive:&lt;/p&gt;\n\n&lt;p&gt;- an improved sorting&lt;br/&gt;\n- added new released books&lt;br/&gt;\n- replaced/deleted many non-retail&lt;/p&gt;\n\n&lt;p&gt;ALL the books have been renamed with Author&amp;#39;s Name Surname - Book title (Series) for an easy search.&lt;/p&gt;\n\n&lt;p&gt;The retail tag means how the book was ripped&lt;/p&gt;\n\n&lt;p&gt;[Retail] - Books that i have bought myself and i have removed the DRM thru calibre&lt;br/&gt;\n(Retail) - Books shared by other users whom DRM has been remove correctly thru calibre&lt;br/&gt;\n(retail) - Books shared by other users who purchased the books but not drm&amp;#39;ed correctly with calibre&lt;/p&gt;\n\n&lt;p&gt;With  this I&amp;#39;m hoping to give the reader a complete collection of WH books in  their best available format and somehow well sorted.&lt;/p&gt;\n\n&lt;p&gt;If  you enjoyed this and found some issues such as typos, bad  scans/conversions, misplaced books and pretty much anything please send  me a message.&lt;/p&gt;\n\n&lt;p&gt;Lastly a huge thanks goes to all the people that helped out with this project. Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Torrent&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;magnet:?xt=urn:btih:cabb1b65ad56be929798de20109fdfb96c6f540b&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13zwspv", "is_robot_indexable": true, "report_reasons": null, "author": "RedHeadedKhajiit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zwspv/warhammer_universe_collection_updated_june_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zwspv/warhammer_universe_collection_updated_june_2023/", "subreddit_subscribers": 686012, "created_utc": 1685842564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use hard disk sentinel, it takes nearly 100 hours to do 8TB:\n\nOverwrites the disk surface with special initialization pattern to restore the sectors to default (empty) status and reads back sector contents, to verify if they are accessible and consistent. Forces the analysis of any weak sectors and verifies any hidden problems and fixes them by reallocation of bad sectors (this is drive regeneration).\n\nEnables better use of the disk as after the test the spare area will be used instead of any problematic sectors.\nVery intensive and time-consuming test, especially if the level (the number of overwrite cycles) is set to higher value.\n\nThe simple version of this test is usually (incorrectly) called as low level format by other tools.\n\nThe test measures transfer time for all blocks to reveal which areas of the surface are slower. As the block is slower, the associated color is darker.", "author_fullname": "t2_buw97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how do you treat (new to you) HDDs? is [Reinitialize disk surface] too much?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1405lq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685865533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use hard disk sentinel, it takes nearly 100 hours to do 8TB:&lt;/p&gt;\n\n&lt;p&gt;Overwrites the disk surface with special initialization pattern to restore the sectors to default (empty) status and reads back sector contents, to verify if they are accessible and consistent. Forces the analysis of any weak sectors and verifies any hidden problems and fixes them by reallocation of bad sectors (this is drive regeneration).&lt;/p&gt;\n\n&lt;p&gt;Enables better use of the disk as after the test the spare area will be used instead of any problematic sectors.\nVery intensive and time-consuming test, especially if the level (the number of overwrite cycles) is set to higher value.&lt;/p&gt;\n\n&lt;p&gt;The simple version of this test is usually (incorrectly) called as low level format by other tools.&lt;/p&gt;\n\n&lt;p&gt;The test measures transfer time for all blocks to reveal which areas of the surface are slower. As the block is slower, the associated color is darker.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1405lq7", "is_robot_indexable": true, "report_reasons": null, "author": "_QUAKE_", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1405lq7/how_do_you_treat_new_to_you_hdds_is_reinitialize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1405lq7/how_do_you_treat_new_to_you_hdds_is_reinitialize/", "subreddit_subscribers": 686012, "created_utc": 1685865533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure people don't get datahoarding or consider it stupid. I for one consider it essential because I am obsessed with data preservation. I considered datahoarding a hobby or a borderline disease until today when I was looking on youtube for a video about migraines. It was a beautiful animation in the style of kurzgesagt that perfectly explained not just what happens during a migraine but also the before and after of a migraine which I consider just as or more important than the migraine itself. Low and behold 3 or 4 years later after seeing the video, I can no longer find it on youtube. So an essential piece of medical knowledge exposed in an absolutely perfect package is nowhere to be found. This is why datahoarding, this is why I am writing wikis, tutorials and trying to instruct my wife to the best of my ability how to take over when I am dead. Because loosing information like this is nothing but detrimental to the human race. Is 70% of our hobby useless? Yes, but the rest of the 30% is PRICELESS. This is why starting from now I am also archiving youtube videos.", "author_fullname": "t2_3ouq5gy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why datahoarding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ztri2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685835537.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685835342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure people don&amp;#39;t get datahoarding or consider it stupid. I for one consider it essential because I am obsessed with data preservation. I considered datahoarding a hobby or a borderline disease until today when I was looking on youtube for a video about migraines. It was a beautiful animation in the style of kurzgesagt that perfectly explained not just what happens during a migraine but also the before and after of a migraine which I consider just as or more important than the migraine itself. Low and behold 3 or 4 years later after seeing the video, I can no longer find it on youtube. So an essential piece of medical knowledge exposed in an absolutely perfect package is nowhere to be found. This is why datahoarding, this is why I am writing wikis, tutorials and trying to instruct my wife to the best of my ability how to take over when I am dead. Because loosing information like this is nothing but detrimental to the human race. Is 70% of our hobby useless? Yes, but the rest of the 30% is PRICELESS. This is why starting from now I am also archiving youtube videos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13ztri2", "is_robot_indexable": true, "report_reasons": null, "author": "ihatenamehoggers", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ztri2/why_datahoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ztri2/why_datahoarding/", "subreddit_subscribers": 686012, "created_utc": 1685835342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 2x2tb HDD's that i want to copy the data from to a 4tb HDD.\n\nI use Windows 10, I have heard of robocopy but upon looking into it, it just looks far too complicated for my needs, I have no interest in learning what each command does, I simply just want all the data from the 2x2tb drives copied over to my 4tb hdd.\n\n&amp;#x200B;\n\nI mistakenly just did it with windows explorer a long time back and didn't think much of it when it finished, However its came to my attention that at least some files got corrupted along the way, so i intend to do it all over again to ensure that the data is transfered correctly.\n\n&amp;#x200B;\n\nI mean if i have to use robocopy then whatever.. I'll have to suck it up and learn about it, Ideally i wanted a more straight forward method, I don't mind if it's paid software.\n\n&amp;#x200B;\n\nTIA", "author_fullname": "t2_evrgtr0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most Noob Friendly way to copy large amounts of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zjwne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685814117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2x2tb HDD&amp;#39;s that i want to copy the data from to a 4tb HDD.&lt;/p&gt;\n\n&lt;p&gt;I use Windows 10, I have heard of robocopy but upon looking into it, it just looks far too complicated for my needs, I have no interest in learning what each command does, I simply just want all the data from the 2x2tb drives copied over to my 4tb hdd.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I mistakenly just did it with windows explorer a long time back and didn&amp;#39;t think much of it when it finished, However its came to my attention that at least some files got corrupted along the way, so i intend to do it all over again to ensure that the data is transfered correctly.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I mean if i have to use robocopy then whatever.. I&amp;#39;ll have to suck it up and learn about it, Ideally i wanted a more straight forward method, I don&amp;#39;t mind if it&amp;#39;s paid software.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zjwne", "is_robot_indexable": true, "report_reasons": null, "author": "BadFixMate", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zjwne/most_noob_friendly_way_to_copy_large_amounts_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zjwne/most_noob_friendly_way_to_copy_large_amounts_of/", "subreddit_subscribers": 686012, "created_utc": 1685814117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "starting my de-duping project. I have some video files. Some clocking in at 2G.  I was planning on using sha512 to enable a quick file compare (same or not)\n\nFirst question is sha512 overkill? Second question in order to index it in a mysql table what hash could i use to hash the sha512 down to a more \"indexable\" size?", "author_fullname": "t2_kz3sxo9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using hash to compare files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zxaz9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685843849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;starting my de-duping project. I have some video files. Some clocking in at 2G.  I was planning on using sha512 to enable a quick file compare (same or not)&lt;/p&gt;\n\n&lt;p&gt;First question is sha512 overkill? Second question in order to index it in a mysql table what hash could i use to hash the sha512 down to a more &amp;quot;indexable&amp;quot; size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zxaz9", "is_robot_indexable": true, "report_reasons": null, "author": "jmclaugmi", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zxaz9/using_hash_to_compare_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zxaz9/using_hash_to_compare_files/", "subreddit_subscribers": 686012, "created_utc": 1685843849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Opinion changes over time and bait/switch hardware is commonplace these days - what's the current opinion on \"Recertified\" drives bouught directly from WD? I'm aiming to expand my Plex storage so I wouldn't be absolutely crushed if the drive kicks the bucket somewhere along the way in the future so this isn't mission critical data, more just inconvenient to replace if the drive dies - Anyone picked up a recert lately? looking at https://www.westerndigital.com/en-gb/products/portable-drives/wd-elements-desktop-hdd-recertified#RWDBWLG0140HBK-EESN", "author_fullname": "t2_95m5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD \"Recertified\" drives (direct from WD) - what's the current feeling from /r/DataHoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zpiaj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685826200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Opinion changes over time and bait/switch hardware is commonplace these days - what&amp;#39;s the current opinion on &amp;quot;Recertified&amp;quot; drives bouught directly from WD? I&amp;#39;m aiming to expand my Plex storage so I wouldn&amp;#39;t be absolutely crushed if the drive kicks the bucket somewhere along the way in the future so this isn&amp;#39;t mission critical data, more just inconvenient to replace if the drive dies - Anyone picked up a recert lately? looking at &lt;a href=\"https://www.westerndigital.com/en-gb/products/portable-drives/wd-elements-desktop-hdd-recertified#RWDBWLG0140HBK-EESN\"&gt;https://www.westerndigital.com/en-gb/products/portable-drives/wd-elements-desktop-hdd-recertified#RWDBWLG0140HBK-EESN&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?auto=webp&amp;v=enabled&amp;s=b54e0080c64b12b840fa08900f1e205c803c4d2a", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e120bc7f706e53d1a04291f4cddc3d73d42c023", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecd3510859beb7b7bd6c315c58720fd09f2c55a5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=162d40047ca46f756d50e6f307b00e5799353ae5", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bcb2f4104fe8c767c8a307958578138121641e1", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a2c20c0ada7414c8e04397f20d7526c315b2787", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/tC03cqodMETYrFtjS-AnF6reJRs73Dtj2pj78vrnCQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82586fb51ec6c61b4a5fdbdad67f14fd9906fcbb", "width": 1080, "height": 1080}], "variants": {}, "id": "QHwzssv2OMyIdW0TGsO0y7vwdsLQXd1z1wIbaXo92_U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB-PLEX", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zpiaj", "is_robot_indexable": true, "report_reasons": null, "author": "PimpDaddyHD", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/13zpiaj/wd_recertified_drives_direct_from_wd_whats_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zpiaj/wd_recertified_drives_direct_from_wd_whats_the/", "subreddit_subscribers": 686012, "created_utc": 1685826200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\n\nI'm looking for advice to upgrade by hardware in the best possible way.\n\nI have a pretty basic setup now - old NUC with 6200U processor and cheap 8TB external HDD. I use it for dockerized Plex/\\*arrs/VPN/etc. Now, I'd like to migrate to something better, with main goal of having a bit more space and storing multiple backups of my personal files (and in general start backing up until it's too late), while reusing my current hardware and keeping in more or less budget. Also I'd like it to be reasonably noisy (it will be in my living room). Let me phrase my questions as good as I can:\n\n1. My main point of doubt. Initially I thought about continuing using my NUC and buy one or two HDDs and a USB-C enclosure, something budget like ICY BOX on [amazon.de](https://amazon.de), but then I've read that it's not a really good solution and a real NAS like Synology will be much better. I don't really want to sell the NUC and lose access to real Linux system, so... are USB-C enclosures really bad/unreliable? If not, can you recommend a brand available in EU?\n2. In terms of storage, seems 12TB would be enough for me and I'm looking to buy Seagate  ST12000VN0008, which costs about $260 here. Any reason it's a bad choice? WD RED costs about $350.\n3. Would it make sense to have RAID1 as a form of backup (not from deletes but from hardware failures)? I use Google Drive as a day-to-day backup but I'd like to duplicate it. Alternatively, instead of RAID1, would it make sense to have cold storage like Amazon S3 Glacier (for personal photos/videos and favorite/rare medias)?", "author_fullname": "t2_kk5we", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations on upgrade to a proper setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zrojd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685836888.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685830740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for advice to upgrade by hardware in the best possible way.&lt;/p&gt;\n\n&lt;p&gt;I have a pretty basic setup now - old NUC with 6200U processor and cheap 8TB external HDD. I use it for dockerized Plex/*arrs/VPN/etc. Now, I&amp;#39;d like to migrate to something better, with main goal of having a bit more space and storing multiple backups of my personal files (and in general start backing up until it&amp;#39;s too late), while reusing my current hardware and keeping in more or less budget. Also I&amp;#39;d like it to be reasonably noisy (it will be in my living room). Let me phrase my questions as good as I can:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;My main point of doubt. Initially I thought about continuing using my NUC and buy one or two HDDs and a USB-C enclosure, something budget like ICY BOX on &lt;a href=\"https://amazon.de\"&gt;amazon.de&lt;/a&gt;, but then I&amp;#39;ve read that it&amp;#39;s not a really good solution and a real NAS like Synology will be much better. I don&amp;#39;t really want to sell the NUC and lose access to real Linux system, so... are USB-C enclosures really bad/unreliable? If not, can you recommend a brand available in EU?&lt;/li&gt;\n&lt;li&gt;In terms of storage, seems 12TB would be enough for me and I&amp;#39;m looking to buy Seagate  ST12000VN0008, which costs about $260 here. Any reason it&amp;#39;s a bad choice? WD RED costs about $350.&lt;/li&gt;\n&lt;li&gt;Would it make sense to have RAID1 as a form of backup (not from deletes but from hardware failures)? I use Google Drive as a day-to-day backup but I&amp;#39;d like to duplicate it. Alternatively, instead of RAID1, would it make sense to have cold storage like Amazon S3 Glacier (for personal photos/videos and favorite/rare medias)?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zrojd", "is_robot_indexable": true, "report_reasons": null, "author": "zzeneg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zrojd/recommendations_on_upgrade_to_a_proper_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zrojd/recommendations_on_upgrade_to_a_proper_setup/", "subreddit_subscribers": 686012, "created_utc": 1685830740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had bought 6 lightly used 18tb HDDs from eBay.  I was running 6 badblocks sessions simultaneously via tmux on my truenas scale install to test them.  After about a week of running badblocks had completed 3, of its 4, tests and had not detected any errors yet.  The power just blink and all my systems restarted.\n\n\"tmux attach\" yields \"no sessions\".  Is there a way to resume badblocks from where it left off?  Which of the 4 patterns does badblocks run last?\n\nThank you.\n\nUpdate:  I've used \"badblocks -b 8192 -ws -t 0x00 /dev/sd\\*\" for each \\*HDD and badblocks is running through the final test on all of them. ", "author_fullname": "t2_16k9lu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to resume badblocks after a power failure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zkkpi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685823938.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685815572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had bought 6 lightly used 18tb HDDs from eBay.  I was running 6 badblocks sessions simultaneously via tmux on my truenas scale install to test them.  After about a week of running badblocks had completed 3, of its 4, tests and had not detected any errors yet.  The power just blink and all my systems restarted.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;tmux attach&amp;quot; yields &amp;quot;no sessions&amp;quot;.  Is there a way to resume badblocks from where it left off?  Which of the 4 patterns does badblocks run last?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n\n&lt;p&gt;Update:  I&amp;#39;ve used &amp;quot;badblocks -b 8192 -ws -t 0x00 /dev/sd*&amp;quot; for each *HDD and badblocks is running through the final test on all of them. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zkkpi", "is_robot_indexable": true, "report_reasons": null, "author": "AwefulUsername", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zkkpi/is_there_a_way_to_resume_badblocks_after_a_power/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zkkpi/is_there_a_way_to_resume_badblocks_after_a_power/", "subreddit_subscribers": 686012, "created_utc": 1685815572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I copy everything from point A to point B with Filezilla.  Filezilla says \"done\", no failed files/folders.\n\nBut how can I trust that?  How can I make sure that everything that was at point A actually got copied to point B?  I've had times where it has messed up despite looking ok.\n\nIs there an easy way to do this?  I'm fairly noobish but want to learn.  \n\nAlso outside of filezilla, just copying from drive to drive, or wherever, how can I make sure it's all good?  In the easiest way possible?\n\nNo one wants that feeling, when your heart sinks, years later when you open a folder and realize, it's all corrupted/missing/empty.", "author_fullname": "t2_vr55ge7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to I ensure file integrity with Filezilla?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ztg4n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685834618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I copy everything from point A to point B with Filezilla.  Filezilla says &amp;quot;done&amp;quot;, no failed files/folders.&lt;/p&gt;\n\n&lt;p&gt;But how can I trust that?  How can I make sure that everything that was at point A actually got copied to point B?  I&amp;#39;ve had times where it has messed up despite looking ok.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to do this?  I&amp;#39;m fairly noobish but want to learn.  &lt;/p&gt;\n\n&lt;p&gt;Also outside of filezilla, just copying from drive to drive, or wherever, how can I make sure it&amp;#39;s all good?  In the easiest way possible?&lt;/p&gt;\n\n&lt;p&gt;No one wants that feeling, when your heart sinks, years later when you open a folder and realize, it&amp;#39;s all corrupted/missing/empty.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ztg4n", "is_robot_indexable": true, "report_reasons": null, "author": "GrandyRetroCandy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ztg4n/how_to_i_ensure_file_integrity_with_filezilla/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ztg4n/how_to_i_ensure_file_integrity_with_filezilla/", "subreddit_subscribers": 686012, "created_utc": 1685834618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there. I am on Mac and and using Google Drive Desktop to sync between local and cloud. I picked streaming (not mirroring) so that I'd save hard drive space on \\~1T of data.\n\nWhen I added files to google drive by uploading directly from computer via web browser, those are clearly only in the cloud.\n\nMy question is...if I move files on my computer to the Google Drive folder, will it upload to cloud and then delete from my computer?\n\nIt does not seem like that is happening. Using that method, I seem to have everything on cloud and on my computer.\n\nThanks in advance for any help.\n\n&amp;#x200B;\n\nEDIT: fixed 1GB of data to 1T", "author_fullname": "t2_tfmzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zphgm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685827786.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685826154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there. I am on Mac and and using Google Drive Desktop to sync between local and cloud. I picked streaming (not mirroring) so that I&amp;#39;d save hard drive space on ~1T of data.&lt;/p&gt;\n\n&lt;p&gt;When I added files to google drive by uploading directly from computer via web browser, those are clearly only in the cloud.&lt;/p&gt;\n\n&lt;p&gt;My question is...if I move files on my computer to the Google Drive folder, will it upload to cloud and then delete from my computer?&lt;/p&gt;\n\n&lt;p&gt;It does not seem like that is happening. Using that method, I seem to have everything on cloud and on my computer.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: fixed 1GB of data to 1T&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zphgm", "is_robot_indexable": true, "report_reasons": null, "author": "Mixleflick", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zphgm/google_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zphgm/google_drive/", "subreddit_subscribers": 686012, "created_utc": 1685826154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Why do you black out the serials when posting your HD photos?   Scams?  How?", "author_fullname": "t2_fwo7huu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard drive serials on photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zov79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685824891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why do you black out the serials when posting your HD photos?   Scams?  How?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zov79", "is_robot_indexable": true, "report_reasons": null, "author": "det1rac", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zov79/hard_drive_serials_on_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zov79/hard_drive_serials_on_photos/", "subreddit_subscribers": 686012, "created_utc": 1685824891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Maybe this time someone is willing to help.\n\nScenario: I want to create a backup, that I can later check for its integrity. I have Original Files OF from what I made Back Up Files BF1 and BF2 on different drives. I'm using some Tool to check if its copied correctly and saving a hashlist.txt/html/csv whatever of the backuped content. Then after two years I want to check if some corruption has occured in the meantime so I want to check the Hash List of a folders files supposed Hashes with the actual hashes and if something is corrupted using the Data from OF2 to repair it.\n\nHow can I do it, which tool I can use to achieve this?", "author_fullname": "t2_2ykfm39v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2nd Try: Compare a Hash List with folders actual contents", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zlmcf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685817870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe this time someone is willing to help.&lt;/p&gt;\n\n&lt;p&gt;Scenario: I want to create a backup, that I can later check for its integrity. I have Original Files OF from what I made Back Up Files BF1 and BF2 on different drives. I&amp;#39;m using some Tool to check if its copied correctly and saving a hashlist.txt/html/csv whatever of the backuped content. Then after two years I want to check if some corruption has occured in the meantime so I want to check the Hash List of a folders files supposed Hashes with the actual hashes and if something is corrupted using the Data from OF2 to repair it.&lt;/p&gt;\n\n&lt;p&gt;How can I do it, which tool I can use to achieve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zlmcf", "is_robot_indexable": true, "report_reasons": null, "author": "KingPaddy0618", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zlmcf/2nd_try_compare_a_hash_list_with_folders_actual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zlmcf/2nd_try_compare_a_hash_list_with_folders_actual/", "subreddit_subscribers": 686012, "created_utc": 1685817870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello\nhi im newbie, recently i iust ran out of my 2tb wd my passport storage so im planning to buy new bigger storage 4tb wd my passport unfortunately its not available in my local PC store ,  as for 4tb they only available for wd my book which is for desktop use because it need power adapter plugged during use.. meanwhile im using a laptop , i tried to avoid any desktop stuff (not battery powered) due to unexpected sudden power outage / blackout in my country which i heard it will damage PC or hard drive.\nso i still thinking about to buy 4tb my book or 2tb my passport..the store owner also offer me another option to use orico 3.5 hdd enclosure and buy 3.5 4tb wd blue hdd for the enclosure but it cost more expensive they said orico power adapter have better protection and if the enclosure fail the hdd still can be use meanwhile both my book and passport cant due to encrypt thing is it really worth to buy enclosure and hdd separately?\n\ndo unexpected power outage really damage the modern hdd nowadays? or it just only happen to older type of hdd?  i also read about nowadays hdd are almost all SMR and i believe the drive i planning to buy are SMR which i read the drive aren't worth to buy , are they really that bad ? do i need to worried about SMR thing if i only to use for save unwatched movies (i usually copy around 50-100gb every few months of unwatched movies) , audio (flac ,mp3) ?\n\nthank you in advance", "author_fullname": "t2_5zrv1y0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "external hard drive question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zkccg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685815326.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685815093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello\nhi im newbie, recently i iust ran out of my 2tb wd my passport storage so im planning to buy new bigger storage 4tb wd my passport unfortunately its not available in my local PC store ,  as for 4tb they only available for wd my book which is for desktop use because it need power adapter plugged during use.. meanwhile im using a laptop , i tried to avoid any desktop stuff (not battery powered) due to unexpected sudden power outage / blackout in my country which i heard it will damage PC or hard drive.\nso i still thinking about to buy 4tb my book or 2tb my passport..the store owner also offer me another option to use orico 3.5 hdd enclosure and buy 3.5 4tb wd blue hdd for the enclosure but it cost more expensive they said orico power adapter have better protection and if the enclosure fail the hdd still can be use meanwhile both my book and passport cant due to encrypt thing is it really worth to buy enclosure and hdd separately?&lt;/p&gt;\n\n&lt;p&gt;do unexpected power outage really damage the modern hdd nowadays? or it just only happen to older type of hdd?  i also read about nowadays hdd are almost all SMR and i believe the drive i planning to buy are SMR which i read the drive aren&amp;#39;t worth to buy , are they really that bad ? do i need to worried about SMR thing if i only to use for save unwatched movies (i usually copy around 50-100gb every few months of unwatched movies) , audio (flac ,mp3) ?&lt;/p&gt;\n\n&lt;p&gt;thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zkccg", "is_robot_indexable": true, "report_reasons": null, "author": "Dazzbee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zkccg/external_hard_drive_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zkccg/external_hard_drive_question/", "subreddit_subscribers": 686012, "created_utc": 1685815093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently decided to re-organize my drives and the back-ups. Till now I used simply the Windows Default copy and paste. After reading about Checksums i wanted to do it more professionally now and gave the free version of tera copy a try. Basic functions are not that much confusing, but it is only checking the Sums between the original files and the copy directly. \n\nHow can I check later the integrity of my backup, when I don't have the original files anymore but still the checksum list that is created from the original? I have seen no option to choose the content and then compare it to a choosen list.", "author_fullname": "t2_2ykfm39v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tapped in Tera Copy recently (Questions regarding file integrety)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zcbqm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685797537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently decided to re-organize my drives and the back-ups. Till now I used simply the Windows Default copy and paste. After reading about Checksums i wanted to do it more professionally now and gave the free version of tera copy a try. Basic functions are not that much confusing, but it is only checking the Sums between the original files and the copy directly. &lt;/p&gt;\n\n&lt;p&gt;How can I check later the integrity of my backup, when I don&amp;#39;t have the original files anymore but still the checksum list that is created from the original? I have seen no option to choose the content and then compare it to a choosen list.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zcbqm", "is_robot_indexable": true, "report_reasons": null, "author": "KingPaddy0618", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zcbqm/tapped_in_tera_copy_recently_questions_regarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zcbqm/tapped_in_tera_copy_recently_questions_regarding/", "subreddit_subscribers": 686012, "created_utc": 1685797537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bing AI says this is the correct subreddit to ask this in!\n\nI have a Tandberg  Data LSO5 HH external tape drive, it's connected to a Dell H200 SAS HBA on a machine running Windows 10 Pro (a test PC freshly formatted to test the drive out)\n\nThe drive and adapter card are detected in device manager.\n\nI followed the instructions at [https://techmattr.wordpress.com/2016/04/11/updated-sas-hba-crossflashing-or-flashing-to-it-mode-dell-perc-h200-and-h310/](https://techmattr.wordpress.com/2016/04/11/updated-sas-hba-crossflashing-or-flashing-to-it-mode-dell-perc-h200-and-h310/) to flash it into IT mode.\n\nWhen running ITDT, the drive is not found during a scan, but if I go into TapeUtil, I can \"open\" the drive, and see its address, etc., I can also eject tapes from with TapeUtil\n\nIf I attempt to add the drive to the diagnostic control centre, the software doesn't complain if I enter the correct address, \\\\\\\\.\\\\scsi0:, it doesn't do anything, but if I enter \\\\\\\\.\\\\scsi1:, it complains: \"Specified device couldn't be detected!\"\n\nI have tried ITDT V9.6, 9.5 and 9.0, all to no avail.\n\nOf course, Veeam doesn't \"see\" the driver either.\n\nThanks in advance", "author_fullname": "t2_14p6odn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tape Drive Problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zbn52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685795946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bing AI says this is the correct subreddit to ask this in!&lt;/p&gt;\n\n&lt;p&gt;I have a Tandberg  Data LSO5 HH external tape drive, it&amp;#39;s connected to a Dell H200 SAS HBA on a machine running Windows 10 Pro (a test PC freshly formatted to test the drive out)&lt;/p&gt;\n\n&lt;p&gt;The drive and adapter card are detected in device manager.&lt;/p&gt;\n\n&lt;p&gt;I followed the instructions at &lt;a href=\"https://techmattr.wordpress.com/2016/04/11/updated-sas-hba-crossflashing-or-flashing-to-it-mode-dell-perc-h200-and-h310/\"&gt;https://techmattr.wordpress.com/2016/04/11/updated-sas-hba-crossflashing-or-flashing-to-it-mode-dell-perc-h200-and-h310/&lt;/a&gt; to flash it into IT mode.&lt;/p&gt;\n\n&lt;p&gt;When running ITDT, the drive is not found during a scan, but if I go into TapeUtil, I can &amp;quot;open&amp;quot; the drive, and see its address, etc., I can also eject tapes from with TapeUtil&lt;/p&gt;\n\n&lt;p&gt;If I attempt to add the drive to the diagnostic control centre, the software doesn&amp;#39;t complain if I enter the correct address, \\\\.\\scsi0:, it doesn&amp;#39;t do anything, but if I enter \\\\.\\scsi1:, it complains: &amp;quot;Specified device couldn&amp;#39;t be detected!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I have tried ITDT V9.6, 9.5 and 9.0, all to no avail.&lt;/p&gt;\n\n&lt;p&gt;Of course, Veeam doesn&amp;#39;t &amp;quot;see&amp;quot; the driver either.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?auto=webp&amp;v=enabled&amp;s=38d34d4e6043d42e0e454cbfa199f507e92e0a4a", "width": 1024, "height": 680}, "resolutions": [{"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9036140b9d62151c73b7ce392d3d85c868e1de60", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ba81441b43f0a7fc45445fe57731a396823acc7", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bb1993c2b324394d16bd1bdd9e60558fce6403a", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21a6b93d1fa66349dcadbfd22c4ef9c0646bedcc", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/xgfKjm2qaCy-sDLygalH9i1nXAnvYSqk_FzaN7KyGWw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5778a800f14ad8b3446bbdd9995f02d7b7e67550", "width": 960, "height": 637}], "variants": {}, "id": "eqCyGN-VCjRNUS1qPIeNNsuCS7vzebvTtUvx69d9brY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zbn52", "is_robot_indexable": true, "report_reasons": null, "author": "CleeBrummie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zbn52/tape_drive_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zbn52/tape_drive_problems/", "subreddit_subscribers": 686012, "created_utc": 1685795946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This might not quite be the best place to ask, but you guys here are very good on advice like this.\n\nI have MythTV (alternatives didn't really do the job as well, and I have experience running MythTV 15 years ago) running on a Raspberry Pi 4, recording all my favourite shows, transcoding them and copying them over to my NAS to be watched via Plex.\n\nThe drive is a cheap SiliconPower SATA SSD drive, I\u2019m pretty sure this is one with SLC cache instead of DRAM cache. It\u2019s connected via a USB3 interface that gets full SATA speed to the Pi.\n\nI decided to have a look at the wear, and I\u2019ve already used 7% in 2634 hours; or 109 days. It\u2019s not like it\u2019s rapidly on its way out, but probably not well suited to the application.\n\n**Question**\n\nIs there a drive that would be better suited to this application? I think the drives above 500GB usually have a better TBW. Also, while I know a spinny HDD would be even better, complexity goes up and write bandwidth goes down.", "author_fullname": "t2_5g468zv7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD for TV/PVR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1409vpf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685877255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might not quite be the best place to ask, but you guys here are very good on advice like this.&lt;/p&gt;\n\n&lt;p&gt;I have MythTV (alternatives didn&amp;#39;t really do the job as well, and I have experience running MythTV 15 years ago) running on a Raspberry Pi 4, recording all my favourite shows, transcoding them and copying them over to my NAS to be watched via Plex.&lt;/p&gt;\n\n&lt;p&gt;The drive is a cheap SiliconPower SATA SSD drive, I\u2019m pretty sure this is one with SLC cache instead of DRAM cache. It\u2019s connected via a USB3 interface that gets full SATA speed to the Pi.&lt;/p&gt;\n\n&lt;p&gt;I decided to have a look at the wear, and I\u2019ve already used 7% in 2634 hours; or 109 days. It\u2019s not like it\u2019s rapidly on its way out, but probably not well suited to the application.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Is there a drive that would be better suited to this application? I think the drives above 500GB usually have a better TBW. Also, while I know a spinny HDD would be even better, complexity goes up and write bandwidth goes down.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1409vpf", "is_robot_indexable": true, "report_reasons": null, "author": "iwashackedlastweek", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1409vpf/ssd_for_tvpvr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1409vpf/ssd_for_tvpvr/", "subreddit_subscribers": 686012, "created_utc": 1685877255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "SanDisk has released a firmware update for the SSD issues that a lot of people were facing. \nHowever, they also released a tool to check if a certain SSD is effected by this issue or not.\nMy SSD matches the model number for the effected drives, but doesn\u2019t match the serial for it in their effected drives database. Should I upgrade the firmware anyway or skip it? \nI haven\u2019t faced any issues with the SSD so far, except for it running hot even when not in use. Not sure if the firmware update could potentially have a fix for that in it.", "author_fullname": "t2_bz7yxcb4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme Pro Firmware update release", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1409m0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685876561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SanDisk has released a firmware update for the SSD issues that a lot of people were facing. \nHowever, they also released a tool to check if a certain SSD is effected by this issue or not.\nMy SSD matches the model number for the effected drives, but doesn\u2019t match the serial for it in their effected drives database. Should I upgrade the firmware anyway or skip it? \nI haven\u2019t faced any issues with the SSD so far, except for it running hot even when not in use. Not sure if the firmware update could potentially have a fix for that in it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1409m0e", "is_robot_indexable": true, "report_reasons": null, "author": "otherworldly_mirror", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1409m0e/sandisk_extreme_pro_firmware_update_release/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1409m0e/sandisk_extreme_pro_firmware_update_release/", "subreddit_subscribers": 686012, "created_utc": 1685876561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there, I bought some seagate exos 10tb drives and did not realize they were SAS not SATA. Definitely on me for not researching but Im a little sad seeing how pricey the external usb enclosures cost? \n\nI do understand now these are enterprise so doesnt seem like it was meant for that. I just want to backup my info on these, dont care to do a nas as im also reading all about the noise here, is there any simple or cheap way to just get connected to the drives via usb or similar?\n\nAll im reading is how it is expensive, shouldn't even work, etc. please let me know! Also I read [https://www.reddit.com/r/DataHoarder/comments/13tjcgi/howto\\_maybe\\_the\\_cheapest\\_way\\_to\\_use\\_48\\_sas\\_drives/](https://www.reddit.com/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/) so I see its possible with some pcie slots etc. but I guess Im also trying to ask here if Im in too over my head with these SAS drives, as nothing I have is compatible. thanks!\n\n\nThe three top comments are all across the board on this haha one says keep another says sell another is down the middle- and thanks so much for that!! All good points and hopefully people can reference this in the future. Still thinking the direction I wanna go here.", "author_fullname": "t2_7e878", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Drive options for Seagate Exos 10TB SAS Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1402hfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685881763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685856877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I bought some seagate exos 10tb drives and did not realize they were SAS not SATA. Definitely on me for not researching but Im a little sad seeing how pricey the external usb enclosures cost? &lt;/p&gt;\n\n&lt;p&gt;I do understand now these are enterprise so doesnt seem like it was meant for that. I just want to backup my info on these, dont care to do a nas as im also reading all about the noise here, is there any simple or cheap way to just get connected to the drives via usb or similar?&lt;/p&gt;\n\n&lt;p&gt;All im reading is how it is expensive, shouldn&amp;#39;t even work, etc. please let me know! Also I read &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/\"&gt;https://www.reddit.com/r/DataHoarder/comments/13tjcgi/howto_maybe_the_cheapest_way_to_use_48_sas_drives/&lt;/a&gt; so I see its possible with some pcie slots etc. but I guess Im also trying to ask here if Im in too over my head with these SAS drives, as nothing I have is compatible. thanks!&lt;/p&gt;\n\n&lt;p&gt;The three top comments are all across the board on this haha one says keep another says sell another is down the middle- and thanks so much for that!! All good points and hopefully people can reference this in the future. Still thinking the direction I wanna go here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1402hfd", "is_robot_indexable": true, "report_reasons": null, "author": "Walk_Yo_Dinosaur", "discussion_type": null, "num_comments": 10, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1402hfd/external_drive_options_for_seagate_exos_10tb_sas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1402hfd/external_drive_options_for_seagate_exos_10tb_sas/", "subreddit_subscribers": 686012, "created_utc": 1685856877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi experts,\nI have about 50k photos/vids from making copies of backups of copies of backups. So many duplicates.\nI have tried a few of the recommended programs to find and remove the dupes but they all seem to struggle with that many comparisons (understandably) and they tend to give up or just miss large numbers from being overwhelmed.\n\nCan anyone recommend one that is up for the job that I can leave running for a week to clean up this mess?\nThanks", "author_fullname": "t2_r4bj5dsj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photo/video sorter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zwj8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685841916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi experts,\nI have about 50k photos/vids from making copies of backups of copies of backups. So many duplicates.\nI have tried a few of the recommended programs to find and remove the dupes but they all seem to struggle with that many comparisons (understandably) and they tend to give up or just miss large numbers from being overwhelmed.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend one that is up for the job that I can leave running for a week to clean up this mess?\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zwj8l", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Paint2888", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zwj8l/photovideo_sorter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zwj8l/photovideo_sorter/", "subreddit_subscribers": 686012, "created_utc": 1685841916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long shot, but had anyone archived the videos uploaded to doctor3who.blogspot.com? Unfortunately, the blog was taken down by Google in 2019.", "author_fullname": "t2_ae38umf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Archive doctor3who.blogspot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zsye4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685833514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long shot, but had anyone archived the videos uploaded to doctor3who.blogspot.com? Unfortunately, the blog was taken down by Google in 2019.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "13zsye4", "is_robot_indexable": true, "report_reasons": null, "author": "SuperWhoLockMED", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zsye4/anyone_archive_doctor3whoblogspot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zsye4/anyone_archive_doctor3whoblogspot/", "subreddit_subscribers": 686012, "created_utc": 1685833514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a [used drive](https://serverpartdeals.com/products/western-digital-ultrastar-dc-hc530-wuh721414ale604-0f31156-14tb-7-2k-rpm-sata-6gb-s-512e-se-power-disable-pin-3-5-refurbished-hdd?variant=39251267584042) from serverpartdeals and tried to set it up today, but in the process I made a huge mistake: somehow I initialized  (but thankfully, didn't format) over one of my old drives thinking that was the drive I just bought. Turns out that newly bought drive refuses to be to be read in windows via disk management or diskpart and by bios refuses to tell  me any info on any sata drives currently connected to my computer.\n\nThankfully I can [still see the old partition](https://i.imgur.com/wwmgj6T.png) via DMDE, but from what I've searched, it seems that doesn't necessarily mean I can recover the partition in place and will probably have to copy it to another disk. But unfortunately, the only other drive that has enough space is newly bought disk.", "author_fullname": "t2_gqxuculs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with data recovery and windows not recognizing disk.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zm31g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685819364.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685818902.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a &lt;a href=\"https://serverpartdeals.com/products/western-digital-ultrastar-dc-hc530-wuh721414ale604-0f31156-14tb-7-2k-rpm-sata-6gb-s-512e-se-power-disable-pin-3-5-refurbished-hdd?variant=39251267584042\"&gt;used drive&lt;/a&gt; from serverpartdeals and tried to set it up today, but in the process I made a huge mistake: somehow I initialized  (but thankfully, didn&amp;#39;t format) over one of my old drives thinking that was the drive I just bought. Turns out that newly bought drive refuses to be to be read in windows via disk management or diskpart and by bios refuses to tell  me any info on any sata drives currently connected to my computer.&lt;/p&gt;\n\n&lt;p&gt;Thankfully I can &lt;a href=\"https://i.imgur.com/wwmgj6T.png\"&gt;still see the old partition&lt;/a&gt; via DMDE, but from what I&amp;#39;ve searched, it seems that doesn&amp;#39;t necessarily mean I can recover the partition in place and will probably have to copy it to another disk. But unfortunately, the only other drive that has enough space is newly bought disk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?auto=webp&amp;v=enabled&amp;s=75356ba56e4c53449dda56208e65b6d853476890", "width": 1339, "height": 1018}, "resolutions": [{"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abccfdb6d92449d0ded3573179c0e50d8428becb", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b887b677a8d338a47c447ae2a115a09ccaa935cf", "width": 216, "height": 164}, {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a53dd206f0d50228770a9e0dc0e7567f2d86b42", "width": 320, "height": 243}, {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14b9a566e831278a8567fff92917999313e5f702", "width": 640, "height": 486}, {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c42d0a5149e3f6858b5d2b3866c91346fceb18af", "width": 960, "height": 729}, {"url": "https://external-preview.redd.it/uGq4JuJBdoAOze0fq9GACTzZ3HIFU56D9z4RpoNJsiI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3be551625123ee5d629ee697f3d34b0af9d8a77", "width": 1080, "height": 821}], "variants": {}, "id": "gP-8Ogdq-MYF8OxPYP2DGaLOIrWvgoZJhC5N8jBPPJ0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zm31g", "is_robot_indexable": true, "report_reasons": null, "author": "kromerless", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zm31g/help_with_data_recovery_and_windows_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zm31g/help_with_data_recovery_and_windows_not/", "subreddit_subscribers": 686012, "created_utc": 1685818902.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The store I went to quoted me 2x to 5x the price of it(3120 EGP, so from 6240 to 15600 EGP) and they would charge me per TB for the data(the data itself was from the late 90s/early 2000s and to the day of its fall I was filling it up and there was about 947 GB free of the 3.64 TB usable data)", "author_fullname": "t2_andpu9r2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This HDD got knocked from the desktop over months ago, and it worked 1 TIME since it fell, now the computers recognize the hardware and makes the \"device connected\" sound, but it doesn't recognize the partition and the storage capacity of it and makes a bad clicking sound. Is it repairable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_13zjg7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ftE5O7PZIam3X5byRxVFg3zkXthX3kbaLCIHT3Ee5GE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685813115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The store I went to quoted me 2x to 5x the price of it(3120 EGP, so from 6240 to 15600 EGP) and they would charge me per TB for the data(the data itself was from the late 90s/early 2000s and to the day of its fall I was filling it up and there was about 947 GB free of the 3.64 TB usable data)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/smhd7teq7u3b1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?auto=webp&amp;v=enabled&amp;s=f553c5ed9aab6120b2c54a012a4090f278928d26", "width": 6120, "height": 8160}, "resolutions": [{"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=268fe76dabe5359ea045b6f42c051a11c93ff919", "width": 108, "height": 144}, {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=986c90a4a0a22b6e27c3dbc6cb39829b090ebd11", "width": 216, "height": 288}, {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91a65dedee8a0715ea4c23bfb843acc5867c23e5", "width": 320, "height": 426}, {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=299af3bae73864af7a7aeb0859a10557c40db378", "width": 640, "height": 853}, {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e190c16dff672cfcfa40dda2cf9be786741d007f", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/smhd7teq7u3b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67b7179b082fe78b0c4c8d02446150ef012fb0a5", "width": 1080, "height": 1440}], "variants": {}, "id": "XiMnhKnSLW_Y9MJ72DbAgywPQ7EuGK8p5ljIqrlNcSo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zjg7i", "is_robot_indexable": true, "report_reasons": null, "author": "EiadSherif2008", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zjg7i/this_hdd_got_knocked_from_the_desktop_over_months/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/smhd7teq7u3b1.jpg", "subreddit_subscribers": 686012, "created_utc": 1685813115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a 4TB Seagate External HDD. I've been having problems every time I connect it to the PC It tries to scan it for errors. If I do scan, It fails but sometimes I'm still able to read what's on the drive. If I ignore the scan I can see what's on it but it won't allow me to copy any of my data over to another HDD to back it up.\n\nCan I fix this? They are important", "author_fullname": "t2_6703mp1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Pending Sector Count: 99 and Uncorrectable Sector Counts: 99", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ziv5j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685811865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a 4TB Seagate External HDD. I&amp;#39;ve been having problems every time I connect it to the PC It tries to scan it for errors. If I do scan, It fails but sometimes I&amp;#39;m still able to read what&amp;#39;s on the drive. If I ignore the scan I can see what&amp;#39;s on it but it won&amp;#39;t allow me to copy any of my data over to another HDD to back it up.&lt;/p&gt;\n\n&lt;p&gt;Can I fix this? They are important&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13ziv5j", "is_robot_indexable": true, "report_reasons": null, "author": "ZAN0ZAN", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13ziv5j/current_pending_sector_count_99_and_uncorrectable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13ziv5j/current_pending_sector_count_99_and_uncorrectable/", "subreddit_subscribers": 686012, "created_utc": 1685811865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there!\n\nI have a bunch of used hard drives and i want to test them all one by one for bad sectors and make sure i won't have any trouble with data loss.\n\nSo, i want you to recommend me a list of software for testing them properly in every way possible.\n\nThanks!", "author_fullname": "t2_gj61x9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zezl4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685803508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of used hard drives and i want to test them all one by one for bad sectors and make sure i won&amp;#39;t have any trouble with data loss.&lt;/p&gt;\n\n&lt;p&gt;So, i want you to recommend me a list of software for testing them properly in every way possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "13zezl4", "is_robot_indexable": true, "report_reasons": null, "author": "Harald_Odin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/13zezl4/software_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/13zezl4/software_recommendation/", "subreddit_subscribers": 686012, "created_utc": 1685803508.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}