{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.\n\nI'm looking for a source around questions like:\n\n\\- Given a source data (JSON, CSV), derive insights to answer questions\n\n\\- Clean up a given dataset to answer questions etc.\n\n\\- Python dictionary / Json API response manipulation.\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the Leetcode equivalent for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13znm1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685822212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a source around questions like:&lt;/p&gt;\n\n&lt;p&gt;- Given a source data (JSON, CSV), derive insights to answer questions&lt;/p&gt;\n\n&lt;p&gt;- Clean up a given dataset to answer questions etc.&lt;/p&gt;\n\n&lt;p&gt;- Python dictionary / Json API response manipulation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13znm1j", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "subreddit_subscribers": 108867, "created_utc": 1685822212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n# How to integrate data quality test in Python ETL pipeline | Test Data Pipelines | Data Quality\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\n**Integrate test cases in ETL pipelines**\n\n[**https://www.youtube.com/watch?v=7FPksG-LYOA&amp;t**](https://www.youtube.com/watch?v=7FPksG-LYOA&amp;t=2s)\n\nTopics covered:\n\n* Data Pipeline\n* Data Quality Tests\n* ETL\n\nTech Stack: **Python, PyTest, Postgres, SQL Server**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate data quality test in ETL pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zuhvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685837047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;How to integrate data quality test in Python ETL pipeline | Test Data Pipelines | Data Quality&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Integrate test cases in ETL pipelines&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=7FPksG-LYOA&amp;amp;t=2s\"&gt;&lt;strong&gt;https://www.youtube.com/watch?v=7FPksG-LYOA&amp;amp;t&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Pipeline&lt;/li&gt;\n&lt;li&gt;Data Quality Tests&lt;/li&gt;\n&lt;li&gt;ETL&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Python, PyTest, Postgres, SQL Server&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?auto=webp&amp;v=enabled&amp;s=cc00a333a7b06b373828f090e8368795bb2f12fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8d6ed9317e1c112f7c716c3b0bf6d59af4772d3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a83d67bf2da459bca296526def8419e6e62420d1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e75c70ce661878447e5dea257f1bce63ade2952f", "width": 320, "height": 240}], "variants": {}, "id": "ZLDBG7h3Vxm0DQa9d03I9XYvP7WTijx5CREbZX5zQIY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zuhvl", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zuhvl/how_to_integrate_data_quality_test_in_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zuhvl/how_to_integrate_data_quality_test_in_etl_pipeline/", "subreddit_subscribers": 108867, "created_utc": 1685837047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \"Hello everyone, I'm considering starting a career in the field of data and I'm trying to choose between Data Science (DS) or Data Engineering (DE). However, I believe that the future will be heavily focused on AI (as we can see with the influence of ChatGPT), and companies will need to ensure high-quality data to feed these AI systems.\n\nThis trend is already happening, as many companies have hired numerous DS professionals in recent years, only to realize that they don't have good quality data to work with. As a result, they have started to hire more DE experts to bridge that gap. Now, things are improving even further, because despite the results that some DS teams can offer to a company, they recognize the value of having skilled DE professionals on their teams. So, what do you think will happen when companies implement AI, which can provide even greater value compared to some DS teams? It is highly likely that there will be a substantial increase in demand for talented DE professionals.\n\nThese are my thoughts on the matter, although I am not currently working in the field. I have been following some excellent YouTube channels that discuss these topics, and I'm highly interested in pursuing a career in this field.   \nIn fact, this very thought is what is making me lean towards pursuing a career in Data Engineering rather than Data Science. Given the increasing importance of ensuring high-quality data for AI applications, it seems like a wise choice. With that in mind, I would greatly appreciate any advice or insights you might have on this matter.\"\n\nWhat are your thoughts on this?\"", "author_fullname": "t2_b58tz9y4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI will make data engineering very valuable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zsuqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685833303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Hello everyone, I&amp;#39;m considering starting a career in the field of data and I&amp;#39;m trying to choose between Data Science (DS) or Data Engineering (DE). However, I believe that the future will be heavily focused on AI (as we can see with the influence of ChatGPT), and companies will need to ensure high-quality data to feed these AI systems.&lt;/p&gt;\n\n&lt;p&gt;This trend is already happening, as many companies have hired numerous DS professionals in recent years, only to realize that they don&amp;#39;t have good quality data to work with. As a result, they have started to hire more DE experts to bridge that gap. Now, things are improving even further, because despite the results that some DS teams can offer to a company, they recognize the value of having skilled DE professionals on their teams. So, what do you think will happen when companies implement AI, which can provide even greater value compared to some DS teams? It is highly likely that there will be a substantial increase in demand for talented DE professionals.&lt;/p&gt;\n\n&lt;p&gt;These are my thoughts on the matter, although I am not currently working in the field. I have been following some excellent YouTube channels that discuss these topics, and I&amp;#39;m highly interested in pursuing a career in this field.&lt;br/&gt;\nIn fact, this very thought is what is making me lean towards pursuing a career in Data Engineering rather than Data Science. Given the increasing importance of ensuring high-quality data for AI applications, it seems like a wise choice. With that in mind, I would greatly appreciate any advice or insights you might have on this matter.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13zsuqi", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Squash8588", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zsuqi/ai_will_make_data_engineering_very_valuable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zsuqi/ai_will_make_data_engineering_very_valuable/", "subreddit_subscribers": 108867, "created_utc": 1685833303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi a recruiter reached out and asking detailed questions like this\n\n1. how many notebooks have you written that are in production?\n2. how did you source control your development of notebooks?\n3. how did you promote your notebooks to production?\n4. how do you organize your notebooks code?\n5. what is the biggest dataset you have created with data bricks?\n6. what is the longest running notebook you have created?\n7. what is the biggest cluster you have required?\n8. what external libraries have you used?\n9. what is the largest data frame you have broadcast?\n10. what rule of thumb do you have for performance?\n\nwhats the point of asking all these? would you not hire me if I dont use data size &gt; 6gb ;))", "author_fullname": "t2_3bj6xwvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks detailed interrogation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zi2jm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685810182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi a recruiter reached out and asking detailed questions like this&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;how many notebooks have you written that are in production?&lt;/li&gt;\n&lt;li&gt;how did you source control your development of notebooks?&lt;/li&gt;\n&lt;li&gt;how did you promote your notebooks to production?&lt;/li&gt;\n&lt;li&gt;how do you organize your notebooks code?&lt;/li&gt;\n&lt;li&gt;what is the biggest dataset you have created with data bricks?&lt;/li&gt;\n&lt;li&gt;what is the longest running notebook you have created?&lt;/li&gt;\n&lt;li&gt;what is the biggest cluster you have required?&lt;/li&gt;\n&lt;li&gt;what external libraries have you used?&lt;/li&gt;\n&lt;li&gt;what is the largest data frame you have broadcast?&lt;/li&gt;\n&lt;li&gt;what rule of thumb do you have for performance?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;whats the point of asking all these? would you not hire me if I dont use data size &amp;gt; 6gb ;))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13zi2jm", "is_robot_indexable": true, "report_reasons": null, "author": "Abject-Promise-2780", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "subreddit_subscribers": 108867, "created_utc": 1685810182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, looking to start storing event and impression data that my users generate. I'm starting from scratch here - I've got thousands of devices generating data and I'm currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I'm at the scale of 5-10 million events per day.\n\nAt this point, I'm just considering storing the data in Postgres but I'm hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!", "author_fullname": "t2_3sz34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Millions of events per day - one man team, where do I get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zilcx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685811313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, looking to start storing event and impression data that my users generate. I&amp;#39;m starting from scratch here - I&amp;#39;ve got thousands of devices generating data and I&amp;#39;m currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I&amp;#39;m at the scale of 5-10 million events per day.&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;m just considering storing the data in Postgres but I&amp;#39;m hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zilcx", "is_robot_indexable": true, "report_reasons": null, "author": "sicentendu", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "subreddit_subscribers": 108867, "created_utc": 1685811313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you'll learn how to:\n\n\\- Ingest data from a CSV file to a PostgreSQL database\n\n\\- Clean the data and perform sentiment analysis using Python\n\n\\- Connect the sentiment analysis table to a dashboard in PowerBI\n\nIf you're interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: [LINK](https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4)\n\nI hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!", "author_fullname": "t2_dem14ic5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis dashboard data pipeline with Python Postgre SQL and PowerBI project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zjpll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685813678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you&amp;#39;ll learn how to:&lt;/p&gt;\n\n&lt;p&gt;- Ingest data from a CSV file to a PostgreSQL database&lt;/p&gt;\n\n&lt;p&gt;- Clean the data and perform sentiment analysis using Python&lt;/p&gt;\n\n&lt;p&gt;- Connect the sentiment analysis table to a dashboard in PowerBI&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: &lt;a href=\"https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4\"&gt;LINK&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?auto=webp&amp;v=enabled&amp;s=bc9f825cf880b702429b5e90f6fc08be5fc85edc", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc80836ded13aa611d30d52a8d05a41770a07b7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8ed71be54947658b486c71565f59460fe3cf6ef", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d87218c476f379a96d40781e508f3d1116c4dbc", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0653b6f59655caed6dd799986d829bfe09e79c6", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b068302c47f92858a263ee173778e7b2cb04e432", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be4e263e7aea28cec215da06da7950944cf2f2ef", "width": 1080, "height": 720}], "variants": {}, "id": "OHBMApcHRfYRpKSJNJQkbefGPe_H09WVqcQN1zau9bE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zjpll", "is_robot_indexable": true, "report_reasons": null, "author": "DataSynapse82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "subreddit_subscribers": 108867, "created_utc": 1685813678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As stated above: What do you use at work and do you like it or hate it? \n\nI have to use Windows and imho this is not suited for Data Engineering at all. Furthermore, I don\u2019t have admin rights at my laptop. Not a big fan of this setup. \n\nWhat about your experiences?", "author_fullname": "t2_6fdt02qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What OS do you (have to) use at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1402mlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685857269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As stated above: What do you use at work and do you like it or hate it? &lt;/p&gt;\n\n&lt;p&gt;I have to use Windows and imho this is not suited for Data Engineering at all. Furthermore, I don\u2019t have admin rights at my laptop. Not a big fan of this setup. &lt;/p&gt;\n\n&lt;p&gt;What about your experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1402mlk", "is_robot_indexable": true, "report_reasons": null, "author": "Insighteous", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1402mlk/what_os_do_you_have_to_use_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1402mlk/what_os_do_you_have_to_use_at_work/", "subreddit_subscribers": 108867, "created_utc": 1685857269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI lack the technical knowledge to fully understand what happens inside DuckDB and Polars, but I think they are the future of Pandas for data scientist and analysts. \n\nI\u2019m confused over investing my time in one solution or the other. My goal is not really to achieve faster queries, but to learn something that will help me in my future career if I want to access more technically mature roles (ML Engineer, Data Scientist / Data Engineer cross role\u2026) and not be constrained in a \u2018jupyter notebook nothing ever goes into production\u2019 role. \n\nFrom my understanding, DuckDB leverages SQL which is always useful to master, and is much faster than Polars (according to several benchmarks I\u2019ve seen).\n\nWhat do you think?", "author_fullname": "t2_1hn4plaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Scientist: should I learn Polars or DuckDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zrwpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685831227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I lack the technical knowledge to fully understand what happens inside DuckDB and Polars, but I think they are the future of Pandas for data scientist and analysts. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m confused over investing my time in one solution or the other. My goal is not really to achieve faster queries, but to learn something that will help me in my future career if I want to access more technically mature roles (ML Engineer, Data Scientist / Data Engineer cross role\u2026) and not be constrained in a \u2018jupyter notebook nothing ever goes into production\u2019 role. &lt;/p&gt;\n\n&lt;p&gt;From my understanding, DuckDB leverages SQL which is always useful to master, and is much faster than Polars (according to several benchmarks I\u2019ve seen).&lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13zrwpq", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonPilgrim", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zrwpq/beginner_data_scientist_should_i_learn_polars_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zrwpq/beginner_data_scientist_should_i_learn_polars_or/", "subreddit_subscribers": 108867, "created_utc": 1685831227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udceb Building Framework on top of Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_13zis26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/5lDsPrzs2P8jEsxE5FVIvJ91zeE3ls5XqH48rH-pp24.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685811699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "junaideffendi.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?auto=webp&amp;v=enabled&amp;s=0df29b05802d79950de2f1736933010fade72725", "width": 1224, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b3832e6cc67943bd48cf2d8bfeadc91e6903def", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=171fdd33ca5176d87697e5542bd9b28227198fde", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4405df3ce3fb55738b245c2f75b61425a332633", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b7081f69887063c87ddeeda8860246a2008a2d6", "width": 640, "height": 418}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8d84d14c69a84b2bad277cc2700bfa3142bcb21", "width": 960, "height": 627}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b327b775b269db4da0c7c002d6706464dd879f05", "width": 1080, "height": 705}], "variants": {}, "id": "06m3kQO6fQ6ey6Ti2otaAWFW4pO65oO_GVSJJLRM3d4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zis26", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zis26/building_framework_on_top_of_great_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "subreddit_subscribers": 108867, "created_utc": 1685811699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI'm thinking about going for the CDMP (Certified Data Management Professional) certification. My goal is to move up at work (from staff engineer to a higher role like principal or architect) and also to just get better at what I do.\n\nIn my job, we mostly use open-source tools, so AWS, GCP, or Azure certifications don't really help me. But I heard CDMP is vendor agnostic, so it seems like a good fit.\n\nHas anyone here done it? Was it tough? Did it help you in your job?\n\nThanks for any advice!", "author_fullname": "t2_vn837v5m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is CDMP Certification Worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140enbn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685888690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about going for the CDMP (Certified Data Management Professional) certification. My goal is to move up at work (from staff engineer to a higher role like principal or architect) and also to just get better at what I do.&lt;/p&gt;\n\n&lt;p&gt;In my job, we mostly use open-source tools, so AWS, GCP, or Azure certifications don&amp;#39;t really help me. But I heard CDMP is vendor agnostic, so it seems like a good fit.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here done it? Was it tough? Did it help you in your job?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "140enbn", "is_robot_indexable": true, "report_reasons": null, "author": "alexchevsky", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140enbn/is_cdmp_certification_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140enbn/is_cdmp_certification_worth_it/", "subreddit_subscribers": 108867, "created_utc": 1685888690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I may have missed something. Is it possible to perform a merge statement or equivalent using DuckDB and Delta-rs? You can read, and write, but what about creating an SCD2 where a valid_from date needs to be updated on an existing record? I don\u2019t seem to be able to find a way to do this.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta-rs with upserts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zuvv6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685837956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I may have missed something. Is it possible to perform a merge statement or equivalent using DuckDB and Delta-rs? You can read, and write, but what about creating an SCD2 where a valid_from date needs to be updated on an existing record? I don\u2019t seem to be able to find a way to do this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zuvv6", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zuvv6/deltars_with_upserts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zuvv6/deltars_with_upserts/", "subreddit_subscribers": 108867, "created_utc": 1685837956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand what should be the proper flow for payments/recurring payments DB with these entities: order, order\\_item, payment\\_transaction\n\nWhen initial order happens the flow is:\n\n new **order** record created -&gt; **order\\_item** record with specific product and quantity added to order -&gt; **payment\\_transaction** record is being created and added to **order**\n\nShould the same exactly flow be used for recurring payment for initially order product? Or should there be just created only another payment\\_transaction?", "author_fullname": "t2_glxz8l6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should recurring payment create new order every time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zraee", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685829898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand what should be the proper flow for payments/recurring payments DB with these entities: order, order_item, payment_transaction&lt;/p&gt;\n\n&lt;p&gt;When initial order happens the flow is:&lt;/p&gt;\n\n&lt;p&gt;new &lt;strong&gt;order&lt;/strong&gt; record created -&amp;gt; &lt;strong&gt;order_item&lt;/strong&gt; record with specific product and quantity added to order -&amp;gt; &lt;strong&gt;payment_transaction&lt;/strong&gt; record is being created and added to &lt;strong&gt;order&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Should the same exactly flow be used for recurring payment for initially order product? Or should there be just created only another payment_transaction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zraee", "is_robot_indexable": true, "report_reasons": null, "author": "No-Race8789", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zraee/should_recurring_payment_create_new_order_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zraee/should_recurring_payment_create_new_order_every/", "subreddit_subscribers": 108867, "created_utc": 1685829898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? \n\nAsking as a business school student trying to learn.", "author_fullname": "t2_a17g9w41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should data transformation tools be priced?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zoq1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685824598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? &lt;/p&gt;\n\n&lt;p&gt;Asking as a business school student trying to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13zoq1x", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological_Lynx69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "subreddit_subscribers": 108867, "created_utc": 1685824598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So first off, as an apology, there's a lot of Databricks terms that I don't have down solid, so I might be using the wrong words. \n\nI've got a parameterized workflow defined that I can trigger manually (either via the web or CLI) and run once.  Unfortunately I need to run this a couple thousand times with various parameters.   I can't just fire off a bunch of CLI invocations because only one will run at a time, and instead of queueing up everything except the first one gets skipped.  The actual job is just a basic ETL that reads from a couple tables (where the actual queries are from the passed parameters), calls some python code, and writes to another table.  \n\nSurely this has to be a thing that Databricks can do, right? \n\nThen once that work has been completed, I'm going to have a table with a whole ton of rows, and I'll need to do another ETL on that table (for each row call some python code and write to yet another table).  And there's no way that *that's* not something Databricks can't do, right?\n\nFor the first task, I had thought that defining a cluster with autoscaling and max_workers larger than one would have done the trick, but instead all that seemed to happen was an individual job might have run faster.  The only option I can think of that I haven't tried is to modify my code to take a list of parameters, spin up a whole bunch of clusters, and manually partition the parameters over each cluster.  (I expect that if I did this I would get yelled at, and maybe that'd be good because someone could tell me how to do it right).\n\nFor the second task, I have no earthly idea where to begin.\n\nWe're on AWS if it makes a difference.\n\nThanks!", "author_fullname": "t2_pvsrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I do a 'job queue' in Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140bzdl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685882712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So first off, as an apology, there&amp;#39;s a lot of Databricks terms that I don&amp;#39;t have down solid, so I might be using the wrong words. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a parameterized workflow defined that I can trigger manually (either via the web or CLI) and run once.  Unfortunately I need to run this a couple thousand times with various parameters.   I can&amp;#39;t just fire off a bunch of CLI invocations because only one will run at a time, and instead of queueing up everything except the first one gets skipped.  The actual job is just a basic ETL that reads from a couple tables (where the actual queries are from the passed parameters), calls some python code, and writes to another table.  &lt;/p&gt;\n\n&lt;p&gt;Surely this has to be a thing that Databricks can do, right? &lt;/p&gt;\n\n&lt;p&gt;Then once that work has been completed, I&amp;#39;m going to have a table with a whole ton of rows, and I&amp;#39;ll need to do another ETL on that table (for each row call some python code and write to yet another table).  And there&amp;#39;s no way that &lt;em&gt;that&amp;#39;s&lt;/em&gt; not something Databricks can&amp;#39;t do, right?&lt;/p&gt;\n\n&lt;p&gt;For the first task, I had thought that defining a cluster with autoscaling and max_workers larger than one would have done the trick, but instead all that seemed to happen was an individual job might have run faster.  The only option I can think of that I haven&amp;#39;t tried is to modify my code to take a list of parameters, spin up a whole bunch of clusters, and manually partition the parameters over each cluster.  (I expect that if I did this I would get yelled at, and maybe that&amp;#39;d be good because someone could tell me how to do it right).&lt;/p&gt;\n\n&lt;p&gt;For the second task, I have no earthly idea where to begin.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on AWS if it makes a difference.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "140bzdl", "is_robot_indexable": true, "report_reasons": null, "author": "SemaphoreBingo", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140bzdl/how_do_i_do_a_job_queue_in_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140bzdl/how_do_i_do_a_job_queue_in_databricks/", "subreddit_subscribers": 108867, "created_utc": 1685882712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help me out dataengineering. \n\nRecently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It's fast and cheap! So now I'm going down the dataengineering rabbithole trying to do the same thing but \"real time\"ish. \n\nI want to copy data from (slow)apis and incrementally update a \"cache\" for ad hoc reporting(sql).  \n\nThis is for SAAS software, the customer would own their own storage on azure(thousands of customers).\n\nNeed fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.\n\nThis must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  \n\nI am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. \n\nThe end users aren't all that technical so need to be able to automate everything myself. Want to build this into software that's all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.\n\nThe most important things:  \n\nI just want to go fast!\n\nCheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. \n\nI just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. \n\nSo basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for \"medium data\"? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?", "author_fullname": "t2_622qq2ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend me a cheap fast azure storage layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zl932", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685817065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help me out dataengineering. &lt;/p&gt;\n\n&lt;p&gt;Recently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It&amp;#39;s fast and cheap! So now I&amp;#39;m going down the dataengineering rabbithole trying to do the same thing but &amp;quot;real time&amp;quot;ish. &lt;/p&gt;\n\n&lt;p&gt;I want to copy data from (slow)apis and incrementally update a &amp;quot;cache&amp;quot; for ad hoc reporting(sql).  &lt;/p&gt;\n\n&lt;p&gt;This is for SAAS software, the customer would own their own storage on azure(thousands of customers).&lt;/p&gt;\n\n&lt;p&gt;Need fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.&lt;/p&gt;\n\n&lt;p&gt;This must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  &lt;/p&gt;\n\n&lt;p&gt;I am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. &lt;/p&gt;\n\n&lt;p&gt;The end users aren&amp;#39;t all that technical so need to be able to automate everything myself. Want to build this into software that&amp;#39;s all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.&lt;/p&gt;\n\n&lt;p&gt;The most important things:  &lt;/p&gt;\n\n&lt;p&gt;I just want to go fast!&lt;/p&gt;\n\n&lt;p&gt;Cheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. &lt;/p&gt;\n\n&lt;p&gt;I just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. &lt;/p&gt;\n\n&lt;p&gt;So basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for &amp;quot;medium data&amp;quot;? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zl932", "is_robot_indexable": true, "report_reasons": null, "author": "WMMMMMMMMMMMMMMMMMMW", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "subreddit_subscribers": 108867, "created_utc": 1685817065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand what the delineation is between these things. For context, I've seen a lot of job descriptions for non-engineering (i.e. analyst) roles that look for experience with data modeling and pipelines, so I'm trying to understand what counts as each of these things. Some more specific questions:\n\n1. I've seen data models and data pipelines used somewhat interchangeably, but are they the same thing? Or is the data model the data organization/logic/code etc (with something like dbt) and the pipeline is how it gets made via airflow or similar? Something else?\n2. What actually defines if something is a data model vs long SQL code (with multiple CTEs, for example). Like lets say you have a data model/table of users with all of their related data that comes from multiple tables and requires transformations/calculations etc to get to those additional columns. If you have that same logic as a SQL query with multiple CTEs for each of the additional column calculations that you join in at the end, is that SQL code technically in and of itself a data model? Would it only be a model if it were set to refresh as a standalone table? Or does it only become a model if there is a demonstrated lineage diagram from something like dbt? dbt turns SQL into a \"model\" so I think that is what is driving my confusion about what separates complex SQL queries from a data model. I've tried googling about this but I mostly get entity relationship diagrams for what a model is.", "author_fullname": "t2_ymtqxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data model vs pipeline vs long CTE-filled SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_140g5eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685891939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand what the delineation is between these things. For context, I&amp;#39;ve seen a lot of job descriptions for non-engineering (i.e. analyst) roles that look for experience with data modeling and pipelines, so I&amp;#39;m trying to understand what counts as each of these things. Some more specific questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;ve seen data models and data pipelines used somewhat interchangeably, but are they the same thing? Or is the data model the data organization/logic/code etc (with something like dbt) and the pipeline is how it gets made via airflow or similar? Something else?&lt;/li&gt;\n&lt;li&gt;What actually defines if something is a data model vs long SQL code (with multiple CTEs, for example). Like lets say you have a data model/table of users with all of their related data that comes from multiple tables and requires transformations/calculations etc to get to those additional columns. If you have that same logic as a SQL query with multiple CTEs for each of the additional column calculations that you join in at the end, is that SQL code technically in and of itself a data model? Would it only be a model if it were set to refresh as a standalone table? Or does it only become a model if there is a demonstrated lineage diagram from something like dbt? dbt turns SQL into a &amp;quot;model&amp;quot; so I think that is what is driving my confusion about what separates complex SQL queries from a data model. I&amp;#39;ve tried googling about this but I mostly get entity relationship diagrams for what a model is.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "140g5eb", "is_robot_indexable": true, "report_reasons": null, "author": "lifeishard2017", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140g5eb/data_model_vs_pipeline_vs_long_ctefilled_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140g5eb/data_model_vs_pipeline_vs_long_ctefilled_sql/", "subreddit_subscribers": 108867, "created_utc": 1685891939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI currently work as a data analyst at a great SaaS company and am looking for opportunities to grow further. Recently, I've been offered a data engineer position at a large tech company that is publicly traded on the NYSE. On the other hand, I've also been proposed a role change within my current company, from data analyst to junior data scientist.\n\nAs a data scientist, I would be working with ML and AI to improve our product, conducting research, and more.\n\nThe pay is similar for both options, so my first question is whether it's better to move to a bigger and more famous company. Secondly, I'm wondering whether it's better to stick with data engineering or dive deeper into data science. I have experience in both fields.\n\nI know that it is almost impossible to answer, but maybe someone went through similar decions process. \n\nHave a nice day", "author_fullname": "t2_108fg37v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE in big tech or DS in a startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_140f4uh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685889764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I currently work as a data analyst at a great SaaS company and am looking for opportunities to grow further. Recently, I&amp;#39;ve been offered a data engineer position at a large tech company that is publicly traded on the NYSE. On the other hand, I&amp;#39;ve also been proposed a role change within my current company, from data analyst to junior data scientist.&lt;/p&gt;\n\n&lt;p&gt;As a data scientist, I would be working with ML and AI to improve our product, conducting research, and more.&lt;/p&gt;\n\n&lt;p&gt;The pay is similar for both options, so my first question is whether it&amp;#39;s better to move to a bigger and more famous company. Secondly, I&amp;#39;m wondering whether it&amp;#39;s better to stick with data engineering or dive deeper into data science. I have experience in both fields.&lt;/p&gt;\n\n&lt;p&gt;I know that it is almost impossible to answer, but maybe someone went through similar decions process. &lt;/p&gt;\n\n&lt;p&gt;Have a nice day&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "140f4uh", "is_robot_indexable": true, "report_reasons": null, "author": "kvapta", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140f4uh/de_in_big_tech_or_ds_in_a_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140f4uh/de_in_big_tech_or_ds_in_a_startup/", "subreddit_subscribers": 108867, "created_utc": 1685889764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm 37 and I'm about to go back to school. I think I'll be aiming for Data Scientist/Data Engineering. WGU offers a BS in Data Management and Analytics but I see most people talk about the computer science degree so does it matter? Please help this noob", "author_fullname": "t2_lnp1fxce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the degree matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140dxh9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685887164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 37 and I&amp;#39;m about to go back to school. I think I&amp;#39;ll be aiming for Data Scientist/Data Engineering. WGU offers a BS in Data Management and Analytics but I see most people talk about the computer science degree so does it matter? Please help this noob&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "140dxh9", "is_robot_indexable": true, "report_reasons": null, "author": "Fungipops", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140dxh9/does_the_degree_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140dxh9/does_the_degree_matter/", "subreddit_subscribers": 108867, "created_utc": 1685887164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIs there a any published info on how much companies spend on data (compute+storage+network) and related tools/SaaS?\n\nThank you :)", "author_fullname": "t2_7b8t7ihk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Usage Reports and Trends", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140ddpp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685885950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Is there a any published info on how much companies spend on data (compute+storage+network) and related tools/SaaS?&lt;/p&gt;\n\n&lt;p&gt;Thank you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "140ddpp", "is_robot_indexable": true, "report_reasons": null, "author": "satantine", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140ddpp/data_usage_reports_and_trends/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140ddpp/data_usage_reports_and_trends/", "subreddit_subscribers": 108867, "created_utc": 1685885950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to get the data of the songs playing at the moment through the lastfm API, send it to a pubsub topic and send the data from this topic to the big query.\n\nI'm having trouble feeding the topic with API data. Initially I thought of requests every x seconds, but if I was playing a song I would have duplicate data, so I needed to think of ways to deduplicate this data after it was in the pubsub topic or before it entered the pubsub topic.\n\nConsidering that the lastfm API \"does not notify\" when it has new data, what alternatives do you suggest to not make requests to the API every x seconds? If this way is the most viable, what deduplication strategies do you suggest?", "author_fullname": "t2_ou16vi7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "real time streaming lastfm, pubsub and bigquery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zsphy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685832986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to get the data of the songs playing at the moment through the lastfm API, send it to a pubsub topic and send the data from this topic to the big query.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having trouble feeding the topic with API data. Initially I thought of requests every x seconds, but if I was playing a song I would have duplicate data, so I needed to think of ways to deduplicate this data after it was in the pubsub topic or before it entered the pubsub topic.&lt;/p&gt;\n\n&lt;p&gt;Considering that the lastfm API &amp;quot;does not notify&amp;quot; when it has new data, what alternatives do you suggest to not make requests to the API every x seconds? If this way is the most viable, what deduplication strategies do you suggest?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zsphy", "is_robot_indexable": true, "report_reasons": null, "author": "saruvulcano", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zsphy/real_time_streaming_lastfm_pubsub_and_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zsphy/real_time_streaming_lastfm_pubsub_and_bigquery/", "subreddit_subscribers": 108867, "created_utc": 1685832986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thanks in advance. The long and short of it is that I have book after book of journals going back probably 15+ years and I want to take the length, date, time, and some other metrics and make a graph of some kind. I\u2019m an artist and this is really for self enlightenment. I\u2019m not trying to spend a bundle on software so something free or inexpensive is preferred. Thanks again and I really hope the answer isn\u2019t excel because then I will feel like a fool", "author_fullname": "t2_9hdb1ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumb question, maybe, but what\u2019s the best program to enter a bunch of collected data and generate images (graphs and charts etc) for an artist project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zqu43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685828949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks in advance. The long and short of it is that I have book after book of journals going back probably 15+ years and I want to take the length, date, time, and some other metrics and make a graph of some kind. I\u2019m an artist and this is really for self enlightenment. I\u2019m not trying to spend a bundle on software so something free or inexpensive is preferred. Thanks again and I really hope the answer isn\u2019t excel because then I will feel like a fool&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zqu43", "is_robot_indexable": true, "report_reasons": null, "author": "lunchmeat42", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zqu43/dumb_question_maybe_but_whats_the_best_program_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zqu43/dumb_question_maybe_but_whats_the_best_program_to/", "subreddit_subscribers": 108867, "created_utc": 1685828949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zk4rc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685814615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zk4rc", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zk4rc/design_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zk4rc/design_question/", "subreddit_subscribers": 108867, "created_utc": 1685814615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, \n\nI am thinking about moving back to London where I studied and apply from some DE job. \n\nCurrently, I have 8 years of DE experience for multiple European institutions and central banks but getting skilled worker visa in UK seem to be a difficult task.\n\nWhere should I look for a job that offer visa sponsorship? I tried linkedin but didn't get any replies.\n\nMany thanks!", "author_fullname": "t2_46l1zqd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard it is to find DE job in London with visa sposorship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_140dte4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685886914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I am thinking about moving back to London where I studied and apply from some DE job. &lt;/p&gt;\n\n&lt;p&gt;Currently, I have 8 years of DE experience for multiple European institutions and central banks but getting skilled worker visa in UK seem to be a difficult task.&lt;/p&gt;\n\n&lt;p&gt;Where should I look for a job that offer visa sponsorship? I tried linkedin but didn&amp;#39;t get any replies.&lt;/p&gt;\n\n&lt;p&gt;Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "140dte4", "is_robot_indexable": true, "report_reasons": null, "author": "pyzo_ryzo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/140dte4/how_hard_it_is_to_find_de_job_in_london_with_visa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/140dte4/how_hard_it_is_to_find_de_job_in_london_with_visa/", "subreddit_subscribers": 108867, "created_utc": 1685886914.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}