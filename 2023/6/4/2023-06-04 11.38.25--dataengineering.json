{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.\n\nI'm looking for a source around questions like:\n\n\\- Given a source data (JSON, CSV), derive insights to answer questions\n\n\\- Clean up a given dataset to answer questions etc.\n\n\\- Python dictionary / Json API response manipulation.\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the Leetcode equivalent for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13znm1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685822212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a source around questions like:&lt;/p&gt;\n\n&lt;p&gt;- Given a source data (JSON, CSV), derive insights to answer questions&lt;/p&gt;\n\n&lt;p&gt;- Clean up a given dataset to answer questions etc.&lt;/p&gt;\n\n&lt;p&gt;- Python dictionary / Json API response manipulation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13znm1j", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "subreddit_subscribers": 108826, "created_utc": 1685822212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v3vfbwzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The growing pains of database architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_13zedmr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XcSAEUlxVUY6I1TTbJ_4ntHlBUvCUCvL3vVJIYu9HUU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685802138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "figma.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?auto=webp&amp;v=enabled&amp;s=b5867ede39eeffae9d13f32e5d9b30e71b339385", "width": 1200, "height": 566}, "resolutions": [{"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10bcc126368cb1da8fbdd64265db8eb18cf03d3f", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f6fc670efbd4ee95002eb7f8808edfbc6d1062", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d64a54c5c6a5a5d66c764358a0b4d486ee9ba00", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93014cbd1a923d348a4887ff8c03ae75e03977a5", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfd7182f905c820ea77288801824630ec4bc932b", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c6e864c52a3c9163365fc761d6fad048e7a918", "width": 1080, "height": 509}], "variants": {}, "id": "f4GO-Re6FLXwf8hsiG60ZlCbPm1yXOfOgWLuB_O23IE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zedmr", "is_robot_indexable": true, "report_reasons": null, "author": "ThePullOutCouches", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zedmr/the_growing_pains_of_database_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/", "subreddit_subscribers": 108826, "created_utc": 1685802138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is data modelling solved in medallion/lakehouse data architecture? Bronze + silver layers are just plain tables, no relationships and gold is \u201cdata mart-ish\u201d with all the relationships? How about the normalization? Bronze + silver denormalized and gold normalized? Or? \n\nAlso, how do you actually make a normalization considering you are working with e.g. parquet files? In the database it is simple but with files?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medallion/lakehouse architecture data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z9byl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685790484.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685790124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is data modelling solved in medallion/lakehouse data architecture? Bronze + silver layers are just plain tables, no relationships and gold is \u201cdata mart-ish\u201d with all the relationships? How about the normalization? Bronze + silver denormalized and gold normalized? Or? &lt;/p&gt;\n\n&lt;p&gt;Also, how do you actually make a normalization considering you are working with e.g. parquet files? In the database it is simple but with files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13z9byl", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z9byl/medallionlakehouse_architecture_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z9byl/medallionlakehouse_architecture_data_modelling/", "subreddit_subscribers": 108826, "created_utc": 1685790124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\n# How to integrate data quality test in Python ETL pipeline | Test Data Pipelines | Data Quality\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\n**Integrate test cases in ETL pipelines**\n\n[**https://www.youtube.com/watch?v=7FPksG-LYOA&amp;t**](https://www.youtube.com/watch?v=7FPksG-LYOA&amp;t=2s)\n\nTopics covered:\n\n* Data Pipeline\n* Data Quality Tests\n* ETL\n\nTech Stack: **Python, PyTest, Postgres, SQL Server**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate data quality test in ETL pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zuhvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685837047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;How to integrate data quality test in Python ETL pipeline | Test Data Pipelines | Data Quality&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Integrate test cases in ETL pipelines&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=7FPksG-LYOA&amp;amp;t=2s\"&gt;&lt;strong&gt;https://www.youtube.com/watch?v=7FPksG-LYOA&amp;amp;t&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Pipeline&lt;/li&gt;\n&lt;li&gt;Data Quality Tests&lt;/li&gt;\n&lt;li&gt;ETL&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Python, PyTest, Postgres, SQL Server&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?auto=webp&amp;v=enabled&amp;s=cc00a333a7b06b373828f090e8368795bb2f12fb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8d6ed9317e1c112f7c716c3b0bf6d59af4772d3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a83d67bf2da459bca296526def8419e6e62420d1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/JcEnzS15Jj6KU3KOL72cY98tMp2A7fdKlfLCpvMK0Lo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e75c70ce661878447e5dea257f1bce63ade2952f", "width": 320, "height": 240}], "variants": {}, "id": "ZLDBG7h3Vxm0DQa9d03I9XYvP7WTijx5CREbZX5zQIY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zuhvl", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zuhvl/how_to_integrate_data_quality_test_in_etl_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zuhvl/how_to_integrate_data_quality_test_in_etl_pipeline/", "subreddit_subscribers": 108826, "created_utc": 1685837047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi a recruiter reached out and asking detailed questions like this\n\n1. how many notebooks have you written that are in production?\n2. how did you source control your development of notebooks?\n3. how did you promote your notebooks to production?\n4. how do you organize your notebooks code?\n5. what is the biggest dataset you have created with data bricks?\n6. what is the longest running notebook you have created?\n7. what is the biggest cluster you have required?\n8. what external libraries have you used?\n9. what is the largest data frame you have broadcast?\n10. what rule of thumb do you have for performance?\n\nwhats the point of asking all these? would you not hire me if I dont use data size &gt; 6gb ;))", "author_fullname": "t2_3bj6xwvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks detailed interrogation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zi2jm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685810182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi a recruiter reached out and asking detailed questions like this&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;how many notebooks have you written that are in production?&lt;/li&gt;\n&lt;li&gt;how did you source control your development of notebooks?&lt;/li&gt;\n&lt;li&gt;how did you promote your notebooks to production?&lt;/li&gt;\n&lt;li&gt;how do you organize your notebooks code?&lt;/li&gt;\n&lt;li&gt;what is the biggest dataset you have created with data bricks?&lt;/li&gt;\n&lt;li&gt;what is the longest running notebook you have created?&lt;/li&gt;\n&lt;li&gt;what is the biggest cluster you have required?&lt;/li&gt;\n&lt;li&gt;what external libraries have you used?&lt;/li&gt;\n&lt;li&gt;what is the largest data frame you have broadcast?&lt;/li&gt;\n&lt;li&gt;what rule of thumb do you have for performance?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;whats the point of asking all these? would you not hire me if I dont use data size &amp;gt; 6gb ;))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13zi2jm", "is_robot_indexable": true, "report_reasons": null, "author": "Abject-Promise-2780", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "subreddit_subscribers": 108826, "created_utc": 1685810182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, looking to start storing event and impression data that my users generate. I'm starting from scratch here - I've got thousands of devices generating data and I'm currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I'm at the scale of 5-10 million events per day.\n\nAt this point, I'm just considering storing the data in Postgres but I'm hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!", "author_fullname": "t2_3sz34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Millions of events per day - one man team, where do I get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zilcx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685811313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, looking to start storing event and impression data that my users generate. I&amp;#39;m starting from scratch here - I&amp;#39;ve got thousands of devices generating data and I&amp;#39;m currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I&amp;#39;m at the scale of 5-10 million events per day.&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;m just considering storing the data in Postgres but I&amp;#39;m hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zilcx", "is_robot_indexable": true, "report_reasons": null, "author": "sicentendu", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "subreddit_subscribers": 108826, "created_utc": 1685811313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \"Hello everyone, I'm considering starting a career in the field of data and I'm trying to choose between Data Science (DS) or Data Engineering (DE). However, I believe that the future will be heavily focused on AI (as we can see with the influence of ChatGPT), and companies will need to ensure high-quality data to feed these AI systems.\n\nThis trend is already happening, as many companies have hired numerous DS professionals in recent years, only to realize that they don't have good quality data to work with. As a result, they have started to hire more DE experts to bridge that gap. Now, things are improving even further, because despite the results that some DS teams can offer to a company, they recognize the value of having skilled DE professionals on their teams. So, what do you think will happen when companies implement AI, which can provide even greater value compared to some DS teams? It is highly likely that there will be a substantial increase in demand for talented DE professionals.\n\nThese are my thoughts on the matter, although I am not currently working in the field. I have been following some excellent YouTube channels that discuss these topics, and I'm highly interested in pursuing a career in this field.   \nIn fact, this very thought is what is making me lean towards pursuing a career in Data Engineering rather than Data Science. Given the increasing importance of ensuring high-quality data for AI applications, it seems like a wise choice. With that in mind, I would greatly appreciate any advice or insights you might have on this matter.\"\n\nWhat are your thoughts on this?\"", "author_fullname": "t2_b58tz9y4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI will make data engineering very valuable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zsuqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685833303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Hello everyone, I&amp;#39;m considering starting a career in the field of data and I&amp;#39;m trying to choose between Data Science (DS) or Data Engineering (DE). However, I believe that the future will be heavily focused on AI (as we can see with the influence of ChatGPT), and companies will need to ensure high-quality data to feed these AI systems.&lt;/p&gt;\n\n&lt;p&gt;This trend is already happening, as many companies have hired numerous DS professionals in recent years, only to realize that they don&amp;#39;t have good quality data to work with. As a result, they have started to hire more DE experts to bridge that gap. Now, things are improving even further, because despite the results that some DS teams can offer to a company, they recognize the value of having skilled DE professionals on their teams. So, what do you think will happen when companies implement AI, which can provide even greater value compared to some DS teams? It is highly likely that there will be a substantial increase in demand for talented DE professionals.&lt;/p&gt;\n\n&lt;p&gt;These are my thoughts on the matter, although I am not currently working in the field. I have been following some excellent YouTube channels that discuss these topics, and I&amp;#39;m highly interested in pursuing a career in this field.&lt;br/&gt;\nIn fact, this very thought is what is making me lean towards pursuing a career in Data Engineering rather than Data Science. Given the increasing importance of ensuring high-quality data for AI applications, it seems like a wise choice. With that in mind, I would greatly appreciate any advice or insights you might have on this matter.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13zsuqi", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Squash8588", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zsuqi/ai_will_make_data_engineering_very_valuable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zsuqi/ai_will_make_data_engineering_very_valuable/", "subreddit_subscribers": 108826, "created_utc": 1685833303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you'll learn how to:\n\n\\- Ingest data from a CSV file to a PostgreSQL database\n\n\\- Clean the data and perform sentiment analysis using Python\n\n\\- Connect the sentiment analysis table to a dashboard in PowerBI\n\nIf you're interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: [LINK](https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4)\n\nI hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!", "author_fullname": "t2_dem14ic5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis dashboard data pipeline with Python Postgre SQL and PowerBI project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zjpll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685813678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you&amp;#39;ll learn how to:&lt;/p&gt;\n\n&lt;p&gt;- Ingest data from a CSV file to a PostgreSQL database&lt;/p&gt;\n\n&lt;p&gt;- Clean the data and perform sentiment analysis using Python&lt;/p&gt;\n\n&lt;p&gt;- Connect the sentiment analysis table to a dashboard in PowerBI&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: &lt;a href=\"https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4\"&gt;LINK&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?auto=webp&amp;v=enabled&amp;s=bc9f825cf880b702429b5e90f6fc08be5fc85edc", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc80836ded13aa611d30d52a8d05a41770a07b7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8ed71be54947658b486c71565f59460fe3cf6ef", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d87218c476f379a96d40781e508f3d1116c4dbc", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0653b6f59655caed6dd799986d829bfe09e79c6", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b068302c47f92858a263ee173778e7b2cb04e432", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be4e263e7aea28cec215da06da7950944cf2f2ef", "width": 1080, "height": 720}], "variants": {}, "id": "OHBMApcHRfYRpKSJNJQkbefGPe_H09WVqcQN1zau9bE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zjpll", "is_robot_indexable": true, "report_reasons": null, "author": "DataSynapse82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "subreddit_subscribers": 108826, "created_utc": 1685813678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udceb Building Framework on top of Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_13zis26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/5lDsPrzs2P8jEsxE5FVIvJ91zeE3ls5XqH48rH-pp24.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685811699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "junaideffendi.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?auto=webp&amp;v=enabled&amp;s=0df29b05802d79950de2f1736933010fade72725", "width": 1224, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b3832e6cc67943bd48cf2d8bfeadc91e6903def", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=171fdd33ca5176d87697e5542bd9b28227198fde", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4405df3ce3fb55738b245c2f75b61425a332633", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b7081f69887063c87ddeeda8860246a2008a2d6", "width": 640, "height": 418}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8d84d14c69a84b2bad277cc2700bfa3142bcb21", "width": 960, "height": 627}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b327b775b269db4da0c7c002d6706464dd879f05", "width": 1080, "height": 705}], "variants": {}, "id": "06m3kQO6fQ6ey6Ti2otaAWFW4pO65oO_GVSJJLRM3d4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zis26", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zis26/building_framework_on_top_of_great_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "subreddit_subscribers": 108826, "created_utc": 1685811699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As stated above: What do you use at work and do you like it or hate it? \n\nI have to use Windows and imho this is not suited for Data Engineering at all. Furthermore, I don\u2019t have admin rights at my laptop. Not a big fan of this setup. \n\nWhat about your experiences?", "author_fullname": "t2_6fdt02qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What OS do you (have to) use at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1402mlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685857269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As stated above: What do you use at work and do you like it or hate it? &lt;/p&gt;\n\n&lt;p&gt;I have to use Windows and imho this is not suited for Data Engineering at all. Furthermore, I don\u2019t have admin rights at my laptop. Not a big fan of this setup. &lt;/p&gt;\n\n&lt;p&gt;What about your experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1402mlk", "is_robot_indexable": true, "report_reasons": null, "author": "Insighteous", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1402mlk/what_os_do_you_have_to_use_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1402mlk/what_os_do_you_have_to_use_at_work/", "subreddit_subscribers": 108826, "created_utc": 1685857269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I may have missed something. Is it possible to perform a merge statement or equivalent using DuckDB and Delta-rs? You can read, and write, but what about creating an SCD2 where a valid_from date needs to be updated on an existing record? I don\u2019t seem to be able to find a way to do this.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta-rs with upserts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zuvv6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685837956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I may have missed something. Is it possible to perform a merge statement or equivalent using DuckDB and Delta-rs? You can read, and write, but what about creating an SCD2 where a valid_from date needs to be updated on an existing record? I don\u2019t seem to be able to find a way to do this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zuvv6", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zuvv6/deltars_with_upserts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zuvv6/deltars_with_upserts/", "subreddit_subscribers": 108826, "created_utc": 1685837956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to understand what should be the proper flow for payments/recurring payments DB with these entities: order, order\\_item, payment\\_transaction\n\nWhen initial order happens the flow is:\n\n new **order** record created -&gt; **order\\_item** record with specific product and quantity added to order -&gt; **payment\\_transaction** record is being created and added to **order**\n\nShould the same exactly flow be used for recurring payment for initially order product? Or should there be just created only another payment\\_transaction?", "author_fullname": "t2_glxz8l6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should recurring payment create new order every time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zraee", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685829898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to understand what should be the proper flow for payments/recurring payments DB with these entities: order, order_item, payment_transaction&lt;/p&gt;\n\n&lt;p&gt;When initial order happens the flow is:&lt;/p&gt;\n\n&lt;p&gt;new &lt;strong&gt;order&lt;/strong&gt; record created -&amp;gt; &lt;strong&gt;order_item&lt;/strong&gt; record with specific product and quantity added to order -&amp;gt; &lt;strong&gt;payment_transaction&lt;/strong&gt; record is being created and added to &lt;strong&gt;order&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Should the same exactly flow be used for recurring payment for initially order product? Or should there be just created only another payment_transaction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zraee", "is_robot_indexable": true, "report_reasons": null, "author": "No-Race8789", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zraee/should_recurring_payment_create_new_order_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zraee/should_recurring_payment_create_new_order_every/", "subreddit_subscribers": 108826, "created_utc": 1685829898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI lack the technical knowledge to fully understand what happens inside DuckDB and Polars, but I think they are the future of Pandas for data scientist and analysts. \n\nI\u2019m confused over investing my time in one solution or the other. My goal is not really to achieve faster queries, but to learn something that will help me in my future career if I want to access more technically mature roles (ML Engineer, Data Scientist / Data Engineer cross role\u2026) and not be constrained in a \u2018jupyter notebook nothing ever goes into production\u2019 role. \n\nFrom my understanding, DuckDB leverages SQL which is always useful to master, and is much faster than Polars (according to several benchmarks I\u2019ve seen).\n\nWhat do you think?", "author_fullname": "t2_1hn4plaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Data Scientist: should I learn Polars or DuckDB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zrwpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685831227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I lack the technical knowledge to fully understand what happens inside DuckDB and Polars, but I think they are the future of Pandas for data scientist and analysts. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m confused over investing my time in one solution or the other. My goal is not really to achieve faster queries, but to learn something that will help me in my future career if I want to access more technically mature roles (ML Engineer, Data Scientist / Data Engineer cross role\u2026) and not be constrained in a \u2018jupyter notebook nothing ever goes into production\u2019 role. &lt;/p&gt;\n\n&lt;p&gt;From my understanding, DuckDB leverages SQL which is always useful to master, and is much faster than Polars (according to several benchmarks I\u2019ve seen).&lt;/p&gt;\n\n&lt;p&gt;What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13zrwpq", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonPilgrim", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zrwpq/beginner_data_scientist_should_i_learn_polars_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zrwpq/beginner_data_scientist_should_i_learn_polars_or/", "subreddit_subscribers": 108826, "created_utc": 1685831227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? \n\nAsking as a business school student trying to learn.", "author_fullname": "t2_a17g9w41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should data transformation tools be priced?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zoq1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685824598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? &lt;/p&gt;\n\n&lt;p&gt;Asking as a business school student trying to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13zoq1x", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological_Lynx69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "subreddit_subscribers": 108826, "created_utc": 1685824598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help me out dataengineering. \n\nRecently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It's fast and cheap! So now I'm going down the dataengineering rabbithole trying to do the same thing but \"real time\"ish. \n\nI want to copy data from (slow)apis and incrementally update a \"cache\" for ad hoc reporting(sql).  \n\nThis is for SAAS software, the customer would own their own storage on azure(thousands of customers).\n\nNeed fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.\n\nThis must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  \n\nI am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. \n\nThe end users aren't all that technical so need to be able to automate everything myself. Want to build this into software that's all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.\n\nThe most important things:  \n\nI just want to go fast!\n\nCheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. \n\nI just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. \n\nSo basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for \"medium data\"? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?", "author_fullname": "t2_622qq2ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend me a cheap fast azure storage layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zl932", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685817065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help me out dataengineering. &lt;/p&gt;\n\n&lt;p&gt;Recently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It&amp;#39;s fast and cheap! So now I&amp;#39;m going down the dataengineering rabbithole trying to do the same thing but &amp;quot;real time&amp;quot;ish. &lt;/p&gt;\n\n&lt;p&gt;I want to copy data from (slow)apis and incrementally update a &amp;quot;cache&amp;quot; for ad hoc reporting(sql).  &lt;/p&gt;\n\n&lt;p&gt;This is for SAAS software, the customer would own their own storage on azure(thousands of customers).&lt;/p&gt;\n\n&lt;p&gt;Need fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.&lt;/p&gt;\n\n&lt;p&gt;This must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  &lt;/p&gt;\n\n&lt;p&gt;I am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. &lt;/p&gt;\n\n&lt;p&gt;The end users aren&amp;#39;t all that technical so need to be able to automate everything myself. Want to build this into software that&amp;#39;s all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.&lt;/p&gt;\n\n&lt;p&gt;The most important things:  &lt;/p&gt;\n\n&lt;p&gt;I just want to go fast!&lt;/p&gt;\n\n&lt;p&gt;Cheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. &lt;/p&gt;\n\n&lt;p&gt;I just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. &lt;/p&gt;\n\n&lt;p&gt;So basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for &amp;quot;medium data&amp;quot;? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zl932", "is_robot_indexable": true, "report_reasons": null, "author": "WMMMMMMMMMMMMMMMMMMW", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "subreddit_subscribers": 108826, "created_utc": 1685817065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey everyone!\n\nWe are a group of design students currently conducting academic research on an intriguing topic: the democratization of data and its potential of data to benefits the public. We believe that data can play a vital role in improving people's lives outside the realm of business, and we would love to hear your thoughts and experiences on this subject.\n\nIf you have a moment, we kindly invite you to answer one or more of the following questions either privately or as a comment:\n\n**- Please share your most recent experience using datasets for self-- worth or public value (non-business purposes). For example, a project that makes data accessible or extracts insights that can help the general public?**\n\n**- Working on the project, what worked and what didn't work? Were there barriers and challenges that you can share?**\n\n**- Are there any insights or tips you would like to share following the project?**\n\n**- Do you have any insights or thoughts regarding the use or accessibility of data for the public good?**\n\nYour contribution can be as brief or as detailed as you like. We greatly appreciate any answers, thoughts, or perspectives you are willing to share.\n\nThank you all!", "author_fullname": "t2_ummt1ubq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Academic research: data for the public good", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zbgkq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685795509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;We are a group of design students currently conducting academic research on an intriguing topic: the democratization of data and its potential of data to benefits the public. We believe that data can play a vital role in improving people&amp;#39;s lives outside the realm of business, and we would love to hear your thoughts and experiences on this subject.&lt;/p&gt;\n\n&lt;p&gt;If you have a moment, we kindly invite you to answer one or more of the following questions either privately or as a comment:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Please share your most recent experience using datasets for self-- worth or public value (non-business purposes). For example, a project that makes data accessible or extracts insights that can help the general public?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Working on the project, what worked and what didn&amp;#39;t work? Were there barriers and challenges that you can share?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Are there any insights or tips you would like to share following the project?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Do you have any insights or thoughts regarding the use or accessibility of data for the public good?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Your contribution can be as brief or as detailed as you like. We greatly appreciate any answers, thoughts, or perspectives you are willing to share.&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13zbgkq", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Goat-2072", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zbgkq/academic_research_data_for_the_public_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zbgkq/academic_research_data_for_the_public_good/", "subreddit_subscribers": 108826, "created_utc": 1685795509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to get the data of the songs playing at the moment through the lastfm API, send it to a pubsub topic and send the data from this topic to the big query.\n\nI'm having trouble feeding the topic with API data. Initially I thought of requests every x seconds, but if I was playing a song I would have duplicate data, so I needed to think of ways to deduplicate this data after it was in the pubsub topic or before it entered the pubsub topic.\n\nConsidering that the lastfm API \"does not notify\" when it has new data, what alternatives do you suggest to not make requests to the API every x seconds? If this way is the most viable, what deduplication strategies do you suggest?", "author_fullname": "t2_ou16vi7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "real time streaming lastfm, pubsub and bigquery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zsphy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685832986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to get the data of the songs playing at the moment through the lastfm API, send it to a pubsub topic and send the data from this topic to the big query.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having trouble feeding the topic with API data. Initially I thought of requests every x seconds, but if I was playing a song I would have duplicate data, so I needed to think of ways to deduplicate this data after it was in the pubsub topic or before it entered the pubsub topic.&lt;/p&gt;\n\n&lt;p&gt;Considering that the lastfm API &amp;quot;does not notify&amp;quot; when it has new data, what alternatives do you suggest to not make requests to the API every x seconds? If this way is the most viable, what deduplication strategies do you suggest?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zsphy", "is_robot_indexable": true, "report_reasons": null, "author": "saruvulcano", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zsphy/real_time_streaming_lastfm_pubsub_and_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zsphy/real_time_streaming_lastfm_pubsub_and_bigquery/", "subreddit_subscribers": 108826, "created_utc": 1685832986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thanks in advance. The long and short of it is that I have book after book of journals going back probably 15+ years and I want to take the length, date, time, and some other metrics and make a graph of some kind. I\u2019m an artist and this is really for self enlightenment. I\u2019m not trying to spend a bundle on software so something free or inexpensive is preferred. Thanks again and I really hope the answer isn\u2019t excel because then I will feel like a fool", "author_fullname": "t2_9hdb1ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dumb question, maybe, but what\u2019s the best program to enter a bunch of collected data and generate images (graphs and charts etc) for an artist project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zqu43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685828949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks in advance. The long and short of it is that I have book after book of journals going back probably 15+ years and I want to take the length, date, time, and some other metrics and make a graph of some kind. I\u2019m an artist and this is really for self enlightenment. I\u2019m not trying to spend a bundle on software so something free or inexpensive is preferred. Thanks again and I really hope the answer isn\u2019t excel because then I will feel like a fool&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zqu43", "is_robot_indexable": true, "report_reasons": null, "author": "lunchmeat42", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zqu43/dumb_question_maybe_but_whats_the_best_program_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zqu43/dumb_question_maybe_but_whats_the_best_program_to/", "subreddit_subscribers": 108826, "created_utc": 1685828949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zk4rc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685814615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zk4rc", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zk4rc/design_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zk4rc/design_question/", "subreddit_subscribers": 108826, "created_utc": 1685814615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a one year experienced engineer ( I can't say that I am truly a data engineer though my profile is). I have worked on two major projects.\n1. Automated time series forecasting tool.\n -  Where I worked on creating orchestrated jobs on databricks , ci cd setup on azure pipelines. I wrote python scripts for data health check, time series scenario simulator, automating environment setup of databricks through py scripts,etc [technology: mostly python , databricks, postgres, azure devops]\n\n2. LLM serving framework.\n - I have worked on serving open source LLMs through fastapi and host them on azure kubernetes service, setting up training environment to train LLMs, create openai type package to use the api service [ technology: kubernetes, docker, fastapi]\n\nI want to make a switch as my work environment is extremely toxic, but I am not sure about what my  work profile should be. Should I try to learn more core data emginner skills( like spark etc) or just try to move towards devops.\n\nSeeking guidance on what skills shall I work on and what should my intended work profile be.", "author_fullname": "t2_7oz5gwm6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ze6ck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685801694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a one year experienced engineer ( I can&amp;#39;t say that I am truly a data engineer though my profile is). I have worked on two major projects.\n1. Automated time series forecasting tool.\n -  Where I worked on creating orchestrated jobs on databricks , ci cd setup on azure pipelines. I wrote python scripts for data health check, time series scenario simulator, automating environment setup of databricks through py scripts,etc [technology: mostly python , databricks, postgres, azure devops]&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;LLM serving framework.\n\n&lt;ul&gt;\n&lt;li&gt;I have worked on serving open source LLMs through fastapi and host them on azure kubernetes service, setting up training environment to train LLMs, create openai type package to use the api service [ technology: kubernetes, docker, fastapi]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I want to make a switch as my work environment is extremely toxic, but I am not sure about what my  work profile should be. Should I try to learn more core data emginner skills( like spark etc) or just try to move towards devops.&lt;/p&gt;\n\n&lt;p&gt;Seeking guidance on what skills shall I work on and what should my intended work profile be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13ze6ck", "is_robot_indexable": true, "report_reasons": null, "author": "saurabhgsingh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ze6ck/career_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ze6ck/career_guidance/", "subreddit_subscribers": 108826, "created_utc": 1685801694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnp5113q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What you need to know about media queries and responsive design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_1405mo3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AWkAE7q_dPtezBgzTYs43W2L6BPuG9J6An0RjivwQvo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685865606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "engineering.kablamo.com.au", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://engineering.kablamo.com.au/posts/2023/media-queries-and-responsive-design/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x-0mk9BC6gydKTNN2Ifh3C_uRa4UW1n94om_5AeQw6g.jpg?auto=webp&amp;v=enabled&amp;s=a8d53f6ee8f370f2445542d5e89122823f215e22", "width": 720, "height": 330}, "resolutions": [{"url": "https://external-preview.redd.it/x-0mk9BC6gydKTNN2Ifh3C_uRa4UW1n94om_5AeQw6g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04ee5fcee4fda52376d82ec661a73a07ce34db24", "width": 108, "height": 49}, {"url": "https://external-preview.redd.it/x-0mk9BC6gydKTNN2Ifh3C_uRa4UW1n94om_5AeQw6g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90f81be3d179678c16d2f7526a397bcc726ad072", "width": 216, "height": 99}, {"url": "https://external-preview.redd.it/x-0mk9BC6gydKTNN2Ifh3C_uRa4UW1n94om_5AeQw6g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d9ee11c41efc8b521a0eb6a4782fff3a8b23011", "width": 320, "height": 146}, {"url": "https://external-preview.redd.it/x-0mk9BC6gydKTNN2Ifh3C_uRa4UW1n94om_5AeQw6g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ac6164b981469283d4b6068498e919a14605ddd", "width": 640, "height": 293}], "variants": {}, "id": "6lU2u9eIM0dfATUG_Yw8H3noibgJrSzZnffy2ABdQnw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1405mo3", "is_robot_indexable": true, "report_reasons": null, "author": "bugcat970", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1405mo3/what_you_need_to_know_about_media_queries_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://engineering.kablamo.com.au/posts/2023/media-queries-and-responsive-design/", "subreddit_subscribers": 108826, "created_utc": 1685865606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ClickHouse &amp; Apache Doris in Keyword Searching by Response Time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "name": "t3_13zfuzo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3YNr8JBsDa-hTVz9X7Mg9ySDf2Gxaz7m4ztNjLjBBHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685805393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qv56puewjt3b1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qv56puewjt3b1.png?auto=webp&amp;v=enabled&amp;s=a46bfc83ff38850db64463af7d32556d44fdd932", "width": 1546, "height": 626}, "resolutions": [{"url": "https://preview.redd.it/qv56puewjt3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d20308115c6aa037f522ccff1818eac2717a08", "width": 108, "height": 43}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c749b2e3f23df617170980afdc803195d3a99eae", "width": 216, "height": 87}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=458ecb686a46b3207b676f3d386cbf22b7582e91", "width": 320, "height": 129}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd78968c09959c5f75a71722198fc2748de3dd7f", "width": 640, "height": 259}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00cd57910c1d39b65f44809409ba8ac5b648b963", "width": 960, "height": 388}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e321b06b84e0f9ec2547da86b87986d9e47ec4f", "width": 1080, "height": 437}], "variants": {}, "id": "1XU_zXzsbjj_W6qRR_YvNN37AggGG6mwMOPp23V2fbQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zfuzo", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zfuzo/clickhouse_apache_doris_in_keyword_searching_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qv56puewjt3b1.png", "subreddit_subscribers": 108826, "created_utc": 1685805393.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}