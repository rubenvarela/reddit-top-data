{"kind": "Listing", "data": {"after": "t3_14k1vv8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Large healthcare insurance provider, moved from on-prem SQL Server to Snowflake. Had a bunch of consultants, senior experienced resources that have worked on Snowflake for other clients help optimize our DWH and models.\n\nNo matter how much credit optimization we do Snowflake is 5 to 10x more expensive than SQL Server and its getting to a stage where we have to move active querying away from Snowflake just to not have cost blowouts. Needless to say IT leadership is not happy - is this normal, would love to hear more about any other large org's have they experienced similar issues?", "author_fullname": "t2_1100bd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone experiencing insane costs with Snowflake in large enterprise org's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k02k6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 109, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 109, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687830619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Large healthcare insurance provider, moved from on-prem SQL Server to Snowflake. Had a bunch of consultants, senior experienced resources that have worked on Snowflake for other clients help optimize our DWH and models.&lt;/p&gt;\n\n&lt;p&gt;No matter how much credit optimization we do Snowflake is 5 to 10x more expensive than SQL Server and its getting to a stage where we have to move active querying away from Snowflake just to not have cost blowouts. Needless to say IT leadership is not happy - is this normal, would love to hear more about any other large org&amp;#39;s have they experienced similar issues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14k02k6", "is_robot_indexable": true, "report_reasons": null, "author": "Lsaone", "discussion_type": null, "num_comments": 90, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k02k6/anyone_experiencing_insane_costs_with_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k02k6/anyone_experiencing_insane_costs_with_snowflake/", "subreddit_subscribers": 112586, "created_utc": 1687830619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nhttps://preview.redd.it/1zgo3vnl3e8b1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=13f740432027d71934c6e58fda8bdbd4609f2763\n\nThis blog post will provide a detailed walkthrough of creating a modern data pipeline using a combination of Terraform, AWS Lambda and S3, Snowflake, DBT, Mage AI, and Dash.\n\n[https://medium.com/@stefentaime\\_10958/building-a-modern-data-pipeline-a-deep-dive-into-terraform-aws-lambda-and-s3-snowflake-dbt-cac6816f2100](https://medium.com/@stefentaime_10958/building-a-modern-data-pipeline-a-deep-dive-into-terraform-aws-lambda-and-s3-snowflake-dbt-cac6816f2100)", "author_fullname": "t2_7sisbd20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Modern Data Pipeline: A Deep Dive into Terraform, AWS Lambda and S3, Snowflake, DBT, Mage AI, and Dash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1zgo3vnl3e8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bf08175fc516acf7cbea7f7720cc123bcf41c1c"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04e89552c17f14df8f0b6327fc8c6e5954f86059"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=925a978ff0457617e42b251cb0495e62167c32ef"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ee5131e09960c47acdb0fc39af9df394f2334d8"}, {"y": 704, "x": 960, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7856db562150383982eaebea3db89ac0eaa44cf"}, {"y": 792, "x": 1080, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ca1cb69aa27349560578e983f2df190b45401d6"}], "s": {"y": 1467, "x": 2000, "u": "https://preview.redd.it/1zgo3vnl3e8b1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=13f740432027d71934c6e58fda8bdbd4609f2763"}, "id": "1zgo3vnl3e8b1"}}, "name": "t3_14jm3gi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/A0OPBLz6sJ-yHcboTDU7hsr8wQ9ttks8Qe8GcFBTFOM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1687797237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/1zgo3vnl3e8b1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=13f740432027d71934c6e58fda8bdbd4609f2763\"&gt;https://preview.redd.it/1zgo3vnl3e8b1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=13f740432027d71934c6e58fda8bdbd4609f2763&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This blog post will provide a detailed walkthrough of creating a modern data pipeline using a combination of Terraform, AWS Lambda and S3, Snowflake, DBT, Mage AI, and Dash.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@stefentaime_10958/building-a-modern-data-pipeline-a-deep-dive-into-terraform-aws-lambda-and-s3-snowflake-dbt-cac6816f2100\"&gt;https://medium.com/@stefentaime_10958/building-a-modern-data-pipeline-a-deep-dive-into-terraform-aws-lambda-and-s3-snowflake-dbt-cac6816f2100&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?auto=webp&amp;v=enabled&amp;s=4f99686eb57abd5f7b3e28eb9ed2c2661de268ae", "width": 1200, "height": 880}, "resolutions": [{"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=720dfdf30d1464df7667e149734ae82ea9a93d0e", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c62112a11eb9e81d3db78295efb48775223a5678", "width": 216, "height": 158}, {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c2daed7632200561109125c8441aaf3c3c7c28b", "width": 320, "height": 234}, {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4961fb4ba56ab2b1aa421e6dd830b048d8ed97ea", "width": 640, "height": 469}, {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=975cc77bb76ea6ea8f9c8b7acc189ec6b2ce4971", "width": 960, "height": 704}, {"url": "https://external-preview.redd.it/6r4TL9q9B990ofCmRY0cMh81_85LhxdABm5Uh3R8E1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0fd81000b505cce6f867df9a8b6b0d8cf1f7c969", "width": 1080, "height": 792}], "variants": {}, "id": "UzgulAVdcHqPLi3sS_J_EFXIPwILYlvRvcQMaDFdfPE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14jm3gi", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous_Ad6059", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jm3gi/building_a_modern_data_pipeline_a_deep_dive_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jm3gi/building_a_modern_data_pipeline_a_deep_dive_into/", "subreddit_subscribers": 112586, "created_utc": 1687797237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI have mentored more than 200+ students and working professionals in the past 2 years. I've just released my latest ebook, **\"Data Engineering 101: A Comprehensive Guide for Beginners and Career Transitioners.\"**\n\nWhether you're a beginner or transitioning careers, this guide covers all the essentials of data engineering. I'd love to hear your feedback and suggestions to make it even better. Please direct message me to receive a copy.\n\nDescription Of the ebook:\n\n\"Data Engineering 101\" is the ultimate resource for anyone interested in exploring the world of data engineering. Authored after having 200+ mentoring sessions and by a seasoned data engineering expert, this guide offers a structured and practical approach to mastering the essentials of data engineering.\n\nWhether you are a beginner aiming to start a career in data engineering or a professional looking to transition into this field, this guide has been meticulously crafted to cater to your needs. It covers everything from the core concepts and responsibilities of a data engineer to the key distinctions between data engineering and other data roles. Additionally, it provides valuable insights into the crucial role of data engineering in today's data-driven organizations.\n\nOne of the standout features of this guide is its comprehensive framework, which breaks down data engineering into six pillars. Each pillar is explored in detail, providing you with a solid foundation and a clear understanding of the subject matter. To further enhance your learning journey, the guide includes a curated list of recommended resources for expanding your knowledge and skill set.\n\n&amp;#x200B;\n\nThank you in advance for your support and participation!\n\n&amp;#x200B;", "author_fullname": "t2_rrbmofj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback on 'Data Engineering 101' eBook!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14joypx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687825224.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687803770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have mentored more than 200+ students and working professionals in the past 2 years. I&amp;#39;ve just released my latest ebook, &lt;strong&gt;&amp;quot;Data Engineering 101: A Comprehensive Guide for Beginners and Career Transitioners.&amp;quot;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a beginner or transitioning careers, this guide covers all the essentials of data engineering. I&amp;#39;d love to hear your feedback and suggestions to make it even better. Please direct message me to receive a copy.&lt;/p&gt;\n\n&lt;p&gt;Description Of the ebook:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Data Engineering 101&amp;quot; is the ultimate resource for anyone interested in exploring the world of data engineering. Authored after having 200+ mentoring sessions and by a seasoned data engineering expert, this guide offers a structured and practical approach to mastering the essentials of data engineering.&lt;/p&gt;\n\n&lt;p&gt;Whether you are a beginner aiming to start a career in data engineering or a professional looking to transition into this field, this guide has been meticulously crafted to cater to your needs. It covers everything from the core concepts and responsibilities of a data engineer to the key distinctions between data engineering and other data roles. Additionally, it provides valuable insights into the crucial role of data engineering in today&amp;#39;s data-driven organizations.&lt;/p&gt;\n\n&lt;p&gt;One of the standout features of this guide is its comprehensive framework, which breaks down data engineering into six pillars. Each pillar is explored in detail, providing you with a solid foundation and a clear understanding of the subject matter. To further enhance your learning journey, the guide includes a curated list of recommended resources for expanding your knowledge and skill set.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your support and participation!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14joypx", "is_robot_indexable": true, "report_reasons": null, "author": "Anishekkamal", "discussion_type": null, "num_comments": 186, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14joypx/seeking_feedback_on_data_engineering_101_ebook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14joypx/seeking_feedback_on_data_engineering_101_ebook/", "subreddit_subscribers": 112586, "created_utc": 1687803770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new to the DE world and I'm trying to learn all the names and the players.  It's occurred to me that a lot of the DE world is like Facebook/MySpace/tiktok/YouTube/etc.  You can do the exact same thing on multiple platforms.  What makes people chose one over the other?  I get price and usability factor in, but are there folks that say, \"I like working with AWS (or MS or Apache, etc) stuff, so I'm just going to stick with what they have\"?", "author_fullname": "t2_j15uu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or are there a bunch products/tools out there that do the exact same thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ju1vu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687815303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new to the DE world and I&amp;#39;m trying to learn all the names and the players.  It&amp;#39;s occurred to me that a lot of the DE world is like Facebook/MySpace/tiktok/YouTube/etc.  You can do the exact same thing on multiple platforms.  What makes people chose one over the other?  I get price and usability factor in, but are there folks that say, &amp;quot;I like working with AWS (or MS or Apache, etc) stuff, so I&amp;#39;m just going to stick with what they have&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ju1vu", "is_robot_indexable": true, "report_reasons": null, "author": "jbrune", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ju1vu/is_it_me_or_are_there_a_bunch_productstools_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ju1vu/is_it_me_or_are_there_a_bunch_productstools_out/", "subreddit_subscribers": 112586, "created_utc": 1687815303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mainly create pipelines and always try to tune and group activities in ADF like a template and refactor the blocks.\n\nMostly, when I create new pipelines that transfer data from source to DWH, I always check some quality data control (if on source I've 50 applications, on DWH I must have 50 applications).\n\nMy question is, how can I automate this kind of  tests? And in which part of Azure? Which tool or component?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can a pipeline ELT be tested?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ju4bn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687815454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mainly create pipelines and always try to tune and group activities in ADF like a template and refactor the blocks.&lt;/p&gt;\n\n&lt;p&gt;Mostly, when I create new pipelines that transfer data from source to DWH, I always check some quality data control (if on source I&amp;#39;ve 50 applications, on DWH I must have 50 applications).&lt;/p&gt;\n\n&lt;p&gt;My question is, how can I automate this kind of  tests? And in which part of Azure? Which tool or component?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ju4bn", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ju4bn/how_can_a_pipeline_elt_be_tested/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ju4bn/how_can_a_pipeline_elt_be_tested/", "subreddit_subscribers": 112586, "created_utc": 1687815454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer with about 4 years of experience, and I'd like to learn full stack development to be able to build my own shit.\n\nI sometimes find stumble upon opportunities where I could make a few extra bucks but have to decline due to lack of expertise.\n\nI am proficient in python, SQL and Typescript, I'm junior level with frontend development in React, know some DevOps and have almost zero knowledge about backend development and web servers.\n\nWhat would you recommend?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning full stack development as a DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k9h4v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687860367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer with about 4 years of experience, and I&amp;#39;d like to learn full stack development to be able to build my own shit.&lt;/p&gt;\n\n&lt;p&gt;I sometimes find stumble upon opportunities where I could make a few extra bucks but have to decline due to lack of expertise.&lt;/p&gt;\n\n&lt;p&gt;I am proficient in python, SQL and Typescript, I&amp;#39;m junior level with frontend development in React, know some DevOps and have almost zero knowledge about backend development and web servers.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14k9h4v", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k9h4v/learning_full_stack_development_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k9h4v/learning_full_stack_development_as_a_de/", "subreddit_subscribers": 112586, "created_utc": 1687860367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I am on data engineering learning track, and i have learnt SQL, and Python, but I wanted to ask if its important or needed to learn SSIS, or should i just go straight to pyspark or cloud data warehouses. I already did a course on udemy that took me through the fundamentals of Datawarehousing though.  \n\n\nN.B I must say, i have learnt a lot from the discourse on this channel. Thank you all so much", "author_fullname": "t2_5n32higch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IS IT NECESSARY TO LEARN SSIS, SSRS AND SSAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jpoj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687805412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am on data engineering learning track, and i have learnt SQL, and Python, but I wanted to ask if its important or needed to learn SSIS, or should i just go straight to pyspark or cloud data warehouses. I already did a course on udemy that took me through the fundamentals of Datawarehousing though.  &lt;/p&gt;\n\n&lt;p&gt;N.B I must say, i have learnt a lot from the discourse on this channel. Thank you all so much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14jpoj6", "is_robot_indexable": true, "report_reasons": null, "author": "Able_Truth6207", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jpoj6/is_it_necessary_to_learn_ssis_ssrs_and_ssas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jpoj6/is_it_necessary_to_learn_ssis_ssrs_and_ssas/", "subreddit_subscribers": 112586, "created_utc": 1687805412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet File Format: Everything You Need to Know", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14k1a5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/N3x30rVgzYui90JTw5nVaBya1HTvO0YnHrdp-ceMXcE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687834082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/parquet-file-format-everything-you-need-to-know-4eed5c0019e7", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?auto=webp&amp;v=enabled&amp;s=3b657379f10b2b27bcb1ad27bc61e9f67b651484", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee525ea6fd4af9a53ca43386aa51d0e5b89f02e2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bd2954af840f3783df6713b6e4c23a2879f9ebf", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f9f59a205a7163a1e5d92d0b6934b5a4c351fa5", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2eb9b8ea1ab88c0bc38a41f94177de2b09abcab3", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8059b36116ab025604bbca0aaf65c7e911dcbf86", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q7kL3YzCJBn-WA6-8krSBJ-dPqfMZRYjbgQamKpCJts.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be43d18185f39241225ff20813ae1b1f99df8cbd", "width": 1080, "height": 607}], "variants": {}, "id": "uuG9uRIscv-ewzbMKqjmDnRqx3qD-tVjogXd2-kOkTs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14k1a5f", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k1a5f/parquet_file_format_everything_you_need_to_know/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/parquet-file-format-everything-you-need-to-know-4eed5c0019e7", "subreddit_subscribers": 112586, "created_utc": 1687834082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\n\n\nHi guys, how is your study routine when you are already employed? do you study on the weekend or after working hours? or just during work? and if it's during work, do you try to research and implement the new concepts in some project at work or do you really study by taking a course, etc? thanks!", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you study outside of work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kdb23", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687871225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, how is your study routine when you are already employed? do you study on the weekend or after working hours? or just during work? and if it&amp;#39;s during work, do you try to research and implement the new concepts in some project at work or do you really study by taking a course, etc? thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14kdb23", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kdb23/do_you_study_outside_of_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kdb23/do_you_study_outside_of_work/", "subreddit_subscribers": 112586, "created_utc": 1687871225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14bjov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Let's install the databricks vs code extension", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14k0199", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aqNDDYu8m__U3ha4Yj91hevpeGgRXPVAvC2z-JSl8CY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687830515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yzmop2clug8b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yzmop2clug8b1.jpg?auto=webp&amp;v=enabled&amp;s=cb99e3b1b3dafe59f97511c151e3374127ec0d5f", "width": 762, "height": 2929}, "resolutions": [{"url": "https://preview.redd.it/yzmop2clug8b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f4ab35586eb533b72434320c4470a1b61b9f9d8", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yzmop2clug8b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26fadc299b8577cfd986b86402b4974a0aef08f1", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yzmop2clug8b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df7abf753e922b3813f25533a26667cb406fa759", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yzmop2clug8b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1954560b0b3f7def0bd9cd7e5426fd7d6649cdc", "width": 640, "height": 1280}], "variants": {}, "id": "XtfCFdekN-4ZN2ek9e95hTzQtSDW4pYkXrh2MMY5jkM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14k0199", "is_robot_indexable": true, "report_reasons": null, "author": "-Maestro-", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k0199/lets_install_the_databricks_vs_code_extension/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yzmop2clug8b1.jpg", "subreddit_subscribers": 112586, "created_utc": 1687830515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings all. i am a data analyst, not engineer so i am not super knowledgeable on data pipelines, but i know a little. i work at a small startup and we are looking to get our data to the next level. We are currently pumping all of our production data into an s3 bucket and using amazon athena to query it. We use looker studio to visualize our data, but have not been able to find a good way to create scheduled sql jobs in athena so our dashboards can run on those specific tables.\n\ni want to get us to a place where all of our business logic for analytics is stored in a specific github repo that the analytics team has access to, can collaborate on &amp; edit, and can run the our jobs. i have been advocating that we switch to a data warehouse and start using something like airflow or dbt to manage our data models (since this is what i have done in the past at other orgs) but some folks higher up maintain that athena is superior to redshift and we shouldnt switch to a warehouse. my question: what is the case for a data warehouse and how can i pitch it effectively? also, if we do switch to redshift or something, is it necessary to also move to a dbt or airflow to create scheduled queries for our data models? apologies for any vagueness, can clarify anything unclear.\n\n&amp;#x200B;\n\nedit: we do not have any data engineers currently, which i have also been advocating for", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how can i pitch the case for a data warehouse to leadership?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jsvux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687813497.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687812681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings all. i am a data analyst, not engineer so i am not super knowledgeable on data pipelines, but i know a little. i work at a small startup and we are looking to get our data to the next level. We are currently pumping all of our production data into an s3 bucket and using amazon athena to query it. We use looker studio to visualize our data, but have not been able to find a good way to create scheduled sql jobs in athena so our dashboards can run on those specific tables.&lt;/p&gt;\n\n&lt;p&gt;i want to get us to a place where all of our business logic for analytics is stored in a specific github repo that the analytics team has access to, can collaborate on &amp;amp; edit, and can run the our jobs. i have been advocating that we switch to a data warehouse and start using something like airflow or dbt to manage our data models (since this is what i have done in the past at other orgs) but some folks higher up maintain that athena is superior to redshift and we shouldnt switch to a warehouse. my question: what is the case for a data warehouse and how can i pitch it effectively? also, if we do switch to redshift or something, is it necessary to also move to a dbt or airflow to create scheduled queries for our data models? apologies for any vagueness, can clarify anything unclear.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: we do not have any data engineers currently, which i have also been advocating for&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14jsvux", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jsvux/how_can_i_pitch_the_case_for_a_data_warehouse_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jsvux/how_can_i_pitch_the_case_for_a_data_warehouse_to/", "subreddit_subscribers": 112586, "created_utc": 1687812681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! All,\n\nI wrote a Single Message Transform for Kafka Connect. It operates on messages that are JSON. It's purpose is to remove fields that have sensitive data, like PII, Financial etc.\n\nHere is the blog post introducing it:\n\n[mask-json-field SMT for Kafka Connect](https://ferozedaud.blogspot.com/2023/06/mask-json-field-transform-kafka-connect.html)\n\nAnd here is the source code:\n\n[GitHub: ferozed/mask-json-field-transform](https://github.com/ferozed/mask-json-field-transform)\n\n&amp;#x200B;", "author_fullname": "t2_a6xh2lu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing `mask-json-field` Single Message Transform for Kafka Connect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jnlp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687800613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! All,&lt;/p&gt;\n\n&lt;p&gt;I wrote a Single Message Transform for Kafka Connect. It operates on messages that are JSON. It&amp;#39;s purpose is to remove fields that have sensitive data, like PII, Financial etc.&lt;/p&gt;\n\n&lt;p&gt;Here is the blog post introducing it:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ferozedaud.blogspot.com/2023/06/mask-json-field-transform-kafka-connect.html\"&gt;mask-json-field SMT for Kafka Connect&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here is the source code:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ferozed/mask-json-field-transform\"&gt;GitHub: ferozed/mask-json-field-transform&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14jnlp2", "is_robot_indexable": true, "report_reasons": null, "author": "Affectionate-Fuel521", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jnlp2/introducing_maskjsonfield_single_message/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jnlp2/introducing_maskjsonfield_single_message/", "subreddit_subscribers": 112586, "created_utc": 1687800613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to enroll to one of the Udemy courses offered by Marc Lamberti. I am not sure which one I should choose as I am still starting my journey in data engineering. For context, I am a backend engineer with &lt;1 year of experience and have worked extensively with Docker, Python and SQL for several school projects of mine during my CS undergrad. I also already have completed this [2 hour course by coder2j on YouTube](https://www.youtube.com/watch?v=K9AnJ9_ZAXE&amp;list=PLwFJcsJ61oujFW8pTo9S8_b6wujg5NgGW&amp;ab_channel=coder2j).   \nI already tried searching for a comparison of the two courses I mentioned but got no luck finding one. I would like to know which course will benefit me the most given my current skills.   \nThank you in advance!", "author_fullname": "t2_9edkfmm32", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Help] Marc Lamberti's Apache Airflow: The Hands-On Guide vs. The Complete Hands-On Introduction to Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kes2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687874945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to enroll to one of the Udemy courses offered by Marc Lamberti. I am not sure which one I should choose as I am still starting my journey in data engineering. For context, I am a backend engineer with &amp;lt;1 year of experience and have worked extensively with Docker, Python and SQL for several school projects of mine during my CS undergrad. I also already have completed this &lt;a href=\"https://www.youtube.com/watch?v=K9AnJ9_ZAXE&amp;amp;list=PLwFJcsJ61oujFW8pTo9S8_b6wujg5NgGW&amp;amp;ab_channel=coder2j\"&gt;2 hour course by coder2j on YouTube&lt;/a&gt;.&lt;br/&gt;\nI already tried searching for a comparison of the two courses I mentioned but got no luck finding one. I would like to know which course will benefit me the most given my current skills.&lt;br/&gt;\nThank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kbFgPxqjG0V9mNQKtNk3p_H0De6gZaJXayk-EltbvVs.jpg?auto=webp&amp;v=enabled&amp;s=21ec4eb3a2657234c76166649292b5c5106a1460", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/kbFgPxqjG0V9mNQKtNk3p_H0De6gZaJXayk-EltbvVs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a38ffb06e5546bdf2cfa179360fb7e740df256d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/kbFgPxqjG0V9mNQKtNk3p_H0De6gZaJXayk-EltbvVs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3457e8fdf979813b9fbdb4490aec405845026aa6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/kbFgPxqjG0V9mNQKtNk3p_H0De6gZaJXayk-EltbvVs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=932e39214ffa089d42d2ed24d8dcc57ef54e29aa", "width": 320, "height": 240}], "variants": {}, "id": "2takmFcuXFg2Qh0ocu9wuENNXk_Xqegsc26PdHHZJ5k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14kes2t", "is_robot_indexable": true, "report_reasons": null, "author": "coldstare_warmheart", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kes2t/help_marc_lambertis_apache_airflow_the_handson/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kes2t/help_marc_lambertis_apache_airflow_the_handson/", "subreddit_subscribers": 112586, "created_utc": 1687874945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Redditors,\n\nI recently passed the AWS CCP certification, and I am studying Kafka and different other technologies, as well as building projects with those. I want to get a more advanced cloud certification in the next two months to prove my skills to a potential employer.\n\n&amp;#x200B;\n\n AWS Associate level has three options: Solutions Architect, Developer and SysOps, and I would like to know which one is the most suitable for starting a career in DE. I know that certs are not the most essential part of a good DE portfolio, but I believe they can help with getting my resume noticed and get some hands-on experience with AWS.\n\n&amp;#x200B;\n\nThank You !\n\n&amp;#x200B;", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which AWS Associate level certification is most suited for a career in data engineering ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ke6rb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687873474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors,&lt;/p&gt;\n\n&lt;p&gt;I recently passed the AWS CCP certification, and I am studying Kafka and different other technologies, as well as building projects with those. I want to get a more advanced cloud certification in the next two months to prove my skills to a potential employer.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;AWS Associate level has three options: Solutions Architect, Developer and SysOps, and I would like to know which one is the most suitable for starting a career in DE. I know that certs are not the most essential part of a good DE portfolio, but I believe they can help with getting my resume noticed and get some hands-on experience with AWS.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank You !&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ke6rb", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ke6rb/which_aws_associate_level_certification_is_most/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ke6rb/which_aws_associate_level_certification_is_most/", "subreddit_subscribers": 112586, "created_utc": 1687873474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I'm Maciej, one of the co-founders of Prophecy ([https://prophecy.io](https://prophecy.io/)) - low code for Data Transformations and Generative-AI. [Blog here.](https://www.prophecy.io/blog/announcing-prophecy-3-0-low-code-sql-transformations)\n\nWe've just released our product's latest version, making it easier for teams to build data pipelines for LLM-based applications. As part of the release, we're also **open-sourcing the toolbox for Spark** ([https://github.com/prophecy-io/spark-ai](https://github.com/prophecy-io/spark-ai)) that contains useful connectors, transformations, and agents for building Gen-AI applications.\n\nHopefully, this allows some of you to build your apps easier and make them more robust and scalable from day one. Quick getting started example available here: [https://github.com/prophecy-samples/gen-ai-chatbot-template](https://github.com/prophecy-samples/gen-ai-chatbot-template) (all code is open-source too).\n\nWhile our product is already mature, the toolbox shared above is still pretty early but will be completely OSS.\n\nAny thoughts on the concept and ideas for what's essential to the community would be super appreciated!", "author_fullname": "t2_jssbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A platform for building Gen-AI applications on Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k0amt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687831252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m Maciej, one of the co-founders of Prophecy (&lt;a href=\"https://prophecy.io/\"&gt;https://prophecy.io&lt;/a&gt;) - low code for Data Transformations and Generative-AI. &lt;a href=\"https://www.prophecy.io/blog/announcing-prophecy-3-0-low-code-sql-transformations\"&gt;Blog here.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve just released our product&amp;#39;s latest version, making it easier for teams to build data pipelines for LLM-based applications. As part of the release, we&amp;#39;re also &lt;strong&gt;open-sourcing the toolbox for Spark&lt;/strong&gt; (&lt;a href=\"https://github.com/prophecy-io/spark-ai\"&gt;https://github.com/prophecy-io/spark-ai&lt;/a&gt;) that contains useful connectors, transformations, and agents for building Gen-AI applications.&lt;/p&gt;\n\n&lt;p&gt;Hopefully, this allows some of you to build your apps easier and make them more robust and scalable from day one. Quick getting started example available here: &lt;a href=\"https://github.com/prophecy-samples/gen-ai-chatbot-template\"&gt;https://github.com/prophecy-samples/gen-ai-chatbot-template&lt;/a&gt; (all code is open-source too).&lt;/p&gt;\n\n&lt;p&gt;While our product is already mature, the toolbox shared above is still pretty early but will be completely OSS.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on the concept and ideas for what&amp;#39;s essential to the community would be super appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?auto=webp&amp;v=enabled&amp;s=4d483aa2f97fb08a4289d8d9eb1ac5a3f9119ce9", "width": 1385, "height": 649}, "resolutions": [{"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fe66dca616c317e8c07135b863d3abf33c70c48", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96158ec9296bdf05e091e8f88c06e2fc88273226", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e71b15ed06c8881d2cc45fa4a29d47bff88ac38", "width": 320, "height": 149}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f20cf63f254ebc37d0355406a1bfd7ff4a76d129", "width": 640, "height": 299}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c5bc95e3dad03c7ec5db1969123516e2339ec2c", "width": 960, "height": 449}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c90bc8932bc119cfd159ff5a1e54c72fb5f8888", "width": 1080, "height": 506}], "variants": {}, "id": "9K0NtMO3DrArRWl1snEoqzUk6sKcnfRw6klEhxAHVCo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14k0amt", "is_robot_indexable": true, "report_reasons": null, "author": "several27", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k0amt/a_platform_for_building_genai_applications_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k0amt/a_platform_for_building_genai_applications_on/", "subreddit_subscribers": 112586, "created_utc": 1687831252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience and thoughts of using EMR to replace their DB?  Saw an article about Netflix switching to this.", "author_fullname": "t2_4k8au9km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing RDBMS with EMR (S3 &amp; Presto)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jwtj1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687821938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience and thoughts of using EMR to replace their DB?  Saw an article about Netflix switching to this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14jwtj1", "is_robot_indexable": true, "report_reasons": null, "author": "Contango_4eva", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jwtj1/replacing_rdbms_with_emr_s3_presto/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jwtj1/replacing_rdbms_with_emr_s3_presto/", "subreddit_subscribers": 112586, "created_utc": 1687821938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm a tech lead who was an analytics engineer prior to this. We need another data engineer to join the team that has devOps experience. We are a startup and knowledge of AWS, database deployment, and things like Kubernetes is pretty critical to success within the role. I personally have little experience with the infra side of things, and thus have little experience interviewing someone for such a role. I would like to give the candidate a debugging exercise or a some kind of problem that would highlight devOps experience. Any thoughts? Thank you", "author_fullname": "t2_8ywetov1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviewing for a Data Engineer with infrastructure/DevOps experience. Need a debugging or technical assessment question/s to ask.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jrmr7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687809865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m a tech lead who was an analytics engineer prior to this. We need another data engineer to join the team that has devOps experience. We are a startup and knowledge of AWS, database deployment, and things like Kubernetes is pretty critical to success within the role. I personally have little experience with the infra side of things, and thus have little experience interviewing someone for such a role. I would like to give the candidate a debugging exercise or a some kind of problem that would highlight devOps experience. Any thoughts? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14jrmr7", "is_robot_indexable": true, "report_reasons": null, "author": "OvremployedSnowflake", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jrmr7/interviewing_for_a_data_engineer_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jrmr7/interviewing_for_a_data_engineer_with/", "subreddit_subscribers": 112586, "created_utc": 1687809865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, new to the group and looking for advice. \n\nWe are running a backfill of GA4 into BigQuery using FiveTran with a task to pull the last 6 months of data. Current GA4 data is streamed directly using the native connector.\n\nWe opted for FiveTran over building a Python call due to limited hours in our contract and the client\u2019s ability to leverage the data moving forward (they have no prowess in SLQ.\n\nWe are seeing that the connector is regularly running the sync every hour as scheduled (everyone here is likely aware of the hourly and daily quotas which we know will restrict the number of records that can be transferred using GA4\u2019s API).\n\nBut, data is cutting off on 5/1/2023. GA4 has been live for this client since April of last year, so there is no apparent reason for this cutoff. \n\nAdditionally, there are several days with null values where this data is observable directly in GA4. \n\nWondering if anyone here has run into similar issues with reverse ETL tools and how they have successfully backfilled historical GA4 data into BigQuery?\n\nAny help will be appreciated. Thanks!", "author_fullname": "t2_cz3efhirx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Fivertran for backfill of GA4 data, but getting cut off before May 2023. Any recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jqibj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687807276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, new to the group and looking for advice. &lt;/p&gt;\n\n&lt;p&gt;We are running a backfill of GA4 into BigQuery using FiveTran with a task to pull the last 6 months of data. Current GA4 data is streamed directly using the native connector.&lt;/p&gt;\n\n&lt;p&gt;We opted for FiveTran over building a Python call due to limited hours in our contract and the client\u2019s ability to leverage the data moving forward (they have no prowess in SLQ.&lt;/p&gt;\n\n&lt;p&gt;We are seeing that the connector is regularly running the sync every hour as scheduled (everyone here is likely aware of the hourly and daily quotas which we know will restrict the number of records that can be transferred using GA4\u2019s API).&lt;/p&gt;\n\n&lt;p&gt;But, data is cutting off on 5/1/2023. GA4 has been live for this client since April of last year, so there is no apparent reason for this cutoff. &lt;/p&gt;\n\n&lt;p&gt;Additionally, there are several days with null values where this data is observable directly in GA4. &lt;/p&gt;\n\n&lt;p&gt;Wondering if anyone here has run into similar issues with reverse ETL tools and how they have successfully backfilled historical GA4 data into BigQuery?&lt;/p&gt;\n\n&lt;p&gt;Any help will be appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14jqibj", "is_robot_indexable": true, "report_reasons": null, "author": "ndertone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jqibj/using_fivertran_for_backfill_of_ga4_data_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jqibj/using_fivertran_for_backfill_of_ga4_data_but/", "subreddit_subscribers": 112586, "created_utc": 1687807276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doing some research about the challenges of creating and using behavioral customer data. Wanted to ask the group what are some of the challenges you're finding collecting and using behavioral customer data? What are your preferred tools, sources, targets for this type of data?\n\n&amp;#x200B;", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using behavioral customer data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14kgls3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687879285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doing some research about the challenges of creating and using behavioral customer data. Wanted to ask the group what are some of the challenges you&amp;#39;re finding collecting and using behavioral customer data? What are your preferred tools, sources, targets for this type of data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14kgls3", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14kgls3/using_behavioral_customer_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14kgls3/using_behavioral_customer_data/", "subreddit_subscribers": 112586, "created_utc": 1687879285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you guys deploy a Kafka consumer on K8?\n\nIs it typical to just trigger the consumer to run from an ETL orchestrator like Airflow? Would you just use the Python operator? Would it be better to have a separate CI/CD tool to build an image, push it to a private repository, and trigger it from airflow using a K8 operator?\n\nIf triggering it from airflow isn\u2019t a good idea, then how could you go about deploying it? How does monitoring work? \n\nI know confluent comes with monitoring. I\u2019m just wondering how to deploy a consumer without using any a service like Confluent", "author_fullname": "t2_9xl98fqkv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deploy Kafka/monitor Consumer without Confluent?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ke21c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687873148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you guys deploy a Kafka consumer on K8?&lt;/p&gt;\n\n&lt;p&gt;Is it typical to just trigger the consumer to run from an ETL orchestrator like Airflow? Would you just use the Python operator? Would it be better to have a separate CI/CD tool to build an image, push it to a private repository, and trigger it from airflow using a K8 operator?&lt;/p&gt;\n\n&lt;p&gt;If triggering it from airflow isn\u2019t a good idea, then how could you go about deploying it? How does monitoring work? &lt;/p&gt;\n\n&lt;p&gt;I know confluent comes with monitoring. I\u2019m just wondering how to deploy a consumer without using any a service like Confluent&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ke21c", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive-Channel39", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ke21c/how_to_deploy_kafkamonitor_consumer_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ke21c/how_to_deploy_kafkamonitor_consumer_without/", "subreddit_subscribers": 112586, "created_utc": 1687873148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to optimise a job which is currently running for 2 hours. It is using rdd\u2019s and converting that into DF\u2019s make it even more worse. Here is what I did:\n\nI have a very big fact table where a column is an array of structs. I can only join with the dimension table when that field is exploded. \n\nOnce I join with dimension table, I need to aggregate based on certain dimension field obtained from dim table and collect all the structs associated with that that field and convert back into array of structs. \n\nAlso, I cannot braodcast the dim table because it\u2019s above 10 GB and the limit is 8 GB. So, instead I built a hash Map and did sc.broadcast to avoid shuffle.\n\nCurrently I\u2019m using explode, hashmap lookups and collect_list functions, but however all the executors are getting killed.\n\nI feel explode and collect_list are also expensive operations. \n\nSo, I\u2019d greatly appreciate if you could suggest me any ways I can optimise it or suggest any alternative and make it run less than an hour.", "author_fullname": "t2_a0rorgfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice on Optimising a long running job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ke0ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687873019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to optimise a job which is currently running for 2 hours. It is using rdd\u2019s and converting that into DF\u2019s make it even more worse. Here is what I did:&lt;/p&gt;\n\n&lt;p&gt;I have a very big fact table where a column is an array of structs. I can only join with the dimension table when that field is exploded. &lt;/p&gt;\n\n&lt;p&gt;Once I join with dimension table, I need to aggregate based on certain dimension field obtained from dim table and collect all the structs associated with that that field and convert back into array of structs. &lt;/p&gt;\n\n&lt;p&gt;Also, I cannot braodcast the dim table because it\u2019s above 10 GB and the limit is 8 GB. So, instead I built a hash Map and did sc.broadcast to avoid shuffle.&lt;/p&gt;\n\n&lt;p&gt;Currently I\u2019m using explode, hashmap lookups and collect_list functions, but however all the executors are getting killed.&lt;/p&gt;\n\n&lt;p&gt;I feel explode and collect_list are also expensive operations. &lt;/p&gt;\n\n&lt;p&gt;So, I\u2019d greatly appreciate if you could suggest me any ways I can optimise it or suggest any alternative and make it run less than an hour.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ke0ao", "is_robot_indexable": true, "report_reasons": null, "author": "Worth-Lie-3432", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ke0ao/need_advice_on_optimising_a_long_running_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ke0ao/need_advice_on_optimising_a_long_running_job/", "subreddit_subscribers": 112586, "created_utc": 1687873019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Information: -\nData pipeline on Azure, gets data as csv files from different souces (SAP, SAGE, KingDee, Dynamics) in ADLS storage. Data Factory does the initial clean up, type casting, schema mapping, etc. and pushes to DB. DB takes care of all harmonisation, currency conversion, unit conversion, etc.\n\nI was interested in the Azure Purview tool to help Data Governance. Unfortunately it has every aspect of Data Governance covered except Data Quality or MDM tools. For MDM Azure heavily certifies CluedIn, however on reseaeching CluedIn come up to be 135k Euros/year + taxes + Azure infrastructure costs for more than 200k data points. Which is exorbitant because our expense on the whole data platform is 10k - 14k a year.\n\nWhat are you advises on MDM tools, our focus is mostly to fix Data Quality issues.", "author_fullname": "t2_9j7ge5o2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MDM Tools - CluedIn, etc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k8khz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687857363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Information: -\nData pipeline on Azure, gets data as csv files from different souces (SAP, SAGE, KingDee, Dynamics) in ADLS storage. Data Factory does the initial clean up, type casting, schema mapping, etc. and pushes to DB. DB takes care of all harmonisation, currency conversion, unit conversion, etc.&lt;/p&gt;\n\n&lt;p&gt;I was interested in the Azure Purview tool to help Data Governance. Unfortunately it has every aspect of Data Governance covered except Data Quality or MDM tools. For MDM Azure heavily certifies CluedIn, however on reseaeching CluedIn come up to be 135k Euros/year + taxes + Azure infrastructure costs for more than 200k data points. Which is exorbitant because our expense on the whole data platform is 10k - 14k a year.&lt;/p&gt;\n\n&lt;p&gt;What are you advises on MDM tools, our focus is mostly to fix Data Quality issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14k8khz", "is_robot_indexable": true, "report_reasons": null, "author": "sc_santy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k8khz/mdm_tools_cluedin_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k8khz/mdm_tools_cluedin_etc/", "subreddit_subscribers": 112586, "created_utc": 1687857363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you use Scripts or Spreadsheets?\n\nThen how do you make sense of the details within each session?\n\n[I wrote a blog about how we do this at Teradata](https://medium.com/p/d1022847fce9) with sessionize, and nPath functions, that efficiently take care of the pre-processing, allowing us to concentrate on analysis and delivering valuable insights to the business.\n\n[https://medium.com/p/d1022847fce9](https://medium.com/p/d1022847fce9)\n\nLet me know what you think about this approach. And if you found my first blog helpful. :)", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use to piece together sessions when analyzing user activity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k53xw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687845691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you use Scripts or Spreadsheets?&lt;/p&gt;\n\n&lt;p&gt;Then how do you make sense of the details within each session?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/d1022847fce9\"&gt;I wrote a blog about how we do this at Teradata&lt;/a&gt; with sessionize, and nPath functions, that efficiently take care of the pre-processing, allowing us to concentrate on analysis and delivering valuable insights to the business.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/d1022847fce9\"&gt;https://medium.com/p/d1022847fce9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think about this approach. And if you found my first blog helpful. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?auto=webp&amp;v=enabled&amp;s=0a0b73496aa44edd4b75c28ee298c8b3db89ed95", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98b9956b1a46e4eb1620adba3adbe7cac6f7b891", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc4ecc77fec97ee69256c0605d05cc3f4eaebd9d", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a23e121efee98d9cd30619456b4908589b2b51b", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba91af3a56e7e97ef48c8347089391e3629426b3", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01575fa9c0de708dd2ff684a7977d15aea3dcf90", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93562252a44fc4a78424fa2fd2f0956c44105a49", "width": 1080, "height": 720}], "variants": {}, "id": "3OXjMmaTyIRlECCMhmjQHQ_AaGze2tzyrHtlhYFkPlg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14k53xw", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k53xw/what_do_you_use_to_piece_together_sessions_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k53xw/what_do_you_use_to_piece_together_sessions_when/", "subreddit_subscribers": 112586, "created_utc": 1687845691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "CONTEXT: I've currently got a lambda running with a cron scheduler to execute every 10 hours which basically grabs a csv file from the web and updates any records / replaces an existing csv file in a S3 bucket with the newer more recent data.\n\nMY GOAL: Now I need to get this csv file in an actual tabular data format (i'm thinking a postgres database?). For starting I don't have too many rows of actual data, around 700 - 800. But I'm planning on adding more pipelines that will automatically collect more data and add to this database (so think few thousands to even 100k+ rows over the coming few months / year). \n\n**MY MAIN QUESTION: My question is, what do I use to perform the simple data engineering required to actually take this raw csv file in my S3 bucket, perform any data cleaning such as replacing nan values, lowercasing, removing any random characters / dropping columns that i may not need, and then uploading all this new cleaned data into a actual postgres database? What AWS tools are required and how do I plan an actual workflow for this type of things?**\n\nWhat is the industry standard way of doing it? (fyi, I don't want to be spending too much, of course I know I'll have to spend $$ for this, but ideally what is a cost efficient way to do this)", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on what tools to use on AWS / best way to do the following task", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k3dnm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687840253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;CONTEXT: I&amp;#39;ve currently got a lambda running with a cron scheduler to execute every 10 hours which basically grabs a csv file from the web and updates any records / replaces an existing csv file in a S3 bucket with the newer more recent data.&lt;/p&gt;\n\n&lt;p&gt;MY GOAL: Now I need to get this csv file in an actual tabular data format (i&amp;#39;m thinking a postgres database?). For starting I don&amp;#39;t have too many rows of actual data, around 700 - 800. But I&amp;#39;m planning on adding more pipelines that will automatically collect more data and add to this database (so think few thousands to even 100k+ rows over the coming few months / year). &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;MY MAIN QUESTION: My question is, what do I use to perform the simple data engineering required to actually take this raw csv file in my S3 bucket, perform any data cleaning such as replacing nan values, lowercasing, removing any random characters / dropping columns that i may not need, and then uploading all this new cleaned data into a actual postgres database? What AWS tools are required and how do I plan an actual workflow for this type of things?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;What is the industry standard way of doing it? (fyi, I don&amp;#39;t want to be spending too much, of course I know I&amp;#39;ll have to spend $$ for this, but ideally what is a cost efficient way to do this)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14k3dnm", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k3dnm/need_advice_on_what_tools_to_use_on_aws_best_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k3dnm/need_advice_on_what_tools_to_use_on_aws_best_way/", "subreddit_subscribers": 112586, "created_utc": 1687840253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How can we get a realtime data stream of the GA4 clickstream?", "author_fullname": "t2_15ed6l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GA4 clickstream data as a data stream", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k1vv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687835807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How can we get a realtime data stream of the GA4 clickstream?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14k1vv8", "is_robot_indexable": true, "report_reasons": null, "author": "gautiexe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14k1vv8/ga4_clickstream_data_as_a_data_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14k1vv8/ga4_clickstream_data_as_a_data_stream/", "subreddit_subscribers": 112586, "created_utc": 1687835807.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}