{"kind": "Listing", "data": {"after": "t3_14k4puc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a mid size company as a manager and generally take a couple of interviews each week, I am frankly exasperated by the shockingly little knowledge even for folks who claim to have worked in the area for years and years.\n\n&amp;#x200B;\n\n1. People would write stuff like LSTM , NN , XGBoost etc. on their resumes but have zero idea of what a linear regression is or what p-values represent. In the last 10-20 interviews I took, not a single one could answer why we use the value of 0.05 as a cut-off (Spoiler - I would accept literally any answer ranging from defending the 0.05 value to just saying that it's random.)\n2.  Shocking logical skills, I tend to assume that people in this field would be at least somewhat competent in maths/logic, apparently not - close to half the interviewed folks can't tell me how many cubes of side 1 cm do I need to create one of side 5 cm.\n3. Communication is exhausting - the words \"explain/describe **briefly**\" apparently doesn't mean shit - I must hear a story from their birth to the end of the universe if I accidently ask an open ended question.\n4. Powerpoint creation / creating synergy between teams doing data work is not data science - please don't waste people's time if that's what you have worked on unless you are trying to switch career paths and are willing to start at the bottom.\n5. Everyone claims that they know \"**advanced excel**\" , knowing how to open an excel sheet and apply =SUM(?:?) is not advanced excel - you better be aware of stuff like offset / lookups  / array formulas / user created functions / named ranges etc. if you claim to be advanced.\n6. There's a massive problem of not understanding the \"**why?**\" about anything - why did you replace your missing values with the medians and not the mean? Why do you use the elbow method for detecting the amount of clusters? What does a scatter plot tell you (hint - In any real world data it doesn't tell you shit - I will fight anyone who claims otherwise.) - they know how to write the code for it, but have absolutely zero idea what's going on under the hood.\n\nThere are many other frustrating things out there but I just had to get this out quickly having done 5 interviews in the last 5 days and wasting 5 hours of my life that I will never get back.\n\n&amp;#x200B;", "author_fullname": "t2_4mhh15o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A small rant - The quality of data analysts / scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k6qt5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 163, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 163, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687851050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a mid size company as a manager and generally take a couple of interviews each week, I am frankly exasperated by the shockingly little knowledge even for folks who claim to have worked in the area for years and years.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;People would write stuff like LSTM , NN , XGBoost etc. on their resumes but have zero idea of what a linear regression is or what p-values represent. In the last 10-20 interviews I took, not a single one could answer why we use the value of 0.05 as a cut-off (Spoiler - I would accept literally any answer ranging from defending the 0.05 value to just saying that it&amp;#39;s random.)&lt;/li&gt;\n&lt;li&gt; Shocking logical skills, I tend to assume that people in this field would be at least somewhat competent in maths/logic, apparently not - close to half the interviewed folks can&amp;#39;t tell me how many cubes of side 1 cm do I need to create one of side 5 cm.&lt;/li&gt;\n&lt;li&gt;Communication is exhausting - the words &amp;quot;explain/describe &lt;strong&gt;briefly&lt;/strong&gt;&amp;quot; apparently doesn&amp;#39;t mean shit - I must hear a story from their birth to the end of the universe if I accidently ask an open ended question.&lt;/li&gt;\n&lt;li&gt;Powerpoint creation / creating synergy between teams doing data work is not data science - please don&amp;#39;t waste people&amp;#39;s time if that&amp;#39;s what you have worked on unless you are trying to switch career paths and are willing to start at the bottom.&lt;/li&gt;\n&lt;li&gt;Everyone claims that they know &amp;quot;&lt;strong&gt;advanced excel&lt;/strong&gt;&amp;quot; , knowing how to open an excel sheet and apply =SUM(?:?) is not advanced excel - you better be aware of stuff like offset / lookups  / array formulas / user created functions / named ranges etc. if you claim to be advanced.&lt;/li&gt;\n&lt;li&gt;There&amp;#39;s a massive problem of not understanding the &amp;quot;&lt;strong&gt;why?&lt;/strong&gt;&amp;quot; about anything - why did you replace your missing values with the medians and not the mean? Why do you use the elbow method for detecting the amount of clusters? What does a scatter plot tell you (hint - In any real world data it doesn&amp;#39;t tell you shit - I will fight anyone who claims otherwise.) - they know how to write the code for it, but have absolutely zero idea what&amp;#39;s going on under the hood.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There are many other frustrating things out there but I just had to get this out quickly having done 5 interviews in the last 5 days and wasting 5 hours of my life that I will never get back.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k6qt5", "is_robot_indexable": true, "report_reasons": null, "author": "singthebollysong", "discussion_type": null, "num_comments": 151, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k6qt5/a_small_rant_the_quality_of_data_analysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k6qt5/a_small_rant_the_quality_of_data_analysts/", "subreddit_subscribers": 932169, "created_utc": 1687851050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all. So I\u2019m coming to Reddit with this question as I feel I can find the most helpful answers here. I\u2019ve done my undergrad in CS and have primarily been focusing on SWE. I\u2019ve done two internships in SWE and one job in it during my undergrad years. I\u2019ve been recently thinking about looking for an internship in DS to experience it once and decide whether or not it is something I want to do or stick with SWE. I\u2019ve an upcoming trainee opportunity in DS field however it will require me to commit for 6months-1year (not sure exact yet), if I commit to this, I will have to turn down other SWE opportunities that come along the way which I\u2019ve not heard from yet. What I like about SWE is that the skills are transferable between companies, moreover there are many companies looking for SWE (albeit it is not the case now, but I\u2019m hoping it gets better), it allows for remote work, and it allows for a certain level of independence. So I want to ask, what is the market like for fresh grads looking for opportunities in DS? Most of the people I know in DS jobs got a masters in it before securing a good job, is it really that important to do masters before hand? What is the data scientists to swe ratio at companies?", "author_fullname": "t2_cw5cd63k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the market like for fresh grads applying for data science roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jlvvs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687797066.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687796767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. So I\u2019m coming to Reddit with this question as I feel I can find the most helpful answers here. I\u2019ve done my undergrad in CS and have primarily been focusing on SWE. I\u2019ve done two internships in SWE and one job in it during my undergrad years. I\u2019ve been recently thinking about looking for an internship in DS to experience it once and decide whether or not it is something I want to do or stick with SWE. I\u2019ve an upcoming trainee opportunity in DS field however it will require me to commit for 6months-1year (not sure exact yet), if I commit to this, I will have to turn down other SWE opportunities that come along the way which I\u2019ve not heard from yet. What I like about SWE is that the skills are transferable between companies, moreover there are many companies looking for SWE (albeit it is not the case now, but I\u2019m hoping it gets better), it allows for remote work, and it allows for a certain level of independence. So I want to ask, what is the market like for fresh grads looking for opportunities in DS? Most of the people I know in DS jobs got a masters in it before securing a good job, is it really that important to do masters before hand? What is the data scientists to swe ratio at companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jlvvs", "is_robot_indexable": true, "report_reasons": null, "author": "No-Championship3342", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jlvvs/what_is_the_market_like_for_fresh_grads_applying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jlvvs/what_is_the_market_like_for_fresh_grads_applying/", "subreddit_subscribers": 932169, "created_utc": 1687796767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm reading Elements is more comprehensive and wasn't sure if it makes sense to read both or if there is alot of overlap and go with Elements", "author_fullname": "t2_4w4kkzlm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need to read Introduction to statistical learning before The Elements of Statistical Learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k371s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687839671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reading Elements is more comprehensive and wasn&amp;#39;t sure if it makes sense to read both or if there is alot of overlap and go with Elements&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k371s", "is_robot_indexable": true, "report_reasons": null, "author": "Liuminescent", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k371s/do_i_need_to_read_introduction_to_statistical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k371s/do_i_need_to_read_introduction_to_statistical/", "subreddit_subscribers": 932169, "created_utc": 1687839671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How often do you need to leave Python/R/SQL and write code in another language like Javascript? \n\nI've (data science intern) been working on building an interactive graph database visualization that my org wants to host for users to explore on our website (it's open gov. data &amp; we're a non-profit). So far, I've been doing everything in Python/Jupyter, using pandas, networkx, and a Sigma.js wrapper for python (ipysigma). But I've now learned that much (maybe all) of what I've written in python will actually need to be implemented in javascript with javascript libraries (certainly the visualization code; most likely the data manipulation code; maybe even the analysis code).\n\nIs it normal to have all your work become useless because it needs to be in another language? Should I learn how to manipulate and analyze data in Javascript?", "author_fullname": "t2_rzuzjxcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need to learn Javascript?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jqmf5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687807538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How often do you need to leave Python/R/SQL and write code in another language like Javascript? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve (data science intern) been working on building an interactive graph database visualization that my org wants to host for users to explore on our website (it&amp;#39;s open gov. data &amp;amp; we&amp;#39;re a non-profit). So far, I&amp;#39;ve been doing everything in Python/Jupyter, using pandas, networkx, and a Sigma.js wrapper for python (ipysigma). But I&amp;#39;ve now learned that much (maybe all) of what I&amp;#39;ve written in python will actually need to be implemented in javascript with javascript libraries (certainly the visualization code; most likely the data manipulation code; maybe even the analysis code).&lt;/p&gt;\n\n&lt;p&gt;Is it normal to have all your work become useless because it needs to be in another language? Should I learn how to manipulate and analyze data in Javascript?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jqmf5", "is_robot_indexable": true, "report_reasons": null, "author": "empirical-sadboy", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jqmf5/do_i_need_to_learn_javascript/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jqmf5/do_i_need_to_learn_javascript/", "subreddit_subscribers": 932169, "created_utc": 1687807538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Some basic plots created using Generative AI for a random housing dataset. Has anyone else been using any generative AI tools to create their plots (for your own datasets)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_14jfhby", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5b2rth27", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AVMxuocNtUUskc4jWMV7FYLgVlRWGgwfBchbjzfoWsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataisbeautiful", "selftext": "", "author_fullname": "t2_5b2rth27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Some basic plots created using Generative AI for a random housing dataset. Has anyone else been using any generative AI tools to create their plots (for your own datasets)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataisbeautiful", "hidden": false, "pwls": 6, "link_flair_css_class": "oc", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_14hzgle", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OC", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AVMxuocNtUUskc4jWMV7FYLgVlRWGgwfBchbjzfoWsE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1687630024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kvq8i6qp808b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kvq8i6qp808b1.png?auto=webp&amp;v=enabled&amp;s=295b5bf2c3e7f380ccdfaa678117043469c01a11", "width": 2000, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836970bfbde7ad3750bb0f484fee3053dd48f6af", "width": 108, "height": 64}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3cd774c58c950e6457f4aa5607bfa2a2ab440c4", "width": 216, "height": 129}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77b21dec711b4702d7a2197048d21b43ee1cd971", "width": 320, "height": 192}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=555884a43532f06ccf8f6f747f7d6ec18cf27900", "width": 640, "height": 384}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=932dca14a699d471aa6f5d4ea50d84f4d1a07631", "width": 960, "height": 576}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d3b006d241c16e9ea166dae58e9b27cdd3535cc", "width": 1080, "height": 648}], "variants": {}, "id": "1pp95e55T7YFxz2klCPbpv-ODSEP0uwHWxPT4ltz35E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2tk95", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14hzgle", "is_robot_indexable": true, "report_reasons": null, "author": "exoxygen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataisbeautiful/comments/14hzgle/oc_some_basic_plots_created_using_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kvq8i6qp808b1.png", "subreddit_subscribers": 19696021, "created_utc": 1687630024.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1687781058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kvq8i6qp808b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kvq8i6qp808b1.png?auto=webp&amp;v=enabled&amp;s=295b5bf2c3e7f380ccdfaa678117043469c01a11", "width": 2000, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836970bfbde7ad3750bb0f484fee3053dd48f6af", "width": 108, "height": 64}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3cd774c58c950e6457f4aa5607bfa2a2ab440c4", "width": 216, "height": 129}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77b21dec711b4702d7a2197048d21b43ee1cd971", "width": 320, "height": 192}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=555884a43532f06ccf8f6f747f7d6ec18cf27900", "width": 640, "height": 384}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=932dca14a699d471aa6f5d4ea50d84f4d1a07631", "width": 960, "height": 576}, {"url": "https://preview.redd.it/kvq8i6qp808b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d3b006d241c16e9ea166dae58e9b27cdd3535cc", "width": 1080, "height": 648}], "variants": {}, "id": "1pp95e55T7YFxz2klCPbpv-ODSEP0uwHWxPT4ltz35E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jfhby", "is_robot_indexable": true, "report_reasons": null, "author": "exoxygen", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14hzgle", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jfhby/oc_some_basic_plots_created_using_generative_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kvq8i6qp808b1.png", "subreddit_subscribers": 932169, "created_utc": 1687781058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI am a graduate of a statistics masters program from last year who has been primarily looking for a job in data science/ML, analytics, or engineering for over half a year. I have had around 20 or so interviews but none panned out, most citing needing more experience despite being entry level positions. My last position was at a nonprofit that ended last fall and since then I have been searching for jobs, working on a project, dealing with mental health, and visiting family primarily to fulfill obligations which are now thankfully done. I feel defeated and am not sure where to go from here. If anyone has any advice feel free to comment.", "author_fullname": "t2_8fclcncq6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jr3ys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687808663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am a graduate of a statistics masters program from last year who has been primarily looking for a job in data science/ML, analytics, or engineering for over half a year. I have had around 20 or so interviews but none panned out, most citing needing more experience despite being entry level positions. My last position was at a nonprofit that ended last fall and since then I have been searching for jobs, working on a project, dealing with mental health, and visiting family primarily to fulfill obligations which are now thankfully done. I feel defeated and am not sure where to go from here. If anyone has any advice feel free to comment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jr3ys", "is_robot_indexable": true, "report_reasons": null, "author": "Anon_Data_guy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jr3ys/career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jr3ys/career_advice/", "subreddit_subscribers": 932169, "created_utc": 1687808663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \nDo you use or know any good app like Duolingo but for maths/stats? I need to use something, as I forget very easy. Thanks!", "author_fullname": "t2_t2dc1g5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation of app for stats/maths", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jqnbm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687807593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nDo you use or know any good app like Duolingo but for maths/stats? I need to use something, as I forget very easy. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jqnbm", "is_robot_indexable": true, "report_reasons": null, "author": "sunflower_ai", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jqnbm/recommendation_of_app_for_statsmaths/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jqnbm/recommendation_of_app_for_statsmaths/", "subreddit_subscribers": 932169, "created_utc": 1687807593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This might be a repetitive post on the sub, sorry if it is. Please redirect me to the answer if already been provided before.  \n\n\nI am graduating with an MSBA degree this fall and looking to improve my DS skills and knowledge for the interview and job. I want to know what are the must-have skills for a Data Scientist and if are there any books/courses/videos that I can refer to make sure I am not missing anything. I am not sure if what I know about Python, SQL, Stats, and Data Science, in general, is enough or not. Please mention any specific topics, tools, or technologies that you think are necessary and not covered in academic settings.", "author_fullname": "t2_7tqen7ik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Must have skills for a Data Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k65hj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687849106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This might be a repetitive post on the sub, sorry if it is. Please redirect me to the answer if already been provided before.  &lt;/p&gt;\n\n&lt;p&gt;I am graduating with an MSBA degree this fall and looking to improve my DS skills and knowledge for the interview and job. I want to know what are the must-have skills for a Data Scientist and if are there any books/courses/videos that I can refer to make sure I am not missing anything. I am not sure if what I know about Python, SQL, Stats, and Data Science, in general, is enough or not. Please mention any specific topics, tools, or technologies that you think are necessary and not covered in academic settings.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k65hj", "is_robot_indexable": true, "report_reasons": null, "author": "Ajinkya1413", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k65hj/must_have_skills_for_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k65hj/must_have_skills_for_a_data_scientist/", "subreddit_subscribers": 932169, "created_utc": 1687849106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, I'm Maciej, one of the co-founders of Prophecy ([https://prophecy.io](https://prophecy.io/)) - low code for Data Transformations and Generative-AI. [Blog here.](https://www.prophecy.io/blog/announcing-prophecy-3-0-low-code-sql-transformations)\n\nWe've just released our product's latest version, making it easier for teams to build data pipelines for LLM-based applications. As part of the release, we're also open-sourcing the toolbox for Spark ([https://github.com/prophecy-io/spark-ai](https://github.com/prophecy-io/spark-ai)) that contains useful connectors, transformations, and agents for building Gen-AI applications.\n\nHopefully, this allows some of you to build your apps easier and make them more robust and scalable from day one. Quick getting started example available here: [https://github.com/prophecy-samples/gen-ai-chatbot-template](https://github.com/prophecy-samples/gen-ai-chatbot-template) (all code is open-source too).\n\nWhile our product is already mature, the toolbox shared above is still pretty early but will be completely OSS.\n\nAny thoughts on the concept and ideas for what's essential to the community would be super appreciated!", "author_fullname": "t2_jssbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A platform for building Gen-AI applications on Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k093h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687831140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I&amp;#39;m Maciej, one of the co-founders of Prophecy (&lt;a href=\"https://prophecy.io/\"&gt;https://prophecy.io&lt;/a&gt;) - low code for Data Transformations and Generative-AI. &lt;a href=\"https://www.prophecy.io/blog/announcing-prophecy-3-0-low-code-sql-transformations\"&gt;Blog here.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve just released our product&amp;#39;s latest version, making it easier for teams to build data pipelines for LLM-based applications. As part of the release, we&amp;#39;re also open-sourcing the toolbox for Spark (&lt;a href=\"https://github.com/prophecy-io/spark-ai\"&gt;https://github.com/prophecy-io/spark-ai&lt;/a&gt;) that contains useful connectors, transformations, and agents for building Gen-AI applications.&lt;/p&gt;\n\n&lt;p&gt;Hopefully, this allows some of you to build your apps easier and make them more robust and scalable from day one. Quick getting started example available here: &lt;a href=\"https://github.com/prophecy-samples/gen-ai-chatbot-template\"&gt;https://github.com/prophecy-samples/gen-ai-chatbot-template&lt;/a&gt; (all code is open-source too).&lt;/p&gt;\n\n&lt;p&gt;While our product is already mature, the toolbox shared above is still pretty early but will be completely OSS.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on the concept and ideas for what&amp;#39;s essential to the community would be super appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?auto=webp&amp;v=enabled&amp;s=4d483aa2f97fb08a4289d8d9eb1ac5a3f9119ce9", "width": 1385, "height": 649}, "resolutions": [{"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fe66dca616c317e8c07135b863d3abf33c70c48", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96158ec9296bdf05e091e8f88c06e2fc88273226", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e71b15ed06c8881d2cc45fa4a29d47bff88ac38", "width": 320, "height": 149}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f20cf63f254ebc37d0355406a1bfd7ff4a76d129", "width": 640, "height": 299}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c5bc95e3dad03c7ec5db1969123516e2339ec2c", "width": 960, "height": 449}, {"url": "https://external-preview.redd.it/y-IQaRiX-fToVq-ph4hQqHzDDhovOlbXyGTne4K-Tj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c90bc8932bc119cfd159ff5a1e54c72fb5f8888", "width": 1080, "height": 506}], "variants": {}, "id": "9K0NtMO3DrArRWl1snEoqzUk6sKcnfRw6klEhxAHVCo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k093h", "is_robot_indexable": true, "report_reasons": null, "author": "several27", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k093h/a_platform_for_building_genai_applications_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k093h/a_platform_for_building_genai_applications_on/", "subreddit_subscribers": 932169, "created_utc": 1687831140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What do you use to piece together sessions when analyzing user activity? Do you use Scripts or Spreadsheets?\n\nThen how do you make sense of the details within each session?\n\n[I wrote a blog about how we do this at Teradata](https://medium.com/p/d1022847fce9) with sessionize, and nPath functions, that efficiently take care of the pre-processing, allowing us to concentrate on analysis and delivering valuable insights to the business.\n\n[https://medium.com/p/d1022847fce9](https://medium.com/p/d1022847fce9)  \n\n\nLet me know what you think about this approach. And if you found my first blog helpful. :)", "author_fullname": "t2_12wozut7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use to piece together sessions when analyzing online user activity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jqq6q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687807778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you use to piece together sessions when analyzing user activity? Do you use Scripts or Spreadsheets?&lt;/p&gt;\n\n&lt;p&gt;Then how do you make sense of the details within each session?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/d1022847fce9\"&gt;I wrote a blog about how we do this at Teradata&lt;/a&gt; with sessionize, and nPath functions, that efficiently take care of the pre-processing, allowing us to concentrate on analysis and delivering valuable insights to the business.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/d1022847fce9\"&gt;https://medium.com/p/d1022847fce9&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think about this approach. And if you found my first blog helpful. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?auto=webp&amp;v=enabled&amp;s=0a0b73496aa44edd4b75c28ee298c8b3db89ed95", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98b9956b1a46e4eb1620adba3adbe7cac6f7b891", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc4ecc77fec97ee69256c0605d05cc3f4eaebd9d", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a23e121efee98d9cd30619456b4908589b2b51b", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba91af3a56e7e97ef48c8347089391e3629426b3", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01575fa9c0de708dd2ff684a7977d15aea3dcf90", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/7qAu8Tp1Ny7WIM7s4rQE6oVWEzImOlYnWviNFRDYKvY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93562252a44fc4a78424fa2fd2f0956c44105a49", "width": 1080, "height": 720}], "variants": {}, "id": "3OXjMmaTyIRlECCMhmjQHQ_AaGze2tzyrHtlhYFkPlg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jqq6q", "is_robot_indexable": true, "report_reasons": null, "author": "JanethL", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jqq6q/what_do_you_use_to_piece_together_sessions_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jqq6q/what_do_you_use_to_piece_together_sessions_when/", "subreddit_subscribers": 932169, "created_utc": 1687807778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow DSers,\n\nWanted to know what projects/courses would be helpful to gain expertise in Spark , especially PySpark?\n\nI have some background in Python.\n\n\nThanks!", "author_fullname": "t2_2h3gl4za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going from Beginner to intermediate level in Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ka1bu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687862115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow DSers,&lt;/p&gt;\n\n&lt;p&gt;Wanted to know what projects/courses would be helpful to gain expertise in Spark , especially PySpark?&lt;/p&gt;\n\n&lt;p&gt;I have some background in Python.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ka1bu", "is_robot_indexable": true, "report_reasons": null, "author": "ieltsp", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ka1bu/going_from_beginner_to_intermediate_level_in_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ka1bu/going_from_beginner_to_intermediate_level_in_spark/", "subreddit_subscribers": 932169, "created_utc": 1687862115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Nominal categorical data in large datasets can be culprits for causing the dimensionality curse. \n\nJust a single column of nominal categ. data like mobile phone models , once encoded (one hot or dummied) can increase the dimension 100-fold or even higher and even break the model \n\nI came across many strategies but one simple approach seems very tempting... how abt just replace the outlier nominal data and nullify. \n\nSeems lazy/naive, but is there no merit to replacing outlier data (nominal categ.) with null? is it better to remove the whole row instead ? Any guidance / expert opinion / or just your thoughts ?", "author_fullname": "t2_4ayumjgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dim. Reduction in nominal Categorical data in a mixed dataset - is replacement with null a reasonable dim. reduction approach?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14joy58", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687803731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Nominal categorical data in large datasets can be culprits for causing the dimensionality curse. &lt;/p&gt;\n\n&lt;p&gt;Just a single column of nominal categ. data like mobile phone models , once encoded (one hot or dummied) can increase the dimension 100-fold or even higher and even break the model &lt;/p&gt;\n\n&lt;p&gt;I came across many strategies but one simple approach seems very tempting... how abt just replace the outlier nominal data and nullify. &lt;/p&gt;\n\n&lt;p&gt;Seems lazy/naive, but is there no merit to replacing outlier data (nominal categ.) with null? is it better to remove the whole row instead ? Any guidance / expert opinion / or just your thoughts ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14joy58", "is_robot_indexable": true, "report_reasons": null, "author": "StarfleetCadetJLP", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14joy58/dim_reduction_in_nominal_categorical_data_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14joy58/dim_reduction_in_nominal_categorical_data_in_a/", "subreddit_subscribers": 932169, "created_utc": 1687803731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I haven't seen this get talked about much in the news, but [this article](https://dailydispatch.ai/training-on-generated-data-makes-models-forget-new-research-talks-degenerative-model-collapse/) talks about what can happen when AI gets trained by other AI. What the article doesn't specifically mention is the fact that because of all the news and big legal concerns around data privacy, *it's way better to* just make up your own fake \"simulated\" data than have to worry about all the concerns around human data.\n\nThe article's analogy about the kid running across the street is just the tip of the iceberg. Concerning IMO!", "author_fullname": "t2_3xg8extd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Businesses training their AI with synthetic data are going to cause trouble", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jjtrf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687792020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t seen this get talked about much in the news, but &lt;a href=\"https://dailydispatch.ai/training-on-generated-data-makes-models-forget-new-research-talks-degenerative-model-collapse/\"&gt;this article&lt;/a&gt; talks about what can happen when AI gets trained by other AI. What the article doesn&amp;#39;t specifically mention is the fact that because of all the news and big legal concerns around data privacy, &lt;em&gt;it&amp;#39;s way better to&lt;/em&gt; just make up your own fake &amp;quot;simulated&amp;quot; data than have to worry about all the concerns around human data.&lt;/p&gt;\n\n&lt;p&gt;The article&amp;#39;s analogy about the kid running across the street is just the tip of the iceberg. Concerning IMO!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NA7JpWuINDudJB3W4eyTkptYmJieWgKvJURmQsm6HrQ.jpg?auto=webp&amp;v=enabled&amp;s=ab3cfacbec2de043952b35728dd92caf927708cd", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/NA7JpWuINDudJB3W4eyTkptYmJieWgKvJURmQsm6HrQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f28a5c8a07d9e29276243ac7c983168917660f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/NA7JpWuINDudJB3W4eyTkptYmJieWgKvJURmQsm6HrQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a7fa99ec92a3c7de6df69ee225423711b7ed207", "width": 216, "height": 216}], "variants": {}, "id": "Sdh33D8rJdJdRyOElNMwOkJn5Qn9w3hKvE3nka8Un84"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jjtrf", "is_robot_indexable": true, "report_reasons": null, "author": "coltan3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jjtrf/businesses_training_their_ai_with_synthetic_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jjtrf/businesses_training_their_ai_with_synthetic_data/", "subreddit_subscribers": 932169, "created_utc": 1687792020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I would appreciate your thoughts on how to optimise campaign banner placement for an ecommerce app\n\nContext: I have been assigned to lead this project (for the first time ever!, so a little inexperienced and a little nervous) on how to find the right placement for campaign banners on our app. Things to optimise for are impressions, click through rate, order conversion and revenue per impression\n\nTypically banner placements are done by \"most attractive\" campaign mechanics i.e. highest discout, popular brand discount etc. as decided by the campaigns team\n\nIn my opinion because \"most attractive\" banners are always placed at the forefront, these banners will receive highest exposure and thus receive higher associated metrics as a result compared to other banners which will require user to actively scroll app in order to view. But I am wondering if these other banners despite not having the \"most attractive\" mechanics actually fare better and could be given a big boost if placed at the forefront. How would you approach this situation?\n\nI am not necessarily looking for an AB test solution, rather a model of sorts or even an elegantly simple solution that can determine this given that we could be running up to 60 different campaigns in a week\n\nYour thoughts are much appreciated \ud83d\ude4f", "author_fullname": "t2_cxcitwobx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to optimise campaign banner placement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14kb2a2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687865786.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687865200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would appreciate your thoughts on how to optimise campaign banner placement for an ecommerce app&lt;/p&gt;\n\n&lt;p&gt;Context: I have been assigned to lead this project (for the first time ever!, so a little inexperienced and a little nervous) on how to find the right placement for campaign banners on our app. Things to optimise for are impressions, click through rate, order conversion and revenue per impression&lt;/p&gt;\n\n&lt;p&gt;Typically banner placements are done by &amp;quot;most attractive&amp;quot; campaign mechanics i.e. highest discout, popular brand discount etc. as decided by the campaigns team&lt;/p&gt;\n\n&lt;p&gt;In my opinion because &amp;quot;most attractive&amp;quot; banners are always placed at the forefront, these banners will receive highest exposure and thus receive higher associated metrics as a result compared to other banners which will require user to actively scroll app in order to view. But I am wondering if these other banners despite not having the &amp;quot;most attractive&amp;quot; mechanics actually fare better and could be given a big boost if placed at the forefront. How would you approach this situation?&lt;/p&gt;\n\n&lt;p&gt;I am not necessarily looking for an AB test solution, rather a model of sorts or even an elegantly simple solution that can determine this given that we could be running up to 60 different campaigns in a week&lt;/p&gt;\n\n&lt;p&gt;Your thoughts are much appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14kb2a2", "is_robot_indexable": true, "report_reasons": null, "author": "shy_terrapin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14kb2a2/how_to_optimise_campaign_banner_placement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14kb2a2/how_to_optimise_campaign_banner_placement/", "subreddit_subscribers": 932169, "created_utc": 1687865200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A month ago, everyone was talking about DragGAN. There were many big words and expectations. And a few hours ago, its code was released on GitHub, and of course, I immediately started studying the topic and went to try out this innovative tool, which seemed promising.\n\nAs a result, I created:\n\n* **A Google Colab notebook with DragGAN**. I also cleaned it up a bit in case you want to try using it too. I'll leave the link below.\n* **Review and tutorial on YouTube**, with general information about GANs, specifically DragGAN, a couple of silly jokes, and my personal opinion after using it. Spoiler: It's not all that great. And one of my impressive results are shown at the bottom.\n\n[GitHub repository](https://github.com/XingangPan/DragGAN)\n\n[The YouTube tutorial](https://www.youtube.com/watch?v=K2p2i62yoG4)", "author_fullname": "t2_z5yukzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DragGAN code is finally released! (Interactive Point-based Manipulation on the Generative Image Manifold) AI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k6579", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687849079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A month ago, everyone was talking about DragGAN. There were many big words and expectations. And a few hours ago, its code was released on GitHub, and of course, I immediately started studying the topic and went to try out this innovative tool, which seemed promising.&lt;/p&gt;\n\n&lt;p&gt;As a result, I created:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;A Google Colab notebook with DragGAN&lt;/strong&gt;. I also cleaned it up a bit in case you want to try using it too. I&amp;#39;ll leave the link below.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Review and tutorial on YouTube&lt;/strong&gt;, with general information about GANs, specifically DragGAN, a couple of silly jokes, and my personal opinion after using it. Spoiler: It&amp;#39;s not all that great. And one of my impressive results are shown at the bottom.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/XingangPan/DragGAN\"&gt;GitHub repository&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=K2p2i62yoG4\"&gt;The YouTube tutorial&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?auto=webp&amp;v=enabled&amp;s=00278d35929341a64ebd3ac342e3e9efbb7a6bba", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf5927548d984e27ce3628f6dc8f00182a0ce5bc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8904c7cce4616b64a6d0d67e8d7aede8c9285528", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c1105209461640fe6c5c48bf6fc92617b8c5608", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e77ec46a78f25e6b3b09ddb5366863a2e8101dfc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d86f4c7abfa5331c29ad41034c4676ded988dad", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/EuHDzSzN7POaAX4I3-PO7TgxOJoPookITa2VoGiCTFM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07a71c54eb34e946a968b2860e3dc87fcd32ad6b", "width": 1080, "height": 540}], "variants": {}, "id": "4tNf35JEIy_nmM33Ba7NsIb_YRrZv842PShPaPFAd80"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k6579", "is_robot_indexable": true, "report_reasons": null, "author": "rocket__cat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k6579/draggan_code_is_finally_released_interactive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k6579/draggan_code_is_finally_released_interactive/", "subreddit_subscribers": 932169, "created_utc": 1687849079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am new to this field and working towards creating a pipeline that would tag and version fine-tuned models with different versions of a dataset.\n\nHowever, I am struggling to find literature on how to do this in anger.\n\nI can't find anything very concrete, I have seen some options but I am not too fond of any, to name a few:\n\n\\- Version controlling the trained model\n\n\\- Storing it in an external bucket, such as MiniO\n\n\\- Storing it in an image registry\n\nI can see trade-offs with each but seems like extra toiling is needed.\n\nWhere and how are people storing the trained models these days? \n\nThanks!", "author_fullname": "t2_j0nnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Versioning trained models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14jl3a5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687794967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to this field and working towards creating a pipeline that would tag and version fine-tuned models with different versions of a dataset.&lt;/p&gt;\n\n&lt;p&gt;However, I am struggling to find literature on how to do this in anger.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t find anything very concrete, I have seen some options but I am not too fond of any, to name a few:&lt;/p&gt;\n\n&lt;p&gt;- Version controlling the trained model&lt;/p&gt;\n\n&lt;p&gt;- Storing it in an external bucket, such as MiniO&lt;/p&gt;\n\n&lt;p&gt;- Storing it in an image registry&lt;/p&gt;\n\n&lt;p&gt;I can see trade-offs with each but seems like extra toiling is needed.&lt;/p&gt;\n\n&lt;p&gt;Where and how are people storing the trained models these days? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14jl3a5", "is_robot_indexable": true, "report_reasons": null, "author": "albertoimpl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14jl3a5/versioning_trained_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14jl3a5/versioning_trained_models/", "subreddit_subscribers": 932169, "created_utc": 1687794967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are staffing/reorganising. Assume 10 people total. Roles are DE DS and DevOps. How many should we have of each? \n\nDetails if relevant:\n\nProduct is saas platform based on analysis of public time series data. \n\nDE do ETL with Airflow from external sources. \nDS do modelling, including transforming knowledge from (some other) domain experts into models, and MLOps. \nDevOps make the web based platform.", "author_fullname": "t2_fgr9fj7o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many to hire/assign for each role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14kbpkn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687867037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are staffing/reorganising. Assume 10 people total. Roles are DE DS and DevOps. How many should we have of each? &lt;/p&gt;\n\n&lt;p&gt;Details if relevant:&lt;/p&gt;\n\n&lt;p&gt;Product is saas platform based on analysis of public time series data. &lt;/p&gt;\n\n&lt;p&gt;DE do ETL with Airflow from external sources. \nDS do modelling, including transforming knowledge from (some other) domain experts into models, and MLOps. \nDevOps make the web based platform.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14kbpkn", "is_robot_indexable": true, "report_reasons": null, "author": "HawkishLore", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14kbpkn/how_many_to_hireassign_for_each_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14kbpkn/how_many_to_hireassign_for_each_role/", "subreddit_subscribers": 932169, "created_utc": 1687867037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I published today a new blog post - [Unleashing the Power Predictive Modeling: Overcoming Challenges in Forecasting Annual Revenue](https://medium.com/lightricks-tech-blog/unleashing-the-power-predictive-modeling-overcoming-challenges-in-forecasting-annual-revenue-7928ebbbedce) and I thought it would be great to share it :)  \nPlease feel free to share your thoughts!   \n\n\nhttps://preview.redd.it/aianjuzssj8b1.png?width=2400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d00ec977e583f76d30d55e0740243c513b210cb", "author_fullname": "t2_qsy3ffat", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unleashing the Power Predictive Modeling: Overcoming Challenges in Forecasting Annual Revenue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "media_metadata": {"aianjuzssj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14150edfce11cd2f78e98f36af8f782fd577b127"}, {"y": 112, "x": 216, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ad36ed38955ddcc050aad27facd95673cbdcdfd"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9657276ea56871c0012afdd02a35ac005ab65425"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cf6fa8ccddc19431358003aed6a9bfed0971a77"}, {"y": 501, "x": 960, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baa265787a2bbd16a2de28527cedd02fdb12dc3e"}, {"y": 564, "x": 1080, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31fff7b02a5cf2e82bb467bc036832e84b108b3b"}], "s": {"y": 1254, "x": 2400, "u": "https://preview.redd.it/aianjuzssj8b1.png?width=2400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d00ec977e583f76d30d55e0740243c513b210cb"}, "id": "aianjuzssj8b1"}}, "name": "t3_14kbey4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/2P1sBAHm0YFWL4XTApiCwruvB-w4XIN1x0Oj0jyWJk0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1687866213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I published today a new blog post - &lt;a href=\"https://medium.com/lightricks-tech-blog/unleashing-the-power-predictive-modeling-overcoming-challenges-in-forecasting-annual-revenue-7928ebbbedce\"&gt;Unleashing the Power Predictive Modeling: Overcoming Challenges in Forecasting Annual Revenue&lt;/a&gt; and I thought it would be great to share it :)&lt;br/&gt;\nPlease feel free to share your thoughts!   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aianjuzssj8b1.png?width=2400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9d00ec977e583f76d30d55e0740243c513b210cb\"&gt;https://preview.redd.it/aianjuzssj8b1.png?width=2400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9d00ec977e583f76d30d55e0740243c513b210cb&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?auto=webp&amp;v=enabled&amp;s=1bb22b1979b556b6bc0045c18bc290312a5219f4", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71d07426afe2030744e05889d41abec61be53e41", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31fd04a61f38ca5f8511da8ed06e48a84e6e9354", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8ad323939a221d4ad0a9e57157791224c8f437b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c3e98734961fe4d1d186c5dc4f8d6876d54fd6d", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9779f2fc84e174528ac734e48a88482710cc164b", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/Aod7FNk4ESlflbsxpEKOSjD0QDBaldS6T-gGaIS79Xg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92f980bdb120d0228a1f9eed368798fc2c06a514", "width": 1080, "height": 564}], "variants": {}, "id": "E55V1niQzyeR0940z5DcwTBbOnhqR5mfh5fB0HGdcMM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14kbey4", "is_robot_indexable": true, "report_reasons": null, "author": "Lightricks_Tech", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14kbey4/unleashing_the_power_predictive_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14kbey4/unleashing_the_power_predictive_modeling/", "subreddit_subscribers": 932169, "created_utc": 1687866213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_83oqqrfa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Become a Data Analyst in USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14ka1eq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EjfTORE2oiYdpMJZOtROo3Oq_NsFvx_zFhhZ9LWQXT0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687862122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ivyproschool.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ivyproschool.com/blog/data-analytics-career-in-usa/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?auto=webp&amp;v=enabled&amp;s=f99b9d24e508b30a6afb4f4eb6368212dce48f97", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f5d2e64316c5ab1df7ab976ff9a37275fadf9d8", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc1d546cba1e98cecbaea90af41dff931e777d0c", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7edaf9adb7f8afd94060a1ad1fb151500dd2a0d", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=564506e4dada876fe0dc763299529deab2b78410", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22bd685bedb9602cda76ff85e93c76b6836627eb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Jl0ZX_n8cg_Nq-USfCxjO6mJwqf8FJRq-RsMv6mg6VE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77318a65f6ae271e333a65813f8131eb884cac48", "width": 1080, "height": 607}], "variants": {}, "id": "aRXpsULVfCVGSKFuz-1bWpx0JhleHIB1Dx1II9pCwSc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ka1eq", "is_robot_indexable": true, "report_reasons": null, "author": "Few_Spirit_7451", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ka1eq/how_to_become_a_data_analyst_in_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ivyproschool.com/blog/data-analytics-career-in-usa/", "subreddit_subscribers": 932169, "created_utc": 1687862122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I have a request for you, that of finding the common points in the images\n\n[1](https://preview.redd.it/yhn6r13egj8b1.png?width=1894&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1d7e94e11312a921992e110b1767a73349701ebe)\n\n[2](https://preview.redd.it/chzy0u7egj8b1.png?width=1900&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=840978ddb9ca453f6721115c4b5594ff5a5b742d)\n\n[3](https://preview.redd.it/thjh6s7egj8b1.png?width=1899&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0a1d1a609df74eadcbf73b7af7396cbd614bfcf5)\n\n[4](https://preview.redd.it/m29uvr7egj8b1.png?width=1901&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7a4c257373753ae91babcad21c11bb4628f60872)\n\n[5](https://preview.redd.it/40jots7egj8b1.png?width=1893&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=498269a09fb538d33f50a8282f09a4848173a651)", "author_fullname": "t2_ae7pu07l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digital data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 12, "top_awarded_type": null, "hide_score": false, "media_metadata": {"40jots7egj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 13, "x": 108, "u": "https://preview.redd.it/40jots7egj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=465cf2e1dae59774228cbbdeaba48d72e7b309a2"}, {"y": 27, "x": 216, "u": "https://preview.redd.it/40jots7egj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c4ab8619e59d340d205bb3882877d1ef449f0c9"}, {"y": 40, "x": 320, "u": "https://preview.redd.it/40jots7egj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a724904364e7c13d3bb2d47cacfbc6109b5b1a3"}, {"y": 80, "x": 640, "u": "https://preview.redd.it/40jots7egj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14925eaa4e5bc05b4cd9c379a206b936de1ed8b7"}, {"y": 121, "x": 960, "u": "https://preview.redd.it/40jots7egj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1dadbff74b1904ba261358eefc68845d695bfc23"}, {"y": 136, "x": 1080, "u": "https://preview.redd.it/40jots7egj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dae0daf8416b208b4fd9f952005f1ae1ffc3076"}], "s": {"y": 239, "x": 1893, "u": "https://preview.redd.it/40jots7egj8b1.png?width=1893&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=498269a09fb538d33f50a8282f09a4848173a651"}, "id": "40jots7egj8b1"}, "chzy0u7egj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 13, "x": 108, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95d7ac8070b8e5ff96fe531407b78aaa5f35269a"}, {"y": 26, "x": 216, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc9353c940cab90f9984719029c469ae0d421d7b"}, {"y": 39, "x": 320, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=307b0ec1bcb6fcbc6730223a4c6b4fa9661ef79f"}, {"y": 78, "x": 640, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e50e6da887103d9f86b7f7dcd6b55d136da6a614"}, {"y": 118, "x": 960, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3dbe365b5e7ab3cd43e1b736c1e87d8bf0d5235a"}, {"y": 133, "x": 1080, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a38ce213b8ce28d8bca72234968e05be545ecf74"}], "s": {"y": 234, "x": 1900, "u": "https://preview.redd.it/chzy0u7egj8b1.png?width=1900&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=840978ddb9ca453f6721115c4b5594ff5a5b742d"}, "id": "chzy0u7egj8b1"}, "thjh6s7egj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 17, "x": 108, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9468f95178c30d12246c71e155d0be02e6666219"}, {"y": 34, "x": 216, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baa62150212d55b840cf1acecb2c7ebfab18059b"}, {"y": 51, "x": 320, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ff5cbb083030f4ab55c3b436219cff0436396f9"}, {"y": 102, "x": 640, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f541bbcc9f2107753d2ec226c28bd9ef6c5bcfd"}, {"y": 154, "x": 960, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6157ad466412cfddeb3b8eba32819f688f6c3e43"}, {"y": 173, "x": 1080, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b681c9fb9340e8e14338bc9d9e04c10216869d9a"}], "s": {"y": 305, "x": 1899, "u": "https://preview.redd.it/thjh6s7egj8b1.png?width=1899&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0a1d1a609df74eadcbf73b7af7396cbd614bfcf5"}, "id": "thjh6s7egj8b1"}, "m29uvr7egj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 11, "x": 108, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1bdb9f6c5f10d054cd25ceeed737e26205536ef"}, {"y": 23, "x": 216, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63b5f4f33e606c0d399ef174501c2c01d2d31699"}, {"y": 34, "x": 320, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=744321df5001f52ad84e25cb0fc48f782b03e6b6"}, {"y": 69, "x": 640, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69715e9db9e33a43c79c54816802e15f12f91e5b"}, {"y": 103, "x": 960, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22fafad63728ced3dd6daed780d42625d8c9cee7"}, {"y": 116, "x": 1080, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=325f69a25f8ce53a38c48cf2b51e56f23efa3b03"}], "s": {"y": 205, "x": 1901, "u": "https://preview.redd.it/m29uvr7egj8b1.png?width=1901&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7a4c257373753ae91babcad21c11bb4628f60872"}, "id": "m29uvr7egj8b1"}, "yhn6r13egj8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 9, "x": 108, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba6d5bfcb21cee59ea7b7f12913c0ebace113316"}, {"y": 19, "x": 216, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f9518bfb7a6b61ae8960e401bed52c2abc1d85f"}, {"y": 28, "x": 320, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee1aa18c7bad1d71525a5d03374fca52ed47b516"}, {"y": 57, "x": 640, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9535fd23547aeb7e13471959c9fc715d3966f3de"}, {"y": 86, "x": 960, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=124cd5a20d10f6ff23773db0f51f6f821b8e2805"}, {"y": 97, "x": 1080, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8200c044cf7d90559454221a91b64169bf55e26"}], "s": {"y": 171, "x": 1894, "u": "https://preview.redd.it/yhn6r13egj8b1.png?width=1894&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1d7e94e11312a921992e110b1767a73349701ebe"}, "id": "yhn6r13egj8b1"}}, "name": "t3_14ka0sy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MlRL5c4HeNdyEqhZbBMnIH5GJJcejtFgHgYeVCq1TnQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687862068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have a request for you, that of finding the common points in the images&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yhn6r13egj8b1.png?width=1894&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1d7e94e11312a921992e110b1767a73349701ebe\"&gt;1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/chzy0u7egj8b1.png?width=1900&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=840978ddb9ca453f6721115c4b5594ff5a5b742d\"&gt;2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/thjh6s7egj8b1.png?width=1899&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0a1d1a609df74eadcbf73b7af7396cbd614bfcf5\"&gt;3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m29uvr7egj8b1.png?width=1901&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7a4c257373753ae91babcad21c11bb4628f60872\"&gt;4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/40jots7egj8b1.png?width=1893&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=498269a09fb538d33f50a8282f09a4848173a651\"&gt;5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ka0sy", "is_robot_indexable": true, "report_reasons": null, "author": "Andrew-Mendez29", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ka0sy/digital_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ka0sy/digital_data/", "subreddit_subscribers": 932169, "created_utc": 1687862068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I have an opinion to ask. I majored in statistics with an emphasis in data science. I\u2019ve been working as a data scientist for 5 years. I mostly worked in product data science. I love what I do, but I can tell I\u2019m not as good in statistics and SQL as I\u2019m good with explaining data to stakeholders and turning data into a story. I like data science but I want to play to my strengths. What jobs should I be on the watch for? Should I change careers?", "author_fullname": "t2_4srla7dh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice career change", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k7dmd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687853198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have an opinion to ask. I majored in statistics with an emphasis in data science. I\u2019ve been working as a data scientist for 5 years. I mostly worked in product data science. I love what I do, but I can tell I\u2019m not as good in statistics and SQL as I\u2019m good with explaining data to stakeholders and turning data into a story. I like data science but I want to play to my strengths. What jobs should I be on the watch for? Should I change careers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k7dmd", "is_robot_indexable": true, "report_reasons": null, "author": "ggllad2020", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k7dmd/advice_career_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k7dmd/advice_career_change/", "subreddit_subscribers": 932169, "created_utc": 1687853198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am currently getting my Master\u2019s in Data analytics. I have no prior experience in data analytics my bachelors was in Industrial Technology(I have a process technology AAS). So what I want to know is what should I be doing to give me a better chance at securing a job after graduation? I am currently 50% through the program already. Thank you in advance!", "author_fullname": "t2_dg6xzlstc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for MDA student!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k5sph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687847932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am currently getting my Master\u2019s in Data analytics. I have no prior experience in data analytics my bachelors was in Industrial Technology(I have a process technology AAS). So what I want to know is what should I be doing to give me a better chance at securing a job after graduation? I am currently 50% through the program already. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k5sph", "is_robot_indexable": true, "report_reasons": null, "author": "Soft-Cardiologist501", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k5sph/advice_for_mda_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k5sph/advice_for_mda_student/", "subreddit_subscribers": 932169, "created_utc": 1687847932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a complete beginner in the field of data science. I came across this topic today and there are some questions and doubts that are burning me down. \n\nThe concept of mutual information helps us have an idea of the shared info between two variables of a dataset, preferably between the target variable and the feature we are working on.   \nIf the feature is a better fit for the model if it is squared, will the MI value be able to reflect that there exists a better relationship between the target variable and the feature than its linear counterpart (derived from correlation) ? It may not be able to suggest that it is the \"Squared\" relationship, but can it just suggest that there exists some transformation in the feature that can make it more suitable for predicting the target variable?  \n\n\nYour help and answers are greatly appreciated.   \nThank you  \nBruce Wayne (from Krypton)", "author_fullname": "t2_e9nen73fv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mutual Information for feature development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k5m3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687847337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a complete beginner in the field of data science. I came across this topic today and there are some questions and doubts that are burning me down. &lt;/p&gt;\n\n&lt;p&gt;The concept of mutual information helps us have an idea of the shared info between two variables of a dataset, preferably between the target variable and the feature we are working on.&lt;br/&gt;\nIf the feature is a better fit for the model if it is squared, will the MI value be able to reflect that there exists a better relationship between the target variable and the feature than its linear counterpart (derived from correlation) ? It may not be able to suggest that it is the &amp;quot;Squared&amp;quot; relationship, but can it just suggest that there exists some transformation in the feature that can make it more suitable for predicting the target variable?  &lt;/p&gt;\n\n&lt;p&gt;Your help and answers are greatly appreciated.&lt;br/&gt;\nThank you&lt;br/&gt;\nBruce Wayne (from Krypton)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k5m3h", "is_robot_indexable": true, "report_reasons": null, "author": "BruceWayneKryptonite", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k5m3h/mutual_information_for_feature_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k5m3h/mutual_information_for_feature_development/", "subreddit_subscribers": 932169, "created_utc": 1687847337.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there.\n\nI am working on a project which involves performing 5 checks for each data point that i have. Each of them returns a score of 0, 0.5 and 1. Finally each of them gets a total marks out of 5. Based on their marks i want to separate into kind of 3 categories (think bad, ok and good).\n\nI want to know if:\n1. There is any robust scheme by which i can decide these cutoffs?\n2. What if any one of these tests return the same score for an overwhelming majority of the data points in my dataset (but this is not true generally), can i add weightages to the scores returned by the 5 tests based on this?\n3. For one test, a score of 0 is more important to me than a score of 1. Is there any way to account for this?\n4. Is the original scoring scheme of 0, 0.5, 1 ok? Are there better scoring schemes for this context?\n\nI want to know if there is any branch of statistics which deals with such scoring and cutoffs problems in case i need to read up on it. \n\nIf this question is not appropriate for this sub, please feel free to tell me where should i post it. Thanks!", "author_fullname": "t2_5zb1uoj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any robust method to create a scoring scheme and cutoffs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14k5622", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687845863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there.&lt;/p&gt;\n\n&lt;p&gt;I am working on a project which involves performing 5 checks for each data point that i have. Each of them returns a score of 0, 0.5 and 1. Finally each of them gets a total marks out of 5. Based on their marks i want to separate into kind of 3 categories (think bad, ok and good).&lt;/p&gt;\n\n&lt;p&gt;I want to know if:\n1. There is any robust scheme by which i can decide these cutoffs?\n2. What if any one of these tests return the same score for an overwhelming majority of the data points in my dataset (but this is not true generally), can i add weightages to the scores returned by the 5 tests based on this?\n3. For one test, a score of 0 is more important to me than a score of 1. Is there any way to account for this?\n4. Is the original scoring scheme of 0, 0.5, 1 ok? Are there better scoring schemes for this context?&lt;/p&gt;\n\n&lt;p&gt;I want to know if there is any branch of statistics which deals with such scoring and cutoffs problems in case i need to read up on it. &lt;/p&gt;\n\n&lt;p&gt;If this question is not appropriate for this sub, please feel free to tell me where should i post it. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k5622", "is_robot_indexable": true, "report_reasons": null, "author": "LaDialga69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k5622/any_robust_method_to_create_a_scoring_scheme_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14k5622/any_robust_method_to_create_a_scoring_scheme_and/", "subreddit_subscribers": 932169, "created_utc": 1687845863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How to Choose the Right Chart Type\n\n\nInfographic\nData Science\nBusiness Intelligence\nData Visualization", "author_fullname": "t2_58q0vqi0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are You Choosing the Right Chart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_14k4puc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/q2x_n4_wLWICq1pw50F8n0j1grADETOKek-mqW6bCdA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687844452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to Choose the Right Chart Type&lt;/p&gt;\n\n&lt;p&gt;Infographic\nData Science\nBusiness Intelligence\nData Visualization&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dwuo8nd40i8b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?auto=webp&amp;v=enabled&amp;s=fd8b5d88ccc8f070c44cb94ef4fb9787ee3b642c", "width": 1200, "height": 910}, "resolutions": [{"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9f77e2dd6178046e4d3af46725f8fb12a4debdb", "width": 108, "height": 81}, {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5edbeef519b1279126050058106ab0ea80e4719b", "width": 216, "height": 163}, {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51bdd04faf24eb07f08290338a2e13054c86b8b5", "width": 320, "height": 242}, {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f11b368ccc7a39f3d92a93aa1d896b2ccab9df4a", "width": 640, "height": 485}, {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=749664d9df096f80cd419b53f69a88f5c1fcf7eb", "width": 960, "height": 728}, {"url": "https://preview.redd.it/dwuo8nd40i8b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4daf432e49b6714f407a1b7351462427b79fa21b", "width": 1080, "height": 819}], "variants": {}, "id": "ReqW7vp6XAeDFdzqDoeF5I1sO_pAegVVVpaVduI3__o"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14k4puc", "is_robot_indexable": true, "report_reasons": null, "author": "LorenFiorini", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14k4puc/are_you_choosing_the_right_chart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dwuo8nd40i8b1.png", "subreddit_subscribers": 932169, "created_utc": 1687844452.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}