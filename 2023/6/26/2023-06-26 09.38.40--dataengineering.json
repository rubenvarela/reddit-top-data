{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to practice my skills in Airflow, AWS cloud provider, and Snowflake by working on a project, and I came across this project pipeline. Do you think this is a good project to enhance my skills and include on my resume? I am aiming to find an end-of-study internship at a reputable company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14irwgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YmWowoqYdS3jnkiojIy9wdpLLOJk_Ki4JfNbDJcF6_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687714152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jl512r4m878b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jl512r4m878b1.jpg?auto=webp&amp;v=enabled&amp;s=c038770b5dc44288de35fd59ea2c59dce888df7b", "width": 1280, "height": 720}, "resolutions": [{"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03e7cd985c4dc1333c69de98dca97ee38981a7e4", "width": 108, "height": 60}, {"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ee5b63aafd85d3b4b5fe127280509757fab1864", "width": 216, "height": 121}, {"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64ac09d91854647b7da1fed9222c6d7376f36cfe", "width": 320, "height": 180}, {"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d87c349982dd8a09c325d83716211edfa261428", "width": 640, "height": 360}, {"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e634cbf954a7103a48f4bd6c2de5df8085936d48", "width": 960, "height": 540}, {"url": "https://preview.redd.it/jl512r4m878b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86b62a744bc8418f11a9e97dfd1e999e85c6ee43", "width": 1080, "height": 607}], "variants": {}, "id": "o1cgxm07Zux9KHauWsal3R_fIXYrAuWDtG0lsQ8TNE0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14irwgo", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14irwgo/i_want_to_practice_my_skills_in_airflow_aws_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jl512r4m878b1.jpg", "subreddit_subscribers": 112337, "created_utc": 1687714152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone! I am excited to share with you a tool I've been developing.\n\n[https://modelfirst.codegeniux.com/](https://modelfirst.codegeniux.com/)\n\nI'd love to hear your thoughts on the code generator and answer any \nquestions you may have. Is a tool that allows you design the Data Model\nvisually and generate the code for different technologies.\n\n* Screenshots\n* SQL \n  * 29 dialects and 76 code generators\n* NoSQL\n  * MongoDb V4.x\n* CSharp\n  * EF Core v6\n* Java\n  * Hibernate v5\n  * JPA 2.1\n* JavaScript\n  * Sequelize V6\n  * Knex\n  * Bookshelf\n  * Mongoose V5x\n* JSON\n  * Draft 07\n  * Ajv schema\n* PHP\n  * Doctrine v2.8\n  * Laravel v8\n* Python\n  * Django v3.2\n  * SQLAlchemy v1.4\n  * Pony\n* Ruby\n  * Rails 6\n* TypeScript\n  * MikroOrm v4.5\n  * TypeORM MySQL\n  * TypeORM Postgres\n  * TypeORM Sqlite\n  * TypeORM SqlServer\n  * TypeORM CockroachDB\n  * TypeORM Oracle\n* Prisma schema\n  * Sqlite\n  * PostgreSQL\n  * MySQL\n  * SQL Server\n* Visual Basic Script\n  * MS Access MDB\n  * MS Access ACCDB\n* GraphQl\n  * GraphQl Schema\n* Swagger\n  * Schema V2\n  * Schema V3\n* JHipster\n  * Domain Language\n* Graphics\n  * GraphViz\n\nI'm still working in some technologies to support Audit and Soft-Deletes.\nIt's only available for Desktop now, Sorry\n\nThanks for your time.\nGreetings", "author_fullname": "t2_51cvit0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Draw Data Model Schema and generate code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14imbg7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687703381.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687699704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I am excited to share with you a tool I&amp;#39;ve been developing.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://modelfirst.codegeniux.com/\"&gt;https://modelfirst.codegeniux.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts on the code generator and answer any \nquestions you may have. Is a tool that allows you design the Data Model\nvisually and generate the code for different technologies.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Screenshots&lt;/li&gt;\n&lt;li&gt;SQL \n\n&lt;ul&gt;\n&lt;li&gt;29 dialects and 76 code generators&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;NoSQL\n\n&lt;ul&gt;\n&lt;li&gt;MongoDb V4.x&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;CSharp\n\n&lt;ul&gt;\n&lt;li&gt;EF Core v6&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Java\n\n&lt;ul&gt;\n&lt;li&gt;Hibernate v5&lt;/li&gt;\n&lt;li&gt;JPA 2.1&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;JavaScript\n\n&lt;ul&gt;\n&lt;li&gt;Sequelize V6&lt;/li&gt;\n&lt;li&gt;Knex&lt;/li&gt;\n&lt;li&gt;Bookshelf&lt;/li&gt;\n&lt;li&gt;Mongoose V5x&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;JSON\n\n&lt;ul&gt;\n&lt;li&gt;Draft 07&lt;/li&gt;\n&lt;li&gt;Ajv schema&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;PHP\n\n&lt;ul&gt;\n&lt;li&gt;Doctrine v2.8&lt;/li&gt;\n&lt;li&gt;Laravel v8&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Python\n\n&lt;ul&gt;\n&lt;li&gt;Django v3.2&lt;/li&gt;\n&lt;li&gt;SQLAlchemy v1.4&lt;/li&gt;\n&lt;li&gt;Pony&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Ruby\n\n&lt;ul&gt;\n&lt;li&gt;Rails 6&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;TypeScript\n\n&lt;ul&gt;\n&lt;li&gt;MikroOrm v4.5&lt;/li&gt;\n&lt;li&gt;TypeORM MySQL&lt;/li&gt;\n&lt;li&gt;TypeORM Postgres&lt;/li&gt;\n&lt;li&gt;TypeORM Sqlite&lt;/li&gt;\n&lt;li&gt;TypeORM SqlServer&lt;/li&gt;\n&lt;li&gt;TypeORM CockroachDB&lt;/li&gt;\n&lt;li&gt;TypeORM Oracle&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Prisma schema\n\n&lt;ul&gt;\n&lt;li&gt;Sqlite&lt;/li&gt;\n&lt;li&gt;PostgreSQL&lt;/li&gt;\n&lt;li&gt;MySQL&lt;/li&gt;\n&lt;li&gt;SQL Server&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Visual Basic Script\n\n&lt;ul&gt;\n&lt;li&gt;MS Access MDB&lt;/li&gt;\n&lt;li&gt;MS Access ACCDB&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;GraphQl\n\n&lt;ul&gt;\n&lt;li&gt;GraphQl Schema&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Swagger\n\n&lt;ul&gt;\n&lt;li&gt;Schema V2&lt;/li&gt;\n&lt;li&gt;Schema V3&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;JHipster\n\n&lt;ul&gt;\n&lt;li&gt;Domain Language&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Graphics\n\n&lt;ul&gt;\n&lt;li&gt;GraphViz&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m still working in some technologies to support Audit and Soft-Deletes.\nIt&amp;#39;s only available for Desktop now, Sorry&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.\nGreetings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14imbg7", "is_robot_indexable": true, "report_reasons": null, "author": "rnapoles", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14imbg7/draw_data_model_schema_and_generate_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14imbg7/draw_data_model_schema_and_generate_code/", "subreddit_subscribers": 112337, "created_utc": 1687699704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone! I'm currently working as a full-time data analyst. To ensure I stay motivated and make consistent progress after work hours, I'm looking for a like-minded individual who is also interested in the data analyst field to be my accountability buddy.\n\nA little about me: After work, I work on Excel, SQL (Danny's 8 week challenge), and Power BI case studies (we could do these together) to enhance my skillset. We could give each other tips on how to do things more efficiently. My goal is to transition into a data engineer role in the future.\n\nWhat I'm looking for: I'm searching for an accountability buddy who is also committed to upskilling as a data analyst. Since my availability primarily lies in the BST (British Summer Time) timezone, it would be great to find someone who shares a similar timeframe. Ideally, we can schedule regular check-ins, throughout the day (as I work from home) whether it's on a daily or every other day basis, to discuss our progress, challenges we've encountered, and set goals for the upcoming week.\n\nIf you're interested in embarking on this upskilling journey together and you're in a similar timezone (BST), please don't hesitate to comment or DM me.\n\nLet's motivate and support each other as we work towards achieving our career goals.", "author_fullname": "t2_5j6z9zgpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking an Accountability Buddy for Upskilling as a Data Analyst (BST Timezone) \u2014&gt; Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14illx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687697711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I&amp;#39;m currently working as a full-time data analyst. To ensure I stay motivated and make consistent progress after work hours, I&amp;#39;m looking for a like-minded individual who is also interested in the data analyst field to be my accountability buddy.&lt;/p&gt;\n\n&lt;p&gt;A little about me: After work, I work on Excel, SQL (Danny&amp;#39;s 8 week challenge), and Power BI case studies (we could do these together) to enhance my skillset. We could give each other tips on how to do things more efficiently. My goal is to transition into a data engineer role in the future.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for: I&amp;#39;m searching for an accountability buddy who is also committed to upskilling as a data analyst. Since my availability primarily lies in the BST (British Summer Time) timezone, it would be great to find someone who shares a similar timeframe. Ideally, we can schedule regular check-ins, throughout the day (as I work from home) whether it&amp;#39;s on a daily or every other day basis, to discuss our progress, challenges we&amp;#39;ve encountered, and set goals for the upcoming week.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in embarking on this upskilling journey together and you&amp;#39;re in a similar timezone (BST), please don&amp;#39;t hesitate to comment or DM me.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s motivate and support each other as we work towards achieving our career goals.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14illx1", "is_robot_indexable": true, "report_reasons": null, "author": "Recent_Pause0", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14illx1/seeking_an_accountability_buddy_for_upskilling_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14illx1/seeking_an_accountability_buddy_for_upskilling_as/", "subreddit_subscribers": 112337, "created_utc": 1687697711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to run Apache Airflow in Docker. I managed to run it without any problems, but I ended up noticing that, whenever I run `docker compose up airflow-init`, 2 volumes are created:\n\n* 1 anonymous volume\n* 1 named volume ( postgres-db-volume)\n\nI was only expecting the named volume. \n\nDoes anyone know why this anonymous volume is created?\n\n&amp;#x200B;", "author_fullname": "t2_c8f4gnokr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Run Apache Airflow through Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14j0f6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687734687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to run Apache Airflow in Docker. I managed to run it without any problems, but I ended up noticing that, whenever I run &lt;code&gt;docker compose up airflow-init&lt;/code&gt;, 2 volumes are created:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1 anonymous volume&lt;/li&gt;\n&lt;li&gt;1 named volume ( postgres-db-volume)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I was only expecting the named volume. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know why this anonymous volume is created?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14j0f6e", "is_robot_indexable": true, "report_reasons": null, "author": "NoobAllTheWay", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14j0f6e/run_apache_airflow_through_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14j0f6e/run_apache_airflow_through_docker/", "subreddit_subscribers": 112337, "created_utc": 1687734687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm starting to play with Dagster, but I find the learning curve pretty steep (as compared to what I see in Prefect for example) and the tutorial a bit confusing. For instance, it doesn't mention Ops at all while it feels like it's a basic building bloc.\n\nAm I missing something ? Could you recommend any good tutorial on Dagster please ? ", "author_fullname": "t2_k7juv3bh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14j1lh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687737797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m starting to play with Dagster, but I find the learning curve pretty steep (as compared to what I see in Prefect for example) and the tutorial a bit confusing. For instance, it doesn&amp;#39;t mention Ops at all while it feels like it&amp;#39;s a basic building bloc.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something ? Could you recommend any good tutorial on Dagster please ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14j1lh5", "is_robot_indexable": true, "report_reasons": null, "author": "TheAlchemist2023", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14j1lh5/dagster_tutorials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14j1lh5/dagster_tutorials/", "subreddit_subscribers": 112337, "created_utc": 1687737797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have a basic understanding of a star schema and how to use it with two or more fact tables in Power BI. A star schema with a single fact table has many dimension tables that relate in a 1 to many way with the fact table. If you have two or more fact tables, you share the common dimension tables so that when you filter your one dimension table, it filters both (or all) of the fact tables. My question is what do you do when you have nested fact tables? Do you denormalize them so that you still just have one fact table or do you leave them as separate tables? For example, if you have a sales table with dimensions of customer and products, but you also have a historical status table that shows how a sale moves through the process from customer placing order, order processed by warehouse, order shipped, etc. Should I denormalize the historical status table and the sales table  so that I have a true star schema or should I leave them separate?\n\nI'm looking to build a project in Azure where I write a script in Python to generate fake data to post somewhere (say my github page), then make a pipeline in ADF to pull the data from there, do some simple transformations, then load the data into one of the Azure storage services. All of this would run on a schedule, probably once a day or once a week. So part of my question is also, is the answer different between modeling in Azure and in Power BI? I imagine the answer would be to keep things as normalized as possible in Azure to minimize storage costs (in a real world example, not really worried about costs with the amount of data my project would generate). \n\nMy last question is, does my project sound like a good one for an early career data analyst looking to become an Azure (or AWS) data engineer?\n\nEDIT: I should add, my  project would have at least two sub fact tables from the sales table. Idk if that changes anything.", "author_fullname": "t2_6ii8z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI/Azure Data Modeling - Question on Star Schema/Noramlized schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14iwqzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687725817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a basic understanding of a star schema and how to use it with two or more fact tables in Power BI. A star schema with a single fact table has many dimension tables that relate in a 1 to many way with the fact table. If you have two or more fact tables, you share the common dimension tables so that when you filter your one dimension table, it filters both (or all) of the fact tables. My question is what do you do when you have nested fact tables? Do you denormalize them so that you still just have one fact table or do you leave them as separate tables? For example, if you have a sales table with dimensions of customer and products, but you also have a historical status table that shows how a sale moves through the process from customer placing order, order processed by warehouse, order shipped, etc. Should I denormalize the historical status table and the sales table  so that I have a true star schema or should I leave them separate?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to build a project in Azure where I write a script in Python to generate fake data to post somewhere (say my github page), then make a pipeline in ADF to pull the data from there, do some simple transformations, then load the data into one of the Azure storage services. All of this would run on a schedule, probably once a day or once a week. So part of my question is also, is the answer different between modeling in Azure and in Power BI? I imagine the answer would be to keep things as normalized as possible in Azure to minimize storage costs (in a real world example, not really worried about costs with the amount of data my project would generate). &lt;/p&gt;\n\n&lt;p&gt;My last question is, does my project sound like a good one for an early career data analyst looking to become an Azure (or AWS) data engineer?&lt;/p&gt;\n\n&lt;p&gt;EDIT: I should add, my  project would have at least two sub fact tables from the sales table. Idk if that changes anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14iwqzm", "is_robot_indexable": true, "report_reasons": null, "author": "sluggles", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14iwqzm/power_biazure_data_modeling_question_on_star/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14iwqzm/power_biazure_data_modeling_question_on_star/", "subreddit_subscribers": 112337, "created_utc": 1687725817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im looking for some help choosing between 2 jobs. As some background I have worked as Data Engineer with Azure for some 2 years now but recently learned Python as well the basics of DE tools (Docker, Airflow, CI/CD) but dont use any of them at my current small company and have been keen to use them as I feel these are future proof and industry standard in the Software and Data Engineering space.\n\nI accepted a Job at Company A after losing out at Company B to a more experienced candidate, but Company B have come back and offered me the same position as another position just opened up a month later. Im conflicted between the 2. Company A Start date is July and Company B is September\n\nCompany A:\n\n* \u00a355,000 Base Salary + \u00a35,500 Car Allowance (basically just extra cash so the salary can be sidered \u00a361,000) + 17.5% bonus\n* Azure Databricks\n* Azure Data Factory\n* Azure Devops / Git (No devops pipelines only source control git type stuff)\n* Azure Cloud\n* Some exposure to Terraform\n* Python\n* SQL\n* Fully Remote\n\n\nVery well known UK based and Global Household name. Very big company. Started their \"modern data journey\" about 18 months ago and have made big leaps in that time but still in their infancy with regards to data. Lots of projects in the pipeline and chances to learn. Large team. Big data and Lots of different areas of data exposure\n\n\nCompany B:\n\n* \u00a350,000 + \u00a31,300 bonus \n* GCP Dataflow  \n* GCP Pub/Sub\n* GCP BigQuery\n* Kafka\n* Docker\n* Terraform\n* Airflow\n* Github Actions\n* Python\n* Hybrid\n\nAnother well known UK Based company. Not as big as Company A but still pretty big. Mature in their data journey. Exposure to All of the tech stack above, extensive usage of engineering stack such as Docker, terraform etc. Hybrid working in office twice a week but the commute is &lt; 30 mins away. Projects would be things like streaming data pipelines, large amounts of Data, big data pipelines. Big focus on best practices and doing things right. Experienced Team.\n\n\nIm conflicted as the pay is great at Company A and would really help me out but I feel as though the tech stack at company B would be alot more beneficial in the long run. However I know Databricks can be a beast in itself and give a good future. Company B I feel would also put to rest the feeling of needing to study and keep up with tech in my own personal time as I would be doing it for work.\n\nAny and all advice would be appreciated.", "author_fullname": "t2_12iasj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conflicted between 2 jobs (UK)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14iqmqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687712713.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687710928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im looking for some help choosing between 2 jobs. As some background I have worked as Data Engineer with Azure for some 2 years now but recently learned Python as well the basics of DE tools (Docker, Airflow, CI/CD) but dont use any of them at my current small company and have been keen to use them as I feel these are future proof and industry standard in the Software and Data Engineering space.&lt;/p&gt;\n\n&lt;p&gt;I accepted a Job at Company A after losing out at Company B to a more experienced candidate, but Company B have come back and offered me the same position as another position just opened up a month later. Im conflicted between the 2. Company A Start date is July and Company B is September&lt;/p&gt;\n\n&lt;p&gt;Company A:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u00a355,000 Base Salary + \u00a35,500 Car Allowance (basically just extra cash so the salary can be sidered \u00a361,000) + 17.5% bonus&lt;/li&gt;\n&lt;li&gt;Azure Databricks&lt;/li&gt;\n&lt;li&gt;Azure Data Factory&lt;/li&gt;\n&lt;li&gt;Azure Devops / Git (No devops pipelines only source control git type stuff)&lt;/li&gt;\n&lt;li&gt;Azure Cloud&lt;/li&gt;\n&lt;li&gt;Some exposure to Terraform&lt;/li&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;SQL&lt;/li&gt;\n&lt;li&gt;Fully Remote&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Very well known UK based and Global Household name. Very big company. Started their &amp;quot;modern data journey&amp;quot; about 18 months ago and have made big leaps in that time but still in their infancy with regards to data. Lots of projects in the pipeline and chances to learn. Large team. Big data and Lots of different areas of data exposure&lt;/p&gt;\n\n&lt;p&gt;Company B:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;\u00a350,000 + \u00a31,300 bonus &lt;/li&gt;\n&lt;li&gt;GCP Dataflow&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;GCP Pub/Sub&lt;/li&gt;\n&lt;li&gt;GCP BigQuery&lt;/li&gt;\n&lt;li&gt;Kafka&lt;/li&gt;\n&lt;li&gt;Docker&lt;/li&gt;\n&lt;li&gt;Terraform&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;Github Actions&lt;/li&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;Hybrid&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Another well known UK Based company. Not as big as Company A but still pretty big. Mature in their data journey. Exposure to All of the tech stack above, extensive usage of engineering stack such as Docker, terraform etc. Hybrid working in office twice a week but the commute is &amp;lt; 30 mins away. Projects would be things like streaming data pipelines, large amounts of Data, big data pipelines. Big focus on best practices and doing things right. Experienced Team.&lt;/p&gt;\n\n&lt;p&gt;Im conflicted as the pay is great at Company A and would really help me out but I feel as though the tech stack at company B would be alot more beneficial in the long run. However I know Databricks can be a beast in itself and give a good future. Company B I feel would also put to rest the feeling of needing to study and keep up with tech in my own personal time as I would be doing it for work.&lt;/p&gt;\n\n&lt;p&gt;Any and all advice would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14iqmqr", "is_robot_indexable": true, "report_reasons": null, "author": "KingofBoo", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14iqmqr/conflicted_between_2_jobs_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14iqmqr/conflicted_between_2_jobs_uk/", "subreddit_subscribers": 112337, "created_utc": 1687710928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_db74x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meerschaum in 100 Seconds (\u00e0 la Fireship)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14iwmnp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": "transparent", "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VFFWe7B33Io?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meerschaum in 100 Seconds\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Meerschaum in 100 Seconds", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VFFWe7B33Io?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meerschaum in 100 Seconds\"&gt;&lt;/iframe&gt;", "author_name": "Bennett Meares", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/VFFWe7B33Io/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@bmeares"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VFFWe7B33Io?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meerschaum in 100 Seconds\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14iwmnp", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/18Rg4QHdPTFqwtFEvbBBBI5WR8EAMBgehgWvFtcz_2E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687725524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/VFFWe7B33Io", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VxFeOwFZwOXZmk37Ls_euc3tEuOVfzGMOfZK-avWYV4.jpg?auto=webp&amp;v=enabled&amp;s=ec4b09b22f2f6df7228cbbfae1bea3671c70bd08", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VxFeOwFZwOXZmk37Ls_euc3tEuOVfzGMOfZK-avWYV4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a72ae213aaddbea9fbfa305db1b384c527a32ff", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VxFeOwFZwOXZmk37Ls_euc3tEuOVfzGMOfZK-avWYV4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93b549819ac990007d0771d6738910806e4a6127", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VxFeOwFZwOXZmk37Ls_euc3tEuOVfzGMOfZK-avWYV4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bc8b9f05c8f3db6193aad2c0a96dbf898636602", "width": 320, "height": 240}], "variants": {}, "id": "TIXmPE2wlCkX3n0lGfzN-FxzLlWTO-meSHH822Jz8cM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14iwmnp", "is_robot_indexable": true, "report_reasons": null, "author": "Obliterative_hippo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14iwmnp/meerschaum_in_100_seconds_\u00e0_la_fireship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/VFFWe7B33Io", "subreddit_subscribers": 112337, "created_utc": 1687725524.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Meerschaum in 100 Seconds", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/VFFWe7B33Io?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meerschaum in 100 Seconds\"&gt;&lt;/iframe&gt;", "author_name": "Bennett Meares", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/VFFWe7B33Io/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@bmeares"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHello everyone,\n\nI would like to seek advice from the experts in this community. Currently, I am working as an AWS lead data engineer with around 11 years of experience and a moderate level of expertise. I am considering transitioning my career to become a data architect. Could you please guide me on the key areas I should focus on and the skills I need to enhance in order to excel in this role? Your valuable insights would be greatly appreciated.", "author_fullname": "t2_r0efk0gv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pathway to AWS Data Architect.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14jbuv7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687769613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I would like to seek advice from the experts in this community. Currently, I am working as an AWS lead data engineer with around 11 years of experience and a moderate level of expertise. I am considering transitioning my career to become a data architect. Could you please guide me on the key areas I should focus on and the skills I need to enhance in order to excel in this role? Your valuable insights would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14jbuv7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Doughnut_8389", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jbuv7/pathway_to_aws_data_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jbuv7/pathway_to_aws_data_architect/", "subreddit_subscribers": 112337, "created_utc": 1687769613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently an analytics engineer (or something like a DAE) in a startup, with 3+ years of experience. I work with Product Growth and Marketing data and do like a lot of those topics, and have been thinking about focusing my career is this area so i can give more insightful inputs along the data modeling process. But, thinking in future job opportunities, is it worth to specialize myself in a single business field? Or would be better to be a more generic professional?", "author_fullname": "t2_bz26jbsjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth it to be an AE (DAE) specialized in a business area?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14j5ode", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687749416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently an analytics engineer (or something like a DAE) in a startup, with 3+ years of experience. I work with Product Growth and Marketing data and do like a lot of those topics, and have been thinking about focusing my career is this area so i can give more insightful inputs along the data modeling process. But, thinking in future job opportunities, is it worth to specialize myself in a single business field? Or would be better to be a more generic professional?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14j5ode", "is_robot_indexable": true, "report_reasons": null, "author": "Tough_Passion4667", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14j5ode/is_it_worth_it_to_be_an_ae_dae_specialized_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14j5ode/is_it_worth_it_to_be_an_ae_dae_specialized_in_a/", "subreddit_subscribers": 112337, "created_utc": 1687749416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Also called sketches - they\u2019re a must in every data engineers toolbox. Widely used across the industry, they offer incredible efficiency gains in less disk/memory used as well as CPU. The only cost is that the result is not 100% accurate.\n\nLinkedIn, Datadog and Reddit have all written interesting blog pieces about how they use such sketch algorithms. The savings were up to 88% disk in LinkedIn\u2019s case and in Reddit - their HyperLogLog solution used just 0.15% of the memory of the naive set solution.\n\nI recently learned about them and wrote a good summary here: https://twitter.com/bdkozlovski/status/1672622173369008128?s=46", "author_fullname": "t2_d2c8s0pb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Heard of Streaming Sublinear Stochastic Algorithms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14ilkoj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z-pBQGy4Fkmb-xbVnzKmMVphJtpLiD0Q_uun576Tb-k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687697611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also called sketches - they\u2019re a must in every data engineers toolbox. Widely used across the industry, they offer incredible efficiency gains in less disk/memory used as well as CPU. The only cost is that the result is not 100% accurate.&lt;/p&gt;\n\n&lt;p&gt;LinkedIn, Datadog and Reddit have all written interesting blog pieces about how they use such sketch algorithms. The savings were up to 88% disk in LinkedIn\u2019s case and in Reddit - their HyperLogLog solution used just 0.15% of the memory of the naive set solution.&lt;/p&gt;\n\n&lt;p&gt;I recently learned about them and wrote a good summary here: &lt;a href=\"https://twitter.com/bdkozlovski/status/1672622173369008128?s=46\"&gt;https://twitter.com/bdkozlovski/status/1672622173369008128?s=46&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/o9kb2xfhv58b1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?auto=webp&amp;v=enabled&amp;s=afebc7d367697c9a279ab9d866dc522f32cedfed", "width": 1600, "height": 900}, "resolutions": [{"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f87df5f8870dffeba6024a84749339b359f119e8", "width": 108, "height": 60}, {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5bb604d82a15a40a6f8ff0e2d66a0d9e2b43e03", "width": 216, "height": 121}, {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ed63f67ade14297e5de04bb58d66cd8060d6c28", "width": 320, "height": 180}, {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e15b976f7c4d577c8d1bf8a0027ebc5d763320b", "width": 640, "height": 360}, {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e36ffbbc0301255fddfa4caceff1a27d29b09c7c", "width": 960, "height": 540}, {"url": "https://preview.redd.it/o9kb2xfhv58b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c17b29baa611887b027633e5ff4f9b8fce7f65da", "width": 1080, "height": 607}], "variants": {}, "id": "T9ts4J9i7_-Ex_q_frfXMYon-UfA9pn7E771RCemlas"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ilkoj", "is_robot_indexable": true, "report_reasons": null, "author": "2minutestreaming", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ilkoj/heard_of_streaming_sublinear_stochastic_algorithms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/o9kb2xfhv58b1.jpg", "subreddit_subscribers": 112337, "created_utc": 1687697611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the best practice to test data pipeline or data quality without query large data in production tables.\nOur team currently build test datasets, tables in the dataset are sampling from production table. However, I don\u2019t think this is a good way to ensure data quality.\nHow you guys do data pipeline test?", "author_fullname": "t2_846xgjv4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to minimize query fee when testing data pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ilf2o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687697153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the best practice to test data pipeline or data quality without query large data in production tables.\nOur team currently build test datasets, tables in the dataset are sampling from production table. However, I don\u2019t think this is a good way to ensure data quality.\nHow you guys do data pipeline test?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ilf2o", "is_robot_indexable": true, "report_reasons": null, "author": "Ssnakei", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ilf2o/how_to_minimize_query_fee_when_testing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ilf2o/how_to_minimize_query_fee_when_testing_data/", "subreddit_subscribers": 112337, "created_utc": 1687697153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks! \n\nCan you share what is the data backup strategy implemented in your organization? I'm not so much informed in this topic. \n\nSome of the questions that comes to mind:\n1. Do you create a copy of your data in another account/environment? Or is multi-az multi-region storage in 1 account enough?\n2. Do you also create backups of your processed data (those in silver and gold layer)? Or only the source raw data?\n3. If you take snapshots of your db, how often do you do so?\n4. If you do item#3, do you delete old snapshots?\n\nThanks!", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Backup strategy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ik622", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687693220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks! &lt;/p&gt;\n\n&lt;p&gt;Can you share what is the data backup strategy implemented in your organization? I&amp;#39;m not so much informed in this topic. &lt;/p&gt;\n\n&lt;p&gt;Some of the questions that comes to mind:\n1. Do you create a copy of your data in another account/environment? Or is multi-az multi-region storage in 1 account enough?\n2. Do you also create backups of your processed data (those in silver and gold layer)? Or only the source raw data?\n3. If you take snapshots of your db, how often do you do so?\n4. If you do item#3, do you delete old snapshots?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ik622", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ik622/data_backup_strategy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ik622/data_backup_strategy/", "subreddit_subscribers": 112337, "created_utc": 1687693220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm curating a Data Newsletter that focuses on news, analysis, opinion, and interviews pertaining to subjects at the crossroads of the data stack, LLMs, and GenAI.   \nHere's the latest issue: [https://datacrossroads.substack.com/p/data-crossroads-2](https://datacrossroads.substack.com/p/data-crossroads-2)  \n\n\nCurrently, I'm using a combination of Hacker news, Articles from Medium, Top posts on Twitter, Interesting discussions or commentary, and other substack newsletters, Could you help in suggesting excellent people/influencers in this industry that you follow and topics that you would love to read about?\n\n&amp;#x200B;", "author_fullname": "t2_8jz9pz97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help! Please suggest people/sources to follow for a Data Newsletter I'm curating.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14jbkan", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687768610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m curating a Data Newsletter that focuses on news, analysis, opinion, and interviews pertaining to subjects at the crossroads of the data stack, LLMs, and GenAI.&lt;br/&gt;\nHere&amp;#39;s the latest issue: &lt;a href=\"https://datacrossroads.substack.com/p/data-crossroads-2\"&gt;https://datacrossroads.substack.com/p/data-crossroads-2&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m using a combination of Hacker news, Articles from Medium, Top posts on Twitter, Interesting discussions or commentary, and other substack newsletters, Could you help in suggesting excellent people/influencers in this industry that you follow and topics that you would love to read about?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MFlzoBVPk25J2_uDs3K2VmDv-fhsLcBXgUqheiYH5oU.jpg?auto=webp&amp;v=enabled&amp;s=e05606d97865b70a2ecb5e5e4e45428dc1189360", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/MFlzoBVPk25J2_uDs3K2VmDv-fhsLcBXgUqheiYH5oU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cccb4106214c675cf442571397c3fba37f99d4b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MFlzoBVPk25J2_uDs3K2VmDv-fhsLcBXgUqheiYH5oU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bec9bb9f8b7b09492ab41798019b5627d8289f4a", "width": 216, "height": 216}], "variants": {}, "id": "NWPncVRwaHmORv-X8gons3myJYVHs8AY-G7x20SSkHA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14jbkan", "is_robot_indexable": true, "report_reasons": null, "author": "Rare_Confusion6373", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14jbkan/help_please_suggest_peoplesources_to_follow_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14jbkan/help_please_suggest_peoplesources_to_follow_for_a/", "subreddit_subscribers": 112337, "created_utc": 1687768610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Current state: we have a daily job within Databricks for a notebook that pulls new data for the day from two tables and merges the data into a single dataframe. After the job has completed he exports the dataframe to his local machine, encrypts them, and uploads them to OneDive.\n\nI would like to automate the process that is currently done manually, but I\u2019m running into issues on how to automate pulling the dataframe from Databricks. If I can figure that part out the rest will be rather easy. \n\nHas anyone done a similar use case using Databricks? Guidance and/or documentation would be extremely helpful!", "author_fullname": "t2_liedv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for guidance on automating an ETL pipeline for a colleague.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14j5kxx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687749127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current state: we have a daily job within Databricks for a notebook that pulls new data for the day from two tables and merges the data into a single dataframe. After the job has completed he exports the dataframe to his local machine, encrypts them, and uploads them to OneDive.&lt;/p&gt;\n\n&lt;p&gt;I would like to automate the process that is currently done manually, but I\u2019m running into issues on how to automate pulling the dataframe from Databricks. If I can figure that part out the rest will be rather easy. &lt;/p&gt;\n\n&lt;p&gt;Has anyone done a similar use case using Databricks? Guidance and/or documentation would be extremely helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14j5kxx", "is_robot_indexable": true, "report_reasons": null, "author": "AlexanderUGA", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14j5kxx/looking_for_guidance_on_automating_an_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14j5kxx/looking_for_guidance_on_automating_an_etl/", "subreddit_subscribers": 112337, "created_utc": 1687749127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For data science , there is a framework called crisp dm that is used to build scale able datascience projects \n\nAnything like that for building large data pipelines?", "author_fullname": "t2_8xyxcgdhc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14iy7nv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687729287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For data science , there is a framework called crisp dm that is used to build scale able datascience projects &lt;/p&gt;\n\n&lt;p&gt;Anything like that for building large data pipelines?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14iy7nv", "is_robot_indexable": true, "report_reasons": null, "author": "fread20009", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14iy7nv/data_engineering_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14iy7nv/data_engineering_framework/", "subreddit_subscribers": 112337, "created_utc": 1687729287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am almost done with 2nd year of my btech cse degree, I have some experience in data engineering (etl using glue, s3, lambda, python, basic airflow, api, data modelling, etc). Now I am planning on making a 2-3 month long portfolio project that covers a lot of stuff. So please help me design a project structure. Here's what I want to do, and my doubts regarding the same:\n\n1- Ingesting data from multiple sources: What can be these sources? Is an open source API and a database on my local machine enough? What data do I put in my local database such that it complements this API data, and where do I get all this data from in general? \n\n2- Landing the data: I want to use the ELT approach this project as it will remove the need of having to have another staging bucket. I have used AWS in past so I'll probably store it to redshift, is there something else I should consider using? \n\n3- Now I need to send this data somewhere where it may be useful and apply the transformation logic accordingly. What are all this places where we usually send data discord? Mail? Some dashboard? Somewhere else? Where do I send it to understand the job? What are all the tools that I might require for this? \nWhat best practices can I use while making this project? Version control, documentation, data governance, dataops, orchrestration where do all these things come in this picture? \nWhat are the least number of things I can do to get most of this job done? What should be the final project? \n\nI am patient, I want to do a good job even if it takes some time. \n\nI'd be very grateful if someone chooses to mentor me through this project (Please DM).", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me plan my personal project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14j7niy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687755564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am almost done with 2nd year of my btech cse degree, I have some experience in data engineering (etl using glue, s3, lambda, python, basic airflow, api, data modelling, etc). Now I am planning on making a 2-3 month long portfolio project that covers a lot of stuff. So please help me design a project structure. Here&amp;#39;s what I want to do, and my doubts regarding the same:&lt;/p&gt;\n\n&lt;p&gt;1- Ingesting data from multiple sources: What can be these sources? Is an open source API and a database on my local machine enough? What data do I put in my local database such that it complements this API data, and where do I get all this data from in general? &lt;/p&gt;\n\n&lt;p&gt;2- Landing the data: I want to use the ELT approach this project as it will remove the need of having to have another staging bucket. I have used AWS in past so I&amp;#39;ll probably store it to redshift, is there something else I should consider using? &lt;/p&gt;\n\n&lt;p&gt;3- Now I need to send this data somewhere where it may be useful and apply the transformation logic accordingly. What are all this places where we usually send data discord? Mail? Some dashboard? Somewhere else? Where do I send it to understand the job? What are all the tools that I might require for this? \nWhat best practices can I use while making this project? Version control, documentation, data governance, dataops, orchrestration where do all these things come in this picture? \nWhat are the least number of things I can do to get most of this job done? What should be the final project? &lt;/p&gt;\n\n&lt;p&gt;I am patient, I want to do a good job even if it takes some time. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be very grateful if someone chooses to mentor me through this project (Please DM).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14j7niy", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14j7niy/help_me_plan_my_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14j7niy/help_me_plan_my_personal_project/", "subreddit_subscribers": 112337, "created_utc": 1687755564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \n\nI am starting a new job for a company, my role is Data Specialist and I will be responsible for working on helping the team with Data migration. \n\nThe task is to do data migration from legacy system to a modern data structure on SharePoint. I am very much aware of the steps involved in this process, however, I have been out of touch with the tools and techniques as last time I studied Python, SSIS, visualization and Excel tools was a few years back and I think it will be difficult for me to contribute immediately as I join them. I am starting my work next week. I wanted to ask you professionals if I would have a hard time at my work with the skills I don\u2019t possess right now and what are the steps I need to take to make sure my employer can count on me going forward. \n\nPS: This is my first day working for an IT company and I have no idea how an IT project works.\n\n \n\nThanks! ", "author_fullname": "t2_3cpobabd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting a new job, need help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14inqtz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687703545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;I am starting a new job for a company, my role is Data Specialist and I will be responsible for working on helping the team with Data migration. &lt;/p&gt;\n\n&lt;p&gt;The task is to do data migration from legacy system to a modern data structure on SharePoint. I am very much aware of the steps involved in this process, however, I have been out of touch with the tools and techniques as last time I studied Python, SSIS, visualization and Excel tools was a few years back and I think it will be difficult for me to contribute immediately as I join them. I am starting my work next week. I wanted to ask you professionals if I would have a hard time at my work with the skills I don\u2019t possess right now and what are the steps I need to take to make sure my employer can count on me going forward. &lt;/p&gt;\n\n&lt;p&gt;PS: This is my first day working for an IT company and I have no idea how an IT project works.&lt;/p&gt;\n\n&lt;p&gt;Thanks! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14inqtz", "is_robot_indexable": true, "report_reasons": null, "author": "shanke_y8", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14inqtz/starting_a_new_job_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14inqtz/starting_a_new_job_need_help/", "subreddit_subscribers": 112337, "created_utc": 1687703545.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}