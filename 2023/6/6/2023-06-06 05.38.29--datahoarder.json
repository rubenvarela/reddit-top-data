{"kind": "Listing", "data": {"after": "t3_141s2xr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_9oj0amkob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit account was banned after adding my subs to the protest", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14140j8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 963, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 963, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1685944422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=36192312", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14140j8", "is_robot_indexable": true, "report_reasons": null, "author": "May_Concert", "discussion_type": null, "num_comments": 128, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14140j8/reddit_account_was_banned_after_adding_my_subs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=36192312", "subreddit_subscribers": 686222, "created_utc": 1685944422.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi Datahoarders! We were thinking that it's time to run another giveaway thread. This time, we are giving away an **IronWolf 125 1TB SSD** to one lucky winner in this thread.\n\nThe prize is: one **IronWolf 125 1TB SSD**\n\n*How to enter:*\nJust reply to this post once with a comment about what you are thankful for. We ask entrants to please include the terms **RunWithIronWolf** and **Seagate** in your comment to be considered for the prize drawing.\n\nFeel free to let us know what project(s) this would help with!\n\nSelection process/rules\n\nOne entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 23, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n\nGeographic restrictions:\n\nOur policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n\nUS\n\nCanada (will require a basic skills-based question if winner is chosen by law)\n\nBrazil\n\nSouth America\n\nUnited Kingdom\n\nGermany\n\nFrance\n\nIberia\n\nAustralia\n\nNew Zealand\n\nKorea\n\nIndia\n\nMalaysia\n\nSingapore\n\nChina", "author_fullname": "t2_16nn7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Official Giveaway: June 2023 Seagate IronWolf Giveaway!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141lmhg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": "", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685985755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Datahoarders! We were thinking that it&amp;#39;s time to run another giveaway thread. This time, we are giving away an &lt;strong&gt;IronWolf 125 1TB SSD&lt;/strong&gt; to one lucky winner in this thread.&lt;/p&gt;\n\n&lt;p&gt;The prize is: one &lt;strong&gt;IronWolf 125 1TB SSD&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;How to enter:&lt;/em&gt;\nJust reply to this post once with a comment about what you are thankful for. We ask entrants to please include the terms &lt;strong&gt;RunWithIronWolf&lt;/strong&gt; and &lt;strong&gt;Seagate&lt;/strong&gt; in your comment to be considered for the prize drawing.&lt;/p&gt;\n\n&lt;p&gt;Feel free to let us know what project(s) this would help with!&lt;/p&gt;\n\n&lt;p&gt;Selection process/rules&lt;/p&gt;\n\n&lt;p&gt;One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 23, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.&lt;/p&gt;\n\n&lt;p&gt;Geographic restrictions:&lt;/p&gt;\n\n&lt;p&gt;Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)&lt;/p&gt;\n\n&lt;p&gt;US&lt;/p&gt;\n\n&lt;p&gt;Canada (will require a basic skills-based question if winner is chosen by law)&lt;/p&gt;\n\n&lt;p&gt;Brazil&lt;/p&gt;\n\n&lt;p&gt;South America&lt;/p&gt;\n\n&lt;p&gt;United Kingdom&lt;/p&gt;\n\n&lt;p&gt;Germany&lt;/p&gt;\n\n&lt;p&gt;France&lt;/p&gt;\n\n&lt;p&gt;Iberia&lt;/p&gt;\n\n&lt;p&gt;Australia&lt;/p&gt;\n\n&lt;p&gt;New Zealand&lt;/p&gt;\n\n&lt;p&gt;Korea&lt;/p&gt;\n\n&lt;p&gt;India&lt;/p&gt;\n\n&lt;p&gt;Malaysia&lt;/p&gt;\n\n&lt;p&gt;Singapore&lt;/p&gt;\n\n&lt;p&gt;China&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OFFICIAL SEAGATE", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "141lmhg", "is_robot_indexable": true, "report_reasons": null, "author": "Seagate_Surfer", "discussion_type": null, "num_comments": 169, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/141lmhg/official_giveaway_june_2023_seagate_ironwolf/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/141lmhg/official_giveaway_june_2023_seagate_ironwolf/", "subreddit_subscribers": 686222, "created_utc": 1685985755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Datahorder community!\n\nI just have a question referance backups of all your precious and (in my case sometimes) usless data! I have for a long time admired the setups people have on here and I have for a very long time wanted a data hording setup of my own (since I was about 15 as im a little bit sad!). I currently have 1TB on Google Drive and I am currently looking at purchasing a Synology DS923+ with 8TB of storage (which I will keep in RAID5 giving me 6TB usable). \n\n&amp;#x200B;\n\nI was just wanting to use you experts as a sounding bored, If i was to get say 3 6TB external HDD's and keep 1 in my bedroom (which will be backed up to daily, or everyother day), 1 in my office (weekly backed up) and 1 in my parents house (monthly backed up). \n\nWould this be sufficent? I feel like paying for a backup to google drive etc defeats purchasing the NAS. I am trying to become self hosted in as many ways as possible.\n\n&amp;#x200B;\n\nThank you for any advice\n\n&amp;#x200B;\n\nAdded:\n\nOn this NAS will be a few docker containers for testing some stuff and just general files and photos\n\nI am also looking at purchasing a older server at some point and that will run my testing and dockers and will backup to the NAS.", "author_fullname": "t2_1wgqbq6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup suggestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141shz5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686000533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Datahorder community!&lt;/p&gt;\n\n&lt;p&gt;I just have a question referance backups of all your precious and (in my case sometimes) usless data! I have for a long time admired the setups people have on here and I have for a very long time wanted a data hording setup of my own (since I was about 15 as im a little bit sad!). I currently have 1TB on Google Drive and I am currently looking at purchasing a Synology DS923+ with 8TB of storage (which I will keep in RAID5 giving me 6TB usable). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was just wanting to use you experts as a sounding bored, If i was to get say 3 6TB external HDD&amp;#39;s and keep 1 in my bedroom (which will be backed up to daily, or everyother day), 1 in my office (weekly backed up) and 1 in my parents house (monthly backed up). &lt;/p&gt;\n\n&lt;p&gt;Would this be sufficent? I feel like paying for a backup to google drive etc defeats purchasing the NAS. I am trying to become self hosted in as many ways as possible.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any advice&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Added:&lt;/p&gt;\n\n&lt;p&gt;On this NAS will be a few docker containers for testing some stuff and just general files and photos&lt;/p&gt;\n\n&lt;p&gt;I am also looking at purchasing a older server at some point and that will run my testing and dockers and will backup to the NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141shz5", "is_robot_indexable": true, "report_reasons": null, "author": "Zetta666", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141shz5/backup_suggestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141shz5/backup_suggestion/", "subreddit_subscribers": 686222, "created_utc": 1686000533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Shouldn't there be a call to start backing up quite a few of these subreddits or is that already done elsewhere?\n\nI'm looking at the *or permanently * part as privating a subreddit is the equivalent of shutting down a forum website in a way, and plan for the worst, hope for the best, you know?", "author_fullname": "t2_16u0wi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question regarding incoming reddit blackouts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1418d9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685956459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Shouldn&amp;#39;t there be a call to start backing up quite a few of these subreddits or is that already done elsewhere?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at the *or permanently * part as privating a subreddit is the equivalent of shutting down a forum website in a way, and plan for the worst, hope for the best, you know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "76/108 TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1418d9z", "is_robot_indexable": true, "report_reasons": null, "author": "TheGleanerBaldwin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1418d9z/question_regarding_incoming_reddit_blackouts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1418d9z/question_regarding_incoming_reddit_blackouts/", "subreddit_subscribers": 686222, "created_utc": 1685956459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It will mostly be a media/jellyfin server, but will do some general use as well. A VM and/or some containers. \n\nFor storage I am looking at either 4x16TB or 6x16TB for storage. Which would be best, and what RAID/UNRAID config should I run for 4 and 6 drives? Should the drives be the same or should I split between 2 or 3 brands? There will be some data that would suck to lose. Most of it is media though. Not critical, but a big pain to find again and would preferably want to avoid doing so. I am willing to pay more for an extra drive or two if necessary.\n\nAs for other hardware. How powerful cpu should I get for running maybe a VM, a container and a jellyfin server? And what about memory?\n\nBig thanks in advance for any input!", "author_fullname": "t2_y5g3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to build a home server. 4 or 6 drives? How powerful hardware", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1420occ", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686018563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It will mostly be a media/jellyfin server, but will do some general use as well. A VM and/or some containers. &lt;/p&gt;\n\n&lt;p&gt;For storage I am looking at either 4x16TB or 6x16TB for storage. Which would be best, and what RAID/UNRAID config should I run for 4 and 6 drives? Should the drives be the same or should I split between 2 or 3 brands? There will be some data that would suck to lose. Most of it is media though. Not critical, but a big pain to find again and would preferably want to avoid doing so. I am willing to pay more for an extra drive or two if necessary.&lt;/p&gt;\n\n&lt;p&gt;As for other hardware. How powerful cpu should I get for running maybe a VM, a container and a jellyfin server? And what about memory?&lt;/p&gt;\n\n&lt;p&gt;Big thanks in advance for any input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1420occ", "is_robot_indexable": true, "report_reasons": null, "author": "TheOptiGamer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1420occ/looking_to_build_a_home_server_4_or_6_drives_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1420occ/looking_to_build_a_home_server_4_or_6_drives_how/", "subreddit_subscribers": 686222, "created_utc": 1686018563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "want to buy a lot of drives and I have found no posts talking about their support once something goes wrong", "author_fullname": "t2_gw5a2p3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have RMA experience with Solidigm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141zgm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686015673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;want to buy a lot of drives and I have found no posts talking about their support once something goes wrong&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141zgm0", "is_robot_indexable": true, "report_reasons": null, "author": "masturbaiter696969", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141zgm0/anyone_have_rma_experience_with_solidigm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141zgm0/anyone_have_rma_experience_with_solidigm/", "subreddit_subscribers": 686222, "created_utc": 1686015673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seem to have a bit of it in everything now, from ZFS special vdevs to the boot drive in my battle station (dat *latency* \ud83d\udc40 \ud83d\udc40 \ud83d\udc40 ). \n\nNewegg just ran out of the 118GB NVMe m.2 and I\u2019m trying to see if anyone has any more ideas to justify stocking up before its all gone for good.", "author_fullname": "t2_u4u6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else taking advantage of the Optane fire sale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141e7uv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685970880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seem to have a bit of it in everything now, from ZFS special vdevs to the boot drive in my battle station (dat &lt;em&gt;latency&lt;/em&gt; \ud83d\udc40 \ud83d\udc40 \ud83d\udc40 ). &lt;/p&gt;\n\n&lt;p&gt;Newegg just ran out of the 118GB NVMe m.2 and I\u2019m trying to see if anyone has any more ideas to justify stocking up before its all gone for good.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141e7uv", "is_robot_indexable": true, "report_reasons": null, "author": "certifiedintelligent", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141e7uv/anyone_else_taking_advantage_of_the_optane_fire/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141e7uv/anyone_else_taking_advantage_of_the_optane_fire/", "subreddit_subscribers": 686222, "created_utc": 1685970880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone!\nThanks for reading!\n\nPlease excuse me if my noob question makes you cringe.\n\nI have been looking for a solution to set all my hdds in one single enclosure so I can access to all of them. Lurking here I read about the Terramaster d5-330 and I got one.\n\nHere is where my problems started. I followed the official guide, watching the videos and spent the last 24hrs reading all I can find on how to set it up. I failed. \n\nI want to use it in SINGLE mode that for what I understand should be pretty much plug and play, but the thunderbolt ports on my ROG ZEPHIRUS g15 only detect it as PD (power device) and I don\u2019t get the prompt to install the drivers nor the raid shows up in my device manager window.\n\nI tried force the update on the thuderbolt to install the official drivers but it got me nowhere. I installed the rain manager and the raid pro manager software. Obviously the drive doesn\u2019t show up so also that is a nonstarter. \n\nI tried several recommended hdd in different all the bays of the D5-330 with always the same results. Btw the light of the drives stay off all the time. I tested the drives before and after, and it works no problem. \n\nIs my first time fiddling with a das so I am sure I can mess up something but I can\u2019t see what \u2026 I am stupid or is this unit defective?\n\nThanks!", "author_fullname": "t2_3cl0d5g5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help/troubleshooting: Terramaster D5-330 failing to be recognized, is it a dudd?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1420fb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686017968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!\nThanks for reading!&lt;/p&gt;\n\n&lt;p&gt;Please excuse me if my noob question makes you cringe.&lt;/p&gt;\n\n&lt;p&gt;I have been looking for a solution to set all my hdds in one single enclosure so I can access to all of them. Lurking here I read about the Terramaster d5-330 and I got one.&lt;/p&gt;\n\n&lt;p&gt;Here is where my problems started. I followed the official guide, watching the videos and spent the last 24hrs reading all I can find on how to set it up. I failed. &lt;/p&gt;\n\n&lt;p&gt;I want to use it in SINGLE mode that for what I understand should be pretty much plug and play, but the thunderbolt ports on my ROG ZEPHIRUS g15 only detect it as PD (power device) and I don\u2019t get the prompt to install the drivers nor the raid shows up in my device manager window.&lt;/p&gt;\n\n&lt;p&gt;I tried force the update on the thuderbolt to install the official drivers but it got me nowhere. I installed the rain manager and the raid pro manager software. Obviously the drive doesn\u2019t show up so also that is a nonstarter. &lt;/p&gt;\n\n&lt;p&gt;I tried several recommended hdd in different all the bays of the D5-330 with always the same results. Btw the light of the drives stay off all the time. I tested the drives before and after, and it works no problem. &lt;/p&gt;\n\n&lt;p&gt;Is my first time fiddling with a das so I am sure I can mess up something but I can\u2019t see what \u2026 I am stupid or is this unit defective?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1420fb0", "is_robot_indexable": true, "report_reasons": null, "author": "FresconeFrizzantino", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1420fb0/helptroubleshooting_terramaster_d5330_failing_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1420fb0/helptroubleshooting_terramaster_d5330_failing_to/", "subreddit_subscribers": 686222, "created_utc": 1686017968.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there any cases out there that can hold the same amount of drives as the 7 XL (18 I believe) or more, for a regular nas build? I\u2019ve seen people say the Lian Li D8000 but it\u2019s discontinued.", "author_fullname": "t2_ba3y5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rival to Fractal Define 7 XL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141o74a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685991024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any cases out there that can hold the same amount of drives as the 7 XL (18 I believe) or more, for a regular nas build? I\u2019ve seen people say the Lian Li D8000 but it\u2019s discontinued.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141o74a", "is_robot_indexable": true, "report_reasons": null, "author": "Conorsavage", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141o74a/rival_to_fractal_define_7_xl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141o74a/rival_to_fractal_define_7_xl/", "subreddit_subscribers": 686222, "created_utc": 1685991024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there!\n\nI have downloaded alot of data from a site called justcritics or smth along the lines.... \n\nAnyway, i've got millions of files (videos and images) which i now need to filter out and categorize.\n\nNow i notice that ntfs/windows isnt well suited for that job, the explorer is constantly crashing and filling up the cache when having a folder with more than 100 images/videos.\n\nCan anyone recommend a good solution for that?", "author_fullname": "t2_onogq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141jcc6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685981219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there!&lt;/p&gt;\n\n&lt;p&gt;I have downloaded alot of data from a site called justcritics or smth along the lines.... &lt;/p&gt;\n\n&lt;p&gt;Anyway, i&amp;#39;ve got millions of files (videos and images) which i now need to filter out and categorize.&lt;/p&gt;\n\n&lt;p&gt;Now i notice that ntfs/windows isnt well suited for that job, the explorer is constantly crashing and filling up the cache when having a folder with more than 100 images/videos.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend a good solution for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141jcc6", "is_robot_indexable": true, "report_reasons": null, "author": "AllCowsAreBurgers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141jcc6/managing_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141jcc6/managing_content/", "subreddit_subscribers": 686222, "created_utc": 1685981219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a piece of software out there that can inspect a bunch of video files, then output the results to some sort of sortable table (like Excel)?\n\nI have tried MediaInfo but it seems a bit too \"cody\" for me - I have tried for over 20 minutes to get it to export something meaningful but the templates aren't much help and I don't even understand when I edit a template, it outputs something completely different to what I edited.\n\nThere is something called \"media center master\" which is great but a little too overpowered for what I need I think.\n\nAny others to consider?", "author_fullname": "t2_mre85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to Inspect a Bunch of Video Files, Output to Excel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141hviu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685978313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a piece of software out there that can inspect a bunch of video files, then output the results to some sort of sortable table (like Excel)?&lt;/p&gt;\n\n&lt;p&gt;I have tried MediaInfo but it seems a bit too &amp;quot;cody&amp;quot; for me - I have tried for over 20 minutes to get it to export something meaningful but the templates aren&amp;#39;t much help and I don&amp;#39;t even understand when I edit a template, it outputs something completely different to what I edited.&lt;/p&gt;\n\n&lt;p&gt;There is something called &amp;quot;media center master&amp;quot; which is great but a little too overpowered for what I need I think.&lt;/p&gt;\n\n&lt;p&gt;Any others to consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141hviu", "is_robot_indexable": true, "report_reasons": null, "author": "banisheduser", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141hviu/software_to_inspect_a_bunch_of_video_files_output/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141hviu/software_to_inspect_a_bunch_of_video_files_output/", "subreddit_subscribers": 686222, "created_utc": 1685978313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently my Seagate Exos 16 TB started having problems reading some old files so I installed HD Sentinel and it showed 9% Health and 2000+ bad sectors.\n\nI tried taking backup of these files but the speed would go down to 0 KB/sec and just get stuck there. So I formatted the entire drive (lost data was not crucial) and tried HD Sentinel's re-initializing disk surface which is showing 0 bad/damaged sectors.\n\nSo is it actually failing?\n\n&amp;#x200B;\n\n[HD Sentinel Status](https://preview.redd.it/2ww41mdyc74b1.jpg?width=3127&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ae8affa932c691ca1426d3cb484362ea700bca33)\n\n&amp;#x200B;\n\n[Re-initialization in progress](https://preview.redd.it/gpbggke1d74b1.jpg?width=2284&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=520720085dff4ccddaf0a04de81fcd80e154c886)", "author_fullname": "t2_2vxfphjm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my drive actually failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2ww41mdyc74b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f77e8479ab682056891f94306ed02005ec03dc9"}, {"y": 127, "x": 216, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ae603ebfe88272fac8cf729686dcfb87282f58d"}, {"y": 189, "x": 320, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b180b1419b2d50fe2914d2705044fb5798258419"}, {"y": 378, "x": 640, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b139b14a792324bb0018e3f287929d42b9cfa7fa"}, {"y": 568, "x": 960, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=210178e02809616c8d02ce0943af0ff052958f24"}, {"y": 639, "x": 1080, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92e04a1267567f6b482178244a9d980970286a6e"}], "s": {"y": 1851, "x": 3127, "u": "https://preview.redd.it/2ww41mdyc74b1.jpg?width=3127&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ae8affa932c691ca1426d3cb484362ea700bca33"}, "id": "2ww41mdyc74b1"}, "gpbggke1d74b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ac3678994a2df21dceeb547ded8ea82598f4cfb"}, {"y": 131, "x": 216, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4041f31faa5fe04e4281bb59f59ba229ab45763"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c1ae2a0b340ae1ea35690e52971f21ca4634051"}, {"y": 390, "x": 640, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c208dfc0d0bcfc1760632d38cd2c3eba02aea8e2"}, {"y": 586, "x": 960, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bacb138d7ef242fa9972c8c73bd8387c7140c60e"}, {"y": 659, "x": 1080, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60f3050053240f9e2388dd28bd22cc5348a099de"}], "s": {"y": 1395, "x": 2284, "u": "https://preview.redd.it/gpbggke1d74b1.jpg?width=2284&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=520720085dff4ccddaf0a04de81fcd80e154c886"}, "id": "gpbggke1d74b1"}}, "name": "t3_141eswz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b3uS7Lq82UGQx_xcqRSa7H5Qe5RFi1kSRqI4FhKgFUc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685972153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently my Seagate Exos 16 TB started having problems reading some old files so I installed HD Sentinel and it showed 9% Health and 2000+ bad sectors.&lt;/p&gt;\n\n&lt;p&gt;I tried taking backup of these files but the speed would go down to 0 KB/sec and just get stuck there. So I formatted the entire drive (lost data was not crucial) and tried HD Sentinel&amp;#39;s re-initializing disk surface which is showing 0 bad/damaged sectors.&lt;/p&gt;\n\n&lt;p&gt;So is it actually failing?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2ww41mdyc74b1.jpg?width=3127&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ae8affa932c691ca1426d3cb484362ea700bca33\"&gt;HD Sentinel Status&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gpbggke1d74b1.jpg?width=2284&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=520720085dff4ccddaf0a04de81fcd80e154c886\"&gt;Re-initialization in progress&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141eswz", "is_robot_indexable": true, "report_reasons": null, "author": "ravenous24", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141eswz/is_my_drive_actually_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141eswz/is_my_drive_actually_failing/", "subreddit_subscribers": 686222, "created_utc": 1685972153.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone been able to download youtube videos on the ```http_dash_segments``` protocol at speed &gt; 500KB/sec ? \n\nWhen I download a video using the ```https``` protocol, I can get speed like 10MB/sec, but other formats of the same video that are listed on the ```http_dash_segments``` protocol, speed is always capped, that is with ```Youtube Download [yt-dlp]``` or ```jDownloader```. \n\nThanks", "author_fullname": "t2_ch4bnghs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "youtube ideos: http_dash_segments protocol speed capped?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14234ic", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686024601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone been able to download youtube videos on the &lt;code&gt;http_dash_segments&lt;/code&gt; protocol at speed &amp;gt; 500KB/sec ? &lt;/p&gt;\n\n&lt;p&gt;When I download a video using the &lt;code&gt;https&lt;/code&gt; protocol, I can get speed like 10MB/sec, but other formats of the same video that are listed on the &lt;code&gt;http_dash_segments&lt;/code&gt; protocol, speed is always capped, that is with &lt;code&gt;Youtube Download [yt-dlp]&lt;/code&gt; or &lt;code&gt;jDownloader&lt;/code&gt;. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14234ic", "is_robot_indexable": true, "report_reasons": null, "author": "cybercastor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14234ic/youtube_ideos_http_dash_segments_protocol_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14234ic/youtube_ideos_http_dash_segments_protocol_speed/", "subreddit_subscribers": 686222, "created_utc": 1686024601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve heard that Reddit users will get free access to the API, so shouldn\u2019t tools like Reddit Media Downloader still work after the changes are implemented? Or will it stop working?\n\nThanks", "author_fullname": "t2_gvdnvhdz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit media downloader and Reddit API changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141m2m3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685986652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve heard that Reddit users will get free access to the API, so shouldn\u2019t tools like Reddit Media Downloader still work after the changes are implemented? Or will it stop working?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141m2m3", "is_robot_indexable": true, "report_reasons": null, "author": "Fresh_Air13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141m2m3/reddit_media_downloader_and_reddit_api_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141m2m3/reddit_media_downloader_and_reddit_api_changes/", "subreddit_subscribers": 686222, "created_utc": 1685986652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title, but I'll elaborate just in case. I did some research on the topic and found threads from 5+ years ago about Macbooks so I think it's ok to ask -\n\nI am using this storage space to hold video files and misc. assets, and have always been told to place an abundance of caution on how the hard drive is removed from the computer. Thoughtless unplugging of a hard drive could cause hours upon hours of lost work and I would like to avoid that. \n\nI've placed this external drive underneath my desk along with my docking station to save space &amp; keep them out of the way. A perfect scenario would be that I can plug my laptop in and get straight to work, and then unplug safely when I'm done, keeping the drive where it is without touching it. \n\nIs this possible, should I just eject before I unplug the USB connection to my laptop? Thank you!", "author_fullname": "t2_6md0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2 TB external drive connected to USB docking station - do I need to worry about ejecting the drive after using the dock?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141l4zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685984789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title, but I&amp;#39;ll elaborate just in case. I did some research on the topic and found threads from 5+ years ago about Macbooks so I think it&amp;#39;s ok to ask -&lt;/p&gt;\n\n&lt;p&gt;I am using this storage space to hold video files and misc. assets, and have always been told to place an abundance of caution on how the hard drive is removed from the computer. Thoughtless unplugging of a hard drive could cause hours upon hours of lost work and I would like to avoid that. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve placed this external drive underneath my desk along with my docking station to save space &amp;amp; keep them out of the way. A perfect scenario would be that I can plug my laptop in and get straight to work, and then unplug safely when I&amp;#39;m done, keeping the drive where it is without touching it. &lt;/p&gt;\n\n&lt;p&gt;Is this possible, should I just eject before I unplug the USB connection to my laptop? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141l4zw", "is_robot_indexable": true, "report_reasons": null, "author": "delmarman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141l4zw/2_tb_external_drive_connected_to_usb_docking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141l4zw/2_tb_external_drive_connected_to_usb_docking/", "subreddit_subscribers": 686222, "created_utc": 1685984789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have 4 WD Elements externals that I use for Kodi. One of which (that was not yet backed up) was tipped to the side and now won't recognize in Windows. When trying to initialize the drive I get the Hardware malfunction error.   \n\n\nIs this drive completely dead? Or is it worth shucking? Would it make a difference if it weren't in the WD enclosure?", "author_fullname": "t2_tv8y5ruk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Elements not showing up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141j7d1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685980942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have 4 WD Elements externals that I use for Kodi. One of which (that was not yet backed up) was tipped to the side and now won&amp;#39;t recognize in Windows. When trying to initialize the drive I get the Hardware malfunction error.   &lt;/p&gt;\n\n&lt;p&gt;Is this drive completely dead? Or is it worth shucking? Would it make a difference if it weren&amp;#39;t in the WD enclosure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141j7d1", "is_robot_indexable": true, "report_reasons": null, "author": "dndoldhead", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141j7d1/wd_elements_not_showing_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141j7d1/wd_elements_not_showing_up/", "subreddit_subscribers": 686222, "created_utc": 1685980942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title speaks for itself. I want to have a redundancy but unfortunately I have 400 gigs left of storage on my 1TB iPhone and my photo library is 800 gigs so I can't just install the Amazon photo app and press sync becausae then it will upload the super bad quality preview picture on my phone.   I do have all originals in the Mac so I was wondering if there is any way to upload them from there to Amazon but also preserving things such as my photo folders and orc the date the picture was taken and the GPS coordinates of each picture.", "author_fullname": "t2_1vvn658m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I export my iCloud photo library to Amazon Photos on Mac OS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141e1x7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685970511.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title speaks for itself. I want to have a redundancy but unfortunately I have 400 gigs left of storage on my 1TB iPhone and my photo library is 800 gigs so I can&amp;#39;t just install the Amazon photo app and press sync becausae then it will upload the super bad quality preview picture on my phone.   I do have all originals in the Mac so I was wondering if there is any way to upload them from there to Amazon but also preserving things such as my photo folders and orc the date the picture was taken and the GPS coordinates of each picture.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141e1x7", "is_robot_indexable": true, "report_reasons": null, "author": "EthanColeK", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141e1x7/how_can_i_export_my_icloud_photo_library_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141e1x7/how_can_i_export_my_icloud_photo_library_to/", "subreddit_subscribers": 686222, "created_utc": 1685970511.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "That's all I'd like to know. Thanks", "author_fullname": "t2_cuaje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Drive Workspace 10TB per day download limit. Is it per Google Account or Team Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141a37i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685961055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s all I&amp;#39;d like to know. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141a37i", "is_robot_indexable": true, "report_reasons": null, "author": "titooo7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141a37i/google_drive_workspace_10tb_per_day_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141a37i/google_drive_workspace_10tb_per_day_download/", "subreddit_subscribers": 686222, "created_utc": 1685961055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are several things I would like to download from Reddit before they kill off API access: \n\n- Every single thread I have commented on, for the purpose of being able to train an LLM to write like me. Reddit is by far the largest collection of text I have written. I have already filed a new CCPA request to get all my comments, but IIRC last time I made a request I only got my comments by themselves, not what they were replying to, so I need a way to automatically download all the context. \n\n- Every single post I have upvoted or saved, if possible. \n\n- Specific subreddits, particularly /r/HFY. I would like to save all the Reddit serials that I enjoy reading on my phone before API access is cut off and I no longer have a comfortable way to read them anymore. \n\nWhat are the best tools to do this with, saving as much metadata as possible in a machine-readable format? \n\nAny other tools for downloading from Reddit, even if not important for my particular use case, are also welcome. I am posting this because at my current point in searching, I have not yet found any good compilation of all the tools available.", "author_fullname": "t2_qp8d2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tools for downloading Reddit before API access is cut off?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1423a1q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686024982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are several things I would like to download from Reddit before they kill off API access: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Every single thread I have commented on, for the purpose of being able to train an LLM to write like me. Reddit is by far the largest collection of text I have written. I have already filed a new CCPA request to get all my comments, but IIRC last time I made a request I only got my comments by themselves, not what they were replying to, so I need a way to automatically download all the context. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Every single post I have upvoted or saved, if possible. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Specific subreddits, particularly &lt;a href=\"/r/HFY\"&gt;/r/HFY&lt;/a&gt;. I would like to save all the Reddit serials that I enjoy reading on my phone before API access is cut off and I no longer have a comfortable way to read them anymore. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are the best tools to do this with, saving as much metadata as possible in a machine-readable format? &lt;/p&gt;\n\n&lt;p&gt;Any other tools for downloading from Reddit, even if not important for my particular use case, are also welcome. I am posting this because at my current point in searching, I have not yet found any good compilation of all the tools available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "11TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1423a1q", "is_robot_indexable": true, "report_reasons": null, "author": "happysmash27", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1423a1q/best_tools_for_downloading_reddit_before_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1423a1q/best_tools_for_downloading_reddit_before_api/", "subreddit_subscribers": 686222, "created_utc": 1686024982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I\u2019ve recently gotten into Data Hoarding as I\u2019d like to begin archiving 2 of my favorite YouTube channels. I have 2x 2TB External HDD, one as my main and the second as a backup, although I might get a 3rd one as another backup (I\u2019ve checked beforehand and the 2 channels together won\u2019t even add up to 3/4 of a TB, so I\u2019m okay with 2TB Drives *for now*). \n\nMoving on, I\u2019ve seen people on this subreddit talk about bit rot and using checksums as a way to detect it. Therefore, **what\u2019s the best way to have checksums while still updating my drives with new videos?** My initial thought was to just have 2 checksums, one for 1 channel and one for the other, however, I ended up finding 2 issues with this: (1) if I keep adding new videos to one channel\u2019s file, then the checksum will keep changing, right? So I\u2019ll have to keep updating the checksum every few days? (2) If bitrot does occur, and I see a different checksum for YT Channel #1\u2019s file on one HDD, I wouldn\u2019t know which specific file is corrupted, just that one (or perhaps a couple) file(s) out of 500 are corrupted. \n\nSo, my next thought was to make checksums for each video, that way if bitrot does occur, I can pinpoint which file is corrupted, however, this would mean having 500+ checksums to check each time I\u2019m looking over one of my HDD\u2019s, which sounds way too inefficient unless there\u2019s a program or application that can do it automatically. \n\nSo, once again, **what\u2019s the best way to have checksums while still updating my drives with new videos?** Would it be best if I sort the videos yearly and then make checksums for each year? Monthly? \n\nWould really appreciate any help I can get!", "author_fullname": "t2_lgtie35c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Hoarding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141v5ga", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686005937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019ve recently gotten into Data Hoarding as I\u2019d like to begin archiving 2 of my favorite YouTube channels. I have 2x 2TB External HDD, one as my main and the second as a backup, although I might get a 3rd one as another backup (I\u2019ve checked beforehand and the 2 channels together won\u2019t even add up to 3/4 of a TB, so I\u2019m okay with 2TB Drives &lt;em&gt;for now&lt;/em&gt;). &lt;/p&gt;\n\n&lt;p&gt;Moving on, I\u2019ve seen people on this subreddit talk about bit rot and using checksums as a way to detect it. Therefore, &lt;strong&gt;what\u2019s the best way to have checksums while still updating my drives with new videos?&lt;/strong&gt; My initial thought was to just have 2 checksums, one for 1 channel and one for the other, however, I ended up finding 2 issues with this: (1) if I keep adding new videos to one channel\u2019s file, then the checksum will keep changing, right? So I\u2019ll have to keep updating the checksum every few days? (2) If bitrot does occur, and I see a different checksum for YT Channel #1\u2019s file on one HDD, I wouldn\u2019t know which specific file is corrupted, just that one (or perhaps a couple) file(s) out of 500 are corrupted. &lt;/p&gt;\n\n&lt;p&gt;So, my next thought was to make checksums for each video, that way if bitrot does occur, I can pinpoint which file is corrupted, however, this would mean having 500+ checksums to check each time I\u2019m looking over one of my HDD\u2019s, which sounds way too inefficient unless there\u2019s a program or application that can do it automatically. &lt;/p&gt;\n\n&lt;p&gt;So, once again, &lt;strong&gt;what\u2019s the best way to have checksums while still updating my drives with new videos?&lt;/strong&gt; Would it be best if I sort the videos yearly and then make checksums for each year? Monthly? &lt;/p&gt;\n\n&lt;p&gt;Would really appreciate any help I can get!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141v5ga", "is_robot_indexable": true, "report_reasons": null, "author": "iMainQuake", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/141v5ga/new_to_data_hoarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141v5ga/new_to_data_hoarding/", "subreddit_subscribers": 686222, "created_utc": 1686005937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for something like [https://www.amazon.com/SanDisk-Cruzer-Flash-Drive-SDCZ33-032G-A11/dp/B008C7C5OC](https://www.amazon.com/SanDisk-Cruzer-Flash-Drive-SDCZ33-032G-A11/dp/B008C7C5OC) but with USB C.  \nSomething like [https://www.amazon.com/Yubico-YubiKey-Factor-Authentication-Security/dp/B07HBTBJ5S](https://www.amazon.com/Yubico-YubiKey-Factor-Authentication-Security/dp/B07HBTBJ5S) but a memory stick.  \n\n\nHas anyone came across anything similar? Im failing to find anything.  \nP.S. if there is more appropriate channel, let me know.", "author_fullname": "t2_173zc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Physically smallest USB C memory stick", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141kvwp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685984292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something like &lt;a href=\"https://www.amazon.com/SanDisk-Cruzer-Flash-Drive-SDCZ33-032G-A11/dp/B008C7C5OC\"&gt;https://www.amazon.com/SanDisk-Cruzer-Flash-Drive-SDCZ33-032G-A11/dp/B008C7C5OC&lt;/a&gt; but with USB C.&lt;br/&gt;\nSomething like &lt;a href=\"https://www.amazon.com/Yubico-YubiKey-Factor-Authentication-Security/dp/B07HBTBJ5S\"&gt;https://www.amazon.com/Yubico-YubiKey-Factor-Authentication-Security/dp/B07HBTBJ5S&lt;/a&gt; but a memory stick.  &lt;/p&gt;\n\n&lt;p&gt;Has anyone came across anything similar? Im failing to find anything.&lt;br/&gt;\nP.S. if there is more appropriate channel, let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141kvwp", "is_robot_indexable": true, "report_reasons": null, "author": "grannyno", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141kvwp/physically_smallest_usb_c_memory_stick/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141kvwp/physically_smallest_usb_c_memory_stick/", "subreddit_subscribers": 686222, "created_utc": 1685984292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\n&amp;nbsp;\n\nI just noticed my 2 year old disks both have around 70 thousand cycles. This is too much. If we [check the wd blue datasheet](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf) we can see that the WD specced load/unload count is 300 thousand. Sure the disks need to be replaced anyway after they're fully used (this would be around after 8 years), but I have some 3TB WD reds from 2013 that are still alive and kicking. So I'd rather have them not kill themselves with wear like this.\n\n&amp;nbsp;\n\nAny way to stop this? No idea why it happens, only noticed it happening to WD Whites. WD Reds are fine.", "author_fullname": "t2_fiawk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD 8TB Whites (EZAZ and EDAZ) issue - Load cycle count and Power-off retract count rapidly rising.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1416mx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685951625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I just noticed my 2 year old disks both have around 70 thousand cycles. This is too much. If we &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\"&gt;check the wd blue datasheet&lt;/a&gt; we can see that the WD specced load/unload count is 300 thousand. Sure the disks need to be replaced anyway after they&amp;#39;re fully used (this would be around after 8 years), but I have some 3TB WD reds from 2013 that are still alive and kicking. So I&amp;#39;d rather have them not kill themselves with wear like this.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Any way to stop this? No idea why it happens, only noticed it happening to WD Whites. WD Reds are fine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1416mx3", "is_robot_indexable": true, "report_reasons": null, "author": "Xillenn", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1416mx3/wd_8tb_whites_ezaz_and_edaz_issue_load_cycle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1416mx3/wd_8tb_whites_ezaz_and_edaz_issue_load_cycle/", "subreddit_subscribers": 686222, "created_utc": 1685951625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Idk how to use yt dl.does anyone know easier alternative?", "author_fullname": "t2_bwel8myj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know a tool to download SoundCloud playlists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1414791", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685944940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Idk how to use yt dl.does anyone know easier alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1414791", "is_robot_indexable": true, "report_reasons": null, "author": "BadConlanger2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1414791/does_anyone_know_a_tool_to_download_soundcloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1414791/does_anyone_know_a_tool_to_download_soundcloud/", "subreddit_subscribers": 686222, "created_utc": 1685944940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Sandisk Extreme portable SSD with movie files. What's the best/most convenient way to password protect it or the files? Ideally it will be just as easy to navigate the files using Finder (macbook). I've looked at a bunch of blogs and youtube videos and nothing stands out to me as convenient, many use third-party apps. Thanks for your advice.", "author_fullname": "t2_dvd0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to password protect Sandisk Extreme SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141ioa1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685979908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Sandisk Extreme portable SSD with movie files. What&amp;#39;s the best/most convenient way to password protect it or the files? Ideally it will be just as easy to navigate the files using Finder (macbook). I&amp;#39;ve looked at a bunch of blogs and youtube videos and nothing stands out to me as convenient, many use third-party apps. Thanks for your advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "141ioa1", "is_robot_indexable": true, "report_reasons": null, "author": "D-Delta", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141ioa1/best_way_to_password_protect_sandisk_extreme_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141ioa1/best_way_to_password_protect_sandisk_extreme_ssd/", "subreddit_subscribers": 686222, "created_utc": 1685979908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to test something.", "author_fullname": "t2_cqgnh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest and quickest way to use a lot of cellular 4g lte or 5g data on a smartphone or tablet ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_141s2xr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685999649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to test something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "141s2xr", "is_robot_indexable": true, "report_reasons": null, "author": "ng4ever", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/141s2xr/easiest_and_quickest_way_to_use_a_lot_of_cellular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/141s2xr/easiest_and_quickest_way_to_use_a_lot_of_cellular/", "subreddit_subscribers": 686222, "created_utc": 1685999649.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}