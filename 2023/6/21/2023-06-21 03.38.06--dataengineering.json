{"kind": "Listing", "data": {"after": "t3_14e21fm", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I went through an old pandas cookbook and repurposed it to use polars instead. I found it pretty useful when I was learning pandas years ago, so I hope that someone learning polars might find this useful as well.\n\n[https://github.com/escobar-west/polars-cookbook](https://github.com/escobar-west/polars-cookbook)", "author_fullname": "t2_66ap8fsy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars cookbook (Jupyter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e7vaz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 84, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 84, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687258385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I went through an old pandas cookbook and repurposed it to use polars instead. I found it pretty useful when I was learning pandas years ago, so I hope that someone learning polars might find this useful as well.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/escobar-west/polars-cookbook\"&gt;https://github.com/escobar-west/polars-cookbook&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?auto=webp&amp;v=enabled&amp;s=592362d1c4e339976f031d949bcc1a05e22b7f4e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3551613ff7b60b7c94377768ed8b29db850b055c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c12baf1254900af0b6d4859d2462846482a64f0c", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1ecc475611cdec786febf54611cb114ac4c474b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f548ffe1921b1738d0e018e1822449ebb6d0adb5", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aed4b7170a404fbf1fc4a7e55841af6218c3faa5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7VZpZQ57HO1gTZkw6mmxwjuCoyQg6FlFcLqgcrXv1UI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ed3855a516b45e30b6e9bdc5b1e936c412c51be", "width": 1080, "height": 540}], "variants": {}, "id": "KdRLT2C5kLn2x2fFkUb3xFufGFffpI8dU8lzcqi7mns"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14e7vaz", "is_robot_indexable": true, "report_reasons": null, "author": "Funny_Cantaloupe_240", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e7vaz/polars_cookbook_jupyter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e7vaz/polars_cookbook_jupyter/", "subreddit_subscribers": 111506, "created_utc": 1687258385.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know i might be asking something very general, but if you are thrown 5000 dashboards and asked to do a BI Modernization program, what 's the approach ?\n\nCollect the max hit dashboards\n\nCheck the datasources\n\nCheck the consumption pattern\n\nCheck the performance\n\nCheck if there are blending in the transformation \n\n&amp;#x200B;\n\nI wonder if there is a way to export the tableau metadata information to collect all of this, i am sure, there should be API's but i don't think i will get access to those\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to optimize 5000 dashboards ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e8nuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687260778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know i might be asking something very general, but if you are thrown 5000 dashboards and asked to do a BI Modernization program, what &amp;#39;s the approach ?&lt;/p&gt;\n\n&lt;p&gt;Collect the max hit dashboards&lt;/p&gt;\n\n&lt;p&gt;Check the datasources&lt;/p&gt;\n\n&lt;p&gt;Check the consumption pattern&lt;/p&gt;\n\n&lt;p&gt;Check the performance&lt;/p&gt;\n\n&lt;p&gt;Check if there are blending in the transformation &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is a way to export the tableau metadata information to collect all of this, i am sure, there should be API&amp;#39;s but i don&amp;#39;t think i will get access to those&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14e8nuu", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e8nuu/what_is_the_best_way_to_optimize_5000_dashboards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e8nuu/what_is_the_best_way_to_optimize_5000_dashboards/", "subreddit_subscribers": 111506, "created_utc": 1687260778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey /r/dataengineering \n\nWe are building a platform called [ShareData](https://sharedata.in) that helps multiple organisations collaborate on large datasets without moving data to a warehouse or datalake. Think of it more like source agnostic snowflake share or delta share. \n\nThe platform is installed on an instance or k8s cluster, and any data in your data stores can be queries by an external 3rd party, without creating pipelines or networking interfaces. \n\nif multiple parties are involved, the platform creates a mesh that can run a federated query such as this \n\n`SELECT entityA.postgres.userTable.name,\nentityB.mysql.customerTable.prodName,...`\n`FROM entityA.postgres.userTable`\n`INNER JOIN entityB.mysql.customerTable`\n`ON entityA.postgres.userTable.name =entityB.mysql.customerTable.customerName;`\n\nWe have been building for the past few months are looking for early adopters and feedback.\\\n\nEdit: Adding an image showing a possible use-case, one entity consuming data from 3 different entities without pipelines. \n\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502                             \u2502\n                           \u2502        Data consumer org    \u2502\n                           \u2502                             \u2502\n                           \u2502            API/JDBC         \u2502\n                           \u2502            \u250c\u2500\u2500\u2500\u2510            \u2502\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u253c\u253c\u253c\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502             \u2502            \u2502\u253c\u253c\u253c\u2502            \u2502                  \u2502\n             \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u253c\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n             \u2502                            \u2502                                 \u2502\n             \u2502                            \u2502                                 \u2502\n             \u2502                            \u2502                                 \u2502\n             \u2502                            \u2502                                 \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n    \u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n    \u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n    \u2502       Org 1      \u2502       \u2502        Org 2        \u2502           \u2502       Org 3        \u2502\n    \u2502 \u2500\u2500\u2510 \u2500\u2500\u2510 \u2500\u2500\u2510 \u2500\u2500\u2510  \u2502       \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510   \u2502           \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2510  \u2502\n    \u2502 DB\u2502 DB\u2502 DB\u2502 DB\u2502  \u2502       \u2502  \u2502     \u2502  \u2502     \u2502   \u2502           \u2502  \u2502     \u2502   \u2502    \u2502  \u2502\n    \u2502 \u250c\u2500\u2524 \u250c\u2500\u2524 \u250c\u2500\u2524 \u250c\u2500\u2524  \u2502       \u2502  \u2502 hive\u2502  \u2502 s3  \u2502   \u2502           \u2502  \u2502ADSL \u2502   \u2502Mongo  \u2502\n    \u2514\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2500\u2518       \u2514\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518", "author_fullname": "t2_v15080di", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback request: Multi-cloud, source agnostic, zero-copy data sharing platform.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dznoy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687241449.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687231697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;We are building a platform called &lt;a href=\"https://sharedata.in\"&gt;ShareData&lt;/a&gt; that helps multiple organisations collaborate on large datasets without moving data to a warehouse or datalake. Think of it more like source agnostic snowflake share or delta share. &lt;/p&gt;\n\n&lt;p&gt;The platform is installed on an instance or k8s cluster, and any data in your data stores can be queries by an external 3rd party, without creating pipelines or networking interfaces. &lt;/p&gt;\n\n&lt;p&gt;if multiple parties are involved, the platform creates a mesh that can run a federated query such as this &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT entityA.postgres.userTable.name,\nentityB.mysql.customerTable.prodName,...&lt;/code&gt;\n&lt;code&gt;FROM entityA.postgres.userTable&lt;/code&gt;\n&lt;code&gt;INNER JOIN entityB.mysql.customerTable&lt;/code&gt;\n&lt;code&gt;ON entityA.postgres.userTable.name =entityB.mysql.customerTable.customerName;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;We have been building for the past few months are looking for early adopters and feedback.\\&lt;/p&gt;\n\n&lt;p&gt;Edit: Adding an image showing a possible use-case, one entity consuming data from 3 different entities without pipelines. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502                             \u2502\n                       \u2502        Data consumer org    \u2502\n                       \u2502                             \u2502\n                       \u2502            API/JDBC         \u2502\n                       \u2502            \u250c\u2500\u2500\u2500\u2510            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u253c\u253c\u253c\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502             \u2502            \u2502\u253c\u253c\u253c\u2502            \u2502                  \u2502\n         \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u253c\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n         \u2502                            \u2502                                 \u2502\n         \u2502                            \u2502                                 \u2502\n         \u2502                            \u2502                                 \u2502\n         \u2502                            \u2502                                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n\u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n\u2502                  \u2502       \u2502                     \u2502           \u2502                    \u2502\n\u2502       Org 1      \u2502       \u2502        Org 2        \u2502           \u2502       Org 3        \u2502\n\u2502 \u2500\u2500\u2510 \u2500\u2500\u2510 \u2500\u2500\u2510 \u2500\u2500\u2510  \u2502       \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510   \u2502           \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502 DB\u2502 DB\u2502 DB\u2502 DB\u2502  \u2502       \u2502  \u2502     \u2502  \u2502     \u2502   \u2502           \u2502  \u2502     \u2502   \u2502    \u2502  \u2502\n\u2502 \u250c\u2500\u2524 \u250c\u2500\u2524 \u250c\u2500\u2524 \u250c\u2500\u2524  \u2502       \u2502  \u2502 hive\u2502  \u2502 s3  \u2502   \u2502           \u2502  \u2502ADSL \u2502   \u2502Mongo  \u2502\n\u2514\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2534\u2500\u2500\u2518       \u2514\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14dznoy", "is_robot_indexable": true, "report_reasons": null, "author": "I_eat_dosa", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14dznoy/feedback_request_multicloud_source_agnostic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14dznoy/feedback_request_multicloud_source_agnostic/", "subreddit_subscribers": 111506, "created_utc": 1687231697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey Folks - we're launching Gradient - Databricks optimization made easy! - It's free to try and we'd love your feedback!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14e8im0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/usasbrhyq57b1/DASH_480.mp4?source=fallback", "has_audio": true, "height": 446, "width": 854, "scrubber_media_url": "https://v.redd.it/usasbrhyq57b1/DASH_96.mp4", "dash_url": "https://v.redd.it/usasbrhyq57b1/DASHPlaylist.mpd?a=1689910686%2COTRjODhiODc3NzMwMjA5NmY5MTI3ODM2NGI1NjNmM2I0N2ZmNmE4ODllMTg0OGEyOTBiNjAwZDYzMWE1YWQ0YQ%3D%3D&amp;v=1&amp;f=sd", "duration": 60, "hls_url": "https://v.redd.it/usasbrhyq57b1/HLSPlaylist.m3u8?a=1689910686%2CMjNmNGQzNTE0YTFkODI4MTQ2MzFjMGQxNzAxYjUxNGUxNmM0NmMzYWQyNTMzMTI3YWMxZDQ0MDM2ZDVlMDMzMg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Q92Ssv2LudjvOktiio_8pVoW9X1XMGKjktrN3r0yYkc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687260320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/usasbrhyq57b1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bef5697ab1124c90b11d05547f5fb2f53e00804d", "width": 1200, "height": 626}, "resolutions": [{"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2c4000a654c87b77cf313439bf84382dec7f97ad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4441fd029ebcb6413bd3e65ad406e31cd2b14b5e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6832220ca63b977d53345351ff7695da347eda8f", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1e6ea20c8ceabbc13f0600b6a0bc58be9296da34", "width": 640, "height": 333}, {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=84f77dc25d2337e994fb293775e8e1b21c649706", "width": 960, "height": 500}, {"url": "https://external-preview.redd.it/mhbnSaCuoUQ71aTxzO2KAsvTknvmajQBRlNgXafDVIk.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b5d959e05dbd205955988ffa1e7eae14faa216f0", "width": 1080, "height": 563}], "variants": {}, "id": "24lvdrwJNcHoXGFsfU3jAmCdEWAqPGNGl12MQCyNFiY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14e8im0", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e8im0/hey_folks_were_launching_gradient_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/usasbrhyq57b1", "subreddit_subscribers": 111506, "created_utc": 1687260320.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/usasbrhyq57b1/DASH_480.mp4?source=fallback", "has_audio": true, "height": 446, "width": 854, "scrubber_media_url": "https://v.redd.it/usasbrhyq57b1/DASH_96.mp4", "dash_url": "https://v.redd.it/usasbrhyq57b1/DASHPlaylist.mpd?a=1689910686%2COTRjODhiODc3NzMwMjA5NmY5MTI3ODM2NGI1NjNmM2I0N2ZmNmE4ODllMTg0OGEyOTBiNjAwZDYzMWE1YWQ0YQ%3D%3D&amp;v=1&amp;f=sd", "duration": 60, "hls_url": "https://v.redd.it/usasbrhyq57b1/HLSPlaylist.m3u8?a=1689910686%2CMjNmNGQzNTE0YTFkODI4MTQ2MzFjMGQxNzAxYjUxNGUxNmM0NmMzYWQyNTMzMTI3YWMxZDQ0MDM2ZDVlMDMzMg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR: Looking for online partner to study Data Engineering stack with: Python, AWS, spark.\n\nOkay, so long story short is, my career is currently fucked up. I have 6 years of experience after passing out from a more than decent college. But all my experience has been, more or less, shitty work. You know, bug fixes, configurations, stuff like that. I never got to work as a proper developer, only doing support kind of stuff. No depth in any technology. It's my fault, I neglected my career for dating, travelling, engaging in other hobbies, etc.\nAnyway, rant over, moving on.\n\nNow, I work as an 'Operations Engineer'. Work is kind of similar to data engineer, so my senior suggested me that I prepare Python, AWS, spark, etc. you know the usual stack for Data Engineering on cloud, so that I can try to switch into that field.\n\nBut thing is, I get so demotivated whenever I start reading or practicing any code; there are like so many basics that I don't know. And I get depressed and guilty that how could I neglect all these things. And soon I give up; can't focus for more than 30 mins. That also half assed focus.\n\nHence, I am looking for an online partner, with whom I can study these things. I am not able to do it by myself, so I thought it would be worth posting here to see if anyone is interested, you know, to just get that extra motivation and enthu to put efforts.\nIdeally, I am looking for someone is also looking to get into data engineering with Python, AWS, pyspark, etc.\n\nThanks in advance.", "author_fullname": "t2_jl74ygnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a practice partner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e98lf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687262463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: Looking for online partner to study Data Engineering stack with: Python, AWS, spark.&lt;/p&gt;\n\n&lt;p&gt;Okay, so long story short is, my career is currently fucked up. I have 6 years of experience after passing out from a more than decent college. But all my experience has been, more or less, shitty work. You know, bug fixes, configurations, stuff like that. I never got to work as a proper developer, only doing support kind of stuff. No depth in any technology. It&amp;#39;s my fault, I neglected my career for dating, travelling, engaging in other hobbies, etc.\nAnyway, rant over, moving on.&lt;/p&gt;\n\n&lt;p&gt;Now, I work as an &amp;#39;Operations Engineer&amp;#39;. Work is kind of similar to data engineer, so my senior suggested me that I prepare Python, AWS, spark, etc. you know the usual stack for Data Engineering on cloud, so that I can try to switch into that field.&lt;/p&gt;\n\n&lt;p&gt;But thing is, I get so demotivated whenever I start reading or practicing any code; there are like so many basics that I don&amp;#39;t know. And I get depressed and guilty that how could I neglect all these things. And soon I give up; can&amp;#39;t focus for more than 30 mins. That also half assed focus.&lt;/p&gt;\n\n&lt;p&gt;Hence, I am looking for an online partner, with whom I can study these things. I am not able to do it by myself, so I thought it would be worth posting here to see if anyone is interested, you know, to just get that extra motivation and enthu to put efforts.\nIdeally, I am looking for someone is also looking to get into data engineering with Python, AWS, pyspark, etc.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14e98lf", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Device689", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e98lf/looking_for_a_practice_partner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e98lf/looking_for_a_practice_partner/", "subreddit_subscribers": 111506, "created_utc": 1687262463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The data project I am working handles several ingestion pipelines from server databases to azure. The whole thing runs on a daily basis and takes currently 3-4 hours.  In many situations I have the feeling that we have way to much overhead and many steps are unnecessary time consuming.  Recently I coded something and our current framework would need 30min for it. I quickly found the issue causing the time delay and proposed and adaption that would reduce the time to few minutes, but it was not the most beautiful approach tbh, but safe and without affecting the quality of the output. The senior dev just said there is no problem, as long as our pipeline runs within couple of hours there's no need to adapt anything. Additionally he didn't like the rather not-perfect approach.  Do you face similar issues that clean code is preferred over efficiency, causing the accumulation of huge overhead? Is it just normal, and I should simply shut up? Any advice how to deal with that?", "author_fullname": "t2_8etbdwvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clean code vs efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ehoy9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687282922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data project I am working handles several ingestion pipelines from server databases to azure. The whole thing runs on a daily basis and takes currently 3-4 hours.  In many situations I have the feeling that we have way to much overhead and many steps are unnecessary time consuming.  Recently I coded something and our current framework would need 30min for it. I quickly found the issue causing the time delay and proposed and adaption that would reduce the time to few minutes, but it was not the most beautiful approach tbh, but safe and without affecting the quality of the output. The senior dev just said there is no problem, as long as our pipeline runs within couple of hours there&amp;#39;s no need to adapt anything. Additionally he didn&amp;#39;t like the rather not-perfect approach.  Do you face similar issues that clean code is preferred over efficiency, causing the accumulation of huge overhead? Is it just normal, and I should simply shut up? Any advice how to deal with that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ehoy9", "is_robot_indexable": true, "report_reasons": null, "author": "Remote-Juice2527", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ehoy9/clean_code_vs_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ehoy9/clean_code_vs_efficiency/", "subreddit_subscribers": 111506, "created_utc": 1687282922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks! We have several ML pipelines based on PyTorch and Spark but the folks who worked on them aren't with us anymore. Our data scientists have been facing a bunch of issue refactoring/updating the algorithm, on top of that the code seems to be lacking some optimization specific to Spark.\n\nWe are a small shop and nobody's expert in Spark infra, we were considering a complete rewrite with Ray for ML as the compute engine as it seems to support just Python code. Interestingly we couldn't find that many materials online regarding it and the documentation is not enough. For example, we couldn't find a proper guideline to setup a test environment with Docker/Docker Compose.\n\nDid you use Ray and what was your experience, in comparison to the alternatives?", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ray for ML projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e2obe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687241081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks! We have several ML pipelines based on PyTorch and Spark but the folks who worked on them aren&amp;#39;t with us anymore. Our data scientists have been facing a bunch of issue refactoring/updating the algorithm, on top of that the code seems to be lacking some optimization specific to Spark.&lt;/p&gt;\n\n&lt;p&gt;We are a small shop and nobody&amp;#39;s expert in Spark infra, we were considering a complete rewrite with Ray for ML as the compute engine as it seems to support just Python code. Interestingly we couldn&amp;#39;t find that many materials online regarding it and the documentation is not enough. For example, we couldn&amp;#39;t find a proper guideline to setup a test environment with Docker/Docker Compose.&lt;/p&gt;\n\n&lt;p&gt;Did you use Ray and what was your experience, in comparison to the alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14e2obe", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14e2obe/ray_for_ml_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e2obe/ray_for_ml_projects/", "subreddit_subscribers": 111506, "created_utc": 1687241081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I was reading a [blog post](https://simmering.dev/blog/dataframes/) from 2021 comparing some python and R dataframe api libraries and I thought it was a truly valuable analysis worth revisiting in the present given some of the innovations I've heard of in this area lately. I'm hoping to spark (literally no pun intended) a thought-provoking discussion around the Python dataframe landscape and the tools and paradigms that are shaping our field today. As someone who works in SQL and Python and has worked across projects large and small using regular old pandas to frameworks like hadoop/hive, Spark, and many other big data tools under the sun, I consistently long to equip teams of engineers with a scalable dataframe API that can handle a variety of workloads and backends. I'm very curious about the theoretical and realized frameworks or emerging trends that are exciting and are pushing our field forward in terms of better, faster, and stronger dataframe programming APIs.\n\nImagine a project's priorities include both read and write efficiency with an emphasis on minimizing external dependencies and reducing the need for extensive infrastructure management. Endpoints for this hypothetical project could range from various SQL data warehouses (like PostgreSQL, MySQL, traditional RDBMS, etc.) to cloud native/file based rdbms systems (Snowflake, Duckdb) to different file systems (such as local and S3 blob storage, and possibly Azure Data Lake Storage - ADLS). For the sake of this discussion I was hoping to exclude Spark as an API due to its somewhat hefty infrastructure requirements (I've used it extensively across several platforms but in my experience non data developer/analyst adoption is too steep), but I can be convinced if someone makes a compelling argument that doesn't involve SaaS in the middle.\n\nThere are several common libraries like Pandas, Dask, and Polars that come to mind for dataframe manipulations, and then others like SQLAlchemy and Ibis for SQL interactions. But the questions I'm most interested in are:\n\n1. **Overlap &amp; Uniqueness:** Where do libraries and tools overlap, and where do they offer unique advantages? What are the abstract principles that would guide you when choosing one over the other, particularly regarding read and write operations? \n\n2. **Emerging Trends:** Are there any new or emerging libraries or tools that are exciting you? Maybe there's something that's not yet mainstream but could potentially be a game-changer? What do you hear on the streets of slack with fellow devs?\n\n3. **Theoretical Best Practices:** What theoretical considerations or best practices guide your decision-making when it comes to Python dataframe operations and SQL data warehouse interactions? Where should transformations take place?\n\n3. **Usability:** I hinted at this with my hot take on Spark already but I tend to believe that the best solution is one that is simple to use for the greatest number of people. Is there a case to be made for any new or old libraries for usability, extensibility, or other considerations around implementation and adoption by large numbers of developers and end users of different skill levels?\n\nUltimately the audience of this discussion is your fellow data engineers. Let's discuss!", "author_fullname": "t2_uqrd0850", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Dataframe APIs: If you had to start from scratch, which would you build with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e06dy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687233278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was reading a &lt;a href=\"https://simmering.dev/blog/dataframes/\"&gt;blog post&lt;/a&gt; from 2021 comparing some python and R dataframe api libraries and I thought it was a truly valuable analysis worth revisiting in the present given some of the innovations I&amp;#39;ve heard of in this area lately. I&amp;#39;m hoping to spark (literally no pun intended) a thought-provoking discussion around the Python dataframe landscape and the tools and paradigms that are shaping our field today. As someone who works in SQL and Python and has worked across projects large and small using regular old pandas to frameworks like hadoop/hive, Spark, and many other big data tools under the sun, I consistently long to equip teams of engineers with a scalable dataframe API that can handle a variety of workloads and backends. I&amp;#39;m very curious about the theoretical and realized frameworks or emerging trends that are exciting and are pushing our field forward in terms of better, faster, and stronger dataframe programming APIs.&lt;/p&gt;\n\n&lt;p&gt;Imagine a project&amp;#39;s priorities include both read and write efficiency with an emphasis on minimizing external dependencies and reducing the need for extensive infrastructure management. Endpoints for this hypothetical project could range from various SQL data warehouses (like PostgreSQL, MySQL, traditional RDBMS, etc.) to cloud native/file based rdbms systems (Snowflake, Duckdb) to different file systems (such as local and S3 blob storage, and possibly Azure Data Lake Storage - ADLS). For the sake of this discussion I was hoping to exclude Spark as an API due to its somewhat hefty infrastructure requirements (I&amp;#39;ve used it extensively across several platforms but in my experience non data developer/analyst adoption is too steep), but I can be convinced if someone makes a compelling argument that doesn&amp;#39;t involve SaaS in the middle.&lt;/p&gt;\n\n&lt;p&gt;There are several common libraries like Pandas, Dask, and Polars that come to mind for dataframe manipulations, and then others like SQLAlchemy and Ibis for SQL interactions. But the questions I&amp;#39;m most interested in are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Overlap &amp;amp; Uniqueness:&lt;/strong&gt; Where do libraries and tools overlap, and where do they offer unique advantages? What are the abstract principles that would guide you when choosing one over the other, particularly regarding read and write operations? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Emerging Trends:&lt;/strong&gt; Are there any new or emerging libraries or tools that are exciting you? Maybe there&amp;#39;s something that&amp;#39;s not yet mainstream but could potentially be a game-changer? What do you hear on the streets of slack with fellow devs?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Theoretical Best Practices:&lt;/strong&gt; What theoretical considerations or best practices guide your decision-making when it comes to Python dataframe operations and SQL data warehouse interactions? Where should transformations take place?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Usability:&lt;/strong&gt; I hinted at this with my hot take on Spark already but I tend to believe that the best solution is one that is simple to use for the greatest number of people. Is there a case to be made for any new or old libraries for usability, extensibility, or other considerations around implementation and adoption by large numbers of developers and end users of different skill levels?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Ultimately the audience of this discussion is your fellow data engineers. Let&amp;#39;s discuss!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14e06dy", "is_robot_indexable": true, "report_reasons": null, "author": "IncognitoEmployee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e06dy/python_dataframe_apis_if_you_had_to_start_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e06dy/python_dataframe_apis_if_you_had_to_start_from/", "subreddit_subscribers": 111506, "created_utc": 1687233278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings DEs!  \n\n\nI see a lot of discussions on tech stacks and standard DE items. I'm curious though if any of you have integrated any Data Governance tools or Master Data Management tools into those stacks and how you're utilizing them.  \n\n\nMy company is spending a lot of money for a DG tool right now that is not doing anything more than being a data catalog. There is no integration with it other than to simply show metadata of some of our sql server dbs.  Now there is a pitch to add an MDM tool to try to help identify accounts that may match between some of our disconnected systems. That's all well and good, but seems like yet another waste of money if that's the only use case we have for it.  \n\n\nIf you're using these tools, do you use them in conjunction with each other, or have some places to watch/read about how they may fit into the modern tech stack appropriately?  \n\n\nThanks,", "author_fullname": "t2_2v1p3nx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MDM and DG for Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eah32", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687265890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings DEs!  &lt;/p&gt;\n\n&lt;p&gt;I see a lot of discussions on tech stacks and standard DE items. I&amp;#39;m curious though if any of you have integrated any Data Governance tools or Master Data Management tools into those stacks and how you&amp;#39;re utilizing them.  &lt;/p&gt;\n\n&lt;p&gt;My company is spending a lot of money for a DG tool right now that is not doing anything more than being a data catalog. There is no integration with it other than to simply show metadata of some of our sql server dbs.  Now there is a pitch to add an MDM tool to try to help identify accounts that may match between some of our disconnected systems. That&amp;#39;s all well and good, but seems like yet another waste of money if that&amp;#39;s the only use case we have for it.  &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re using these tools, do you use them in conjunction with each other, or have some places to watch/read about how they may fit into the modern tech stack appropriately?  &lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Architect", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14eah32", "is_robot_indexable": true, "report_reasons": null, "author": "No-Current-7884", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14eah32/mdm_and_dg_for_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eah32/mdm_and_dg_for_engineers/", "subreddit_subscribers": 111506, "created_utc": 1687265890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say that you have thousands of Parquet files already stored on S3.\n\nThe schema is similar, but it is not identical for all the files. For example:\n\n* some may have some additional columns or less columns\n* rarely a column may be of different type (like a status column may be an integer but sometimes a string).\n\nIs it possible to use Trino (or similar) to query all the files in a directory on S3?\n\nLike `SELECT count(*) FROM /s3path/custom/2023/06/*.parquet WHERE status = 300`\n\nOr is it possible to give Trino (or similar) a long list of files on S3 to query dynamically?\n\nLike `SELECT count(*) FROM s3_file_1, s3_file_2, ... s3_file1000 WHERE status = 300`\n\nIdeally each query uses a different set of files (they are grouped in partitions), so it would be better to be able to execute the queries directly on a list of files, without having to perform too many intermediate steps.\n\nIs this possible with Trino? Or are there any other open source, distributed SQL engines that can do that?", "author_fullname": "t2_fsm2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trino (or similar SQL engines): is it possible to query many Parquet files stored on S3 with a single query?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e6t5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687254971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say that you have thousands of Parquet files already stored on S3.&lt;/p&gt;\n\n&lt;p&gt;The schema is similar, but it is not identical for all the files. For example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;some may have some additional columns or less columns&lt;/li&gt;\n&lt;li&gt;rarely a column may be of different type (like a status column may be an integer but sometimes a string).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is it possible to use Trino (or similar) to query all the files in a directory on S3?&lt;/p&gt;\n\n&lt;p&gt;Like &lt;code&gt;SELECT count(*) FROM /s3path/custom/2023/06/*.parquet WHERE status = 300&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Or is it possible to give Trino (or similar) a long list of files on S3 to query dynamically?&lt;/p&gt;\n\n&lt;p&gt;Like &lt;code&gt;SELECT count(*) FROM s3_file_1, s3_file_2, ... s3_file1000 WHERE status = 300&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Ideally each query uses a different set of files (they are grouped in partitions), so it would be better to be able to execute the queries directly on a list of files, without having to perform too many intermediate steps.&lt;/p&gt;\n\n&lt;p&gt;Is this possible with Trino? Or are there any other open source, distributed SQL engines that can do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14e6t5f", "is_robot_indexable": true, "report_reasons": null, "author": "collimarco", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e6t5f/trino_or_similar_sql_engines_is_it_possible_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e6t5f/trino_or_similar_sql_engines_is_it_possible_to/", "subreddit_subscribers": 111506, "created_utc": 1687254971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We just wrote a big ebook on choosing the right data integration tool, and I wanted to share one part I found particularly interesting: **The list of common requirements most companies** will encounter when looking for a new ETL/ EL tool.  \n\n\n*FWIW: We think it's best to* ***choose quickly*** *by covering the most important requirements in a couple of days at most. We don't think there is a \"right\" tool. That said, whatever you do to choose, always build something, always do a prototype; there's always something hidden between the lines (of code).* \n\n# Things that every company will need\n\n* If you choose a new data integration tool, ensure it is extensible (in any form! Paying for a new connector is ok!). Your data stack will simply look different in 6 months... prepare for that\n* Make sure it's easy on developers, really easy! 90% of the cost of data stacks is in developers maintaining it, not the fees for the tool itself. (In our experience, it might be very different for 1-person teams, though!)\n* The tool should have minimal lock-in! You will likely want to switch something within 6-12 months (maybe only the underlying data warehouse, but that might require you to switch the ETL tool as well)  \n\n\n# A list of potential requirements\n\nThis list is more of an inspiration to pick from.\n\n**Connectors**\n\n* Ability to source data from your production database.\n* Ability to target your analytics data warehouse.\n* Ability to target common data lakes (AWS S3,...)\n* A broad connector library (100+).\n* Connectors of high quality, where issues are fixed within one week for the company\u2019s most important 5 data sources.\n* Connector library needs to continue to grow. (1-2 new connectors should be added each month)\n* Ability to upgrade to paid support to fix connector bugs faster than one week.\n* Ability to build a connector yourself with some SDK.\n\n**Tools themselves**\n\n* The pricing model should be affordable for your company's workloads. Based on your current load + 50% more \"load\" (just 1.5x the data sources &amp; data volume to get an estimate)\n* Self-hosting option is available - to get off the ground quickly before switching to a managed service.\n* Onboarding time for a new data engineer should be 1-2 days max.\n* Testing &amp; versioning should be available for the extract &amp; load pipelines.\n* The tool should be able to run its pipelines against different environments (local testing, cloud testing, and the production env. at the minimum)\n* The tool should be HIPPA compliant.\n* The tool should be GDPR-compliant (EU).\n* The tool should be deployable into your company's secured internal network.\n* The tools need to be able to modify data to remove/mask/... personally identifiable information (PII) securely.\n\n**Tool environment**\n\n* The tool should have a partner network, including consultants, service partners, and implementation partners.\n* The tool should have robust documentation. There should be guides and plenty of examples of implementations on the internet.\n* The tool should have a strong community (e.g., on Slack, Forums, Reddit/Stackoverflow).\n* The tool should have decent general support getting feedback within an hour.\n\nIf you want to read the complete guide, it's [gated (sign up with mail) here](https://meltano.com/lp/5-day-data-integration-guide/). \n\n&amp;#x200B;\n\n*How about you? What would you add to the list? What would you remove from it?*  \n", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common requirements for choosing a data integration tool - a list, add yours!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e63i3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687252586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We just wrote a big ebook on choosing the right data integration tool, and I wanted to share one part I found particularly interesting: &lt;strong&gt;The list of common requirements most companies&lt;/strong&gt; will encounter when looking for a new ETL/ EL tool.  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;FWIW: We think it&amp;#39;s best to&lt;/em&gt; &lt;strong&gt;&lt;em&gt;choose quickly&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;by covering the most important requirements in a couple of days at most. We don&amp;#39;t think there is a &amp;quot;right&amp;quot; tool. That said, whatever you do to choose, always build something, always do a prototype; there&amp;#39;s always something hidden between the lines (of code).&lt;/em&gt; &lt;/p&gt;\n\n&lt;h1&gt;Things that every company will need&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If you choose a new data integration tool, ensure it is extensible (in any form! Paying for a new connector is ok!). Your data stack will simply look different in 6 months... prepare for that&lt;/li&gt;\n&lt;li&gt;Make sure it&amp;#39;s easy on developers, really easy! 90% of the cost of data stacks is in developers maintaining it, not the fees for the tool itself. (In our experience, it might be very different for 1-person teams, though!)&lt;/li&gt;\n&lt;li&gt;The tool should have minimal lock-in! You will likely want to switch something within 6-12 months (maybe only the underlying data warehouse, but that might require you to switch the ETL tool as well)&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;A list of potential requirements&lt;/h1&gt;\n\n&lt;p&gt;This list is more of an inspiration to pick from.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Connectors&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ability to source data from your production database.&lt;/li&gt;\n&lt;li&gt;Ability to target your analytics data warehouse.&lt;/li&gt;\n&lt;li&gt;Ability to target common data lakes (AWS S3,...)&lt;/li&gt;\n&lt;li&gt;A broad connector library (100+).&lt;/li&gt;\n&lt;li&gt;Connectors of high quality, where issues are fixed within one week for the company\u2019s most important 5 data sources.&lt;/li&gt;\n&lt;li&gt;Connector library needs to continue to grow. (1-2 new connectors should be added each month)&lt;/li&gt;\n&lt;li&gt;Ability to upgrade to paid support to fix connector bugs faster than one week.&lt;/li&gt;\n&lt;li&gt;Ability to build a connector yourself with some SDK.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tools themselves&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The pricing model should be affordable for your company&amp;#39;s workloads. Based on your current load + 50% more &amp;quot;load&amp;quot; (just 1.5x the data sources &amp;amp; data volume to get an estimate)&lt;/li&gt;\n&lt;li&gt;Self-hosting option is available - to get off the ground quickly before switching to a managed service.&lt;/li&gt;\n&lt;li&gt;Onboarding time for a new data engineer should be 1-2 days max.&lt;/li&gt;\n&lt;li&gt;Testing &amp;amp; versioning should be available for the extract &amp;amp; load pipelines.&lt;/li&gt;\n&lt;li&gt;The tool should be able to run its pipelines against different environments (local testing, cloud testing, and the production env. at the minimum)&lt;/li&gt;\n&lt;li&gt;The tool should be HIPPA compliant.&lt;/li&gt;\n&lt;li&gt;The tool should be GDPR-compliant (EU).&lt;/li&gt;\n&lt;li&gt;The tool should be deployable into your company&amp;#39;s secured internal network.&lt;/li&gt;\n&lt;li&gt;The tools need to be able to modify data to remove/mask/... personally identifiable information (PII) securely.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Tool environment&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The tool should have a partner network, including consultants, service partners, and implementation partners.&lt;/li&gt;\n&lt;li&gt;The tool should have robust documentation. There should be guides and plenty of examples of implementations on the internet.&lt;/li&gt;\n&lt;li&gt;The tool should have a strong community (e.g., on Slack, Forums, Reddit/Stackoverflow).&lt;/li&gt;\n&lt;li&gt;The tool should have decent general support getting feedback within an hour.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you want to read the complete guide, it&amp;#39;s &lt;a href=\"https://meltano.com/lp/5-day-data-integration-guide/\"&gt;gated (sign up with mail) here&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;How about you? What would you add to the list? What would you remove from it?&lt;/em&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?auto=webp&amp;v=enabled&amp;s=24ab8392447b05ee349b4542ce1b4248af9b6a9a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a1d9de48faefd16bbe9d2e8ac9eb94796785b0b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=316a339d46b08eb224726edca015c35714e0bf11", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbd2e2ae91f794048cf4e427104d75a520b14206", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a55cd5be0f83a8767073be9f07437fdaf6135547", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e68e3abd4e307230bc10c5de32b24395b255a0d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Avl47kjVL8ZM92aZQxYRYA_YBrzP_59zXfpIRCFQg5E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=026f254b4848178436734efa24b977d0a46c23a4", "width": 1080, "height": 567}], "variants": {}, "id": "8KWDQ8KYENJxOXHCIU4W7z2CqjsF4-NMjniSkKD_kEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14e63i3", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e63i3/common_requirements_for_choosing_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e63i3/common_requirements_for_choosing_a_data/", "subreddit_subscribers": 111506, "created_utc": 1687252586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIs writing articles about DE (and relevant domains) a good and valuable way to position yourself for X, where X can be:\n\n\\- promotion  \n\\- attracting recruiters  \n\\- leadership role  \n\\- establishing oneself as an expert  \n\\- showing you enjoy/want to be a mentor  \n\\- other reasons\n\nDoes it add credibility? Obviously it's not a replacement for actual experience, but would this open more doors or other doors that perhaps might have stayed closed?\n\nLove to hear professionals here that went that route and what your experiences are? Did you benefit at all, or did it hurt your career? Any tips, advice, do's and don'ts that you like to share?\n\nThank you.", "author_fullname": "t2_kh3ubtce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing articles to position yourself for X", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14efjv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687278141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Is writing articles about DE (and relevant domains) a good and valuable way to position yourself for X, where X can be:&lt;/p&gt;\n\n&lt;p&gt;- promotion&lt;br/&gt;\n- attracting recruiters&lt;br/&gt;\n- leadership role&lt;br/&gt;\n- establishing oneself as an expert&lt;br/&gt;\n- showing you enjoy/want to be a mentor&lt;br/&gt;\n- other reasons&lt;/p&gt;\n\n&lt;p&gt;Does it add credibility? Obviously it&amp;#39;s not a replacement for actual experience, but would this open more doors or other doors that perhaps might have stayed closed?&lt;/p&gt;\n\n&lt;p&gt;Love to hear professionals here that went that route and what your experiences are? Did you benefit at all, or did it hurt your career? Any tips, advice, do&amp;#39;s and don&amp;#39;ts that you like to share?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14efjv4", "is_robot_indexable": true, "report_reasons": null, "author": "SquidsAndMartians", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14efjv4/writing_articles_to_position_yourself_for_x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14efjv4/writing_articles_to_position_yourself_for_x/", "subreddit_subscribers": 111506, "created_utc": 1687278141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Current situation**\n\nJob title: Data engineer, but I'm really an analytics engineer doing mostly custom batch ETL, report automation, prepping data for analysts.\n\nExperience: 2 years; switched from unrelated career\n\nLocation: USA\n\nCompensation: $100k (+$5k profit sharing bonus when possible)\n\nSkills:\n\n* Programming: Python (good), SQL (good), Linux shell (enough to get around), Git (enough)\n\n* Other tech: AWS, Airflow, Postgres, Docker, Pandas, BI tools\n\n* Knowledge: Data modeling (dimensional, normalization), data management (observability, lineage, alerting, etc.), query optimization, SWE design &amp; best practices (self taught here though without much team experience)\n\n* Other info: I have a security clearance\n\n* Concerns: I don't feel there's much room for advancement in my current position. Additionally, the only \"senior data engineer\" on our team works separately from me and from what I gather I wouldn't learn a ton from him anyway. Because of this, I don't feel that I'm getting as much mentorship as I should as someone with 2 YOE.\n\n**Goals**\n\nI'm sure this will sound rather vain to the community of geniuses on this sub (srs), but my main objective is to get into the ~$180k+ range in the next 5 years or so, preferably working for someone else.\n\nI'm a competitive nerd at heart, and in my previous career I over-optimized for technical skill and under-optimized for money. I love working with data, and I know I could easily spend a decade going deep on distributed computing, devops / IaC, database internals, etc.\n\nBut personally, I'm not interested in obsessing over the micro aspects of my craft anymore. I'm in my 30s, have a social / family life, and want to enjoy that with as little financial stress as possible.\n\n**Career plan**\n\nI don't know exactly what I want to do, which is why I'm posting. Some initial thoughts:\n\n* My \"moats\": I'm an American with a security clearance. I'm likeable, can converse about whatever. I'm very logical and a good big picture thinker. Good at explaining things in easy to understand ways when I'm prepared well.\n\n* Based on these, I'm thinking a couple decent career directions might be enterprise sales engineer or solutions architect. **What do you think about these? Please recommend other stuff that could be a good fit!**\n\n**Path forward**\n\n* While I don't want to over-optimize for technical skill, I know I still have much to learn to be a competent architect and even engineer. I plan on building a personal project using stream architecture/processing, Spark, containers, simple CI/CD pipeline.\n\n* On the soft skills side, I want to get really good at whiteboarding, speaking confidently / voice projection, being persuasive, presenting in general\n\n**Strategy**\n\nFinally, I want to lay out what I'm thinking as a medium-term strategy. \n\n* Interview for customer-facing mid-level and hopefully get a 20%-ish pay bump and yearly raises. Hopefully get some CRM and sales calls exposure in this role.\n\n* Keep leveling up my skillsets\n\n* Attempt to land a SE / SA role (or something else?) after a few years\n\nThanks for reading. Please poke holes in my plan and offer advice or future job suggestions =]", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's my next move?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14egko0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687280422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Current situation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Job title: Data engineer, but I&amp;#39;m really an analytics engineer doing mostly custom batch ETL, report automation, prepping data for analysts.&lt;/p&gt;\n\n&lt;p&gt;Experience: 2 years; switched from unrelated career&lt;/p&gt;\n\n&lt;p&gt;Location: USA&lt;/p&gt;\n\n&lt;p&gt;Compensation: $100k (+$5k profit sharing bonus when possible)&lt;/p&gt;\n\n&lt;p&gt;Skills:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Programming: Python (good), SQL (good), Linux shell (enough to get around), Git (enough)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other tech: AWS, Airflow, Postgres, Docker, Pandas, BI tools&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Knowledge: Data modeling (dimensional, normalization), data management (observability, lineage, alerting, etc.), query optimization, SWE design &amp;amp; best practices (self taught here though without much team experience)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other info: I have a security clearance&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Concerns: I don&amp;#39;t feel there&amp;#39;s much room for advancement in my current position. Additionally, the only &amp;quot;senior data engineer&amp;quot; on our team works separately from me and from what I gather I wouldn&amp;#39;t learn a ton from him anyway. Because of this, I don&amp;#39;t feel that I&amp;#39;m getting as much mentorship as I should as someone with 2 YOE.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure this will sound rather vain to the community of geniuses on this sub (srs), but my main objective is to get into the ~$180k+ range in the next 5 years or so, preferably working for someone else.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a competitive nerd at heart, and in my previous career I over-optimized for technical skill and under-optimized for money. I love working with data, and I know I could easily spend a decade going deep on distributed computing, devops / IaC, database internals, etc.&lt;/p&gt;\n\n&lt;p&gt;But personally, I&amp;#39;m not interested in obsessing over the micro aspects of my craft anymore. I&amp;#39;m in my 30s, have a social / family life, and want to enjoy that with as little financial stress as possible.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Career plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know exactly what I want to do, which is why I&amp;#39;m posting. Some initial thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;My &amp;quot;moats&amp;quot;: I&amp;#39;m an American with a security clearance. I&amp;#39;m likeable, can converse about whatever. I&amp;#39;m very logical and a good big picture thinker. Good at explaining things in easy to understand ways when I&amp;#39;m prepared well.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Based on these, I&amp;#39;m thinking a couple decent career directions might be enterprise sales engineer or solutions architect. &lt;strong&gt;What do you think about these? Please recommend other stuff that could be a good fit!&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Path forward&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;While I don&amp;#39;t want to over-optimize for technical skill, I know I still have much to learn to be a competent architect and even engineer. I plan on building a personal project using stream architecture/processing, Spark, containers, simple CI/CD pipeline.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;On the soft skills side, I want to get really good at whiteboarding, speaking confidently / voice projection, being persuasive, presenting in general&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Strategy&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Finally, I want to lay out what I&amp;#39;m thinking as a medium-term strategy. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Interview for customer-facing mid-level and hopefully get a 20%-ish pay bump and yearly raises. Hopefully get some CRM and sales calls exposure in this role.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Keep leveling up my skillsets&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Attempt to land a SE / SA role (or something else?) after a few years&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks for reading. Please poke holes in my plan and offer advice or future job suggestions =]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14egko0", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14egko0/whats_my_next_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14egko0/whats_my_next_move/", "subreddit_subscribers": 111506, "created_utc": 1687280422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI am in the process of transitioning into Data Engineering. For context, I have a mechanical engineering degree and business masters degree from a reputable university and have worked as an engineer for a large supply chain/logistics/transportation company for a couple of years now. In my current role, I do a good bit of data analytics, although mainly using lower-level tools. In my free time, I have taken to learning Python (including pandas, NumPy, etc.) via online tutorials and text books and have implemented this in my current role by working on miscellaneous \"sandbox\" projects. I have also gained a fundamental understanding of database design and SQL and am taking some online trainings for Databricks.\n\nAm I crazy to think that I can pivot careers through my own dedication rather than seeking an additional degree? I am a technical learner and am dedicated to growing my knowledge gradually, but the terminology and vast number of tools can seem overwhelming at times. If it is possible to pivot on my own, does anyone have recommendations for materials/tutorials/online courses to grow my knowledge in ETL pipelines, distributed computing (Hadoop, Spark, etc.), and other cloud tools? I plan on working my way slowly through some of the recommendations from this subreddit's Learning Resources section. Apologies for the long post. Any advice is much appreciated in advance!\n\nThanks, all!", "author_fullname": "t2_5tzzasmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Pivot Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14etouq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687311357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am in the process of transitioning into Data Engineering. For context, I have a mechanical engineering degree and business masters degree from a reputable university and have worked as an engineer for a large supply chain/logistics/transportation company for a couple of years now. In my current role, I do a good bit of data analytics, although mainly using lower-level tools. In my free time, I have taken to learning Python (including pandas, NumPy, etc.) via online tutorials and text books and have implemented this in my current role by working on miscellaneous &amp;quot;sandbox&amp;quot; projects. I have also gained a fundamental understanding of database design and SQL and am taking some online trainings for Databricks.&lt;/p&gt;\n\n&lt;p&gt;Am I crazy to think that I can pivot careers through my own dedication rather than seeking an additional degree? I am a technical learner and am dedicated to growing my knowledge gradually, but the terminology and vast number of tools can seem overwhelming at times. If it is possible to pivot on my own, does anyone have recommendations for materials/tutorials/online courses to grow my knowledge in ETL pipelines, distributed computing (Hadoop, Spark, etc.), and other cloud tools? I plan on working my way slowly through some of the recommendations from this subreddit&amp;#39;s Learning Resources section. Apologies for the long post. Any advice is much appreciated in advance!&lt;/p&gt;\n\n&lt;p&gt;Thanks, all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14etouq", "is_robot_indexable": true, "report_reasons": null, "author": "SmeagolsPrecious_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14etouq/career_pivot_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14etouq/career_pivot_advice/", "subreddit_subscribers": 111506, "created_utc": 1687311357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks.\nI pretend to learn data engineering. I\u2019m already in Data Analytics field. Which is the order I should learn those books:\n\n* The data Warehouse toolkit\n* The kimball group reader\n* designing data intensive applications \n* Fundamentals of data engineering \n* T-SQL fundamentals \n* T-SQL Querying\n\nThanks in advanced", "author_fullname": "t2_bnqvpnvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ebooks order to read", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eqed6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687302424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks.\nI pretend to learn data engineering. I\u2019m already in Data Analytics field. Which is the order I should learn those books:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The data Warehouse toolkit&lt;/li&gt;\n&lt;li&gt;The kimball group reader&lt;/li&gt;\n&lt;li&gt;designing data intensive applications &lt;/li&gt;\n&lt;li&gt;Fundamentals of data engineering &lt;/li&gt;\n&lt;li&gt;T-SQL fundamentals &lt;/li&gt;\n&lt;li&gt;T-SQL Querying&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advanced&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14eqed6", "is_robot_indexable": true, "report_reasons": null, "author": "Mr-Wedge01", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14eqed6/ebooks_order_to_read/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eqed6/ebooks_order_to_read/", "subreddit_subscribers": 111506, "created_utc": 1687302424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am half Japanese, speak the language good (can have long discussions over various topics) along with family in Japan. \n\nI am considering the possibility of trying to offer some data architecture services in Japan for businesses. I understand the work culture is a lot more conservative than the US.\n\nCurrently, am a US citizen. I also have been a data architect the past 6 years with consulting experience. Id like to still be based in the US, but can definetly travel for work.\n\nWould appreciate anyones thoughts on this.", "author_fullname": "t2_l1vnoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Consulting work in Japan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14emrtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687294180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am half Japanese, speak the language good (can have long discussions over various topics) along with family in Japan. &lt;/p&gt;\n\n&lt;p&gt;I am considering the possibility of trying to offer some data architecture services in Japan for businesses. I understand the work culture is a lot more conservative than the US.&lt;/p&gt;\n\n&lt;p&gt;Currently, am a US citizen. I also have been a data architect the past 6 years with consulting experience. Id like to still be based in the US, but can definetly travel for work.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate anyones thoughts on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14emrtx", "is_robot_indexable": true, "report_reasons": null, "author": "Paulythress", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14emrtx/thoughts_on_consulting_work_in_japan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14emrtx/thoughts_on_consulting_work_in_japan/", "subreddit_subscribers": 111506, "created_utc": 1687294180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I follow a lot of podcasts, LinkedIn personalities and some blogs and reddits that talk about Data Engineering tools and practices. I rarely (if ever?) hear any discussion on ADF as a tool within the data ecosystem, the state of it, pros and cons, etc. However, working as a consultant (Sweden based) ADF is a sought after tool to master, generally.\n\nCan anyone shed some light on why this is? \n\nWhat is the general opinion in the DE community on ADF?", "author_fullname": "t2_2iwhn32y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE community opinion on Azure Data Factory?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e4jra", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687247347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I follow a lot of podcasts, LinkedIn personalities and some blogs and reddits that talk about Data Engineering tools and practices. I rarely (if ever?) hear any discussion on ADF as a tool within the data ecosystem, the state of it, pros and cons, etc. However, working as a consultant (Sweden based) ADF is a sought after tool to master, generally.&lt;/p&gt;\n\n&lt;p&gt;Can anyone shed some light on why this is? &lt;/p&gt;\n\n&lt;p&gt;What is the general opinion in the DE community on ADF?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14e4jra", "is_robot_indexable": true, "report_reasons": null, "author": "yeykawb", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e4jra/de_community_opinion_on_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e4jra/de_community_opinion_on_azure_data_factory/", "subreddit_subscribers": 111506, "created_utc": 1687247347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nI am looking for some tutorial where I can see the step by step working of Hbase, from installation to creating the cluster and pipeline working till the final output along with following the steps on my local machine. \n\nIf anyone can suggest me any videos on YouTube or Udemy, I\u2019d really appreciate that.\n\nMany thanks in advance!", "author_fullname": "t2_75qrazx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tutorials for Hbase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e39xm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687243018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I am looking for some tutorial where I can see the step by step working of Hbase, from installation to creating the cluster and pipeline working till the final output along with following the steps on my local machine. &lt;/p&gt;\n\n&lt;p&gt;If anyone can suggest me any videos on YouTube or Udemy, I\u2019d really appreciate that.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14e39xm", "is_robot_indexable": true, "report_reasons": null, "author": "rshikhahim", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e39xm/tutorials_for_hbase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e39xm/tutorials_for_hbase/", "subreddit_subscribers": 111506, "created_utc": 1687243018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How good is your prod and dev environment seggregated for code and data?\nFor data, we do once a week sync from prod to dev. \nFor code, we handle different config in code base using if else. \nAre there any tools and efficient ways to do?", "author_fullname": "t2_6zaja793", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prod and Dev", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eexja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687276723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How good is your prod and dev environment seggregated for code and data?\nFor data, we do once a week sync from prod to dev. \nFor code, we handle different config in code base using if else. \nAre there any tools and efficient ways to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14eexja", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious_Cucumber96", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14eexja/prod_and_dev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eexja/prod_and_dev/", "subreddit_subscribers": 111506, "created_utc": 1687276723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So one of my customers is about to replace the hardware in their 16 server cluster, they have no rack space so we cant turn up a second cluster with the new hardware. We only have 4 days with someone who will be in the data center. Is it possible to just rsync all of the HDFS files/name/checkpoint from the old servers to the new servers as we turn them up to reduce the amount of time it would take to sync hdfs replications across the cluster?", "author_fullname": "t2_zb22f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Possible to rsync HDFS files to new server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ee1gm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687274604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So one of my customers is about to replace the hardware in their 16 server cluster, they have no rack space so we cant turn up a second cluster with the new hardware. We only have 4 days with someone who will be in the data center. Is it possible to just rsync all of the HDFS files/name/checkpoint from the old servers to the new servers as we turn them up to reduce the amount of time it would take to sync hdfs replications across the cluster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ee1gm", "is_robot_indexable": true, "report_reasons": null, "author": "iamthemadz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ee1gm/possible_to_rsync_hdfs_files_to_new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ee1gm/possible_to_rsync_hdfs_files_to_new_server/", "subreddit_subscribers": 111506, "created_utc": 1687274604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am inheriting a workflow that is using EMR to transform json to parquet which is then sourced to s3. Once there redshift can update some physical tables and then the data will remain in the data lake in s3. \n\nLately the volume of data has increased and the EMR process is struggling. \n\nI am looking at new options for refactoring this process for performance. \nWhat can I improve here?", "author_fullname": "t2_apr0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to handle flattening and parquet conversion of thousands of JSON files daily", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eb1x9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687267386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am inheriting a workflow that is using EMR to transform json to parquet which is then sourced to s3. Once there redshift can update some physical tables and then the data will remain in the data lake in s3. &lt;/p&gt;\n\n&lt;p&gt;Lately the volume of data has increased and the EMR process is struggling. &lt;/p&gt;\n\n&lt;p&gt;I am looking at new options for refactoring this process for performance. \nWhat can I improve here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14eb1x9", "is_robot_indexable": true, "report_reasons": null, "author": "sghokie", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14eb1x9/best_way_to_handle_flattening_and_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eb1x9/best_way_to_handle_flattening_and_parquet/", "subreddit_subscribers": 111506, "created_utc": 1687267386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote this article:  \n[https://medium.com/@lgsoliveira/three-alternatives-to-pandas-polars-and-pyspark-to-work-with-data-in-python-153f7cb0c3e5](https://medium.com/@lgsoliveira/three-alternatives-to-pandas-polars-and-pyspark-to-work-with-data-in-python-153f7cb0c3e5)\n\nWHAT IS IT? An article showing 3 alternatives to work with dataframes in Python\n\nWHO IS IT FOR? For all data professionals working with Python\n\nWHY IS IT RELEVANT? Because it is important to be on top of the programming benchmark  \n\n\nWhat it is your opinion? Do you just work with Pandas?   \nDo you use all the 6 libraries? ", "author_fullname": "t2_7dy3sswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your opinion which are the best alternatives to Pandas,Polars and PySpark to work with dataframes in Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e6et1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687253651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote this article:&lt;br/&gt;\n&lt;a href=\"https://medium.com/@lgsoliveira/three-alternatives-to-pandas-polars-and-pyspark-to-work-with-data-in-python-153f7cb0c3e5\"&gt;https://medium.com/@lgsoliveira/three-alternatives-to-pandas-polars-and-pyspark-to-work-with-data-in-python-153f7cb0c3e5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;WHAT IS IT? An article showing 3 alternatives to work with dataframes in Python&lt;/p&gt;\n\n&lt;p&gt;WHO IS IT FOR? For all data professionals working with Python&lt;/p&gt;\n\n&lt;p&gt;WHY IS IT RELEVANT? Because it is important to be on top of the programming benchmark  &lt;/p&gt;\n\n&lt;p&gt;What it is your opinion? Do you just work with Pandas?&lt;br/&gt;\nDo you use all the 6 libraries? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?auto=webp&amp;v=enabled&amp;s=9148a0e35c7a2733ea8a4e1e33b647d6233ba3a6", "width": 1000, "height": 667}, "resolutions": [{"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86aa5d40cc5ad33282e6d729f8d0f82f9e8f5a90", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f0c370b8292604c456b0da73803cfb673c8d1df", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=784544441a53e9ed0d62cb60933aa125646f2fdb", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=693df60bdc73b4c8335784ab2025bd08c396891c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/CvtyQGe90aWnFgEueYlLDnGGbmZwg_A10UHs8yrabwI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cee3dac4dad54bce290e7ebc5815004a32897233", "width": 960, "height": 640}], "variants": {}, "id": "oacwr2bYsutSy_UiCIhkrYVI_T49ZJsN-UpknlFXPG0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14e6et1", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Organization7", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e6et1/in_your_opinion_which_are_the_best_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e6et1/in_your_opinion_which_are_the_best_alternatives/", "subreddit_subscribers": 111506, "created_utc": 1687253651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ah the joys of the Postgres vector extension.", "author_fullname": "t2_ltzfd6pc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use BERT to spot inaccuracies in DAX", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_14e3y8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TYPTlPSwLaqP_cPRcSZS6RB7c7aZiwNKNs5bKnZ3N-4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687245270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ah the joys of the Postgres vector extension.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qsuxth8gi47b1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?auto=webp&amp;v=enabled&amp;s=2d29afea272362f1d5c9dccb5cbfef0a6b141b2f", "width": 2366, "height": 1169}, "resolutions": [{"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d5630f02c561a3b91ba97e58597d5a94bf4306", "width": 108, "height": 53}, {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9900550d9a2f6eba40e3bcce42d1e46a62e238b6", "width": 216, "height": 106}, {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7020dd7170b1471aec9b1864af32e9876e8c5cf", "width": 320, "height": 158}, {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44ab26ad4cf06871fca931ffed25742e140d00a0", "width": 640, "height": 316}, {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9d719a831d0813bb60ce1eba532045e74be8ddc", "width": 960, "height": 474}, {"url": "https://preview.redd.it/qsuxth8gi47b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=899162227a0cf91080bfd2614a57eca848ba4e0b", "width": 1080, "height": 533}], "variants": {}, "id": "jykZ5hq2WUkC8wQa2eAJxiAEJiBzRAUwBqAMjguj744"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14e3y8v", "is_robot_indexable": true, "report_reasons": null, "author": "FactMuncher", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e3y8v/use_bert_to_spot_inaccuracies_in_dax/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qsuxth8gi47b1.jpg", "subreddit_subscribers": 111506, "created_utc": 1687245270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been thinking a lot about the tough problem of validating ETLS. \n\nI've found that standardized or automated checks can only do so much. Checking for things like duplicates and row ranges can be helpful, but will not work completely and could event give a false sense of security.\n\nUltimately we must check that the ETL logic matches business intention and this is very difficult to do in an automated or standardized way.\n\nThese errors are often tough to discover, but very important to discover as early as possible. It is not as simple as something will not be working. The job could run for a long time without error but with incorrect data.\u00a0\n\nMain issues that can arise with checking the ETL against business logic logic:\n\n1. can be put in wrong with the wrong intention\n   - ex: engineer thought that the definition of \u201cview\u201d in the event table was different then it was) \n2. There can be because there was a mistake in the code which foils the business intention\n   - ex: there is a left join applied with a where clause that makes the join equivalent to an inner join and filters out data which should not be filtered out\n\nFor #1, that is best resolved in code review, involvement with product, and checking the table against similar metrics in other tables if they exist.\n\nFor #2, for me this involves recreating portions of the ETL in a way which I believe that should match the logic of the ETL and checking it against my test table. If there is a discrepancy between the ETL rows and the test rows, I investigate/fix the side with the errors until the data matches.\n\nThis is a very time consuming and painstaking process, but I have found is the best way to prevent errors of this type. \n\n\n- Do these complaints ring true to you? \n\n- How do you solve the problem #2? Is there any standardized or automated way to do this that you have found helpful/less time consuming?\n\n- What tools do you use for initial data validation for problem #2? I use databricks notebooks to recreate the ETL and compare against my test table, but I am interested to see how common this is.", "author_fullname": "t2_uyst4agu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The problem of data validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e33qm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687277108.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687242469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been thinking a lot about the tough problem of validating ETLS. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found that standardized or automated checks can only do so much. Checking for things like duplicates and row ranges can be helpful, but will not work completely and could event give a false sense of security.&lt;/p&gt;\n\n&lt;p&gt;Ultimately we must check that the ETL logic matches business intention and this is very difficult to do in an automated or standardized way.&lt;/p&gt;\n\n&lt;p&gt;These errors are often tough to discover, but very important to discover as early as possible. It is not as simple as something will not be working. The job could run for a long time without error but with incorrect data.\u00a0&lt;/p&gt;\n\n&lt;p&gt;Main issues that can arise with checking the ETL against business logic logic:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;can be put in wrong with the wrong intention\n\n&lt;ul&gt;\n&lt;li&gt;ex: engineer thought that the definition of \u201cview\u201d in the event table was different then it was) &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;There can be because there was a mistake in the code which foils the business intention\n\n&lt;ul&gt;\n&lt;li&gt;ex: there is a left join applied with a where clause that makes the join equivalent to an inner join and filters out data which should not be filtered out&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For #1, that is best resolved in code review, involvement with product, and checking the table against similar metrics in other tables if they exist.&lt;/p&gt;\n\n&lt;p&gt;For #2, for me this involves recreating portions of the ETL in a way which I believe that should match the logic of the ETL and checking it against my test table. If there is a discrepancy between the ETL rows and the test rows, I investigate/fix the side with the errors until the data matches.&lt;/p&gt;\n\n&lt;p&gt;This is a very time consuming and painstaking process, but I have found is the best way to prevent errors of this type. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Do these complaints ring true to you? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you solve the problem #2? Is there any standardized or automated way to do this that you have found helpful/less time consuming?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;What tools do you use for initial data validation for problem #2? I use databricks notebooks to recreate the ETL and compare against my test table, but I am interested to see how common this is.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14e33qm", "is_robot_indexable": true, "report_reasons": null, "author": "The_Data_Man", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e33qm/the_problem_of_data_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e33qm/the_problem_of_data_validation/", "subreddit_subscribers": 111506, "created_utc": 1687242469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm currently working in Seattle with a TC around 185k and I'm trying to gauge how much people are getting paid for their DE roles in the area. My YOE is about 9 years but I've only been working in DE for almost 2 years.  \n\n\nI'm more of a \"Cloud Engineer\" if you will as my day-to-day includes working with Terraform, AWS Glue, Lake Formation, Athena, S3. I work mainly on IaC and less actual data wrangling/data pipelines. I make sure the blueprints to build the infrastructure is there for the clients to follow through in-house Terraform modules.  \n\n\nI also worked on building some REST APIs utilizing AWS API GW, Step Function, Lambda, &amp; DynamoDB as well which was a bit more coding with Python along with IaC.\n\nWith that said, does anyone have any advice on a potential career path I can try to follow with my current skill set/experience and what range in salary can be expected from it?", "author_fullname": "t2_97h3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Path Suggestions &amp; TC Gauge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14e21fm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687239101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working in Seattle with a TC around 185k and I&amp;#39;m trying to gauge how much people are getting paid for their DE roles in the area. My YOE is about 9 years but I&amp;#39;ve only been working in DE for almost 2 years.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m more of a &amp;quot;Cloud Engineer&amp;quot; if you will as my day-to-day includes working with Terraform, AWS Glue, Lake Formation, Athena, S3. I work mainly on IaC and less actual data wrangling/data pipelines. I make sure the blueprints to build the infrastructure is there for the clients to follow through in-house Terraform modules.  &lt;/p&gt;\n\n&lt;p&gt;I also worked on building some REST APIs utilizing AWS API GW, Step Function, Lambda, &amp;amp; DynamoDB as well which was a bit more coding with Python along with IaC.&lt;/p&gt;\n\n&lt;p&gt;With that said, does anyone have any advice on a potential career path I can try to follow with my current skill set/experience and what range in salary can be expected from it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14e21fm", "is_robot_indexable": true, "report_reasons": null, "author": "rkwong792", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14e21fm/career_path_suggestions_tc_gauge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14e21fm/career_path_suggestions_tc_gauge/", "subreddit_subscribers": 111506, "created_utc": 1687239101.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}