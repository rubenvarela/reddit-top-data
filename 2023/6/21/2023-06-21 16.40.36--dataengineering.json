{"kind": "Listing", "data": {"after": "t3_14eqed6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just received this requirement from our users.\n\nhttps://preview.redd.it/dkvbl0ytob7b1.png?width=207&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=284cf935784d2eb5c31122197f6b6f800a28f644", "author_fullname": "t2_wrxmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best User Requirement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 43, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dkvbl0ytob7b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/dkvbl0ytob7b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=054c812515c43abbfdc945d62ce495737c34259a"}], "s": {"y": 64, "x": 207, "u": "https://preview.redd.it/dkvbl0ytob7b1.png?width=207&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=284cf935784d2eb5c31122197f6b6f800a28f644"}, "id": "dkvbl0ytob7b1"}}, "name": "t3_14f0msx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6tMBza5b6ErUTennUGN8xWA-okWWK-mxvvGe9Sjas2g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687332123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just received this requirement from our users.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dkvbl0ytob7b1.png?width=207&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=284cf935784d2eb5c31122197f6b6f800a28f644\"&gt;https://preview.redd.it/dkvbl0ytob7b1.png?width=207&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=284cf935784d2eb5c31122197f6b6f800a28f644&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14f0msx", "is_robot_indexable": true, "report_reasons": null, "author": "napstervab", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f0msx/best_user_requirement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f0msx/best_user_requirement/", "subreddit_subscribers": 111586, "created_utc": 1687332123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had an interview the other day that was pretty standard technical and competency based questions. But the last one stumped me. \u201cHow would you support your new team and team manager\u201d . I fluffed some rubbish about looking for areas team members needed support in to take work off their plate and help me get up to speed. \n\nBut I\u2019m curious as to what everyone else would say and particularly anyone leading a data team would be thinking of?", "author_fullname": "t2_scnmi5ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you answer this interview question?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eyqrg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687325998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had an interview the other day that was pretty standard technical and competency based questions. But the last one stumped me. \u201cHow would you support your new team and team manager\u201d . I fluffed some rubbish about looking for areas team members needed support in to take work off their plate and help me get up to speed. &lt;/p&gt;\n\n&lt;p&gt;But I\u2019m curious as to what everyone else would say and particularly anyone leading a data team would be thinking of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14eyqrg", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Aardvark258", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14eyqrg/how_would_you_answer_this_interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eyqrg/how_would_you_answer_this_interview_question/", "subreddit_subscribers": 111586, "created_utc": 1687325998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI am in the process of transitioning into Data Engineering. For context, I have a mechanical engineering degree and business masters degree from a reputable university and have worked as an engineer for a large supply chain/logistics/transportation company for a couple of years now. In my current role, I do a good bit of data analytics, although mainly using lower-level tools. In my free time, I have taken to learning Python (including pandas, NumPy, etc.) via online tutorials and text books and have implemented this in my current role by working on miscellaneous \"sandbox\" projects. I have also gained a fundamental understanding of database design and SQL and am taking some online trainings for Databricks.\n\nAm I crazy to think that I can pivot careers through my own dedication rather than seeking an additional degree? I am a technical learner and am dedicated to growing my knowledge gradually, but the terminology and vast number of tools can seem overwhelming at times. If it is possible to pivot on my own, does anyone have recommendations for materials/tutorials/online courses to grow my knowledge in ETL pipelines, distributed computing (Hadoop, Spark, etc.), and other cloud tools? I plan on working my way slowly through some of the recommendations from this subreddit's Learning Resources section. Apologies for the long post. Any advice is much appreciated in advance!\n\nThanks, all!", "author_fullname": "t2_5tzzasmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Pivot Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14etouq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687311357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am in the process of transitioning into Data Engineering. For context, I have a mechanical engineering degree and business masters degree from a reputable university and have worked as an engineer for a large supply chain/logistics/transportation company for a couple of years now. In my current role, I do a good bit of data analytics, although mainly using lower-level tools. In my free time, I have taken to learning Python (including pandas, NumPy, etc.) via online tutorials and text books and have implemented this in my current role by working on miscellaneous &amp;quot;sandbox&amp;quot; projects. I have also gained a fundamental understanding of database design and SQL and am taking some online trainings for Databricks.&lt;/p&gt;\n\n&lt;p&gt;Am I crazy to think that I can pivot careers through my own dedication rather than seeking an additional degree? I am a technical learner and am dedicated to growing my knowledge gradually, but the terminology and vast number of tools can seem overwhelming at times. If it is possible to pivot on my own, does anyone have recommendations for materials/tutorials/online courses to grow my knowledge in ETL pipelines, distributed computing (Hadoop, Spark, etc.), and other cloud tools? I plan on working my way slowly through some of the recommendations from this subreddit&amp;#39;s Learning Resources section. Apologies for the long post. Any advice is much appreciated in advance!&lt;/p&gt;\n\n&lt;p&gt;Thanks, all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14etouq", "is_robot_indexable": true, "report_reasons": null, "author": "SmeagolsPrecious_", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14etouq/career_pivot_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14etouq/career_pivot_advice/", "subreddit_subscribers": 111586, "created_utc": 1687311357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[Playlist](https://www.youtube.com/watch?v=VtL6Y4x10O0&amp;list=PLGVZCDnMOq0peDguAzds7kVmBr8avp46K)\n\nSome of the talks I found most intersting:\n\n* [ Use Spark from anywhere - A Spark client in Python powered by Spark Connect](https://www.youtube.com/watch?v=PzgPcvFDD4I&amp;t=1339s)\n* [Streamlit meets WebAssembly - stlite](https://www.youtube.com/watch?v=XivJYZUm1GY&amp;t=1368s)\n* [Pragmatic ways of using Rust in your data project](https://www.youtube.com/watch?v=Jk9NXfvgclU&amp;t=1374s)\n* [An Introduction to Apache Spark](https://www.youtube.com/watch?v=jOJceajwMGs&amp;t=749s)\n* [WebAssembly demystified](https://www.youtube.com/watch?v=VCkcv0ppYXs&amp;t=5s)\n* [Rusty Python - A Case Study](https://www.youtube.com/watch?v=Y5XQR0wUEyM&amp;t=52s)\n* [Towards Learned Database Systems](https://www.youtube.com/watch?v=VtL6Y4x10O0&amp;t=13s)", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyCon DE &amp; PyData Berlin 2023 Playlist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f73gz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687352384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=VtL6Y4x10O0&amp;amp;list=PLGVZCDnMOq0peDguAzds7kVmBr8avp46K\"&gt;Playlist&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Some of the talks I found most intersting:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=PzgPcvFDD4I&amp;amp;t=1339s\"&gt; Use Spark from anywhere - A Spark client in Python powered by Spark Connect&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=XivJYZUm1GY&amp;amp;t=1368s\"&gt;Streamlit meets WebAssembly - stlite&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=Jk9NXfvgclU&amp;amp;t=1374s\"&gt;Pragmatic ways of using Rust in your data project&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=jOJceajwMGs&amp;amp;t=749s\"&gt;An Introduction to Apache Spark&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=VCkcv0ppYXs&amp;amp;t=5s\"&gt;WebAssembly demystified&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=Y5XQR0wUEyM&amp;amp;t=52s\"&gt;Rusty Python - A Case Study&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.youtube.com/watch?v=VtL6Y4x10O0&amp;amp;t=13s\"&gt;Towards Learned Database Systems&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z9edXAhh-aBR9kQgHf91R1BQAa8YHzOzrPzFgw-B22w.jpg?auto=webp&amp;v=enabled&amp;s=a3492d7c1a5ad1a7128c98e245be41f067f20795", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Z9edXAhh-aBR9kQgHf91R1BQAa8YHzOzrPzFgw-B22w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c85fba682150a25e76d4b3f3d192b4e9d7729e59", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Z9edXAhh-aBR9kQgHf91R1BQAa8YHzOzrPzFgw-B22w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3d984e0b2729f9057c257397a25749f467a8337", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Z9edXAhh-aBR9kQgHf91R1BQAa8YHzOzrPzFgw-B22w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49ad477876c3a7b0ab159660bcff9ba2a6bdc865", "width": 320, "height": 240}], "variants": {}, "id": "qVYw_YvefBehG9llXEP7eXxaUqId0OOhkEobkd1GcbM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14f73gz", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f73gz/pycon_de_pydata_berlin_2023_playlist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f73gz/pycon_de_pydata_berlin_2023_playlist/", "subreddit_subscribers": 111586, "created_utc": 1687352384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The data project I am working handles several ingestion pipelines from server databases to azure. The whole thing runs on a daily basis and takes currently 3-4 hours.  In many situations I have the feeling that we have way to much overhead and many steps are unnecessary time consuming.  Recently I coded something and our current framework would need 30min for it. I quickly found the issue causing the time delay and proposed and adaption that would reduce the time to few minutes, but it was not the most beautiful approach tbh, but safe and without affecting the quality of the output. The senior dev just said there is no problem, as long as our pipeline runs within couple of hours there's no need to adapt anything. Additionally he didn't like the rather not-perfect approach.  Do you face similar issues that clean code is preferred over efficiency, causing the accumulation of huge overhead? Is it just normal, and I should simply shut up? Any advice how to deal with that?", "author_fullname": "t2_8etbdwvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clean code vs efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ehoy9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687282922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The data project I am working handles several ingestion pipelines from server databases to azure. The whole thing runs on a daily basis and takes currently 3-4 hours.  In many situations I have the feeling that we have way to much overhead and many steps are unnecessary time consuming.  Recently I coded something and our current framework would need 30min for it. I quickly found the issue causing the time delay and proposed and adaption that would reduce the time to few minutes, but it was not the most beautiful approach tbh, but safe and without affecting the quality of the output. The senior dev just said there is no problem, as long as our pipeline runs within couple of hours there&amp;#39;s no need to adapt anything. Additionally he didn&amp;#39;t like the rather not-perfect approach.  Do you face similar issues that clean code is preferred over efficiency, causing the accumulation of huge overhead? Is it just normal, and I should simply shut up? Any advice how to deal with that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ehoy9", "is_robot_indexable": true, "report_reasons": null, "author": "Remote-Juice2527", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ehoy9/clean_code_vs_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ehoy9/clean_code_vs_efficiency/", "subreddit_subscribers": 111586, "created_utc": 1687282922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIs writing articles about DE (and relevant domains) a good and valuable way to position yourself for X, where X can be:\n\n\\- promotion  \n\\- attracting recruiters  \n\\- leadership role  \n\\- establishing oneself as an expert  \n\\- showing you enjoy/want to be a mentor  \n\\- other reasons\n\nDoes it add credibility? Obviously it's not a replacement for actual experience, but would this open more doors or other doors that perhaps might have stayed closed?\n\nLove to hear professionals here that went that route and what your experiences are? Did you benefit at all, or did it hurt your career? Any tips, advice, do's and don'ts that you like to share?\n\nThank you.", "author_fullname": "t2_kh3ubtce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing articles to position yourself for X", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14efjv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687278141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Is writing articles about DE (and relevant domains) a good and valuable way to position yourself for X, where X can be:&lt;/p&gt;\n\n&lt;p&gt;- promotion&lt;br/&gt;\n- attracting recruiters&lt;br/&gt;\n- leadership role&lt;br/&gt;\n- establishing oneself as an expert&lt;br/&gt;\n- showing you enjoy/want to be a mentor&lt;br/&gt;\n- other reasons&lt;/p&gt;\n\n&lt;p&gt;Does it add credibility? Obviously it&amp;#39;s not a replacement for actual experience, but would this open more doors or other doors that perhaps might have stayed closed?&lt;/p&gt;\n\n&lt;p&gt;Love to hear professionals here that went that route and what your experiences are? Did you benefit at all, or did it hurt your career? Any tips, advice, do&amp;#39;s and don&amp;#39;ts that you like to share?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14efjv4", "is_robot_indexable": true, "report_reasons": null, "author": "SquidsAndMartians", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14efjv4/writing_articles_to_position_yourself_for_x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14efjv4/writing_articles_to_position_yourself_for_x/", "subreddit_subscribers": 111586, "created_utc": 1687278141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It'll be so fun. Every week we'll invite a stakeholder to join us and make an absurd request for some view or something, and we'll role-play how we respond to keep the stakeholder happy to our own detriment.\n\nhttps://preview.redd.it/977fk80hkd7b1.png?width=910&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6c89e2daf37736dd39d62a2783f354bb804b65f3", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody want to join my book club?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"977fk80hkd7b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 143, "x": 108, "u": "https://preview.redd.it/977fk80hkd7b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a236563704fb8a2a5295c901a49dedd9d42d0f6"}, {"y": 287, "x": 216, "u": "https://preview.redd.it/977fk80hkd7b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb1a37c61e110db11ae11524371ffc4d785d039d"}, {"y": 425, "x": 320, "u": "https://preview.redd.it/977fk80hkd7b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1107950234e6cefd1fffebc16a5103df0ff71ad"}, {"y": 851, "x": 640, "u": "https://preview.redd.it/977fk80hkd7b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af838dc270b66d9070ce3060c486679e7167d9e9"}], "s": {"y": 1211, "x": 910, "u": "https://preview.redd.it/977fk80hkd7b1.png?width=910&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6c89e2daf37736dd39d62a2783f354bb804b65f3"}, "id": "977fk80hkd7b1"}}, "name": "t3_14f846e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jdrS8rYFm1Szp6wJdBpRHCXbPC0SNZXemW-X7IBQEPs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687354978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;ll be so fun. Every week we&amp;#39;ll invite a stakeholder to join us and make an absurd request for some view or something, and we&amp;#39;ll role-play how we respond to keep the stakeholder happy to our own detriment.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/977fk80hkd7b1.png?width=910&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6c89e2daf37736dd39d62a2783f354bb804b65f3\"&gt;https://preview.redd.it/977fk80hkd7b1.png?width=910&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6c89e2daf37736dd39d62a2783f354bb804b65f3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14f846e", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f846e/anybody_want_to_join_my_book_club/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f846e/anybody_want_to_join_my_book_club/", "subreddit_subscribers": 111586, "created_utc": 1687354978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, so to explain my problem to you, I need to ingest data from Google ADS DATA HUB (ADH) to Big Query and I have done the python code, the code needs to be run weekly (cron job), however we need a snapshot of the tables in the end of the month. The final code will be dockerized and run on Google Kubernetes Engine.\n\nWhat solutions do you suggest to me? I\u2019m open to any suggestion to further learn and improve my data engineering skills.\n\nTL;DR I need to schedule the python code to run weekly and last day of the month. Any suggestions?\n\nEdit: typo and added details", "author_fullname": "t2_5u3c1gj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Ingestion from google ads to big query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f60ba", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687360316.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687349426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, so to explain my problem to you, I need to ingest data from Google ADS DATA HUB (ADH) to Big Query and I have done the python code, the code needs to be run weekly (cron job), however we need a snapshot of the tables in the end of the month. The final code will be dockerized and run on Google Kubernetes Engine.&lt;/p&gt;\n\n&lt;p&gt;What solutions do you suggest to me? I\u2019m open to any suggestion to further learn and improve my data engineering skills.&lt;/p&gt;\n\n&lt;p&gt;TL;DR I need to schedule the python code to run weekly and last day of the month. Any suggestions?&lt;/p&gt;\n\n&lt;p&gt;Edit: typo and added details&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14f60ba", "is_robot_indexable": true, "report_reasons": null, "author": "iGodFather302", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f60ba/data_ingestion_from_google_ads_to_big_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f60ba/data_ingestion_from_google_ads_to_big_query/", "subreddit_subscribers": 111586, "created_utc": 1687349426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I\u2019ve long worked with Databricks and want to step up my work on projects outside of my job. I really love developing in notebooks, but being able to version control with .py files and have all that git goodness. Also the flexibility of using that code in VS Code. \n\nMy question is, what open source alternatives are there such that I can develop in a \u201cnotebook\u201d, and version control it without a headache? Thanks!\n\nEDIT: I guess to clarify, I don\u2019t want to work out of Databricks for personal projects, so the aim is to retain the full functionality of working in notebooks that then have the benefits of easy version control, as eg Jupiter notebooks are horrible with being a bunch of json when directly vc\u2019d in a repo.", "author_fullname": "t2_7kdevi10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source Databricks notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f1fvs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687351642.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687334832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019ve long worked with Databricks and want to step up my work on projects outside of my job. I really love developing in notebooks, but being able to version control with .py files and have all that git goodness. Also the flexibility of using that code in VS Code. &lt;/p&gt;\n\n&lt;p&gt;My question is, what open source alternatives are there such that I can develop in a \u201cnotebook\u201d, and version control it without a headache? Thanks!&lt;/p&gt;\n\n&lt;p&gt;EDIT: I guess to clarify, I don\u2019t want to work out of Databricks for personal projects, so the aim is to retain the full functionality of working in notebooks that then have the benefits of easy version control, as eg Jupiter notebooks are horrible with being a bunch of json when directly vc\u2019d in a repo.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14f1fvs", "is_robot_indexable": true, "report_reasons": null, "author": "Impressive_Fact_6561", "discussion_type": null, "num_comments": 14, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f1fvs/open_source_databricks_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f1fvs/open_source_databricks_notebooks/", "subreddit_subscribers": 111586, "created_utc": 1687334832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Offcourse I do understand that governance is a massive module and may not be linked to DE directly. \n\nI see lot of overlaps between the two modules: Lineage, basic catalog, and metadata mgmt \n\nI would like to learn from comments and views.", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MonteCarlo integrates with Atlan or vice-versa - I think Data observability should be unified with catalog / governance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f93du", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687357349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Offcourse I do understand that governance is a massive module and may not be linked to DE directly. &lt;/p&gt;\n\n&lt;p&gt;I see lot of overlaps between the two modules: Lineage, basic catalog, and metadata mgmt &lt;/p&gt;\n\n&lt;p&gt;I would like to learn from comments and views.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14f93du", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f93du/montecarlo_integrates_with_atlan_or_viceversa_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f93du/montecarlo_integrates_with_atlan_or_viceversa_i/", "subreddit_subscribers": 111586, "created_utc": 1687357349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My first post here. I hope this is the right place to ask this question and have a meaningful discussion.\n\nWhat started as a pet project quickly became can internal tool for our company. When ever I am dealing with REST APIs, I have found building lots of bespoke data pipelines per API to manage the data ingestion. Especially to deal with authentication and pagination. I've come across some unconventional authentication mechanism as well as standard once like basic auth, Bearer token, api key etc. \n\nThen the problem of looping. For example load date related data using dynamic date parameters or load a list from one API endpoint and then loop through the list to load data from second endpoint etc.\n\nI wanted to simplify these implementation and haven't really found any tools for that task. So started working on one. Idea is to provide a single tool that can take instructions from data engineers, deal with authentications, manage the pagination, deal with loop and dynamic parameters and save the outcome to a storage (azure datalake, snowflake etc) or just return a JSON response at the end with all the data. Imagine postman with some added options that can be executed remotely to fetch data.\n\nI am interested to know if people face similar challenges, what use cases you deal/have dealt with and what's your approach been?\n\nHere is a small video of the tool in action. Please let me know if anyone is interested testing this. It's a fully hosted solution and I can set you up with an UI access. I found this works well with data pipelines in azure, remove the headaches, also tried it with other data ingestion tools such as Hevo and fivetran. ", "author_fullname": "t2_i9luvah0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "REST API connector tester and use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14ey7cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/muy5o5yf1b7b1/DASH_480.mp4?source=fallback", "has_audio": false, "height": 428, "width": 854, "scrubber_media_url": "https://v.redd.it/muy5o5yf1b7b1/DASH_96.mp4", "dash_url": "https://v.redd.it/muy5o5yf1b7b1/DASHPlaylist.mpd?a=1689957635%2CMjI0YzVkZGFmMDM1NDg3NzQ2OTkzYWM0YWU2NmEzYjRiZDViMmMyYzQyNzYyZGUzMDdmZGM0ZDdmYzQ5MWU1ZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/muy5o5yf1b7b1/HLSPlaylist.m3u8?a=1689957635%2COWJhNmViNzA3YTJjNTRlYjBjMTFmMTVjMDhkZmIxMmU0NGZiZWRlOWY1MDg3OTc3NjFkYWRjYThlZGI2ZmIxZA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=d2b2a2623a936e5fd4baac4afe2d88cb23d51687", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687324299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My first post here. I hope this is the right place to ask this question and have a meaningful discussion.&lt;/p&gt;\n\n&lt;p&gt;What started as a pet project quickly became can internal tool for our company. When ever I am dealing with REST APIs, I have found building lots of bespoke data pipelines per API to manage the data ingestion. Especially to deal with authentication and pagination. I&amp;#39;ve come across some unconventional authentication mechanism as well as standard once like basic auth, Bearer token, api key etc. &lt;/p&gt;\n\n&lt;p&gt;Then the problem of looping. For example load date related data using dynamic date parameters or load a list from one API endpoint and then loop through the list to load data from second endpoint etc.&lt;/p&gt;\n\n&lt;p&gt;I wanted to simplify these implementation and haven&amp;#39;t really found any tools for that task. So started working on one. Idea is to provide a single tool that can take instructions from data engineers, deal with authentications, manage the pagination, deal with loop and dynamic parameters and save the outcome to a storage (azure datalake, snowflake etc) or just return a JSON response at the end with all the data. Imagine postman with some added options that can be executed remotely to fetch data.&lt;/p&gt;\n\n&lt;p&gt;I am interested to know if people face similar challenges, what use cases you deal/have dealt with and what&amp;#39;s your approach been?&lt;/p&gt;\n\n&lt;p&gt;Here is a small video of the tool in action. Please let me know if anyone is interested testing this. It&amp;#39;s a fully hosted solution and I can set you up with an UI access. I found this works well with data pipelines in azure, remove the headaches, also tried it with other data ingestion tools such as Hevo and fivetran. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/muy5o5yf1b7b1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3409cda296cf88e427a5f46726a9e4280ff62505", "width": 1080, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1f8fcbc2f749b468b64c8f2ece163cf06fcb2ddf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=fac6181b17769b8d28a5d0f6c791ffd817e04aa3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7a94fbd36e068a47d82f11366a5e9e743aa00077", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=94a96526cd4f3a8f781a113522114da70dfbae58", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c6970740f45dd4e8146ef323cf94166ecda88b46", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=adde90c08d02cebaeb9a77006825f5085a8ac6c9", "width": 1080, "height": 540}], "variants": {}, "id": "NmhlcHEydmYxYjdiMevGc2-hs7PLVFc3ePDJV3vg671EdiMKQDcAFBOSYIKw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ey7cr", "is_robot_indexable": true, "report_reasons": null, "author": "Kabir-rab", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ey7cr/rest_api_connector_tester_and_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/muy5o5yf1b7b1", "subreddit_subscribers": 111586, "created_utc": 1687324299.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/muy5o5yf1b7b1/DASH_480.mp4?source=fallback", "has_audio": false, "height": 428, "width": 854, "scrubber_media_url": "https://v.redd.it/muy5o5yf1b7b1/DASH_96.mp4", "dash_url": "https://v.redd.it/muy5o5yf1b7b1/DASHPlaylist.mpd?a=1689957635%2CMjI0YzVkZGFmMDM1NDg3NzQ2OTkzYWM0YWU2NmEzYjRiZDViMmMyYzQyNzYyZGUzMDdmZGM0ZDdmYzQ5MWU1ZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 52, "hls_url": "https://v.redd.it/muy5o5yf1b7b1/HLSPlaylist.m3u8?a=1689957635%2COWJhNmViNzA3YTJjNTRlYjBjMTFmMTVjMDhkZmIxMmU0NGZiZWRlOWY1MDg3OTc3NjFkYWRjYThlZGI2ZmIxZA%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am half Japanese, speak the language good (can have long discussions over various topics) along with family in Japan. \n\nI am considering the possibility of trying to offer some data architecture services in Japan for businesses. I understand the work culture is a lot more conservative than the US.\n\nCurrently, am a US citizen. I also have been a data architect the past 6 years with consulting experience. Id like to still be based in the US, but can definetly travel for work.\n\nWould appreciate anyones thoughts on this.", "author_fullname": "t2_l1vnoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Consulting work in Japan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14emrtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687294180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am half Japanese, speak the language good (can have long discussions over various topics) along with family in Japan. &lt;/p&gt;\n\n&lt;p&gt;I am considering the possibility of trying to offer some data architecture services in Japan for businesses. I understand the work culture is a lot more conservative than the US.&lt;/p&gt;\n\n&lt;p&gt;Currently, am a US citizen. I also have been a data architect the past 6 years with consulting experience. Id like to still be based in the US, but can definetly travel for work.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate anyones thoughts on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14emrtx", "is_robot_indexable": true, "report_reasons": null, "author": "Paulythress", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14emrtx/thoughts_on_consulting_work_in_japan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14emrtx/thoughts_on_consulting_work_in_japan/", "subreddit_subscribers": 111586, "created_utc": 1687294180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Current situation**\n\nJob title: Data engineer, but I'm really an analytics engineer doing mostly custom batch ETL, report automation, prepping data for analysts.\n\nExperience: 2 years; switched from unrelated career\n\nLocation: USA\n\nCompensation: $100k (+$5k profit sharing bonus when possible)\n\nSkills:\n\n* Programming: Python (good), SQL (good), Linux shell (enough to get around), Git (enough)\n\n* Other tech: AWS, Airflow, Postgres, Docker, Pandas, BI tools\n\n* Knowledge: Data modeling (dimensional, normalization), data management (observability, lineage, alerting, etc.), query optimization, SWE design &amp; best practices (self taught here though without much team experience)\n\n* Other info: I have a security clearance\n\n* Concerns: I don't feel there's much room for advancement in my current position. Additionally, the only \"senior data engineer\" on our team works separately from me and from what I gather I wouldn't learn a ton from him anyway. Because of this, I don't feel that I'm getting as much mentorship as I should as someone with 2 YOE.\n\n**Goals**\n\nI'm sure this will sound rather vain to the community of geniuses on this sub (srs), but my main objective is to get into the ~$180k+ range in the next 5 years or so, preferably working for someone else.\n\nI'm a competitive nerd at heart, and in my previous career I over-optimized for technical skill and under-optimized for money. I love working with data, and I know I could easily spend a decade going deep on distributed computing, devops / IaC, database internals, etc.\n\nBut personally, I'm not interested in obsessing over the micro aspects of my craft anymore. I'm in my 30s, have a social / family life, and want to enjoy that with as little financial stress as possible.\n\n**Career plan**\n\nI don't know exactly what I want to do, which is why I'm posting. Some initial thoughts:\n\n* My \"moats\": I'm an American with a security clearance. I'm likeable, can converse about whatever. I'm very logical and a good big picture thinker. Good at explaining things in easy to understand ways when I'm prepared well.\n\n* Based on these, I'm thinking a couple decent career directions might be enterprise sales engineer or solutions architect. **What do you think about these? Please recommend other stuff that could be a good fit!**\n\n**Path forward**\n\n* While I don't want to over-optimize for technical skill, I know I still have much to learn to be a competent architect and even engineer. I plan on building a personal project using stream architecture/processing, Spark, containers, simple CI/CD pipeline.\n\n* On the soft skills side, I want to get really good at whiteboarding, speaking confidently / voice projection, being persuasive, presenting in general\n\n**Strategy**\n\nFinally, I want to lay out what I'm thinking as a medium-term strategy. \n\n* Interview for customer-facing mid-level and hopefully get a 20%-ish pay bump and yearly raises. Hopefully get some CRM and sales calls exposure in this role.\n\n* Keep leveling up my skillsets\n\n* Attempt to land a SE / SA role (or something else?) after a few years\n\nThanks for reading. Please poke holes in my plan and offer advice or future job suggestions =]", "author_fullname": "t2_cqvp4nt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's my next move?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14egko0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687280422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Current situation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Job title: Data engineer, but I&amp;#39;m really an analytics engineer doing mostly custom batch ETL, report automation, prepping data for analysts.&lt;/p&gt;\n\n&lt;p&gt;Experience: 2 years; switched from unrelated career&lt;/p&gt;\n\n&lt;p&gt;Location: USA&lt;/p&gt;\n\n&lt;p&gt;Compensation: $100k (+$5k profit sharing bonus when possible)&lt;/p&gt;\n\n&lt;p&gt;Skills:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Programming: Python (good), SQL (good), Linux shell (enough to get around), Git (enough)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other tech: AWS, Airflow, Postgres, Docker, Pandas, BI tools&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Knowledge: Data modeling (dimensional, normalization), data management (observability, lineage, alerting, etc.), query optimization, SWE design &amp;amp; best practices (self taught here though without much team experience)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other info: I have a security clearance&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Concerns: I don&amp;#39;t feel there&amp;#39;s much room for advancement in my current position. Additionally, the only &amp;quot;senior data engineer&amp;quot; on our team works separately from me and from what I gather I wouldn&amp;#39;t learn a ton from him anyway. Because of this, I don&amp;#39;t feel that I&amp;#39;m getting as much mentorship as I should as someone with 2 YOE.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Goals&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure this will sound rather vain to the community of geniuses on this sub (srs), but my main objective is to get into the ~$180k+ range in the next 5 years or so, preferably working for someone else.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a competitive nerd at heart, and in my previous career I over-optimized for technical skill and under-optimized for money. I love working with data, and I know I could easily spend a decade going deep on distributed computing, devops / IaC, database internals, etc.&lt;/p&gt;\n\n&lt;p&gt;But personally, I&amp;#39;m not interested in obsessing over the micro aspects of my craft anymore. I&amp;#39;m in my 30s, have a social / family life, and want to enjoy that with as little financial stress as possible.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Career plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know exactly what I want to do, which is why I&amp;#39;m posting. Some initial thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;My &amp;quot;moats&amp;quot;: I&amp;#39;m an American with a security clearance. I&amp;#39;m likeable, can converse about whatever. I&amp;#39;m very logical and a good big picture thinker. Good at explaining things in easy to understand ways when I&amp;#39;m prepared well.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Based on these, I&amp;#39;m thinking a couple decent career directions might be enterprise sales engineer or solutions architect. &lt;strong&gt;What do you think about these? Please recommend other stuff that could be a good fit!&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Path forward&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;While I don&amp;#39;t want to over-optimize for technical skill, I know I still have much to learn to be a competent architect and even engineer. I plan on building a personal project using stream architecture/processing, Spark, containers, simple CI/CD pipeline.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;On the soft skills side, I want to get really good at whiteboarding, speaking confidently / voice projection, being persuasive, presenting in general&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Strategy&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Finally, I want to lay out what I&amp;#39;m thinking as a medium-term strategy. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Interview for customer-facing mid-level and hopefully get a 20%-ish pay bump and yearly raises. Hopefully get some CRM and sales calls exposure in this role.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Keep leveling up my skillsets&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Attempt to land a SE / SA role (or something else?) after a few years&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks for reading. Please poke holes in my plan and offer advice or future job suggestions =]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14egko0", "is_robot_indexable": true, "report_reasons": null, "author": "udonthave2call", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14egko0/whats_my_next_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14egko0/whats_my_next_move/", "subreddit_subscribers": 111586, "created_utc": 1687280422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying Databricks for the first time. I created a 'standard' workspace using 'Quickstart on AWS' option.\n\nCloudformation runs into error during 'assign Metastore' step.\n\nFollowing is the error from Cloudwatch:\n\nHTTP content: b'\n\n{ \"error\\_code\": \"PERMISSION\\_DENIED\", \"message\": \"Cannot assign metastore to STANDARD tier workspace xyz\" }\n\nWhat is the solution for this?", "author_fullname": "t2_jl74ygnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks: Error while creating workspace with 'Quickstart' on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14faojz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687361087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying Databricks for the first time. I created a &amp;#39;standard&amp;#39; workspace using &amp;#39;Quickstart on AWS&amp;#39; option.&lt;/p&gt;\n\n&lt;p&gt;Cloudformation runs into error during &amp;#39;assign Metastore&amp;#39; step.&lt;/p&gt;\n\n&lt;p&gt;Following is the error from Cloudwatch:&lt;/p&gt;\n\n&lt;p&gt;HTTP content: b&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;{ &amp;quot;error_code&amp;quot;: &amp;quot;PERMISSION_DENIED&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Cannot assign metastore to STANDARD tier workspace xyz&amp;quot; }&lt;/p&gt;\n\n&lt;p&gt;What is the solution for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14faojz", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Device689", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14faojz/databricks_error_while_creating_workspace_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14faojz/databricks_error_while_creating_workspace_with/", "subreddit_subscribers": 111586, "created_utc": 1687361087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DEs! Thanks for so much info over the last year, this is a great resource for those of us in the field. \n\nI have been working as a \"Data Engineer\" for the last year and a half. The reason I put this in quotes is because I don't feel like I live up to the title, as cool as it sounds. I read through these posts daily and have no idea what most of you are talking about, most of the time. A little background is that I came into this position by luck because I had a good resume within the company and the company doesn't have much internal competition for technical positions. I have no background in CS, DWH, DE, or really any type of coding. I've entirely learned on the job. \n\nThe problem with that is this is a very large company ( a large government organization ) and I work on one specific team that handles ETL exclusively. If I understand the term correctly our stack is: Ab Initio (ETL apps), oracle db for staging tables, and UNIX servers. My daily work consists of making updates to these ab initio applications. Within those applications are a bunch of unix shell scripts that I also have to work with. As far as the oracle db, I don't really do any SQL work. We have a modeling team that handles all of that. So the primary skills would be Ab Initio development &amp; shell scripting, and then navigating the metric ton of red tape for promotions to prod. \n\nMy question is , am I wasting my time? From everything I read on here, it seems like ab initio is a dying tool on its way out. It also seems like shell scripting isn't used much. Everyone seems to be using python, cloud, and a litany of other tools I've never heard of. This type of work does not come easy to me, as much as I wish it did. I work with a bunch of people who are either not great at the job, and if they are they aren't good communicators, nor do they want to mentor a new developer. \n\nTLDR: It feels like I am fighting an uphill battle to learn outdated technology that is only useful in my current role but doesn't actually build me into a true DE. I'm still relatively young and at a pivotal moment of my career. It feels like if I want a career in this field, this isn't the right place. What would you data Jedis do?", "author_fullname": "t2_73cw9sv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dinosaur tools &amp; a dead stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14fajwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687360785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DEs! Thanks for so much info over the last year, this is a great resource for those of us in the field. &lt;/p&gt;\n\n&lt;p&gt;I have been working as a &amp;quot;Data Engineer&amp;quot; for the last year and a half. The reason I put this in quotes is because I don&amp;#39;t feel like I live up to the title, as cool as it sounds. I read through these posts daily and have no idea what most of you are talking about, most of the time. A little background is that I came into this position by luck because I had a good resume within the company and the company doesn&amp;#39;t have much internal competition for technical positions. I have no background in CS, DWH, DE, or really any type of coding. I&amp;#39;ve entirely learned on the job. &lt;/p&gt;\n\n&lt;p&gt;The problem with that is this is a very large company ( a large government organization ) and I work on one specific team that handles ETL exclusively. If I understand the term correctly our stack is: Ab Initio (ETL apps), oracle db for staging tables, and UNIX servers. My daily work consists of making updates to these ab initio applications. Within those applications are a bunch of unix shell scripts that I also have to work with. As far as the oracle db, I don&amp;#39;t really do any SQL work. We have a modeling team that handles all of that. So the primary skills would be Ab Initio development &amp;amp; shell scripting, and then navigating the metric ton of red tape for promotions to prod. &lt;/p&gt;\n\n&lt;p&gt;My question is , am I wasting my time? From everything I read on here, it seems like ab initio is a dying tool on its way out. It also seems like shell scripting isn&amp;#39;t used much. Everyone seems to be using python, cloud, and a litany of other tools I&amp;#39;ve never heard of. This type of work does not come easy to me, as much as I wish it did. I work with a bunch of people who are either not great at the job, and if they are they aren&amp;#39;t good communicators, nor do they want to mentor a new developer. &lt;/p&gt;\n\n&lt;p&gt;TLDR: It feels like I am fighting an uphill battle to learn outdated technology that is only useful in my current role but doesn&amp;#39;t actually build me into a true DE. I&amp;#39;m still relatively young and at a pivotal moment of my career. It feels like if I want a career in this field, this isn&amp;#39;t the right place. What would you data Jedis do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14fajwv", "is_robot_indexable": true, "report_reasons": null, "author": "ApatheticRart", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14fajwv/dinosaur_tools_a_dead_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14fajwv/dinosaur_tools_a_dead_stack/", "subreddit_subscribers": 111586, "created_utc": 1687360785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Common Anti-Scraping Measures on Websites and How to Bypass Them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_14f9q8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gD9F-J0b8487yZfi24T6NRpDLgh22cSkGmohKTlzBgs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687358880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "javascript.plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://javascript.plainenglish.io/common-anti-scraping-measures-on-websites-and-how-to-bypass-them-a32de1b066a2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?auto=webp&amp;v=enabled&amp;s=42c59a73b3ad91dce8fcd997a95d024ff551cc8f", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04478cd9c6d2a35eb877e84520629c45354d80f3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a98eda0cbd3d0cfd4690879ac960bd381e9155c9", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bec1880dd7f6f7eefaa7bbf3bad9b37b13bba0c7", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8779f32e08b68a043c6684866de331b337660a3f", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15e3a4d1e59ac9aa7adc3772d0a940f425912392", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/7yKKS1kBAIsgjZdaj0xcTI76r8ow3utJYiE22CzcTRs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68007d0fa94969d328ff24d08a740023c51c6be1", "width": 1080, "height": 1080}], "variants": {}, "id": "2Qq3JmMuayyJv838L8VeYv47kDei9weoMUIDYVk3Q68"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14f9q8p", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f9q8p/common_antiscraping_measures_on_websites_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://javascript.plainenglish.io/common-anti-scraping-measures-on-websites-and-how-to-bypass-them-a32de1b066a2", "subreddit_subscribers": 111586, "created_utc": 1687358880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, i'm the data engineer building the open source python library that will revolutionise data ingestion.   \n\n\nHere's the latest: Generate a pipeline from Openapi spec - complete with scalability, schema inference and evolution [https://dlthub.com/docs/blog/open-api-spec-for-dlt-init](https://dlthub.com/docs/blog/open-api-spec-for-dlt-init)  \n\n\nWith this and possibly a little help from LLMs, it should be possible to generate pipelines for half the apis out there.\n\nIf you wanna check out the schema evolution, try the colab demo [https://dlthub.com/docs/getting-started/try-in-colab](https://dlthub.com/docs/getting-started/try-in-colab)  \n", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenAPI: The pathway to 100.000s of pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14f9uef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687359151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m the data engineer building the open source python library that will revolutionise data ingestion.   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the latest: Generate a pipeline from Openapi spec - complete with scalability, schema inference and evolution &lt;a href=\"https://dlthub.com/docs/blog/open-api-spec-for-dlt-init\"&gt;https://dlthub.com/docs/blog/open-api-spec-for-dlt-init&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;With this and possibly a little help from LLMs, it should be possible to generate pipelines for half the apis out there.&lt;/p&gt;\n\n&lt;p&gt;If you wanna check out the schema evolution, try the colab demo &lt;a href=\"https://dlthub.com/docs/getting-started/try-in-colab\"&gt;https://dlthub.com/docs/getting-started/try-in-colab&lt;/a&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NzlwzurLRCXqoiPOMF1LXQUZ4LFax3Wsw8AEkGZa5AA.jpg?auto=webp&amp;v=enabled&amp;s=54d27c0d798e6729ca65b90d6d2e40ef71fb764c", "width": 640, "height": 346}, "resolutions": [{"url": "https://external-preview.redd.it/NzlwzurLRCXqoiPOMF1LXQUZ4LFax3Wsw8AEkGZa5AA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=373185d5f44073efe56b82a266bf54a90b7ca708", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/NzlwzurLRCXqoiPOMF1LXQUZ4LFax3Wsw8AEkGZa5AA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e3ad820d66a7be26d44db68447dbba12b00b066", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/NzlwzurLRCXqoiPOMF1LXQUZ4LFax3Wsw8AEkGZa5AA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e988077e4c7a75b052d3c8c3fadee728730b8e3", "width": 320, "height": 173}, {"url": "https://external-preview.redd.it/NzlwzurLRCXqoiPOMF1LXQUZ4LFax3Wsw8AEkGZa5AA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d807b64df7cb43abc03005bb52002efa71d230e5", "width": 640, "height": 346}], "variants": {}, "id": "vqjzGeZqWiXKH8ES7HpXNAVyurt8I5ufVEYBGA7HY2g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14f9uef", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f9uef/openapi_the_pathway_to_100000s_of_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f9uef/openapi_the_pathway_to_100000s_of_pipelines/", "subreddit_subscribers": 111586, "created_utc": 1687359151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone,\n\nI have an issue relating to a local Oracle server (19c) creating a link to AWS via IAM user.\n\nI have an access key for the AWS IAM user, and AWS automatically generates a secret key (password) associated with the access key. Now the secret key is about 40chars long.  \nIn Oracle 19c the maximum length for an identifier is 30chars!?  \nMeaning when I try using JDBC to connect Oracle to AWS I get an error (ORA-00972: identifier is too long).  \n\n\nHas anyone experienced something like this? Any workarounds?  \nHelp would be much appreciated \ud83d\ude4f", "author_fullname": "t2_4wsp8k38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connecting to AWS From and Oracle Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f8dqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687355639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,&lt;/p&gt;\n\n&lt;p&gt;I have an issue relating to a local Oracle server (19c) creating a link to AWS via IAM user.&lt;/p&gt;\n\n&lt;p&gt;I have an access key for the AWS IAM user, and AWS automatically generates a secret key (password) associated with the access key. Now the secret key is about 40chars long.&lt;br/&gt;\nIn Oracle 19c the maximum length for an identifier is 30chars!?&lt;br/&gt;\nMeaning when I try using JDBC to connect Oracle to AWS I get an error (ORA-00972: identifier is too long).  &lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced something like this? Any workarounds?&lt;br/&gt;\nHelp would be much appreciated \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14f8dqg", "is_robot_indexable": true, "report_reasons": null, "author": "trendy_parker", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f8dqg/connecting_to_aws_from_and_oracle_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f8dqg/connecting_to_aws_from_and_oracle_server/", "subreddit_subscribers": 111586, "created_utc": 1687355639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So ill be doing a test this week for a job, before starting the test there are some instructions and its written \"You can write your solution(s) in SQL.\"\n\nDoes this means its a pure SQL test? Ive been studying python for this test in the last few days, now maybe i should stop and go full SQL.", "author_fullname": "t2_w5u5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quick question about Codility test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f7hg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687353344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So ill be doing a test this week for a job, before starting the test there are some instructions and its written &amp;quot;You can write your solution(s) in SQL.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Does this means its a pure SQL test? Ive been studying python for this test in the last few days, now maybe i should stop and go full SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14f7hg8", "is_robot_indexable": true, "report_reasons": null, "author": "Lenant", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f7hg8/quick_question_about_codility_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f7hg8/quick_question_about_codility_test/", "subreddit_subscribers": 111586, "created_utc": 1687353344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anybody please help me with visualizer for kafka? Something that I can use to check the lag of particular topic and also work as consumer to listen on it may be?\nI tried kadeck but looking at any other alternatives that can help?", "author_fullname": "t2_e77dyu0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualizer for kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f5ppz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687348627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody please help me with visualizer for kafka? Something that I can use to check the lag of particular topic and also work as consumer to listen on it may be?\nI tried kadeck but looking at any other alternatives that can help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14f5ppz", "is_robot_indexable": true, "report_reasons": null, "author": "Jalebibabyded", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f5ppz/visualizer_for_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f5ppz/visualizer_for_kafka/", "subreddit_subscribers": 111586, "created_utc": 1687348627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "a lot of talk around LLMs &amp; their potential impact on data teams workflows. \n\nMy guess is we'll see a lot of these pop-up in our favorite tools in the next few years (databricks, Snowflake, Tableau, Looker, dbt, etc).\n\ncan you add a quick explanation in comment to make it more interesting?\n\n[View Poll](https://www.reddit.com/poll/14f5mdr)", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of the emerging concept of \"data copilots\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f5mdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687348355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;a lot of talk around LLMs &amp;amp; their potential impact on data teams workflows. &lt;/p&gt;\n\n&lt;p&gt;My guess is we&amp;#39;ll see a lot of these pop-up in our favorite tools in the next few years (databricks, Snowflake, Tableau, Looker, dbt, etc).&lt;/p&gt;\n\n&lt;p&gt;can you add a quick explanation in comment to make it more interesting?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14f5mdr\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14f5mdr", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1687607555683, "options": [{"text": "Over-hyped", "id": "23557093"}, {"text": "Game-changing", "id": "23557094"}, {"text": "No Opinion", "id": "23557095"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 44, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f5mdr/what_do_you_think_of_the_emerging_concept_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/14f5mdr/what_do_you_think_of_the_emerging_concept_of_data/", "subreddit_subscribers": 111586, "created_utc": 1687348355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am fairly new to data engineering and have a query / trouble understanding the overall picture. \n\nI have an on prem oracle DB with a table with 20 mil + rows. My requirement is to pivot two of the columns and then consume to pivoted data in Power Bi. \n\nHow do i use synapse and adf to accomplish this? \nHow do I leverage synapses spark compute to get this done? \n\nThanks!!", "author_fullname": "t2_gwyx0bqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I leverage Azure Synapse and ADf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f3nix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687342335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am fairly new to data engineering and have a query / trouble understanding the overall picture. &lt;/p&gt;\n\n&lt;p&gt;I have an on prem oracle DB with a table with 20 mil + rows. My requirement is to pivot two of the columns and then consume to pivoted data in Power Bi. &lt;/p&gt;\n\n&lt;p&gt;How do i use synapse and adf to accomplish this? \nHow do I leverage synapses spark compute to get this done? &lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14f3nix", "is_robot_indexable": true, "report_reasons": null, "author": "AmritaOS", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f3nix/how_do_i_leverage_azure_synapse_and_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f3nix/how_do_i_leverage_azure_synapse_and_adf/", "subreddit_subscribers": 111586, "created_utc": 1687342335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my fellow data magicians,\n\nI'm a relatively new DE (&gt;1yoe), I started as a data scientist in my company with a relatively small data team (5 people), and when the old DE left I took over a lot of the ETL responsibilities and I really enjoyed them So I kind of transitioned to this role and I love it but the time has come for me to explore the market and I see there are some practices that my company just doesn't follow that are extremely crucial for a DE. At my company, I usually use ADF (code-free ETL pipelines) for simpler transformations and for complex ones, I use Databricks notebooks and integrate them into the ADF pipelines. For Storage, I use Azure Blobs with Databricks tables as my final destination where the tables can be queried by the BI team. The problem is, I'm not sure if this is the optimal way of doing this. For example, I only use git for version control and archive blobs when testing and debugging errors and I don't have separate development and production environments and I have no idea how to implement CI/CD. I would really appreciate it if you guys have any advice for me about what concepts I should be looking into and where to improve as a DE and improve the robustness of my pipelines.\n\nThanks again for taking the time to read all of that. Have a good day :) ", "author_fullname": "t2_4ozsxw58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help Leveling up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14f2rj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687339380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my fellow data magicians,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a relatively new DE (&amp;gt;1yoe), I started as a data scientist in my company with a relatively small data team (5 people), and when the old DE left I took over a lot of the ETL responsibilities and I really enjoyed them So I kind of transitioned to this role and I love it but the time has come for me to explore the market and I see there are some practices that my company just doesn&amp;#39;t follow that are extremely crucial for a DE. At my company, I usually use ADF (code-free ETL pipelines) for simpler transformations and for complex ones, I use Databricks notebooks and integrate them into the ADF pipelines. For Storage, I use Azure Blobs with Databricks tables as my final destination where the tables can be queried by the BI team. The problem is, I&amp;#39;m not sure if this is the optimal way of doing this. For example, I only use git for version control and archive blobs when testing and debugging errors and I don&amp;#39;t have separate development and production environments and I have no idea how to implement CI/CD. I would really appreciate it if you guys have any advice for me about what concepts I should be looking into and where to improve as a DE and improve the robustness of my pipelines.&lt;/p&gt;\n\n&lt;p&gt;Thanks again for taking the time to read all of that. Have a good day :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14f2rj2", "is_robot_indexable": true, "report_reasons": null, "author": "Mortariano", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14f2rj2/need_help_leveling_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14f2rj2/need_help_leveling_up/", "subreddit_subscribers": 111586, "created_utc": 1687339380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm under the impression that placing the burden of compute on a resource such as Snowflake is much better for dashboard performance, as opposed to running an extract into the BI tool and using it's resources to compute. Is this correct? Or is there much more nuance here im missing?", "author_fullname": "t2_43fb03vm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compute burden - bi tool or backend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14exa00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687321445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m under the impression that placing the burden of compute on a resource such as Snowflake is much better for dashboard performance, as opposed to running an extract into the BI tool and using it&amp;#39;s resources to compute. Is this correct? Or is there much more nuance here im missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14exa00", "is_robot_indexable": true, "report_reasons": null, "author": "idiotlog", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14exa00/compute_burden_bi_tool_or_backend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14exa00/compute_burden_bi_tool_or_backend/", "subreddit_subscribers": 111586, "created_utc": 1687321445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks.\nI pretend to learn data engineering. I\u2019m already in Data Analytics field. Which is the order I should learn those books:\n\n* The data Warehouse toolkit\n* The kimball group reader\n* designing data intensive applications \n* Fundamentals of data engineering \n* T-SQL fundamentals \n* T-SQL Querying\n\nThanks in advanced", "author_fullname": "t2_bnqvpnvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ebooks order to read", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14eqed6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687302424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks.\nI pretend to learn data engineering. I\u2019m already in Data Analytics field. Which is the order I should learn those books:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The data Warehouse toolkit&lt;/li&gt;\n&lt;li&gt;The kimball group reader&lt;/li&gt;\n&lt;li&gt;designing data intensive applications &lt;/li&gt;\n&lt;li&gt;Fundamentals of data engineering &lt;/li&gt;\n&lt;li&gt;T-SQL fundamentals &lt;/li&gt;\n&lt;li&gt;T-SQL Querying&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advanced&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14eqed6", "is_robot_indexable": true, "report_reasons": null, "author": "Mr-Wedge01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14eqed6/ebooks_order_to_read/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14eqed6/ebooks_order_to_read/", "subreddit_subscribers": 111586, "created_utc": 1687302424.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}