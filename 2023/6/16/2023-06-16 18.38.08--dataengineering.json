{"kind": "Listing", "data": {"after": "t3_14afbs0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I switched from mechanical engineering to IoT data engineering about a year ago. At first I was pretty oblivious to a lot of stuff, but as I've learned I look around in horror.\n\nThere's so much duplicate information, bad source data, free-for-all solo project DBs.\n\nEverything is a mess and I can't help but think most other companies are like this. Both companies I've worked for didn't start hiring a serious amount of IT infrastructure until a few years ago. The data is clearly getting better but has a loooong way to go.\n\nAnd now with ML, Industry 4.0, and cloud being pushed I feel companies will all start running before they walk and everything will be a massive mess.\n\nI thought data jobs were peaking now but in reality I think they're just now going to start growing, thoughts?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data at every company still an absolute mess?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14abng6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 205, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 205, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686858979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I switched from mechanical engineering to IoT data engineering about a year ago. At first I was pretty oblivious to a lot of stuff, but as I&amp;#39;ve learned I look around in horror.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s so much duplicate information, bad source data, free-for-all solo project DBs.&lt;/p&gt;\n\n&lt;p&gt;Everything is a mess and I can&amp;#39;t help but think most other companies are like this. Both companies I&amp;#39;ve worked for didn&amp;#39;t start hiring a serious amount of IT infrastructure until a few years ago. The data is clearly getting better but has a loooong way to go.&lt;/p&gt;\n\n&lt;p&gt;And now with ML, Industry 4.0, and cloud being pushed I feel companies will all start running before they walk and everything will be a massive mess.&lt;/p&gt;\n\n&lt;p&gt;I thought data jobs were peaking now but in reality I think they&amp;#39;re just now going to start growing, thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14abng6", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 136, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14abng6/is_data_at_every_company_still_an_absolute_mess/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14abng6/is_data_at_every_company_still_an_absolute_mess/", "subreddit_subscribers": 110753, "created_utc": 1686858979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://dataisle.io/posts/data-engineering-technologies/](https://dataisle.io/posts/data-engineering-technologies/)\n\nHi all! I've noticed a lot of questions like this one around here, so I tried to give my take on it in this post. I understand it's hard to write such lists as everyone has a bit of a different opinion and experience and would like to put something in or take something out. My goal was to put in things I think are essential, especially for a new data engineer or someone with 1 to 2 years of experience.\n\nFeedback and questions are appreciated. :)", "author_fullname": "t2_qrz48vz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does a data engineer need to know other than Python and SQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aanke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686856581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://dataisle.io/posts/data-engineering-technologies/\"&gt;https://dataisle.io/posts/data-engineering-technologies/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi all! I&amp;#39;ve noticed a lot of questions like this one around here, so I tried to give my take on it in this post. I understand it&amp;#39;s hard to write such lists as everyone has a bit of a different opinion and experience and would like to put something in or take something out. My goal was to put in things I think are essential, especially for a new data engineer or someone with 1 to 2 years of experience.&lt;/p&gt;\n\n&lt;p&gt;Feedback and questions are appreciated. :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14aanke", "is_robot_indexable": true, "report_reasons": null, "author": "Ervolius", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aanke/what_does_a_data_engineer_need_to_know_other_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aanke/what_does_a_data_engineer_need_to_know_other_than/", "subreddit_subscribers": 110753, "created_utc": 1686856581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,  \nI want to share my website [https://technicalsummaries.com/](https://technicalsummaries.com/).\n\nYou can find there summaries of books:\n\n* `Fundamentals of Data Engineering` \\- Joe Reis, Matt Housley.\n* `Designing Data-Intensive Applications` \\- Martin Kleppmann.\n\nAlso, I am working on a summary of the course `Database Systems` by Prof. Dr Jens Dittrich, which is very underrated.\n\nYou can comment at the bottom of every chapter or edit the content.\n\nIf you have any suggestions regarding my page, I am more than grateful to take some advice.\n\nI created the page because I can learn much more effectively when I need to structure the text I've just read, and also, it was mainly for my students, who are too lazy to read the whole book :D\n\nThanks.", "author_fullname": "t2_99xm7vrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My website with summaries of data engineering books and courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a8ymy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686852418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;br/&gt;\nI want to share my website &lt;a href=\"https://technicalsummaries.com/\"&gt;https://technicalsummaries.com/&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;You can find there summaries of books:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;Fundamentals of Data Engineering&lt;/code&gt; - Joe Reis, Matt Housley.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;Designing Data-Intensive Applications&lt;/code&gt; - Martin Kleppmann.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also, I am working on a summary of the course &lt;code&gt;Database Systems&lt;/code&gt; by Prof. Dr Jens Dittrich, which is very underrated.&lt;/p&gt;\n\n&lt;p&gt;You can comment at the bottom of every chapter or edit the content.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions regarding my page, I am more than grateful to take some advice.&lt;/p&gt;\n\n&lt;p&gt;I created the page because I can learn much more effectively when I need to structure the text I&amp;#39;ve just read, and also, it was mainly for my students, who are too lazy to read the whole book :D&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14a8ymy", "is_robot_indexable": true, "report_reasons": null, "author": "Brief_Priority_2193", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14a8ymy/my_website_with_summaries_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14a8ymy/my_website_with_summaries_of_data_engineering/", "subreddit_subscribers": 110753, "created_utc": 1686852418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Dagster Master Plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14az4gz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cLNw5l3GlrASSy-nBqRgrjOQ0usKiV_A1lL-vXs-W4c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686927674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-master-plan", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?auto=webp&amp;v=enabled&amp;s=5e576129ef6e809ae03398b59e5eac6af438af01", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8653bf88106073b8fc1cc77ebdb44700ce26eac0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a934b4c7ad4d724aee64b10e1e790a16ba152768", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b40c3d49af780ca4a5d309f3c434d7f8fefa4c58", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fc90d78ba482a53d867382ceeb73d85d678e5db", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=167d911182695702969305badfff1b4b1cf51aab", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=accd0a6eb7acf9b76dca5e4191e51b903a4aa227", "width": 1080, "height": 567}], "variants": {}, "id": "D2sMhqXf73jaVMZw01DtRTchkeGVvrYwOOR-HI2Bzhs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14az4gz", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14az4gz/the_dagster_master_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-master-plan", "subreddit_subscribers": 110753, "created_utc": 1686927674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semantic Layer Sync to connect Cube to BI tools like Superset and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14aaw6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/acju1GEriKBJIa7fWHAHsxt01HI6EimFmzq_C2uf7bI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686857154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-semantic-layer-sync", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?auto=webp&amp;v=enabled&amp;s=5e9ceabbfac593efe45b895da8e120009dfe1f58", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d2be7930877af4635a0145f4a36fb9caa269543", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b6c4eecffbeb60d21a55bb03109c17955fa065f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f001bae86760dbc938265f050dcd72e613f1aeb1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4572125ca3bafb509da45f9dac8006a484667c64", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dec4b6ad8f87d4aa88b26e559856df3a0f01a82", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/nT5yyt3AxLB92opFcpJoynd3Zbt4h1H2866TH1KJANc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04f3e52f8ac4a1bf21ddc1877f0fb8716037763e", "width": 1080, "height": 567}], "variants": {}, "id": "2avi_icXINfxH9P1XchLINHjz55Qn91geqTToNKicR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14aaw6p", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aaw6p/semantic_layer_sync_to_connect_cube_to_bi_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-semantic-layer-sync", "subreddit_subscribers": 110753, "created_utc": 1686857154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in BigQuery and we're using a traditional star schema to build out our data model. However I'm learning that BQ is columnar based so it'll only scan the columns you pull. That gets me wondering, what if we just had a really wide fact table that had all the attributes listed. That way we'd scan less data when doing the joins, no need to join to anything, and the ETL would be much easier as would wouldn't need to do a bunch of inserts into the different dim tables.\n\nAnyone have any experience with this and what the pros and cons would be?\n\nAlso our tables are partitioned by date so we've worked on our optimization there as well.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traditional Star Schema vs Wide Fact Table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ad9je", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686862825.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in BigQuery and we&amp;#39;re using a traditional star schema to build out our data model. However I&amp;#39;m learning that BQ is columnar based so it&amp;#39;ll only scan the columns you pull. That gets me wondering, what if we just had a really wide fact table that had all the attributes listed. That way we&amp;#39;d scan less data when doing the joins, no need to join to anything, and the ETL would be much easier as would wouldn&amp;#39;t need to do a bunch of inserts into the different dim tables.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any experience with this and what the pros and cons would be?&lt;/p&gt;\n\n&lt;p&gt;Also our tables are partitioned by date so we&amp;#39;ve worked on our optimization there as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ad9je", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ad9je/traditional_star_schema_vs_wide_fact_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ad9je/traditional_star_schema_vs_wide_fact_table/", "subreddit_subscribers": 110753, "created_utc": 1686862825.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I just started my new project and I have a problem with data cleaning. I  don't know which path I'm supposed to go. Cleaning data in Python  Pandas or importing CSV into the database, I must say that cleaning data  in the database is so much easier. I don't know why people do analysis  in Python", "author_fullname": "t2_c4wcir5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Cleaning (Pyhton vs Database)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14atps1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686912845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my new project and I have a problem with data cleaning. I  don&amp;#39;t know which path I&amp;#39;m supposed to go. Cleaning data in Python  Pandas or importing CSV into the database, I must say that cleaning data  in the database is so much easier. I don&amp;#39;t know why people do analysis  in Python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14atps1", "is_robot_indexable": true, "report_reasons": null, "author": "AdOrnery1159", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14atps1/data_cleaning_pyhton_vs_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14atps1/data_cleaning_pyhton_vs_database/", "subreddit_subscribers": 110753, "created_utc": 1686912845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, right now I am working in finance (credit risk, customer selection models etc), one of the top world banks. My job involves compilance, analyzing the models, whether the data is correct and so on. It involves also writing reports and conclusions about the models for upper managment. I do have some ML, statistics, risk, python knowledge but I thought I would move to more coding job so it would be more stimulating for me. Are this skills actually possible to leverege in data engineer/analytics engineer role (I would like to do something like this). I would not like to start completely at junior level because my background is kind of flexible and some parts of the job do have intersections with DE job. I am right now doing some courses on the GCP and will start building projects using docker etc for the future. Are there some roles that would have intersections involving my job and possible DE job? Thanks!", "author_fullname": "t2_2oo6rj79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job transition - finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14arw5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686906594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, right now I am working in finance (credit risk, customer selection models etc), one of the top world banks. My job involves compilance, analyzing the models, whether the data is correct and so on. It involves also writing reports and conclusions about the models for upper managment. I do have some ML, statistics, risk, python knowledge but I thought I would move to more coding job so it would be more stimulating for me. Are this skills actually possible to leverege in data engineer/analytics engineer role (I would like to do something like this). I would not like to start completely at junior level because my background is kind of flexible and some parts of the job do have intersections with DE job. I am right now doing some courses on the GCP and will start building projects using docker etc for the future. Are there some roles that would have intersections involving my job and possible DE job? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14arw5e", "is_robot_indexable": true, "report_reasons": null, "author": "Omnetfh", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14arw5e/job_transition_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14arw5e/job_transition_finance/", "subreddit_subscribers": 110753, "created_utc": 1686906594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Redditors,\n\nI'm currently exploring the field of system design and looking to deepen my understanding of this fascinating subject. I've been studying on my own and have a decent grasp of the basics, but I'm now interested in finding more structured and comprehensive resources to further my knowledge.\n\nI was wondering if any of you have come across university courses or programs that specifically focus on system design. I believe that formal education could provide a solid foundation and a more in-depth exploration of the subject matter.\n\n&amp;#x200B;\n\nAdditionally, if you have any personal experiences, insights, or resources that have helped you in your system design journey, please feel free to share them as well. Any books, online tutorials, or other materials you found valuable would be highly appreciated.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_52qbnz6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are There Any University Courses on System Design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ajo25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686879485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring the field of system design and looking to deepen my understanding of this fascinating subject. I&amp;#39;ve been studying on my own and have a decent grasp of the basics, but I&amp;#39;m now interested in finding more structured and comprehensive resources to further my knowledge.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if any of you have come across university courses or programs that specifically focus on system design. I believe that formal education could provide a solid foundation and a more in-depth exploration of the subject matter.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, if you have any personal experiences, insights, or resources that have helped you in your system design journey, please feel free to share them as well. Any books, online tutorials, or other materials you found valuable would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ajo25", "is_robot_indexable": true, "report_reasons": null, "author": "ravicric", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ajo25/are_there_any_university_courses_on_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ajo25/are_there_any_university_courses_on_system_design/", "subreddit_subscribers": 110753, "created_utc": 1686879485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there! I am a mechanical engineer but currently working as a Senior Business Analyst at a fintech on a developing country. My activities mainly revolve around working with Python/SQL to run data analysis and create visualizations, thus generating business value.\n\nI have developed a liking for DE and since the beginning of the year I started getting my feet wet on the field, and here's what I have done so far:\n\n1. Got my hands on Fundamentals of Data Engineering to get a good feeling of the fundamentals, but still have trouble completing reading it cover to cover (I admit I am not a good reader)\n\n2. Completed a 4 month bootcamp, which was not top notch quality but helped me get a grasp of some concepts, tools and run some projects\n\n3. Developed 3 pet projects using Python (OOP and Pandas, mostly), SQL, basic cloud services (AWS S3 and Redshift/ GCP Cloud Storage, VMs and BigQuery), Data Modeling concepts, Tests with Pytest, Airflow for orchestration, Docker to run both Airflow and Postgres containers and data viz tools.\n\nI am trying to figure out what my next steps are. Here are the things I am considering\n\n1. Forcing myself to read Fundamentals of Data Engineering cover to cover\n\n2. Picking up another course, as I tend to learn better having an structured path I can follow. I have two in mind: Udacity's [Data Engineering Nanodegree on AWS](https://www.udacity.com/course/data-engineer-nanodegree--nd027) (not so good reviews) or Andreas' Kretz [Data Engineering Academy](https://learndataengineering.com/p/academy) (couldn't find much feedback on it). The goal here is getting more exposure to different concepts and tools (like distributed computing using Spark and Kafka) as well as building on the things I already got exposure to.\n\n3. Going the cert route. Some options: [Astronomer's Airflow certification](https://academy.astronomer.io/astronomer-certified-apache-airflow-core-exam) (I got it for free), [AWS Cloud Practioneer](https://aws.amazon.com/certification/certified-cloud-practitioner/) or [GCP Associate Cloud Engineer](https://cloud.google.com/certification/cloud-engineer) (my company uses GCP and that can be a factor)\n\nI am trying to figure out what's the best ROI in terms of both money and time. Would you mind sharing your two cents? Thanks.", "author_fullname": "t2_ghwq1i0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me figure out the next steps of my DE learning journey!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14afyeh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686869228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I am a mechanical engineer but currently working as a Senior Business Analyst at a fintech on a developing country. My activities mainly revolve around working with Python/SQL to run data analysis and create visualizations, thus generating business value.&lt;/p&gt;\n\n&lt;p&gt;I have developed a liking for DE and since the beginning of the year I started getting my feet wet on the field, and here&amp;#39;s what I have done so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Got my hands on Fundamentals of Data Engineering to get a good feeling of the fundamentals, but still have trouble completing reading it cover to cover (I admit I am not a good reader)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Completed a 4 month bootcamp, which was not top notch quality but helped me get a grasp of some concepts, tools and run some projects&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Developed 3 pet projects using Python (OOP and Pandas, mostly), SQL, basic cloud services (AWS S3 and Redshift/ GCP Cloud Storage, VMs and BigQuery), Data Modeling concepts, Tests with Pytest, Airflow for orchestration, Docker to run both Airflow and Postgres containers and data viz tools.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am trying to figure out what my next steps are. Here are the things I am considering&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Forcing myself to read Fundamentals of Data Engineering cover to cover&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Picking up another course, as I tend to learn better having an structured path I can follow. I have two in mind: Udacity&amp;#39;s &lt;a href=\"https://www.udacity.com/course/data-engineer-nanodegree--nd027\"&gt;Data Engineering Nanodegree on AWS&lt;/a&gt; (not so good reviews) or Andreas&amp;#39; Kretz &lt;a href=\"https://learndataengineering.com/p/academy\"&gt;Data Engineering Academy&lt;/a&gt; (couldn&amp;#39;t find much feedback on it). The goal here is getting more exposure to different concepts and tools (like distributed computing using Spark and Kafka) as well as building on the things I already got exposure to.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Going the cert route. Some options: &lt;a href=\"https://academy.astronomer.io/astronomer-certified-apache-airflow-core-exam\"&gt;Astronomer&amp;#39;s Airflow certification&lt;/a&gt; (I got it for free), &lt;a href=\"https://aws.amazon.com/certification/certified-cloud-practitioner/\"&gt;AWS Cloud Practioneer&lt;/a&gt; or &lt;a href=\"https://cloud.google.com/certification/cloud-engineer\"&gt;GCP Associate Cloud Engineer&lt;/a&gt; (my company uses GCP and that can be a factor)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am trying to figure out what&amp;#39;s the best ROI in terms of both money and time. Would you mind sharing your two cents? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?auto=webp&amp;v=enabled&amp;s=7209ab4475371d979ea53c765e4879a1494ec237", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ef17ebe9474fe876ba5f596976122604abb349b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad79f389a39a9be76a06be921d1a6848242ea490", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=176a5e7b8ef6eb4582d678647b72a7441d0bfd8a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06bcb0ddb6b9cfc8090c4ddfcbdf9ca95ae3c234", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50a33f67f093b7db6d87ac8abbc0e12655f4911a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/N_zmRgqg5tJxPlD1di_4s_hPL5STdgdWxcTbEumqbP4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a4fc464563baebf13686fbddc6e56a4de8cc09c", "width": 1080, "height": 567}], "variants": {}, "id": "qyhAU2yjVXk1e9zfugxtYEgqPn3zOzlf71XxIsed1Mg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14afyeh", "is_robot_indexable": true, "report_reasons": null, "author": "savarinho", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14afyeh/help_me_figure_out_the_next_steps_of_my_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14afyeh/help_me_figure_out_the_next_steps_of_my_de/", "subreddit_subscribers": 110753, "created_utc": 1686869228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Of course, it goes without saying, we can almost guarantee that Microsoft will somehow find a way of fucking this up.  That being said, as the title says, I've started looking into the promo materials and am not entirely unhappy with what they're offering provided they pull it off.\n\n**Existing trends based on the demos**\n\n* For data, whilst people on here hate developing in notebooks, they clearly aren't going anywhere any time soon.  They're extremely favoured by businesses and, currently, according to my understanding of Azure pricing, there seems to be very little difference in cost in Synapse for using a notebook vs. a Spark job in terms of compute, whereas that cost difference is very clear on Databricks (for the anticipated \"notebooks in PRODUCTION?? REEEEEE\" comments).\n\n**What I'm looking forward to**\n\n* **Native VS code integration**: The fact they're putting this in makes me think thank fuck.  Working in notebooks isn't always the most fun, especially when something is a bit bigger although, as mentioned, the fact it can plug into pipelines as first class citizens makes them bearable.  Being able to run them on a spark pool from an actual IDE would make them a lot more bearable.  I'm still annoyed it has taken this long to happen though.\n\n* **Library/Dependency management**: Managing extra Python libraries in Synapse sucks so much dick. The fact this has even been considered is, for me, good enough.  The fact that this is something I'm looking forward to is, to be honest, pretty sad. \n\n* **Additional connectors**: Very small, although they revealed a native email connector which can be used in-line with pipelines which makes me wonder what else they have going on.  Again, very low impact.\n\n**What I think will still be shit**\n\n* **CI/CD**: I can almost guarantee the CI/CD experience in Fabric will be dreadful because I highly doubt they've rebuilt the way they do everything (JSONs holding the definitions for workspaces).\n\n* **Costs**: We will all feel disgusted by how much having all of this functionality costs.\n\n* **Azure Data Flows**: I think anybody who has the option to avoid using these would agree these are absolute demonspawn to work with.  If given the choice, I'd rather actively search for the last King in a very sweaty game of Ring of Fire (or King's cup depending where you're from) and neck a dirty pint before working with these.\n\n* **Spark cluster management**: Databricks absolutely shits on Microsoft every time in this regard.\n\n* **Most things Synapse related**: I work with Synapse a lot and have gone from absolutely hating it to thinking there's actually quite a lot of convenience once you get going with enough data.  That being said, there are just so many things Synapse does poorly.\n\n**What I don't know**\n\n* They mentioned Github Copilot integration which got me thinking - will there be further LLM integration (I don't know if Github Copilot is technically a child of LLM)? Thinking it'd be quite interesting being able to potentially do data analysis and summaries in plain English as comments in notebooks.\n\n* Is this going to be enough to drag people away from Databricks?\n\n* Like Synapse, how are Microsoft going to absolutely chuck this after release?\n\n* Lastly, is Fabric simply doing far too much for it's own good? Wondering if this is going to be Synapse 2 and it's going to just die slowly.\n\nIf you are either currently in an MS stack or looking to go into one, what are you looking forward to, what do you think will still be awful, and what are you hoping for?", "author_fullname": "t2_2gp1vrnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I started watching some of the promotional materials on MS Fabric and, unfortunately, am not completely upset about it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aeq5c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686866234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Of course, it goes without saying, we can almost guarantee that Microsoft will somehow find a way of fucking this up.  That being said, as the title says, I&amp;#39;ve started looking into the promo materials and am not entirely unhappy with what they&amp;#39;re offering provided they pull it off.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Existing trends based on the demos&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;For data, whilst people on here hate developing in notebooks, they clearly aren&amp;#39;t going anywhere any time soon.  They&amp;#39;re extremely favoured by businesses and, currently, according to my understanding of Azure pricing, there seems to be very little difference in cost in Synapse for using a notebook vs. a Spark job in terms of compute, whereas that cost difference is very clear on Databricks (for the anticipated &amp;quot;notebooks in PRODUCTION?? REEEEEE&amp;quot; comments).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking forward to&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Native VS code integration&lt;/strong&gt;: The fact they&amp;#39;re putting this in makes me think thank fuck.  Working in notebooks isn&amp;#39;t always the most fun, especially when something is a bit bigger although, as mentioned, the fact it can plug into pipelines as first class citizens makes them bearable.  Being able to run them on a spark pool from an actual IDE would make them a lot more bearable.  I&amp;#39;m still annoyed it has taken this long to happen though.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Library/Dependency management&lt;/strong&gt;: Managing extra Python libraries in Synapse sucks so much dick. The fact this has even been considered is, for me, good enough.  The fact that this is something I&amp;#39;m looking forward to is, to be honest, pretty sad. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Additional connectors&lt;/strong&gt;: Very small, although they revealed a native email connector which can be used in-line with pipelines which makes me wonder what else they have going on.  Again, very low impact.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What I think will still be shit&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;CI/CD&lt;/strong&gt;: I can almost guarantee the CI/CD experience in Fabric will be dreadful because I highly doubt they&amp;#39;ve rebuilt the way they do everything (JSONs holding the definitions for workspaces).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Costs&lt;/strong&gt;: We will all feel disgusted by how much having all of this functionality costs.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Azure Data Flows&lt;/strong&gt;: I think anybody who has the option to avoid using these would agree these are absolute demonspawn to work with.  If given the choice, I&amp;#39;d rather actively search for the last King in a very sweaty game of Ring of Fire (or King&amp;#39;s cup depending where you&amp;#39;re from) and neck a dirty pint before working with these.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Spark cluster management&lt;/strong&gt;: Databricks absolutely shits on Microsoft every time in this regard.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Most things Synapse related&lt;/strong&gt;: I work with Synapse a lot and have gone from absolutely hating it to thinking there&amp;#39;s actually quite a lot of convenience once you get going with enough data.  That being said, there are just so many things Synapse does poorly.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What I don&amp;#39;t know&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;They mentioned Github Copilot integration which got me thinking - will there be further LLM integration (I don&amp;#39;t know if Github Copilot is technically a child of LLM)? Thinking it&amp;#39;d be quite interesting being able to potentially do data analysis and summaries in plain English as comments in notebooks.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is this going to be enough to drag people away from Databricks?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Like Synapse, how are Microsoft going to absolutely chuck this after release?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Lastly, is Fabric simply doing far too much for it&amp;#39;s own good? Wondering if this is going to be Synapse 2 and it&amp;#39;s going to just die slowly.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you are either currently in an MS stack or looking to go into one, what are you looking forward to, what do you think will still be awful, and what are you hoping for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Shitty Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14aeq5c", "is_robot_indexable": true, "report_reasons": null, "author": "MikeDoesEverything", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14aeq5c/i_started_watching_some_of_the_promotional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aeq5c/i_started_watching_some_of_the_promotional/", "subreddit_subscribers": 110753, "created_utc": 1686866234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm building a pipeline to extract data from a number of tables in a mysql database, transform some of the data and run some logic before storing the result in another database for use by a Looker Studio dashboard. In theory all very simple stuff, so having created something similar at a previous job using Airflow, I thought i'd look around for the best practises for a modern data stack. \n\nThis brought me to dagster. Really cool software, similar to Airflow in many ways but feels more modern. I've paired it with Airbyte to extract data from the production database to a reporting database. The dagster assets then run their magic and I wrote a final asset to write the information to another database (using SQLAlchemy in the end because I can't for the life of me figure out how to upsert data into a database using dataframes.)\n\nSo this all mostly works, but my issue now is regarding partitioning of the data. In the source database, there's a table tracking number of sales by cashier. The assets are configured with the DailyPartitionsDefinition partitions definition to allow for backfilling. My assets work but my long winded question is: when backfilling multiple days of data, the sync request on my airbyte resources is triggered for each backfill, leading to a timeout by the airbyte server from the later backfill requests. How should I best structure my assets to prevent this?\n\nOptions:\n\n* Remove airbyte from dagsterand figure out a way to connect the assets without the integration\n* Do everything manually in Python and dagster. Read from the database taking into account partitioning, e.g. select \\* from sales where date = 2023-06-16\n* Rip it all out and go back to Airflow\n\nI really like dagster, I just can't get my head around this. Every example I see is either really simple or way too complicated.\n\nSorry for the rambling question, I hope it makes sense but any direction would be very much appreciated!", "author_fullname": "t2_3zctr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster/Airbyte ELT - Feeling like i'm losing my mind!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14au1rj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686913872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m building a pipeline to extract data from a number of tables in a mysql database, transform some of the data and run some logic before storing the result in another database for use by a Looker Studio dashboard. In theory all very simple stuff, so having created something similar at a previous job using Airflow, I thought i&amp;#39;d look around for the best practises for a modern data stack. &lt;/p&gt;\n\n&lt;p&gt;This brought me to dagster. Really cool software, similar to Airflow in many ways but feels more modern. I&amp;#39;ve paired it with Airbyte to extract data from the production database to a reporting database. The dagster assets then run their magic and I wrote a final asset to write the information to another database (using SQLAlchemy in the end because I can&amp;#39;t for the life of me figure out how to upsert data into a database using dataframes.)&lt;/p&gt;\n\n&lt;p&gt;So this all mostly works, but my issue now is regarding partitioning of the data. In the source database, there&amp;#39;s a table tracking number of sales by cashier. The assets are configured with the DailyPartitionsDefinition partitions definition to allow for backfilling. My assets work but my long winded question is: when backfilling multiple days of data, the sync request on my airbyte resources is triggered for each backfill, leading to a timeout by the airbyte server from the later backfill requests. How should I best structure my assets to prevent this?&lt;/p&gt;\n\n&lt;p&gt;Options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Remove airbyte from dagsterand figure out a way to connect the assets without the integration&lt;/li&gt;\n&lt;li&gt;Do everything manually in Python and dagster. Read from the database taking into account partitioning, e.g. select * from sales where date = 2023-06-16&lt;/li&gt;\n&lt;li&gt;Rip it all out and go back to Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I really like dagster, I just can&amp;#39;t get my head around this. Every example I see is either really simple or way too complicated.&lt;/p&gt;\n\n&lt;p&gt;Sorry for the rambling question, I hope it makes sense but any direction would be very much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14au1rj", "is_robot_indexable": true, "report_reasons": null, "author": "dixonl90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14au1rj/dagsterairbyte_elt_feeling_like_im_losing_my_mind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14au1rj/dagsterairbyte_elt_feeling_like_im_losing_my_mind/", "subreddit_subscribers": 110753, "created_utc": 1686913872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work more in the Analytics Engineering space so my question might not make complete sense however I would appreciate any clarity than can be provided.\n\nMy understanding is a common way for data to flow is as follows:\n\nApplication database (MySQL) &gt;&gt; Datalake (S3) &gt;&gt; Data Warehouse (Snowflake).\n\nAs an Analytics Eng I do many transformations in the Data Warehouse. \n\nWhy does the data need to go into S3 first? \n\nAre additional transformations happening in there done by the Data Engineer? \n\nCould S3 be removed and the data can go directly from the application database to the data warehouse?\n\nThanks", "author_fullname": "t2_fwqwbjia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Flow Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14attqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686913208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work more in the Analytics Engineering space so my question might not make complete sense however I would appreciate any clarity than can be provided.&lt;/p&gt;\n\n&lt;p&gt;My understanding is a common way for data to flow is as follows:&lt;/p&gt;\n\n&lt;p&gt;Application database (MySQL) &amp;gt;&amp;gt; Datalake (S3) &amp;gt;&amp;gt; Data Warehouse (Snowflake).&lt;/p&gt;\n\n&lt;p&gt;As an Analytics Eng I do many transformations in the Data Warehouse. &lt;/p&gt;\n\n&lt;p&gt;Why does the data need to go into S3 first? &lt;/p&gt;\n\n&lt;p&gt;Are additional transformations happening in there done by the Data Engineer? &lt;/p&gt;\n\n&lt;p&gt;Could S3 be removed and the data can go directly from the application database to the data warehouse?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14attqq", "is_robot_indexable": true, "report_reasons": null, "author": "space-trader-92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14attqq/data_flow_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14attqq/data_flow_question/", "subreddit_subscribers": 110753, "created_utc": 1686913208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd love to use prefect as a self hosted service. I've been able to deploy it behind a nginx proxy with oauth authentication but that breaks their cli. Om familiar with the basic oauth paradigm and have used the Google oauth package to authenticate, then pass those headers to the requests library. \n\nCan I do something similar to use their cli? Where do I store the credentials?", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone self hosting prefect? How are you handling oauth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14afact", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686867574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d love to use prefect as a self hosted service. I&amp;#39;ve been able to deploy it behind a nginx proxy with oauth authentication but that breaks their cli. Om familiar with the basic oauth paradigm and have used the Google oauth package to authenticate, then pass those headers to the requests library. &lt;/p&gt;\n\n&lt;p&gt;Can I do something similar to use their cli? Where do I store the credentials?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14afact", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14afact/anyone_self_hosting_prefect_how_are_you_handling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14afact/anyone_self_hosting_prefect_how_are_you_handling/", "subreddit_subscribers": 110753, "created_utc": 1686867574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey everyone,\n\nI've been exploring the world of big data and cloud computing lately, and I've come across two powerful tools: Databricks and AWS Glue. However, I'm still trying to understand how these two services work together.\n\nI know that Databricks is a unified analytics platform built on Apache Spark, which allows you to process big data and perform advanced analytics. On the other hand, AWS Glue is an ETL (Extract, Transform, Load) service provided by Amazon Web Services (AWS).\n\nWhat I'm particularly interested in is how Databricks utilizes AWS Glue. I've heard that Glue can help with data preparation and integration tasks, but I'm curious about the specific use cases and benefits of using Glue within the Databricks ecosystem.\n\nDoes anyone have experience or insights into how Databricks integrates with AWS Glue? How does Glue enhance the data processing capabilities of Databricks? Are there any specific features or functionalities that make this integration advantageous?\n\nI'm looking to understand the synergy between these two services and how they can work together to streamline big data workflows. Any real-world examples, tutorials, or recommended resources would be greatly appreciated.\n\nThanks in advance for your help!", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Databricks utilize AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aslc7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686909052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring the world of big data and cloud computing lately, and I&amp;#39;ve come across two powerful tools: Databricks and AWS Glue. However, I&amp;#39;m still trying to understand how these two services work together.&lt;/p&gt;\n\n&lt;p&gt;I know that Databricks is a unified analytics platform built on Apache Spark, which allows you to process big data and perform advanced analytics. On the other hand, AWS Glue is an ETL (Extract, Transform, Load) service provided by Amazon Web Services (AWS).&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m particularly interested in is how Databricks utilizes AWS Glue. I&amp;#39;ve heard that Glue can help with data preparation and integration tasks, but I&amp;#39;m curious about the specific use cases and benefits of using Glue within the Databricks ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience or insights into how Databricks integrates with AWS Glue? How does Glue enhance the data processing capabilities of Databricks? Are there any specific features or functionalities that make this integration advantageous?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to understand the synergy between these two services and how they can work together to streamline big data workflows. Any real-world examples, tutorials, or recommended resources would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14aslc7", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aslc7/how_does_databricks_utilize_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aslc7/how_does_databricks_utilize_aws_glue/", "subreddit_subscribers": 110753, "created_utc": 1686909052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Concepts #1 \u2014 Slowly Changing Dimensions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_14aptlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/j33fu5QP0HvPZZMWG2BYVM1eRcbeejhl-7jE8f5YNkc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686899178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdev.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdev.com/data-engineering-concepts-1-slowly-changing-dimensions-851d52446ccd", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?auto=webp&amp;v=enabled&amp;s=ff330e6e2e5785bb8424797f7c39d4b74c190af8", "width": 1042, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de25db31e40a22646c5c596b81063b75c3023763", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc4bb5daa5da77bc5cb6835c507556dcf88406cb", "width": 216, "height": 159}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=262252caf96f6c965bdebbacfe2b0aab892bb2e2", "width": 320, "height": 235}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=460c0fd68ca540a96b5ba363148877845d82447a", "width": 640, "height": 471}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65d1b0eb76070d9857982a27cb530dc1902310e6", "width": 960, "height": 707}], "variants": {}, "id": "5kaNvsWQE49zdI4YIIyHTEvB1Quj-zmYZ9zpTSBU7Og"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14aptlk", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aptlk/data_engineering_concepts_1_slowly_changing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdev.com/data-engineering-concepts-1-slowly-changing-dimensions-851d52446ccd", "subreddit_subscribers": 110753, "created_utc": 1686899178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm not sure if this is the right sub, but what I'm working on is somewhere between backend and data eng'g. Anyw, I\u2019m currently setting up a log-based cdc with debezium that feeds a message broker for streams. The thing is, I want to only capture the record if the command is an update. However, I can't find any good resource that tackles the configuration for debezium to function like that. If \"directly altering debezium behavior\" is not an option, then I can only think of one solution - create an outbox table to store updated records, that of which can be implemented w either of the ff:\n\n(a) Let some middleman (stored procedures) trigger the insertion of record to the outbox table and it gets deleted as soon as the connector publishes it to the broker to keep the db clean. This is a process that happens at the db level; I am abstracting the work away from the application layer. The drawbacks now would be: trouble with keeping this procedure as part of the entire update transaction since the update is handled by an ORM tool from the app layer. This can be solved by (b) though.\n\n(b) To keep the entire update + insertion to outbox table an entire transaction, I perform the write on the service that deals with update operation and wrap these into one transactional method. Now the drawbacks would be, it adds unnecessary configs and load to the app layer. \n\nAre there better workarounds for this? If there are configurable alternatives to debezium, please let me know. Thank you very much.", "author_fullname": "t2_t73a89x8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debezium for Postgres CDC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14azwp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686929551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not sure if this is the right sub, but what I&amp;#39;m working on is somewhere between backend and data eng&amp;#39;g. Anyw, I\u2019m currently setting up a log-based cdc with debezium that feeds a message broker for streams. The thing is, I want to only capture the record if the command is an update. However, I can&amp;#39;t find any good resource that tackles the configuration for debezium to function like that. If &amp;quot;directly altering debezium behavior&amp;quot; is not an option, then I can only think of one solution - create an outbox table to store updated records, that of which can be implemented w either of the ff:&lt;/p&gt;\n\n&lt;p&gt;(a) Let some middleman (stored procedures) trigger the insertion of record to the outbox table and it gets deleted as soon as the connector publishes it to the broker to keep the db clean. This is a process that happens at the db level; I am abstracting the work away from the application layer. The drawbacks now would be: trouble with keeping this procedure as part of the entire update transaction since the update is handled by an ORM tool from the app layer. This can be solved by (b) though.&lt;/p&gt;\n\n&lt;p&gt;(b) To keep the entire update + insertion to outbox table an entire transaction, I perform the write on the service that deals with update operation and wrap these into one transactional method. Now the drawbacks would be, it adds unnecessary configs and load to the app layer. &lt;/p&gt;\n\n&lt;p&gt;Are there better workarounds for this? If there are configurable alternatives to debezium, please let me know. Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14azwp3", "is_robot_indexable": true, "report_reasons": null, "author": "midnight_babyyy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14azwp3/debezium_for_postgres_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14azwp3/debezium_for_postgres_cdc/", "subreddit_subscribers": 110753, "created_utc": 1686929551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to implement data sanity check for two databases, also return the inconsistent results(most prob extact rows) and since I have to implement this for a very huge database(let\u2019s say each database have min. 20 tables each with 2.5M+ data) so what techniques would you suggest? Or do you use in your company?", "author_fullname": "t2_aahomxjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you perform data sanity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ay92f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686925544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to implement data sanity check for two databases, also return the inconsistent results(most prob extact rows) and since I have to implement this for a very huge database(let\u2019s say each database have min. 20 tables each with 2.5M+ data) so what techniques would you suggest? Or do you use in your company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ay92f", "is_robot_indexable": true, "report_reasons": null, "author": "Icraveviolencemother", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ay92f/how_do_you_perform_data_sanity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ay92f/how_do_you_perform_data_sanity/", "subreddit_subscribers": 110753, "created_utc": 1686925544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven't found much on this topic. To me this seems an oversight/developer marketing opportunity, as I can see a lot of companies/projects wanting to do this in the near future.\n\nAnyway, do you have any good resources you can point me to?  \n\nHow would you approach it?  \n\nHave a CDC pipeline with Debezium/Kafka to consume the Postgres events and then build a custom connector to Qdrant (in my case)?  \n\nDo you have any learning materials that would make it easier for me to get going?", "author_fullname": "t2_c056b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep a vector database in sync with a source-of-truth SQL database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14asu6u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686909874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t found much on this topic. To me this seems an oversight/developer marketing opportunity, as I can see a lot of companies/projects wanting to do this in the near future.&lt;/p&gt;\n\n&lt;p&gt;Anyway, do you have any good resources you can point me to?  &lt;/p&gt;\n\n&lt;p&gt;How would you approach it?  &lt;/p&gt;\n\n&lt;p&gt;Have a CDC pipeline with Debezium/Kafka to consume the Postgres events and then build a custom connector to Qdrant (in my case)?  &lt;/p&gt;\n\n&lt;p&gt;Do you have any learning materials that would make it easier for me to get going?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14asu6u", "is_robot_indexable": true, "report_reasons": null, "author": "retendo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14asu6u/how_to_keep_a_vector_database_in_sync_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14asu6u/how_to_keep_a_vector_database_in_sync_with_a/", "subreddit_subscribers": 110753, "created_utc": 1686909874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to use the limit offset feature of HiveQL to paginate a table. My question is that if I use this feature without using ORDER BY to order the table will the order of rows returned by the query be determinate or will it be random, in which case is there a chance that I could get duplicate rows in subsequent pages. \n\nIf the order of the rows is determinate will this query be faster than the query using ORDER BY or does limit offset also somehow use ordering inside of it resulting no performance gain?", "author_fullname": "t2_5jmtd87l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does HiveQL guarantee determinate order of rows returned in case of limit offset queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aoihp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686894776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to use the limit offset feature of HiveQL to paginate a table. My question is that if I use this feature without using ORDER BY to order the table will the order of rows returned by the query be determinate or will it be random, in which case is there a chance that I could get duplicate rows in subsequent pages. &lt;/p&gt;\n\n&lt;p&gt;If the order of the rows is determinate will this query be faster than the query using ORDER BY or does limit offset also somehow use ordering inside of it resulting no performance gain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14aoihp", "is_robot_indexable": true, "report_reasons": null, "author": "Pantheramaximus", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aoihp/does_hiveql_guarantee_determinate_order_of_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aoihp/does_hiveql_guarantee_determinate_order_of_rows/", "subreddit_subscribers": 110753, "created_utc": 1686894776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow Data Engineers,\n\nI'm currently working at a tech company as a Senior Data Engineer; I was laid off last year by another company, and while looking for my current job, I noticed many hiring managers like more to have a Software Engineer title in the resume.\n\nMy current job has lots of Software Engineering work (e.g., developing AWS lambdas in TypeScript), so I don't feel too distant from an SWE. I also want to always target more technical DE roles instead of analytical ones (like my previous role at FAANG).\n\nSo I was wondering if it's okay changing the title in my resume (for future jobs), from Senior Data Engineer to Senior Software Engineer (Data).\n\nIs there any potential downside when doing a background check?\n\n[View Poll](https://www.reddit.com/poll/14b12o5)", "author_fullname": "t2_5dn8ds4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to change the title in my resume from Data Engineer to Software Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b12o5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686932387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working at a tech company as a Senior Data Engineer; I was laid off last year by another company, and while looking for my current job, I noticed many hiring managers like more to have a Software Engineer title in the resume.&lt;/p&gt;\n\n&lt;p&gt;My current job has lots of Software Engineering work (e.g., developing AWS lambdas in TypeScript), so I don&amp;#39;t feel too distant from an SWE. I also want to always target more technical DE roles instead of analytical ones (like my previous role at FAANG).&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if it&amp;#39;s okay changing the title in my resume (for future jobs), from Senior Data Engineer to Senior Software Engineer (Data).&lt;/p&gt;\n\n&lt;p&gt;Is there any potential downside when doing a background check?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14b12o5\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b12o5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Muffin-8079", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1687364387266, "options": [{"text": "Changing title to Software Engineer, Data", "id": "23495915"}, {"text": "Changing title to Software Engineer", "id": "23495916"}, {"text": "Leaving title as Data Engineer", "id": "23495917"}, {"text": "View results", "id": "23495918"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 71, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b12o5/is_it_ok_to_change_the_title_in_my_resume_from/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/14b12o5/is_it_ok_to_change_the_title_in_my_resume_from/", "subreddit_subscribers": 110753, "created_utc": 1686932387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model and Data Versioning: An Introduction to mlflow and DVC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14avpao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/18UUk4H6u7huOYzLrAp0EU-9F4fNSuZX-CRR_ny0mHQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686918876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/walmartglobaltech/model-and-data-versioning-an-introduction-to-mlflow-and-dvc-260347cd0f6e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?auto=webp&amp;v=enabled&amp;s=c6f576dea82fe4d4c467239ef411c86b8f85de28", "width": 934, "height": 524}, "resolutions": [{"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=022ff67292ee0d96700d98e250dfdb2490907eb9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d50e59cb44b20a9630c6fd1add53bc436244d51", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5615b277d788185f428fee0b1a0dab672078241d", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8465c379f3313251030dc1c2cc78ba050aa56e76", "width": 640, "height": 359}], "variants": {}, "id": "3VBNHf_29E4hJ2ZK7F-hdoRprCfV28NKadAC3E-K_Cg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14avpao", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14avpao/model_and_data_versioning_an_introduction_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/walmartglobaltech/model-and-data-versioning-an-introduction-to-mlflow-and-dvc-260347cd0f6e", "subreddit_subscribers": 110753, "created_utc": 1686918876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI've recently started to study some of the tools necessary to become a data engineer: airflow, spark, etc. However, while some things are starting to make sense, I'm still trying to figure out the beggining of it all: how do you even start to incorporate this tools in a company that does not use them at all?\n\nWhat I'm trying to understand, and I am failing to do, is what should be the first steps of implementation. For instance, my company has a lot of IoT data that they don't use - but want to start doing so, and I would love to be part of it and learn how to build pipelines, understand more about how we should storage the data, etc. \n\nDoes anyone here have this initial implementation experience and would like to share? Books, articles, anything is valid.\n\n&amp;#x200B;\n\nThank you for your time.", "author_fullname": "t2_2117hvx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does one starts applying data engineering in a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14at7ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686911097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started to study some of the tools necessary to become a data engineer: airflow, spark, etc. However, while some things are starting to make sense, I&amp;#39;m still trying to figure out the beggining of it all: how do you even start to incorporate this tools in a company that does not use them at all?&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m trying to understand, and I am failing to do, is what should be the first steps of implementation. For instance, my company has a lot of IoT data that they don&amp;#39;t use - but want to start doing so, and I would love to be part of it and learn how to build pipelines, understand more about how we should storage the data, etc. &lt;/p&gt;\n\n&lt;p&gt;Does anyone here have this initial implementation experience and would like to share? Books, articles, anything is valid.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14at7ca", "is_robot_indexable": true, "report_reasons": null, "author": "tryingnewhabits", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14at7ca/how_does_one_starts_applying_data_engineering_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14at7ca/how_does_one_starts_applying_data_engineering_in/", "subreddit_subscribers": 110753, "created_utc": 1686911097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Don't have to read any of the below, just my random thinking: \n-----\nWe're talking about creating a Data Dictionary.  What will be stored in it? Undefined.  \n\nI've been asked where to store it.  Which isn't really the big issue in my mind (more, that these things tend to fail; how can this one not fail), but it's the immediate ask. \n\nWe currently store various documentation in 8 different systems (too many)\n\n  * Yammer\n  * Teams/Sharepoint\n  * A homegrown intranet page\n  * Learning Mgmt System\n  * ServiceNow\n  * A new document mgmt system that's upcoming\n  * Onenote\n  * Dataverse tables fed via power apps\n\nThere are also 3rd party products that are expensive and I assume have weird caveats. My initial reaction is we don't need an 9th system with a subscription. Then again, I don't know what these do. I assume some cool things along with bizarre limitations. \n\nI lean toward keep it simple, either:\n  * Excel file in Sharepoint with (mostly) read-only access, or\n  * A series of database tables.  \n   * This appeals to me for the queries that could be done...but to do that, also means a more to maintain. And these things tend to fail due to lack of updates, so maybe that's not a good idea. \n  * Power app feeding a dataverse table.  Then users could enter...but would they 1 year later? \n\nSo then I'm down to an Excel file stored somewhere, starting with the bare minimum, and *if* that's kept up, expand it. \n\nYour thoughts though?", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where have your companies stored their Data Dictionary? How have you set them up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ahntm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686873694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Title. Don&amp;#39;t have to read any of the below, just my random thinking: &lt;/h2&gt;\n\n&lt;p&gt;We&amp;#39;re talking about creating a Data Dictionary.  What will be stored in it? Undefined.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked where to store it.  Which isn&amp;#39;t really the big issue in my mind (more, that these things tend to fail; how can this one not fail), but it&amp;#39;s the immediate ask. &lt;/p&gt;\n\n&lt;p&gt;We currently store various documentation in 8 different systems (too many)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Yammer&lt;/li&gt;\n&lt;li&gt;Teams/Sharepoint&lt;/li&gt;\n&lt;li&gt;A homegrown intranet page&lt;/li&gt;\n&lt;li&gt;Learning Mgmt System&lt;/li&gt;\n&lt;li&gt;ServiceNow&lt;/li&gt;\n&lt;li&gt;A new document mgmt system that&amp;#39;s upcoming&lt;/li&gt;\n&lt;li&gt;Onenote&lt;/li&gt;\n&lt;li&gt;Dataverse tables fed via power apps&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There are also 3rd party products that are expensive and I assume have weird caveats. My initial reaction is we don&amp;#39;t need an 9th system with a subscription. Then again, I don&amp;#39;t know what these do. I assume some cool things along with bizarre limitations. &lt;/p&gt;\n\n&lt;p&gt;I lean toward keep it simple, either:\n  * Excel file in Sharepoint with (mostly) read-only access, or\n  * A series of database tables.&lt;br/&gt;\n   * This appeals to me for the queries that could be done...but to do that, also means a more to maintain. And these things tend to fail due to lack of updates, so maybe that&amp;#39;s not a good idea. \n  * Power app feeding a dataverse table.  Then users could enter...but would they 1 year later? &lt;/p&gt;\n\n&lt;p&gt;So then I&amp;#39;m down to an Excel file stored somewhere, starting with the bare minimum, and &lt;em&gt;if&lt;/em&gt; that&amp;#39;s kept up, expand it. &lt;/p&gt;\n\n&lt;p&gt;Your thoughts though?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ahntm", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ahntm/where_have_your_companies_stored_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ahntm/where_have_your_companies_stored_their_data/", "subreddit_subscribers": 110753, "created_utc": 1686873694.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Concerning the data documentation in your company\n\n[View Poll](https://www.reddit.com/poll/14afbs0)", "author_fullname": "t2_6io23nxgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Concerning the data documentation in you company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14afbs0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686869899.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686867668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Concerning the data documentation in your company&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14afbs0\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14afbs0", "is_robot_indexable": true, "report_reasons": null, "author": "ricardokj", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1687040468395, "options": [{"text": "We dont have", "id": "23487039"}, {"text": "We have and don't use", "id": "23487040"}, {"text": "We have and use", "id": "23487041"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 91, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14afbs0/concerning_the_data_documentation_in_you_company/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/14afbs0/concerning_the_data_documentation_in_you_company/", "subreddit_subscribers": 110753, "created_utc": 1686867668.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}