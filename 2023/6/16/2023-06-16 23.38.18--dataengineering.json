{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Dagster Master Plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14az4gz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cLNw5l3GlrASSy-nBqRgrjOQ0usKiV_A1lL-vXs-W4c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686927674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-master-plan", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?auto=webp&amp;v=enabled&amp;s=5e576129ef6e809ae03398b59e5eac6af438af01", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8653bf88106073b8fc1cc77ebdb44700ce26eac0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a934b4c7ad4d724aee64b10e1e790a16ba152768", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b40c3d49af780ca4a5d309f3c434d7f8fefa4c58", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5fc90d78ba482a53d867382ceeb73d85d678e5db", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=167d911182695702969305badfff1b4b1cf51aab", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/VTnl1-iAcevGqv-mpuqbX_nf3KpnSxR9vKFLM9RWXm8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=accd0a6eb7acf9b76dca5e4191e51b903a4aa227", "width": 1080, "height": 567}], "variants": {}, "id": "D2sMhqXf73jaVMZw01DtRTchkeGVvrYwOOR-HI2Bzhs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14az4gz", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14az4gz/the_dagster_master_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-master-plan", "subreddit_subscribers": 110789, "created_utc": 1686927674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I just started my new project and I have a problem with data cleaning. I  don't know which path I'm supposed to go. Cleaning data in Python  Pandas or importing CSV into the database, I must say that cleaning data  in the database is so much easier. I don't know why people do analysis  in Python", "author_fullname": "t2_c4wcir5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Cleaning (Pyhton vs Database)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14atps1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686912845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started my new project and I have a problem with data cleaning. I  don&amp;#39;t know which path I&amp;#39;m supposed to go. Cleaning data in Python  Pandas or importing CSV into the database, I must say that cleaning data  in the database is so much easier. I don&amp;#39;t know why people do analysis  in Python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14atps1", "is_robot_indexable": true, "report_reasons": null, "author": "AdOrnery1159", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14atps1/data_cleaning_pyhton_vs_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14atps1/data_cleaning_pyhton_vs_database/", "subreddit_subscribers": 110789, "created_utc": 1686912845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, right now I am working in finance (credit risk, customer selection models etc), one of the top world banks. My job involves compilance, analyzing the models, whether the data is correct and so on. It involves also writing reports and conclusions about the models for upper managment. I do have some ML, statistics, risk, python knowledge but I thought I would move to more coding job so it would be more stimulating for me. Are this skills actually possible to leverege in data engineer/analytics engineer role (I would like to do something like this). I would not like to start completely at junior level because my background is kind of flexible and some parts of the job do have intersections with DE job. I am right now doing some courses on the GCP and will start building projects using docker etc for the future. Are there some roles that would have intersections involving my job and possible DE job? Thanks!", "author_fullname": "t2_2oo6rj79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job transition - finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14arw5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686906594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, right now I am working in finance (credit risk, customer selection models etc), one of the top world banks. My job involves compilance, analyzing the models, whether the data is correct and so on. It involves also writing reports and conclusions about the models for upper managment. I do have some ML, statistics, risk, python knowledge but I thought I would move to more coding job so it would be more stimulating for me. Are this skills actually possible to leverege in data engineer/analytics engineer role (I would like to do something like this). I would not like to start completely at junior level because my background is kind of flexible and some parts of the job do have intersections with DE job. I am right now doing some courses on the GCP and will start building projects using docker etc for the future. Are there some roles that would have intersections involving my job and possible DE job? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14arw5e", "is_robot_indexable": true, "report_reasons": null, "author": "Omnetfh", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14arw5e/job_transition_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14arw5e/job_transition_finance/", "subreddit_subscribers": 110789, "created_utc": 1686906594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going to guess early to mid 20s.", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How old were you when you landed your first real data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b5t87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686944009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to guess early to mid 20s.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14b5t87", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b5t87/how_old_were_you_when_you_landed_your_first_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b5t87/how_old_were_you_when_you_landed_your_first_real/", "subreddit_subscribers": 110789, "created_utc": 1686944009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Redditors,\n\nI'm currently exploring the field of system design and looking to deepen my understanding of this fascinating subject. I've been studying on my own and have a decent grasp of the basics, but I'm now interested in finding more structured and comprehensive resources to further my knowledge.\n\nI was wondering if any of you have come across university courses or programs that specifically focus on system design. I believe that formal education could provide a solid foundation and a more in-depth exploration of the subject matter.\n\n&amp;#x200B;\n\nAdditionally, if you have any personal experiences, insights, or resources that have helped you in your system design journey, please feel free to share them as well. Any books, online tutorials, or other materials you found valuable would be highly appreciated.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_52qbnz6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are There Any University Courses on System Design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ajo25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686879485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring the field of system design and looking to deepen my understanding of this fascinating subject. I&amp;#39;ve been studying on my own and have a decent grasp of the basics, but I&amp;#39;m now interested in finding more structured and comprehensive resources to further my knowledge.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if any of you have come across university courses or programs that specifically focus on system design. I believe that formal education could provide a solid foundation and a more in-depth exploration of the subject matter.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additionally, if you have any personal experiences, insights, or resources that have helped you in your system design journey, please feel free to share them as well. Any books, online tutorials, or other materials you found valuable would be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "14ajo25", "is_robot_indexable": true, "report_reasons": null, "author": "ravicric", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ajo25/are_there_any_university_courses_on_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ajo25/are_there_any_university_courses_on_system_design/", "subreddit_subscribers": 110789, "created_utc": 1686879485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm building a pipeline to extract data from a number of tables in a mysql database, transform some of the data and run some logic before storing the result in another database for use by a Looker Studio dashboard. In theory all very simple stuff, so having created something similar at a previous job using Airflow, I thought i'd look around for the best practises for a modern data stack. \n\nThis brought me to dagster. Really cool software, similar to Airflow in many ways but feels more modern. I've paired it with Airbyte to extract data from the production database to a reporting database. The dagster assets then run their magic and I wrote a final asset to write the information to another database (using SQLAlchemy in the end because I can't for the life of me figure out how to upsert data into a database using dataframes.)\n\nSo this all mostly works, but my issue now is regarding partitioning of the data. In the source database, there's a table tracking number of sales by cashier. The assets are configured with the DailyPartitionsDefinition partitions definition to allow for backfilling. My assets work but my long winded question is: when backfilling multiple days of data, the sync request on my airbyte resources is triggered for each backfill, leading to a timeout by the airbyte server from the later backfill requests. How should I best structure my assets to prevent this?\n\nOptions:\n\n* Remove airbyte from dagsterand figure out a way to connect the assets without the integration\n* Do everything manually in Python and dagster. Read from the database taking into account partitioning, e.g. select \\* from sales where date = 2023-06-16\n* Rip it all out and go back to Airflow\n\nI really like dagster, I just can't get my head around this. Every example I see is either really simple or way too complicated.\n\nSorry for the rambling question, I hope it makes sense but any direction would be very much appreciated!", "author_fullname": "t2_3zctr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster/Airbyte ELT - Feeling like i'm losing my mind!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14au1rj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686913872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m building a pipeline to extract data from a number of tables in a mysql database, transform some of the data and run some logic before storing the result in another database for use by a Looker Studio dashboard. In theory all very simple stuff, so having created something similar at a previous job using Airflow, I thought i&amp;#39;d look around for the best practises for a modern data stack. &lt;/p&gt;\n\n&lt;p&gt;This brought me to dagster. Really cool software, similar to Airflow in many ways but feels more modern. I&amp;#39;ve paired it with Airbyte to extract data from the production database to a reporting database. The dagster assets then run their magic and I wrote a final asset to write the information to another database (using SQLAlchemy in the end because I can&amp;#39;t for the life of me figure out how to upsert data into a database using dataframes.)&lt;/p&gt;\n\n&lt;p&gt;So this all mostly works, but my issue now is regarding partitioning of the data. In the source database, there&amp;#39;s a table tracking number of sales by cashier. The assets are configured with the DailyPartitionsDefinition partitions definition to allow for backfilling. My assets work but my long winded question is: when backfilling multiple days of data, the sync request on my airbyte resources is triggered for each backfill, leading to a timeout by the airbyte server from the later backfill requests. How should I best structure my assets to prevent this?&lt;/p&gt;\n\n&lt;p&gt;Options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Remove airbyte from dagsterand figure out a way to connect the assets without the integration&lt;/li&gt;\n&lt;li&gt;Do everything manually in Python and dagster. Read from the database taking into account partitioning, e.g. select * from sales where date = 2023-06-16&lt;/li&gt;\n&lt;li&gt;Rip it all out and go back to Airflow&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I really like dagster, I just can&amp;#39;t get my head around this. Every example I see is either really simple or way too complicated.&lt;/p&gt;\n\n&lt;p&gt;Sorry for the rambling question, I hope it makes sense but any direction would be very much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14au1rj", "is_robot_indexable": true, "report_reasons": null, "author": "dixonl90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14au1rj/dagsterairbyte_elt_feeling_like_im_losing_my_mind/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14au1rj/dagsterairbyte_elt_feeling_like_im_losing_my_mind/", "subreddit_subscribers": 110789, "created_utc": 1686913872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work more in the Analytics Engineering space so my question might not make complete sense however I would appreciate any clarity than can be provided.\n\nMy understanding is a common way for data to flow is as follows:\n\nApplication database (MySQL) &gt;&gt; Datalake (S3) &gt;&gt; Data Warehouse (Snowflake).\n\nAs an Analytics Eng I do many transformations in the Data Warehouse. \n\nWhy does the data need to go into S3 first? \n\nAre additional transformations happening in there done by the Data Engineer? \n\nCould S3 be removed and the data can go directly from the application database to the data warehouse?\n\nThanks", "author_fullname": "t2_fwqwbjia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Flow Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14attqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686913208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work more in the Analytics Engineering space so my question might not make complete sense however I would appreciate any clarity than can be provided.&lt;/p&gt;\n\n&lt;p&gt;My understanding is a common way for data to flow is as follows:&lt;/p&gt;\n\n&lt;p&gt;Application database (MySQL) &amp;gt;&amp;gt; Datalake (S3) &amp;gt;&amp;gt; Data Warehouse (Snowflake).&lt;/p&gt;\n\n&lt;p&gt;As an Analytics Eng I do many transformations in the Data Warehouse. &lt;/p&gt;\n\n&lt;p&gt;Why does the data need to go into S3 first? &lt;/p&gt;\n\n&lt;p&gt;Are additional transformations happening in there done by the Data Engineer? &lt;/p&gt;\n\n&lt;p&gt;Could S3 be removed and the data can go directly from the application database to the data warehouse?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14attqq", "is_robot_indexable": true, "report_reasons": null, "author": "space-trader-92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14attqq/data_flow_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14attqq/data_flow_question/", "subreddit_subscribers": 110789, "created_utc": 1686913208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey everyone,\n\nI've been exploring the world of big data and cloud computing lately, and I've come across two powerful tools: Databricks and AWS Glue. However, I'm still trying to understand how these two services work together.\n\nI know that Databricks is a unified analytics platform built on Apache Spark, which allows you to process big data and perform advanced analytics. On the other hand, AWS Glue is an ETL (Extract, Transform, Load) service provided by Amazon Web Services (AWS).\n\nWhat I'm particularly interested in is how Databricks utilizes AWS Glue. I've heard that Glue can help with data preparation and integration tasks, but I'm curious about the specific use cases and benefits of using Glue within the Databricks ecosystem.\n\nDoes anyone have experience or insights into how Databricks integrates with AWS Glue? How does Glue enhance the data processing capabilities of Databricks? Are there any specific features or functionalities that make this integration advantageous?\n\nI'm looking to understand the synergy between these two services and how they can work together to streamline big data workflows. Any real-world examples, tutorials, or recommended resources would be greatly appreciated.\n\nThanks in advance for your help!", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Databricks utilize AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aslc7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686909052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been exploring the world of big data and cloud computing lately, and I&amp;#39;ve come across two powerful tools: Databricks and AWS Glue. However, I&amp;#39;m still trying to understand how these two services work together.&lt;/p&gt;\n\n&lt;p&gt;I know that Databricks is a unified analytics platform built on Apache Spark, which allows you to process big data and perform advanced analytics. On the other hand, AWS Glue is an ETL (Extract, Transform, Load) service provided by Amazon Web Services (AWS).&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m particularly interested in is how Databricks utilizes AWS Glue. I&amp;#39;ve heard that Glue can help with data preparation and integration tasks, but I&amp;#39;m curious about the specific use cases and benefits of using Glue within the Databricks ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience or insights into how Databricks integrates with AWS Glue? How does Glue enhance the data processing capabilities of Databricks? Are there any specific features or functionalities that make this integration advantageous?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to understand the synergy between these two services and how they can work together to streamline big data workflows. Any real-world examples, tutorials, or recommended resources would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14aslc7", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aslc7/how_does_databricks_utilize_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aslc7/how_does_databricks_utilize_aws_glue/", "subreddit_subscribers": 110789, "created_utc": 1686909052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to implement data sanity check for two databases, also return the inconsistent results(most prob extact rows) and since I have to implement this for a very huge database(let\u2019s say each database have min. 20 tables each with 2.5M+ data) so what techniques would you suggest? Or do you use in your company?", "author_fullname": "t2_aahomxjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you perform data sanity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ay92f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686925544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to implement data sanity check for two databases, also return the inconsistent results(most prob extact rows) and since I have to implement this for a very huge database(let\u2019s say each database have min. 20 tables each with 2.5M+ data) so what techniques would you suggest? Or do you use in your company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14ay92f", "is_robot_indexable": true, "report_reasons": null, "author": "Icraveviolencemother", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ay92f/how_do_you_perform_data_sanity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ay92f/how_do_you_perform_data_sanity/", "subreddit_subscribers": 110789, "created_utc": 1686925544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Concepts #1 \u2014 Slowly Changing Dimensions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "name": "t3_14aptlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/j33fu5QP0HvPZZMWG2BYVM1eRcbeejhl-7jE8f5YNkc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686899178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdev.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdev.com/data-engineering-concepts-1-slowly-changing-dimensions-851d52446ccd", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?auto=webp&amp;v=enabled&amp;s=ff330e6e2e5785bb8424797f7c39d4b74c190af8", "width": 1042, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de25db31e40a22646c5c596b81063b75c3023763", "width": 108, "height": 79}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc4bb5daa5da77bc5cb6835c507556dcf88406cb", "width": 216, "height": 159}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=262252caf96f6c965bdebbacfe2b0aab892bb2e2", "width": 320, "height": 235}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=460c0fd68ca540a96b5ba363148877845d82447a", "width": 640, "height": 471}, {"url": "https://external-preview.redd.it/lRA2iUt5uW51DNS4l3EsJufC2u06h7hOPG20t4fljNk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65d1b0eb76070d9857982a27cb530dc1902310e6", "width": 960, "height": 707}], "variants": {}, "id": "5kaNvsWQE49zdI4YIIyHTEvB1Quj-zmYZ9zpTSBU7Og"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14aptlk", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aptlk/data_engineering_concepts_1_slowly_changing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdev.com/data-engineering-concepts-1-slowly-changing-dimensions-851d52446ccd", "subreddit_subscribers": 110789, "created_utc": 1686899178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy Father's Day, data engineers!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7yl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Sl5mzne5DYIbwhxTi2qEII3ZkEaQz1Ou2HXwJC7WSI0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686949266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gv8fyeo72g6b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?auto=webp&amp;v=enabled&amp;s=a405764be344f4174597e60ae04e32667967016e", "width": 1200, "height": 1500}, "resolutions": [{"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0059acfcb203aa81fffbd0158ac07fea739a35d", "width": 108, "height": 135}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c28feaea9d5706438dc1fb501df46b59cd73a717", "width": 216, "height": 270}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2503bca3436d416646111d0f00ed51f7f2ad470d", "width": 320, "height": 400}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=941df641c128f37b6a37de589577db7a2f6c7e80", "width": 640, "height": 800}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=328b95e457ff6dbfdb6da2f9629d9dae69e7cf89", "width": 960, "height": 1200}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13151f090b4e7af9a6d05bf59e22293f1d2e617a", "width": 1080, "height": 1350}], "variants": {}, "id": "HPCRKmZuUHk-w5Gl_juNUl5814xnwImdyOk_Cp85yOI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14b7yl2", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7yl2/happy_fathers_day_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gv8fyeo72g6b1.png", "subreddit_subscribers": 110789, "created_utc": 1686949266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand the appeal of airbyte and have successfully deployed it on my laptop for testing, but now I wanted to move what I have deployed into AWS and possibly the cloud offering. Anyone knows if that is possible (e.g. to have a config file with what we develop locally, send to github to be reviewed/versioned and then apply that same config for testing/production) or would I need to test the extraction locally and then need to do the same process all over again (manually) to deploy it in a different environment ?", "author_fullname": "t2_hz0e0qby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b31sc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686937279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand the appeal of airbyte and have successfully deployed it on my laptop for testing, but now I wanted to move what I have deployed into AWS and possibly the cloud offering. Anyone knows if that is possible (e.g. to have a config file with what we develop locally, send to github to be reviewed/versioned and then apply that same config for testing/production) or would I need to test the extraction locally and then need to do the same process all over again (manually) to deploy it in a different environment ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14b31sc", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Ratio1642", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b31sc/airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b31sc/airbyte/", "subreddit_subscribers": 110789, "created_utc": 1686937279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I'm not sure if this is the right sub, but what I'm working on is somewhere between backend and data eng'g. Anyw, I\u2019m currently setting up a log-based cdc with debezium that feeds a message broker for streams. The thing is, I want to only capture the record if the command is an update. However, I can't find any good resource that tackles the configuration for debezium to function like that. If \"directly altering debezium behavior\" is not an option, then I can only think of one solution - create an outbox table to store updated records, that of which can be implemented w either of the ff:\n\n(a) Let some middleman (stored procedures) trigger the insertion of record to the outbox table and it gets deleted as soon as the connector publishes it to the broker to keep the db clean. This is a process that happens at the db level; I am abstracting the work away from the application layer. The drawbacks now would be: trouble with keeping this procedure as part of the entire update transaction since the update is handled by an ORM tool from the app layer. This can be solved by (b) though.\n\n(b) To keep the entire update + insertion to outbox table an entire transaction, I perform the write on the service that deals with update operation and wrap these into one transactional method. Now the drawbacks would be, it adds unnecessary configs and load to the app layer. \n\nAre there better workarounds for this? If there are configurable alternatives to debezium, please let me know. Thank you very much.", "author_fullname": "t2_t73a89x8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debezium for Postgres CDC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14azwp3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686929551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m not sure if this is the right sub, but what I&amp;#39;m working on is somewhere between backend and data eng&amp;#39;g. Anyw, I\u2019m currently setting up a log-based cdc with debezium that feeds a message broker for streams. The thing is, I want to only capture the record if the command is an update. However, I can&amp;#39;t find any good resource that tackles the configuration for debezium to function like that. If &amp;quot;directly altering debezium behavior&amp;quot; is not an option, then I can only think of one solution - create an outbox table to store updated records, that of which can be implemented w either of the ff:&lt;/p&gt;\n\n&lt;p&gt;(a) Let some middleman (stored procedures) trigger the insertion of record to the outbox table and it gets deleted as soon as the connector publishes it to the broker to keep the db clean. This is a process that happens at the db level; I am abstracting the work away from the application layer. The drawbacks now would be: trouble with keeping this procedure as part of the entire update transaction since the update is handled by an ORM tool from the app layer. This can be solved by (b) though.&lt;/p&gt;\n\n&lt;p&gt;(b) To keep the entire update + insertion to outbox table an entire transaction, I perform the write on the service that deals with update operation and wrap these into one transactional method. Now the drawbacks would be, it adds unnecessary configs and load to the app layer. &lt;/p&gt;\n\n&lt;p&gt;Are there better workarounds for this? If there are configurable alternatives to debezium, please let me know. Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14azwp3", "is_robot_indexable": true, "report_reasons": null, "author": "midnight_babyyy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14azwp3/debezium_for_postgres_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14azwp3/debezium_for_postgres_cdc/", "subreddit_subscribers": 110789, "created_utc": 1686929551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I haven't found much on this topic. To me this seems an oversight/developer marketing opportunity, as I can see a lot of companies/projects wanting to do this in the near future.\n\nAnyway, do you have any good resources you can point me to?  \n\nHow would you approach it?  \n\nHave a CDC pipeline with Debezium/Kafka to consume the Postgres events and then build a custom connector to Qdrant (in my case)?  \n\nDo you have any learning materials that would make it easier for me to get going?", "author_fullname": "t2_c056b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep a vector database in sync with a source-of-truth SQL database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14asu6u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686909874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t found much on this topic. To me this seems an oversight/developer marketing opportunity, as I can see a lot of companies/projects wanting to do this in the near future.&lt;/p&gt;\n\n&lt;p&gt;Anyway, do you have any good resources you can point me to?  &lt;/p&gt;\n\n&lt;p&gt;How would you approach it?  &lt;/p&gt;\n\n&lt;p&gt;Have a CDC pipeline with Debezium/Kafka to consume the Postgres events and then build a custom connector to Qdrant (in my case)?  &lt;/p&gt;\n\n&lt;p&gt;Do you have any learning materials that would make it easier for me to get going?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14asu6u", "is_robot_indexable": true, "report_reasons": null, "author": "retendo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14asu6u/how_to_keep_a_vector_database_in_sync_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14asu6u/how_to_keep_a_vector_database_in_sync_with_a/", "subreddit_subscribers": 110789, "created_utc": 1686909874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to use the limit offset feature of HiveQL to paginate a table. My question is that if I use this feature without using ORDER BY to order the table will the order of rows returned by the query be determinate or will it be random, in which case is there a chance that I could get duplicate rows in subsequent pages. \n\nIf the order of the rows is determinate will this query be faster than the query using ORDER BY or does limit offset also somehow use ordering inside of it resulting no performance gain?", "author_fullname": "t2_5jmtd87l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does HiveQL guarantee determinate order of rows returned in case of limit offset queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14aoihp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686894776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to use the limit offset feature of HiveQL to paginate a table. My question is that if I use this feature without using ORDER BY to order the table will the order of rows returned by the query be determinate or will it be random, in which case is there a chance that I could get duplicate rows in subsequent pages. &lt;/p&gt;\n\n&lt;p&gt;If the order of the rows is determinate will this query be faster than the query using ORDER BY or does limit offset also somehow use ordering inside of it resulting no performance gain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14aoihp", "is_robot_indexable": true, "report_reasons": null, "author": "Pantheramaximus", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14aoihp/does_hiveql_guarantee_determinate_order_of_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14aoihp/does_hiveql_guarantee_determinate_order_of_rows/", "subreddit_subscribers": 110789, "created_utc": 1686894776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I overheard a conversation that data-oriented programming is old school and Data oriented programming is the better way to programming. \n\nCan I use DOP outside of game development? I really want to understand more", "author_fullname": "t2_8skbp1qj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "?? Server efficiency through Data Oriented Design??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7nu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686948543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I overheard a conversation that data-oriented programming is old school and Data oriented programming is the better way to programming. &lt;/p&gt;\n\n&lt;p&gt;Can I use DOP outside of game development? I really want to understand more&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b7nu4", "is_robot_indexable": true, "report_reasons": null, "author": "Positive-Fly4773", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7nu4/server_efficiency_through_data_oriented_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b7nu4/server_efficiency_through_data_oriented_design/", "subreddit_subscribers": 110789, "created_utc": 1686948543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the fastest way to run a small etl pipeline on a single node databricks cluster. \n\nUsing sqlalchemy and polars to read and wrangle is quite a bit faster than using the overhead of pyspark. The bottleneck is writing if data is smallish yet not tiny (e.g. 5 to 10 million rows).\n\nWhat is the best approach here? Pandas to_sql with sqlalchemy engine set to fast_executemany=True works okayish. Is molding the pandas df into a spark df and then using pyspark to export faster? Are there other faster options?", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing to Azure SQL server from single node DBX cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7475", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686947215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the fastest way to run a small etl pipeline on a single node databricks cluster. &lt;/p&gt;\n\n&lt;p&gt;Using sqlalchemy and polars to read and wrangle is quite a bit faster than using the overhead of pyspark. The bottleneck is writing if data is smallish yet not tiny (e.g. 5 to 10 million rows).&lt;/p&gt;\n\n&lt;p&gt;What is the best approach here? Pandas to_sql with sqlalchemy engine set to fast_executemany=True works okayish. Is molding the pandas df into a spark df and then using pyspark to export faster? Are there other faster options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b7475", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7475/writing_to_azure_sql_server_from_single_node_dbx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b7475/writing_to_azure_sql_server_from_single_node_dbx/", "subreddit_subscribers": 110789, "created_utc": 1686947215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_54sig", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping dynamic websites using cloud based Scraper API and Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14b3yer", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jm-7mvf5ZyeJb0WsiK_5XC4MMsa3FlzqfTIDEmG5cXA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686939474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.adnansiddiqi.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.adnansiddiqi.me/scraping-dynamic-websites-using-scraper-api-and-python/?utm_source=reddit_de&amp;utm_medium=reddit&amp;utm_campaign=c_reddit_de_scraperapi_1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?auto=webp&amp;v=enabled&amp;s=0be9678b4647c2d6408183cce9b9aa0529608b7a", "width": 2240, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5f86e79c73632718a0192d0770cef735ef71afe", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6036e446628cf00e86d298ac6686dc79c73c1300", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70b62381374986e58ee72a922723f53997296918", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d178dd6248e816a1a25776439716e1b990c0508", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90afa6ec317edb114bad30f7f0f876ebf1e9ba29", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/yQgcQcuDQDOMy--Ho_nWMPEBbfkEZoy4IZMsfxOYB8U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9817f3cab85ca2f9aa6f96bba6673b4654369567", "width": 1080, "height": 607}], "variants": {}, "id": "0ZTLqnRC7I-OtWL4YPQWymXBI_n4kH4DoAVlbgZ_Wrw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14b3yer", "is_robot_indexable": true, "report_reasons": null, "author": "pknerd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14b3yer/scraping_dynamic_websites_using_cloud_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.adnansiddiqi.me/scraping-dynamic-websites-using-scraper-api-and-python/?utm_source=reddit_de&amp;utm_medium=reddit&amp;utm_campaign=c_reddit_de_scraperapi_1", "subreddit_subscribers": 110789, "created_utc": 1686939474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow Data Engineers,\n\nI'm currently working at a tech company as a Senior Data Engineer; I was laid off last year by another company, and while looking for my current job, I noticed many hiring managers like more to have a Software Engineer title in the resume.\n\nMy current job has lots of Software Engineering work (e.g., developing AWS lambdas in TypeScript), so I don't feel too distant from an SWE. I also want to always target more technical DE roles instead of analytical ones (like my previous role at FAANG).\n\nSo I was wondering if it's okay changing the title in my resume (for future jobs), from Senior Data Engineer to Senior Software Engineer (Data).\n\nIs there any potential downside when doing a background check?\n\n[View Poll](https://www.reddit.com/poll/14b12o5)", "author_fullname": "t2_5dn8ds4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it ok to change the title in my resume from Data Engineer to Software Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b12o5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686932387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working at a tech company as a Senior Data Engineer; I was laid off last year by another company, and while looking for my current job, I noticed many hiring managers like more to have a Software Engineer title in the resume.&lt;/p&gt;\n\n&lt;p&gt;My current job has lots of Software Engineering work (e.g., developing AWS lambdas in TypeScript), so I don&amp;#39;t feel too distant from an SWE. I also want to always target more technical DE roles instead of analytical ones (like my previous role at FAANG).&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if it&amp;#39;s okay changing the title in my resume (for future jobs), from Senior Data Engineer to Senior Software Engineer (Data).&lt;/p&gt;\n\n&lt;p&gt;Is there any potential downside when doing a background check?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/14b12o5\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b12o5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Muffin-8079", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1687364387266, "options": [{"text": "Changing title to Software Engineer, Data", "id": "23495915"}, {"text": "Changing title to Software Engineer", "id": "23495916"}, {"text": "Leaving title as Data Engineer", "id": "23495917"}, {"text": "View results", "id": "23495918"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 215, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b12o5/is_it_ok_to_change_the_title_in_my_resume_from/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/14b12o5/is_it_ok_to_change_the_title_in_my_resume_from/", "subreddit_subscribers": 110789, "created_utc": 1686932387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_75heuca3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model and Data Versioning: An Introduction to mlflow and DVC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14avpao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/18UUk4H6u7huOYzLrAp0EU-9F4fNSuZX-CRR_ny0mHQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686918876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/walmartglobaltech/model-and-data-versioning-an-introduction-to-mlflow-and-dvc-260347cd0f6e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?auto=webp&amp;v=enabled&amp;s=c6f576dea82fe4d4c467239ef411c86b8f85de28", "width": 934, "height": 524}, "resolutions": [{"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=022ff67292ee0d96700d98e250dfdb2490907eb9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d50e59cb44b20a9630c6fd1add53bc436244d51", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5615b277d788185f428fee0b1a0dab672078241d", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/SmP166aNO4sLv1hicYp9gtTRxiQjbyfz4zUCI6ja9Ks.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8465c379f3313251030dc1c2cc78ba050aa56e76", "width": 640, "height": 359}], "variants": {}, "id": "3VBNHf_29E4hJ2ZK7F-hdoRprCfV28NKadAC3E-K_Cg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14avpao", "is_robot_indexable": true, "report_reasons": null, "author": "Junior-Salary-6859", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14avpao/model_and_data_versioning_an_introduction_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/walmartglobaltech/model-and-data-versioning-an-introduction-to-mlflow-and-dvc-260347cd0f6e", "subreddit_subscribers": 110789, "created_utc": 1686918876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI've recently started to study some of the tools necessary to become a data engineer: airflow, spark, etc. However, while some things are starting to make sense, I'm still trying to figure out the beggining of it all: how do you even start to incorporate this tools in a company that does not use them at all?\n\nWhat I'm trying to understand, and I am failing to do, is what should be the first steps of implementation. For instance, my company has a lot of IoT data that they don't use - but want to start doing so, and I would love to be part of it and learn how to build pipelines, understand more about how we should storage the data, etc. \n\nDoes anyone here have this initial implementation experience and would like to share? Books, articles, anything is valid.\n\n&amp;#x200B;\n\nThank you for your time.", "author_fullname": "t2_2117hvx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does one starts applying data engineering in a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14at7ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686911097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently started to study some of the tools necessary to become a data engineer: airflow, spark, etc. However, while some things are starting to make sense, I&amp;#39;m still trying to figure out the beggining of it all: how do you even start to incorporate this tools in a company that does not use them at all?&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m trying to understand, and I am failing to do, is what should be the first steps of implementation. For instance, my company has a lot of IoT data that they don&amp;#39;t use - but want to start doing so, and I would love to be part of it and learn how to build pipelines, understand more about how we should storage the data, etc. &lt;/p&gt;\n\n&lt;p&gt;Does anyone here have this initial implementation experience and would like to share? Books, articles, anything is valid.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14at7ca", "is_robot_indexable": true, "report_reasons": null, "author": "tryingnewhabits", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14at7ca/how_does_one_starts_applying_data_engineering_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14at7ca/how_does_one_starts_applying_data_engineering_in/", "subreddit_subscribers": 110789, "created_utc": 1686911097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Don't have to read any of the below, just my random thinking: \n-----\nWe're talking about creating a Data Dictionary.  What will be stored in it? Undefined.  \n\nI've been asked where to store it.  Which isn't really the big issue in my mind (more, that these things tend to fail; how can this one not fail), but it's the immediate ask. \n\nWe currently store various documentation in 8 different systems (too many)\n\n  * Yammer\n  * Teams/Sharepoint\n  * A homegrown intranet page\n  * Learning Mgmt System\n  * ServiceNow\n  * A new document mgmt system that's upcoming\n  * Onenote\n  * Dataverse tables fed via power apps\n\nThere are also 3rd party products that are expensive and I assume have weird caveats. My initial reaction is we don't need an 9th system with a subscription. Then again, I don't know what these do. I assume some cool things along with bizarre limitations. \n\nI lean toward keep it simple, either:\n  * Excel file in Sharepoint with (mostly) read-only access, or\n  * A series of database tables.  \n   * This appeals to me for the queries that could be done...but to do that, also means a more to maintain. And these things tend to fail due to lack of updates, so maybe that's not a good idea. \n  * Power app feeding a dataverse table.  Then users could enter...but would they 1 year later? \n\nSo then I'm down to an Excel file stored somewhere, starting with the bare minimum, and *if* that's kept up, expand it. \n\nYour thoughts though?", "author_fullname": "t2_3bc49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where have your companies stored their Data Dictionary? How have you set them up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ahntm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686873694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Title. Don&amp;#39;t have to read any of the below, just my random thinking: &lt;/h2&gt;\n\n&lt;p&gt;We&amp;#39;re talking about creating a Data Dictionary.  What will be stored in it? Undefined.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked where to store it.  Which isn&amp;#39;t really the big issue in my mind (more, that these things tend to fail; how can this one not fail), but it&amp;#39;s the immediate ask. &lt;/p&gt;\n\n&lt;p&gt;We currently store various documentation in 8 different systems (too many)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Yammer&lt;/li&gt;\n&lt;li&gt;Teams/Sharepoint&lt;/li&gt;\n&lt;li&gt;A homegrown intranet page&lt;/li&gt;\n&lt;li&gt;Learning Mgmt System&lt;/li&gt;\n&lt;li&gt;ServiceNow&lt;/li&gt;\n&lt;li&gt;A new document mgmt system that&amp;#39;s upcoming&lt;/li&gt;\n&lt;li&gt;Onenote&lt;/li&gt;\n&lt;li&gt;Dataverse tables fed via power apps&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;There are also 3rd party products that are expensive and I assume have weird caveats. My initial reaction is we don&amp;#39;t need an 9th system with a subscription. Then again, I don&amp;#39;t know what these do. I assume some cool things along with bizarre limitations. &lt;/p&gt;\n\n&lt;p&gt;I lean toward keep it simple, either:\n  * Excel file in Sharepoint with (mostly) read-only access, or\n  * A series of database tables.&lt;br/&gt;\n   * This appeals to me for the queries that could be done...but to do that, also means a more to maintain. And these things tend to fail due to lack of updates, so maybe that&amp;#39;s not a good idea. \n  * Power app feeding a dataverse table.  Then users could enter...but would they 1 year later? &lt;/p&gt;\n\n&lt;p&gt;So then I&amp;#39;m down to an Excel file stored somewhere, starting with the bare minimum, and &lt;em&gt;if&lt;/em&gt; that&amp;#39;s kept up, expand it. &lt;/p&gt;\n\n&lt;p&gt;Your thoughts though?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ahntm", "is_robot_indexable": true, "report_reasons": null, "author": "cdigioia", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ahntm/where_have_your_companies_stored_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ahntm/where_have_your_companies_stored_their_data/", "subreddit_subscribers": 110789, "created_utc": 1686873694.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I am a data engineer myself and after 10y in the profession I built a library to automate schema inference, typing,evolution - the most tedious part of the work.\n\nI did this because i think it adds so much value to the loading stack, that you will never want to build any custom loading again.It's basically an approach to just throw your json to a loader, and let the loader handle normalisation, loading, and schema evolution and change alerts.\n\nI try to explain the why here. Recipe included. Feedback very welcome[https://dlthub.com/docs/blog/automating-data-engineers](https://dlthub.com/docs/blog/automating-data-engineers)", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer talent shortage: I offer a tech open source solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ar69y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.48, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686904024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I am a data engineer myself and after 10y in the profession I built a library to automate schema inference, typing,evolution - the most tedious part of the work.&lt;/p&gt;\n\n&lt;p&gt;I did this because i think it adds so much value to the loading stack, that you will never want to build any custom loading again.It&amp;#39;s basically an approach to just throw your json to a loader, and let the loader handle normalisation, loading, and schema evolution and change alerts.&lt;/p&gt;\n\n&lt;p&gt;I try to explain the why here. Recipe included. Feedback very welcome&lt;a href=\"https://dlthub.com/docs/blog/automating-data-engineers\"&gt;https://dlthub.com/docs/blog/automating-data-engineers&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14ar69y", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ar69y/data_engineer_talent_shortage_i_offer_a_tech_open/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ar69y/data_engineer_talent_shortage_i_offer_a_tech_open/", "subreddit_subscribers": 110789, "created_utc": 1686904024.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}