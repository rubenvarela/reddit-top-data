{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ap0s21sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Yes, it is reposted and remote opportunity. But 2690 applicants or views or clicks? That\u2019s astounding.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14do4jm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 174, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 174, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RrBGfjNg8LMPUIL_Zz8d0GW-LvqKLiWywE_lxcvSFqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687202959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ujqnjrqm017b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?auto=webp&amp;v=enabled&amp;s=ee9fe37933784d8ca4989f5b7a5dde682327fce4", "width": 1125, "height": 2436}, "resolutions": [{"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=543de30c34890274d832c1d23791be9286378c36", "width": 108, "height": 216}, {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f9b5e31cfb158dff85ac7954c417557415933c", "width": 216, "height": 432}, {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac0f6765ba1b1d9bdf64b7f683268c3ec654e6eb", "width": 320, "height": 640}, {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7c937ee89032cf778cf81d6c07b3486c4a77b8f", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2aea2dd5f03e2e1124cbe6125de420d390c89cd9", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/ujqnjrqm017b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e12733c1526efca3c08711302c604e99db295ab9", "width": 1080, "height": 2160}], "variants": {}, "id": "n3bjvifSr41nZ1tUH15kHrIrpmAIBWFf-53t4Rdd8e4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14do4jm", "is_robot_indexable": true, "report_reasons": null, "author": "hootandahalf_", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14do4jm/yes_it_is_reposted_and_remote_opportunity_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ujqnjrqm017b1.jpg", "subreddit_subscribers": 927654, "created_utc": 1687202959.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious if anyone knows of an orchestra that has a data scientist on staff? I've always thought it would be an interesting combination to help optimize business operations.", "author_fullname": "t2_4yu5zg3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Know any orchestras that use data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14di6w4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687189623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious if anyone knows of an orchestra that has a data scientist on staff? I&amp;#39;ve always thought it would be an interesting combination to help optimize business operations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14di6w4", "is_robot_indexable": true, "report_reasons": null, "author": "CommercialScholar7", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14di6w4/know_any_orchestras_that_use_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14di6w4/know_any_orchestras_that_use_data_science/", "subreddit_subscribers": 927654, "created_utc": 1687189623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there!\n\nI\u2019m an experienced Data Scientist with 3 years of industry experience, including 1.5 years of full-time work and a year-long internship. Currently, I\u2019m putting my skills to work at a bootstrapped startup. My expertise lies in the exciting realm of US Healthcare, where I\u2019ve had the opportunity to develop Analytics solutions and build decision support systems using the power of Machine Learning.\n\nWhen it comes to technical tools, I\u2019m well-versed in SQL, Python, R, Power BI, and Tableau. On top of that, I have a solid grasp of Statistics, enabling me to extract valuable insights from data. I take pride in tailoring my resume to match the job descriptions, ensuring it\u2019s well-formatted and polished.\n\nNow, here\u2019s the challenge I\u2019m facing: I\u2019ve been encountering difficulties in transitioning to a new job. I believe the hurdle might be my college background from a Tier 3 institution. Despite actively applying through platforms like LinkedIn, Wellfound, and Startup Jobs since January, I\u2019ve only received responses from two companies so far.\n\nMy ultimate goal is to secure a high-paying position at a growing startup, and that\u2019s why I\u2019m turning to the Reddit community for guidance. I would greatly appreciate any advice or insights on how I can overcome potential biases related to college rankings. How can I stand out among other candidates and increase my chances of landing a desirable job?\n\nJust to give you a little context, I\u2019m currently based in India and working the typical 10 am to 7 pm shift in an office setup.\n\nThank you all in advance for your valuable support and recommendations. Your input means a lot to me!\n\nEdit: I am looking for jobs in India. I work in Healthcare catering to US Hospitals.", "author_fullname": "t2_4lsdulflt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experienced Data Scientist Looking for Job Transition Advice - Seeking Insights on Improving Application Success", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dazsm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687186295.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687171042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an experienced Data Scientist with 3 years of industry experience, including 1.5 years of full-time work and a year-long internship. Currently, I\u2019m putting my skills to work at a bootstrapped startup. My expertise lies in the exciting realm of US Healthcare, where I\u2019ve had the opportunity to develop Analytics solutions and build decision support systems using the power of Machine Learning.&lt;/p&gt;\n\n&lt;p&gt;When it comes to technical tools, I\u2019m well-versed in SQL, Python, R, Power BI, and Tableau. On top of that, I have a solid grasp of Statistics, enabling me to extract valuable insights from data. I take pride in tailoring my resume to match the job descriptions, ensuring it\u2019s well-formatted and polished.&lt;/p&gt;\n\n&lt;p&gt;Now, here\u2019s the challenge I\u2019m facing: I\u2019ve been encountering difficulties in transitioning to a new job. I believe the hurdle might be my college background from a Tier 3 institution. Despite actively applying through platforms like LinkedIn, Wellfound, and Startup Jobs since January, I\u2019ve only received responses from two companies so far.&lt;/p&gt;\n\n&lt;p&gt;My ultimate goal is to secure a high-paying position at a growing startup, and that\u2019s why I\u2019m turning to the Reddit community for guidance. I would greatly appreciate any advice or insights on how I can overcome potential biases related to college rankings. How can I stand out among other candidates and increase my chances of landing a desirable job?&lt;/p&gt;\n\n&lt;p&gt;Just to give you a little context, I\u2019m currently based in India and working the typical 10 am to 7 pm shift in an office setup.&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance for your valuable support and recommendations. Your input means a lot to me!&lt;/p&gt;\n\n&lt;p&gt;Edit: I am looking for jobs in India. I work in Healthcare catering to US Hospitals.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dazsm", "is_robot_indexable": true, "report_reasons": null, "author": "stickyzbae", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dazsm/experienced_data_scientist_looking_for_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dazsm/experienced_data_scientist_looking_for_job/", "subreddit_subscribers": 927654, "created_utc": 1687171042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 19 Jun, 2023 - 26 Jun, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14d3wmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687147290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14d3wmn", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 22, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14d3wmn/weekly_entering_transitioning_thread_19_jun_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/14d3wmn/weekly_entering_transitioning_thread_19_jun_2023/", "subreddit_subscribers": 927654, "created_utc": 1687147290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not a data scientist, I'm totally willing to hire somebody for this project if necessary because I'm way out of my depth here.  \n\n\nHere is the problem, we have multiple clients, and sizing the market is complicated and is taking us 3 to 4 weeks, the info we get most of the time is how many sales the client and X amount of competitors have over time, how many sales per month, sales speed, pricing variance,  etc. basically we have a lot of good data on pricing, sales volume, marketing spend and all of that for customers and competitors, we have also noticed that CCI plays an important role in B2B SaaS so we use that too.  \n\n\nNow I stumbled upon an article explaining that Market size can be calculated with a Montecarlo simulation but it seems broken? I tried following the example in jupyter and it is broken even in the article itself.  \n\n\nSo I come here for enlightenment, would Montecarlo be an appropriate solution and if so, is there a way a noob like me can do it or should I find a data scientist in Upwork maybe?", "author_fullname": "t2_o3hg65o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market size calculation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14du7nk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687217013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not a data scientist, I&amp;#39;m totally willing to hire somebody for this project if necessary because I&amp;#39;m way out of my depth here.  &lt;/p&gt;\n\n&lt;p&gt;Here is the problem, we have multiple clients, and sizing the market is complicated and is taking us 3 to 4 weeks, the info we get most of the time is how many sales the client and X amount of competitors have over time, how many sales per month, sales speed, pricing variance,  etc. basically we have a lot of good data on pricing, sales volume, marketing spend and all of that for customers and competitors, we have also noticed that CCI plays an important role in B2B SaaS so we use that too.  &lt;/p&gt;\n\n&lt;p&gt;Now I stumbled upon an article explaining that Market size can be calculated with a Montecarlo simulation but it seems broken? I tried following the example in jupyter and it is broken even in the article itself.  &lt;/p&gt;\n\n&lt;p&gt;So I come here for enlightenment, would Montecarlo be an appropriate solution and if so, is there a way a noob like me can do it or should I find a data scientist in Upwork maybe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14du7nk", "is_robot_indexable": true, "report_reasons": null, "author": "Pristine_Swimming_16", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14du7nk/market_size_calculation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14du7nk/market_size_calculation/", "subreddit_subscribers": 927654, "created_utc": 1687217013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got laid off 3 months ago and have been struggling to find a new job since. I have plenty of experience doing the typical kaggle competition ML pipeline and I'm wanting to do a project that will develop new skills.\n\n At my previous job I worked a lot with computer vision in the realm of synthetic apature radar and I'm wanting to pivot into a role that uses computer vision (seems like the only in my prior field seem to be for 25y experience PhDs). I find that for a lot of the \"computer vision engineer\" jobs that I'm applying for, I lack experience using big data tools like pyspark, cuda, advanced sql and c++. Are there any good kaggle (or other) projects that utilize a lot of these tools?", "author_fullname": "t2_d0rzkd4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any suggestions for personal projects to improve my marketability?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dss15", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687213498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got laid off 3 months ago and have been struggling to find a new job since. I have plenty of experience doing the typical kaggle competition ML pipeline and I&amp;#39;m wanting to do a project that will develop new skills.&lt;/p&gt;\n\n&lt;p&gt;At my previous job I worked a lot with computer vision in the realm of synthetic apature radar and I&amp;#39;m wanting to pivot into a role that uses computer vision (seems like the only in my prior field seem to be for 25y experience PhDs). I find that for a lot of the &amp;quot;computer vision engineer&amp;quot; jobs that I&amp;#39;m applying for, I lack experience using big data tools like pyspark, cuda, advanced sql and c++. Are there any good kaggle (or other) projects that utilize a lot of these tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dss15", "is_robot_indexable": true, "report_reasons": null, "author": "Supremus_memeus", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dss15/any_suggestions_for_personal_projects_to_improve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dss15/any_suggestions_for_personal_projects_to_improve/", "subreddit_subscribers": 927654, "created_utc": 1687213498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am investigating building tools to help data engineers build data pipelines for machine learning.\n\nI was wondering what are the three biggest problems you encounter on a day-to-day basis.\n\nFor example, is it extracting unstructured data, merging data streams, meeting throughput or latency requirements, keeping upstream and downstream schemas in sync, managing a large number of components in the pipeline, etc. or something else that gives you headaches? Curious to hear!", "author_fullname": "t2_9grwmp0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: What gives you headaches when building / using data pipelines for ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dlz8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687198162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am investigating building tools to help data engineers build data pipelines for machine learning.&lt;/p&gt;\n\n&lt;p&gt;I was wondering what are the three biggest problems you encounter on a day-to-day basis.&lt;/p&gt;\n\n&lt;p&gt;For example, is it extracting unstructured data, merging data streams, meeting throughput or latency requirements, keeping upstream and downstream schemas in sync, managing a large number of components in the pipeline, etc. or something else that gives you headaches? Curious to hear!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dlz8h", "is_robot_indexable": true, "report_reasons": null, "author": "Tricky_Drawer_2917", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dlz8h/discussion_what_gives_you_headaches_when_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dlz8h/discussion_what_gives_you_headaches_when_building/", "subreddit_subscribers": 927654, "created_utc": 1687198162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I\u2019m interested in a few things, as my desktop has shit itself for the final time today, I\u2019m trying to decide which machine is better.\n\nMy interests in data science are volumetric face reconstruction and monocular depth extraction via Midas v3.1.\n\nMy issue comes from this, these are built on PyTorch.\nShould I run them on an M1 Mac or should I just rebuilt my desktop for Cuda.\nWhich is better and why?", "author_fullname": "t2_88kgq9g6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "M2 or Nvidia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dw0sw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687221662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m interested in a few things, as my desktop has shit itself for the final time today, I\u2019m trying to decide which machine is better.&lt;/p&gt;\n\n&lt;p&gt;My interests in data science are volumetric face reconstruction and monocular depth extraction via Midas v3.1.&lt;/p&gt;\n\n&lt;p&gt;My issue comes from this, these are built on PyTorch.\nShould I run them on an M1 Mac or should I just rebuilt my desktop for Cuda.\nWhich is better and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dw0sw", "is_robot_indexable": true, "report_reasons": null, "author": "ImSure92123", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dw0sw/m2_or_nvidia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dw0sw/m2_or_nvidia/", "subreddit_subscribers": 927654, "created_utc": 1687221662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wanted to use OpenAI API but it's a paid service. What are alternatives for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14djkzg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_clezfvye", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnmachinelearning", "selftext": "I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.", "author_fullname": "t2_clezfvye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wanted to use OpenAI API but it's a paid service. What are alternatives for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnmachinelearning", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14djjsj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687192717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3cqa1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14djjsj", "is_robot_indexable": true, "report_reasons": null, "author": "Beginning-Scholar105", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/", "subreddit_subscribers": 308333, "created_utc": 1687192717.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1687192794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnmachinelearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14djkzg", "is_robot_indexable": true, "report_reasons": null, "author": "Beginning-Scholar105", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14djjsj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14djkzg/i_wanted_to_use_openai_api_but_its_a_paid_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/", "subreddit_subscribers": 927654, "created_utc": 1687192794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I get some dataset from hugging face dataset but they all are in either jpg or png format and converting them in text format is very complecated.\n\nIf you know any such dataset in doc format then please share that.", "author_fullname": "t2_clezfvye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do I get get dataset for different types of invoices in doc format.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14dxm5w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687226002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get some dataset from hugging face dataset but they all are in either jpg or png format and converting them in text format is very complecated.&lt;/p&gt;\n\n&lt;p&gt;If you know any such dataset in doc format then please share that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dxm5w", "is_robot_indexable": true, "report_reasons": null, "author": "Beginning-Scholar105", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dxm5w/where_do_i_get_get_dataset_for_different_types_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dxm5w/where_do_i_get_get_dataset_for_different_types_of/", "subreddit_subscribers": 927654, "created_utc": 1687226002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone - \n\nI'm getting my computer setup to start practicing coding, specifically coding in Python so that I can follow along to the MIT intro to computational science and programming with Python. \n\nIt seems like Anaconda is the preferred platform to begin. \n\nFor the free version, are there any pros/cons to having installed locally versus using the cloud version?", "author_fullname": "t2_qr8yadbf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anaconda: Cloud or Installed Locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14dxer9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687225442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone - &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m getting my computer setup to start practicing coding, specifically coding in Python so that I can follow along to the MIT intro to computational science and programming with Python. &lt;/p&gt;\n\n&lt;p&gt;It seems like Anaconda is the preferred platform to begin. &lt;/p&gt;\n\n&lt;p&gt;For the free version, are there any pros/cons to having installed locally versus using the cloud version?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dxer9", "is_robot_indexable": true, "report_reasons": null, "author": "Ready-Toe-1135", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dxer9/anaconda_cloud_or_installed_locally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dxer9/anaconda_cloud_or_installed_locally/", "subreddit_subscribers": 927654, "created_utc": 1687225442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] How to check which variable has strongest correlation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14duu9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_5lqdweph", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "statistics", "selftext": "So I have some numerical data with various input variable and some output variables, and I was wondering what technique it would be to find out how much a given variable is correlated with an output, so like how much a % change in variable a causes a change in my output. \n\nPCA doesn't seem correct since I think you only do that to input data to see which variable causes the most variation in the data, but not to see how it correlated with the output.\n\nIt's also pretty nonlinear though taking the log does seem to help.", "author_fullname": "t2_5lqdweph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] How to check which variable has strongest correlation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/statistics", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14duthp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687218560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have some numerical data with various input variable and some output variables, and I was wondering what technique it would be to find out how much a given variable is correlated with an output, so like how much a % change in variable a causes a change in my output. &lt;/p&gt;\n\n&lt;p&gt;PCA doesn&amp;#39;t seem correct since I think you only do that to input data to see which variable causes the most variation in the data, but not to see how it correlated with the output.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s also pretty nonlinear though taking the log does seem to help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhfi", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14duthp", "is_robot_indexable": true, "report_reasons": null, "author": "Quantenine", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/statistics/comments/14duthp/question_how_to_check_which_variable_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/statistics/comments/14duthp/question_how_to_check_which_variable_has/", "subreddit_subscribers": 536445, "created_utc": 1687218560.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1687218617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.statistics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/statistics/comments/14duthp/question_how_to_check_which_variable_has/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14duu9m", "is_robot_indexable": true, "report_reasons": null, "author": "Quantenine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14duthp", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14duu9m/question_how_to_check_which_variable_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/statistics/comments/14duthp/question_how_to_check_which_variable_has/", "subreddit_subscribers": 927654, "created_utc": 1687218617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a discussion with my friend about his CV. He is doing PhD in data science but he wants to continue his carrier in industry. He has put PhD job in cv as research scientist, I'm suggesting headline data scientist (the title of the job) would be better since he is  applying for data science jobs in an industry and his research is about data science and it makes the experience more relevant and clear. \n\nWhat is your opinion?", "author_fullname": "t2_ux2z6uya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientist or research scientist ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14drjke", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687210704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a discussion with my friend about his CV. He is doing PhD in data science but he wants to continue his carrier in industry. He has put PhD job in cv as research scientist, I&amp;#39;m suggesting headline data scientist (the title of the job) would be better since he is  applying for data science jobs in an industry and his research is about data science and it makes the experience more relevant and clear. &lt;/p&gt;\n\n&lt;p&gt;What is your opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14drjke", "is_robot_indexable": true, "report_reasons": null, "author": "_Tuesday_1", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14drjke/data_scientist_or_research_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14drjke/data_scientist_or_research_scientist/", "subreddit_subscribers": 927654, "created_utc": 1687210704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn Data Science with a GPT-powered Tutor: ProTaska-GPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dbbaf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7ybeiihm", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnpython", "selftext": "[removed]", "author_fullname": "t2_7ybeiihm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn Data Science with a GPT-powered Tutor: ProTaska-GPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnpython", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14db957", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687171853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": "moderator", "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8ot", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14db957", "is_robot_indexable": false, "report_reasons": null, "author": "Ono_Sureiya", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnpython/comments/14db957/learn_data_science_with_a_gptpowered_tutor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnpython/comments/14db957/learn_data_science_with_a_gptpowered_tutor/", "subreddit_subscribers": 717456, "created_utc": 1687171853.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1687172037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnpython/comments/14db957/learn_data_science_with_a_gptpowered_tutor/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?auto=webp&amp;v=enabled&amp;s=1e2d6d68444e813d8d2aaf487ac1ce4fed1afa36", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=873aece0f3ad3b5ceb4fb42644fa5a5d12b80048", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b7cdde26112033733e22da19b6e7291b0f08512", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0dfd4e2b822d7b933b9d5424fa381a3dc29a3b7e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cfd85234ac158708421649949840907e849e1e9", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d84033994613924a828c94b5ad819e408c881a85", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XwFEaToa2Yp5MHnAlWOJOMZgSSwDymgS8JzRIqIVRhs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d65bb6bbf887e3e224e649c90578893bbd162ac", "width": 1080, "height": 540}], "variants": {}, "id": "b6x8D1Bl8B51xD0h0NRlG9p42Pwdn-RaYdjHIbmWcoQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dbbaf", "is_robot_indexable": true, "report_reasons": null, "author": "Ono_Sureiya", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14db957", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dbbaf/learn_data_science_with_a_gptpowered_tutor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnpython/comments/14db957/learn_data_science_with_a_gptpowered_tutor/", "subreddit_subscribers": 927654, "created_utc": 1687172037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow: Rolling forward with ZFS and `httm`", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dj0m5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_hokp5z5a", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "sysadmin", "selftext": "[httm](https://github.com/kimono-koans/httm) prints the size, date and corresponding locations of available unique versions (deduplicated by modify time and size) of files residing on snapshots, but can also be used interactively to select and restore files, even snapshot mounts by file! `httm` might change the way you use snapshots (because ZFS/BTRFS/NILFS2 aren't designed for finding for unique file versions) or the Time Machine concept (because httm is very fast!).\n\nBut httm, of course, does other odd and delightful things.  One of the latest is:\n\n    --roll-forward=&lt;ROLL_FORWARD&gt;\n    traditionally 'zfs rollback' is a destructive operation, whereas httm roll-forward is non-destructive.  httm will copy only files and their attributes that have changed since a specified snapshot, from that snapshot, to its live dataset.  httm will also take two precautionary snapshots, one before and one after the copy.  Should the roll forward fail for any reason, httm will roll back to the pre-execution state.  Caveats: This is a ZFS only option which requires super user privileges.\n\n***Why?***\n\nBecause `rsync` is either too slow (when run with checksums enabled) or inaccurate (when run without checksums enabled).\n\n* Sysadmins: Imagine you absolutely *need to rollback* to a previous filesystem state.  For instance, in the case of ransomware or malware.  But perhaps you also want to keep data regarding the attack for forensic purposes.  `zfs rollback` will destroy the interstitial snapshots between now and the prior version.  `httm --roll-forward` allows you to preserve those snapshots.\n* Data scientists: `httm` has proved popular with data scientists for one big reason: Transferring your big data around never made any sense.  Get access to your prior versions without going directory spelunking, to manually copying things around.  Do work on the data where it lives, and then roll forward to a clean dataset, while preserving your prior work.\n\n***How this works:***\n\n* `httm` uses `zfs diff` to find the local files to copy.\n* `httm` then generates new local paths, and copies the attributes and file data to the those paths.  Only the deltas between the source and destination files are sent, just like `rsync`.\n* `httm` then confirms the files match by comparing the source and destination metadata.\n* Because `zfs diff` is broken regarding hard links, `httm` also preserves hard links in a manner similar to `rsync` by building two hard link maps in the background\n* And, should the procedure for any reason fail, `httm` will automatically rollback to the pre-execution state before exiting.\n\nSee a video of roll forward in action: [asciicast](https://asciinema.org/a/572918)\n\nLatest version is [0.29.3](https://github.com/kimono-koans/httm#install-via-native-packages).", "author_fullname": "t2_hokp5z5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workflow: Rolling forward with ZFS and `httm`", "link_flair_richtext": [{"e": "text", "t": "General Discussion"}], "subreddit_name_prefixed": "r/sysadmin", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dj065", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "General Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687191451.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/kimono-koans/httm\"&gt;httm&lt;/a&gt; prints the size, date and corresponding locations of available unique versions (deduplicated by modify time and size) of files residing on snapshots, but can also be used interactively to select and restore files, even snapshot mounts by file! &lt;code&gt;httm&lt;/code&gt; might change the way you use snapshots (because ZFS/BTRFS/NILFS2 aren&amp;#39;t designed for finding for unique file versions) or the Time Machine concept (because httm is very fast!).&lt;/p&gt;\n\n&lt;p&gt;But httm, of course, does other odd and delightful things.  One of the latest is:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;--roll-forward=&amp;lt;ROLL_FORWARD&amp;gt;\ntraditionally &amp;#39;zfs rollback&amp;#39; is a destructive operation, whereas httm roll-forward is non-destructive.  httm will copy only files and their attributes that have changed since a specified snapshot, from that snapshot, to its live dataset.  httm will also take two precautionary snapshots, one before and one after the copy.  Should the roll forward fail for any reason, httm will roll back to the pre-execution state.  Caveats: This is a ZFS only option which requires super user privileges.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Why?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Because &lt;code&gt;rsync&lt;/code&gt; is either too slow (when run with checksums enabled) or inaccurate (when run without checksums enabled).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Sysadmins: Imagine you absolutely &lt;em&gt;need to rollback&lt;/em&gt; to a previous filesystem state.  For instance, in the case of ransomware or malware.  But perhaps you also want to keep data regarding the attack for forensic purposes.  &lt;code&gt;zfs rollback&lt;/code&gt; will destroy the interstitial snapshots between now and the prior version.  &lt;code&gt;httm --roll-forward&lt;/code&gt; allows you to preserve those snapshots.&lt;/li&gt;\n&lt;li&gt;Data scientists: &lt;code&gt;httm&lt;/code&gt; has proved popular with data scientists for one big reason: Transferring your big data around never made any sense.  Get access to your prior versions without going directory spelunking, to manually copying things around.  Do work on the data where it lives, and then roll forward to a clean dataset, while preserving your prior work.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;How this works:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;httm&lt;/code&gt; uses &lt;code&gt;zfs diff&lt;/code&gt; to find the local files to copy.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;httm&lt;/code&gt; then generates new local paths, and copies the attributes and file data to the those paths.  Only the deltas between the source and destination files are sent, just like &lt;code&gt;rsync&lt;/code&gt;.&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;httm&lt;/code&gt; then confirms the files match by comparing the source and destination metadata.&lt;/li&gt;\n&lt;li&gt;Because &lt;code&gt;zfs diff&lt;/code&gt; is broken regarding hard links, &lt;code&gt;httm&lt;/code&gt; also preserves hard links in a manner similar to &lt;code&gt;rsync&lt;/code&gt; by building two hard link maps in the background&lt;/li&gt;\n&lt;li&gt;And, should the procedure for any reason fail, &lt;code&gt;httm&lt;/code&gt; will automatically rollback to the pre-execution state before exiting.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;See a video of roll forward in action: &lt;a href=\"https://asciinema.org/a/572918\"&gt;asciicast&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Latest version is &lt;a href=\"https://github.com/kimono-koans/httm#install-via-native-packages\"&gt;0.29.3&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?auto=webp&amp;v=enabled&amp;s=7b515159b74925070a22fbc932d316c14fb0e899", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a16c7d76c6c4f5ca3845e88aae2f9a9c8aaa14dd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65333666b37ec358ed6181c64f322fcfe1d98536", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e746d6194313ecee4ec06505218fab55380d47d4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42a0aa1f7a5c15d912d63d05487e9fbf0bf018b6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f90f3973d6f8b501bd9de6df97031e7bb9986d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f07216f61e5a333ef17d3047e7ca0bf562b9ef", "width": 1080, "height": 540}], "variants": {}, "id": "wGDAH0vLbp_XphYTE0GmnI16WkQDoI0D1HxW4kVpGIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e1597ab8-8e34-11e1-95a6-12313d051e91", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qnp7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#6698ff", "id": "14dj065", "is_robot_indexable": true, "report_reasons": null, "author": "small_kimono", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/sysadmin/comments/14dj065/workflow_rolling_forward_with_zfs_and_httm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/sysadmin/comments/14dj065/workflow_rolling_forward_with_zfs_and_httm/", "subreddit_subscribers": 800219, "created_utc": 1687191451.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1687191482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.sysadmin", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/sysadmin/comments/14dj065/workflow_rolling_forward_with_zfs_and_httm/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?auto=webp&amp;v=enabled&amp;s=7b515159b74925070a22fbc932d316c14fb0e899", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a16c7d76c6c4f5ca3845e88aae2f9a9c8aaa14dd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65333666b37ec358ed6181c64f322fcfe1d98536", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e746d6194313ecee4ec06505218fab55380d47d4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42a0aa1f7a5c15d912d63d05487e9fbf0bf018b6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f90f3973d6f8b501bd9de6df97031e7bb9986d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5NRdlqa66cA6WqkIojZXuyBRatp36sCS6B4XwU4AtcI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f07216f61e5a333ef17d3047e7ca0bf562b9ef", "width": 1080, "height": 540}], "variants": {}, "id": "wGDAH0vLbp_XphYTE0GmnI16WkQDoI0D1HxW4kVpGIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dj0m5", "is_robot_indexable": true, "report_reasons": null, "author": "small_kimono", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14dj065", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dj0m5/workflow_rolling_forward_with_zfs_and_httm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/sysadmin/comments/14dj065/workflow_rolling_forward_with_zfs_and_httm/", "subreddit_subscribers": 927654, "created_utc": 1687191482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A survey of 33 companies in the Sequoia network, from start-ups at the start-up stage to large public enterprises about implementing AI in their products.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_14deoll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_quu3akj0", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gXi3VGgO5WVYEMrfR4z-NGakORGBdTgfU-1h7VFJwlU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "lablabai", "selftext": "[As we can see on the picture, so far 94% are \"let's poke around the Open AI API (91%) or Claude's (15%) and come up with something based on that.](https://www.sequoiacap.com/article/llm-stack-perspective/)\n\nhttps://preview.redd.it/682c0q0p6z6b1.jpg?width=1440&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d76871e438c153c89094eee665fa66a6358c9aff\n\nThe main points are:\n\n1. Almost every company in the Sequoia network is building language models into their products. \n\n2. The new stack for these applications focuses on the language model API, but the use of open source is also growing. \n\n3. Companies want to adapt language models to their unique context. \n\n4. Today the stack for the LLM API may seem separate from the user model learning stack, but over time they blend.\n\n5. The stack is becoming more and more developer-friendly.\n\n6. Language models need to become more robust (output quality, data privacy, security) for full implementation. \n\n7. Language model applications will become increasingly multimodal\n\n8. AI moves too fast to be sure of the final stack. Training and customisation of open source and custom models also seems to be on the rise.", "author_fullname": "t2_quu3akj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A survey of 33 companies in the Sequoia network, from start-ups at the start-up stage to large public enterprises about implementing AI in their products.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/lablabai", "hidden": false, "pwls": null, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "media_metadata": {"682c0q0p6z6b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50dd4e051bd1cd3373b6c11a3a440a07583d86b6"}, {"y": 150, "x": 216, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a64b27b521e38b9a544f35ffcb11be4c61880cea"}, {"y": 222, "x": 320, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=113e2ad2907aa29124ea1e6d5cee56c49b9a2ad4"}, {"y": 444, "x": 640, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcf5bd7230161bd24421df751d12caa26abe3cb8"}, {"y": 666, "x": 960, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=769a916eb152c61ddef32c411e16932139b65d4c"}, {"y": 750, "x": 1080, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf5a3126e208858c4209723aaa8a209396c8da4a"}], "s": {"y": 1000, "x": 1440, "u": "https://preview.redd.it/682c0q0p6z6b1.jpg?width=1440&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d76871e438c153c89094eee665fa66a6358c9aff"}, "id": "682c0q0p6z6b1"}}, "name": "t3_14dei8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tech News", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gXi3VGgO5WVYEMrfR4z-NGakORGBdTgfU-1h7VFJwlU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1687180815.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.lablabai", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.sequoiacap.com/article/llm-stack-perspective/\"&gt;As we can see on the picture, so far 94% are &amp;quot;let&amp;#39;s poke around the Open AI API (91%) or Claude&amp;#39;s (15%) and come up with something based on that.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/682c0q0p6z6b1.jpg?width=1440&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d76871e438c153c89094eee665fa66a6358c9aff\"&gt;https://preview.redd.it/682c0q0p6z6b1.jpg?width=1440&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d76871e438c153c89094eee665fa66a6358c9aff&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The main points are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Almost every company in the Sequoia network is building language models into their products. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The new stack for these applications focuses on the language model API, but the use of open source is also growing. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Companies want to adapt language models to their unique context. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Today the stack for the LLM API may seem separate from the user model learning stack, but over time they blend.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The stack is becoming more and more developer-friendly.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Language models need to become more robust (output quality, data privacy, security) for full implementation. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Language model applications will become increasingly multimodal&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;AI moves too fast to be sure of the final stack. Training and customisation of open source and custom models also seems to be on the rise.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?auto=webp&amp;v=enabled&amp;s=68dba991f2344b425a0a6e1133341fb6fb7ba889", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08527c99d57f5a2d2de17c818afa8e6d1bad0c0c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4012d7100dd49d1427e57a5f227d42be1bfa410e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e58aa4967e42f88b5420026e19b52586d287eff", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51c0bb2c6f10417d4aecc8dc110518a3a4385437", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6cd5a152972c6c7817cfdecf97575e0e999343d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9fbd851aedcda1624fae0c28c55b8056a45a06d", "width": 1080, "height": 567}], "variants": {}, "id": "aqA5PXxYP1c_uyajKt0unsk0PUa7-mwe8F-cbKQFQTQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f65a2c10-050a-11ee-9666-f6d6563c7394", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_8bsgk5", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14dei8p", "is_robot_indexable": true, "report_reasons": null, "author": "lablabai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/lablabai/comments/14dei8p/a_survey_of_33_companies_in_the_sequoia_network/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/lablabai/comments/14dei8p/a_survey_of_33_companies_in_the_sequoia_network/", "subreddit_subscribers": 63, "created_utc": 1687180815.0, "num_crossposts": 14, "media": null, "is_video": false}], "created": 1687181270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.lablabai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/lablabai/comments/14dei8p/a_survey_of_33_companies_in_the_sequoia_network/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?auto=webp&amp;v=enabled&amp;s=68dba991f2344b425a0a6e1133341fb6fb7ba889", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08527c99d57f5a2d2de17c818afa8e6d1bad0c0c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4012d7100dd49d1427e57a5f227d42be1bfa410e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e58aa4967e42f88b5420026e19b52586d287eff", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51c0bb2c6f10417d4aecc8dc110518a3a4385437", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6cd5a152972c6c7817cfdecf97575e0e999343d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9Cp5hrhEjWDEl86EITA0yyw3qRZls2TzdsXdGcMnYHw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9fbd851aedcda1624fae0c28c55b8056a45a06d", "width": 1080, "height": 567}], "variants": {}, "id": "aqA5PXxYP1c_uyajKt0unsk0PUa7-mwe8F-cbKQFQTQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14deoll", "is_robot_indexable": true, "report_reasons": null, "author": "lablabai", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14dei8p", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14deoll/a_survey_of_33_companies_in_the_sequoia_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/lablabai/comments/14dei8p/a_survey_of_33_companies_in_the_sequoia_network/", "subreddit_subscribers": 927654, "created_utc": 1687181270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data-driven Design- Occupancy Planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14d6to7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_33lq5l9v", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/URwe-LadOSa-7aKF2HFsbx-R2kMrz_B7ultGxN4X4-A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_Zyeta", "selftext": "", "author_fullname": "t2_33lq5l9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data-driven Design- Occupancy Planning", "link_flair_richtext": [], "subreddit_name_prefixed": "u/Zyeta", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14d6qce", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/URwe-LadOSa-7aKF2HFsbx-R2kMrz_B7ultGxN4X4-A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1687156608.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7076394482698498048", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?auto=webp&amp;v=enabled&amp;s=fdcc112103a1fbb449190ef7b42ed002d967b000", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c2386b96939569f0b9897f889c5aa1177da9e8d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2341a4a7d44a8795452214129e187e66f31329a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa8e4fb0381cff92e7d0834cb2db263ed84a3df3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ccc87605dae417403227e09b59d21c6d92db322", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7702c1f2a12d1b8f65d4fe488518a1c255b5ab9", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a759da390caa76e85dff9aeb38f247f3b628bddb", "width": 1080, "height": 607}], "variants": {}, "id": "xAJvhMlYamS48Dp0GTB02BoJgCrhI4ZGgAqkClww-8g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_wyof5", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14d6qce", "is_robot_indexable": true, "report_reasons": null, "author": "Zyeta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_Zyeta/comments/14d6qce/datadriven_design_occupancy_planning/", "parent_whitelist_status": null, "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7076394482698498048", "subreddit_subscribers": 0, "created_utc": 1687156608.0, "num_crossposts": 5, "media": null, "is_video": false}], "created": 1687156921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7076394482698498048", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?auto=webp&amp;v=enabled&amp;s=fdcc112103a1fbb449190ef7b42ed002d967b000", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c2386b96939569f0b9897f889c5aa1177da9e8d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2341a4a7d44a8795452214129e187e66f31329a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa8e4fb0381cff92e7d0834cb2db263ed84a3df3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ccc87605dae417403227e09b59d21c6d92db322", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7702c1f2a12d1b8f65d4fe488518a1c255b5ab9", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/CjIwvHoLtsSrDvt7RTPJ_BXkcujqa0uSv4uTgKHACrM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a759da390caa76e85dff9aeb38f247f3b628bddb", "width": 1080, "height": 607}], "variants": {}, "id": "xAJvhMlYamS48Dp0GTB02BoJgCrhI4ZGgAqkClww-8g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14d6to7", "is_robot_indexable": true, "report_reasons": null, "author": "Zyeta", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14d6qce", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14d6to7/datadriven_design_occupancy_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7076394482698498048", "subreddit_subscribers": 927654, "created_utc": 1687156921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datacamp: Data Analyst Professional - Data Validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14dal03", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_8kmrzse7", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zDgfeqgjZAmy0Ccb3iqvFRRwpL-bM4LwJdUneKzZ8CM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "DataCamp", "selftext": "Hi there! Recently I submitted my case study for the data analist professional exam. I looked at the examples that are provided on datacamp and tried to provide a similar solution. \n\nI have no clue why my data validation is wrong. Can someone give me a clue so that I pass next time? Many thanks!", "author_fullname": "t2_8kmrzse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst Professional - Data Validation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataCamp", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_14d6yc2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zDgfeqgjZAmy0Ccb3iqvFRRwpL-bM4LwJdUneKzZ8CM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1687157381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! Recently I submitted my case study for the data analist professional exam. I looked at the examples that are provided on datacamp and tried to provide a similar solution. &lt;/p&gt;\n\n&lt;p&gt;I have no clue why my data validation is wrong. Can someone give me a clue so that I pass next time? Many thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/b01ocj049x6b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?auto=webp&amp;v=enabled&amp;s=527721f1ca5c30af7c989a9993f486526372face", "width": 1142, "height": 766}, "resolutions": [{"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7850ec27d167a4affa38bad196e4a0ffde29d92b", "width": 108, "height": 72}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c00e5d0c44fea657cfb9b50998006a8e77893ef", "width": 216, "height": 144}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=181b5c9695fba2425903e5327ccbced3108515e8", "width": 320, "height": 214}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5b1fce5bde4e058c8918be001103452a306b496", "width": 640, "height": 429}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc1af188dc12d98e08f807c3d570a35f5125a1d1", "width": 960, "height": 643}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cf6a721c5472f3aaea8eb1a830e11bf9e31281d", "width": 1080, "height": 724}], "variants": {}, "id": "grqRTG4yYszHpvWR1_8d7KyCXnJ76us27SSTs8U-N80"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_3fd1q", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14d6yc2", "is_robot_indexable": true, "report_reasons": null, "author": "sportyboi98", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataCamp/comments/14d6yc2/data_analyst_professional_data_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/b01ocj049x6b1.jpg", "subreddit_subscribers": 4062, "created_utc": 1687157381.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1687169790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/b01ocj049x6b1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?auto=webp&amp;v=enabled&amp;s=527721f1ca5c30af7c989a9993f486526372face", "width": 1142, "height": 766}, "resolutions": [{"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7850ec27d167a4affa38bad196e4a0ffde29d92b", "width": 108, "height": 72}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c00e5d0c44fea657cfb9b50998006a8e77893ef", "width": 216, "height": 144}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=181b5c9695fba2425903e5327ccbced3108515e8", "width": 320, "height": 214}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5b1fce5bde4e058c8918be001103452a306b496", "width": 640, "height": 429}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc1af188dc12d98e08f807c3d570a35f5125a1d1", "width": 960, "height": 643}, {"url": "https://preview.redd.it/b01ocj049x6b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cf6a721c5472f3aaea8eb1a830e11bf9e31281d", "width": 1080, "height": 724}], "variants": {}, "id": "grqRTG4yYszHpvWR1_8d7KyCXnJ76us27SSTs8U-N80"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dal03", "is_robot_indexable": true, "report_reasons": null, "author": "sportyboi98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14d6yc2", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dal03/datacamp_data_analyst_professional_data_validation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/b01ocj049x6b1.jpg", "subreddit_subscribers": 927654, "created_utc": 1687169790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After reading their paper RedefinedWeb, the tl;dr answer is simply better data better model, if you want to see more details I explain the paper in this article [https://medium.com/@azizbelaweid/behind-falcon-40bs-rise-the-story-of-dominating-the-open-source-llm-board-cd9d000c3987](https://medium.com/@azizbelaweid/behind-falcon-40bs-rise-the-story-of-dominating-the-open-source-llm-board-cd9d000c3987)", "author_fullname": "t2_8btx52ld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Falcon 40B managed to beat LLaMA 65B?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14dky2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.09, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687195867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After reading their paper RedefinedWeb, the tl;dr answer is simply better data better model, if you want to see more details I explain the paper in this article &lt;a href=\"https://medium.com/@azizbelaweid/behind-falcon-40bs-rise-the-story-of-dominating-the-open-source-llm-board-cd9d000c3987\"&gt;https://medium.com/@azizbelaweid/behind-falcon-40bs-rise-the-story-of-dominating-the-open-source-llm-board-cd9d000c3987&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?auto=webp&amp;v=enabled&amp;s=1f118353bc2c2455b22b73453ee7f79350e0f683", "width": 1200, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f41a6631ea0fe5be481b4d4651fb371528b658b", "width": 108, "height": 135}, {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=970a35fd78035487959e1ef10befe94be46f24f1", "width": 216, "height": 270}, {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbb2275ed49b2a8700152b048f341941f9f9ca99", "width": 320, "height": 400}, {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c151c2d31c2405e2c1538ec1c3f6b19377a0033", "width": 640, "height": 800}, {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fb84a363d9af7b6e924f54ffaca5cb26b3a7105", "width": 960, "height": 1200}, {"url": "https://external-preview.redd.it/462x8L1AHtwfadD1NiQCIRej5cYR_BxIe_FMWCabdss.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbdfcc95682e4c84e04fe6fca37b6af9a3cbaed6", "width": 1080, "height": 1350}], "variants": {}, "id": "EvPPP04Zrk8sUkQzTG6GI94siyHMAcJdi6F80Qfhf8U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14dky2v", "is_robot_indexable": true, "report_reasons": null, "author": "Key-Philosopher101", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14dky2v/why_falcon_40b_managed_to_beat_llama_65b/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14dky2v/why_falcon_40b_managed_to_beat_llama_65b/", "subreddit_subscribers": 927654, "created_utc": 1687195867.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}