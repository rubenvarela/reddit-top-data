{"kind": "Listing", "data": {"after": "t3_149t0kp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanted to thank everyone for taking the time to read my thread. \n\nI'm almost 30 years old, and have been in the same career for 8 years. I'm a \"Data Scientist\" with a Bachelors degree in Mathematics &amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp; executives. I work for a major financial institution. \n\nHere's the problem : I feel so disconnected &amp; unpassionate about my job. It's partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp; those who are passionate about Data Science - I'm losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp; improve. This has really never been me. I was able to succeed in the mid to late 2010's being fresh out of school &amp; having an \"up to date\" skillset ... but I don't think I have the drive or desire to do what I have to do to keep up in the mid to late 2020's.  \n\nI feel like I fell into this career out of the start of my career, but now a few months away from 30 I'm questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don't know what it is I'm passionate about, but working as a data scientist in the financial sector for the next 25 years isn't it (or maybe being a data scientist at all). \n\nAt the same time, I don't want to start my career fresh at the age of 30. I think I'm a naturally analytical person, and want to be able to carry over some of the skills I've picked up from the last 8 years into a new role, that might bring more passion &amp; joy back into my job. \n\nSo, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don't want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?\n\nThanks, look forward to hearing some stories", "author_fullname": "t2_ahx89ryl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't want to be a Data Scientist Anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ea3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 362, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 362, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686765001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to thank everyone for taking the time to read my thread. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m almost 30 years old, and have been in the same career for 8 years. I&amp;#39;m a &amp;quot;Data Scientist&amp;quot; with a Bachelors degree in Mathematics &amp;amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp;amp; executives. I work for a major financial institution. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the problem : I feel so disconnected &amp;amp; unpassionate about my job. It&amp;#39;s partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp;amp; those who are passionate about Data Science - I&amp;#39;m losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp;amp; improve. This has really never been me. I was able to succeed in the mid to late 2010&amp;#39;s being fresh out of school &amp;amp; having an &amp;quot;up to date&amp;quot; skillset ... but I don&amp;#39;t think I have the drive or desire to do what I have to do to keep up in the mid to late 2020&amp;#39;s.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I fell into this career out of the start of my career, but now a few months away from 30 I&amp;#39;m questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp;amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don&amp;#39;t know what it is I&amp;#39;m passionate about, but working as a data scientist in the financial sector for the next 25 years isn&amp;#39;t it (or maybe being a data scientist at all). &lt;/p&gt;\n\n&lt;p&gt;At the same time, I don&amp;#39;t want to start my career fresh at the age of 30. I think I&amp;#39;m a naturally analytical person, and want to be able to carry over some of the skills I&amp;#39;ve picked up from the last 8 years into a new role, that might bring more passion &amp;amp; joy back into my job. &lt;/p&gt;\n\n&lt;p&gt;So, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don&amp;#39;t want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?&lt;/p&gt;\n\n&lt;p&gt;Thanks, look forward to hearing some stories&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ea3x", "is_robot_indexable": true, "report_reasons": null, "author": "I_am_Howie_Dewitt", "discussion_type": null, "num_comments": 190, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "subreddit_subscribers": 925142, "created_utc": 1686765001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth investing time in learning specialized Python frameworks for data science, such as TensorFlow or PyTorch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498nva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686751246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498nva", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "subreddit_subscribers": 925142, "created_utc": 1686751246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Consulting analyst with 20 yrs across industries with functional DS and MLOps skills.  For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?\n\nIt\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..", "author_fullname": "t2_a6aqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are your executive team members armchair \u201cAI strategists\u201d now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149nszy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686788760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consulting analyst with 20 yrs across industries with functional DS and MLOps skills.  For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?&lt;/p&gt;\n\n&lt;p&gt;It\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149nszy", "is_robot_indexable": true, "report_reasons": null, "author": "JasonSuave", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "subreddit_subscribers": 925142, "created_utc": 1686788760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?", "author_fullname": "t2_cqm8clcx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning form Data Scientist to Product Analyst.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1497dmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686747878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1497dmz", "is_robot_indexable": true, "report_reasons": null, "author": "Conscious-Rush-9646", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "subreddit_subscribers": 925142, "created_utc": 1686747878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. \n\nAs an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. \n\nIf there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. \n\nIf anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break the \u201cneed experience to get experience\u201d cycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149bakb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686757729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. &lt;/p&gt;\n\n&lt;p&gt;As an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. &lt;/p&gt;\n\n&lt;p&gt;If there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. &lt;/p&gt;\n\n&lt;p&gt;If anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149bakb", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "subreddit_subscribers": 925142, "created_utc": 1686757729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is large but not very advanced technologically and the users of this prediction model will be lamens who input features of a new sample and want a prediction as an output. None of the users can have Python on their machine except for me, which is where I've built my models.\n\nMost tools we make are built within excel as this is something everyone has access to and can use. I can use excel if I stick to simple regressions, but if I want something like a random forest regression model I don't think it's possible to build that into an excel formula or VBA (as far as I know).\n\nHow do people normally get around this issue? Is there some easy alternative I'm missing?  \n\n\nEdit: Thanks everyone for your insightful answers. I clearly have a lot to learn about deployment and will research your ideas, thanks again.", "author_fullname": "t2_1055bs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do You Let End Users Use Your Prediction Models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149jie6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686827309.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686777608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is large but not very advanced technologically and the users of this prediction model will be lamens who input features of a new sample and want a prediction as an output. None of the users can have Python on their machine except for me, which is where I&amp;#39;ve built my models.&lt;/p&gt;\n\n&lt;p&gt;Most tools we make are built within excel as this is something everyone has access to and can use. I can use excel if I stick to simple regressions, but if I want something like a random forest regression model I don&amp;#39;t think it&amp;#39;s possible to build that into an excel formula or VBA (as far as I know).&lt;/p&gt;\n\n&lt;p&gt;How do people normally get around this issue? Is there some easy alternative I&amp;#39;m missing?  &lt;/p&gt;\n\n&lt;p&gt;Edit: Thanks everyone for your insightful answers. I clearly have a lot to learn about deployment and will research your ideas, thanks again.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149jie6", "is_robot_indexable": true, "report_reasons": null, "author": "Gef_1_Man_Army", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149jie6/how_do_you_let_end_users_use_your_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149jie6/how_do_you_let_end_users_use_your_prediction/", "subreddit_subscribers": 925142, "created_utc": 1686777608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. \n\nIs this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.", "author_fullname": "t2_5238n9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are extremely long take home assignments in interview processes the norm now, or am I unlucky?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149cj12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686762740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. &lt;/p&gt;\n\n&lt;p&gt;Is this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cj12", "is_robot_indexable": true, "report_reasons": null, "author": "ravidampatel", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "subreddit_subscribers": 925142, "created_utc": 1686760756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! You can find more [here](https://github.com/bentoml/OpenLLM).\n\nTo start, install it with pip: `pip install -U openllm`. It currently supports all significant SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more! To start, do `openllm start:`\n\n    openllm start dolly-v2 --model-id databricks/dolly-v2-7b\n\nTo ask this LLM, you can do `openllm query --endpoint http://localhost:3000 \"What is the meaning of life?\"`\n\nNote that you can easily call a remote LLM server running with OpenLLM via query.\n\nIt also includes a seamless transition between SDK and CLI, meaning you can directly ask the LLM within Python SDK:\n\n    import openllm\n    \n    client = openllm.client.HTTPClient(\"http://localhost:3000\")\n    \n    client.query(\"what is the meaning of life?\")\n\nTo easily bundle these into a deployable format, you can do `openllm build`\n\nIt will create a format called Bento, which can be easily sharable and create containers with it!.\n\n**Some of the feature that is currently wip:**\n\n\\- Fine-tuning API with `LLM.tuning()`\n\n    import openllm\n    \n    llm = openllm.AutoLLM.for_model(\"opt\", model_id='facebook/opt-350m')\n    llm.tuning(mode='lora', quantize='bitsandbytes', load_in_4bit=True, \n    dataloader=..., max_steps=..., \n    )\n\nthis LLM class can also easily apply pretrained LoRA or GPTQ layer:\n\n    llm = openllm.AutoLLM.for_model(\"opt\", model_id='facebook/opt-350m', \n                                    adapter_id='aarnphm/opt-lora-alpaca-350m' # this can also be a path)\n    assert llm.wrapped_with_adapter is True\n\n\\- LangChain integration\n\nIn future LangChain release, one can do\n\nTo quickly start a local LLM, simply do the following:\n\n    from langchain.llms import OpenLLM\n    llm = OpenLLM(model_name=\"dolly-v2\", model_id='databricks/dolly-v2-7b', device_map='auto')  \n    llm(\"What is the difference between a duck and a goose? And why there are so many Goose in Canada?\")\n\nAs mentioned above, the integration will also have the capabilities tointeract with remote OpenLLM Server. Given there is a running OpenLLM server at address \"a\" you can do the following:\n\n    from langchain.llms import OpenLLM\n    \n    llm = OpenLLM(server_url=\"http://address:3000\")\n    llm(\"What is the difference between duck and goose?\")\n\n\\- OpenAI Compatible API\n\n    import openai\n    \n    openai.api_base = \"http://localhost:3000\" # Running with OpenLLM\n    \n    completion = openai.Completion.create(...)\n\nWe are actively developing the library so we would love your thoughts and feedback.", "author_fullname": "t2_bkphm0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing, OpenLLM \ud83c\udf89", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149v241", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686811279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! You can find more &lt;a href=\"https://github.com/bentoml/OpenLLM\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;To start, install it with pip: &lt;code&gt;pip install -U openllm&lt;/code&gt;. It currently supports all significant SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more! To start, do &lt;code&gt;openllm start:&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;openllm start dolly-v2 --model-id databricks/dolly-v2-7b\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To ask this LLM, you can do &lt;code&gt;openllm query --endpoint http://localhost:3000 &amp;quot;What is the meaning of life?&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Note that you can easily call a remote LLM server running with OpenLLM via query.&lt;/p&gt;\n\n&lt;p&gt;It also includes a seamless transition between SDK and CLI, meaning you can directly ask the LLM within Python SDK:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import openllm\n\nclient = openllm.client.HTTPClient(&amp;quot;http://localhost:3000&amp;quot;)\n\nclient.query(&amp;quot;what is the meaning of life?&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To easily bundle these into a deployable format, you can do &lt;code&gt;openllm build&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;It will create a format called Bento, which can be easily sharable and create containers with it!.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some of the feature that is currently wip:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Fine-tuning API with &lt;code&gt;LLM.tuning()&lt;/code&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import openllm\n\nllm = openllm.AutoLLM.for_model(&amp;quot;opt&amp;quot;, model_id=&amp;#39;facebook/opt-350m&amp;#39;)\nllm.tuning(mode=&amp;#39;lora&amp;#39;, quantize=&amp;#39;bitsandbytes&amp;#39;, load_in_4bit=True, \ndataloader=..., max_steps=..., \n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;this LLM class can also easily apply pretrained LoRA or GPTQ layer:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;llm = openllm.AutoLLM.for_model(&amp;quot;opt&amp;quot;, model_id=&amp;#39;facebook/opt-350m&amp;#39;, \n                                adapter_id=&amp;#39;aarnphm/opt-lora-alpaca-350m&amp;#39; # this can also be a path)\nassert llm.wrapped_with_adapter is True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;- LangChain integration&lt;/p&gt;\n\n&lt;p&gt;In future LangChain release, one can do&lt;/p&gt;\n\n&lt;p&gt;To quickly start a local LLM, simply do the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from langchain.llms import OpenLLM\nllm = OpenLLM(model_name=&amp;quot;dolly-v2&amp;quot;, model_id=&amp;#39;databricks/dolly-v2-7b&amp;#39;, device_map=&amp;#39;auto&amp;#39;)  \nllm(&amp;quot;What is the difference between a duck and a goose? And why there are so many Goose in Canada?&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;As mentioned above, the integration will also have the capabilities tointeract with remote OpenLLM Server. Given there is a running OpenLLM server at address &amp;quot;a&amp;quot; you can do the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from langchain.llms import OpenLLM\n\nllm = OpenLLM(server_url=&amp;quot;http://address:3000&amp;quot;)\nllm(&amp;quot;What is the difference between duck and goose?&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;- OpenAI Compatible API&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import openai\n\nopenai.api_base = &amp;quot;http://localhost:3000&amp;quot; # Running with OpenLLM\n\ncompletion = openai.Completion.create(...)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We are actively developing the library so we would love your thoughts and feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?auto=webp&amp;v=enabled&amp;s=21939d72bda937c6874fc1891b6f861c31245852", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f232026305afb8fff7146334d0a008c90ddf6ee", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bfacef9427be64c448a339bf6292c6bf1192c7b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cec6897345fb42f68246119454aba03b6dccda36", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6692d76291a5936f49104b2cd87e3a41977919c0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9844e6ac567e4e85e8342828e78bceac30b3d5f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/tC_wOPeiMYFTP6_bob4P63PUZat4nbaWjzRLMNGCxuw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cc68887d501e319977201a78d7f88a0e02f7b04", "width": 1080, "height": 540}], "variants": {}, "id": "6SOFROuee8kILHsJKHGtMmu4qOhjHmA4Nj1vuo4ja0Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149v241", "is_robot_indexable": true, "report_reasons": null, "author": "AaZasDass", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149v241/introducing_openllm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149v241/introducing_openllm/", "subreddit_subscribers": 925142, "created_utc": 1686811279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. \n\nWhat are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I've previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?", "author_fullname": "t2_9chfd9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Healthcare", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149amep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686756070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. &lt;/p&gt;\n\n&lt;p&gt;What are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I&amp;#39;ve previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149amep", "is_robot_indexable": true, "report_reasons": null, "author": "Statefan3778", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149amep/data_science_in_healthcare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149amep/data_science_in_healthcare/", "subreddit_subscribers": 925142, "created_utc": 1686756070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How does one un-learn how to micro-manage, especially in data science where it can be tempting to drift on your own path into an EDA rabbit-hole, and accidentally hoard all the work? Or rather get into a rabbit-hole and produce a disproportionately higher volume of (perhaps even unneeded) work compared to your teammates, making it *seem* like you shouldered most of the effort?\n\nI've come from a high school experience where I've been surrounded by slackers. But now that I'm in a good college, I should know that I am surrounded by diligent, educated peers. And yet in a lot of the coding projects that I can recall, I've always hoarded most of the work or fell back into my old high school habits of micro-managing. What do I do?", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlearning how to micro-manage in DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149rbom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686799550.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686799149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does one un-learn how to micro-manage, especially in data science where it can be tempting to drift on your own path into an EDA rabbit-hole, and accidentally hoard all the work? Or rather get into a rabbit-hole and produce a disproportionately higher volume of (perhaps even unneeded) work compared to your teammates, making it &lt;em&gt;seem&lt;/em&gt; like you shouldered most of the effort?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come from a high school experience where I&amp;#39;ve been surrounded by slackers. But now that I&amp;#39;m in a good college, I should know that I am surrounded by diligent, educated peers. And yet in a lot of the coding projects that I can recall, I&amp;#39;ve always hoarded most of the work or fell back into my old high school habits of micro-managing. What do I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149rbom", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149rbom/unlearning_how_to_micromanage_in_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149rbom/unlearning_how_to_micromanage_in_ds/", "subreddit_subscribers": 925142, "created_utc": 1686799149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an engineering degree in hydraulic engineering, and i want to completely switch career to data science. My question is for me later to get a job, is it best to:  \n1- Study online free courses on coursera and then afterwards pass certification Azure/GC/AWS.\n\n2- Look for a university for a Master's degree (and probably study online).  \n\n\nI'm not working nor planning to work this whole entire time, so i'm looking for a cost effective solution , And i really don't wanna follow a path and waste my time.  \nThanks in advance, and pardon my english.", "author_fullname": "t2_3xfhtj08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to study online free courses or to take a course in a university?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149pt2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686794573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an engineering degree in hydraulic engineering, and i want to completely switch career to data science. My question is for me later to get a job, is it best to:&lt;br/&gt;\n1- Study online free courses on coursera and then afterwards pass certification Azure/GC/AWS.&lt;/p&gt;\n\n&lt;p&gt;2- Look for a university for a Master&amp;#39;s degree (and probably study online).  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not working nor planning to work this whole entire time, so i&amp;#39;m looking for a cost effective solution , And i really don&amp;#39;t wanna follow a path and waste my time.&lt;br/&gt;\nThanks in advance, and pardon my english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149pt2v", "is_robot_indexable": true, "report_reasons": null, "author": "EcstaticShadow", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149pt2v/is_it_better_to_study_online_free_courses_or_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149pt2v/is_it_better_to_study_online_free_courses_or_to/", "subreddit_subscribers": 925142, "created_utc": 1686794573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey folks,   \nLet's say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no \"relevant\" domain experience. \n\nWhat are your advices on having more chances to be given a chance?\n\nI heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.  \nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?", "author_fullname": "t2_s9fqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to increase chances for an interview when switching industries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149cvkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686761622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;br/&gt;\nLet&amp;#39;s say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no &amp;quot;relevant&amp;quot; domain experience. &lt;/p&gt;\n\n&lt;p&gt;What are your advices on having more chances to be given a chance?&lt;/p&gt;\n\n&lt;p&gt;I heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.&lt;br/&gt;\nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cvkw", "is_robot_indexable": true, "report_reasons": null, "author": "scriptosens", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "subreddit_subscribers": 925142, "created_utc": 1686761622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_c1m2cvcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hawkflow.ai - free early access for r/datascience users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_149wclh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/---Ocmmc_PNPL6k-Lkk_pPClHPLQ4h9loff1Q1dUKVs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686815875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hu2r01dh156b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hu2r01dh156b1.png?auto=webp&amp;v=enabled&amp;s=193bcb36934d8c6dfbcb355be634f08cb3c3a036", "width": 973, "height": 603}, "resolutions": [{"url": "https://preview.redd.it/hu2r01dh156b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55556db46d5258984e836e4178ba8ee610222cce", "width": 108, "height": 66}, {"url": "https://preview.redd.it/hu2r01dh156b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cbaa9dc36b7d21d53ce9a504c6061a272a9b13d7", "width": 216, "height": 133}, {"url": "https://preview.redd.it/hu2r01dh156b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef607eee6b5e0f1787ed2d07de09069c2273521d", "width": 320, "height": 198}, {"url": "https://preview.redd.it/hu2r01dh156b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6804be564cae4380414f35dff222804e30eec3c2", "width": 640, "height": 396}, {"url": "https://preview.redd.it/hu2r01dh156b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14412654dc46d19feaa73d122c96378499470a47", "width": 960, "height": 594}], "variants": {}, "id": "3zzKolC15Z-5w1D_Sy9u82mp2QbnchZr_Qq8OixZtbo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "149wclh", "is_robot_indexable": true, "report_reasons": null, "author": "HawkFlowAI", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149wclh/hawkflowai_free_early_access_for_rdatascience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hu2r01dh156b1.png", "subreddit_subscribers": 925142, "created_utc": 1686815875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For people who've worked in industry for more than 2 years, how do you quickly find out what the latest changes are in the field. Like 4-5 years ago I was right out of college and then catboost came out, transfer learning became viable with resnet and hugging face (which was massive since it allows deeplearning for small datasets), but I feel like since then I've basically just sharped up on engineering practices and GPT-3 is a better language model. \n\nAre there just less new things coming out or how do you see the top 5 highlights each year that you should play around with", "author_fullname": "t2_23bi1gsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you keep up to date with the latest changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ve08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686812437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For people who&amp;#39;ve worked in industry for more than 2 years, how do you quickly find out what the latest changes are in the field. Like 4-5 years ago I was right out of college and then catboost came out, transfer learning became viable with resnet and hugging face (which was massive since it allows deeplearning for small datasets), but I feel like since then I&amp;#39;ve basically just sharped up on engineering practices and GPT-3 is a better language model. &lt;/p&gt;\n\n&lt;p&gt;Are there just less new things coming out or how do you see the top 5 highlights each year that you should play around with&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ve08", "is_robot_indexable": true, "report_reasons": null, "author": "Alienbushman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ve08/how_do_you_keep_up_to_date_with_the_latest_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ve08/how_do_you_keep_up_to_date_with_the_latest_changes/", "subreddit_subscribers": 925142, "created_utc": 1686812437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently got a scholarship to study on Datacamp. It's a huge deal to someone like me who wouldn't normally be able to afford it. The scholarship runs for six months, afterwards, I will have to pay to continue. This isn't an option for me though so my only chance is to maximize it while it's still free. \n\nFor anyone that has uses Datacamp as a learning resource, how do I best maximize it? \n\nI want to complete the Data Science with Python Professional certification before time runs out. Is it possible to do this?\n\n I've heard a lot of mixed reviews about the platform. Some people have told me that it's great for learning but makes you dependent on their IDE and other platforms.  Is this true? \n\nI am a newbie in the data science space, so there's a lot of things I may not know that I should be doing on other places(for example, I know that I should use an IDE like Pycharm/ Vscode for programming in Python but what of other things I may not know). I want to learn with the course but also make sure not to become dependent and be able to do things outside their platform. How do I best do this?\n\n&amp;#x200B;\n\nAnswering any or all of my questions will be highly appreciated  !!! Also, if you have any tips for me, do share!", "author_fullname": "t2_7k6ix3ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about DATACAMP(please answer if you can, please!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149tmd1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686806421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got a scholarship to study on Datacamp. It&amp;#39;s a huge deal to someone like me who wouldn&amp;#39;t normally be able to afford it. The scholarship runs for six months, afterwards, I will have to pay to continue. This isn&amp;#39;t an option for me though so my only chance is to maximize it while it&amp;#39;s still free. &lt;/p&gt;\n\n&lt;p&gt;For anyone that has uses Datacamp as a learning resource, how do I best maximize it? &lt;/p&gt;\n\n&lt;p&gt;I want to complete the Data Science with Python Professional certification before time runs out. Is it possible to do this?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard a lot of mixed reviews about the platform. Some people have told me that it&amp;#39;s great for learning but makes you dependent on their IDE and other platforms.  Is this true? &lt;/p&gt;\n\n&lt;p&gt;I am a newbie in the data science space, so there&amp;#39;s a lot of things I may not know that I should be doing on other places(for example, I know that I should use an IDE like Pycharm/ Vscode for programming in Python but what of other things I may not know). I want to learn with the course but also make sure not to become dependent and be able to do things outside their platform. How do I best do this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Answering any or all of my questions will be highly appreciated  !!! Also, if you have any tips for me, do share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149tmd1", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Row_5195", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149tmd1/questions_about_datacampplease_answer_if_you_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149tmd1/questions_about_datacampplease_answer_if_you_can/", "subreddit_subscribers": 925142, "created_utc": 1686806421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)", "author_fullname": "t2_a2ps3jf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on ETL tools like Azure Data Factory or AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149chge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149chge", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent-Bunch7505", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "subreddit_subscribers": 925142, "created_utc": 1686760645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Excited to announce DataCopilot, an open-source framework for creating chat-based apps, powered by Python and Vue.js! \ud83c\udf89\n\nThink chat apps that can interact with your files, docs, images, or anything your imagination can conceive! \ud83d\udcad\ud83d\ude80 And, it's designed to be super user-friendly and you have full control!\n\nDataCopilot comes with two compute backends by default both for chatting with your XLSX and CSV files but can easily be extended.\n\nWe would greatly appreciate it if you could try out DataCopilot and provide your insights. Your input will significantly contribute to its upcoming improvements and development.\n\n[http://github.com/modulos/data\\_copilot](http://github.com/modulos/data_copilot)\n\n    pip install data-copilot\n\n[https://pypi.org/project/data-copilot/](https://pypi.org/project/data-copilot/)", "author_fullname": "t2_czm7z9qa8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build a scalable custom chat-based app with OpenAI API and DataCopilot \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149vi1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686813059.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686812779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excited to announce DataCopilot, an open-source framework for creating chat-based apps, powered by Python and Vue.js! \ud83c\udf89&lt;/p&gt;\n\n&lt;p&gt;Think chat apps that can interact with your files, docs, images, or anything your imagination can conceive! \ud83d\udcad\ud83d\ude80 And, it&amp;#39;s designed to be super user-friendly and you have full control!&lt;/p&gt;\n\n&lt;p&gt;DataCopilot comes with two compute backends by default both for chatting with your XLSX and CSV files but can easily be extended.&lt;/p&gt;\n\n&lt;p&gt;We would greatly appreciate it if you could try out DataCopilot and provide your insights. Your input will significantly contribute to its upcoming improvements and development.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://github.com/modulos/data_copilot\"&gt;http://github.com/modulos/data_copilot&lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install data-copilot\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://pypi.org/project/data-copilot/\"&gt;https://pypi.org/project/data-copilot/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?auto=webp&amp;v=enabled&amp;s=9e4e0d83cba380e6b39133ba5d10de4ed042d65b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1142e3fda346dd5866ae7fa36770064f964a354c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9eb964d47bb8ddfa9bc252b566e6aa8a9f34d42", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca7feb630b0775451f397dc55d80538c5746647b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=937503e11d7f06e6123fb4b18b2299ea81f47752", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2280aa48aca687944edb246daa41c88fec2e2818", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/yeidlLzJZxNgN28to5hfJgQIl1Xy1yfdB7Sg86Mlcgc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebaf4b3bab3a449aa4012157eacb23709c5890a4", "width": 1080, "height": 540}], "variants": {}, "id": "d8zhm4ekkjHyc09LWEwnaTFwqw2Gzgp14I0rfQDHkvU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149vi1f", "is_robot_indexable": true, "report_reasons": null, "author": "leokster", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149vi1f/build_a_scalable_custom_chatbased_app_with_openai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149vi1f/build_a_scalable_custom_chatbased_app_with_openai/", "subreddit_subscribers": 925142, "created_utc": 1686812779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    \n\n\nIf anybody can please ping me we can discuss it in more detail.  \n\n\nThanks!", "author_fullname": "t2_t423y52t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to scrape unstructured and repetitive data from a pdf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ky0f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    &lt;/p&gt;\n\n&lt;p&gt;If anybody can please ping me we can discuss it in more detail.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ky0f", "is_robot_indexable": true, "report_reasons": null, "author": "YoloPoloGolo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "subreddit_subscribers": 925142, "created_utc": 1686781156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498fdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_cvej3qatd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "FeatureEng", "selftext": "Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:\n\n1. A feature with high impact does not necessarily have a causal relationship with the target variable.\n2. The feature relationship learned by the model may not generalize well in the future.\n\nTo illustrate this, let's consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn't seen new timestamps before and doesn't know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.\n\nThis problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.\n\nI encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition's conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.\n\nTo address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here's what I did for the GE Flight Quest:\n\n1. Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.\n2. Then, I trained a second model to capture the residual effects specific to each airport.\n\nThis two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.\n\nI see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:\n\n1. Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.\n2. Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.\n\nHave you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?\n\nGxav", "author_fullname": "t2_cvej3qatd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/FeatureEng", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_147x9gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686602923.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A feature with high impact does not necessarily have a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;The feature relationship learned by the model may not generalize well in the future.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To illustrate this, let&amp;#39;s consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn&amp;#39;t seen new timestamps before and doesn&amp;#39;t know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.&lt;/p&gt;\n\n&lt;p&gt;This problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.&lt;/p&gt;\n\n&lt;p&gt;I encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition&amp;#39;s conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.&lt;/p&gt;\n\n&lt;p&gt;To address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here&amp;#39;s what I did for the GE Flight Quest:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.&lt;/li&gt;\n&lt;li&gt;Then, I trained a second model to capture the residual effects specific to each airport.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.&lt;/p&gt;\n\n&lt;p&gt;I see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Have you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?&lt;/p&gt;\n\n&lt;p&gt;Gxav&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_8kc7h0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "147x9gj", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 60, "created_utc": 1686602923.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1686750652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498fdy", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_147x9gj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498fdy/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 925142, "created_utc": 1686750652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have two spark data frames, 1st data frame contains two columns named X and y, both columns contains float numbers, df1.count() is 10. 2nd df also looks like df1 but has only 1 row, df2.count() is 1. I want to subtract this row from each row in df1. How can I do it ? in pyspark", "author_fullname": "t2_573xy5ar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark dataframe problem ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14a1wgd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686834178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two spark data frames, 1st data frame contains two columns named X and y, both columns contains float numbers, df1.count() is 10. 2nd df also looks like df1 but has only 1 row, df2.count() is 1. I want to subtract this row from each row in df1. How can I do it ? in pyspark&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a1wgd", "is_robot_indexable": true, "report_reasons": null, "author": "arya_Kumar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a1wgd/spark_dataframe_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a1wgd/spark_dataframe_problem/", "subreddit_subscribers": 925142, "created_utc": 1686834178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi MLearners, i would like to know if some of you has imagined the features and weights that can be included in the famous \"algorithm\" for positioning a video on YouTube, like views, upvote, down vote, semantic analysis of comments, video length, seo title...what's next?", "author_fullname": "t2_16ei22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14a0ctj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686829736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi MLearners, i would like to know if some of you has imagined the features and weights that can be included in the famous &amp;quot;algorithm&amp;quot; for positioning a video on YouTube, like views, upvote, down vote, semantic analysis of comments, video length, seo title...what&amp;#39;s next?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a0ctj", "is_robot_indexable": true, "report_reasons": null, "author": "satchurated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a0ctj/google_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a0ctj/google_algorithm/", "subreddit_subscribers": 925142, "created_utc": 1686829736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  \n\n\nI have received an interview invitation from a small company (&lt;100 employees) regarding the position of ML / AI student assistant. I already have a job in an even smaller company as a BI developer, but I have been considering the switch for some time already.   \n\n\nThat hiring company has started the digitization process last year and is now looking to hire a team of 3 students - 2 AI/ML students and 1 BI student - to work with CDO/CIO to research, test, build and implement new technologies. It is also mentioned that I would both be closely cooperating with that team as well as have some individual projects to work on.   \n\n\nAs for the responsibilities,  the job would be to \"research existing AI and ML tools, test them,  present the possible use-cases and either implement and integrate the existing tools that are already on the market or build your own. You will focus on how AI and ML can be utilized in both e-commerce and  digital marketing to create results and how it can be used in the entire clothing design process to assist our designers\".   \n\n\nI am happy to receive the interview invitation, but I would like to know what red flags should I spot and be wary of. I have a weird feeling that something is odd about it, even though I know close-to-nothing about the industry.", "author_fullname": "t2_5d0gohyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job opportunity potential red flags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14a082z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686829317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;I have received an interview invitation from a small company (&amp;lt;100 employees) regarding the position of ML / AI student assistant. I already have a job in an even smaller company as a BI developer, but I have been considering the switch for some time already.   &lt;/p&gt;\n\n&lt;p&gt;That hiring company has started the digitization process last year and is now looking to hire a team of 3 students - 2 AI/ML students and 1 BI student - to work with CDO/CIO to research, test, build and implement new technologies. It is also mentioned that I would both be closely cooperating with that team as well as have some individual projects to work on.   &lt;/p&gt;\n\n&lt;p&gt;As for the responsibilities,  the job would be to &amp;quot;research existing AI and ML tools, test them,  present the possible use-cases and either implement and integrate the existing tools that are already on the market or build your own. You will focus on how AI and ML can be utilized in both e-commerce and  digital marketing to create results and how it can be used in the entire clothing design process to assist our designers&amp;quot;.   &lt;/p&gt;\n\n&lt;p&gt;I am happy to receive the interview invitation, but I would like to know what red flags should I spot and be wary of. I have a weird feeling that something is odd about it, even though I know close-to-nothing about the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a082z", "is_robot_indexable": true, "report_reasons": null, "author": "Mewashek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a082z/job_opportunity_potential_red_flags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a082z/job_opportunity_potential_red_flags/", "subreddit_subscribers": 925142, "created_utc": 1686829317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vkom8wkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Choose a Database for Your Needs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_149xvf6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YfxuZsUDo9fzSR4DkrHSaucnQcxLkwcGHhSm5v9caVE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686821416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/how-to-choose-a-database-for-your-needs", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?auto=webp&amp;v=enabled&amp;s=42c6033683335d3472f09ec7e3dc04c599600066", "width": 2400, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc6fc2502f2c66d56f740be5cfc4bdcf7ffcf5e3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76ef2c7a68abbc6adddecf8b70956c3ce4511a77", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e1acef1ed48065a3b457b349fc809bccad76b2b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bdf98a693c90f42a23891d4e90f88b4a006bfe7c", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd9e9b8a6445f9e27c48c49ed0346a3e34ca34b2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/tTnqPlZaQW4gc1aBy3HGWimCv-8zrnGkEYEodSCW-5o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be20e2a68f8d92c281be6f4f7e0bfb49f8195b4a", "width": 1080, "height": 540}], "variants": {}, "id": "pfqKOQdmKL_wxvZuoQ6df31vIkJ4cDXSjLEllJ_yuMw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "149xvf6", "is_robot_indexable": true, "report_reasons": null, "author": "JuYuJu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149xvf6/how_to_choose_a_database_for_your_needs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/how-to-choose-a-database-for-your-needs", "subreddit_subscribers": 925142, "created_utc": 1686821416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking into open sourcing Jupyter Lab extensions that focus on making data scientists more productive as such I would like to know what tasks are boring, tedious, time-consuming, error-prone,...\n\n[View Poll](https://www.reddit.com/poll/149x8hn)", "author_fullname": "t2_c38i49mwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most boring and time consuming activities for a data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149x8hn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686819108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking into open sourcing Jupyter Lab extensions that focus on making data scientists more productive as such I would like to know what tasks are boring, tedious, time-consuming, error-prone,...&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/149x8hn\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "149x8hn", "is_robot_indexable": true, "report_reasons": null, "author": "0011ai", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1687078308609, "options": [{"text": "data cleansing", "id": "23478961"}, {"text": "data transformation", "id": "23478962"}, {"text": "data labelling", "id": "23478963"}, {"text": "model training", "id": "23478964"}, {"text": "model fine tuning", "id": "23478965"}, {"text": "Other? (please comment)", "id": "23478966"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 222, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149x8hn/what_are_the_most_boring_and_time_consuming/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/149x8hn/what_are_the_most_boring_and_time_consuming/", "subreddit_subscribers": 925142, "created_utc": 1686819108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been a data scientist in industry for a couple years now. It has been a great experience but I feel like I am stagnating in building new skills since my role is somewhat repetitive. I was recently approached for a position as a sales engineer at a data cloud / AI company. I feel like it is a good opportunity to further my career and broaden my skill set. I am mainly worried that this will shut the door for me to return to data science and machine learning if I decide to move back to more technical roles. Does this sales engineering role sound like it would limit my career path in that way?", "author_fullname": "t2_2413z598", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science to Sales Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149t0kp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686804460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a data scientist in industry for a couple years now. It has been a great experience but I feel like I am stagnating in building new skills since my role is somewhat repetitive. I was recently approached for a position as a sales engineer at a data cloud / AI company. I feel like it is a good opportunity to further my career and broaden my skill set. I am mainly worried that this will shut the door for me to return to data science and machine learning if I decide to move back to more technical roles. Does this sales engineering role sound like it would limit my career path in that way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149t0kp", "is_robot_indexable": true, "report_reasons": null, "author": "cbarraugh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149t0kp/data_science_to_sales_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149t0kp/data_science_to_sales_engineering/", "subreddit_subscribers": 925142, "created_utc": 1686804460.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}