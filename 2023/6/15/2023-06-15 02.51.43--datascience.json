{"kind": "Listing", "data": {"after": "t3_149jpiv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanted to thank everyone for taking the time to read my thread. \n\nI'm almost 30 years old, and have been in the same career for 8 years. I'm a \"Data Scientist\" with a Bachelors degree in Mathematics &amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp; executives. I work for a major financial institution. \n\nHere's the problem : I feel so disconnected &amp; unpassionate about my job. It's partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp; those who are passionate about Data Science - I'm losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp; improve. This has really never been me. I was able to succeed in the mid to late 2010's being fresh out of school &amp; having an \"up to date\" skillset ... but I don't think I have the drive or desire to do what I have to do to keep up in the mid to late 2020's.  \n\nI feel like I fell into this career out of the start of my career, but now a few months away from 30 I'm questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don't know what it is I'm passionate about, but working as a data scientist in the financial sector for the next 25 years isn't it (or maybe being a data scientist at all). \n\nAt the same time, I don't want to start my career fresh at the age of 30. I think I'm a naturally analytical person, and want to be able to carry over some of the skills I've picked up from the last 8 years into a new role, that might bring more passion &amp; joy back into my job. \n\nSo, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don't want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?\n\nThanks, look forward to hearing some stories", "author_fullname": "t2_ahx89ryl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't want to be a Data Scientist Anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ea3x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 230, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 230, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686765001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to thank everyone for taking the time to read my thread. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m almost 30 years old, and have been in the same career for 8 years. I&amp;#39;m a &amp;quot;Data Scientist&amp;quot; with a Bachelors degree in Mathematics &amp;amp; a Minor in CS. My day to day as a Data Scientist is a collection of building/testing/implementing SQL procedures, fitting simple models (Linear Models, Regression Trees, etc.), implementing model results as live models, delivering analysis to decision makers &amp;amp; executives. I work for a major financial institution. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the problem : I feel so disconnected &amp;amp; unpassionate about my job. It&amp;#39;s partially an imposter syndrome issue. Looking at my skillset compared to other data scientists &amp;amp; those who are passionate about Data Science - I&amp;#39;m losing pace. My peers who care about this type of work are deeply involved in improved learning - new Python libraries, new modeling techniques. Everyone in this profession have a strong desire to learn &amp;amp; improve. This has really never been me. I was able to succeed in the mid to late 2010&amp;#39;s being fresh out of school &amp;amp; having an &amp;quot;up to date&amp;quot; skillset ... but I don&amp;#39;t think I have the drive or desire to do what I have to do to keep up in the mid to late 2020&amp;#39;s.  &lt;/p&gt;\n\n&lt;p&gt;I feel like I fell into this career out of the start of my career, but now a few months away from 30 I&amp;#39;m questioning if this is what I want my next 25 years of work to be. I have friends, family and colleagues who are passionate &amp;amp; driven about work. I feel like this was the career I fell into because of my Math degree. I really don&amp;#39;t know what it is I&amp;#39;m passionate about, but working as a data scientist in the financial sector for the next 25 years isn&amp;#39;t it (or maybe being a data scientist at all). &lt;/p&gt;\n\n&lt;p&gt;At the same time, I don&amp;#39;t want to start my career fresh at the age of 30. I think I&amp;#39;m a naturally analytical person, and want to be able to carry over some of the skills I&amp;#39;ve picked up from the last 8 years into a new role, that might bring more passion &amp;amp; joy back into my job. &lt;/p&gt;\n\n&lt;p&gt;So, I wanted to see if others on this sub have gone through the same thing. If yes - what were some stories you have that I can use as inspiration? Are there career options out there for ex Data Scientists who don&amp;#39;t want to be technical code monkeys anymore, that can leverage some of our analytical backgrounds to thrive?&lt;/p&gt;\n\n&lt;p&gt;Thanks, look forward to hearing some stories&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ea3x", "is_robot_indexable": true, "report_reasons": null, "author": "I_am_Howie_Dewitt", "discussion_type": null, "num_comments": 148, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ea3x/i_dont_want_to_be_a_data_scientist_anymore/", "subreddit_subscribers": 924907, "created_utc": 1686765001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_97r2dx3cw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it worth investing time in learning specialized Python frameworks for data science, such as TensorFlow or PyTorch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498nva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686751246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498nva", "is_robot_indexable": true, "report_reasons": null, "author": "Bitter-Tell-8088", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1498nva/is_it_worth_investing_time_in_learning/", "subreddit_subscribers": 924907, "created_utc": 1686751246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best algorithms and what are the purposes thag we can use Machine learning and deep learning algorithms in banking sector ?", "author_fullname": "t2_wasnzue9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science in banking sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148z8eg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686719771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best algorithms and what are the purposes thag we can use Machine learning and deep learning algorithms in banking sector ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148z8eg", "is_robot_indexable": true, "report_reasons": null, "author": "kavinda_uthsuka97", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148z8eg/data_science_in_banking_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148z8eg/data_science_in_banking_sector/", "subreddit_subscribers": 924907, "created_utc": 1686719771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?", "author_fullname": "t2_cqm8clcx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning form Data Scientist to Product Analyst.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1497dmz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686747878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a Data scientist working in London. I was offered a position of Senior Product Analyst in another company. the skill required is quite similar (SQL - python - ETL experience - AB testing - advance statistical modelling) I was wondering if anyone else made this transition and how difficult or easy it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1497dmz", "is_robot_indexable": true, "report_reasons": null, "author": "Conscious-Rush-9646", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1497dmz/transitioning_form_data_scientist_to_product/", "subreddit_subscribers": 924907, "created_utc": 1686747878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Want to stay on top of all new data science research that is coming out. Does anyone have ways to find research papers (best ways to find them)? Just want to make sure I do not fall behind and find reading the papers pretty interesting.", "author_fullname": "t2_1yczo6px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keeping on top of Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148vsv6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686708528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to stay on top of all new data science research that is coming out. Does anyone have ways to find research papers (best ways to find them)? Just want to make sure I do not fall behind and find reading the papers pretty interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148vsv6", "is_robot_indexable": true, "report_reasons": null, "author": "v3rycrafty", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148vsv6/keeping_on_top_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148vsv6/keeping_on_top_of_data_science/", "subreddit_subscribers": 924907, "created_utc": 1686708528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m at a small tech company based out of Toronto, but I work remotely from a LCOL city a few hours away. I do data migrations, a ton of SQL querying for customer requests, working with JSON files, a ton of Azure and occasionally I\u2019ll whip up some PowerBI dashboards for the company when they need something to look nice. I make $70k before bonuses and it\u2019s my first real job out of university (about 3 year of total experience since finishing undergrad). If I had to estimate my average hours spent working most weeks, I\u2019d say it\u2019s about 10. Only the first week of each month do I put in anywhere near a full 40 hours. \n\nI really couldn\u2019t ask for more with my job. I don\u2019t have dread on Sundays worrying about another work week. In fact, I\u2019m doing a full time MS in Data Science right now with how much free time I have. \n\nI\u2019ve recently been applying to other jobs with better titles and slightly higher salaries, but I can\u2019t get myself to leave my current one. I have solid knowledge of Python &amp; R, solid knowledge of analytics and relatively good knowledge of ML, but I don\u2019t have any opportunity to use it. As much as I want a more prestigious title/raise and some analytical work, I can\u2019t help but feel that it\u2019s not worth hating my job/life for a few hundred extra on my cheques you know?\n\nSo, I\u2019ve come to the conclusion that when I\u2019m done my masters in a couple months I\u2019m going to get a part time role on top of my current one. The problem is, I have no idea if they exist. \n\nSide note - I have my annual review next week. What would be something appropriate to bring up to him when talking about wanting to utilize my skill set? Furthermore, how do you suggest a change to a more prestigious title since I spend so much time writing custom queries and working on Azure?", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part-Time Roles: Do They Exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_148vsm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686751662.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686708503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m at a small tech company based out of Toronto, but I work remotely from a LCOL city a few hours away. I do data migrations, a ton of SQL querying for customer requests, working with JSON files, a ton of Azure and occasionally I\u2019ll whip up some PowerBI dashboards for the company when they need something to look nice. I make $70k before bonuses and it\u2019s my first real job out of university (about 3 year of total experience since finishing undergrad). If I had to estimate my average hours spent working most weeks, I\u2019d say it\u2019s about 10. Only the first week of each month do I put in anywhere near a full 40 hours. &lt;/p&gt;\n\n&lt;p&gt;I really couldn\u2019t ask for more with my job. I don\u2019t have dread on Sundays worrying about another work week. In fact, I\u2019m doing a full time MS in Data Science right now with how much free time I have. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve recently been applying to other jobs with better titles and slightly higher salaries, but I can\u2019t get myself to leave my current one. I have solid knowledge of Python &amp;amp; R, solid knowledge of analytics and relatively good knowledge of ML, but I don\u2019t have any opportunity to use it. As much as I want a more prestigious title/raise and some analytical work, I can\u2019t help but feel that it\u2019s not worth hating my job/life for a few hundred extra on my cheques you know?&lt;/p&gt;\n\n&lt;p&gt;So, I\u2019ve come to the conclusion that when I\u2019m done my masters in a couple months I\u2019m going to get a part time role on top of my current one. The problem is, I have no idea if they exist. &lt;/p&gt;\n\n&lt;p&gt;Side note - I have my annual review next week. What would be something appropriate to bring up to him when talking about wanting to utilize my skill set? Furthermore, how do you suggest a change to a more prestigious title since I spend so much time writing custom queries and working on Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "148vsm4", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/148vsm4/parttime_roles_do_they_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/148vsm4/parttime_roles_do_they_exist/", "subreddit_subscribers": 924907, "created_utc": 1686708503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. \n\nAs an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. \n\nIf there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. \n\nIf anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break the \u201cneed experience to get experience\u201d cycle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149bakb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686757729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something I\u2019ve wondered as I\u2019ve been trying to make the shift from data science to more ML/DL related roles. My background being a MS in Statistics, it qualifies me for a lot of data scientist jobs. I recently posted here and a lot of folks mentioned alternatives, like applied scientist roles, or research scientist roles. A lot of these roles in the industry are focused on deep learning, always mentioning how they want people from stats/cs/math, but have this extra requirement of experience in deep learning research. &lt;/p&gt;\n\n&lt;p&gt;As an MS student in statistics departments this is quite difficult. Any research have done is, well, statistical. With no cs background it becomes even harder to \u201cget experience\u201d in deep learning or machine learning research. &lt;/p&gt;\n\n&lt;p&gt;If there is anyone who made the switch to more deep learning or machine learning research roles as an applied scientist, how did you \u201cget experience\u201d in publishing ML papers? This is often a hard prerequisite I see in a lot of job descriptions, and I don\u2019t really know how to do this besides applying to PhD programs in CS or trying to take a pay cut to work as a researcher with professors in a CS dept. &lt;/p&gt;\n\n&lt;p&gt;If anyone has insights on how to break the cycle of getting experience to get experience for deep learning or machine learning research, I\u2019d love to know how you guys did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149bakb", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149bakb/how_to_break_the_need_experience_to_get/", "subreddit_subscribers": 924907, "created_utc": 1686757729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. \n\nIs this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.", "author_fullname": "t2_5238n9a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are extremely long take home assignments in interview processes the norm now, or am I unlucky?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149cj12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686762740.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the last 2 months I\u2019ve been referred to 2 roles, both at private equity firms coincidentally (edit: 1 was actually VC). Both times I\u2019ve been asked to complete take home assignments that are quite long within 2-3 days. Like multiple relatively complex modeling tasks on unclean data, in jargon-heavy domains, with a decent chunk of written analysis expected. I realized they\u2019re not expecting perfection, but even a sloppy write up would take at least 8 hours of my time in both cases imo. &lt;/p&gt;\n\n&lt;p&gt;Is this the norm for interview processes now or is it just private equity? I\u2019ve done take home assignments in the past and they were never this insane.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cj12", "is_robot_indexable": true, "report_reasons": null, "author": "ravidampatel", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cj12/are_extremely_long_take_home_assignments_in/", "subreddit_subscribers": 924907, "created_utc": 1686760756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is large but not very advanced technologically and the users of this prediction model will be lamens who input features of a new sample and want a prediction as an output. None of the users can have Python on their machine except for me, which is where I've built my models.  \n\n\nMost tools we make are built within excel as this is something everyone has access to and can use. I can use excel if I stick to simple regressions, but if I want something like a random forest regression model I don't think it's possible to build that into an excel formula or VBA (as far as I know).  \n\n\nHow do people normally get around this issue? Is there some easy alternative I'm missing?", "author_fullname": "t2_1055bs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Do You Let End Users Use Your Prediction Models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149jie6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686777608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is large but not very advanced technologically and the users of this prediction model will be lamens who input features of a new sample and want a prediction as an output. None of the users can have Python on their machine except for me, which is where I&amp;#39;ve built my models.  &lt;/p&gt;\n\n&lt;p&gt;Most tools we make are built within excel as this is something everyone has access to and can use. I can use excel if I stick to simple regressions, but if I want something like a random forest regression model I don&amp;#39;t think it&amp;#39;s possible to build that into an excel formula or VBA (as far as I know).  &lt;/p&gt;\n\n&lt;p&gt;How do people normally get around this issue? Is there some easy alternative I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149jie6", "is_robot_indexable": true, "report_reasons": null, "author": "Gef_1_Man_Army", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149jie6/how_do_you_let_end_users_use_your_prediction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149jie6/how_do_you_let_end_users_use_your_prediction/", "subreddit_subscribers": 924907, "created_utc": 1686777608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Could you please mention what are the best steps of feature engineering ?", "author_fullname": "t2_wasnzue9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the main steps for feature engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1495cyi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686741839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could you please mention what are the best steps of feature engineering ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1495cyi", "is_robot_indexable": true, "report_reasons": null, "author": "kavinda_uthsuka97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1495cyi/what_are_the_main_steps_for_feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1495cyi/what_are_the_main_steps_for_feature_engineering/", "subreddit_subscribers": 924907, "created_utc": 1686741839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Consulting analyst with 20 yrs across industries with functional DS and MLOps skills.  For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?\n\nIt\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..", "author_fullname": "t2_a6aqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are your executive team members armchair \u201cAI strategists\u201d now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149nszy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686788760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consulting analyst with 20 yrs across industries with functional DS and MLOps skills.  For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?&lt;/p&gt;\n\n&lt;p&gt;It\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149nszy", "is_robot_indexable": true, "report_reasons": null, "author": "JasonSuave", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "subreddit_subscribers": 924907, "created_utc": 1686788760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. \n\nWhat are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I've previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?", "author_fullname": "t2_9chfd9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Healthcare", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149amep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686756070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in Healthcare for a specialized  healthcare organization that takes on very sick members from large health insurance plans knowing that our specialized treatment can do better than their current treatment plans based on NYU studies. We use K means clustering to determine which members would be good candidates for our specialized care. I would like to work on additional projects involving Membership, Eligibility, Claims, Rx for our organization. Additionally I would like to look more at impactiblity of our K means selection as well. &lt;/p&gt;\n\n&lt;p&gt;What are some good projects and algorithms that may be helpful in developing new algorithms and data science tools for our organization. I&amp;#39;ve previously seen Data Science projects that can potentially predict who may be high risk for not taking their medication but wanted to see what others in Healthcare, specifically Medical Economics think. Is there a better way of calculating Membership, Utilization, PMPM, MLR, Ibnr using data science tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149amep", "is_robot_indexable": true, "report_reasons": null, "author": "Statefan3778", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149amep/data_science_in_healthcare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149amep/data_science_in_healthcare/", "subreddit_subscribers": 924907, "created_utc": 1686756070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey folks,   \nLet's say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no \"relevant\" domain experience. \n\nWhat are your advices on having more chances to be given a chance?\n\nI heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.  \nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?", "author_fullname": "t2_s9fqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to increase chances for an interview when switching industries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149cvkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686761622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks,&lt;br/&gt;\nLet&amp;#39;s say I worked as a DS in one industry (energy, medical, etc.) and want to set the foot into fintech, consumer goods or whatever else. I have a feeling that many initial HR screenings will filter my resume out because of no &amp;quot;relevant&amp;quot; domain experience. &lt;/p&gt;\n\n&lt;p&gt;What are your advices on having more chances to be given a chance?&lt;/p&gt;\n\n&lt;p&gt;I heard that I need to strip my CV out of any industry-specific staff and only describe technical achievements.&lt;br/&gt;\nAlso, if I did some online courses to understand the specifics of my new target industry, how to communicate that and highlight better? Put it on top of the Experience section?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149cvkw", "is_robot_indexable": true, "report_reasons": null, "author": "scriptosens", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149cvkw/how_to_increase_chances_for_an_interview_when/", "subreddit_subscribers": 924907, "created_utc": 1686761622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)", "author_fullname": "t2_a2ps3jf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on ETL tools like Azure Data Factory or AWS Glue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149chge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686760645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been trying to get started as a Data Analyst switching from a Software Developer position. I usually find myself using Python etc. to carry out the ETL process manually because I\u2019m too lazy to go through the learning curve of tools like Data Factory or AWS Glue. Do you think they are worth learning? Are they capable and intuitive for complex cleaning and transformation tasks?(I mainly work on Business Analytics projects)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149chge", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent-Bunch7505", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149chge/opinions_on_etl_tools_like_azure_data_factory_or/", "subreddit_subscribers": 924907, "created_utc": 1686760645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In Regression analysis, there are basically two hypothesis tests. T-Test and F-Tests.\n\nIn most books there is a big deal about the LINE assumptions of linear regression, but if I understand it right, the t test only needs normal distribution if the sample size is small. If I have a sufficiently large sample size, I would assume that we do not need normality of residuals in regression as the CLT kicks in?\n\nHow does that behave for the the F-Tests?\n\nHence in DS most sample sizes are large, can we just more or less skip the N in LINE? or is it a LIE?\n\n(Sorry)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nEdit:   \n\n\nI think when it comes to interpretation of transformations we still need the normality, assumption, as we apply the notion, that mean = median, which only holds for a at least symetric distribution of residuals.\n\nAnd I found this  \n\n\n[https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis](https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis)", "author_fullname": "t2_9jc8y5kx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Normality of residuals in linear regression for hypothesis tests.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1490r3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686727315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686725213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In Regression analysis, there are basically two hypothesis tests. T-Test and F-Tests.&lt;/p&gt;\n\n&lt;p&gt;In most books there is a big deal about the LINE assumptions of linear regression, but if I understand it right, the t test only needs normal distribution if the sample size is small. If I have a sufficiently large sample size, I would assume that we do not need normality of residuals in regression as the CLT kicks in?&lt;/p&gt;\n\n&lt;p&gt;How does that behave for the the F-Tests?&lt;/p&gt;\n\n&lt;p&gt;Hence in DS most sample sizes are large, can we just more or less skip the N in LINE? or is it a LIE?&lt;/p&gt;\n\n&lt;p&gt;(Sorry)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit:   &lt;/p&gt;\n\n&lt;p&gt;I think when it comes to interpretation of transformations we still need the normality, assumption, as we apply the notion, that mean = median, which only holds for a at least symetric distribution of residuals.&lt;/p&gt;\n\n&lt;p&gt;And I found this  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis\"&gt;https://blog.minitab.com/en/adventures-in-statistics-2/how-important-are-normal-residuals-in-regression-analysis&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?auto=webp&amp;v=enabled&amp;s=72c13130d870084d77eda19882d28124c486f818", "width": 576, "height": 384}, "resolutions": [{"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=058d21915c61f3473bff13f8f8f2c4f6d0b021b5", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=add76eef4177ac69590f8a74cd0ab7673383effc", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Y4KpixsVJp69cjALqcCXgKDTNU6ltEnkvOGjwyWyKuw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8e1bf1d17da2da349262ce590a7413c77996bac", "width": 320, "height": 213}], "variants": {}, "id": "A1UkfvdVRRULPfpZqh4KtHTnbw5sv3j-itYfKqCA6V0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1490r3e", "is_robot_indexable": true, "report_reasons": null, "author": "dududu87", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1490r3e/normality_of_residuals_in_linear_regression_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1490r3e/normality_of_residuals_in_linear_regression_for/", "subreddit_subscribers": 924907, "created_utc": 1686725213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    \n\n\nIf anybody can please ping me we can discuss it in more detail.  \n\n\nThanks!", "author_fullname": "t2_t423y52t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to scrape unstructured and repetitive data from a pdf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ky0f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    &lt;/p&gt;\n\n&lt;p&gt;If anybody can please ping me we can discuss it in more detail.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ky0f", "is_robot_indexable": true, "report_reasons": null, "author": "YoloPoloGolo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "subreddit_subscribers": 924907, "created_utc": 1686781156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have noticed among data scientists I know in the UK, that none native speakers get paid less, get promoted less, change companies less than their Native English speakers counterparts. Some times even though none native speakers are more with higher degrees, more skilled. \nThis is a common trend among people I know and may not apply to everyone. I would love to hear if others seeing the same trend or not.\nHow a none native speakers data scientist can break of the cycle of being under paid?", "author_fullname": "t2_b4f14n03l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does UK companies pay none native speakers data scientists less? And why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149fbpi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686767570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have noticed among data scientists I know in the UK, that none native speakers get paid less, get promoted less, change companies less than their Native English speakers counterparts. Some times even though none native speakers are more with higher degrees, more skilled. \nThis is a common trend among people I know and may not apply to everyone. I would love to hear if others seeing the same trend or not.\nHow a none native speakers data scientist can break of the cycle of being under paid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149fbpi", "is_robot_indexable": true, "report_reasons": null, "author": "glo-aistar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149fbpi/does_uk_companies_pay_none_native_speakers_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149fbpi/does_uk_companies_pay_none_native_speakers_data/", "subreddit_subscribers": 924907, "created_utc": 1686767570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1498fdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_cvej3qatd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "FeatureEng", "selftext": "Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:\n\n1. A feature with high impact does not necessarily have a causal relationship with the target variable.\n2. The feature relationship learned by the model may not generalize well in the future.\n\nTo illustrate this, let's consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn't seen new timestamps before and doesn't know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.\n\nThis problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.\n\nI encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition's conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.\n\nTo address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here's what I did for the GE Flight Quest:\n\n1. Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.\n2. Then, I trained a second model to capture the residual effects specific to each airport.\n\nThis two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.\n\nI see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:\n\n1. Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.\n2. Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.\n\nHave you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?\n\nGxav", "author_fullname": "t2_cvej3qatd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Features that may have poor representation in the training data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/FeatureEng", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_147x9gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686602923.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Feature selection is a challenging task in machine learning, and while feature importance reports can be helpful, blindly trusting all features is not always recommended. There are two important facts I try to keep in mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A feature with high impact does not necessarily have a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;The feature relationship learned by the model may not generalize well in the future.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To illustrate this, let&amp;#39;s consider the example of a timestamp feature in an XGBoost model. The timestamp may exhibit high importance in the model, but it can lead to poor performance during inference. This is because the model hasn&amp;#39;t seen new timestamps before and doesn&amp;#39;t know how to extrapolate from them. The model predicts as if the new timestamps are equal to the latest timestamp in the training data. This example demonstrates the issue of prediction data having a different distribution from the training data, with unseen distribution points.&lt;/p&gt;\n\n&lt;p&gt;This problem of poor generalization can also occur when the joint distribution of the prediction data differs from that of the training data.&lt;/p&gt;\n\n&lt;p&gt;I encountered this problem during the GE Flight Quest competition, where I had to predict future delays of US domestic flights. The training data covered a three-month period, while the final test data consisted of data from the month following the competition&amp;#39;s conclusion. Weather conditions varied during those three months, and while the training data covered all airports, some airports did not experience poor weather. This posed a risk that the distribution of weather conditions per airport observed in the training data was not representative of the distribution at prediction time. I was concerned that XGBoost might use the airport name as a proxy for good weather and fail to predict delays when poor weather conditions occurred in those airports that had not experienced poor weather in the training data.&lt;/p&gt;\n\n&lt;p&gt;To address this challenge, I employed a two-stage modeling approach that I learned from the insurance industry. Here&amp;#39;s what I did for the GE Flight Quest:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Initially, I trained my model using features related to adverse weather and traffic conditions, which I intuitively believed had a strong causal relationship with flight delays.&lt;/li&gt;\n&lt;li&gt;Then, I trained a second model to capture the residual effects specific to each airport.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This two-stage approach can be compared to boosting. The prediction of the first model serves as an offset for the second model. The key difference is that the choice of features is not random; you start with features you trust.&lt;/p&gt;\n\n&lt;p&gt;I see this approach as a good candidate to reduce potential model bias. The strategy would be as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Train a first model using features that you have high confidence in and trust, and that you intuitively see a causal relationship with the target variable.&lt;/li&gt;\n&lt;li&gt;Train a second model using the predictions of the first model as an offset, while incorporating features in which you have less confidence.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Have you employed similar two-stage modeling approaches to reduce bias? Can you recommend alternative modeling techniques to handle features with poor representation in the training data?&lt;/p&gt;\n\n&lt;p&gt;Gxav&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_8kc7h0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "147x9gj", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 57, "created_utc": 1686602923.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1686750652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.FeatureEng", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1498fdy", "is_robot_indexable": true, "report_reasons": null, "author": "Gxav73", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_147x9gj", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1498fdy/features_that_may_have_poor_representation_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/FeatureEng/comments/147x9gj/features_that_may_have_poor_representation_in_the/", "subreddit_subscribers": 924907, "created_utc": 1686750652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I have a basic machine learning background and understand the \"traditional\" regression/classification models etc. and would like to get some solid knowledge on deep learning. I recently watched the MIT DL series on youtube, which is a good foundation, but I feel it lacks a lot of practicality. Additionally, a lot of the online courses are outdated and use obsolete versions of machine learning libraries.\n\nI'm looking for a relatively new/updated course on deep learning that will teach me the basics such as CNN, RNN, reinforcement learning, generative models etc. Preferably, there will be a good explanation on the maths behind these concepts and there will also be good practical examples/coding projects.", "author_fullname": "t2_4pjl2389", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the Best Online Deep Learning Course for 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1494bor", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686738446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I have a basic machine learning background and understand the &amp;quot;traditional&amp;quot; regression/classification models etc. and would like to get some solid knowledge on deep learning. I recently watched the MIT DL series on youtube, which is a good foundation, but I feel it lacks a lot of practicality. Additionally, a lot of the online courses are outdated and use obsolete versions of machine learning libraries.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a relatively new/updated course on deep learning that will teach me the basics such as CNN, RNN, reinforcement learning, generative models etc. Preferably, there will be a good explanation on the maths behind these concepts and there will also be good practical examples/coding projects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1494bor", "is_robot_indexable": true, "report_reasons": null, "author": "souvlaki_mix", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1494bor/which_is_the_best_online_deep_learning_course_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1494bor/which_is_the_best_online_deep_learning_course_for/", "subreddit_subscribers": 924907, "created_utc": 1686738446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team builds and maintains a number of models and dashboards in addition to undertaking analytics projects for a large business. Normally with the teams we are structurally closer to we would build something for a team, have agreed scope and touch points through an engagement. As part of that we walk the team through use of the product etc.\nMany of our more sophisticated models were built as self scoped initiatives where we anticipated a need. Most of these have proven quite popular and a number of more removed business units know us for these products. \nHowever, we recently moved to a new division we previously did a fair amount of work for. This division has had significant turnover in the past few years. Despite spending a significant amount of time explaining these models to new hires(and their replacements) in these teams. There is persistent commentary that these teams don't have what they need and that they are not aware these products exist and don't have access. However these teams don't come and ask for information, first interaction is that complaint. \n\nNo other teams outside this division we work with act like this. They all come with questions or projects and we're generally well regarded. \n\nI think we have more than met what is required in explaning the use and existence of these products. And that it's not my role to make sure there is handover within other teams. Particularly as we don't know about turnover elsewhere. Am I wrong?\n\nWe've met with these teams to determine their priorities and directly ask what their needs are, what work may be upcoming etc, we direct them to resources and work with them as needed but I'm at a loss of what else I can do. \n\nFull disclosure I've tapered off these explanations as they were taking up too much time and impacting our availability and deliverables", "author_fullname": "t2_1pb50w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice: Who's responsible for keeping end users aware of a model and other data products", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1492eu4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686731388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team builds and maintains a number of models and dashboards in addition to undertaking analytics projects for a large business. Normally with the teams we are structurally closer to we would build something for a team, have agreed scope and touch points through an engagement. As part of that we walk the team through use of the product etc.\nMany of our more sophisticated models were built as self scoped initiatives where we anticipated a need. Most of these have proven quite popular and a number of more removed business units know us for these products. \nHowever, we recently moved to a new division we previously did a fair amount of work for. This division has had significant turnover in the past few years. Despite spending a significant amount of time explaining these models to new hires(and their replacements) in these teams. There is persistent commentary that these teams don&amp;#39;t have what they need and that they are not aware these products exist and don&amp;#39;t have access. However these teams don&amp;#39;t come and ask for information, first interaction is that complaint. &lt;/p&gt;\n\n&lt;p&gt;No other teams outside this division we work with act like this. They all come with questions or projects and we&amp;#39;re generally well regarded. &lt;/p&gt;\n\n&lt;p&gt;I think we have more than met what is required in explaning the use and existence of these products. And that it&amp;#39;s not my role to make sure there is handover within other teams. Particularly as we don&amp;#39;t know about turnover elsewhere. Am I wrong?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve met with these teams to determine their priorities and directly ask what their needs are, what work may be upcoming etc, we direct them to resources and work with them as needed but I&amp;#39;m at a loss of what else I can do. &lt;/p&gt;\n\n&lt;p&gt;Full disclosure I&amp;#39;ve tapered off these explanations as they were taking up too much time and impacting our availability and deliverables&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1492eu4", "is_robot_indexable": true, "report_reasons": null, "author": "origami_knight", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1492eu4/advice_whos_responsible_for_keeping_end_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1492eu4/advice_whos_responsible_for_keeping_end_users/", "subreddit_subscribers": 924907, "created_utc": 1686731388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the context of a bank's internal audit function, I understand that it is about risk management by evaluating the controls and processes.\n\nHow do we apply machine learning in the internal audit function?", "author_fullname": "t2_pnx7y1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Machine Learning in Internal Audit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149ptdq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686794593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the context of a bank&amp;#39;s internal audit function, I understand that it is about risk management by evaluating the controls and processes.&lt;/p&gt;\n\n&lt;p&gt;How do we apply machine learning in the internal audit function?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ptdq", "is_robot_indexable": true, "report_reasons": null, "author": "appleciderv", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ptdq/machine_learning_in_internal_audit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ptdq/machine_learning_in_internal_audit/", "subreddit_subscribers": 924907, "created_utc": 1686794593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an engineering degree in hydraulic engineering, and i want to completely switch career to data science. My question is for me later to get a job, is it best to:  \n1- Study online free courses on coursera and then afterwards pass certification Azure/GC/AWS.\n\n2- Look for a university for a Master's degree (and probably study online).  \n\n\nI'm not working nor planning to work this whole entire time, so i'm looking for a cost effective solution , And i really don't wanna follow a path and waste my time.  \nThanks in advance, and pardon my english.", "author_fullname": "t2_3xfhtj08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to study online free courses or to take a course in a university?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149pt2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686794573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an engineering degree in hydraulic engineering, and i want to completely switch career to data science. My question is for me later to get a job, is it best to:&lt;br/&gt;\n1- Study online free courses on coursera and then afterwards pass certification Azure/GC/AWS.&lt;/p&gt;\n\n&lt;p&gt;2- Look for a university for a Master&amp;#39;s degree (and probably study online).  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not working nor planning to work this whole entire time, so i&amp;#39;m looking for a cost effective solution , And i really don&amp;#39;t wanna follow a path and waste my time.&lt;br/&gt;\nThanks in advance, and pardon my english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149pt2v", "is_robot_indexable": true, "report_reasons": null, "author": "EcstaticShadow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149pt2v/is_it_better_to_study_online_free_courses_or_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149pt2v/is_it_better_to_study_online_free_courses_or_to/", "subreddit_subscribers": 924907, "created_utc": 1686794573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "cross posting from analytics to here in hopes to get some thoughts on this:\n\n&amp;#x200B;\n\nHow should your approach change in analyzing results if you have 3 groups?\n\nWe have an A/B test measuring clicks per user, and we have a control group and 2 treatment groups so 3 groups total.\n\ndo we typically try to measure performance of 1 group against both groups, or do we typically measure performance of 1 group vs 1 of the other 2, if that makes sense. for example group A vs group B, and then group A vs group C, or do we try to say \"group A showed an statistically sig lift vs groups B and C\"", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B. test with 2 groups vs 3 groups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149m9s7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686784559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;cross posting from analytics to here in hopes to get some thoughts on this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How should your approach change in analyzing results if you have 3 groups?&lt;/p&gt;\n\n&lt;p&gt;We have an A/B test measuring clicks per user, and we have a control group and 2 treatment groups so 3 groups total.&lt;/p&gt;\n\n&lt;p&gt;do we typically try to measure performance of 1 group against both groups, or do we typically measure performance of 1 group vs 1 of the other 2, if that makes sense. for example group A vs group B, and then group A vs group C, or do we try to say &amp;quot;group A showed an statistically sig lift vs groups B and C&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149m9s7", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149m9s7/ab_test_with_2_groups_vs_3_groups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149m9s7/ab_test_with_2_groups_vs_3_groups/", "subreddit_subscribers": 924907, "created_utc": 1686784559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First of all: not a data scientist.\n\nI have a time series and I would like to detect steps. I've found a few algorithms on the internet but they are too parametric and need a lot of optimization that is hard to apply to versatile time series. \n\nMy data is not very noisy and there are very strong steps just like from a stair. One data set has about 40 steps. One drawback is that sometimes the steps start with a strong peak that very quickly fades again. Essentially a needle placed vertically at the beginning of a step, whereas a step should be defined at the beginning of these needles.\n\nWhat so far worked best was just to compute a moving min-max with window size of e.g. 5. If the min max surpasses a certain threshold I interpret it as a step. This leads to about 4 consecutive values surpassing that value such that I get rid of the first 3 and classify the 4th as a \"step\".    \n\nHowever, one problem arises when the step is very small and falls below the noise of my data, but the step is still very apparent. In that case I should be doing a t-test to compare the means of previous to subsequent steps with also e.g. window size 5, but I don't know how to implement it such that it only applies to these affected regions. It would be amazing to perform a \"moving t-test with window size 5 and 5, both windows representing one sample and being located next to each other\" instead of \"min max\".\n\nDo you think this is a good approach and if so, could you add something to that? Alternative approaches are also appreciated.\n\nI was also thinking about using a convolutional neural network with a 1D kernel and training data, but I think that ML algorithms will not do the job especially since labeling my graphs would take an eternity and hyperparameter tuning too.\n\nThanks!", "author_fullname": "t2_2fohpkzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Step detector algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149l3rz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686782267.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all: not a data scientist.&lt;/p&gt;\n\n&lt;p&gt;I have a time series and I would like to detect steps. I&amp;#39;ve found a few algorithms on the internet but they are too parametric and need a lot of optimization that is hard to apply to versatile time series. &lt;/p&gt;\n\n&lt;p&gt;My data is not very noisy and there are very strong steps just like from a stair. One data set has about 40 steps. One drawback is that sometimes the steps start with a strong peak that very quickly fades again. Essentially a needle placed vertically at the beginning of a step, whereas a step should be defined at the beginning of these needles.&lt;/p&gt;\n\n&lt;p&gt;What so far worked best was just to compute a moving min-max with window size of e.g. 5. If the min max surpasses a certain threshold I interpret it as a step. This leads to about 4 consecutive values surpassing that value such that I get rid of the first 3 and classify the 4th as a &amp;quot;step&amp;quot;.    &lt;/p&gt;\n\n&lt;p&gt;However, one problem arises when the step is very small and falls below the noise of my data, but the step is still very apparent. In that case I should be doing a t-test to compare the means of previous to subsequent steps with also e.g. window size 5, but I don&amp;#39;t know how to implement it such that it only applies to these affected regions. It would be amazing to perform a &amp;quot;moving t-test with window size 5 and 5, both windows representing one sample and being located next to each other&amp;quot; instead of &amp;quot;min max&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Do you think this is a good approach and if so, could you add something to that? Alternative approaches are also appreciated.&lt;/p&gt;\n\n&lt;p&gt;I was also thinking about using a convolutional neural network with a 1D kernel and training data, but I think that ML algorithms will not do the job especially since labeling my graphs would take an eternity and hyperparameter tuning too.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149l3rz", "is_robot_indexable": true, "report_reasons": null, "author": "mikehawk1988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149l3rz/step_detector_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149l3rz/step_detector_algorithm/", "subreddit_subscribers": 924907, "created_utc": 1686781556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just curious, working at a healthcare company, Thanks for your time and consideration.", "author_fullname": "t2_cilgh4v8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best database solution to store large amounts of medical health record data, including both structured data as well as large images, and be able to perform fast aggregate analytics as well as standard SQL-like queries (record lookup, join, etc.)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149jpiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686778089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious, working at a healthcare company, Thanks for your time and consideration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149jpiv", "is_robot_indexable": true, "report_reasons": null, "author": "AdhesivenessFinal421", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149jpiv/what_is_the_best_database_solution_to_store_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149jpiv/what_is_the_best_database_solution_to_store_large/", "subreddit_subscribers": 924907, "created_utc": 1686778089.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}